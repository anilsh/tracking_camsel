{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Camera Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io as spio\n",
    "#from __future__ import print_function\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from IPython.display import clear_output\n",
    "from IPython import display\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "#import cv2 as cv\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is available\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "from torch.distributions import Categorical\n",
    "import time, math\n",
    " \n",
    "torch.backends.cudnn.enabled = True\n",
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "use_cuda = torch.cuda.is_available()\n",
    "\n",
    "if use_cuda:\n",
    "    print ('CUDA is available')\n",
    "#use_cuda=False   #uncomment this if you dont want to use cuda variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import gc\n",
    "import collections\n",
    "# import hickle as hkl\n",
    "# import ttictoc as tt\n",
    "\n",
    "sys.path.insert(0, '../data/')\n",
    "import get_pid_train_test as db\n",
    "import auxiliary as af"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sys.path.insert(0,'../py-MDNet/modules')\n",
    "# from sample_generator import *\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test function\n",
    "def plot_current_state(ped, c,fno):\n",
    "    # load image for current location\n",
    "    img,bb = load_image(ped,c,fno,db_no)\n",
    "\n",
    "    dpi = 80.0\n",
    "    #figsize = (img.size[0]/dpi, img.size[1]/dpi)\n",
    "    figsize = (img.shape[0]/dpi, img.shape[1]/dpi)\n",
    "    fig = plt.figure(frameon=False, figsize=figsize, dpi=dpi)\n",
    "    ax = plt.Axes(fig, [0., 0., 1., 1.])\n",
    "    ax.set_axis_off()\n",
    "    fig.add_axes(ax)\n",
    "\n",
    "    # get image and rect handle\n",
    "    imAX = ax.imshow(img, aspect='normal')\n",
    "    rect = plt.Rectangle(tuple(bb[0,:2]),bb[0,2],bb[0,3], \n",
    "        linewidth=3, edgecolor=\"#ff0000\", zorder=1, fill=False)\n",
    "    ax.add_patch(rect)\n",
    "\n",
    "    plt.pause(.01)\n",
    "    plt.draw()\n",
    "    #fig.savefig(os.path.join(savefig_dir,'0000.jpg'),dpi=dpi)\n",
    "    \n",
    "    return imAX, rect\n",
    "    \n",
    "def plot_second(ped,c,curr_frame, imAX,rect):\n",
    "    img,bb =  load_image(ped,c,curr_frame,db_no)\n",
    "    #if np.array(img).shape[0] > 0:\n",
    "    if img != []:\n",
    "        imAX.set_data(img)\n",
    "    #print (bb)\n",
    "\n",
    "    #if bb.shape[0] > 0:\n",
    "    if bb != []:\n",
    "        rect.set_xy(bb[0,:2])\n",
    "        rect.set_width(bb[0,2])\n",
    "        rect.set_height(bb[0,3])\n",
    "        print ('Correct camera')\n",
    "    elif c!= num_camera-1:\n",
    "        print ('Wrong camera')\n",
    "\n",
    "    \n",
    "    display.display(plt.gcf())\n",
    "    plt.pause(1)\n",
    "    plt.draw()\n",
    "    #fig.savefig(os.path.join(savefig_dir,'%04d.jpg'%(i)),dpi=dpi)\n",
    "\n",
    "def get_reward_gt(ped, curr_frame, c):\n",
    "    y = afc.find_target_camera(ped,curr_frame)\n",
    "    # get reward (give reward at end of episode)\n",
    "    if y == num_camera-1 and y == c:\n",
    "        reward = 0\n",
    "    elif y == c:\n",
    "        reward = 1\n",
    "    else:\n",
    "        reward = -1\n",
    "        \n",
    "    return reward,y\n",
    "\n",
    "def get_next_step(ped,c,curr_frame, state):\n",
    "    # update current state and history\n",
    "    ispresent,this_state = get_state_vector(ped, c,curr_frame)\n",
    "    if ispresent:\n",
    "        next_state = this_state\n",
    "    else:\n",
    "        # use previous state\n",
    "        next_state = state\n",
    "    \n",
    "    # get correct label from ground truth\n",
    "    reward,y = get_reward_gt(ped, curr_frame,c)\n",
    "\n",
    "    return next_state,reward,y,ispresent\n",
    "\n",
    "def test_func(pTest, iloc='first', eloc='last', fixLoc=-1, isdebug=0, req_inc=1):\n",
    "    policy_net.eval()\n",
    "    rsT,accT = [],[]\n",
    "    Qvalues = []\n",
    "    numTrAllP = []\n",
    "    \n",
    "    for p in range(pTest.shape[0]): \n",
    "        reward_sum = 0\n",
    "        accP = []\n",
    "        inc = 1\n",
    "        aaa = 1\n",
    "        Qval_1p = []\n",
    "        numTr = 0\n",
    "        \n",
    "        # load p'th person data\n",
    "        ped = np.copy(pTest[p])\n",
    "        # camera index and frame index starts from zero\n",
    "        ped[:,0] -= 1\n",
    "        ped[:,1] -= 1\n",
    "        \n",
    "        # Initialize with current state with start frame\n",
    "        if iloc == 'first':\n",
    "            startIDX = 0\n",
    "        elif iloc == 'rand':\n",
    "            startIDX = np.random.randint( 0,ped.shape[0]-20 )\n",
    "        elif iloc == 'fix':\n",
    "            startIDX = fixLoc\n",
    "        if startIDX > ped.shape[0]:\n",
    "            continue\n",
    "        myPos = ped[startIDX,0:]\n",
    "        print ('Initial position: ',myPos)\n",
    "        \n",
    "        curr_camera = myPos[0]\n",
    "        curr_frame = myPos[1]\n",
    "        \n",
    "        # Initialize history variable (one-hot encoding)\n",
    "        ch = np.zeros((h_len,duke_cam))\n",
    "        occ_len = 0.01\n",
    "        # Make initial state\n",
    "        x_t,c_t,te_tau,r_t = make_state_vector(ped, curr_camera,curr_frame,ch,occ_len)\n",
    "        prev_rt = r_t[0:4]\n",
    "        #print (state.size())\n",
    "        num_steps = 0\n",
    "        prev_camera = curr_camera\n",
    "        count_curr_c = 0\n",
    "        \n",
    "        if render: # show current location\n",
    "            plot_current_state(ped, curr_camera,curr_frame)\n",
    "\n",
    "            display.clear_output(wait=True)\n",
    "            display.display(plt.gcf())\n",
    "\n",
    "        # select an action from the current state\n",
    "        hidden, cell = enc(torch.from_numpy(ch).float().cuda().unsqueeze(1))\n",
    "        #print (x_t.size(),h_t.size(),enc_history.size())\n",
    "        state_xt = torch.cat([x_t, te_tau], dim=1)\n",
    "        state = torch.cat([state_xt, hidden[1,].detach()], dim=1)\n",
    "        \n",
    "        \n",
    "        while(curr_frame <= ped[-1,1]): # alltime-6):\n",
    "            \n",
    "            if use_cuda:\n",
    "                state_in = Variable(state)\n",
    "                value_c = policy_net(state_in)\n",
    "            else:\n",
    "                state_in = Variable(state)\n",
    "                value_c = policy_net(state_in)\n",
    "                \n",
    "            # Only exploitation for testing\n",
    "            camera_index = torch.argmax(value_c)\n",
    "            c = camera_index.detach().cpu().numpy()\n",
    "            \n",
    "            occ_max_val = 12000000\n",
    "            aaa += 1\n",
    "            if aaa > 1 and occ_len > occ_max_val:\n",
    "                c = c #np.array(num_camera-1)\n",
    "            if occ_len > occ_max_val and aaa%50 == 0:\n",
    "                aaa = 1\n",
    "                c = np.array(np.random.randint(num_camera))\n",
    "\n",
    "            # find target for the next frame\n",
    "            curr_frame += fpsc\n",
    "            num_steps += 1\n",
    "            \n",
    "            # get correct label from ground truth\n",
    "            reward,y = get_reward_gt(ped, curr_frame,c)\n",
    "            #if req_inc:\n",
    "            if inc==1 and y!=num_camera-1:\n",
    "                # inside a camera\n",
    "                if req_inc:\n",
    "                    accP.append((y,y))\n",
    "                    c = y\n",
    "                else:\n",
    "                    accP.append((y,c.item(0)))\n",
    "            elif inc==0 and y==c.item(0) and y!=num_camera-1:\n",
    "                # transitioning to second camera\n",
    "                accP.append((y,c.item(0)))\n",
    "                inc = 1\n",
    "                numTr += 1\n",
    "            elif inc==1 and y==num_camera-1:\n",
    "                # moving out of a camera FOV\n",
    "                inc = 0\n",
    "                accP.append((y,c.item(0)))\n",
    "            else:\n",
    "                # Making transition\n",
    "                accP.append((y,c.item(0)))\n",
    "                #print ('Another case',y,c.item(0))\n",
    "                    \n",
    "            #else:\n",
    "            #    accP.append((y,c.item(0)))\n",
    "            \n",
    "            # get the current bounding box\n",
    "            bbox = ped[ np.logical_and(ped[:,0]==c,ped[:,1]==curr_frame),2:]\n",
    "            if bbox.shape[0] > 0: # and np.random.rand < 0.95:\n",
    "                bbox = bbox[0]\n",
    "                rt = np.zeros((8))\n",
    "                rt[0] = bbox[0]/1920 -(np.random.rand()-0.5)/100\n",
    "                rt[1] = bbox[1]/1080 -(np.random.rand()-0.5)/100\n",
    "                rt[2] = bbox[2]/1920 -(np.random.rand()-0.5)/100\n",
    "                rt[3] = bbox[3]/1080 -(np.random.rand()-0.5)/100\n",
    "                rt[4] = rt[0] - prev_rt[0] if occ_len < 0.2 else 0\n",
    "                rt[5] = rt[1] - prev_rt[1] if occ_len < 0.2 else 0\n",
    "                rt[6] = rt[2] - prev_rt[2] if occ_len < 0.2 else 0\n",
    "                rt[7] = rt[3] - prev_rt[3] if occ_len < 0.2 else 0\n",
    "                curr_camera = c\n",
    "                \n",
    "                # make next_state vector\n",
    "                this_cam = afc.make_one_hot_camera(curr_camera)\n",
    "                x_t = np.concatenate((this_cam, rt.ravel()))\n",
    "                x_t[x_t==0] = -10\n",
    "                x_t[x_t==1] = 10\n",
    "                x_t = x_t.reshape(1,-1)\n",
    "                if use_cuda:\n",
    "                    x_t = torch.from_numpy(x_t).float().cuda()\n",
    "                \n",
    "                \n",
    "                ispresent = 1\n",
    "                prev_rt = rt[0:4]\n",
    "                    \n",
    "            else:\n",
    "                ispresent = 0\n",
    "                \n",
    "            # count the time of prev_camera selection\n",
    "            if ispresent:\n",
    "                occ_len = 0.01\n",
    "            else:\n",
    "                occ_len += 1\n",
    "            #hcount = np.array(-occ_max_val + (occ_len/500)*(occ_max_val-(-occ_max_val)))\n",
    "            hcount = np.array(10*np.log(occ_len))\n",
    "            \n",
    "            # update current state and history\n",
    "            ch[1:,] = ch[0:-1,]\n",
    "            ch[0,0:num_camera] = afc.make_one_hot_camera(c)\n",
    "            ch[0,num_camera:] = 0\n",
    "            this_cam = afc.make_one_hot_camera(c)\n",
    "            c_t = this_cam.reshape(1,-1)\n",
    "            \n",
    "            if use_cuda:\n",
    "                c_t = torch.from_numpy(c_t).float().cuda()\n",
    "                te_tau = torch.from_numpy(hcount.reshape(1,-1)).float().cuda()\n",
    "            else:\n",
    "                c_t = torch.from_numpy(c_t).float()\n",
    "                te_tau = torch.from_numpy(hcount.reshape(1,-1)).float()\n",
    "                \n",
    "            if isdebug:\n",
    "                print ( np.where(rt.ravel()))\n",
    "                print ( np.where(ch))\n",
    "                print (c, curr_frame)\n",
    "                print ('isPresent', ispresent)\n",
    "                \n",
    "            # make next_state vector\n",
    "            hidden, cell = enc(torch.from_numpy(ch).float().cuda().unsqueeze(1))\n",
    "            #print (x_t.size(),h_t.size(),enc_history.size())\n",
    "            next_state_xt = torch.cat([x_t, te_tau], dim=1)\n",
    "            next_state = torch.cat([next_state_xt, hidden[1,].detach()], dim=1)\n",
    "            \n",
    "            # store current reward\n",
    "            reward_sum += reward\n",
    "            Qval_1p.append((list(value_c.detach().cpu().numpy()[0]),hcount.ravel()[0],reward,False,y,c,state.detach().cpu().numpy()))\n",
    "                        \n",
    "            #state = next_state\n",
    "            #state_xt = next_state_xt\n",
    "            state = next_state #torch.cat([state_xt, enc_history], dim=1)\n",
    "            prev_camera = c\n",
    "            \n",
    "            if render:\n",
    "                plot_second()\n",
    "            if eloc != 'last':\n",
    "                if num_steps > eloc:\n",
    "                    break\n",
    "            \n",
    "        # stack episodic reward \n",
    "        Qvalues.append((np.stack(Qval_1p)))\n",
    "        rsT.append((reward_sum,num_steps))\n",
    "        accT.append(accP)\n",
    "        numTrAllP.append(numTr)\n",
    "        \n",
    "    return rsT, accT, Qvalues, numTrAllP\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize hyper-parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-4\n",
    "batch_size = 1500\n",
    "replay_memory_size = 20000\n",
    "#epsilon = 0.1\n",
    "gamma = 0.99\n",
    "\n",
    "resume = False # resume from previous checkpoint\n",
    "render = False\n",
    "eps = np.finfo(np.float32).eps.item()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of person in data set:  (1, 1812)\n",
      "Total number of person in data set:  (1, 1812)\n"
     ]
    }
   ],
   "source": [
    "# load dataset\n",
    "db_no = 5\n",
    "[pALL,num_camera,alltime,fps] = db.get_pid(set_no=db_no, train_flag='train')\n",
    "num_camera += 1  # occlusion is also considered as a FOV\n",
    "fpsc = 6\n",
    "pALL = np.array(pALL)\n",
    "\n",
    "# load test set for current data set\n",
    "[pTest,num_camera,alltime,fps] = db.get_pid(set_no=db_no, train_flag='test')\n",
    "num_camera += 1  # occlusion is also considered as a FOV\n",
    "fpsc = 2\n",
    "pTest = np.array(pTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainval2.csv  trainval.csv  trainval.mat  trainvalRaw.csv  trainvalRaw.mat\r\n"
     ]
    }
   ],
   "source": [
    "!ls /home/anils/8tb/hpc-storage/dukeMTMC/ground_truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of full ground truth (4077132, 6)\n"
     ]
    }
   ],
   "source": [
    "tvmat = spio.loadmat('/home/anils/8tb/hpc-storage/dukeMTMC/ground_truth/trainval.mat')\n",
    "camGTT = tvmat['trainData'].astype(np.int)\n",
    "camGT = camGTT[:,[0,2,3,4,5,6]]\n",
    "camGT[:,0]-=1\n",
    "camGT[:,1]-=1\n",
    "# camGT = matlab.double(camGT)\n",
    "print('Shape of full ground truth', camGT.shape)\n",
    "\n",
    "\n",
    "# camGTT = pd.read_csv(os.path.expanduser('~/8tb/hpc-storage/nlpr/annotation_files/annotation/Dataset' + str(db_no) + '/fullgt.csv'), header=None).values.astype(np.int)[:,:7]\n",
    "# tmp = np.copy(camGTT[:,1])\n",
    "# camGTT[:,1] = camGTT[:,2]\n",
    "# camGTT[:,2] = tmp\n",
    "# camGT = camGTT[:,[0,2,3,4,5,6]]\n",
    "\n",
    "# # In NLPR GT, frames already start with 0, only cam needs to be decremented\n",
    "# camGT[:,0]-=1\n",
    "# # camGT[:,1]-=1\n",
    "# # camGT = matlab.double(camGT)\n",
    "# print('Shape of full ground truth', camGT.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "numEpoch = 100000\n",
    "d = 10\n",
    "region_size = (d,d)\n",
    "\n",
    "h_len = 10\n",
    "\n",
    "# Load auxiliary functions using an object\n",
    "afc = af.AuxiliaryFunction(num_camera=num_camera, d=d, h_len=h_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Policy Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize required parameters\n",
    "lstm_size = 256\n",
    "hidden_size1 = 4096\n",
    "hidden_size2 = 2048\n",
    "hidden_size3 = 256\n",
    "\n",
    "input_size = lstm_size + num_camera+ 4*2 +1\n",
    "\n",
    "# Required network\n",
    "class NextCamera(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NextCamera, self).__init__()\n",
    "        \n",
    "        # make decoder layers\n",
    "        self.fch1 = nn.Linear(input_size, hidden_size1)\n",
    "        self.fch2 = nn.Linear(hidden_size1, hidden_size2)\n",
    "        self.fch3 = nn.Linear(hidden_size2, hidden_size3)\n",
    "        self.fco = nn.Linear(hidden_size3, num_camera)\n",
    "        \n",
    "        # Activation function \n",
    "        self.tanh = nn.Tanh() #ReLU()\n",
    "        self.relu = nn.ReLU() #ReLU()\n",
    "        #self.linear = nn.Linear() \n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = self.relu(self.fch1(x))\n",
    "        x = self.relu(self.fch2(x))\n",
    "        x = self.relu(self.fch3(x))\n",
    "        x = self.fco(x)\n",
    "            \n",
    "        return x # nn.functional.softmax(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build the model\n",
    "if use_cuda:\n",
    "    policy_net = NextCamera().float().cuda()\n",
    "    criterion = nn.MSELoss().cuda()\n",
    "    \n",
    "else:\n",
    "    policy_net = NextCamera().float()\n",
    "    criterion = nn.MSELoss()\n",
    "    \n",
    "if use_cuda:\n",
    "    target_net = NextCamera().cuda()\n",
    "    target_net.float().cuda()\n",
    "target_net.load_state_dict(policy_net.state_dict())\n",
    "\n",
    "# use ADAM as optimizer since we can load the whole data to train\n",
    "optimizer = optim.Adam(policy_net.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backward_network(replay_memory_pos,pos_prob, replay_memory_neg, replay_memory_cx, update_criteria):\n",
    "\n",
    "    # sample random minibatch\n",
    "    minibatch_pos = random.choices(replay_memory_pos, k=min(len(replay_memory_pos), 500), weights=pos_prob)\n",
    "    #minibatch_pos = random.sample(replay_memory_pos, min(len(replay_memory_pos), 300)) #int(batch_size/3)))\n",
    "    minibatch_posneg = minibatch_pos + random.sample(replay_memory_neg, min(len(replay_memory_neg), 500)) # int(batch_size/3)))\n",
    "    minibatch = minibatch_posneg + random.sample(replay_memory_cx, min(len(replay_memory_cx), 500)) #int(batch_size/3)))\n",
    "    \n",
    "    # unpack minibatch\n",
    "    #state_xt = tuple(d[0] for d in minibatch)\n",
    "    state = torch.cat(tuple(d[0] for d in minibatch))\n",
    "    #prev_ch = tuple(d[1] for d in minibatch)\n",
    "    action = torch.cat(tuple(d[1] for d in minibatch))\n",
    "    reward = torch.cat(tuple(d[2] for d in minibatch))\n",
    "    #next_state_xt = tuple(d[4] for d in minibatch)\n",
    "    next_state = torch.cat(tuple(d[3] for d in minibatch))\n",
    "    #ch = tuple(d[5] for d in minibatch)\n",
    "    \n",
    "    # num samples of different categories\n",
    "    numRew = torch.stack([torch.sum(reward>=0.2),torch.sum(reward==-1),torch.sum(reward==0.01)]).data.cpu().numpy()\n",
    "    \n",
    "    # get output for the next state\n",
    "    next_output = target_net(next_state)\n",
    "\n",
    "    # set y_j to r_j for terminal state, otherwise to r_j + gamma*max(Q)\n",
    "    y = torch.cat(tuple(reward[i] if minibatch[i][4] \\\n",
    "                        else reward[i] + gamma * torch.max(next_output[i]) \\\n",
    "                        for i in range(len(minibatch))))\n",
    "\n",
    "    # extract Q-value\n",
    "    q_value = torch.sum(policy_net(state) * action, dim=1)\n",
    "\n",
    "    # PyTorch accumulates gradients by default, so they need to be reset in each pass\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # returns a new Tensor, detached from the current graph, the result will never require gradient\n",
    "    y = y.detach()\n",
    "\n",
    "    #print (y, q_value)\n",
    "    # calculate loss\n",
    "    loss = criterion(q_value, y)\n",
    "\n",
    "    # do backward pass\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # copy weights from policy_net to target_net\n",
    "    if update_criteria == 10:\n",
    "        target_net.load_state_dict(policy_net.state_dict())\n",
    "        update_criteria = 0\n",
    "    update_criteria += 1\n",
    "    \n",
    "    return loss.data,numRew,update_criteria"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AE Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_dim, emb_dim, hid_dim, n_layers, dropout):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.hid_dim = hid_dim\n",
    "        self.n_layers = n_layers\n",
    "        \n",
    "        self.embedding = nn.Embedding(input_dim, emb_dim)\n",
    "        \n",
    "        self.rnn = nn.LSTM(emb_dim, hid_dim, n_layers, dropout = dropout)\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, src):\n",
    "        \n",
    "        #src = [src len, batch size]\n",
    "        \n",
    "        embedded = src #self.dropout(self.embedding(src))\n",
    "        \n",
    "        #embedded = [src len, batch size, emb dim]\n",
    "        \n",
    "        outputs, (hidden, cell) = self.rnn(embedded)\n",
    "        \n",
    "        #outputs = [src len, batch size, hid dim * n directions]\n",
    "        #hidden = [n layers * n directions, batch size, hid dim]\n",
    "        #cell = [n layers * n directions, batch size, hid dim]\n",
    "        \n",
    "        #outputs are always from the top hidden layer\n",
    "        \n",
    "        return hidden, cell\n",
    "    \n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, output_dim, emb_dim, hid_dim, n_layers, dropout):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.output_dim = output_dim\n",
    "        self.hid_dim = hid_dim\n",
    "        self.n_layers = n_layers\n",
    "        \n",
    "        self.embedding = nn.Embedding(output_dim, emb_dim)\n",
    "        \n",
    "        self.rnn = nn.LSTM(emb_dim, hid_dim, n_layers, dropout = dropout)\n",
    "        self.fc_out = nn.Linear(hid_dim, output_dim)\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, input, hidden, cell):\n",
    "        \n",
    "        #input = [batch size, dim]\n",
    "        #hidden = [n layers * n directions, batch size, hid dim]\n",
    "        #cell = [n layers * n directions, batch size, hid dim]\n",
    "        \n",
    "        #n directions in the decoder will both always be 1, therefore:\n",
    "        #hidden = [n layers, batch size, hid dim]\n",
    "        #context = [n layers, batch size, hid dim]\n",
    "        \n",
    "        input = input.unsqueeze(0)\n",
    "        \n",
    "        #input = [1, batch size, dim]\n",
    "        \n",
    "        embedded = input #self.dropout(self.embedding(input))\n",
    "        #embedded[np.arange(embedded.size),a] = 1\n",
    "        \n",
    "        #embedded = [1, batch size, emb dim]\n",
    "        \n",
    "        output, (hidden, cell) = self.rnn(embedded, (hidden, cell))\n",
    "        \n",
    "        #output = [seq len, batch size, hid dim * n directions]\n",
    "        #hidden = [n layers * n directions, batch size, hid dim]\n",
    "        #cell = [n layers * n directions, batch size, hid dim]\n",
    "        \n",
    "        #seq len and n directions will always be 1 in the decoder, therefore:\n",
    "        #output = [1, batch size, hid dim]\n",
    "        #hidden = [n layers, batch size, hid dim]\n",
    "        #cell = [n layers, batch size, hid dim]\n",
    "        \n",
    "        prediction = self.fc_out(output.squeeze(0))\n",
    "        \n",
    "        #prediction = [batch size, output dim]\n",
    "        \n",
    "        return prediction, hidden, cell\n",
    "    \n",
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, encoder, decoder, device):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.device = device\n",
    "        \n",
    "        assert encoder.hid_dim == decoder.hid_dim, \\\n",
    "            \"Hidden dimensions of encoder and decoder must be equal!\"\n",
    "        assert encoder.n_layers == decoder.n_layers, \\\n",
    "            \"Encoder and decoder must have equal number of layers!\"\n",
    "        \n",
    "    def forward(self, src, trg, teacher_forcing_ratio = 0.1):\n",
    "        \n",
    "        #src = [src len, batch size, dim]\n",
    "        #trg = [trg len, batch size, dim]\n",
    "        #teacher_forcing_ratio is probability to use teacher forcing\n",
    "        #e.g. if teacher_forcing_ratio is 0.75 we use ground-truth inputs 75% of the time\n",
    "        \n",
    "        batch_size = trg.shape[1]\n",
    "        trg_len = trg.shape[0]\n",
    "        trg_vocab_size = self.decoder.output_dim\n",
    "        \n",
    "        #tensor to store decoder outputs\n",
    "        outputs = torch.zeros(trg_len, batch_size, trg_vocab_size).to(self.device)\n",
    "        \n",
    "        #last hidden state of the encoder is used as the initial hidden state of the decoder\n",
    "        hidden, cell = self.encoder(src)\n",
    "        \n",
    "        #first input to the decoder is the <sos> tokens\n",
    "        input = trg[0,:]\n",
    "        \n",
    "        for t in range(1, trg_len):\n",
    "            \n",
    "            #insert input token embedding, previous hidden and previous cell states\n",
    "            #receive output tensor (predictions) and new hidden and cell states\n",
    "            output, hidden, cell = self.decoder(input, hidden, cell)\n",
    "            \n",
    "            #place predictions in a tensor holding predictions for each token\n",
    "            outputs[t] = output\n",
    "            \n",
    "            #decide if we are going to use teacher forcing or not\n",
    "            teacher_force = random.random() < teacher_forcing_ratio\n",
    "            \n",
    "            #get the highest predicted token from our predictions\n",
    "            top1 = output #.argmax(1) \n",
    "            \n",
    "            #if teacher forcing, use actual next token as next input\n",
    "            #if not, use predicted token\n",
    "            input = trg[t] if teacher_force else top1\n",
    "        \n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "duke_cam = 41\n",
    "INPUT_DIM = duke_cam\n",
    "OUTPUT_DIM = duke_cam\n",
    "ENC_EMB_DIM = duke_cam\n",
    "DEC_EMB_DIM = duke_cam\n",
    "HID_DIM = 256\n",
    "N_LAYERS = 2\n",
    "ENC_DROPOUT = 0.5\n",
    "DEC_DROPOUT = 0.5\n",
    "\n",
    "enc = Encoder(INPUT_DIM, ENC_EMB_DIM, HID_DIM, N_LAYERS, ENC_DROPOUT).float().cuda()\n",
    "dec = Decoder(OUTPUT_DIM, DEC_EMB_DIM, HID_DIM, N_LAYERS, DEC_DROPOUT).float().cuda()\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = Seq2Seq(enc, dec, device).float().to(device)\n",
    "criterion_ae = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Seq2Seq(\n",
       "  (encoder): Encoder(\n",
       "    (embedding): Embedding(41, 41)\n",
       "    (rnn): LSTM(41, 256, num_layers=2, dropout=0.5)\n",
       "    (dropout): Dropout(p=0.5)\n",
       "  )\n",
       "  (decoder): Decoder(\n",
       "    (embedding): Embedding(41, 41)\n",
       "    (rnn): LSTM(41, 256, num_layers=2, dropout=0.5)\n",
       "    (fc_out): Linear(in_features=256, out_features=41, bias=True)\n",
       "    (dropout): Dropout(p=0.5)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load encoder model\n",
    "#enc.load_state_dict(torch.load('enc-model_manyDB_state64.pt'))\n",
    "#enc.load_state_dict(torch.load('enc-model_manyDB.pt'))\n",
    "#enc.eval()\n",
    "#dec.load_state_dict(torch.load('dec-model_manyDB_state64.pt'))\n",
    "#dec.eval()\n",
    "#model.load_state_dict(torch.load('../eccv2020/tut1-model_duke_lstmSize128_manyDB_2.pt'))\n",
    "model.load_state_dict(torch.load('../eccv2020/tut1-model_AICity_lstmSize256_manyDB.pt'))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run episodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "reward_sum = 0\n",
    "running_reward = None\n",
    "xs,rs,cprs = [],[],[]\n",
    "episode_number = 0\n",
    "episode_durations = []\n",
    "episode_reward = []\n",
    "validation_reward= []\n",
    "replay_memory_pos = []\n",
    "pos_prob = []\n",
    "replay_memory_neg = []\n",
    "replay_memory_cx = []\n",
    "M = np.zeros((num_camera,num_camera))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_state_vector(ped, curr_camera,curr_frame, ch,occ_len):\n",
    "    numSamples = 30\n",
    "    overlap_thres = [0.9, 1]\n",
    "        \n",
    "    # read image\n",
    "    img,bbox,p = afc.load_image(ped,curr_camera,curr_frame,db_no)\n",
    "    imw, imh = (1920,1080) #img.size\n",
    "    hc = np.array(10*np.log(occ_len))\n",
    "    \n",
    "    if p:\n",
    "        rt = np.zeros((8))\n",
    "        rt[0] = bbox[0]/imw -(np.random.rand()-0.5)/100\n",
    "        rt[1] = bbox[1]/imh -(np.random.rand()-0.5)/100\n",
    "        rt[2] = bbox[2]/imw -(np.random.rand()-0.5)/100\n",
    "        rt[3] = bbox[3]/imh -(np.random.rand()-0.5)/100\n",
    "        rt[4] = 0\n",
    "        rt[5] = 0\n",
    "        rt[6] = 0\n",
    "        rt[7] = 0\n",
    "        #print (np.where(rt.ravel()))\n",
    "        \n",
    "        # make next_state vector\n",
    "        #this_cam = afc.make_one_hot_camera(curr_camera)\n",
    "        #state = np.concatenate((this_cam, rt.ravel()))\n",
    "        #state = np.concatenate((state, hc.ravel()))\n",
    "        #state = np.concatenate((state, ch.ravel()))\n",
    "        #state = state.reshape(1,-1)\n",
    "        #state[state==0] = -10\n",
    "        #state[state==1] = 10\n",
    "        \n",
    "        # make next_state vector\n",
    "        this_cam = afc.make_one_hot_camera(curr_camera)\n",
    "        xt = np.concatenate((this_cam, rt.ravel()))\n",
    "        xt[xt==0] = -10\n",
    "        xt[xt==1] = 10\n",
    "        xt = xt.reshape(1,-1)\n",
    "        \n",
    "        # make history vector\n",
    "        c_t = this_cam.reshape(1,-1)\n",
    "        \n",
    "        if use_cuda:\n",
    "            xt = torch.from_numpy(xt).float().cuda()\n",
    "            c_t = torch.from_numpy(c_t).float().cuda()\n",
    "            hc = torch.from_numpy(hc.reshape(1,-1)).float().cuda()\n",
    "        else:\n",
    "            xt = torch.from_numpy(xt).float()\n",
    "            c_t = torch.from_numpy(c_t).float()\n",
    "            hc = torch.from_numpy(hc.reshape(1,-1)).float()\n",
    "    else:\n",
    "        print ('Target is not present in ',c,curr_frame)\n",
    "        xt,h_t = [],[]\n",
    "    \n",
    "    return xt,c_t,hc,rt #p,state,rt\n",
    "\n",
    "def append_reward(rs,num_steps):\n",
    "    if len(rs) > 0:\n",
    "        # stack episodic reward \n",
    "        epR = np.vstack(rs)\n",
    "        rs = []\n",
    "\n",
    "        # append the episodic reward\n",
    "        #episode_number += 1\n",
    "        #episode_durations.append(num_steps)\n",
    "        reward_stat = [num_steps,np.std(epR),np.sum(epR)]\n",
    "        episode_reward.append(reward_stat)\n",
    "    \n",
    "    return rs\n",
    "\n",
    "def reinit_ae(ch):\n",
    "    # Initialize history variable (one-hot encoding)\n",
    "    if use_cuda:\n",
    "        ch = torch.from_numpy(ch).float().cuda()\n",
    "        enc_h = torch.zeros(1,lstm_size).float().cuda()\n",
    "        enc_c = torch.zeros(1,lstm_size).float().cuda()\n",
    "    else:\n",
    "        enc_h = torch.zeros(1,lstm_size).float()\n",
    "        enc_c = torch.zeros(1,lstm_size).float()\n",
    "        \n",
    "    # encode whole camera history\n",
    "    for i in range(seq_len-1,-1,-1):\n",
    "        #print (ch[i,:])\n",
    "        x = ch[i,:].view(1,-1)\n",
    "        h_lstm,enc = ae_enc((enc_h,enc_c), x)\n",
    "        (enc_h,enc_c) = h_lstm\n",
    "\n",
    "    return h_lstm,enc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch = 0\n",
    "occ_max_val = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "EpData = []\n",
    "allEpData = []\n",
    "numRew=[]\n",
    "\n",
    "numUpdateRew=[]\n",
    "update_criteria = 0\n",
    "episode_count = 0\n",
    "steps_count = 0\n",
    "initialEpsilon = 0.4\n",
    "finalEpsilon = 0.01\n",
    "epsilon = initialEpsilon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "trExplored = {}\n",
    "for i in range(num_camera):\n",
    "    for j in range(num_camera):\n",
    "        trExplored[str(i)+'-'+str(j)] = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "resume = False\n",
    "if resume:\n",
    "    epoch = 600\n",
    "    epsilon = 0.170962\n",
    "    aaa = np.load('./EpData/.npy', allow_pickle=True)\n",
    "    episode_count = aaa[2]\n",
    "    steps_count = aaa[3]\n",
    "    episode_reward_pre = aaa[0]\n",
    "    validation_reward_pre = aaa[1]\n",
    "    policy_net.load_state_dict(torch.load('./models/')['state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tt.tic()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bb_intersection_over_union(boxA, boxB):\n",
    "    boxA = np.array(boxA)\n",
    "    boxB = np.array(boxB)\n",
    "    # convert to x1,y1,x2,y2\n",
    "    boxA[2] = boxA[2] + boxA[0]\n",
    "    boxA[3] = boxA[3] + boxA[1]\n",
    "    boxB[2] = boxB[2] + boxB[0]\n",
    "    boxB[3] = boxB[3] + boxB[1]\n",
    "    \n",
    "    # determine the (x, y)-coordinates of the intersection rectangle\n",
    "    xA = max(boxA[0], boxB[0])\n",
    "    yA = max(boxA[1], boxB[1])\n",
    "    xB = min(boxA[2], boxB[2])\n",
    "    yB = min(boxA[3], boxB[3])\n",
    "    # compute the area of intersection rectangle\n",
    "    interArea = max(0, xB - xA + 1) * max(0, yB - yA + 1)\n",
    "    # compute the area of both the prediction and ground-truth\n",
    "    # rectangles\n",
    "    boxAArea = (boxA[2] - boxA[0] + 1) * (boxA[3] - boxA[1] + 1)\n",
    "    boxBArea = (boxB[2] - boxB[0] + 1) * (boxB[3] - boxB[1] + 1)\n",
    "    # compute the intersec1tion over union by taking the intersection\n",
    "    # area and dividing it by the sum of prediction + ground-truth\n",
    "    # areas - the interesection area\n",
    "    iou = interArea / float(boxAArea + boxBArea - interArea)\n",
    "    # return the intersection over union value\n",
    "    return iou\n",
    "\n",
    "cam_sync_offset = [5543,3607,27244,31182,1,22402,18968,46766]\n",
    "def find_nearest_box(c,frame_no, prev_box):\n",
    "    # find all bounding boxes\n",
    "    #print (c, frame_no)\n",
    "    all_dets = np.copy(camGT[np.logical_and(camGT[:,0]==c, camGT[:,1]==(frame_no+46766-cam_sync_offset[c])), 2:])\n",
    "    \n",
    "    #print (all_dets, prev_box)\n",
    "    \n",
    "    # find the nearest box\n",
    "    maxIOU = -1\n",
    "    box = np.array([])\n",
    "    for i in range(len(all_dets)):\n",
    "        this_box = np.copy(all_dets[i])\n",
    "        iou = bb_intersection_over_union(this_box, prev_box)\n",
    "        #print (iou, this_box)\n",
    "        if iou > maxIOU and iou > 0.4:\n",
    "            maxIOU = iou\n",
    "            box = np.copy(all_dets[i])\n",
    "            \n",
    "    return box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def discount_rewards(r):\n",
    "#     \"\"\" take 1D float array of rewards and compute discounted reward \"\"\"\n",
    "#     discounted_r = np.zeros_like(r)\n",
    "#     running_add = 0\n",
    "#     for t in reversed(range(0, r.size)):\n",
    "#         if r[t] != 0: running_add = 0 # reset the sum, since this was a game boundary (pong specific!)\n",
    "#         running_add = running_add * gamma + r[t]\n",
    "#         discounted_r[t] = running_add\n",
    "#     return discounted_r\n",
    "\n",
    "# def discount_rewards(r):\n",
    "#     \"\"\" take 1D float array of rewards and compute discounted reward \"\"\"\n",
    "#     discounted_r = [] #np.zeros_like(r)\n",
    "#     running_add = 0\n",
    "#     for t in reversed(range(0, len(r))):\n",
    "#         if r[t] != 0: running_add = 0 # reset the sum, since this was a game boundary (pong specific!)\n",
    "#         running_add = running_add * gamma + r[t]\n",
    "#         #discounted_r[t] = running_add\n",
    "#         discounted_r.append(running_add)\n",
    "#     return discounted_r\n",
    "\n",
    "def discount_rewards(r,c):\n",
    "    \"\"\" take 1D float array of rewards and compute discounted reward \"\"\"\n",
    "    discounted_r = [] #np.zeros_like(r)\n",
    "    running_add = 0\n",
    "    pivot = c[-1]\n",
    "    for t in reversed(range(0, len(r))):\n",
    "        if r[t] != 0: \n",
    "            running_add = 0 # reset the sum, since this was a game boundary (pong specific!)\n",
    "            pivot = c[t]\n",
    "        if c[t] == pivot:\n",
    "            running_add = running_add * gamma + r[t]\n",
    "            #discounted_r[t] = running_add\n",
    "            discounted_r.append(running_add)\n",
    "        else:\n",
    "            running_add = running_add * gamma + 0\n",
    "            discounted_r.append(0)\n",
    "            \n",
    "        \n",
    "    return discounted_r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 0: ep_len:500 episode reward: total was -99.500000. running mean: -100.835226\n",
      "ep 0: ep_len:820 episode reward: total was -152.910000. running mean: -101.355974\n",
      "ep 0: ep_len:655 episode reward: total was -120.470000. running mean: -101.547114\n",
      "ep 0: ep_len:510 episode reward: total was -61.490000. running mean: -101.146543\n",
      "ep 0: ep_len:500 episode reward: total was -80.950000. running mean: -100.944577\n",
      "ep 0: ep_len:560 episode reward: total was -102.950000. running mean: -100.964632\n",
      "ep 0: ep_len:875 episode reward: total was -162.920000. running mean: -101.584185\n",
      "ep 0: ep_len:520 episode reward: total was -69.990000. running mean: -101.268243\n",
      "ep 0: ep_len:890 episode reward: total was -169.940000. running mean: -101.954961\n",
      "ep 0: ep_len:1235 episode reward: total was -208.800000. running mean: -103.023411\n",
      "ep 0: ep_len:530 episode reward: total was -50.520000. running mean: -102.498377\n",
      "ep 0: ep_len:550 episode reward: total was -72.180000. running mean: -102.195193\n",
      "ep 0: ep_len:685 episode reward: total was -81.490000. running mean: -101.988142\n",
      "ep 0: ep_len:246 episode reward: total was -41.000000. running mean: -101.378260\n",
      "ep 0: ep_len:1070 episode reward: total was -200.930000. running mean: -102.373777\n",
      "ep 0: ep_len:910 episode reward: total was -173.940000. running mean: -103.089440\n",
      "ep 0: ep_len:751 episode reward: total was -118.340000. running mean: -103.241945\n",
      "ep 0: ep_len:688 episode reward: total was -133.970000. running mean: -103.549226\n",
      "ep 0: ep_len:505 episode reward: total was -88.440000. running mean: -103.398134\n",
      "ep 0: ep_len:580 episode reward: total was -95.330000. running mean: -103.317452\n",
      "ep 0: ep_len:865 episode reward: total was -123.670000. running mean: -103.520978\n",
      "ep 0: ep_len:1505 episode reward: total was -285.870000. running mean: -105.344468\n",
      "ep 0: ep_len:1065 episode reward: total was -200.900000. running mean: -106.300023\n",
      "ep 0: ep_len:500 episode reward: total was -61.480000. running mean: -105.851823\n",
      "ep 0: ep_len:965 episode reward: total was -186.470000. running mean: -106.658005\n",
      "ep 0: ep_len:198 episode reward: total was -19.000000. running mean: -105.781425\n",
      "ep 0: ep_len:715 episode reward: total was -101.440000. running mean: -105.738011\n",
      "ep 0: ep_len:670 episode reward: total was -127.960000. running mean: -105.960230\n",
      "ep 0: ep_len:605 episode reward: total was -52.450000. running mean: -105.425128\n",
      "ep 0: ep_len:760 episode reward: total was -143.940000. running mean: -105.810277\n",
      "ep 0: ep_len:505 episode reward: total was -62.500000. running mean: -105.377174\n",
      "ep 0: ep_len:810 episode reward: total was -125.470000. running mean: -105.578102\n",
      "ep 0: ep_len:209 episode reward: total was -16.500000. running mean: -104.687321\n",
      "ep 0: ep_len:650 episode reward: total was -120.440000. running mean: -104.844848\n",
      "ep 0: ep_len:797 episode reward: total was -151.960000. running mean: -105.316000\n",
      "ep 0: ep_len:630 episode reward: total was -97.960000. running mean: -105.242440\n",
      "ep 0: ep_len:500 episode reward: total was -53.980000. running mean: -104.729815\n",
      "ep 0: ep_len:880 episode reward: total was -158.400000. running mean: -105.266517\n",
      "ep 0: ep_len:550 episode reward: total was -49.420000. running mean: -104.708052\n",
      "ep 0: ep_len:467 episode reward: total was -35.500000. running mean: -104.015971\n",
      "ep 0: ep_len:1767 episode reward: total was -271.940000. running mean: -105.695212\n",
      "ep 0: ep_len:730 episode reward: total was -64.170000. running mean: -105.279960\n",
      "ep 0: ep_len:276 episode reward: total was -51.000000. running mean: -104.737160\n",
      "ep 0: ep_len:565 episode reward: total was -52.940000. running mean: -104.219188\n",
      "ep 0: ep_len:500 episode reward: total was -48.920000. running mean: -103.666196\n",
      "ep 0: ep_len:1135 episode reward: total was -216.430000. running mean: -104.793835\n",
      "ep 0: ep_len:965 episode reward: total was -117.490000. running mean: -104.920796\n",
      "ep 0: ep_len:500 episode reward: total was -49.970000. running mean: -104.371288\n",
      "ep 0: ep_len:815 episode reward: total was -75.180000. running mean: -104.079375\n",
      "ep 0: ep_len:1355 episode reward: total was -99.840000. running mean: -104.036982\n",
      "ep 0: ep_len:775 episode reward: total was -63.620000. running mean: -103.632812\n",
      "ep 0: ep_len:185 episode reward: total was -2.500000. running mean: -102.621484\n",
      "ep 0: ep_len:705 episode reward: total was -134.470000. running mean: -102.939969\n",
      "ep 0: ep_len:830 episode reward: total was -85.990000. running mean: -102.770469\n",
      "ep 0: ep_len:690 episode reward: total was -123.910000. running mean: -102.981864\n",
      "ep 0: ep_len:655 episode reward: total was -124.960000. running mean: -103.201646\n",
      "ep 0: ep_len:113 episode reward: total was 2.000000. running mean: -102.149629\n",
      "ep 0: ep_len:877 episode reward: total was -128.950000. running mean: -102.417633\n",
      "ep 0: ep_len:956 episode reward: total was -152.620000. running mean: -102.919657\n",
      "ep 0: ep_len:500 episode reward: total was -49.880000. running mean: -102.389260\n",
      "ep 0: ep_len:343 episode reward: total was -4.000000. running mean: -101.405368\n",
      "ep 0: ep_len:18135 episode reward: total was -1264.600000. running mean: -113.037314\n",
      "ep 0: ep_len:610 episode reward: total was -50.310000. running mean: -112.410041\n",
      "ep 0: ep_len:560 episode reward: total was -34.280000. running mean: -111.628740\n",
      "ep 0: ep_len:150 episode reward: total was -9.000000. running mean: -110.602453\n",
      "ep 0: ep_len:1090 episode reward: total was -164.450000. running mean: -111.140928\n",
      "ep 0: ep_len:471 episode reward: total was -31.000000. running mean: -110.339519\n",
      "ep 0: ep_len:1295 episode reward: total was -86.730000. running mean: -110.103424\n",
      "ep 0: ep_len:710 episode reward: total was -64.280000. running mean: -109.645190\n",
      "ep 0: ep_len:1060 episode reward: total was -183.420000. running mean: -110.382938\n",
      "ep 0: ep_len:886 episode reward: total was -112.390000. running mean: -110.403008\n",
      "ep 0: ep_len:895 episode reward: total was -60.140000. running mean: -109.900378\n",
      "ep 0: ep_len:190 episode reward: total was 0.000000. running mean: -108.801375\n",
      "ep 0: ep_len:1080 episode reward: total was -171.360000. running mean: -109.426961\n",
      "ep 0: ep_len:935 episode reward: total was -95.290000. running mean: -109.285591\n",
      "ep 0: ep_len:585 episode reward: total was -92.320000. running mean: -109.115935\n",
      "ep 0: ep_len:545 episode reward: total was -97.420000. running mean: -108.998976\n",
      "ep 0: ep_len:500 episode reward: total was -26.490000. running mean: -108.173886\n",
      "ep 0: ep_len:545 episode reward: total was -93.400000. running mean: -108.026147\n",
      "ep 0: ep_len:510 episode reward: total was -27.050000. running mean: -107.216386\n",
      "ep 0: ep_len:505 episode reward: total was -30.960000. running mean: -106.453822\n",
      "ep 0: ep_len:1065 episode reward: total was -66.570000. running mean: -106.054984\n",
      "ep 0: ep_len:474 episode reward: total was -8.000000. running mean: -105.074434\n",
      "ep 0: ep_len:810 episode reward: total was -139.910000. running mean: -105.422790\n",
      "ep 0: ep_len:560 episode reward: total was -50.440000. running mean: -104.872962\n",
      "ep 0: ep_len:1115 episode reward: total was -144.000000. running mean: -105.264232\n",
      "ep 0: ep_len:645 episode reward: total was -58.840000. running mean: -104.799990\n",
      "ep 0: ep_len:645 episode reward: total was -46.230000. running mean: -104.214290\n",
      "ep 0: ep_len:510 episode reward: total was -49.480000. running mean: -103.666947\n",
      "ep 0: ep_len:795 episode reward: total was -150.960000. running mean: -104.139877\n",
      "ep 0: ep_len:560 episode reward: total was -52.300000. running mean: -103.621479\n",
      "ep 0: ep_len:665 episode reward: total was -126.980000. running mean: -103.855064\n",
      "ep 0: ep_len:855 episode reward: total was -77.120000. running mean: -103.587713\n",
      "ep 0: ep_len:530 episode reward: total was -98.460000. running mean: -103.536436\n",
      "ep 0: ep_len:510 episode reward: total was -44.490000. running mean: -102.945972\n",
      "ep 0: ep_len:785 episode reward: total was -72.700000. running mean: -102.643512\n",
      "ep 0: ep_len:1060 episode reward: total was -148.460000. running mean: -103.101677\n",
      "ep 0: ep_len:515 episode reward: total was -51.160000. running mean: -102.582260\n",
      "ep 0: ep_len:500 episode reward: total was -85.970000. running mean: -102.416138\n",
      "ep 0: ep_len:705 episode reward: total was -60.250000. running mean: -101.994476\n",
      "ep 0: ep_len:510 episode reward: total was -40.490000. running mean: -101.379431\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 0: ep_len:965 episode reward: total was -165.940000. running mean: -102.025037\n",
      "ep 0: ep_len:500 episode reward: total was -34.460000. running mean: -101.349387\n",
      "ep 0: ep_len:835 episode reward: total was -106.460000. running mean: -101.400493\n",
      "ep 0: ep_len:740 episode reward: total was -135.930000. running mean: -101.745788\n",
      "ep 0: ep_len:610 episode reward: total was -98.820000. running mean: -101.716530\n",
      "ep 0: ep_len:650 episode reward: total was -117.930000. running mean: -101.878665\n",
      "ep 0: ep_len:194 episode reward: total was -1.500000. running mean: -100.874878\n",
      "ep 0: ep_len:605 episode reward: total was -114.990000. running mean: -101.016029\n",
      "ep 0: ep_len:1055 episode reward: total was -140.430000. running mean: -101.410169\n",
      "ep 0: ep_len:665 episode reward: total was -66.350000. running mean: -101.059567\n",
      "ep 0: ep_len:645 episode reward: total was -92.900000. running mean: -100.977972\n",
      "ep 0: ep_len:500 episode reward: total was -80.400000. running mean: -100.772192\n",
      "ep 0: ep_len:1100 episode reward: total was -117.520000. running mean: -100.939670\n",
      "ep 0: ep_len:855 episode reward: total was -60.680000. running mean: -100.537073\n",
      "ep 0: ep_len:545 episode reward: total was -88.330000. running mean: -100.415003\n",
      "ep 0: ep_len:960 episode reward: total was -104.730000. running mean: -100.458153\n",
      "ep 0: ep_len:1030 episode reward: total was -152.020000. running mean: -100.973771\n",
      "ep 0: ep_len:560 episode reward: total was -62.560000. running mean: -100.589633\n",
      "ep 0: ep_len:500 episode reward: total was -65.910000. running mean: -100.242837\n",
      "ep 0: ep_len:590 episode reward: total was -87.460000. running mean: -100.115009\n",
      "ep 0: ep_len:875 episode reward: total was -89.170000. running mean: -100.005559\n",
      "ep 0: ep_len:505 episode reward: total was -6.500000. running mean: -99.070503\n",
      "ep 0: ep_len:755 episode reward: total was -63.670000. running mean: -98.716498\n",
      "ep 0: ep_len:995 episode reward: total was -146.430000. running mean: -99.193633\n",
      "ep 0: ep_len:121 episode reward: total was -1.500000. running mean: -98.216697\n",
      "ep 0: ep_len:910 episode reward: total was -80.810000. running mean: -98.042630\n",
      "ep 0: ep_len:1025 episode reward: total was -128.780000. running mean: -98.350003\n",
      "ep 0: ep_len:745 episode reward: total was -138.920000. running mean: -98.755703\n",
      "ep 0: ep_len:1055 episode reward: total was -138.960000. running mean: -99.157746\n",
      "ep 0: ep_len:1010 episode reward: total was -140.950000. running mean: -99.575669\n",
      "ep 0: ep_len:1400 episode reward: total was -93.200000. running mean: -99.511912\n",
      "ep 0: ep_len:1330 episode reward: total was -99.890000. running mean: -99.515693\n",
      "ep 0: ep_len:740 episode reward: total was -67.650000. running mean: -99.197036\n",
      "ep 0: ep_len:655 episode reward: total was -126.490000. running mean: -99.469966\n",
      "ep 0: ep_len:530 episode reward: total was -33.490000. running mean: -98.810166\n",
      "ep 0: ep_len:650 episode reward: total was -75.500000. running mean: -98.577064\n",
      "ep 0: ep_len:510 episode reward: total was -38.460000. running mean: -97.975894\n",
      "ep 0: ep_len:920 episode reward: total was -104.270000. running mean: -98.038835\n",
      "ep 0: ep_len:1565 episode reward: total was -297.900000. running mean: -100.037446\n",
      "ep 0: ep_len:505 episode reward: total was -48.480000. running mean: -99.521872\n",
      "ep 0: ep_len:500 episode reward: total was -24.860000. running mean: -98.775253\n",
      "ep 0: ep_len:500 episode reward: total was -9.000000. running mean: -97.877501\n",
      "ep 0: ep_len:285 episode reward: total was 0.010000. running mean: -96.898626\n",
      "ep 0: ep_len:715 episode reward: total was -91.910000. running mean: -96.848739\n",
      "ep 0: ep_len:850 episode reward: total was -81.960000. running mean: -96.699852\n",
      "ep 0: ep_len:915 episode reward: total was -110.230000. running mean: -96.835154\n",
      "ep 0: ep_len:213 episode reward: total was 1.500000. running mean: -95.851802\n",
      "ep 0: ep_len:505 episode reward: total was -19.850000. running mean: -95.091784\n",
      "ep 0: ep_len:765 episode reward: total was -104.250000. running mean: -95.183366\n",
      "ep 0: ep_len:515 episode reward: total was -2.500000. running mean: -94.256533\n",
      "ep 0: ep_len:850 episode reward: total was -101.370000. running mean: -94.327667\n",
      "ep 0: ep_len:147 episode reward: total was -0.500000. running mean: -93.389391\n",
      "ep 0: ep_len:500 episode reward: total was -64.970000. running mean: -93.105197\n",
      "ep 0: ep_len:645 episode reward: total was -46.980000. running mean: -92.643945\n",
      "ep 0: ep_len:875 episode reward: total was -79.100000. running mean: -92.508505\n",
      "ep 0: ep_len:740 episode reward: total was -60.670000. running mean: -92.190120\n",
      "ep 0: ep_len:935 episode reward: total was -73.940000. running mean: -92.007619\n",
      "ep 0: ep_len:320 episode reward: total was -23.980000. running mean: -91.327343\n",
      "ep 0: ep_len:1115 episode reward: total was -202.330000. running mean: -92.437369\n",
      "ep 0: ep_len:530 episode reward: total was -48.460000. running mean: -91.997596\n",
      "ep 0: ep_len:615 episode reward: total was -73.410000. running mean: -91.811720\n",
      "ep 0: ep_len:740 episode reward: total was -67.660000. running mean: -91.570202\n",
      "ep 0: ep_len:170 episode reward: total was 1.000000. running mean: -90.644500\n",
      "ep 0: ep_len:332 episode reward: total was 9.500000. running mean: -89.643055\n",
      "ep 0: ep_len:565 episode reward: total was -99.920000. running mean: -89.745825\n",
      "ep 0: ep_len:510 episode reward: total was -27.890000. running mean: -89.127267\n",
      "ep 0: ep_len:1115 episode reward: total was -141.330000. running mean: -89.649294\n",
      "ep 0: ep_len:710 episode reward: total was -50.110000. running mean: -89.253901\n",
      "ep 0: ep_len:500 episode reward: total was -44.190000. running mean: -88.803262\n",
      "ep 0: ep_len:1060 episode reward: total was -94.830000. running mean: -88.863529\n",
      "ep 0: ep_len:545 episode reward: total was -42.630000. running mean: -88.401194\n",
      "ep 0: ep_len:640 episode reward: total was -50.280000. running mean: -88.019982\n",
      "ep 0: ep_len:730 episode reward: total was -61.180000. running mean: -87.751582\n",
      "ep 0: ep_len:149 episode reward: total was 8.500000. running mean: -86.789067\n",
      "ep 0: ep_len:940 episode reward: total was -108.750000. running mean: -87.008676\n",
      "ep 0: ep_len:1095 episode reward: total was -108.420000. running mean: -87.222789\n",
      "ep 0: ep_len:204 episode reward: total was -7.000000. running mean: -86.420561\n",
      "ep 0: ep_len:695 episode reward: total was -66.230000. running mean: -86.218656\n",
      "ep 0: ep_len:885 episode reward: total was -70.550000. running mean: -86.061969\n",
      "ep 0: ep_len:500 episode reward: total was -33.500000. running mean: -85.536349\n",
      "ep 0: ep_len:505 episode reward: total was -32.710000. running mean: -85.008086\n",
      "ep 0: ep_len:500 episode reward: total was -58.980000. running mean: -84.747805\n",
      "ep 0: ep_len:545 episode reward: total was -64.610000. running mean: -84.546427\n",
      "ep 0: ep_len:500 episode reward: total was -42.490000. running mean: -84.125863\n",
      "ep 0: ep_len:500 episode reward: total was -60.240000. running mean: -83.887004\n",
      "ep 0: ep_len:535 episode reward: total was -69.680000. running mean: -83.744934\n",
      "ep 0: ep_len:500 episode reward: total was -30.420000. running mean: -83.211685\n",
      "ep 0: ep_len:505 episode reward: total was -30.000000. running mean: -82.679568\n",
      "ep 0: ep_len:500 episode reward: total was -44.070000. running mean: -82.293472\n",
      "ep 0: ep_len:660 episode reward: total was -60.960000. running mean: -82.080137\n",
      "ep 0: ep_len:870 episode reward: total was -73.540000. running mean: -81.994736\n",
      "ep 0: ep_len:238 episode reward: total was 0.000000. running mean: -81.174789\n",
      "ep 0: ep_len:795 episode reward: total was -63.590000. running mean: -80.998941\n",
      "ep 0: ep_len:211 episode reward: total was -6.500000. running mean: -80.253951\n",
      "ep 0: ep_len:990 episode reward: total was -184.400000. running mean: -81.295412\n",
      "ep 0: ep_len:505 episode reward: total was -29.360000. running mean: -80.776058\n",
      "ep 0: ep_len:359 episode reward: total was -48.000000. running mean: -80.448297\n",
      "ep 0: ep_len:505 episode reward: total was -40.490000. running mean: -80.048714\n",
      "ep 0: ep_len:630 episode reward: total was -46.230000. running mean: -79.710527\n",
      "ep 0: ep_len:720 episode reward: total was -66.250000. running mean: -79.575922\n",
      "ep 0: ep_len:1070 episode reward: total was -98.110000. running mean: -79.761263\n",
      "ep 0: ep_len:830 episode reward: total was -84.270000. running mean: -79.806350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 0: ep_len:535 episode reward: total was -64.980000. running mean: -79.658086\n",
      "ep 0: ep_len:560 episode reward: total was -104.950000. running mean: -79.911006\n",
      "ep 0: ep_len:605 episode reward: total was -106.470000. running mean: -80.176596\n",
      "ep 0: ep_len:650 episode reward: total was -118.940000. running mean: -80.564230\n",
      "ep 0: ep_len:500 episode reward: total was -51.470000. running mean: -80.273287\n",
      "ep 0: ep_len:1020 episode reward: total was -127.410000. running mean: -80.744654\n",
      "ep 0: ep_len:500 episode reward: total was -31.970000. running mean: -80.256908\n",
      "ep 0: ep_len:505 episode reward: total was -27.210000. running mean: -79.726439\n",
      "ep 0: ep_len:875 episode reward: total was -77.930000. running mean: -79.708474\n",
      "ep 0: ep_len:565 episode reward: total was -90.370000. running mean: -79.815090\n",
      "ep 0: ep_len:500 episode reward: total was -47.960000. running mean: -79.496539\n",
      "ep 0: ep_len:375 episode reward: total was -6.500000. running mean: -78.766573\n",
      "ep 0: ep_len:505 episode reward: total was -65.240000. running mean: -78.631308\n",
      "ep 0: ep_len:500 episode reward: total was -15.140000. running mean: -77.996395\n",
      "ep 0: ep_len:500 episode reward: total was -55.870000. running mean: -77.775131\n",
      "ep 0: ep_len:650 episode reward: total was -60.850000. running mean: -77.605879\n",
      "ep 0: ep_len:650 episode reward: total was -100.290000. running mean: -77.832721\n",
      "ep 0: ep_len:705 episode reward: total was -73.870000. running mean: -77.793093\n",
      "ep 0: ep_len:1040 episode reward: total was -118.190000. running mean: -78.197062\n",
      "ep 0: ep_len:800 episode reward: total was -79.250000. running mean: -78.207592\n",
      "ep 0: ep_len:505 episode reward: total was -53.200000. running mean: -77.957516\n",
      "ep 0: ep_len:940 episode reward: total was -63.950000. running mean: -77.817441\n",
      "ep 0: ep_len:785 episode reward: total was -113.620000. running mean: -78.175466\n",
      "ep 0: ep_len:525 episode reward: total was -36.380000. running mean: -77.757512\n",
      "ep 0: ep_len:850 episode reward: total was -106.450000. running mean: -78.044437\n",
      "ep 0: ep_len:510 episode reward: total was -50.600000. running mean: -77.769992\n",
      "ep 0: ep_len:640 episode reward: total was -64.130000. running mean: -77.633592\n",
      "ep 0: ep_len:660 episode reward: total was -37.500000. running mean: -77.232256\n",
      "ep 0: ep_len:735 episode reward: total was -83.420000. running mean: -77.294134\n",
      "ep 0: ep_len:825 episode reward: total was -105.950000. running mean: -77.580692\n",
      "ep 0: ep_len:870 episode reward: total was -73.540000. running mean: -77.540285\n",
      "ep 0: ep_len:640 episode reward: total was -62.390000. running mean: -77.388783\n",
      "ep 0: ep_len:820 episode reward: total was -157.960000. running mean: -78.194495\n",
      "ep 0: ep_len:755 episode reward: total was -110.130000. running mean: -78.513850\n",
      "ep 0: ep_len:510 episode reward: total was -56.840000. running mean: -78.297111\n",
      "ep 0: ep_len:1315 episode reward: total was -107.480000. running mean: -78.588940\n",
      "ep 0: ep_len:745 episode reward: total was -46.810000. running mean: -78.271151\n",
      "ep 0: ep_len:755 episode reward: total was -91.460000. running mean: -78.403039\n",
      "ep 0: ep_len:760 episode reward: total was -64.670000. running mean: -78.265709\n",
      "ep 0: ep_len:500 episode reward: total was -52.480000. running mean: -78.007852\n",
      "ep 0: ep_len:500 episode reward: total was -40.950000. running mean: -77.637273\n",
      "ep 0: ep_len:1300 episode reward: total was -218.180000. running mean: -79.042701\n",
      "ep 0: ep_len:500 episode reward: total was -53.430000. running mean: -78.786574\n",
      "ep 0: ep_len:161 episode reward: total was 1.500000. running mean: -77.983708\n",
      "ep 0: ep_len:850 episode reward: total was -78.630000. running mean: -77.990171\n",
      "ep 0: ep_len:500 episode reward: total was -58.860000. running mean: -77.798869\n",
      "ep 0: ep_len:500 episode reward: total was -33.960000. running mean: -77.360480\n",
      "ep 0: ep_len:510 episode reward: total was -56.460000. running mean: -77.151476\n",
      "ep 0: ep_len:740 episode reward: total was -70.450000. running mean: -77.084461\n",
      "ep 0: ep_len:49 episode reward: total was -3.000000. running mean: -76.343616\n",
      "ep 0: ep_len:625 episode reward: total was -77.580000. running mean: -76.355980\n",
      "ep 0: ep_len:520 episode reward: total was -42.330000. running mean: -76.015720\n",
      "ep 0: ep_len:540 episode reward: total was -52.980000. running mean: -75.785363\n",
      "ep 0: ep_len:810 episode reward: total was -86.300000. running mean: -75.890509\n",
      "ep 0: ep_len:610 episode reward: total was -55.450000. running mean: -75.686104\n",
      "ep 0: ep_len:208 episode reward: total was 5.500000. running mean: -74.874243\n",
      "ep 0: ep_len:695 episode reward: total was -77.130000. running mean: -74.896801\n",
      "ep 0: ep_len:665 episode reward: total was -75.920000. running mean: -74.907033\n",
      "ep 0: ep_len:1055 episode reward: total was -152.960000. running mean: -75.687562\n",
      "ep 0: ep_len:540 episode reward: total was -29.760000. running mean: -75.228287\n",
      "ep 0: ep_len:500 episode reward: total was -77.950000. running mean: -75.255504\n",
      "ep 0: ep_len:1120 episode reward: total was -111.520000. running mean: -75.618149\n",
      "ep 0: ep_len:505 episode reward: total was -82.410000. running mean: -75.686067\n",
      "ep 0: ep_len:231 episode reward: total was 3.500000. running mean: -74.894207\n",
      "ep 0: ep_len:1090 episode reward: total was -103.280000. running mean: -75.178065\n",
      "ep 0: ep_len:795 episode reward: total was -93.130000. running mean: -75.357584\n",
      "ep 0: ep_len:500 episode reward: total was -75.470000. running mean: -75.358708\n",
      "ep 0: ep_len:500 episode reward: total was -20.770000. running mean: -74.812821\n",
      "ep 0: ep_len:635 episode reward: total was -98.770000. running mean: -75.052393\n",
      "ep 0: ep_len:550 episode reward: total was -58.740000. running mean: -74.889269\n",
      "ep 0: ep_len:237 episode reward: total was 4.000000. running mean: -74.100376\n",
      "ep 0: ep_len:258 episode reward: total was -0.500000. running mean: -73.364373\n",
      "ep 0: ep_len:505 episode reward: total was -67.870000. running mean: -73.309429\n",
      "ep 0: ep_len:500 episode reward: total was -23.750000. running mean: -72.813835\n",
      "ep 0: ep_len:525 episode reward: total was -43.880000. running mean: -72.524496\n",
      "ep 0: ep_len:525 episode reward: total was -89.380000. running mean: -72.693051\n",
      "ep 0: ep_len:615 episode reward: total was -84.410000. running mean: -72.810221\n",
      "ep 0: ep_len:1190 episode reward: total was -215.310000. running mean: -74.235219\n",
      "ep 0: ep_len:550 episode reward: total was -42.340000. running mean: -73.916266\n",
      "ep 0: ep_len:500 episode reward: total was -49.360000. running mean: -73.670704\n",
      "ep 0: ep_len:580 episode reward: total was -55.450000. running mean: -73.488497\n",
      "ep 0: ep_len:349 episode reward: total was -4.000000. running mean: -72.793612\n",
      "ep 0: ep_len:204 episode reward: total was -16.500000. running mean: -72.230676\n",
      "ep 0: ep_len:635 episode reward: total was -73.000000. running mean: -72.238369\n",
      "ep 0: ep_len:1060 episode reward: total was -168.100000. running mean: -73.196985\n",
      "ep 0: ep_len:500 episode reward: total was -17.280000. running mean: -72.637815\n",
      "ep 0: ep_len:462 episode reward: total was -36.250000. running mean: -72.273937\n",
      "ep 0: ep_len:1065 episode reward: total was -74.920000. running mean: -72.300398\n",
      "ep 0: ep_len:1107 episode reward: total was -133.650000. running mean: -72.913894\n",
      "ep 0: ep_len:1860 episode reward: total was -247.510000. running mean: -74.659855\n",
      "ep 0: ep_len:895 episode reward: total was -68.300000. running mean: -74.596256\n",
      "ep 0: ep_len:815 episode reward: total was -81.210000. running mean: -74.662394\n",
      "ep 0: ep_len:545 episode reward: total was -45.170000. running mean: -74.367470\n",
      "ep 0: ep_len:865 episode reward: total was -138.310000. running mean: -75.006895\n",
      "ep 0: ep_len:760 episode reward: total was -67.210000. running mean: -74.928926\n",
      "ep 0: ep_len:1110 episode reward: total was -144.280000. running mean: -75.622437\n",
      "ep 0: ep_len:505 episode reward: total was -29.780000. running mean: -75.164012\n",
      "ep 0: ep_len:515 episode reward: total was -43.460000. running mean: -74.846972\n",
      "ep 0: ep_len:870 episode reward: total was -91.590000. running mean: -75.014403\n",
      "ep 0: ep_len:246 episode reward: total was -4.000000. running mean: -74.304259\n",
      "ep 0: ep_len:500 episode reward: total was -40.800000. running mean: -73.969216\n",
      "ep 0: ep_len:755 episode reward: total was -115.180000. running mean: -74.381324\n",
      "ep 0: ep_len:505 episode reward: total was -26.890000. running mean: -73.906411\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 0: ep_len:520 episode reward: total was -37.230000. running mean: -73.539647\n",
      "ep 0: ep_len:520 episode reward: total was -42.440000. running mean: -73.228650\n",
      "ep 0: ep_len:125 episode reward: total was -7.500000. running mean: -72.571364\n",
      "ep 0: ep_len:133 episode reward: total was 1.500000. running mean: -71.830650\n",
      "ep 0: ep_len:296 episode reward: total was -8.500000. running mean: -71.197343\n",
      "ep 0: ep_len:205 episode reward: total was -1.500000. running mean: -70.500370\n",
      "ep 0: ep_len:320 episode reward: total was -8.000000. running mean: -69.875366\n",
      "ep 0: ep_len:860 episode reward: total was -102.990000. running mean: -70.206513\n",
      "ep 0: ep_len:500 episode reward: total was -41.710000. running mean: -69.921548\n",
      "ep 0: ep_len:258 episode reward: total was -6.000000. running mean: -69.282332\n",
      "ep 0: ep_len:500 episode reward: total was -30.770000. running mean: -68.897209\n",
      "ep 0: ep_len:1070 episode reward: total was -101.940000. running mean: -69.227637\n",
      "ep 0: ep_len:500 episode reward: total was -32.310000. running mean: -68.858460\n",
      "ep 0: ep_len:840 episode reward: total was -84.400000. running mean: -69.013876\n",
      "ep 0: ep_len:505 episode reward: total was -35.350000. running mean: -68.677237\n",
      "ep 0: ep_len:745 episode reward: total was -71.900000. running mean: -68.709465\n",
      "ep 0: ep_len:765 episode reward: total was -53.550000. running mean: -68.557870\n",
      "ep 0: ep_len:510 episode reward: total was -24.790000. running mean: -68.120191\n",
      "ep 0: ep_len:640 episode reward: total was -29.420000. running mean: -67.733189\n",
      "ep 0: ep_len:965 episode reward: total was -93.980000. running mean: -67.995657\n",
      "ep 0: ep_len:1080 episode reward: total was -65.120000. running mean: -67.966901\n",
      "ep 0: ep_len:505 episode reward: total was -27.800000. running mean: -67.565232\n",
      "ep 0: ep_len:510 episode reward: total was -17.380000. running mean: -67.063379\n",
      "ep 0: ep_len:500 episode reward: total was -17.370000. running mean: -66.566446\n",
      "ep 0: ep_len:710 episode reward: total was -84.750000. running mean: -66.748281\n",
      "ep 0: ep_len:505 episode reward: total was -52.830000. running mean: -66.609098\n",
      "ep 0: ep_len:940 episode reward: total was -87.540000. running mean: -66.818407\n",
      "ep 0: ep_len:500 episode reward: total was -31.940000. running mean: -66.469623\n",
      "ep 0: ep_len:625 episode reward: total was -109.900000. running mean: -66.903927\n",
      "ep 0: ep_len:860 episode reward: total was -90.650000. running mean: -67.141388\n",
      "ep 0: ep_len:755 episode reward: total was -67.270000. running mean: -67.142674\n",
      "ep 0: ep_len:775 episode reward: total was -54.050000. running mean: -67.011747\n",
      "ep 0: ep_len:545 episode reward: total was -42.390000. running mean: -66.765530\n",
      "ep 0: ep_len:191 episode reward: total was -4.500000. running mean: -66.142874\n",
      "ep 0: ep_len:595 episode reward: total was -66.010000. running mean: -66.141546\n",
      "ep 0: ep_len:600 episode reward: total was -64.560000. running mean: -66.125730\n",
      "ep 0: ep_len:1315 episode reward: total was -171.140000. running mean: -67.175873\n",
      "ep 0: ep_len:505 episode reward: total was -4.500000. running mean: -66.549114\n",
      "ep 0: ep_len:640 episode reward: total was -100.400000. running mean: -66.887623\n",
      "ep 0: ep_len:515 episode reward: total was -42.890000. running mean: -66.647647\n",
      "ep 0: ep_len:500 episode reward: total was -56.300000. running mean: -66.544170\n",
      "ep 0: ep_len:500 episode reward: total was -69.750000. running mean: -66.576229\n",
      "ep 0: ep_len:700 episode reward: total was -73.390000. running mean: -66.644366\n",
      "ep 0: ep_len:875 episode reward: total was -111.810000. running mean: -67.096023\n",
      "ep 0: ep_len:735 episode reward: total was -97.370000. running mean: -67.398763\n",
      "ep 0: ep_len:500 episode reward: total was -37.880000. running mean: -67.103575\n",
      "ep 0: ep_len:500 episode reward: total was -63.310000. running mean: -67.065639\n",
      "ep 0: ep_len:500 episode reward: total was -46.980000. running mean: -66.864783\n",
      "ep 0: ep_len:212 episode reward: total was -5.500000. running mean: -66.251135\n",
      "ep 0: ep_len:500 episode reward: total was -0.500000. running mean: -65.593624\n",
      "ep 0: ep_len:500 episode reward: total was -36.020000. running mean: -65.297887\n",
      "ep 0: ep_len:665 episode reward: total was -52.220000. running mean: -65.167108\n",
      "ep 0: ep_len:800 episode reward: total was -109.820000. running mean: -65.613637\n",
      "ep 0: ep_len:535 episode reward: total was -36.350000. running mean: -65.321001\n",
      "ep 0: ep_len:510 episode reward: total was -64.800000. running mean: -65.315791\n",
      "ep 0: ep_len:615 episode reward: total was -59.290000. running mean: -65.255533\n",
      "ep 0: ep_len:555 episode reward: total was -35.480000. running mean: -64.957778\n",
      "ep 0: ep_len:640 episode reward: total was -61.880000. running mean: -64.927000\n",
      "ep 0: ep_len:1015 episode reward: total was -116.170000. running mean: -65.439430\n",
      "ep 0: ep_len:515 episode reward: total was -30.200000. running mean: -65.087036\n",
      "ep 0: ep_len:510 episode reward: total was -38.560000. running mean: -64.821765\n",
      "ep 0: ep_len:1310 episode reward: total was -196.240000. running mean: -66.135948\n",
      "ep 0: ep_len:750 episode reward: total was -70.540000. running mean: -66.179988\n",
      "ep 0: ep_len:500 episode reward: total was -34.550000. running mean: -65.863688\n",
      "ep 0: ep_len:500 episode reward: total was -28.330000. running mean: -65.488351\n",
      "ep 0: ep_len:500 episode reward: total was -26.040000. running mean: -65.093868\n",
      "ep 0: ep_len:930 episode reward: total was -89.580000. running mean: -65.338729\n",
      "ep 0: ep_len:890 episode reward: total was -86.140000. running mean: -65.546742\n",
      "ep 0: ep_len:505 episode reward: total was -49.230000. running mean: -65.383575\n",
      "ep 0: ep_len:500 episode reward: total was -29.760000. running mean: -65.027339\n",
      "ep 0: ep_len:510 episode reward: total was -42.090000. running mean: -64.797965\n",
      "ep 0: ep_len:1350 episode reward: total was -235.250000. running mean: -66.502486\n",
      "ep 0: ep_len:785 episode reward: total was -114.600000. running mean: -66.983461\n",
      "ep 0: ep_len:510 episode reward: total was -39.840000. running mean: -66.712026\n",
      "ep 0: ep_len:675 episode reward: total was -88.590000. running mean: -66.930806\n",
      "ep 0: ep_len:500 episode reward: total was -48.110000. running mean: -66.742598\n",
      "ep 0: ep_len:710 episode reward: total was -61.640000. running mean: -66.691572\n",
      "ep 0: ep_len:1145 episode reward: total was -204.290000. running mean: -68.067556\n",
      "ep 0: ep_len:1705 episode reward: total was -260.160000. running mean: -69.988481\n",
      "ep 0: ep_len:645 episode reward: total was -126.000000. running mean: -70.548596\n",
      "ep 0: ep_len:710 episode reward: total was -95.070000. running mean: -70.793810\n",
      "ep 0: ep_len:865 episode reward: total was -65.830000. running mean: -70.744172\n",
      "ep 0: ep_len:500 episode reward: total was 0.000000. running mean: -70.036730\n",
      "ep 0: ep_len:1065 episode reward: total was -135.280000. running mean: -70.689163\n",
      "ep 0: ep_len:515 episode reward: total was -40.460000. running mean: -70.386871\n",
      "ep 0: ep_len:1550 episode reward: total was -149.430000. running mean: -71.177302\n",
      "ep 0: ep_len:505 episode reward: total was -58.230000. running mean: -71.047829\n",
      "ep 0: ep_len:505 episode reward: total was -1.000000. running mean: -70.347351\n",
      "ep 0: ep_len:515 episode reward: total was -78.810000. running mean: -70.431978\n",
      "ep 0: ep_len:1030 episode reward: total was -79.020000. running mean: -70.517858\n",
      "ep 0: ep_len:520 episode reward: total was -73.230000. running mean: -70.544979\n",
      "ep 0: ep_len:224 episode reward: total was 6.000000. running mean: -69.779529\n",
      "ep 0: ep_len:1040 episode reward: total was -69.050000. running mean: -69.772234\n",
      "ep 0: ep_len:252 episode reward: total was -0.500000. running mean: -69.079512\n",
      "ep 0: ep_len:1230 episode reward: total was -147.240000. running mean: -69.861117\n",
      "ep 0: ep_len:865 episode reward: total was -76.090000. running mean: -69.923406\n",
      "ep 0: ep_len:575 episode reward: total was -68.840000. running mean: -69.912571\n",
      "ep 0: ep_len:313 episode reward: total was 0.000000. running mean: -69.213446\n",
      "ep 0: ep_len:500 episode reward: total was -7.360000. running mean: -68.594911\n",
      "ep 0: ep_len:1235 episode reward: total was -65.490000. running mean: -68.563862\n",
      "ep 0: ep_len:500 episode reward: total was -63.220000. running mean: -68.510424\n",
      "ep 0: ep_len:193 episode reward: total was -1.000000. running mean: -67.835319\n",
      "ep 0: ep_len:1085 episode reward: total was -104.540000. running mean: -68.202366\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 0: ep_len:910 episode reward: total was -106.560000. running mean: -68.585942\n",
      "ep 0: ep_len:170 episode reward: total was 2.000000. running mean: -67.880083\n",
      "ep 0: ep_len:765 episode reward: total was -62.150000. running mean: -67.822782\n",
      "ep 0: ep_len:895 episode reward: total was -50.250000. running mean: -67.647054\n",
      "ep 0: ep_len:1025 episode reward: total was -70.530000. running mean: -67.675884\n",
      "ep 0: ep_len:254 episode reward: total was -4.500000. running mean: -67.044125\n",
      "ep 0: ep_len:570 episode reward: total was -85.920000. running mean: -67.232884\n",
      "ep 0: ep_len:510 episode reward: total was -46.990000. running mean: -67.030455\n",
      "ep 0: ep_len:815 episode reward: total was -70.130000. running mean: -67.061450\n",
      "ep 0: ep_len:535 episode reward: total was -76.720000. running mean: -67.158036\n",
      "ep 0: ep_len:1020 episode reward: total was -151.500000. running mean: -68.001456\n",
      "ep 0: ep_len:1550 episode reward: total was -194.080000. running mean: -69.262241\n",
      "ep 0: ep_len:418 episode reward: total was -7.500000. running mean: -68.644619\n",
      "ep 0: ep_len:358 episode reward: total was -35.760000. running mean: -68.315772\n",
      "ep 0: ep_len:590 episode reward: total was -52.400000. running mean: -68.156615\n",
      "ep 0: ep_len:500 episode reward: total was -83.400000. running mean: -68.309049\n",
      "ep 0: ep_len:935 episode reward: total was -81.000000. running mean: -68.435958\n",
      "ep 0: ep_len:730 episode reward: total was -82.390000. running mean: -68.575498\n",
      "ep 0: ep_len:745 episode reward: total was -75.950000. running mean: -68.649243\n",
      "ep 0: ep_len:675 episode reward: total was -50.210000. running mean: -68.464851\n",
      "ep 0: ep_len:700 episode reward: total was -42.100000. running mean: -68.201203\n",
      "ep 0: ep_len:840 episode reward: total was -67.020000. running mean: -68.189390\n",
      "ep 0: ep_len:725 episode reward: total was -67.280000. running mean: -68.180297\n",
      "ep 0: ep_len:875 episode reward: total was -65.910000. running mean: -68.157594\n",
      "ep 0: ep_len:500 episode reward: total was -55.360000. running mean: -68.029618\n",
      "ep 0: ep_len:1025 episode reward: total was -73.130000. running mean: -68.080622\n",
      "ep 0: ep_len:500 episode reward: total was -55.350000. running mean: -67.953315\n",
      "ep 0: ep_len:615 episode reward: total was -74.350000. running mean: -68.017282\n",
      "ep 0: ep_len:730 episode reward: total was -52.310000. running mean: -67.860209\n",
      "ep 0: ep_len:8525 episode reward: total was -1542.180000. running mean: -82.603407\n",
      "ep 0: ep_len:1025 episode reward: total was -75.590000. running mean: -82.533273\n",
      "ep 0: ep_len:500 episode reward: total was -19.830000. running mean: -81.906240\n",
      "ep 0: ep_len:273 episode reward: total was -4.000000. running mean: -81.127178\n",
      "ep 0: ep_len:540 episode reward: total was -96.910000. running mean: -81.285006\n",
      "ep 0: ep_len:500 episode reward: total was -16.850000. running mean: -80.640656\n",
      "ep 0: ep_len:500 episode reward: total was -55.880000. running mean: -80.393050\n",
      "ep 0: ep_len:500 episode reward: total was -31.820000. running mean: -79.907319\n",
      "ep 0: ep_len:590 episode reward: total was -57.940000. running mean: -79.687646\n",
      "ep 0: ep_len:690 episode reward: total was -55.800000. running mean: -79.448769\n",
      "ep 0: ep_len:510 episode reward: total was -40.040000. running mean: -79.054682\n",
      "ep 0: ep_len:635 episode reward: total was -19.760000. running mean: -78.461735\n",
      "ep 0: ep_len:505 episode reward: total was -25.790000. running mean: -77.935018\n",
      "ep 0: ep_len:910 episode reward: total was -68.540000. running mean: -77.841067\n",
      "ep 0: ep_len:500 episode reward: total was -29.830000. running mean: -77.360957\n",
      "ep 0: ep_len:500 episode reward: total was -36.830000. running mean: -76.955647\n",
      "ep 0: ep_len:505 episode reward: total was -54.350000. running mean: -76.729591\n",
      "ep 0: ep_len:1105 episode reward: total was -95.260000. running mean: -76.914895\n",
      "ep 0: ep_len:895 episode reward: total was -97.240000. running mean: -77.118146\n",
      "ep 0: ep_len:780 episode reward: total was -97.440000. running mean: -77.321364\n",
      "ep 0: ep_len:530 episode reward: total was -49.980000. running mean: -77.047951\n",
      "ep 0: ep_len:765 episode reward: total was -42.830000. running mean: -76.705771\n",
      "ep 0: ep_len:500 episode reward: total was -61.300000. running mean: -76.551714\n",
      "ep 0: ep_len:710 episode reward: total was -73.760000. running mean: -76.523796\n",
      "ep 0: ep_len:595 episode reward: total was -59.730000. running mean: -76.355858\n",
      "ep 0: ep_len:650 episode reward: total was -67.920000. running mean: -76.271500\n",
      "ep 0: ep_len:670 episode reward: total was -67.240000. running mean: -76.181185\n",
      "ep 0: ep_len:505 episode reward: total was -49.980000. running mean: -75.919173\n",
      "ep 0: ep_len:510 episode reward: total was -41.040000. running mean: -75.570381\n",
      "ep 0: ep_len:850 episode reward: total was -118.510000. running mean: -75.999777\n",
      "ep 0: ep_len:500 episode reward: total was -36.940000. running mean: -75.609180\n",
      "ep 0: ep_len:1170 episode reward: total was -142.210000. running mean: -76.275188\n",
      "ep 0: ep_len:510 episode reward: total was -29.340000. running mean: -75.805836\n",
      "ep 0: ep_len:146 episode reward: total was -4.500000. running mean: -75.092778\n",
      "ep 0: ep_len:530 episode reward: total was -79.270000. running mean: -75.134550\n",
      "ep 0: ep_len:500 episode reward: total was -74.910000. running mean: -75.132304\n",
      "ep 0: ep_len:550 episode reward: total was -70.140000. running mean: -75.082381\n",
      "ep 0: ep_len:965 episode reward: total was -63.600000. running mean: -74.967558\n",
      "ep 0: ep_len:505 episode reward: total was -47.120000. running mean: -74.689082\n",
      "ep 0: ep_len:148 episode reward: total was -1.500000. running mean: -73.957191\n",
      "ep 0: ep_len:500 episode reward: total was -45.110000. running mean: -73.668719\n",
      "ep 0: ep_len:850 episode reward: total was -76.330000. running mean: -73.695332\n",
      "ep 0: ep_len:660 episode reward: total was -69.920000. running mean: -73.657579\n",
      "ep 0: ep_len:206 episode reward: total was 4.000000. running mean: -72.881003\n",
      "ep 0: ep_len:10400 episode reward: total was -1908.130000. running mean: -91.233493\n",
      "ep 0: ep_len:515 episode reward: total was -49.770000. running mean: -90.818858\n",
      "ep 0: ep_len:1646 episode reward: total was -117.780000. running mean: -91.088469\n",
      "ep 0: ep_len:655 episode reward: total was -117.890000. running mean: -91.356485\n",
      "ep 0: ep_len:635 episode reward: total was -54.250000. running mean: -90.985420\n",
      "ep 0: ep_len:510 episode reward: total was -30.430000. running mean: -90.379866\n",
      "ep 0: ep_len:500 episode reward: total was -54.270000. running mean: -90.018767\n",
      "ep 0: ep_len:505 episode reward: total was -41.880000. running mean: -89.537379\n",
      "ep 0: ep_len:42235 episode reward: total was -8087.460000. running mean: -169.516606\n",
      "ep 0: ep_len:1040 episode reward: total was -135.200000. running mean: -169.173439\n",
      "ep 0: ep_len:1080 episode reward: total was -137.680000. running mean: -168.858505\n",
      "ep 0: ep_len:655 episode reward: total was -119.420000. running mean: -168.364120\n",
      "ep 0: ep_len:1000 episode reward: total was -187.410000. running mean: -168.554579\n",
      "ep 0: ep_len:670 episode reward: total was -108.420000. running mean: -167.953233\n",
      "ep 0: ep_len:914 episode reward: total was -172.940000. running mean: -168.003101\n",
      "ep 0: ep_len:835 episode reward: total was -153.400000. running mean: -167.857070\n",
      "ep 0: ep_len:625 episode reward: total was -114.430000. running mean: -167.322799\n",
      "ep 0: ep_len:505 episode reward: total was -34.390000. running mean: -165.993471\n",
      "ep 0: ep_len:580 episode reward: total was -55.450000. running mean: -164.888036\n",
      "ep 0: ep_len:500 episode reward: total was -31.180000. running mean: -163.550956\n",
      "ep 0: ep_len:500 episode reward: total was -35.710000. running mean: -162.272546\n",
      "ep 0: ep_len:510 episode reward: total was -28.410000. running mean: -160.933921\n",
      "ep 0: ep_len:570 episode reward: total was -76.460000. running mean: -160.089182\n",
      "ep 0: ep_len:880 episode reward: total was -168.460000. running mean: -160.172890\n",
      "ep 0: ep_len:655 episode reward: total was -75.450000. running mean: -159.325661\n",
      "ep 0: ep_len:555 episode reward: total was -46.840000. running mean: -158.200804\n",
      "ep 0: ep_len:510 episode reward: total was -58.340000. running mean: -157.202196\n",
      "ep 0: ep_len:1020 episode reward: total was -104.430000. running mean: -156.674474\n",
      "ep 0: ep_len:505 episode reward: total was -39.650000. running mean: -155.504230\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 0: ep_len:685 episode reward: total was -50.360000. running mean: -154.452787\n",
      "ep 0: ep_len:693 episode reward: total was -92.550000. running mean: -153.833759\n",
      "ep 0: ep_len:635 episode reward: total was -50.780000. running mean: -152.803222\n",
      "ep 0: ep_len:670 episode reward: total was -71.490000. running mean: -151.990090\n",
      "ep 0: ep_len:645 episode reward: total was -90.990000. running mean: -151.380089\n",
      "ep 0: ep_len:1130 episode reward: total was -148.170000. running mean: -151.347988\n",
      "ep 0: ep_len:1915 episode reward: total was -353.920000. running mean: -153.373708\n",
      "ep 0: ep_len:735 episode reward: total was -82.190000. running mean: -152.661871\n",
      "ep 0: ep_len:515 episode reward: total was -33.400000. running mean: -151.469252\n",
      "ep 0: ep_len:505 episode reward: total was -49.890000. running mean: -150.453460\n",
      "ep 0: ep_len:500 episode reward: total was -37.950000. running mean: -149.328425\n",
      "ep 0: ep_len:500 episode reward: total was -31.110000. running mean: -148.146241\n",
      "ep 0: ep_len:1942 episode reward: total was -172.230000. running mean: -148.387078\n",
      "ep 0: ep_len:1055 episode reward: total was -81.740000. running mean: -147.720608\n",
      "ep 0: ep_len:570 episode reward: total was -65.840000. running mean: -146.901802\n",
      "ep 0: ep_len:505 episode reward: total was -76.920000. running mean: -146.201984\n",
      "ep 0: ep_len:940 episode reward: total was -94.610000. running mean: -145.686064\n",
      "ep 0: ep_len:500 episode reward: total was -29.990000. running mean: -144.529103\n",
      "ep 0: ep_len:417 episode reward: total was -42.370000. running mean: -143.507512\n",
      "ep 0: ep_len:735 episode reward: total was -66.390000. running mean: -142.736337\n",
      "ep 0: ep_len:920 episode reward: total was -118.880000. running mean: -142.497774\n",
      "ep 0: ep_len:500 episode reward: total was -81.440000. running mean: -141.887196\n",
      "ep 0: ep_len:510 episode reward: total was -90.420000. running mean: -141.372524\n",
      "ep 0: ep_len:500 episode reward: total was -43.940000. running mean: -140.398199\n",
      "ep 0: ep_len:515 episode reward: total was -73.730000. running mean: -139.731517\n",
      "ep 0: ep_len:600 episode reward: total was -49.070000. running mean: -138.824901\n",
      "ep 0: ep_len:505 episode reward: total was -44.090000. running mean: -137.877552\n",
      "ep 0: ep_len:780 episode reward: total was -106.560000. running mean: -137.564377\n",
      "ep 0: ep_len:800 episode reward: total was -60.550000. running mean: -136.794233\n",
      "ep 0: ep_len:163 episode reward: total was -5.000000. running mean: -135.476291\n",
      "ep 0: ep_len:500 episode reward: total was -27.050000. running mean: -134.392028\n",
      "ep 0: ep_len:840 episode reward: total was -96.340000. running mean: -134.011508\n",
      "ep 0: ep_len:500 episode reward: total was -33.720000. running mean: -133.008593\n",
      "ep 0: ep_len:595 episode reward: total was -28.870000. running mean: -131.967207\n",
      "ep 0: ep_len:168 episode reward: total was -30.000000. running mean: -130.947535\n",
      "ep 0: ep_len:500 episode reward: total was -17.900000. running mean: -129.817059\n",
      "ep 0: ep_len:830 episode reward: total was -108.450000. running mean: -129.603389\n",
      "ep 0: ep_len:510 episode reward: total was -50.170000. running mean: -128.809055\n",
      "ep 0: ep_len:600 episode reward: total was -74.690000. running mean: -128.267864\n",
      "ep 0: ep_len:1047 episode reward: total was -119.570000. running mean: -128.180886\n",
      "ep 0: ep_len:208 episode reward: total was -3.500000. running mean: -126.934077\n",
      "ep 0: ep_len:2270 episode reward: total was -311.620000. running mean: -128.780936\n",
      "ep 0: ep_len:164 episode reward: total was 0.000000. running mean: -127.493127\n",
      "ep 0: ep_len:164 episode reward: total was -2.000000. running mean: -126.238195\n",
      "ep 0: ep_len:500 episode reward: total was -63.380000. running mean: -125.609613\n",
      "ep 0: ep_len:500 episode reward: total was -38.720000. running mean: -124.740717\n",
      "ep 0: ep_len:254 episode reward: total was -4.000000. running mean: -123.533310\n",
      "ep 0: ep_len:500 episode reward: total was -23.880000. running mean: -122.536777\n",
      "ep 0: ep_len:188 episode reward: total was 4.000000. running mean: -121.271409\n",
      "ep 0: ep_len:710 episode reward: total was -78.200000. running mean: -120.840695\n",
      "ep 0: ep_len:500 episode reward: total was -47.740000. running mean: -120.109688\n",
      "ep 0: ep_len:515 episode reward: total was -54.050000. running mean: -119.449091\n",
      "ep 0: ep_len:825 episode reward: total was -95.850000. running mean: -119.213100\n",
      "ep 0: ep_len:585 episode reward: total was -62.510000. running mean: -118.646069\n",
      "ep 0: ep_len:505 episode reward: total was -23.740000. running mean: -117.697009\n",
      "ep 0: ep_len:164 episode reward: total was -2.000000. running mean: -116.540039\n",
      "ep 0: ep_len:223 episode reward: total was 0.000000. running mean: -115.374638\n",
      "ep 0: ep_len:920 episode reward: total was -65.410000. running mean: -114.874992\n",
      "ep 0: ep_len:825 episode reward: total was -75.160000. running mean: -114.477842\n",
      "ep 0: ep_len:1180 episode reward: total was -53.930000. running mean: -113.872363\n",
      "ep 0: ep_len:805 episode reward: total was -51.970000. running mean: -113.253340\n",
      "ep 0: ep_len:560 episode reward: total was -55.350000. running mean: -112.674306\n",
      "ep 0: ep_len:500 episode reward: total was -35.810000. running mean: -111.905663\n",
      "ep 0: ep_len:535 episode reward: total was -35.220000. running mean: -111.138807\n",
      "ep 0: ep_len:500 episode reward: total was -30.840000. running mean: -110.335819\n",
      "ep 0: ep_len:555 episode reward: total was -49.760000. running mean: -109.730060\n",
      "ep 0: ep_len:675 episode reward: total was -93.300000. running mean: -109.565760\n",
      "ep 0: ep_len:1375 episode reward: total was -116.970000. running mean: -109.639802\n",
      "ep 0: ep_len:164 episode reward: total was -8.000000. running mean: -108.623404\n",
      "ep 0: ep_len:505 episode reward: total was -35.110000. running mean: -107.888270\n",
      "ep 0: ep_len:675 episode reward: total was -61.810000. running mean: -107.427487\n",
      "ep 0: ep_len:595 episode reward: total was -80.640000. running mean: -107.159613\n",
      "ep 0: ep_len:820 episode reward: total was -62.040000. running mean: -106.708416\n",
      "ep 0: ep_len:170 episode reward: total was -4.000000. running mean: -105.681332\n",
      "ep 0: ep_len:500 episode reward: total was -58.210000. running mean: -105.206619\n",
      "ep 0: ep_len:635 episode reward: total was -45.730000. running mean: -104.611853\n",
      "ep 0: ep_len:665 episode reward: total was -50.940000. running mean: -104.075134\n",
      "ep 0: ep_len:510 episode reward: total was -54.700000. running mean: -103.581383\n",
      "ep 0: ep_len:385 episode reward: total was 1.500000. running mean: -102.530569\n",
      "ep 0: ep_len:505 episode reward: total was -41.790000. running mean: -101.923163\n",
      "ep 0: ep_len:505 episode reward: total was -50.290000. running mean: -101.406832\n",
      "ep 0: ep_len:505 episode reward: total was -39.070000. running mean: -100.783463\n",
      "ep 0: ep_len:575 episode reward: total was -34.220000. running mean: -100.117829\n",
      "ep 0: ep_len:785 episode reward: total was -67.160000. running mean: -99.788251\n",
      "ep 0: ep_len:525 episode reward: total was -49.500000. running mean: -99.285368\n",
      "ep 0: ep_len:505 episode reward: total was -22.810000. running mean: -98.520614\n",
      "ep 0: ep_len:545 episode reward: total was -52.180000. running mean: -98.057208\n",
      "ep 0: ep_len:500 episode reward: total was -6.500000. running mean: -97.141636\n",
      "ep 0: ep_len:500 episode reward: total was -40.880000. running mean: -96.579020\n",
      "ep 0: ep_len:197 episode reward: total was 3.500000. running mean: -95.578230\n",
      "ep 0: ep_len:1045 episode reward: total was -75.160000. running mean: -95.374047\n",
      "ep 0: ep_len:292 episode reward: total was -45.910000. running mean: -94.879407\n",
      "ep 0: ep_len:805 episode reward: total was -129.220000. running mean: -95.222813\n",
      "ep 0: ep_len:184 episode reward: total was -6.500000. running mean: -94.335585\n",
      "ep 0: ep_len:530 episode reward: total was -46.190000. running mean: -93.854129\n",
      "ep 0: ep_len:670 episode reward: total was -73.940000. running mean: -93.654987\n",
      "ep 0: ep_len:311 episode reward: total was -2.000000. running mean: -92.738438\n",
      "ep 0: ep_len:1075 episode reward: total was -83.100000. running mean: -92.642053\n",
      "ep 0: ep_len:500 episode reward: total was -15.770000. running mean: -91.873333\n",
      "ep 0: ep_len:505 episode reward: total was 1.500000. running mean: -90.939599\n",
      "ep 0: ep_len:840 episode reward: total was -66.510000. running mean: -90.695303\n",
      "ep 0: ep_len:835 episode reward: total was -95.830000. running mean: -90.746650\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 0: ep_len:184 episode reward: total was 3.500000. running mean: -89.804184\n",
      "ep 0: ep_len:515 episode reward: total was -29.440000. running mean: -89.200542\n",
      "ep 0: ep_len:610 episode reward: total was -47.220000. running mean: -88.780737\n",
      "ep 0: ep_len:855 episode reward: total was -70.540000. running mean: -88.598329\n",
      "ep 0: ep_len:780 episode reward: total was -30.970000. running mean: -88.022046\n",
      "ep 0: ep_len:805 episode reward: total was -36.210000. running mean: -87.503925\n",
      "ep 0: ep_len:525 episode reward: total was -30.960000. running mean: -86.938486\n",
      "ep 0: ep_len:510 episode reward: total was -32.850000. running mean: -86.397601\n",
      "ep 0: ep_len:500 episode reward: total was -14.300000. running mean: -85.676625\n",
      "ep 0: ep_len:850 episode reward: total was -68.480000. running mean: -85.504659\n",
      "ep 0: ep_len:505 episode reward: total was -27.670000. running mean: -84.926312\n",
      "ep 0: ep_len:880 episode reward: total was -70.550000. running mean: -84.782549\n",
      "ep 0: ep_len:500 episode reward: total was -35.310000. running mean: -84.287824\n",
      "ep 0: ep_len:785 episode reward: total was -66.150000. running mean: -84.106446\n",
      "ep 0: ep_len:505 episode reward: total was -50.090000. running mean: -83.766281\n",
      "ep 0: ep_len:735 episode reward: total was -81.130000. running mean: -83.739918\n",
      "ep 0: ep_len:500 episode reward: total was -49.720000. running mean: -83.399719\n",
      "ep 0: ep_len:500 episode reward: total was 2.000000. running mean: -82.545722\n",
      "ep 0: ep_len:505 episode reward: total was -34.250000. running mean: -82.062765\n",
      "ep 0: ep_len:505 episode reward: total was -29.210000. running mean: -81.534237\n",
      "ep 0: ep_len:515 episode reward: total was -39.420000. running mean: -81.113095\n",
      "ep 0: ep_len:510 episode reward: total was -50.540000. running mean: -80.807364\n",
      "ep 0: ep_len:650 episode reward: total was -58.280000. running mean: -80.582090\n",
      "ep 0: ep_len:705 episode reward: total was -54.680000. running mean: -80.323069\n",
      "ep 0: ep_len:1305 episode reward: total was -93.390000. running mean: -80.453739\n",
      "ep 0: ep_len:358 episode reward: total was -27.000000. running mean: -79.919201\n",
      "ep 0: ep_len:1015 episode reward: total was -98.070000. running mean: -80.100709\n",
      "ep 0: ep_len:710 episode reward: total was -60.240000. running mean: -79.902102\n",
      "ep 0: ep_len:890 episode reward: total was -93.500000. running mean: -80.038081\n",
      "ep 0: ep_len:840 episode reward: total was -67.080000. running mean: -79.908500\n",
      "ep 0: ep_len:500 episode reward: total was -14.750000. running mean: -79.256915\n",
      "ep 0: ep_len:1005 episode reward: total was -59.060000. running mean: -79.054946\n",
      "ep 0: ep_len:935 episode reward: total was -92.020000. running mean: -79.184597\n",
      "ep 0: ep_len:765 episode reward: total was -61.140000. running mean: -79.004151\n",
      "ep 0: ep_len:500 episode reward: total was -24.320000. running mean: -78.457309\n",
      "ep 0: ep_len:975 episode reward: total was -92.790000. running mean: -78.600636\n",
      "ep 0: ep_len:895 episode reward: total was -97.030000. running mean: -78.784930\n",
      "ep 0: ep_len:660 episode reward: total was -105.790000. running mean: -79.054980\n",
      "ep 0: ep_len:785 episode reward: total was -67.710000. running mean: -78.941531\n",
      "ep 0: ep_len:500 episode reward: total was -38.590000. running mean: -78.538015\n",
      "ep 0: ep_len:765 episode reward: total was -82.350000. running mean: -78.576135\n",
      "ep 0: ep_len:620 episode reward: total was -65.590000. running mean: -78.446274\n",
      "ep 0: ep_len:705 episode reward: total was -95.600000. running mean: -78.617811\n",
      "ep 0: ep_len:875 episode reward: total was -79.070000. running mean: -78.622333\n",
      "ep 0: ep_len:790 episode reward: total was -59.640000. running mean: -78.432510\n",
      "ep 0: ep_len:505 episode reward: total was -82.410000. running mean: -78.472285\n",
      "ep 0: ep_len:500 episode reward: total was -54.630000. running mean: -78.233862\n",
      "ep 0: ep_len:1380 episode reward: total was -196.190000. running mean: -79.413423\n",
      "ep 0: ep_len:505 episode reward: total was -33.230000. running mean: -78.951589\n",
      "ep 0: ep_len:510 episode reward: total was -33.460000. running mean: -78.496673\n",
      "ep 0: ep_len:500 episode reward: total was -22.760000. running mean: -77.939306\n",
      "ep 0: ep_len:540 episode reward: total was -49.500000. running mean: -77.654913\n",
      "ep 0: ep_len:1075 episode reward: total was -171.840000. running mean: -78.596764\n",
      "ep 0: ep_len:500 episode reward: total was -60.250000. running mean: -78.413296\n",
      "ep 0: ep_len:2025 episode reward: total was -327.270000. running mean: -80.901863\n",
      "ep 0: ep_len:630 episode reward: total was -65.940000. running mean: -80.752245\n",
      "ep 0: ep_len:625 episode reward: total was -105.950000. running mean: -81.004222\n",
      "ep 0: ep_len:505 episode reward: total was -27.850000. running mean: -80.472680\n",
      "ep 0: ep_len:530 episode reward: total was -51.040000. running mean: -80.178353\n",
      "ep 0: ep_len:980 episode reward: total was -54.100000. running mean: -79.917570\n",
      "ep 0: ep_len:890 episode reward: total was -85.810000. running mean: -79.976494\n",
      "ep 0: ep_len:910 episode reward: total was -88.610000. running mean: -80.062829\n",
      "ep 0: ep_len:163 episode reward: total was 3.000000. running mean: -79.232201\n",
      "ep 0: ep_len:530 episode reward: total was -29.730000. running mean: -78.737179\n",
      "ep 0: ep_len:575 episode reward: total was -47.870000. running mean: -78.428507\n",
      "ep 0: ep_len:137 episode reward: total was -1.500000. running mean: -77.659222\n",
      "ep 0: ep_len:505 episode reward: total was -50.830000. running mean: -77.390930\n",
      "ep 0: ep_len:500 episode reward: total was -40.920000. running mean: -77.026220\n",
      "ep 0: ep_len:500 episode reward: total was -30.830000. running mean: -76.564258\n",
      "ep 0: ep_len:500 episode reward: total was -69.810000. running mean: -76.496716\n",
      "ep 0: ep_len:505 episode reward: total was -53.300000. running mean: -76.264749\n",
      "ep 0: ep_len:865 episode reward: total was -63.970000. running mean: -76.141801\n",
      "ep 0: ep_len:565 episode reward: total was -47.450000. running mean: -75.854883\n",
      "ep 0: ep_len:855 episode reward: total was -78.130000. running mean: -75.877634\n",
      "ep 0: ep_len:875 episode reward: total was -41.830000. running mean: -75.537158\n",
      "ep 0: ep_len:640 episode reward: total was -18.120000. running mean: -74.962986\n",
      "ep 0: ep_len:500 episode reward: total was -70.930000. running mean: -74.922656\n",
      "ep 0: ep_len:805 episode reward: total was -54.190000. running mean: -74.715330\n",
      "ep 0: ep_len:695 episode reward: total was -74.440000. running mean: -74.712577\n",
      "ep 0: ep_len:500 episode reward: total was -38.900000. running mean: -74.354451\n",
      "ep 0: ep_len:915 episode reward: total was -118.900000. running mean: -74.799906\n",
      "ep 0: ep_len:855 episode reward: total was -80.200000. running mean: -74.853907\n",
      "ep 0: ep_len:695 episode reward: total was -64.800000. running mean: -74.753368\n",
      "ep 0: ep_len:645 episode reward: total was -69.820000. running mean: -74.704034\n",
      "ep 0: ep_len:258 episode reward: total was 0.000000. running mean: -73.956994\n",
      "ep 0: ep_len:580 episode reward: total was -70.080000. running mean: -73.918224\n",
      "ep 0: ep_len:880 episode reward: total was -53.650000. running mean: -73.715542\n",
      "ep 0: ep_len:570 episode reward: total was -39.430000. running mean: -73.372687\n",
      "ep 0: ep_len:4435 episode reward: total was -788.560000. running mean: -80.524560\n",
      "ep 0: ep_len:560 episode reward: total was -43.860000. running mean: -80.157914\n",
      "ep 0: ep_len:505 episode reward: total was -12.880000. running mean: -79.485135\n",
      "ep 0: ep_len:745 episode reward: total was -60.170000. running mean: -79.291984\n",
      "ep 0: ep_len:500 episode reward: total was -38.530000. running mean: -78.884364\n",
      "ep 0: ep_len:500 episode reward: total was -22.840000. running mean: -78.323920\n",
      "ep 0: ep_len:276 episode reward: total was 4.000000. running mean: -77.500681\n",
      "ep 0: ep_len:680 episode reward: total was -57.270000. running mean: -77.298374\n",
      "ep 0: ep_len:515 episode reward: total was -20.920000. running mean: -76.734590\n",
      "ep 0: ep_len:500 episode reward: total was -28.900000. running mean: -76.256244\n",
      "ep 0: ep_len:545 episode reward: total was -42.360000. running mean: -75.917282\n",
      "ep 0: ep_len:710 episode reward: total was -68.390000. running mean: -75.842009\n",
      "ep 0: ep_len:740 episode reward: total was -37.320000. running mean: -75.456789\n",
      "ep 0: ep_len:615 episode reward: total was -90.380000. running mean: -75.606021\n",
      "ep 0: ep_len:530 episode reward: total was -75.350000. running mean: -75.603461\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 0: ep_len:500 episode reward: total was -74.370000. running mean: -75.591126\n",
      "ep 0: ep_len:1045 episode reward: total was -171.740000. running mean: -76.552615\n",
      "ep 0: ep_len:615 episode reward: total was -51.830000. running mean: -76.305389\n",
      "ep 0: ep_len:945 episode reward: total was -110.280000. running mean: -76.645135\n",
      "ep 0: ep_len:505 episode reward: total was -11.930000. running mean: -75.997984\n",
      "ep 0: ep_len:1260 episode reward: total was -74.040000. running mean: -75.978404\n",
      "ep 0: ep_len:645 episode reward: total was -51.280000. running mean: -75.731420\n",
      "ep 0: ep_len:500 episode reward: total was -40.900000. running mean: -75.383106\n",
      "ep 0: ep_len:540 episode reward: total was -47.940000. running mean: -75.108675\n",
      "ep 0: ep_len:655 episode reward: total was -40.250000. running mean: -74.760088\n",
      "ep 0: ep_len:970 episode reward: total was -103.670000. running mean: -75.049187\n",
      "ep 0: ep_len:570 episode reward: total was -47.390000. running mean: -74.772595\n",
      "ep 0: ep_len:535 episode reward: total was -90.890000. running mean: -74.933769\n",
      "ep 0: ep_len:705 episode reward: total was -56.700000. running mean: -74.751431\n",
      "ep 0: ep_len:945 episode reward: total was -116.670000. running mean: -75.170617\n",
      "ep 0: ep_len:186 episode reward: total was -7.000000. running mean: -74.488911\n",
      "ep 0: ep_len:500 episode reward: total was -72.320000. running mean: -74.467222\n",
      "ep 0: ep_len:535 episode reward: total was -41.400000. running mean: -74.136550\n",
      "ep 0: ep_len:505 episode reward: total was -78.400000. running mean: -74.179184\n",
      "ep 0: ep_len:630 episode reward: total was -60.270000. running mean: -74.040092\n",
      "ep 0: ep_len:1370 episode reward: total was -213.940000. running mean: -75.439091\n",
      "ep 0: ep_len:500 episode reward: total was -51.110000. running mean: -75.195800\n",
      "ep 0: ep_len:750 episode reward: total was -116.840000. running mean: -75.612242\n",
      "ep 0: ep_len:830 episode reward: total was -76.650000. running mean: -75.622620\n",
      "ep 0: ep_len:575 episode reward: total was -81.720000. running mean: -75.683594\n",
      "ep 0: ep_len:207 episode reward: total was -4.500000. running mean: -74.971758\n",
      "ep 0: ep_len:782 episode reward: total was -100.790000. running mean: -75.229940\n",
      "ep 0: ep_len:500 episode reward: total was -36.780000. running mean: -74.845441\n",
      "ep 0: ep_len:279 episode reward: total was -7.000000. running mean: -74.166986\n",
      "ep 0: ep_len:1700 episode reward: total was -298.120000. running mean: -76.406517\n",
      "ep 0: ep_len:505 episode reward: total was -27.730000. running mean: -75.919751\n",
      "ep 0: ep_len:505 episode reward: total was -44.030000. running mean: -75.600854\n",
      "ep 0: ep_len:805 episode reward: total was -86.280000. running mean: -75.707645\n",
      "ep 0: ep_len:665 episode reward: total was -73.430000. running mean: -75.684869\n",
      "ep 0: ep_len:515 episode reward: total was -51.540000. running mean: -75.443420\n",
      "ep 0: ep_len:292 episode reward: total was -41.000000. running mean: -75.098986\n",
      "ep 0: ep_len:740 episode reward: total was -85.300000. running mean: -75.200996\n",
      "ep 0: ep_len:1070 episode reward: total was -149.080000. running mean: -75.939786\n",
      "ep 0: ep_len:765 episode reward: total was -127.800000. running mean: -76.458388\n",
      "ep 0: ep_len:565 episode reward: total was -51.410000. running mean: -76.207904\n",
      "ep 0: ep_len:660 episode reward: total was -52.850000. running mean: -75.974325\n",
      "ep 0: ep_len:675 episode reward: total was -91.100000. running mean: -76.125582\n",
      "ep 0: ep_len:775 episode reward: total was -71.250000. running mean: -76.076826\n",
      "ep 0: ep_len:113 episode reward: total was -2.500000. running mean: -75.341058\n",
      "ep 0: ep_len:230 episode reward: total was -5.500000. running mean: -74.642648\n",
      "ep 0: ep_len:500 episode reward: total was -19.270000. running mean: -74.088921\n",
      "ep 0: ep_len:775 episode reward: total was -69.170000. running mean: -74.039732\n",
      "ep 0: ep_len:565 episode reward: total was -64.540000. running mean: -73.944735\n",
      "ep 0: ep_len:1195 episode reward: total was -134.650000. running mean: -74.551787\n",
      "ep 0: ep_len:765 episode reward: total was -107.080000. running mean: -74.877069\n",
      "ep 0: ep_len:505 episode reward: total was -52.200000. running mean: -74.650299\n",
      "ep 0: ep_len:239 episode reward: total was -2.000000. running mean: -73.923796\n",
      "ep 0: ep_len:500 episode reward: total was -25.850000. running mean: -73.443058\n",
      "ep 0: ep_len:580 episode reward: total was -49.390000. running mean: -73.202527\n",
      "ep 0: ep_len:500 episode reward: total was -26.830000. running mean: -72.738802\n",
      "ep 0: ep_len:102 episode reward: total was 4.000000. running mean: -71.971414\n",
      "ep 0: ep_len:500 episode reward: total was -23.810000. running mean: -71.489800\n",
      "ep 0: ep_len:485 episode reward: total was -35.870000. running mean: -71.133602\n",
      "ep 0: ep_len:500 episode reward: total was -61.700000. running mean: -71.039266\n",
      "ep 0: ep_len:260 episode reward: total was -0.500000. running mean: -70.333873\n",
      "ep 0: ep_len:590 episode reward: total was -67.030000. running mean: -70.300834\n",
      "ep 0: ep_len:197 episode reward: total was -1.500000. running mean: -69.612826\n",
      "ep 0: ep_len:500 episode reward: total was -27.350000. running mean: -69.190198\n",
      "ep 0: ep_len:760 episode reward: total was -67.600000. running mean: -69.174296\n",
      "ep 0: ep_len:560 episode reward: total was -81.960000. running mean: -69.302153\n",
      "ep 0: ep_len:2746 episode reward: total was -406.140000. running mean: -72.670531\n",
      "ep 0: ep_len:725 episode reward: total was -74.800000. running mean: -72.691826\n",
      "ep 0: ep_len:505 episode reward: total was -2.000000. running mean: -71.984908\n",
      "ep 0: ep_len:890 episode reward: total was -118.930000. running mean: -72.454359\n",
      "ep 0: ep_len:525 episode reward: total was -43.930000. running mean: -72.169115\n",
      "ep 0: ep_len:500 episode reward: total was -46.850000. running mean: -71.915924\n",
      "ep 0: ep_len:500 episode reward: total was -7.500000. running mean: -71.271765\n",
      "ep 0: ep_len:500 episode reward: total was -13.000000. running mean: -70.689047\n",
      "ep 0: ep_len:500 episode reward: total was -26.740000. running mean: -70.249556\n",
      "epsilon:0.384497 episode_count: 795. steps_count: 605261.000000\n",
      "ep 1: ep_len:500 episode reward: total was -24.780000. running mean: -69.794861\n",
      "ep 1: ep_len:820 episode reward: total was -48.390000. running mean: -69.580812\n",
      "ep 1: ep_len:500 episode reward: total was -46.270000. running mean: -69.347704\n",
      "ep 1: ep_len:1005 episode reward: total was -144.630000. running mean: -70.100527\n",
      "ep 1: ep_len:705 episode reward: total was -55.640000. running mean: -69.955922\n",
      "ep 1: ep_len:500 episode reward: total was -46.260000. running mean: -69.718963\n",
      "ep 1: ep_len:740 episode reward: total was -58.180000. running mean: -69.603573\n",
      "ep 1: ep_len:500 episode reward: total was -29.310000. running mean: -69.200637\n",
      "ep 1: ep_len:810 episode reward: total was -52.450000. running mean: -69.033131\n",
      "ep 1: ep_len:675 episode reward: total was -41.680000. running mean: -68.759600\n",
      "ep 1: ep_len:790 episode reward: total was -38.630000. running mean: -68.458304\n",
      "ep 1: ep_len:500 episode reward: total was -35.910000. running mean: -68.132821\n",
      "ep 1: ep_len:500 episode reward: total was -66.230000. running mean: -68.113792\n",
      "ep 1: ep_len:214 episode reward: total was 0.000000. running mean: -67.432654\n",
      "ep 1: ep_len:1000 episode reward: total was -60.930000. running mean: -67.367628\n",
      "ep 1: ep_len:830 episode reward: total was -63.520000. running mean: -67.329152\n",
      "ep 1: ep_len:515 episode reward: total was -36.430000. running mean: -67.020160\n",
      "ep 1: ep_len:500 episode reward: total was -51.320000. running mean: -66.863159\n",
      "ep 1: ep_len:505 episode reward: total was -45.280000. running mean: -66.647327\n",
      "ep 1: ep_len:580 episode reward: total was -88.750000. running mean: -66.868354\n",
      "ep 1: ep_len:510 episode reward: total was -26.830000. running mean: -66.467970\n",
      "ep 1: ep_len:1485 episode reward: total was -112.710000. running mean: -66.930390\n",
      "ep 1: ep_len:255 episode reward: total was -3.000000. running mean: -66.291087\n",
      "ep 1: ep_len:1215 episode reward: total was -127.880000. running mean: -66.906976\n",
      "ep 1: ep_len:1505 episode reward: total was -252.570000. running mean: -68.763606\n",
      "ep 1: ep_len:498 episode reward: total was -33.290000. running mean: -68.408870\n",
      "ep 1: ep_len:600 episode reward: total was -78.700000. running mean: -68.511781\n",
      "ep 1: ep_len:500 episode reward: total was -14.770000. running mean: -67.974363\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 1: ep_len:14715 episode reward: total was -2700.940000. running mean: -94.304020\n",
      "ep 1: ep_len:720 episode reward: total was -92.020000. running mean: -94.281179\n",
      "ep 1: ep_len:665 episode reward: total was -43.860000. running mean: -93.776968\n",
      "ep 1: ep_len:665 episode reward: total was -20.290000. running mean: -93.042098\n",
      "ep 1: ep_len:500 episode reward: total was -12.370000. running mean: -92.235377\n",
      "ep 1: ep_len:810 episode reward: total was -76.570000. running mean: -92.078723\n",
      "ep 1: ep_len:560 episode reward: total was -51.130000. running mean: -91.669236\n",
      "ep 1: ep_len:500 episode reward: total was -22.930000. running mean: -90.981844\n",
      "ep 1: ep_len:700 episode reward: total was -96.100000. running mean: -91.033025\n",
      "ep 1: ep_len:570 episode reward: total was -66.060000. running mean: -90.783295\n",
      "ep 1: ep_len:500 episode reward: total was -14.910000. running mean: -90.024562\n",
      "ep 1: ep_len:660 episode reward: total was -35.200000. running mean: -89.476316\n",
      "ep 1: ep_len:570 episode reward: total was -30.790000. running mean: -88.889453\n",
      "ep 1: ep_len:515 episode reward: total was -67.180000. running mean: -88.672359\n",
      "ep 1: ep_len:755 episode reward: total was -75.250000. running mean: -88.538135\n",
      "ep 1: ep_len:830 episode reward: total was -101.270000. running mean: -88.665454\n",
      "ep 1: ep_len:870 episode reward: total was -84.640000. running mean: -88.625199\n",
      "ep 1: ep_len:184 episode reward: total was 0.000000. running mean: -87.738947\n",
      "ep 1: ep_len:19965 episode reward: total was -3761.280000. running mean: -124.474358\n",
      "ep 1: ep_len:830 episode reward: total was -59.750000. running mean: -123.827114\n",
      "ep 1: ep_len:1070 episode reward: total was -119.080000. running mean: -123.779643\n",
      "ep 1: ep_len:500 episode reward: total was -32.590000. running mean: -122.867747\n",
      "ep 1: ep_len:177 episode reward: total was 2.500000. running mean: -121.614069\n",
      "ep 1: ep_len:840 episode reward: total was -118.310000. running mean: -121.581028\n",
      "ep 1: ep_len:500 episode reward: total was -34.900000. running mean: -120.714218\n",
      "ep 1: ep_len:575 episode reward: total was -29.480000. running mean: -119.801876\n",
      "ep 1: ep_len:660 episode reward: total was -87.090000. running mean: -119.474757\n",
      "ep 1: ep_len:505 episode reward: total was -69.400000. running mean: -118.974010\n",
      "ep 1: ep_len:695 episode reward: total was -101.680000. running mean: -118.801070\n",
      "ep 1: ep_len:500 episode reward: total was -85.470000. running mean: -118.467759\n",
      "ep 1: ep_len:18725 episode reward: total was -3591.500000. running mean: -153.198081\n",
      "ep 1: ep_len:1070 episode reward: total was -103.340000. running mean: -152.699500\n",
      "ep 1: ep_len:565 episode reward: total was -78.710000. running mean: -151.959605\n",
      "ep 1: ep_len:500 episode reward: total was -68.400000. running mean: -151.124009\n",
      "ep 1: ep_len:500 episode reward: total was -20.910000. running mean: -149.821869\n",
      "ep 1: ep_len:1220 episode reward: total was -138.820000. running mean: -149.711851\n",
      "ep 1: ep_len:580 episode reward: total was -106.440000. running mean: -149.279132\n",
      "ep 1: ep_len:520 episode reward: total was -95.970000. running mean: -148.746041\n",
      "ep 1: ep_len:580 episode reward: total was -109.470000. running mean: -148.353280\n",
      "ep 1: ep_len:845 episode reward: total was -157.940000. running mean: -148.449148\n",
      "ep 1: ep_len:745 episode reward: total was -94.960000. running mean: -147.914256\n",
      "ep 1: ep_len:950 episode reward: total was -131.770000. running mean: -147.752814\n",
      "ep 1: ep_len:500 episode reward: total was -30.280000. running mean: -146.578085\n",
      "ep 1: ep_len:500 episode reward: total was -83.920000. running mean: -145.951505\n",
      "ep 1: ep_len:630 episode reward: total was -64.620000. running mean: -145.138190\n",
      "ep 1: ep_len:500 episode reward: total was -35.410000. running mean: -144.040908\n",
      "ep 1: ep_len:1945 episode reward: total was -148.640000. running mean: -144.086899\n",
      "ep 1: ep_len:510 episode reward: total was -60.640000. running mean: -143.252430\n",
      "ep 1: ep_len:775 episode reward: total was -105.530000. running mean: -142.875205\n",
      "ep 1: ep_len:510 episode reward: total was -30.340000. running mean: -141.749853\n",
      "ep 1: ep_len:675 episode reward: total was -55.900000. running mean: -140.891355\n",
      "ep 1: ep_len:64 episode reward: total was -1.500000. running mean: -139.497441\n",
      "ep 1: ep_len:505 episode reward: total was -94.960000. running mean: -139.052067\n",
      "ep 1: ep_len:500 episode reward: total was -65.800000. running mean: -138.319546\n",
      "ep 1: ep_len:555 episode reward: total was -79.740000. running mean: -137.733751\n",
      "ep 1: ep_len:705 episode reward: total was -106.190000. running mean: -137.418313\n",
      "ep 1: ep_len:665 episode reward: total was -90.630000. running mean: -136.950430\n",
      "ep 1: ep_len:640 episode reward: total was -63.410000. running mean: -136.215026\n",
      "ep 1: ep_len:1195 episode reward: total was -114.580000. running mean: -135.998675\n",
      "ep 1: ep_len:1655 episode reward: total was -104.290000. running mean: -135.681589\n",
      "ep 1: ep_len:525 episode reward: total was -98.960000. running mean: -135.314373\n",
      "ep 1: ep_len:635 episode reward: total was -37.880000. running mean: -134.340029\n",
      "ep 1: ep_len:19175 episode reward: total was -3140.170000. running mean: -164.398329\n",
      "ep 1: ep_len:935 episode reward: total was -109.680000. running mean: -163.851145\n",
      "ep 1: ep_len:218 episode reward: total was -2.500000. running mean: -162.237634\n",
      "ep 1: ep_len:500 episode reward: total was -47.070000. running mean: -161.085958\n",
      "ep 1: ep_len:510 episode reward: total was -56.830000. running mean: -160.043398\n",
      "ep 1: ep_len:500 episode reward: total was -40.000000. running mean: -158.842964\n",
      "ep 1: ep_len:715 episode reward: total was -65.770000. running mean: -157.912234\n",
      "ep 1: ep_len:580 episode reward: total was -42.410000. running mean: -156.757212\n",
      "ep 1: ep_len:710 episode reward: total was -130.420000. running mean: -156.493840\n",
      "ep 1: ep_len:885 episode reward: total was -107.710000. running mean: -156.006002\n",
      "ep 1: ep_len:515 episode reward: total was -89.920000. running mean: -155.345142\n",
      "ep 1: ep_len:1005 episode reward: total was -85.530000. running mean: -154.646990\n",
      "ep 1: ep_len:615 episode reward: total was -60.920000. running mean: -153.709720\n",
      "ep 1: ep_len:500 episode reward: total was -62.310000. running mean: -152.795723\n",
      "ep 1: ep_len:655 episode reward: total was -107.300000. running mean: -152.340766\n",
      "ep 1: ep_len:500 episode reward: total was -66.840000. running mean: -151.485758\n",
      "ep 1: ep_len:500 episode reward: total was -6.500000. running mean: -150.035901\n",
      "ep 1: ep_len:500 episode reward: total was -32.810000. running mean: -148.863642\n",
      "ep 1: ep_len:740 episode reward: total was -97.060000. running mean: -148.345605\n",
      "ep 1: ep_len:860 episode reward: total was -102.850000. running mean: -147.890649\n",
      "ep 1: ep_len:500 episode reward: total was -47.760000. running mean: -146.889343\n",
      "ep 1: ep_len:510 episode reward: total was -50.160000. running mean: -145.922049\n",
      "ep 1: ep_len:1032 episode reward: total was -138.390000. running mean: -145.846729\n",
      "ep 1: ep_len:880 episode reward: total was -58.410000. running mean: -144.972361\n",
      "ep 1: ep_len:515 episode reward: total was -59.650000. running mean: -144.119138\n",
      "ep 1: ep_len:1310 episode reward: total was -189.820000. running mean: -144.576146\n",
      "ep 1: ep_len:765 episode reward: total was -77.900000. running mean: -143.909385\n",
      "ep 1: ep_len:675 episode reward: total was -68.390000. running mean: -143.154191\n",
      "ep 1: ep_len:1515 episode reward: total was -263.660000. running mean: -144.359249\n",
      "ep 1: ep_len:505 episode reward: total was -44.730000. running mean: -143.362957\n",
      "ep 1: ep_len:745 episode reward: total was -87.440000. running mean: -142.803727\n",
      "ep 1: ep_len:98 episode reward: total was 0.500000. running mean: -141.370690\n",
      "ep 1: ep_len:635 episode reward: total was -40.860000. running mean: -140.365583\n",
      "ep 1: ep_len:1170 episode reward: total was -123.990000. running mean: -140.201827\n",
      "ep 1: ep_len:695 episode reward: total was -38.640000. running mean: -139.186209\n",
      "ep 1: ep_len:775 episode reward: total was -102.030000. running mean: -138.814647\n",
      "ep 1: ep_len:505 episode reward: total was -23.330000. running mean: -137.659800\n",
      "ep 1: ep_len:1465 episode reward: total was -128.910000. running mean: -137.572302\n",
      "ep 1: ep_len:708 episode reward: total was -112.230000. running mean: -137.318879\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 1: ep_len:505 episode reward: total was -45.310000. running mean: -136.398790\n",
      "ep 1: ep_len:500 episode reward: total was -47.500000. running mean: -135.509803\n",
      "ep 1: ep_len:500 episode reward: total was -53.070000. running mean: -134.685405\n",
      "ep 1: ep_len:2460 episode reward: total was -280.440000. running mean: -136.142951\n",
      "ep 1: ep_len:500 episode reward: total was -25.870000. running mean: -135.040221\n",
      "ep 1: ep_len:875 episode reward: total was -78.550000. running mean: -134.475319\n",
      "ep 1: ep_len:1510 episode reward: total was -123.250000. running mean: -134.363066\n",
      "ep 1: ep_len:665 episode reward: total was -46.490000. running mean: -133.484335\n",
      "ep 1: ep_len:500 episode reward: total was -46.030000. running mean: -132.609792\n",
      "ep 1: ep_len:219 episode reward: total was -18.000000. running mean: -131.463694\n",
      "ep 1: ep_len:500 episode reward: total was -5.500000. running mean: -130.204057\n",
      "ep 1: ep_len:500 episode reward: total was -43.170000. running mean: -129.333716\n",
      "ep 1: ep_len:755 episode reward: total was -77.810000. running mean: -128.818479\n",
      "ep 1: ep_len:505 episode reward: total was -33.910000. running mean: -127.869394\n",
      "ep 1: ep_len:1000 episode reward: total was -122.280000. running mean: -127.813500\n",
      "ep 1: ep_len:580 episode reward: total was -59.490000. running mean: -127.130265\n",
      "ep 1: ep_len:570 episode reward: total was -47.390000. running mean: -126.332863\n",
      "ep 1: ep_len:1040 episode reward: total was -120.180000. running mean: -126.271334\n",
      "ep 1: ep_len:167 episode reward: total was -3.000000. running mean: -125.038621\n",
      "ep 1: ep_len:1310 episode reward: total was -125.900000. running mean: -125.047234\n",
      "ep 1: ep_len:505 episode reward: total was -21.310000. running mean: -124.009862\n",
      "ep 1: ep_len:550 episode reward: total was -48.720000. running mean: -123.256963\n",
      "ep 1: ep_len:800 episode reward: total was -47.630000. running mean: -122.500694\n",
      "ep 1: ep_len:535 episode reward: total was -25.890000. running mean: -121.534587\n",
      "ep 1: ep_len:735 episode reward: total was -56.700000. running mean: -120.886241\n",
      "ep 1: ep_len:725 episode reward: total was -28.520000. running mean: -119.962579\n",
      "ep 1: ep_len:500 episode reward: total was -79.880000. running mean: -119.561753\n",
      "ep 1: ep_len:650 episode reward: total was -86.620000. running mean: -119.232335\n",
      "ep 1: ep_len:575 episode reward: total was -93.320000. running mean: -118.973212\n",
      "ep 1: ep_len:795 episode reward: total was -55.020000. running mean: -118.333680\n",
      "ep 1: ep_len:565 episode reward: total was -55.450000. running mean: -117.704843\n",
      "ep 1: ep_len:500 episode reward: total was -20.940000. running mean: -116.737195\n",
      "ep 1: ep_len:570 episode reward: total was -51.890000. running mean: -116.088723\n",
      "ep 1: ep_len:620 episode reward: total was -57.390000. running mean: -115.501735\n",
      "ep 1: ep_len:729 episode reward: total was -116.770000. running mean: -115.514418\n",
      "ep 1: ep_len:750 episode reward: total was -72.250000. running mean: -115.081774\n",
      "ep 1: ep_len:391 episode reward: total was 3.500000. running mean: -113.895956\n",
      "ep 1: ep_len:680 episode reward: total was -56.260000. running mean: -113.319597\n",
      "ep 1: ep_len:975 episode reward: total was -77.820000. running mean: -112.964601\n",
      "ep 1: ep_len:970 episode reward: total was -96.570000. running mean: -112.800655\n",
      "ep 1: ep_len:1160 episode reward: total was -108.860000. running mean: -112.761248\n",
      "ep 1: ep_len:136 episode reward: total was 3.500000. running mean: -111.598636\n",
      "ep 1: ep_len:500 episode reward: total was -46.120000. running mean: -110.943849\n",
      "ep 1: ep_len:161 episode reward: total was -0.500000. running mean: -109.839411\n",
      "ep 1: ep_len:500 episode reward: total was -12.860000. running mean: -108.869617\n",
      "ep 1: ep_len:500 episode reward: total was -38.870000. running mean: -108.169620\n",
      "ep 1: ep_len:505 episode reward: total was -48.010000. running mean: -107.568024\n",
      "ep 1: ep_len:500 episode reward: total was -45.370000. running mean: -106.946044\n",
      "ep 1: ep_len:575 episode reward: total was -86.770000. running mean: -106.744284\n",
      "ep 1: ep_len:1285 episode reward: total was -175.860000. running mean: -107.435441\n",
      "ep 1: ep_len:670 episode reward: total was -31.540000. running mean: -106.676486\n",
      "ep 1: ep_len:545 episode reward: total was -79.240000. running mean: -106.402121\n",
      "ep 1: ep_len:505 episode reward: total was -19.370000. running mean: -105.531800\n",
      "ep 1: ep_len:505 episode reward: total was -17.890000. running mean: -104.655382\n",
      "ep 1: ep_len:500 episode reward: total was -37.030000. running mean: -103.979128\n",
      "ep 1: ep_len:500 episode reward: total was -34.730000. running mean: -103.286637\n",
      "ep 1: ep_len:675 episode reward: total was -66.860000. running mean: -102.922371\n",
      "ep 1: ep_len:274 episode reward: total was -1.000000. running mean: -101.903147\n",
      "ep 1: ep_len:835 episode reward: total was -95.340000. running mean: -101.837516\n",
      "ep 1: ep_len:785 episode reward: total was -58.680000. running mean: -101.405940\n",
      "ep 1: ep_len:585 episode reward: total was -84.210000. running mean: -101.233981\n",
      "ep 1: ep_len:2010 episode reward: total was -344.260000. running mean: -103.664241\n",
      "ep 1: ep_len:630 episode reward: total was -51.810000. running mean: -103.145699\n",
      "ep 1: ep_len:500 episode reward: total was -36.800000. running mean: -102.482242\n",
      "ep 1: ep_len:970 episode reward: total was -67.660000. running mean: -102.134019\n",
      "ep 1: ep_len:890 episode reward: total was -73.120000. running mean: -101.843879\n",
      "ep 1: ep_len:505 episode reward: total was -10.300000. running mean: -100.928440\n",
      "ep 1: ep_len:620 episode reward: total was -87.690000. running mean: -100.796056\n",
      "ep 1: ep_len:545 episode reward: total was -75.200000. running mean: -100.540095\n",
      "ep 1: ep_len:660 episode reward: total was -90.690000. running mean: -100.441595\n",
      "ep 1: ep_len:580 episode reward: total was -103.960000. running mean: -100.476779\n",
      "ep 1: ep_len:500 episode reward: total was -36.900000. running mean: -99.841011\n",
      "ep 1: ep_len:4520 episode reward: total was -706.960000. running mean: -105.912201\n",
      "ep 1: ep_len:680 episode reward: total was -41.500000. running mean: -105.268079\n",
      "ep 1: ep_len:580 episode reward: total was -55.280000. running mean: -104.768198\n",
      "ep 1: ep_len:1015 episode reward: total was -61.120000. running mean: -104.331716\n",
      "ep 1: ep_len:1215 episode reward: total was -97.610000. running mean: -104.264499\n",
      "ep 1: ep_len:185 episode reward: total was -22.490000. running mean: -103.446754\n",
      "ep 1: ep_len:500 episode reward: total was -44.170000. running mean: -102.853986\n",
      "ep 1: ep_len:505 episode reward: total was -65.240000. running mean: -102.477846\n",
      "ep 1: ep_len:2060 episode reward: total was -228.340000. running mean: -103.736468\n",
      "ep 1: ep_len:500 episode reward: total was -52.780000. running mean: -103.226903\n",
      "ep 1: ep_len:700 episode reward: total was -111.770000. running mean: -103.312334\n",
      "ep 1: ep_len:580 episode reward: total was -51.390000. running mean: -102.793111\n",
      "ep 1: ep_len:500 episode reward: total was -19.820000. running mean: -101.963380\n",
      "ep 1: ep_len:500 episode reward: total was -48.630000. running mean: -101.430046\n",
      "ep 1: ep_len:825 episode reward: total was -39.500000. running mean: -100.810745\n",
      "ep 1: ep_len:500 episode reward: total was -46.830000. running mean: -100.270938\n",
      "ep 1: ep_len:615 episode reward: total was -62.450000. running mean: -99.892729\n",
      "ep 1: ep_len:580 episode reward: total was -57.120000. running mean: -99.465001\n",
      "ep 1: ep_len:500 episode reward: total was -25.320000. running mean: -98.723551\n",
      "ep 1: ep_len:520 episode reward: total was -37.110000. running mean: -98.107416\n",
      "ep 1: ep_len:500 episode reward: total was -45.540000. running mean: -97.581742\n",
      "ep 1: ep_len:500 episode reward: total was -4.900000. running mean: -96.654924\n",
      "ep 1: ep_len:505 episode reward: total was -37.480000. running mean: -96.063175\n",
      "ep 1: ep_len:670 episode reward: total was -58.840000. running mean: -95.690943\n",
      "ep 1: ep_len:550 episode reward: total was -52.480000. running mean: -95.258834\n",
      "ep 1: ep_len:530 episode reward: total was -48.450000. running mean: -94.790745\n",
      "ep 1: ep_len:500 episode reward: total was -23.300000. running mean: -94.075838\n",
      "ep 1: ep_len:505 episode reward: total was -32.970000. running mean: -93.464780\n",
      "ep 1: ep_len:630 episode reward: total was -86.660000. running mean: -93.396732\n",
      "ep 1: ep_len:890 episode reward: total was -153.810000. running mean: -94.000865\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 1: ep_len:1655 episode reward: total was -127.150000. running mean: -94.332356\n",
      "ep 1: ep_len:560 episode reward: total was -53.470000. running mean: -93.923732\n",
      "ep 1: ep_len:720 episode reward: total was -78.400000. running mean: -93.768495\n",
      "ep 1: ep_len:835 episode reward: total was -68.070000. running mean: -93.511510\n",
      "ep 1: ep_len:530 episode reward: total was -64.270000. running mean: -93.219095\n",
      "ep 1: ep_len:715 episode reward: total was -40.930000. running mean: -92.696204\n",
      "ep 1: ep_len:510 episode reward: total was -93.970000. running mean: -92.708942\n",
      "ep 1: ep_len:500 episode reward: total was -30.260000. running mean: -92.084453\n",
      "ep 1: ep_len:142 episode reward: total was -6.500000. running mean: -91.228608\n",
      "ep 1: ep_len:143 episode reward: total was 0.500000. running mean: -90.311322\n",
      "ep 1: ep_len:500 episode reward: total was -19.320000. running mean: -89.601409\n",
      "ep 1: ep_len:500 episode reward: total was -34.210000. running mean: -89.047495\n",
      "ep 1: ep_len:815 episode reward: total was -87.930000. running mean: -89.036320\n",
      "ep 1: ep_len:505 episode reward: total was -35.150000. running mean: -88.497457\n",
      "ep 1: ep_len:500 episode reward: total was -19.840000. running mean: -87.810882\n",
      "ep 1: ep_len:500 episode reward: total was -11.780000. running mean: -87.050573\n",
      "ep 1: ep_len:500 episode reward: total was -71.460000. running mean: -86.894667\n",
      "ep 1: ep_len:500 episode reward: total was -17.280000. running mean: -86.198521\n",
      "ep 1: ep_len:925 episode reward: total was -69.690000. running mean: -86.033436\n",
      "ep 1: ep_len:500 episode reward: total was -28.900000. running mean: -85.462101\n",
      "ep 1: ep_len:510 episode reward: total was -46.970000. running mean: -85.077180\n",
      "ep 1: ep_len:500 episode reward: total was -58.270000. running mean: -84.809108\n",
      "ep 1: ep_len:275 episode reward: total was -6.990000. running mean: -84.030917\n",
      "ep 1: ep_len:500 episode reward: total was -43.980000. running mean: -83.630408\n",
      "ep 1: ep_len:560 episode reward: total was -97.910000. running mean: -83.773204\n",
      "ep 1: ep_len:257 episode reward: total was 0.000000. running mean: -82.935472\n",
      "ep 1: ep_len:505 episode reward: total was -38.120000. running mean: -82.487317\n",
      "ep 1: ep_len:540 episode reward: total was -91.370000. running mean: -82.576144\n",
      "ep 1: ep_len:500 episode reward: total was -58.150000. running mean: -82.331883\n",
      "ep 1: ep_len:174 episode reward: total was -1.000000. running mean: -81.518564\n",
      "ep 1: ep_len:580 episode reward: total was -43.330000. running mean: -81.136678\n",
      "ep 1: ep_len:710 episode reward: total was -65.780000. running mean: -80.983111\n",
      "ep 1: ep_len:670 episode reward: total was -62.540000. running mean: -80.798680\n",
      "ep 1: ep_len:2625 episode reward: total was -272.550000. running mean: -82.716193\n",
      "ep 1: ep_len:780 episode reward: total was -95.990000. running mean: -82.848932\n",
      "ep 1: ep_len:615 episode reward: total was -55.350000. running mean: -82.573942\n",
      "ep 1: ep_len:500 episode reward: total was -22.350000. running mean: -81.971703\n",
      "ep 1: ep_len:500 episode reward: total was -23.680000. running mean: -81.388786\n",
      "ep 1: ep_len:515 episode reward: total was -54.050000. running mean: -81.115398\n",
      "ep 1: ep_len:505 episode reward: total was -68.820000. running mean: -80.992444\n",
      "ep 1: ep_len:500 episode reward: total was -77.310000. running mean: -80.955619\n",
      "ep 1: ep_len:1365 episode reward: total was -228.580000. running mean: -82.431863\n",
      "ep 1: ep_len:510 episode reward: total was -60.240000. running mean: -82.209945\n",
      "ep 1: ep_len:500 episode reward: total was -27.800000. running mean: -81.665845\n",
      "ep 1: ep_len:550 episode reward: total was -41.860000. running mean: -81.267787\n",
      "ep 1: ep_len:304 episode reward: total was -11.500000. running mean: -80.570109\n",
      "ep 1: ep_len:905 episode reward: total was -53.240000. running mean: -80.296808\n",
      "ep 1: ep_len:1075 episode reward: total was -139.270000. running mean: -80.886540\n",
      "ep 1: ep_len:605 episode reward: total was -21.730000. running mean: -80.294974\n",
      "ep 1: ep_len:494 episode reward: total was -54.160000. running mean: -80.033625\n",
      "ep 1: ep_len:535 episode reward: total was -74.730000. running mean: -79.980588\n",
      "ep 1: ep_len:775 episode reward: total was -58.060000. running mean: -79.761382\n",
      "ep 1: ep_len:1480 episode reward: total was -100.600000. running mean: -79.969769\n",
      "ep 1: ep_len:840 episode reward: total was -72.350000. running mean: -79.893571\n",
      "ep 1: ep_len:505 episode reward: total was -0.500000. running mean: -79.099635\n",
      "ep 1: ep_len:910 episode reward: total was -60.660000. running mean: -78.915239\n",
      "ep 1: ep_len:690 episode reward: total was -58.630000. running mean: -78.712386\n",
      "ep 1: ep_len:600 episode reward: total was -86.690000. running mean: -78.792163\n",
      "ep 1: ep_len:850 episode reward: total was -84.440000. running mean: -78.848641\n",
      "ep 1: ep_len:1250 episode reward: total was -158.900000. running mean: -79.649155\n",
      "ep 1: ep_len:1280 episode reward: total was -181.290000. running mean: -80.665563\n",
      "ep 1: ep_len:382 episode reward: total was -23.500000. running mean: -80.093907\n",
      "ep 1: ep_len:1070 episode reward: total was -149.900000. running mean: -80.791968\n",
      "ep 1: ep_len:530 episode reward: total was -27.110000. running mean: -80.255149\n",
      "ep 1: ep_len:1095 episode reward: total was -57.820000. running mean: -80.030797\n",
      "ep 1: ep_len:625 episode reward: total was -62.430000. running mean: -79.854789\n",
      "ep 1: ep_len:840 episode reward: total was -133.190000. running mean: -80.388141\n",
      "ep 1: ep_len:1010 episode reward: total was -79.850000. running mean: -80.382760\n",
      "ep 1: ep_len:258 episode reward: total was -2.000000. running mean: -79.598932\n",
      "ep 1: ep_len:167 episode reward: total was 2.000000. running mean: -78.782943\n",
      "ep 1: ep_len:268 episode reward: total was -11.500000. running mean: -78.110114\n",
      "ep 1: ep_len:500 episode reward: total was -62.940000. running mean: -77.958412\n",
      "ep 1: ep_len:505 episode reward: total was -24.650000. running mean: -77.425328\n",
      "ep 1: ep_len:750 episode reward: total was -39.490000. running mean: -77.045975\n",
      "ep 1: ep_len:505 episode reward: total was -69.740000. running mean: -76.972915\n",
      "ep 1: ep_len:170 episode reward: total was -2.500000. running mean: -76.228186\n",
      "ep 1: ep_len:690 episode reward: total was -55.230000. running mean: -76.018204\n",
      "ep 1: ep_len:515 episode reward: total was -17.400000. running mean: -75.432022\n",
      "ep 1: ep_len:320 episode reward: total was -1.000000. running mean: -74.687702\n",
      "ep 1: ep_len:645 episode reward: total was -71.970000. running mean: -74.660525\n",
      "ep 1: ep_len:1010 episode reward: total was -113.660000. running mean: -75.050520\n",
      "ep 1: ep_len:775 episode reward: total was -75.260000. running mean: -75.052615\n",
      "ep 1: ep_len:505 episode reward: total was -48.190000. running mean: -74.783988\n",
      "ep 1: ep_len:515 episode reward: total was -79.820000. running mean: -74.834348\n",
      "ep 1: ep_len:505 episode reward: total was -13.790000. running mean: -74.223905\n",
      "ep 1: ep_len:1115 episode reward: total was -92.440000. running mean: -74.406066\n",
      "ep 1: ep_len:590 episode reward: total was -48.600000. running mean: -74.148005\n",
      "ep 1: ep_len:730 episode reward: total was -51.950000. running mean: -73.926025\n",
      "ep 1: ep_len:580 episode reward: total was -106.960000. running mean: -74.256365\n",
      "ep 1: ep_len:1080 episode reward: total was -115.180000. running mean: -74.665601\n",
      "ep 1: ep_len:1535 episode reward: total was -231.970000. running mean: -76.238645\n",
      "ep 1: ep_len:1020 episode reward: total was -98.000000. running mean: -76.456259\n",
      "ep 1: ep_len:505 episode reward: total was -35.020000. running mean: -76.041896\n",
      "ep 1: ep_len:945 episode reward: total was -98.680000. running mean: -76.268277\n",
      "ep 1: ep_len:245 episode reward: total was -11.000000. running mean: -75.615595\n",
      "ep 1: ep_len:610 episode reward: total was -79.750000. running mean: -75.656939\n",
      "ep 1: ep_len:505 episode reward: total was -48.340000. running mean: -75.383769\n",
      "ep 1: ep_len:730 episode reward: total was -62.220000. running mean: -75.252132\n",
      "ep 1: ep_len:500 episode reward: total was -7.880000. running mean: -74.578410\n",
      "ep 1: ep_len:244 episode reward: total was 3.000000. running mean: -73.802626\n",
      "ep 1: ep_len:118 episode reward: total was 2.500000. running mean: -73.039600\n",
      "ep 1: ep_len:810 episode reward: total was -98.910000. running mean: -73.298304\n",
      "ep 1: ep_len:500 episode reward: total was -38.430000. running mean: -72.949621\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 1: ep_len:238 episode reward: total was 0.000000. running mean: -72.220125\n",
      "ep 1: ep_len:322 episode reward: total was -24.860000. running mean: -71.746523\n",
      "ep 1: ep_len:1070 episode reward: total was -149.380000. running mean: -72.522858\n",
      "ep 1: ep_len:885 episode reward: total was -110.360000. running mean: -72.901230\n",
      "ep 1: ep_len:650 episode reward: total was -79.080000. running mean: -72.963017\n",
      "ep 1: ep_len:505 episode reward: total was -34.290000. running mean: -72.576287\n",
      "ep 1: ep_len:890 episode reward: total was -64.190000. running mean: -72.492424\n",
      "ep 1: ep_len:505 episode reward: total was -51.920000. running mean: -72.286700\n",
      "ep 1: ep_len:700 episode reward: total was -65.800000. running mean: -72.221833\n",
      "ep 1: ep_len:685 episode reward: total was -99.790000. running mean: -72.497515\n",
      "ep 1: ep_len:505 episode reward: total was -37.900000. running mean: -72.151539\n",
      "ep 1: ep_len:590 episode reward: total was -43.290000. running mean: -71.862924\n",
      "ep 1: ep_len:500 episode reward: total was -15.250000. running mean: -71.296795\n",
      "ep 1: ep_len:1190 episode reward: total was -210.260000. running mean: -72.686427\n",
      "ep 1: ep_len:500 episode reward: total was -25.760000. running mean: -72.217163\n",
      "ep 1: ep_len:680 episode reward: total was -75.940000. running mean: -72.254391\n",
      "ep 1: ep_len:520 episode reward: total was -42.410000. running mean: -71.955947\n",
      "ep 1: ep_len:680 episode reward: total was -43.770000. running mean: -71.674088\n",
      "ep 1: ep_len:510 episode reward: total was -42.120000. running mean: -71.378547\n",
      "ep 1: ep_len:153 episode reward: total was 4.500000. running mean: -70.619761\n",
      "ep 1: ep_len:500 episode reward: total was -38.710000. running mean: -70.300664\n",
      "ep 1: ep_len:500 episode reward: total was -36.570000. running mean: -69.963357\n",
      "ep 1: ep_len:635 episode reward: total was -53.810000. running mean: -69.801823\n",
      "ep 1: ep_len:500 episode reward: total was -46.030000. running mean: -69.564105\n",
      "ep 1: ep_len:585 episode reward: total was -84.730000. running mean: -69.715764\n",
      "ep 1: ep_len:500 episode reward: total was -58.840000. running mean: -69.607007\n",
      "ep 1: ep_len:1092 episode reward: total was -167.010000. running mean: -70.581036\n",
      "ep 1: ep_len:505 episode reward: total was -51.230000. running mean: -70.387526\n",
      "ep 1: ep_len:515 episode reward: total was -62.650000. running mean: -70.310151\n",
      "ep 1: ep_len:540 episode reward: total was -47.800000. running mean: -70.085049\n",
      "ep 1: ep_len:500 episode reward: total was -58.670000. running mean: -69.970899\n",
      "ep 1: ep_len:750 episode reward: total was -52.080000. running mean: -69.791990\n",
      "ep 1: ep_len:2185 episode reward: total was -291.010000. running mean: -72.004170\n",
      "ep 1: ep_len:500 episode reward: total was 7.000000. running mean: -71.214128\n",
      "ep 1: ep_len:590 episode reward: total was -51.130000. running mean: -71.013287\n",
      "ep 1: ep_len:540 episode reward: total was -44.530000. running mean: -70.748454\n",
      "ep 1: ep_len:925 episode reward: total was -41.870000. running mean: -70.459670\n",
      "ep 1: ep_len:540 episode reward: total was -69.410000. running mean: -70.449173\n",
      "ep 1: ep_len:575 episode reward: total was -52.290000. running mean: -70.267581\n",
      "ep 1: ep_len:530 episode reward: total was -85.330000. running mean: -70.418205\n",
      "ep 1: ep_len:2355 episode reward: total was -303.350000. running mean: -72.747523\n",
      "ep 1: ep_len:630 episode reward: total was -41.060000. running mean: -72.430648\n",
      "ep 1: ep_len:935 episode reward: total was -71.960000. running mean: -72.425942\n",
      "ep 1: ep_len:1495 episode reward: total was -134.910000. running mean: -73.050782\n",
      "ep 1: ep_len:510 episode reward: total was -43.960000. running mean: -72.759874\n",
      "ep 1: ep_len:905 episode reward: total was -93.190000. running mean: -72.964176\n",
      "ep 1: ep_len:690 episode reward: total was -80.450000. running mean: -73.039034\n",
      "ep 1: ep_len:500 episode reward: total was 3.500000. running mean: -72.273643\n",
      "ep 1: ep_len:1120 episode reward: total was -164.460000. running mean: -73.195507\n",
      "ep 1: ep_len:935 episode reward: total was -49.750000. running mean: -72.961052\n",
      "ep 1: ep_len:1580 episode reward: total was -124.150000. running mean: -73.472941\n",
      "ep 1: ep_len:500 episode reward: total was -22.330000. running mean: -72.961512\n",
      "ep 1: ep_len:9180 episode reward: total was -1645.040000. running mean: -88.682297\n",
      "ep 1: ep_len:805 episode reward: total was -62.560000. running mean: -88.421074\n",
      "ep 1: ep_len:1060 episode reward: total was -114.120000. running mean: -88.678063\n",
      "ep 1: ep_len:530 episode reward: total was -71.710000. running mean: -88.508383\n",
      "ep 1: ep_len:147 episode reward: total was 0.000000. running mean: -87.623299\n",
      "ep 1: ep_len:131 episode reward: total was -3.500000. running mean: -86.782066\n",
      "ep 1: ep_len:840 episode reward: total was -57.440000. running mean: -86.488645\n",
      "ep 1: ep_len:790 episode reward: total was -75.370000. running mean: -86.377459\n",
      "ep 1: ep_len:665 episode reward: total was -41.140000. running mean: -85.925084\n",
      "ep 1: ep_len:1365 episode reward: total was -250.310000. running mean: -87.568933\n",
      "ep 1: ep_len:505 episode reward: total was -21.360000. running mean: -86.906844\n",
      "ep 1: ep_len:1145 episode reward: total was -80.870000. running mean: -86.846475\n",
      "ep 1: ep_len:500 episode reward: total was -24.130000. running mean: -86.219311\n",
      "ep 1: ep_len:220 episode reward: total was 4.500000. running mean: -85.312118\n",
      "ep 1: ep_len:1165 episode reward: total was -96.180000. running mean: -85.420796\n",
      "ep 1: ep_len:540 episode reward: total was -65.900000. running mean: -85.225588\n",
      "ep 1: ep_len:258 episode reward: total was 9.000000. running mean: -84.283333\n",
      "ep 1: ep_len:585 episode reward: total was -41.860000. running mean: -83.859099\n",
      "ep 1: ep_len:500 episode reward: total was -54.380000. running mean: -83.564308\n",
      "ep 1: ep_len:840 episode reward: total was -104.450000. running mean: -83.773165\n",
      "ep 1: ep_len:500 episode reward: total was -81.870000. running mean: -83.754134\n",
      "ep 1: ep_len:780 episode reward: total was -62.750000. running mean: -83.544092\n",
      "ep 1: ep_len:975 episode reward: total was -63.090000. running mean: -83.339551\n",
      "ep 1: ep_len:505 episode reward: total was -38.170000. running mean: -82.887856\n",
      "ep 1: ep_len:1275 episode reward: total was -115.670000. running mean: -83.215677\n",
      "ep 1: ep_len:1485 episode reward: total was -223.810000. running mean: -84.621620\n",
      "ep 1: ep_len:510 episode reward: total was -24.390000. running mean: -84.019304\n",
      "ep 1: ep_len:535 episode reward: total was -48.660000. running mean: -83.665711\n",
      "ep 1: ep_len:570 episode reward: total was -96.880000. running mean: -83.797854\n",
      "ep 1: ep_len:630 episode reward: total was -58.360000. running mean: -83.543476\n",
      "ep 1: ep_len:1040 episode reward: total was -84.310000. running mean: -83.551141\n",
      "ep 1: ep_len:595 episode reward: total was -75.100000. running mean: -83.466629\n",
      "ep 1: ep_len:740 episode reward: total was -93.760000. running mean: -83.569563\n",
      "ep 1: ep_len:500 episode reward: total was -34.240000. running mean: -83.076267\n",
      "ep 1: ep_len:639 episode reward: total was -77.710000. running mean: -83.022605\n",
      "ep 1: ep_len:172 episode reward: total was 2.500000. running mean: -82.167379\n",
      "ep 1: ep_len:500 episode reward: total was -64.780000. running mean: -81.993505\n",
      "ep 1: ep_len:500 episode reward: total was -24.870000. running mean: -81.422270\n",
      "ep 1: ep_len:510 episode reward: total was -78.820000. running mean: -81.396247\n",
      "ep 1: ep_len:805 episode reward: total was -60.220000. running mean: -81.184485\n",
      "ep 1: ep_len:940 episode reward: total was -78.940000. running mean: -81.162040\n",
      "ep 1: ep_len:520 episode reward: total was -23.670000. running mean: -80.587119\n",
      "ep 1: ep_len:510 episode reward: total was -51.180000. running mean: -80.293048\n",
      "ep 1: ep_len:540 episode reward: total was -45.920000. running mean: -79.949318\n",
      "ep 1: ep_len:1160 episode reward: total was -78.610000. running mean: -79.935925\n",
      "ep 1: ep_len:328 episode reward: total was -11.000000. running mean: -79.246565\n",
      "ep 1: ep_len:499 episode reward: total was -24.390000. running mean: -78.698000\n",
      "ep 1: ep_len:665 episode reward: total was -69.100000. running mean: -78.602020\n",
      "ep 1: ep_len:940 episode reward: total was -112.160000. running mean: -78.937600\n",
      "ep 1: ep_len:545 episode reward: total was -43.400000. running mean: -78.582224\n",
      "ep 1: ep_len:1155 episode reward: total was -154.260000. running mean: -79.339001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 1: ep_len:910 episode reward: total was -101.220000. running mean: -79.557811\n",
      "ep 1: ep_len:525 episode reward: total was -55.530000. running mean: -79.317533\n",
      "ep 1: ep_len:850 episode reward: total was -108.930000. running mean: -79.613658\n",
      "ep 1: ep_len:995 episode reward: total was -86.980000. running mean: -79.687321\n",
      "ep 1: ep_len:505 episode reward: total was -32.710000. running mean: -79.217548\n",
      "ep 1: ep_len:505 episode reward: total was -29.320000. running mean: -78.718573\n",
      "ep 1: ep_len:705 episode reward: total was -47.120000. running mean: -78.402587\n",
      "ep 1: ep_len:500 episode reward: total was -48.290000. running mean: -78.101461\n",
      "ep 1: ep_len:580 episode reward: total was -17.210000. running mean: -77.492546\n",
      "ep 1: ep_len:795 episode reward: total was -71.550000. running mean: -77.433121\n",
      "ep 1: ep_len:505 episode reward: total was -57.870000. running mean: -77.237490\n",
      "ep 1: ep_len:620 episode reward: total was -67.820000. running mean: -77.143315\n",
      "ep 1: ep_len:930 episode reward: total was -96.140000. running mean: -77.333282\n",
      "ep 1: ep_len:1045 episode reward: total was -179.240000. running mean: -78.352349\n",
      "ep 1: ep_len:555 episode reward: total was -94.890000. running mean: -78.517725\n",
      "ep 1: ep_len:228 episode reward: total was 4.500000. running mean: -77.687548\n",
      "ep 1: ep_len:500 episode reward: total was -50.400000. running mean: -77.414673\n",
      "ep 1: ep_len:500 episode reward: total was -38.450000. running mean: -77.025026\n",
      "ep 1: ep_len:500 episode reward: total was -32.190000. running mean: -76.576676\n",
      "ep 1: ep_len:505 episode reward: total was -14.890000. running mean: -75.959809\n",
      "ep 1: ep_len:915 episode reward: total was -68.920000. running mean: -75.889411\n",
      "ep 1: ep_len:500 episode reward: total was -68.850000. running mean: -75.819017\n",
      "ep 1: ep_len:500 episode reward: total was -50.160000. running mean: -75.562426\n",
      "ep 1: ep_len:650 episode reward: total was -31.450000. running mean: -75.121302\n",
      "ep 1: ep_len:500 episode reward: total was -39.320000. running mean: -74.763289\n",
      "ep 1: ep_len:560 episode reward: total was -65.590000. running mean: -74.671556\n",
      "ep 1: ep_len:500 episode reward: total was -40.610000. running mean: -74.330941\n",
      "ep 1: ep_len:167 episode reward: total was -1.000000. running mean: -73.597631\n",
      "ep 1: ep_len:505 episode reward: total was -26.700000. running mean: -73.128655\n",
      "ep 1: ep_len:785 episode reward: total was -63.120000. running mean: -73.028568\n",
      "ep 1: ep_len:1320 episode reward: total was -216.730000. running mean: -74.465583\n",
      "ep 1: ep_len:555 episode reward: total was -50.450000. running mean: -74.225427\n",
      "ep 1: ep_len:845 episode reward: total was -115.520000. running mean: -74.638373\n",
      "ep 1: ep_len:1225 episode reward: total was -162.360000. running mean: -75.515589\n",
      "ep 1: ep_len:920 episode reward: total was -94.130000. running mean: -75.701733\n",
      "ep 1: ep_len:730 episode reward: total was -36.860000. running mean: -75.313316\n",
      "ep 1: ep_len:201 episode reward: total was 1.500000. running mean: -74.545183\n",
      "ep 1: ep_len:1005 episode reward: total was -156.090000. running mean: -75.360631\n",
      "ep 1: ep_len:500 episode reward: total was -33.730000. running mean: -74.944324\n",
      "ep 1: ep_len:1500 episode reward: total was -174.000000. running mean: -75.934881\n",
      "ep 1: ep_len:370 episode reward: total was 0.500000. running mean: -75.170532\n",
      "ep 1: ep_len:500 episode reward: total was -27.820000. running mean: -74.697027\n",
      "ep 1: ep_len:477 episode reward: total was -52.840000. running mean: -74.478457\n",
      "ep 1: ep_len:920 episode reward: total was -110.810000. running mean: -74.841772\n",
      "ep 1: ep_len:500 episode reward: total was -29.830000. running mean: -74.391655\n",
      "ep 1: ep_len:555 episode reward: total was -46.410000. running mean: -74.111838\n",
      "ep 1: ep_len:1000 episode reward: total was -122.770000. running mean: -74.598420\n",
      "ep 1: ep_len:500 episode reward: total was -54.260000. running mean: -74.395035\n",
      "ep 1: ep_len:500 episode reward: total was -44.190000. running mean: -74.092985\n",
      "ep 1: ep_len:2020 episode reward: total was -235.380000. running mean: -75.705855\n",
      "ep 1: ep_len:660 episode reward: total was -63.860000. running mean: -75.587397\n",
      "ep 1: ep_len:590 episode reward: total was -85.730000. running mean: -75.688823\n",
      "ep 1: ep_len:860 episode reward: total was -85.680000. running mean: -75.788734\n",
      "ep 1: ep_len:515 episode reward: total was -68.360000. running mean: -75.714447\n",
      "ep 1: ep_len:355 episode reward: total was -44.820000. running mean: -75.405503\n",
      "ep 1: ep_len:500 episode reward: total was -57.290000. running mean: -75.224348\n",
      "ep 1: ep_len:655 episode reward: total was -77.210000. running mean: -75.244204\n",
      "ep 1: ep_len:870 episode reward: total was -81.100000. running mean: -75.302762\n",
      "ep 1: ep_len:915 episode reward: total was -105.050000. running mean: -75.600234\n",
      "ep 1: ep_len:500 episode reward: total was -49.580000. running mean: -75.340032\n",
      "ep 1: ep_len:905 episode reward: total was -81.550000. running mean: -75.402132\n",
      "ep 1: ep_len:1270 episode reward: total was -107.160000. running mean: -75.719710\n",
      "ep 1: ep_len:500 episode reward: total was -13.260000. running mean: -75.095113\n",
      "ep 1: ep_len:323 episode reward: total was 6.500000. running mean: -74.279162\n",
      "ep 1: ep_len:595 episode reward: total was -60.440000. running mean: -74.140771\n",
      "ep 1: ep_len:580 episode reward: total was -46.360000. running mean: -73.862963\n",
      "ep 1: ep_len:500 episode reward: total was -66.720000. running mean: -73.791533\n",
      "ep 1: ep_len:500 episode reward: total was -47.060000. running mean: -73.524218\n",
      "ep 1: ep_len:500 episode reward: total was -14.340000. running mean: -72.932376\n",
      "ep 1: ep_len:635 episode reward: total was -73.910000. running mean: -72.942152\n",
      "ep 1: ep_len:815 episode reward: total was -59.180000. running mean: -72.804530\n",
      "ep 1: ep_len:900 episode reward: total was -87.110000. running mean: -72.947585\n",
      "ep 1: ep_len:1450 episode reward: total was -144.580000. running mean: -73.663909\n",
      "ep 1: ep_len:610 episode reward: total was -65.980000. running mean: -73.587070\n",
      "ep 1: ep_len:515 episode reward: total was -51.540000. running mean: -73.366600\n",
      "ep 1: ep_len:625 episode reward: total was -43.350000. running mean: -73.066434\n",
      "ep 1: ep_len:555 episode reward: total was -53.970000. running mean: -72.875469\n",
      "ep 1: ep_len:600 episode reward: total was -50.250000. running mean: -72.649215\n",
      "ep 1: ep_len:288 episode reward: total was 7.500000. running mean: -71.847722\n",
      "ep 1: ep_len:1435 episode reward: total was -159.790000. running mean: -72.727145\n",
      "ep 1: ep_len:1475 episode reward: total was -90.990000. running mean: -72.909774\n",
      "ep 1: ep_len:790 episode reward: total was -63.110000. running mean: -72.811776\n",
      "ep 1: ep_len:500 episode reward: total was -47.190000. running mean: -72.555558\n",
      "ep 1: ep_len:700 episode reward: total was -67.300000. running mean: -72.503003\n",
      "ep 1: ep_len:500 episode reward: total was -25.880000. running mean: -72.036773\n",
      "ep 1: ep_len:403 episode reward: total was -18.880000. running mean: -71.505205\n",
      "ep 1: ep_len:500 episode reward: total was -26.350000. running mean: -71.053653\n",
      "ep 1: ep_len:500 episode reward: total was -44.220000. running mean: -70.785316\n",
      "ep 1: ep_len:700 episode reward: total was -42.500000. running mean: -70.502463\n",
      "ep 1: ep_len:140 episode reward: total was 2.000000. running mean: -69.777438\n",
      "ep 1: ep_len:500 episode reward: total was -38.650000. running mean: -69.466164\n",
      "ep 1: ep_len:505 episode reward: total was -55.600000. running mean: -69.327502\n",
      "ep 1: ep_len:615 episode reward: total was -68.510000. running mean: -69.319327\n",
      "ep 1: ep_len:505 episode reward: total was -14.840000. running mean: -68.774534\n",
      "ep 1: ep_len:500 episode reward: total was -5.310000. running mean: -68.139889\n",
      "ep 1: ep_len:505 episode reward: total was -10.710000. running mean: -67.565590\n",
      "ep 1: ep_len:770 episode reward: total was -84.360000. running mean: -67.733534\n",
      "ep 1: ep_len:152 episode reward: total was 0.000000. running mean: -67.056199\n",
      "ep 1: ep_len:500 episode reward: total was -41.240000. running mean: -66.798037\n",
      "ep 1: ep_len:670 episode reward: total was -41.020000. running mean: -66.540256\n",
      "ep 1: ep_len:685 episode reward: total was -72.410000. running mean: -66.598954\n",
      "ep 1: ep_len:416 episode reward: total was -20.730000. running mean: -66.140264\n",
      "ep 1: ep_len:102 episode reward: total was -0.500000. running mean: -65.483862\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 1: ep_len:340 episode reward: total was -9.000000. running mean: -64.919023\n",
      "ep 1: ep_len:412 episode reward: total was -33.500000. running mean: -64.604833\n",
      "ep 1: ep_len:785 episode reward: total was -88.590000. running mean: -64.844684\n",
      "ep 1: ep_len:630 episode reward: total was -63.920000. running mean: -64.835438\n",
      "ep 1: ep_len:905 episode reward: total was -92.480000. running mean: -65.111883\n",
      "ep 1: ep_len:545 episode reward: total was -55.000000. running mean: -65.010764\n",
      "ep 1: ep_len:230 episode reward: total was 3.500000. running mean: -64.325657\n",
      "ep 1: ep_len:500 episode reward: total was -41.790000. running mean: -64.100300\n",
      "ep 1: ep_len:195 episode reward: total was -21.490000. running mean: -63.674197\n",
      "ep 1: ep_len:695 episode reward: total was -100.150000. running mean: -64.038955\n",
      "ep 1: ep_len:510 episode reward: total was -29.420000. running mean: -63.692766\n",
      "ep 1: ep_len:159 episode reward: total was -6.500000. running mean: -63.120838\n",
      "ep 1: ep_len:500 episode reward: total was -47.560000. running mean: -62.965230\n",
      "ep 1: ep_len:710 episode reward: total was -104.650000. running mean: -63.382077\n",
      "ep 1: ep_len:45 episode reward: total was 3.000000. running mean: -62.718257\n",
      "ep 1: ep_len:620 episode reward: total was -90.200000. running mean: -62.993074\n",
      "ep 1: ep_len:825 episode reward: total was -64.540000. running mean: -63.008543\n",
      "ep 1: ep_len:615 episode reward: total was -66.490000. running mean: -63.043358\n",
      "ep 1: ep_len:675 episode reward: total was -24.830000. running mean: -62.661224\n",
      "ep 1: ep_len:855 episode reward: total was -37.930000. running mean: -62.413912\n",
      "ep 1: ep_len:780 episode reward: total was -61.000000. running mean: -62.399773\n",
      "ep 1: ep_len:840 episode reward: total was -68.060000. running mean: -62.456375\n",
      "ep 1: ep_len:1150 episode reward: total was -173.820000. running mean: -63.570011\n",
      "ep 1: ep_len:560 episode reward: total was -46.190000. running mean: -63.396211\n",
      "ep 1: ep_len:500 episode reward: total was -29.870000. running mean: -63.060949\n",
      "ep 1: ep_len:510 episode reward: total was -38.860000. running mean: -62.818940\n",
      "ep 1: ep_len:500 episode reward: total was -27.380000. running mean: -62.464550\n",
      "ep 1: ep_len:500 episode reward: total was -40.630000. running mean: -62.246205\n",
      "ep 1: ep_len:208 episode reward: total was 7.000000. running mean: -61.553743\n",
      "ep 1: ep_len:785 episode reward: total was -74.300000. running mean: -61.681205\n",
      "ep 1: ep_len:1510 episode reward: total was -131.440000. running mean: -62.378793\n",
      "ep 1: ep_len:500 episode reward: total was -21.810000. running mean: -61.973105\n",
      "ep 1: ep_len:1755 episode reward: total was -329.840000. running mean: -64.651774\n",
      "ep 1: ep_len:800 episode reward: total was -48.630000. running mean: -64.491557\n",
      "ep 1: ep_len:510 episode reward: total was -36.640000. running mean: -64.213041\n",
      "ep 1: ep_len:760 episode reward: total was -92.270000. running mean: -64.493611\n",
      "ep 1: ep_len:505 episode reward: total was -79.320000. running mean: -64.641874\n",
      "ep 1: ep_len:525 episode reward: total was -61.700000. running mean: -64.612456\n",
      "ep 1: ep_len:500 episode reward: total was -33.750000. running mean: -64.303831\n",
      "ep 1: ep_len:500 episode reward: total was 5.000000. running mean: -63.610793\n",
      "ep 1: ep_len:510 episode reward: total was -31.860000. running mean: -63.293285\n",
      "ep 1: ep_len:500 episode reward: total was -17.100000. running mean: -62.831352\n",
      "ep 1: ep_len:510 episode reward: total was -12.790000. running mean: -62.330939\n",
      "ep 1: ep_len:510 episode reward: total was -15.810000. running mean: -61.865729\n",
      "ep 1: ep_len:645 episode reward: total was -76.530000. running mean: -62.012372\n",
      "ep 1: ep_len:545 episode reward: total was -30.720000. running mean: -61.699448\n",
      "ep 1: ep_len:505 episode reward: total was -9.340000. running mean: -61.175854\n",
      "ep 1: ep_len:500 episode reward: total was -40.120000. running mean: -60.965295\n",
      "ep 1: ep_len:1080 episode reward: total was -109.280000. running mean: -61.448442\n",
      "ep 1: ep_len:860 episode reward: total was -96.880000. running mean: -61.802758\n",
      "ep 1: ep_len:1155 episode reward: total was -68.130000. running mean: -61.866030\n",
      "ep 1: ep_len:480 episode reward: total was -64.330000. running mean: -61.890670\n",
      "ep 1: ep_len:745 episode reward: total was -100.230000. running mean: -62.274063\n",
      "ep 1: ep_len:525 episode reward: total was -42.720000. running mean: -62.078523\n",
      "ep 1: ep_len:620 episode reward: total was -57.390000. running mean: -62.031637\n",
      "ep 1: ep_len:289 episode reward: total was 9.000000. running mean: -61.321321\n",
      "ep 1: ep_len:500 episode reward: total was -53.170000. running mean: -61.239808\n",
      "ep 1: ep_len:500 episode reward: total was -24.260000. running mean: -60.870010\n",
      "ep 1: ep_len:500 episode reward: total was 4.500000. running mean: -60.216310\n",
      "ep 1: ep_len:680 episode reward: total was -41.600000. running mean: -60.030146\n",
      "ep 1: ep_len:735 episode reward: total was -95.540000. running mean: -60.385245\n",
      "ep 1: ep_len:172 episode reward: total was 5.000000. running mean: -59.731393\n",
      "ep 1: ep_len:815 episode reward: total was -88.090000. running mean: -60.014979\n",
      "ep 1: ep_len:515 episode reward: total was -55.640000. running mean: -59.971229\n",
      "ep 1: ep_len:800 episode reward: total was -88.310000. running mean: -60.254617\n",
      "ep 1: ep_len:500 episode reward: total was -37.460000. running mean: -60.026670\n",
      "ep 1: ep_len:500 episode reward: total was -35.710000. running mean: -59.783504\n",
      "ep 1: ep_len:198 episode reward: total was -2.500000. running mean: -59.210669\n",
      "ep 1: ep_len:500 episode reward: total was -38.560000. running mean: -59.004162\n",
      "ep 1: ep_len:500 episode reward: total was -56.120000. running mean: -58.975320\n",
      "ep 1: ep_len:1055 episode reward: total was -93.250000. running mean: -59.318067\n",
      "ep 1: ep_len:1005 episode reward: total was -84.640000. running mean: -59.571286\n",
      "ep 1: ep_len:1295 episode reward: total was -125.700000. running mean: -60.232574\n",
      "ep 1: ep_len:800 episode reward: total was -82.250000. running mean: -60.452748\n",
      "ep 1: ep_len:505 episode reward: total was -28.350000. running mean: -60.131720\n",
      "ep 1: ep_len:950 episode reward: total was -57.730000. running mean: -60.107703\n",
      "ep 1: ep_len:500 episode reward: total was -18.930000. running mean: -59.695926\n",
      "ep 1: ep_len:500 episode reward: total was -73.880000. running mean: -59.837767\n",
      "ep 1: ep_len:160 episode reward: total was 1.500000. running mean: -59.224389\n",
      "ep 1: ep_len:500 episode reward: total was -22.790000. running mean: -58.860045\n",
      "ep 1: ep_len:500 episode reward: total was 3.500000. running mean: -58.236445\n",
      "ep 1: ep_len:565 episode reward: total was -66.590000. running mean: -58.319980\n",
      "ep 1: ep_len:690 episode reward: total was -35.100000. running mean: -58.087781\n",
      "ep 1: ep_len:505 episode reward: total was -34.420000. running mean: -57.851103\n",
      "ep 1: ep_len:500 episode reward: total was -58.240000. running mean: -57.854992\n",
      "ep 1: ep_len:610 episode reward: total was -60.360000. running mean: -57.880042\n",
      "ep 1: ep_len:695 episode reward: total was -53.170000. running mean: -57.832941\n",
      "ep 1: ep_len:1305 episode reward: total was -180.740000. running mean: -59.062012\n",
      "ep 1: ep_len:315 episode reward: total was -1.500000. running mean: -58.486392\n",
      "ep 1: ep_len:500 episode reward: total was -26.820000. running mean: -58.169728\n",
      "ep 1: ep_len:630 episode reward: total was -47.240000. running mean: -58.060431\n",
      "ep 1: ep_len:765 episode reward: total was -51.040000. running mean: -57.990226\n",
      "ep 1: ep_len:505 episode reward: total was 2.500000. running mean: -57.385324\n",
      "ep 1: ep_len:500 episode reward: total was -35.380000. running mean: -57.165271\n",
      "ep 1: ep_len:1020 episode reward: total was -52.660000. running mean: -57.120218\n",
      "ep 1: ep_len:585 episode reward: total was -81.700000. running mean: -57.366016\n",
      "ep 1: ep_len:800 episode reward: total was -60.160000. running mean: -57.393956\n",
      "ep 1: ep_len:500 episode reward: total was -32.350000. running mean: -57.143516\n",
      "ep 1: ep_len:163 episode reward: total was -1.500000. running mean: -56.587081\n",
      "ep 1: ep_len:1265 episode reward: total was -99.610000. running mean: -57.017310\n",
      "ep 1: ep_len:750 episode reward: total was -62.150000. running mean: -57.068637\n",
      "ep 1: ep_len:500 episode reward: total was -61.180000. running mean: -57.109751\n",
      "ep 1: ep_len:710 episode reward: total was -46.100000. running mean: -56.999653\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 1: ep_len:825 episode reward: total was -65.250000. running mean: -57.082157\n",
      "ep 1: ep_len:670 episode reward: total was -60.290000. running mean: -57.114235\n",
      "ep 1: ep_len:575 episode reward: total was -62.670000. running mean: -57.169793\n",
      "ep 1: ep_len:500 episode reward: total was -55.390000. running mean: -57.151995\n",
      "ep 1: ep_len:950 episode reward: total was -97.620000. running mean: -57.556675\n",
      "ep 1: ep_len:500 episode reward: total was -32.730000. running mean: -57.308408\n",
      "ep 1: ep_len:500 episode reward: total was -34.890000. running mean: -57.084224\n",
      "ep 1: ep_len:535 episode reward: total was -76.780000. running mean: -57.281182\n",
      "ep 1: ep_len:635 episode reward: total was -71.310000. running mean: -57.421470\n",
      "ep 1: ep_len:535 episode reward: total was -87.340000. running mean: -57.720655\n",
      "ep 1: ep_len:210 episode reward: total was -16.430000. running mean: -57.307749\n",
      "ep 1: ep_len:500 episode reward: total was -38.530000. running mean: -57.119971\n",
      "ep 1: ep_len:1020 episode reward: total was -111.030000. running mean: -57.659072\n",
      "ep 1: ep_len:500 episode reward: total was -26.330000. running mean: -57.345781\n",
      "ep 1: ep_len:675 episode reward: total was -100.680000. running mean: -57.779123\n",
      "ep 1: ep_len:740 episode reward: total was -58.720000. running mean: -57.788532\n",
      "ep 1: ep_len:705 episode reward: total was -48.830000. running mean: -57.698947\n",
      "ep 1: ep_len:500 episode reward: total was -42.540000. running mean: -57.547357\n",
      "ep 1: ep_len:1050 episode reward: total was -132.800000. running mean: -58.299884\n",
      "ep 1: ep_len:500 episode reward: total was -20.310000. running mean: -57.919985\n",
      "ep 1: ep_len:905 episode reward: total was -66.750000. running mean: -58.008285\n",
      "ep 1: ep_len:178 episode reward: total was -5.500000. running mean: -57.483202\n",
      "ep 1: ep_len:610 episode reward: total was -74.580000. running mean: -57.654170\n",
      "ep 1: ep_len:850 episode reward: total was -83.140000. running mean: -57.909028\n",
      "ep 1: ep_len:1095 episode reward: total was -80.120000. running mean: -58.131138\n",
      "ep 1: ep_len:730 episode reward: total was -49.880000. running mean: -58.048627\n",
      "ep 1: ep_len:1480 episode reward: total was -230.730000. running mean: -59.775440\n",
      "ep 1: ep_len:770 episode reward: total was -73.220000. running mean: -59.909886\n",
      "ep 1: ep_len:500 episode reward: total was -64.330000. running mean: -59.954087\n",
      "ep 1: ep_len:620 episode reward: total was -73.880000. running mean: -60.093346\n",
      "ep 1: ep_len:645 episode reward: total was -44.700000. running mean: -59.939413\n",
      "ep 1: ep_len:500 episode reward: total was -18.500000. running mean: -59.525019\n",
      "ep 1: ep_len:500 episode reward: total was -30.440000. running mean: -59.234168\n",
      "ep 1: ep_len:750 episode reward: total was -59.150000. running mean: -59.233327\n",
      "ep 1: ep_len:147 episode reward: total was 1.000000. running mean: -58.630993\n",
      "ep 1: ep_len:835 episode reward: total was -87.210000. running mean: -58.916784\n",
      "ep 1: ep_len:500 episode reward: total was -29.270000. running mean: -58.620316\n",
      "ep 1: ep_len:500 episode reward: total was -40.580000. running mean: -58.439913\n",
      "ep 1: ep_len:206 episode reward: total was 6.000000. running mean: -57.795513\n",
      "ep 1: ep_len:505 episode reward: total was -22.270000. running mean: -57.440258\n",
      "ep 1: ep_len:705 episode reward: total was -61.750000. running mean: -57.483356\n",
      "ep 1: ep_len:500 episode reward: total was -22.350000. running mean: -57.132022\n",
      "ep 1: ep_len:525 episode reward: total was -28.280000. running mean: -56.843502\n",
      "ep 1: ep_len:1615 episode reward: total was -298.290000. running mean: -59.257967\n",
      "ep 1: ep_len:560 episode reward: total was -51.470000. running mean: -59.180087\n",
      "ep 1: ep_len:505 episode reward: total was -19.500000. running mean: -58.783286\n",
      "ep 1: ep_len:500 episode reward: total was -49.120000. running mean: -58.686654\n",
      "ep 1: ep_len:750 episode reward: total was -42.620000. running mean: -58.525987\n",
      "ep 1: ep_len:500 episode reward: total was -32.420000. running mean: -58.264927\n",
      "ep 1: ep_len:500 episode reward: total was -31.240000. running mean: -57.994678\n",
      "ep 1: ep_len:500 episode reward: total was -45.480000. running mean: -57.869531\n",
      "ep 1: ep_len:101 episode reward: total was 2.500000. running mean: -57.265836\n",
      "ep 1: ep_len:655 episode reward: total was -36.760000. running mean: -57.060777\n",
      "ep 1: ep_len:680 episode reward: total was -51.700000. running mean: -57.007170\n",
      "ep 1: ep_len:600 episode reward: total was -98.320000. running mean: -57.420298\n",
      "ep 1: ep_len:545 episode reward: total was -30.660000. running mean: -57.152695\n",
      "ep 1: ep_len:213 episode reward: total was -1.000000. running mean: -56.591168\n",
      "ep 1: ep_len:1015 episode reward: total was -75.680000. running mean: -56.782056\n",
      "ep 1: ep_len:500 episode reward: total was -37.690000. running mean: -56.591136\n",
      "ep 1: ep_len:330 episode reward: total was 1.010000. running mean: -56.015124\n",
      "ep 1: ep_len:610 episode reward: total was -53.860000. running mean: -55.993573\n",
      "ep 1: ep_len:500 episode reward: total was -22.260000. running mean: -55.656237\n",
      "ep 1: ep_len:500 episode reward: total was -40.980000. running mean: -55.509475\n",
      "ep 1: ep_len:695 episode reward: total was -38.340000. running mean: -55.337780\n",
      "ep 1: ep_len:972 episode reward: total was -125.920000. running mean: -56.043602\n",
      "ep 1: ep_len:500 episode reward: total was -51.170000. running mean: -55.994866\n",
      "ep 1: ep_len:830 episode reward: total was -40.150000. running mean: -55.836418\n",
      "ep 1: ep_len:1170 episode reward: total was -171.600000. running mean: -56.994054\n",
      "ep 1: ep_len:505 episode reward: total was -28.260000. running mean: -56.706713\n",
      "ep 1: ep_len:940 episode reward: total was -93.670000. running mean: -57.076346\n",
      "ep 1: ep_len:500 episode reward: total was -24.900000. running mean: -56.754582\n",
      "ep 1: ep_len:1190 episode reward: total was -157.740000. running mean: -57.764437\n",
      "ep 1: ep_len:635 episode reward: total was -54.330000. running mean: -57.730092\n",
      "ep 1: ep_len:510 episode reward: total was -38.320000. running mean: -57.535991\n",
      "ep 1: ep_len:555 episode reward: total was -57.520000. running mean: -57.535831\n",
      "ep 1: ep_len:800 episode reward: total was -73.190000. running mean: -57.692373\n",
      "ep 1: ep_len:1025 episode reward: total was -118.320000. running mean: -58.298649\n",
      "ep 1: ep_len:520 episode reward: total was -42.930000. running mean: -58.144963\n",
      "ep 1: ep_len:500 episode reward: total was -52.740000. running mean: -58.090913\n",
      "ep 1: ep_len:500 episode reward: total was -23.240000. running mean: -57.742404\n",
      "ep 1: ep_len:500 episode reward: total was -48.230000. running mean: -57.647280\n",
      "ep 1: ep_len:500 episode reward: total was -70.240000. running mean: -57.773207\n",
      "ep 1: ep_len:18 episode reward: total was -1.000000. running mean: -57.205475\n",
      "ep 1: ep_len:925 episode reward: total was -102.690000. running mean: -57.660320\n",
      "ep 1: ep_len:550 episode reward: total was -50.520000. running mean: -57.588917\n",
      "ep 1: ep_len:585 episode reward: total was -57.210000. running mean: -57.585128\n",
      "ep 1: ep_len:500 episode reward: total was -38.300000. running mean: -57.392277\n",
      "ep 1: ep_len:205 episode reward: total was 0.000000. running mean: -56.818354\n",
      "ep 1: ep_len:1295 episode reward: total was -205.520000. running mean: -58.305371\n",
      "ep 1: ep_len:910 episode reward: total was -151.320000. running mean: -59.235517\n",
      "ep 1: ep_len:855 episode reward: total was -105.180000. running mean: -59.694962\n",
      "ep 1: ep_len:1100 episode reward: total was -66.080000. running mean: -59.758812\n",
      "ep 1: ep_len:535 episode reward: total was -73.200000. running mean: -59.893224\n",
      "ep 1: ep_len:540 episode reward: total was -37.840000. running mean: -59.672692\n",
      "ep 1: ep_len:500 episode reward: total was -60.280000. running mean: -59.678765\n",
      "ep 1: ep_len:500 episode reward: total was -29.860000. running mean: -59.380577\n",
      "ep 1: ep_len:730 episode reward: total was -106.320000. running mean: -59.849971\n",
      "ep 1: ep_len:550 episode reward: total was -31.050000. running mean: -59.561972\n",
      "ep 1: ep_len:870 episode reward: total was -65.760000. running mean: -59.623952\n",
      "ep 1: ep_len:500 episode reward: total was -39.450000. running mean: -59.422212\n",
      "ep 1: ep_len:525 episode reward: total was -66.640000. running mean: -59.494390\n",
      "ep 1: ep_len:500 episode reward: total was -69.260000. running mean: -59.592046\n",
      "ep 1: ep_len:725 episode reward: total was -75.360000. running mean: -59.749726\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 1: ep_len:1070 episode reward: total was -131.520000. running mean: -60.467429\n",
      "ep 1: ep_len:535 episode reward: total was -43.420000. running mean: -60.296954\n",
      "ep 1: ep_len:500 episode reward: total was -68.740000. running mean: -60.381385\n",
      "ep 1: ep_len:665 episode reward: total was -59.320000. running mean: -60.370771\n",
      "ep 1: ep_len:770 episode reward: total was -64.210000. running mean: -60.409163\n",
      "ep 1: ep_len:500 episode reward: total was -28.320000. running mean: -60.088272\n",
      "ep 1: ep_len:725 episode reward: total was -64.250000. running mean: -60.129889\n",
      "ep 1: ep_len:500 episode reward: total was -19.850000. running mean: -59.727090\n",
      "ep 1: ep_len:710 episode reward: total was -72.360000. running mean: -59.853419\n",
      "ep 1: ep_len:715 episode reward: total was -47.820000. running mean: -59.733085\n",
      "ep 1: ep_len:855 episode reward: total was -81.740000. running mean: -59.953154\n",
      "ep 1: ep_len:239 episode reward: total was -4.000000. running mean: -59.393623\n",
      "ep 1: ep_len:500 episode reward: total was -62.790000. running mean: -59.427586\n",
      "ep 1: ep_len:500 episode reward: total was -43.000000. running mean: -59.263310\n",
      "ep 1: ep_len:500 episode reward: total was -26.860000. running mean: -58.939277\n",
      "ep 1: ep_len:500 episode reward: total was -13.790000. running mean: -58.487785\n",
      "ep 1: ep_len:454 episode reward: total was -14.290000. running mean: -58.045807\n",
      "ep 1: ep_len:555 episode reward: total was -79.740000. running mean: -58.262749\n",
      "ep 1: ep_len:149 episode reward: total was 2.500000. running mean: -57.655121\n",
      "ep 1: ep_len:635 episode reward: total was -64.730000. running mean: -57.725870\n",
      "ep 1: ep_len:620 episode reward: total was -51.540000. running mean: -57.664011\n",
      "ep 1: ep_len:800 episode reward: total was -64.540000. running mean: -57.732771\n",
      "ep 1: ep_len:505 episode reward: total was -61.780000. running mean: -57.773243\n",
      "ep 1: ep_len:2847 episode reward: total was -404.560000. running mean: -61.241111\n",
      "ep 1: ep_len:925 episode reward: total was -84.460000. running mean: -61.473300\n",
      "ep 1: ep_len:5615 episode reward: total was -920.310000. running mean: -70.061667\n",
      "ep 1: ep_len:900 episode reward: total was -78.820000. running mean: -70.149250\n",
      "ep 1: ep_len:500 episode reward: total was -77.830000. running mean: -70.226058\n",
      "ep 1: ep_len:500 episode reward: total was -57.960000. running mean: -70.103397\n",
      "ep 1: ep_len:520 episode reward: total was -61.920000. running mean: -70.021563\n",
      "ep 1: ep_len:462 episode reward: total was -28.980000. running mean: -69.611148\n",
      "ep 1: ep_len:635 episode reward: total was -60.400000. running mean: -69.519036\n",
      "epsilon:0.369326 episode_count: 1573. steps_count: 1208840.000000\n",
      "ep 2: ep_len:505 episode reward: total was -27.920000. running mean: -69.103046\n",
      "ep 2: ep_len:835 episode reward: total was -69.080000. running mean: -69.102815\n",
      "ep 2: ep_len:510 episode reward: total was -50.680000. running mean: -68.918587\n",
      "ep 2: ep_len:665 episode reward: total was -82.210000. running mean: -69.051501\n",
      "ep 2: ep_len:970 episode reward: total was -54.940000. running mean: -68.910386\n",
      "ep 2: ep_len:975 episode reward: total was -117.770000. running mean: -69.398982\n",
      "ep 2: ep_len:965 episode reward: total was -82.980000. running mean: -69.534793\n",
      "ep 2: ep_len:505 episode reward: total was -27.420000. running mean: -69.113645\n",
      "ep 2: ep_len:795 episode reward: total was -98.450000. running mean: -69.407008\n",
      "ep 2: ep_len:1040 episode reward: total was -67.690000. running mean: -69.389838\n",
      "ep 2: ep_len:690 episode reward: total was -72.370000. running mean: -69.419640\n",
      "ep 2: ep_len:505 episode reward: total was -38.750000. running mean: -69.112943\n",
      "ep 2: ep_len:505 episode reward: total was -28.940000. running mean: -68.711214\n",
      "ep 2: ep_len:166 episode reward: total was 4.500000. running mean: -67.979102\n",
      "ep 2: ep_len:860 episode reward: total was -82.650000. running mean: -68.125811\n",
      "ep 2: ep_len:845 episode reward: total was -83.690000. running mean: -68.281453\n",
      "ep 2: ep_len:417 episode reward: total was -1.000000. running mean: -67.608638\n",
      "ep 2: ep_len:505 episode reward: total was -50.810000. running mean: -67.440652\n",
      "ep 2: ep_len:720 episode reward: total was -42.290000. running mean: -67.189145\n",
      "ep 2: ep_len:231 episode reward: total was 5.000000. running mean: -66.467254\n",
      "ep 2: ep_len:700 episode reward: total was -53.820000. running mean: -66.340781\n",
      "ep 2: ep_len:500 episode reward: total was -32.670000. running mean: -66.004073\n",
      "ep 2: ep_len:1740 episode reward: total was -153.960000. running mean: -66.883633\n",
      "ep 2: ep_len:980 episode reward: total was -105.640000. running mean: -67.271196\n",
      "ep 2: ep_len:500 episode reward: total was -44.180000. running mean: -67.040284\n",
      "ep 2: ep_len:500 episode reward: total was -45.390000. running mean: -66.823782\n",
      "ep 2: ep_len:201 episode reward: total was 3.500000. running mean: -66.120544\n",
      "ep 2: ep_len:505 episode reward: total was -67.920000. running mean: -66.138538\n",
      "ep 2: ep_len:500 episode reward: total was -36.140000. running mean: -65.838553\n",
      "ep 2: ep_len:500 episode reward: total was -24.650000. running mean: -65.426667\n",
      "ep 2: ep_len:890 episode reward: total was -42.150000. running mean: -65.193901\n",
      "ep 2: ep_len:500 episode reward: total was -24.320000. running mean: -64.785162\n",
      "ep 2: ep_len:500 episode reward: total was -21.270000. running mean: -64.350010\n",
      "ep 2: ep_len:164 episode reward: total was 4.500000. running mean: -63.661510\n",
      "ep 2: ep_len:500 episode reward: total was -29.320000. running mean: -63.318095\n",
      "ep 2: ep_len:765 episode reward: total was -49.200000. running mean: -63.176914\n",
      "ep 2: ep_len:515 episode reward: total was -84.900000. running mean: -63.394145\n",
      "ep 2: ep_len:505 episode reward: total was -16.830000. running mean: -62.928503\n",
      "ep 2: ep_len:880 episode reward: total was -81.140000. running mean: -63.110618\n",
      "ep 2: ep_len:655 episode reward: total was -73.540000. running mean: -63.214912\n",
      "ep 2: ep_len:500 episode reward: total was -30.590000. running mean: -62.888663\n",
      "ep 2: ep_len:520 episode reward: total was -48.330000. running mean: -62.743076\n",
      "ep 2: ep_len:500 episode reward: total was -27.350000. running mean: -62.389146\n",
      "ep 2: ep_len:205 episode reward: total was -12.490000. running mean: -61.890154\n",
      "ep 2: ep_len:500 episode reward: total was -27.850000. running mean: -61.549753\n",
      "ep 2: ep_len:960 episode reward: total was -63.820000. running mean: -61.572455\n",
      "ep 2: ep_len:575 episode reward: total was -82.210000. running mean: -61.778831\n",
      "ep 2: ep_len:935 episode reward: total was -73.330000. running mean: -61.894342\n",
      "ep 2: ep_len:705 episode reward: total was -108.780000. running mean: -62.363199\n",
      "ep 2: ep_len:980 episode reward: total was -68.730000. running mean: -62.426867\n",
      "ep 2: ep_len:1200 episode reward: total was -87.960000. running mean: -62.682198\n",
      "ep 2: ep_len:267 episode reward: total was 5.500000. running mean: -62.000376\n",
      "ep 2: ep_len:500 episode reward: total was -37.320000. running mean: -61.753572\n",
      "ep 2: ep_len:174 episode reward: total was -3.000000. running mean: -61.166037\n",
      "ep 2: ep_len:505 episode reward: total was -59.120000. running mean: -61.145576\n",
      "ep 2: ep_len:700 episode reward: total was -73.360000. running mean: -61.267721\n",
      "ep 2: ep_len:650 episode reward: total was -39.370000. running mean: -61.048743\n",
      "ep 2: ep_len:685 episode reward: total was -55.240000. running mean: -60.990656\n",
      "ep 2: ep_len:86 episode reward: total was -1.000000. running mean: -60.390749\n",
      "ep 2: ep_len:500 episode reward: total was -43.080000. running mean: -60.217642\n",
      "ep 2: ep_len:720 episode reward: total was -61.230000. running mean: -60.227765\n",
      "ep 2: ep_len:500 episode reward: total was -35.240000. running mean: -59.977888\n",
      "ep 2: ep_len:800 episode reward: total was -74.690000. running mean: -60.125009\n",
      "ep 2: ep_len:500 episode reward: total was -6.350000. running mean: -59.587259\n",
      "ep 2: ep_len:570 episode reward: total was -46.350000. running mean: -59.454886\n",
      "ep 2: ep_len:181 episode reward: total was 6.500000. running mean: -58.795337\n",
      "ep 2: ep_len:810 episode reward: total was -74.950000. running mean: -58.956884\n",
      "ep 2: ep_len:695 episode reward: total was -64.950000. running mean: -59.016815\n",
      "ep 2: ep_len:1145 episode reward: total was -150.240000. running mean: -59.929047\n",
      "ep 2: ep_len:680 episode reward: total was -65.470000. running mean: -59.984457\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 2: ep_len:505 episode reward: total was -53.580000. running mean: -59.920412\n",
      "ep 2: ep_len:585 episode reward: total was -52.410000. running mean: -59.845308\n",
      "ep 2: ep_len:750 episode reward: total was -71.330000. running mean: -59.960155\n",
      "ep 2: ep_len:500 episode reward: total was -8.770000. running mean: -59.448253\n",
      "ep 2: ep_len:860 episode reward: total was -73.660000. running mean: -59.590371\n",
      "ep 2: ep_len:725 episode reward: total was -54.720000. running mean: -59.541667\n",
      "ep 2: ep_len:530 episode reward: total was -49.490000. running mean: -59.441150\n",
      "ep 2: ep_len:505 episode reward: total was -13.810000. running mean: -58.984839\n",
      "ep 2: ep_len:500 episode reward: total was -81.870000. running mean: -59.213690\n",
      "ep 2: ep_len:500 episode reward: total was -29.680000. running mean: -58.918354\n",
      "ep 2: ep_len:1325 episode reward: total was -125.150000. running mean: -59.580670\n",
      "ep 2: ep_len:950 episode reward: total was -136.640000. running mean: -60.351263\n",
      "ep 2: ep_len:560 episode reward: total was -29.240000. running mean: -60.040151\n",
      "ep 2: ep_len:815 episode reward: total was -60.120000. running mean: -60.040949\n",
      "ep 2: ep_len:625 episode reward: total was -48.960000. running mean: -59.930140\n",
      "ep 2: ep_len:212 episode reward: total was -1.000000. running mean: -59.340838\n",
      "ep 2: ep_len:500 episode reward: total was -25.270000. running mean: -59.000130\n",
      "ep 2: ep_len:570 episode reward: total was -47.390000. running mean: -58.884029\n",
      "ep 2: ep_len:630 episode reward: total was -54.340000. running mean: -58.838588\n",
      "ep 2: ep_len:865 episode reward: total was -123.220000. running mean: -59.482402\n",
      "ep 2: ep_len:705 episode reward: total was -45.590000. running mean: -59.343478\n",
      "ep 2: ep_len:505 episode reward: total was -74.420000. running mean: -59.494244\n",
      "ep 2: ep_len:500 episode reward: total was -22.330000. running mean: -59.122601\n",
      "ep 2: ep_len:505 episode reward: total was -17.320000. running mean: -58.704575\n",
      "ep 2: ep_len:560 episode reward: total was -60.510000. running mean: -58.722629\n",
      "ep 2: ep_len:18980 episode reward: total was -3612.720000. running mean: -94.262603\n",
      "ep 2: ep_len:980 episode reward: total was -52.180000. running mean: -93.841777\n",
      "ep 2: ep_len:267 episode reward: total was 15.000000. running mean: -92.753359\n",
      "ep 2: ep_len:500 episode reward: total was -13.910000. running mean: -91.964926\n",
      "ep 2: ep_len:500 episode reward: total was -14.940000. running mean: -91.194676\n",
      "ep 2: ep_len:930 episode reward: total was -111.810000. running mean: -91.400830\n",
      "ep 2: ep_len:690 episode reward: total was -49.140000. running mean: -90.978221\n",
      "ep 2: ep_len:501 episode reward: total was -12.460000. running mean: -90.193039\n",
      "ep 2: ep_len:825 episode reward: total was -147.360000. running mean: -90.764709\n",
      "ep 2: ep_len:500 episode reward: total was -35.530000. running mean: -90.212362\n",
      "ep 2: ep_len:650 episode reward: total was -86.920000. running mean: -90.179438\n",
      "ep 2: ep_len:326 episode reward: total was -2.000000. running mean: -89.297644\n",
      "ep 2: ep_len:895 episode reward: total was -115.340000. running mean: -89.558067\n",
      "ep 2: ep_len:615 episode reward: total was -91.740000. running mean: -89.579887\n",
      "ep 2: ep_len:327 episode reward: total was 1.500000. running mean: -88.669088\n",
      "ep 2: ep_len:500 episode reward: total was -27.340000. running mean: -88.055797\n",
      "ep 2: ep_len:182 episode reward: total was 1.500000. running mean: -87.160239\n",
      "ep 2: ep_len:650 episode reward: total was -42.180000. running mean: -86.710436\n",
      "ep 2: ep_len:675 episode reward: total was -93.620000. running mean: -86.779532\n",
      "ep 2: ep_len:765 episode reward: total was -89.910000. running mean: -86.810837\n",
      "ep 2: ep_len:520 episode reward: total was -22.930000. running mean: -86.172028\n",
      "ep 2: ep_len:795 episode reward: total was -60.270000. running mean: -85.913008\n",
      "ep 2: ep_len:815 episode reward: total was -128.680000. running mean: -86.340678\n",
      "ep 2: ep_len:500 episode reward: total was 9.500000. running mean: -85.382271\n",
      "ep 2: ep_len:500 episode reward: total was -67.350000. running mean: -85.201949\n",
      "ep 2: ep_len:750 episode reward: total was -75.310000. running mean: -85.103029\n",
      "ep 2: ep_len:565 episode reward: total was -19.360000. running mean: -84.445599\n",
      "ep 2: ep_len:625 episode reward: total was -73.020000. running mean: -84.331343\n",
      "ep 2: ep_len:1530 episode reward: total was -191.400000. running mean: -85.402029\n",
      "ep 2: ep_len:560 episode reward: total was -66.320000. running mean: -85.211209\n",
      "ep 2: ep_len:740 episode reward: total was -70.250000. running mean: -85.061597\n",
      "ep 2: ep_len:1530 episode reward: total was -288.360000. running mean: -87.094581\n",
      "ep 2: ep_len:750 episode reward: total was -69.250000. running mean: -86.916135\n",
      "ep 2: ep_len:760 episode reward: total was -73.270000. running mean: -86.779674\n",
      "ep 2: ep_len:690 episode reward: total was -78.120000. running mean: -86.693077\n",
      "ep 2: ep_len:875 episode reward: total was -73.040000. running mean: -86.556546\n",
      "ep 2: ep_len:530 episode reward: total was -54.840000. running mean: -86.239381\n",
      "ep 2: ep_len:500 episode reward: total was -34.760000. running mean: -85.724587\n",
      "ep 2: ep_len:500 episode reward: total was -13.290000. running mean: -85.000241\n",
      "ep 2: ep_len:2215 episode reward: total was -337.490000. running mean: -87.525139\n",
      "ep 2: ep_len:500 episode reward: total was -55.790000. running mean: -87.207787\n",
      "ep 2: ep_len:500 episode reward: total was -57.840000. running mean: -86.914110\n",
      "ep 2: ep_len:500 episode reward: total was -78.960000. running mean: -86.834568\n",
      "ep 2: ep_len:500 episode reward: total was -20.800000. running mean: -86.174223\n",
      "ep 2: ep_len:500 episode reward: total was -1.500000. running mean: -85.327481\n",
      "ep 2: ep_len:500 episode reward: total was -27.440000. running mean: -84.748606\n",
      "ep 2: ep_len:505 episode reward: total was -21.310000. running mean: -84.114220\n",
      "ep 2: ep_len:1955 episode reward: total was -121.660000. running mean: -84.489677\n",
      "ep 2: ep_len:500 episode reward: total was -25.420000. running mean: -83.898981\n",
      "ep 2: ep_len:630 episode reward: total was -41.480000. running mean: -83.474791\n",
      "ep 2: ep_len:150 episode reward: total was 2.510000. running mean: -82.614943\n",
      "ep 2: ep_len:610 episode reward: total was -100.810000. running mean: -82.796894\n",
      "ep 2: ep_len:520 episode reward: total was -41.840000. running mean: -82.387325\n",
      "ep 2: ep_len:670 episode reward: total was -62.340000. running mean: -82.186851\n",
      "ep 2: ep_len:500 episode reward: total was -38.440000. running mean: -81.749383\n",
      "ep 2: ep_len:198 episode reward: total was 0.000000. running mean: -80.931889\n",
      "ep 2: ep_len:515 episode reward: total was -53.040000. running mean: -80.652970\n",
      "ep 2: ep_len:765 episode reward: total was -103.800000. running mean: -80.884440\n",
      "ep 2: ep_len:565 episode reward: total was -66.650000. running mean: -80.742096\n",
      "ep 2: ep_len:500 episode reward: total was -38.760000. running mean: -80.322275\n",
      "ep 2: ep_len:505 episode reward: total was -30.280000. running mean: -79.821852\n",
      "ep 2: ep_len:845 episode reward: total was -85.150000. running mean: -79.875134\n",
      "ep 2: ep_len:890 episode reward: total was -112.390000. running mean: -80.200282\n",
      "ep 2: ep_len:505 episode reward: total was -87.400000. running mean: -80.272280\n",
      "ep 2: ep_len:765 episode reward: total was -52.540000. running mean: -79.994957\n",
      "ep 2: ep_len:800 episode reward: total was -49.650000. running mean: -79.691507\n",
      "ep 2: ep_len:500 episode reward: total was -64.880000. running mean: -79.543392\n",
      "ep 2: ep_len:960 episode reward: total was -67.980000. running mean: -79.427758\n",
      "ep 2: ep_len:500 episode reward: total was -62.950000. running mean: -79.262981\n",
      "ep 2: ep_len:615 episode reward: total was -67.000000. running mean: -79.140351\n",
      "ep 2: ep_len:860 episode reward: total was -52.670000. running mean: -78.875647\n",
      "ep 2: ep_len:590 episode reward: total was -53.900000. running mean: -78.625891\n",
      "ep 2: ep_len:475 episode reward: total was -12.360000. running mean: -77.963232\n",
      "ep 2: ep_len:505 episode reward: total was -55.800000. running mean: -77.741600\n",
      "ep 2: ep_len:885 episode reward: total was -45.610000. running mean: -77.420284\n",
      "ep 2: ep_len:505 episode reward: total was -37.450000. running mean: -77.020581\n",
      "ep 2: ep_len:960 episode reward: total was -96.590000. running mean: -77.216275\n",
      "ep 2: ep_len:560 episode reward: total was -73.670000. running mean: -77.180812\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 2: ep_len:500 episode reward: total was -19.880000. running mean: -76.607804\n",
      "ep 2: ep_len:890 episode reward: total was -86.500000. running mean: -76.706726\n",
      "ep 2: ep_len:510 episode reward: total was -45.020000. running mean: -76.389859\n",
      "ep 2: ep_len:500 episode reward: total was -10.830000. running mean: -75.734260\n",
      "ep 2: ep_len:640 episode reward: total was -56.690000. running mean: -75.543818\n",
      "ep 2: ep_len:195 episode reward: total was 1.500000. running mean: -74.773379\n",
      "ep 2: ep_len:750 episode reward: total was -55.110000. running mean: -74.576746\n",
      "ep 2: ep_len:510 episode reward: total was -63.150000. running mean: -74.462478\n",
      "ep 2: ep_len:635 episode reward: total was -82.610000. running mean: -74.543953\n",
      "ep 2: ep_len:500 episode reward: total was -18.100000. running mean: -73.979514\n",
      "ep 2: ep_len:500 episode reward: total was -13.840000. running mean: -73.378119\n",
      "ep 2: ep_len:710 episode reward: total was -56.160000. running mean: -73.205938\n",
      "ep 2: ep_len:302 episode reward: total was 6.000000. running mean: -72.413878\n",
      "ep 2: ep_len:500 episode reward: total was -19.360000. running mean: -71.883339\n",
      "ep 2: ep_len:48 episode reward: total was -3.000000. running mean: -71.194506\n",
      "ep 2: ep_len:500 episode reward: total was 0.000000. running mean: -70.482561\n",
      "ep 2: ep_len:500 episode reward: total was -21.310000. running mean: -69.990835\n",
      "ep 2: ep_len:575 episode reward: total was -46.460000. running mean: -69.755527\n",
      "ep 2: ep_len:500 episode reward: total was -51.070000. running mean: -69.568672\n",
      "ep 2: ep_len:575 episode reward: total was -15.650000. running mean: -69.029485\n",
      "ep 2: ep_len:760 episode reward: total was -51.540000. running mean: -68.854590\n",
      "ep 2: ep_len:810 episode reward: total was -76.200000. running mean: -68.928044\n",
      "ep 2: ep_len:1165 episode reward: total was -182.180000. running mean: -70.060564\n",
      "ep 2: ep_len:500 episode reward: total was -30.740000. running mean: -69.667358\n",
      "ep 2: ep_len:1973 episode reward: total was -328.870000. running mean: -72.259385\n",
      "ep 2: ep_len:500 episode reward: total was -14.280000. running mean: -71.679591\n",
      "ep 2: ep_len:620 episode reward: total was -42.240000. running mean: -71.385195\n",
      "ep 2: ep_len:775 episode reward: total was -74.250000. running mean: -71.413843\n",
      "ep 2: ep_len:970 episode reward: total was -39.480000. running mean: -71.094504\n",
      "ep 2: ep_len:905 episode reward: total was -109.240000. running mean: -71.475959\n",
      "ep 2: ep_len:198 episode reward: total was -4.500000. running mean: -70.806200\n",
      "ep 2: ep_len:650 episode reward: total was -50.260000. running mean: -70.600738\n",
      "ep 2: ep_len:570 episode reward: total was -53.940000. running mean: -70.434130\n",
      "ep 2: ep_len:500 episode reward: total was -44.160000. running mean: -70.171389\n",
      "ep 2: ep_len:505 episode reward: total was -29.180000. running mean: -69.761475\n",
      "ep 2: ep_len:520 episode reward: total was -45.720000. running mean: -69.521061\n",
      "ep 2: ep_len:565 episode reward: total was -84.250000. running mean: -69.668350\n",
      "ep 2: ep_len:500 episode reward: total was -29.990000. running mean: -69.271566\n",
      "ep 2: ep_len:1010 episode reward: total was -87.580000. running mean: -69.454651\n",
      "ep 2: ep_len:505 episode reward: total was -14.720000. running mean: -68.907304\n",
      "ep 2: ep_len:905 episode reward: total was -81.550000. running mean: -69.033731\n",
      "ep 2: ep_len:196 episode reward: total was 6.000000. running mean: -68.283394\n",
      "ep 2: ep_len:515 episode reward: total was -40.290000. running mean: -68.003460\n",
      "ep 2: ep_len:825 episode reward: total was -82.540000. running mean: -68.148825\n",
      "ep 2: ep_len:500 episode reward: total was -14.700000. running mean: -67.614337\n",
      "ep 2: ep_len:500 episode reward: total was -58.210000. running mean: -67.520294\n",
      "ep 2: ep_len:500 episode reward: total was -20.820000. running mean: -67.053291\n",
      "ep 2: ep_len:573 episode reward: total was -74.640000. running mean: -67.129158\n",
      "ep 2: ep_len:580 episode reward: total was -57.440000. running mean: -67.032266\n",
      "ep 2: ep_len:188 episode reward: total was 3.500000. running mean: -66.326944\n",
      "ep 2: ep_len:860 episode reward: total was -58.440000. running mean: -66.248074\n",
      "ep 2: ep_len:845 episode reward: total was -88.220000. running mean: -66.467793\n",
      "ep 2: ep_len:505 episode reward: total was -27.520000. running mean: -66.078316\n",
      "ep 2: ep_len:590 episode reward: total was -43.310000. running mean: -65.850632\n",
      "ep 2: ep_len:840 episode reward: total was -64.320000. running mean: -65.835326\n",
      "ep 2: ep_len:389 episode reward: total was -10.830000. running mean: -65.285273\n",
      "ep 2: ep_len:665 episode reward: total was -95.160000. running mean: -65.584020\n",
      "ep 2: ep_len:630 episode reward: total was -73.010000. running mean: -65.658280\n",
      "ep 2: ep_len:740 episode reward: total was -59.980000. running mean: -65.601497\n",
      "ep 2: ep_len:515 episode reward: total was -31.480000. running mean: -65.260282\n",
      "ep 2: ep_len:755 episode reward: total was -68.720000. running mean: -65.294879\n",
      "ep 2: ep_len:520 episode reward: total was -36.760000. running mean: -65.009530\n",
      "ep 2: ep_len:980 episode reward: total was -140.990000. running mean: -65.769335\n",
      "ep 2: ep_len:505 episode reward: total was -23.830000. running mean: -65.349942\n",
      "ep 2: ep_len:795 episode reward: total was -89.620000. running mean: -65.592642\n",
      "ep 2: ep_len:695 episode reward: total was -85.520000. running mean: -65.791916\n",
      "ep 2: ep_len:770 episode reward: total was -55.560000. running mean: -65.689597\n",
      "ep 2: ep_len:1315 episode reward: total was -122.140000. running mean: -66.254101\n",
      "ep 2: ep_len:500 episode reward: total was -5.310000. running mean: -65.644660\n",
      "ep 2: ep_len:500 episode reward: total was 7.000000. running mean: -64.918213\n",
      "ep 2: ep_len:700 episode reward: total was -46.610000. running mean: -64.735131\n",
      "ep 2: ep_len:515 episode reward: total was -52.340000. running mean: -64.611180\n",
      "ep 2: ep_len:500 episode reward: total was -32.280000. running mean: -64.287868\n",
      "ep 2: ep_len:715 episode reward: total was -49.120000. running mean: -64.136189\n",
      "ep 2: ep_len:550 episode reward: total was -44.890000. running mean: -63.943727\n",
      "ep 2: ep_len:150 episode reward: total was 1.500000. running mean: -63.289290\n",
      "ep 2: ep_len:855 episode reward: total was -72.040000. running mean: -63.376797\n",
      "ep 2: ep_len:500 episode reward: total was -26.710000. running mean: -63.010129\n",
      "ep 2: ep_len:545 episode reward: total was -44.100000. running mean: -62.821028\n",
      "ep 2: ep_len:505 episode reward: total was -47.800000. running mean: -62.670818\n",
      "ep 2: ep_len:515 episode reward: total was -45.480000. running mean: -62.498910\n",
      "ep 2: ep_len:500 episode reward: total was -21.810000. running mean: -62.092020\n",
      "ep 2: ep_len:500 episode reward: total was -34.760000. running mean: -61.818700\n",
      "ep 2: ep_len:510 episode reward: total was -56.650000. running mean: -61.767013\n",
      "ep 2: ep_len:1110 episode reward: total was -66.980000. running mean: -61.819143\n",
      "ep 2: ep_len:505 episode reward: total was -36.360000. running mean: -61.564552\n",
      "ep 2: ep_len:560 episode reward: total was -48.130000. running mean: -61.430206\n",
      "ep 2: ep_len:720 episode reward: total was -83.420000. running mean: -61.650104\n",
      "ep 2: ep_len:960 episode reward: total was -52.820000. running mean: -61.561803\n",
      "ep 2: ep_len:535 episode reward: total was -71.700000. running mean: -61.663185\n",
      "ep 2: ep_len:153 episode reward: total was -4.500000. running mean: -61.091553\n",
      "ep 2: ep_len:500 episode reward: total was -30.250000. running mean: -60.783138\n",
      "ep 2: ep_len:780 episode reward: total was -55.540000. running mean: -60.730706\n",
      "ep 2: ep_len:1005 episode reward: total was -69.700000. running mean: -60.820399\n",
      "ep 2: ep_len:590 episode reward: total was -51.360000. running mean: -60.725795\n",
      "ep 2: ep_len:720 episode reward: total was -36.330000. running mean: -60.481837\n",
      "ep 2: ep_len:510 episode reward: total was -15.780000. running mean: -60.034819\n",
      "ep 2: ep_len:241 episode reward: total was -4.500000. running mean: -59.479471\n",
      "ep 2: ep_len:500 episode reward: total was -13.240000. running mean: -59.017076\n",
      "ep 2: ep_len:805 episode reward: total was -59.360000. running mean: -59.020505\n",
      "ep 2: ep_len:500 episode reward: total was 11.000000. running mean: -58.320300\n",
      "ep 2: ep_len:845 episode reward: total was -52.720000. running mean: -58.264297\n",
      "ep 2: ep_len:179 episode reward: total was 2.500000. running mean: -57.656654\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 2: ep_len:955 episode reward: total was -147.460000. running mean: -58.554688\n",
      "ep 2: ep_len:510 episode reward: total was -26.290000. running mean: -58.232041\n",
      "ep 2: ep_len:540 episode reward: total was -35.820000. running mean: -58.007920\n",
      "ep 2: ep_len:880 episode reward: total was -73.020000. running mean: -58.158041\n",
      "ep 2: ep_len:725 episode reward: total was -69.790000. running mean: -58.274361\n",
      "ep 2: ep_len:1690 episode reward: total was -170.860000. running mean: -59.400217\n",
      "ep 2: ep_len:815 episode reward: total was -56.420000. running mean: -59.370415\n",
      "ep 2: ep_len:505 episode reward: total was -15.720000. running mean: -58.933911\n",
      "ep 2: ep_len:570 episode reward: total was -60.000000. running mean: -58.944572\n",
      "ep 2: ep_len:278 episode reward: total was -18.500000. running mean: -58.540126\n",
      "ep 2: ep_len:214 episode reward: total was -4.000000. running mean: -57.994725\n",
      "ep 2: ep_len:154 episode reward: total was 1.500000. running mean: -57.399777\n",
      "ep 2: ep_len:590 episode reward: total was -80.650000. running mean: -57.632280\n",
      "ep 2: ep_len:1090 episode reward: total was -150.380000. running mean: -58.559757\n",
      "ep 2: ep_len:520 episode reward: total was -32.830000. running mean: -58.302459\n",
      "ep 2: ep_len:500 episode reward: total was -48.920000. running mean: -58.208635\n",
      "ep 2: ep_len:750 episode reward: total was -69.740000. running mean: -58.323948\n",
      "ep 2: ep_len:1065 episode reward: total was -92.140000. running mean: -58.662109\n",
      "ep 2: ep_len:1715 episode reward: total was -164.380000. running mean: -59.719288\n",
      "ep 2: ep_len:1085 episode reward: total was -88.330000. running mean: -60.005395\n",
      "ep 2: ep_len:505 episode reward: total was 2.500000. running mean: -59.380341\n",
      "ep 2: ep_len:870 episode reward: total was -83.730000. running mean: -59.623838\n",
      "ep 2: ep_len:555 episode reward: total was -64.590000. running mean: -59.673499\n",
      "ep 2: ep_len:850 episode reward: total was -73.050000. running mean: -59.807264\n",
      "ep 2: ep_len:690 episode reward: total was -66.340000. running mean: -59.872592\n",
      "ep 2: ep_len:1010 episode reward: total was -117.700000. running mean: -60.450866\n",
      "ep 2: ep_len:568 episode reward: total was -47.380000. running mean: -60.320157\n",
      "ep 2: ep_len:675 episode reward: total was -73.260000. running mean: -60.449555\n",
      "ep 2: ep_len:745 episode reward: total was -46.020000. running mean: -60.305260\n",
      "ep 2: ep_len:157 episode reward: total was -2.500000. running mean: -59.727207\n",
      "ep 2: ep_len:520 episode reward: total was -50.790000. running mean: -59.637835\n",
      "ep 2: ep_len:740 episode reward: total was -89.960000. running mean: -59.941057\n",
      "ep 2: ep_len:570 episode reward: total was -47.910000. running mean: -59.820746\n",
      "ep 2: ep_len:500 episode reward: total was -35.220000. running mean: -59.574739\n",
      "ep 2: ep_len:570 episode reward: total was -43.840000. running mean: -59.417391\n",
      "ep 2: ep_len:143 episode reward: total was 0.500000. running mean: -58.818218\n",
      "ep 2: ep_len:177 episode reward: total was 1.000000. running mean: -58.220035\n",
      "ep 2: ep_len:239 episode reward: total was -9.500000. running mean: -57.732835\n",
      "ep 2: ep_len:500 episode reward: total was -55.880000. running mean: -57.714307\n",
      "ep 2: ep_len:860 episode reward: total was -37.240000. running mean: -57.509564\n",
      "ep 2: ep_len:555 episode reward: total was -41.850000. running mean: -57.352968\n",
      "ep 2: ep_len:2140 episode reward: total was -179.590000. running mean: -58.575338\n",
      "ep 2: ep_len:129 episode reward: total was -0.500000. running mean: -57.994585\n",
      "ep 2: ep_len:665 episode reward: total was -47.690000. running mean: -57.891539\n",
      "ep 2: ep_len:500 episode reward: total was -14.370000. running mean: -57.456324\n",
      "ep 2: ep_len:675 episode reward: total was -57.400000. running mean: -57.455760\n",
      "ep 2: ep_len:1035 episode reward: total was -52.590000. running mean: -57.407103\n",
      "ep 2: ep_len:815 episode reward: total was -74.720000. running mean: -57.580232\n",
      "ep 2: ep_len:645 episode reward: total was -63.400000. running mean: -57.638429\n",
      "ep 2: ep_len:500 episode reward: total was -18.340000. running mean: -57.245445\n",
      "ep 2: ep_len:965 episode reward: total was -70.910000. running mean: -57.382091\n",
      "ep 2: ep_len:825 episode reward: total was -58.480000. running mean: -57.393070\n",
      "ep 2: ep_len:500 episode reward: total was -25.800000. running mean: -57.077139\n",
      "ep 2: ep_len:500 episode reward: total was -18.860000. running mean: -56.694968\n",
      "ep 2: ep_len:675 episode reward: total was -96.910000. running mean: -57.097118\n",
      "ep 2: ep_len:1030 episode reward: total was -103.030000. running mean: -57.556447\n",
      "ep 2: ep_len:342 episode reward: total was -10.410000. running mean: -57.084982\n",
      "ep 2: ep_len:1445 episode reward: total was -159.310000. running mean: -58.107233\n",
      "ep 2: ep_len:505 episode reward: total was -30.420000. running mean: -57.830360\n",
      "ep 2: ep_len:645 episode reward: total was -61.380000. running mean: -57.865857\n",
      "ep 2: ep_len:247 episode reward: total was 2.000000. running mean: -57.267198\n",
      "ep 2: ep_len:545 episode reward: total was -53.470000. running mean: -57.229226\n",
      "ep 2: ep_len:645 episode reward: total was -47.210000. running mean: -57.129034\n",
      "ep 2: ep_len:725 episode reward: total was -55.650000. running mean: -57.114243\n",
      "ep 2: ep_len:500 episode reward: total was -16.910000. running mean: -56.712201\n",
      "ep 2: ep_len:277 episode reward: total was -0.500000. running mean: -56.150079\n",
      "ep 2: ep_len:500 episode reward: total was -20.040000. running mean: -55.788978\n",
      "ep 2: ep_len:570 episode reward: total was -44.920000. running mean: -55.680288\n",
      "ep 2: ep_len:230 episode reward: total was -2.000000. running mean: -55.143486\n",
      "ep 2: ep_len:1435 episode reward: total was -153.880000. running mean: -56.130851\n",
      "ep 2: ep_len:177 episode reward: total was 4.000000. running mean: -55.529542\n",
      "ep 2: ep_len:505 episode reward: total was 6.500000. running mean: -54.909247\n",
      "ep 2: ep_len:690 episode reward: total was -55.490000. running mean: -54.915054\n",
      "ep 2: ep_len:565 episode reward: total was -95.360000. running mean: -55.319504\n",
      "ep 2: ep_len:159 episode reward: total was 5.000000. running mean: -54.716309\n",
      "ep 2: ep_len:505 episode reward: total was -27.340000. running mean: -54.442546\n",
      "ep 2: ep_len:880 episode reward: total was -72.290000. running mean: -54.621020\n",
      "ep 2: ep_len:615 episode reward: total was -62.400000. running mean: -54.698810\n",
      "ep 2: ep_len:1060 episode reward: total was -70.670000. running mean: -54.858522\n",
      "ep 2: ep_len:683 episode reward: total was -106.710000. running mean: -55.377037\n",
      "ep 2: ep_len:208 episode reward: total was 1.000000. running mean: -54.813266\n",
      "ep 2: ep_len:605 episode reward: total was -71.040000. running mean: -54.975534\n",
      "ep 2: ep_len:500 episode reward: total was -17.770000. running mean: -54.603478\n",
      "ep 2: ep_len:550 episode reward: total was -64.600000. running mean: -54.703444\n",
      "ep 2: ep_len:2560 episode reward: total was -340.820000. running mean: -57.564609\n",
      "ep 2: ep_len:500 episode reward: total was -39.630000. running mean: -57.385263\n",
      "ep 2: ep_len:820 episode reward: total was -50.120000. running mean: -57.312610\n",
      "ep 2: ep_len:710 episode reward: total was -44.900000. running mean: -57.188484\n",
      "ep 2: ep_len:500 episode reward: total was -13.400000. running mean: -56.750599\n",
      "ep 2: ep_len:500 episode reward: total was -39.170000. running mean: -56.574793\n",
      "ep 2: ep_len:500 episode reward: total was -65.250000. running mean: -56.661546\n",
      "ep 2: ep_len:780 episode reward: total was -72.650000. running mean: -56.821430\n",
      "ep 2: ep_len:905 episode reward: total was -106.310000. running mean: -57.316316\n",
      "ep 2: ep_len:500 episode reward: total was -17.320000. running mean: -56.916353\n",
      "ep 2: ep_len:615 episode reward: total was -84.150000. running mean: -57.188689\n",
      "ep 2: ep_len:845 episode reward: total was -47.850000. running mean: -57.095302\n",
      "ep 2: ep_len:479 episode reward: total was -46.600000. running mean: -56.990349\n",
      "ep 2: ep_len:234 episode reward: total was 3.500000. running mean: -56.385446\n",
      "ep 2: ep_len:760 episode reward: total was -49.340000. running mean: -56.314991\n",
      "ep 2: ep_len:500 episode reward: total was -44.170000. running mean: -56.193541\n",
      "ep 2: ep_len:500 episode reward: total was -28.400000. running mean: -55.915606\n",
      "ep 2: ep_len:500 episode reward: total was -26.130000. running mean: -55.617750\n",
      "ep 2: ep_len:770 episode reward: total was -72.240000. running mean: -55.783972\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 2: ep_len:256 episode reward: total was -10.500000. running mean: -55.331133\n",
      "ep 2: ep_len:1095 episode reward: total was -102.240000. running mean: -55.800221\n",
      "ep 2: ep_len:545 episode reward: total was -71.650000. running mean: -55.958719\n",
      "ep 2: ep_len:245 episode reward: total was -2.000000. running mean: -55.419132\n",
      "ep 2: ep_len:740 episode reward: total was -55.700000. running mean: -55.421941\n",
      "ep 2: ep_len:570 episode reward: total was -43.350000. running mean: -55.301221\n",
      "ep 2: ep_len:505 episode reward: total was -24.770000. running mean: -54.995909\n",
      "ep 2: ep_len:500 episode reward: total was -35.280000. running mean: -54.798750\n",
      "ep 2: ep_len:500 episode reward: total was -33.810000. running mean: -54.588862\n",
      "ep 2: ep_len:550 episode reward: total was -26.730000. running mean: -54.310274\n",
      "ep 2: ep_len:2805 episode reward: total was -399.740000. running mean: -57.764571\n",
      "ep 2: ep_len:805 episode reward: total was -43.150000. running mean: -57.618425\n",
      "ep 2: ep_len:730 episode reward: total was -65.740000. running mean: -57.699641\n",
      "ep 2: ep_len:1730 episode reward: total was -174.940000. running mean: -58.872045\n",
      "ep 2: ep_len:765 episode reward: total was -115.460000. running mean: -59.437924\n",
      "ep 2: ep_len:745 episode reward: total was -71.340000. running mean: -59.556945\n",
      "ep 2: ep_len:650 episode reward: total was -56.290000. running mean: -59.524275\n",
      "ep 2: ep_len:500 episode reward: total was -2.000000. running mean: -58.949033\n",
      "ep 2: ep_len:1220 episode reward: total was -118.560000. running mean: -59.545142\n",
      "ep 2: ep_len:975 episode reward: total was -74.860000. running mean: -59.698291\n",
      "ep 2: ep_len:1465 episode reward: total was -120.830000. running mean: -60.309608\n",
      "ep 2: ep_len:505 episode reward: total was -30.830000. running mean: -60.014812\n",
      "ep 2: ep_len:505 episode reward: total was -6.500000. running mean: -59.479664\n",
      "ep 2: ep_len:510 episode reward: total was -25.830000. running mean: -59.143167\n",
      "ep 2: ep_len:805 episode reward: total was -64.580000. running mean: -59.197536\n",
      "ep 2: ep_len:500 episode reward: total was -24.290000. running mean: -58.848460\n",
      "ep 2: ep_len:1175 episode reward: total was -64.500000. running mean: -58.904976\n",
      "ep 2: ep_len:500 episode reward: total was -35.070000. running mean: -58.666626\n",
      "ep 2: ep_len:1179 episode reward: total was -119.370000. running mean: -59.273660\n",
      "ep 2: ep_len:515 episode reward: total was -48.230000. running mean: -59.163223\n",
      "ep 2: ep_len:500 episode reward: total was -15.410000. running mean: -58.725691\n",
      "ep 2: ep_len:1325 episode reward: total was -71.430000. running mean: -58.852734\n",
      "ep 2: ep_len:920 episode reward: total was -77.950000. running mean: -59.043707\n",
      "ep 2: ep_len:209 episode reward: total was 0.000000. running mean: -58.453269\n",
      "ep 2: ep_len:1310 episode reward: total was -68.630000. running mean: -58.555037\n",
      "ep 2: ep_len:965 episode reward: total was -96.990000. running mean: -58.939386\n",
      "ep 2: ep_len:500 episode reward: total was -38.630000. running mean: -58.736293\n",
      "ep 2: ep_len:505 episode reward: total was -55.830000. running mean: -58.707230\n",
      "ep 2: ep_len:885 episode reward: total was -51.810000. running mean: -58.638257\n",
      "ep 2: ep_len:685 episode reward: total was -57.100000. running mean: -58.622875\n",
      "ep 2: ep_len:840 episode reward: total was -71.480000. running mean: -58.751446\n",
      "ep 2: ep_len:955 episode reward: total was -81.940000. running mean: -58.983332\n",
      "ep 2: ep_len:955 episode reward: total was -62.860000. running mean: -59.022098\n",
      "ep 2: ep_len:1015 episode reward: total was -151.020000. running mean: -59.942077\n",
      "ep 2: ep_len:1455 episode reward: total was -179.430000. running mean: -61.136956\n",
      "ep 2: ep_len:540 episode reward: total was -32.310000. running mean: -60.848687\n",
      "ep 2: ep_len:500 episode reward: total was -46.810000. running mean: -60.708300\n",
      "ep 2: ep_len:1010 episode reward: total was -148.000000. running mean: -61.581217\n",
      "ep 2: ep_len:500 episode reward: total was -34.430000. running mean: -61.309705\n",
      "ep 2: ep_len:1311 episode reward: total was -123.890000. running mean: -61.935508\n",
      "ep 2: ep_len:890 episode reward: total was -69.460000. running mean: -62.010753\n",
      "ep 2: ep_len:1020 episode reward: total was -149.670000. running mean: -62.887345\n",
      "ep 2: ep_len:1055 episode reward: total was -82.670000. running mean: -63.085172\n",
      "ep 2: ep_len:853 episode reward: total was -67.620000. running mean: -63.130520\n",
      "ep 2: ep_len:500 episode reward: total was -32.470000. running mean: -62.823915\n",
      "ep 2: ep_len:980 episode reward: total was -98.570000. running mean: -63.181376\n",
      "ep 2: ep_len:316 episode reward: total was 7.500000. running mean: -62.474562\n",
      "ep 2: ep_len:500 episode reward: total was -66.230000. running mean: -62.512116\n",
      "ep 2: ep_len:500 episode reward: total was -47.830000. running mean: -62.365295\n",
      "ep 2: ep_len:865 episode reward: total was -63.940000. running mean: -62.381042\n",
      "ep 2: ep_len:590 episode reward: total was -57.940000. running mean: -62.336632\n",
      "ep 2: ep_len:500 episode reward: total was -60.140000. running mean: -62.314665\n",
      "ep 2: ep_len:505 episode reward: total was -18.280000. running mean: -61.874319\n",
      "ep 2: ep_len:8775 episode reward: total was -1639.220000. running mean: -77.647776\n",
      "ep 2: ep_len:905 episode reward: total was -62.910000. running mean: -77.500398\n",
      "ep 2: ep_len:500 episode reward: total was -39.590000. running mean: -77.121294\n",
      "ep 2: ep_len:520 episode reward: total was -30.810000. running mean: -76.658181\n",
      "ep 2: ep_len:500 episode reward: total was -44.070000. running mean: -76.332299\n",
      "ep 2: ep_len:595 episode reward: total was -64.350000. running mean: -76.212476\n",
      "ep 2: ep_len:1125 episode reward: total was -170.510000. running mean: -77.155451\n",
      "ep 2: ep_len:605 episode reward: total was -41.750000. running mean: -76.801397\n",
      "ep 2: ep_len:500 episode reward: total was -22.460000. running mean: -76.257983\n",
      "ep 2: ep_len:755 episode reward: total was -56.200000. running mean: -76.057403\n",
      "ep 2: ep_len:925 episode reward: total was -55.340000. running mean: -75.850229\n",
      "ep 2: ep_len:500 episode reward: total was -35.390000. running mean: -75.445627\n",
      "ep 2: ep_len:500 episode reward: total was -22.460000. running mean: -74.915770\n",
      "ep 2: ep_len:675 episode reward: total was -70.900000. running mean: -74.875613\n",
      "ep 2: ep_len:550 episode reward: total was -33.880000. running mean: -74.465657\n",
      "ep 2: ep_len:900 episode reward: total was -65.060000. running mean: -74.371600\n",
      "ep 2: ep_len:935 episode reward: total was -65.330000. running mean: -74.281184\n",
      "ep 2: ep_len:690 episode reward: total was -86.540000. running mean: -74.403772\n",
      "ep 2: ep_len:870 episode reward: total was -54.870000. running mean: -74.208435\n",
      "ep 2: ep_len:950 episode reward: total was -57.770000. running mean: -74.044050\n",
      "ep 2: ep_len:930 episode reward: total was -85.020000. running mean: -74.153810\n",
      "ep 2: ep_len:620 episode reward: total was -68.700000. running mean: -74.099272\n",
      "ep 2: ep_len:220 episode reward: total was 2.500000. running mean: -73.333279\n",
      "ep 2: ep_len:560 episode reward: total was -63.930000. running mean: -73.239246\n",
      "ep 2: ep_len:535 episode reward: total was -75.220000. running mean: -73.259054\n",
      "ep 2: ep_len:500 episode reward: total was -42.750000. running mean: -72.953963\n",
      "ep 2: ep_len:580 episode reward: total was -73.110000. running mean: -72.955523\n",
      "ep 2: ep_len:525 episode reward: total was -27.380000. running mean: -72.499768\n",
      "ep 2: ep_len:500 episode reward: total was -31.380000. running mean: -72.088571\n",
      "ep 2: ep_len:500 episode reward: total was -65.400000. running mean: -72.021685\n",
      "ep 2: ep_len:790 episode reward: total was -112.600000. running mean: -72.427468\n",
      "ep 2: ep_len:500 episode reward: total was -13.810000. running mean: -71.841293\n",
      "ep 2: ep_len:505 episode reward: total was -39.840000. running mean: -71.521280\n",
      "ep 2: ep_len:620 episode reward: total was -81.340000. running mean: -71.619468\n",
      "ep 2: ep_len:107 episode reward: total was 0.500000. running mean: -70.898273\n",
      "ep 2: ep_len:500 episode reward: total was -2.500000. running mean: -70.214290\n",
      "ep 2: ep_len:760 episode reward: total was -49.550000. running mean: -70.007647\n",
      "ep 2: ep_len:845 episode reward: total was -89.270000. running mean: -70.200271\n",
      "ep 2: ep_len:535 episode reward: total was -32.800000. running mean: -69.826268\n",
      "ep 2: ep_len:825 episode reward: total was -70.200000. running mean: -69.830005\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 2: ep_len:500 episode reward: total was -16.300000. running mean: -69.294705\n",
      "ep 2: ep_len:730 episode reward: total was -60.690000. running mean: -69.208658\n",
      "ep 2: ep_len:540 episode reward: total was -36.830000. running mean: -68.884872\n",
      "ep 2: ep_len:1065 episode reward: total was -75.600000. running mean: -68.952023\n",
      "ep 2: ep_len:505 episode reward: total was -50.230000. running mean: -68.764803\n",
      "ep 2: ep_len:950 episode reward: total was -85.500000. running mean: -68.932155\n",
      "ep 2: ep_len:880 episode reward: total was -64.880000. running mean: -68.891633\n",
      "ep 2: ep_len:505 episode reward: total was -32.350000. running mean: -68.526217\n",
      "ep 2: ep_len:471 episode reward: total was -12.840000. running mean: -67.969355\n",
      "ep 2: ep_len:500 episode reward: total was -41.830000. running mean: -67.707961\n",
      "ep 2: ep_len:510 episode reward: total was -39.970000. running mean: -67.430582\n",
      "ep 2: ep_len:500 episode reward: total was -35.440000. running mean: -67.110676\n",
      "ep 2: ep_len:1025 episode reward: total was -107.890000. running mean: -67.518469\n",
      "ep 2: ep_len:505 episode reward: total was -60.280000. running mean: -67.446084\n",
      "ep 2: ep_len:560 episode reward: total was -64.060000. running mean: -67.412223\n",
      "ep 2: ep_len:1965 episode reward: total was -339.490000. running mean: -70.133001\n",
      "ep 2: ep_len:595 episode reward: total was -58.450000. running mean: -70.016171\n",
      "ep 2: ep_len:1050 episode reward: total was -67.520000. running mean: -69.991209\n",
      "ep 2: ep_len:780 episode reward: total was -89.360000. running mean: -70.184897\n",
      "ep 2: ep_len:590 episode reward: total was -66.650000. running mean: -70.149548\n",
      "ep 2: ep_len:500 episode reward: total was -47.460000. running mean: -69.922653\n",
      "ep 2: ep_len:705 episode reward: total was -61.230000. running mean: -69.835726\n",
      "ep 2: ep_len:500 episode reward: total was -48.770000. running mean: -69.625069\n",
      "ep 2: ep_len:830 episode reward: total was -93.330000. running mean: -69.862118\n",
      "ep 2: ep_len:257 episode reward: total was 3.000000. running mean: -69.133497\n",
      "ep 2: ep_len:505 episode reward: total was -19.750000. running mean: -68.639662\n",
      "ep 2: ep_len:500 episode reward: total was -29.560000. running mean: -68.248866\n",
      "ep 2: ep_len:1343 episode reward: total was -162.360000. running mean: -69.189977\n",
      "ep 2: ep_len:500 episode reward: total was -8.240000. running mean: -68.580477\n",
      "ep 2: ep_len:755 episode reward: total was -30.580000. running mean: -68.200472\n",
      "ep 2: ep_len:515 episode reward: total was -40.810000. running mean: -67.926568\n",
      "ep 2: ep_len:695 episode reward: total was -43.580000. running mean: -67.683102\n",
      "ep 2: ep_len:600 episode reward: total was -72.550000. running mean: -67.731771\n",
      "ep 2: ep_len:500 episode reward: total was -26.340000. running mean: -67.317853\n",
      "ep 2: ep_len:730 episode reward: total was -51.430000. running mean: -67.158975\n",
      "ep 2: ep_len:590 episode reward: total was -60.280000. running mean: -67.090185\n",
      "ep 2: ep_len:505 episode reward: total was -48.650000. running mean: -66.905783\n",
      "ep 2: ep_len:505 episode reward: total was -49.690000. running mean: -66.733625\n",
      "ep 2: ep_len:690 episode reward: total was -58.230000. running mean: -66.648589\n",
      "ep 2: ep_len:1685 episode reward: total was -280.080000. running mean: -68.782903\n",
      "ep 2: ep_len:620 episode reward: total was -53.350000. running mean: -68.628574\n",
      "ep 2: ep_len:505 episode reward: total was -22.830000. running mean: -68.170588\n",
      "ep 2: ep_len:615 episode reward: total was -28.720000. running mean: -67.776083\n",
      "ep 2: ep_len:675 episode reward: total was -64.160000. running mean: -67.739922\n",
      "ep 2: ep_len:520 episode reward: total was -50.720000. running mean: -67.569722\n",
      "ep 2: ep_len:1370 episode reward: total was -201.330000. running mean: -68.907325\n",
      "ep 2: ep_len:1245 episode reward: total was -97.620000. running mean: -69.194452\n",
      "ep 2: ep_len:510 episode reward: total was -24.270000. running mean: -68.745207\n",
      "ep 2: ep_len:515 episode reward: total was -39.450000. running mean: -68.452255\n",
      "ep 2: ep_len:890 episode reward: total was -77.200000. running mean: -68.539733\n",
      "ep 2: ep_len:500 episode reward: total was -18.900000. running mean: -68.043336\n",
      "ep 2: ep_len:434 episode reward: total was -34.820000. running mean: -67.711102\n",
      "ep 2: ep_len:510 episode reward: total was -19.830000. running mean: -67.232291\n",
      "ep 2: ep_len:500 episode reward: total was -15.820000. running mean: -66.718168\n",
      "ep 2: ep_len:500 episode reward: total was -54.140000. running mean: -66.592387\n",
      "ep 2: ep_len:500 episode reward: total was -54.140000. running mean: -66.467863\n",
      "ep 2: ep_len:505 episode reward: total was -30.380000. running mean: -66.106984\n",
      "ep 2: ep_len:605 episode reward: total was -59.410000. running mean: -66.040014\n",
      "ep 2: ep_len:500 episode reward: total was -30.870000. running mean: -65.688314\n",
      "ep 2: ep_len:500 episode reward: total was -19.880000. running mean: -65.230231\n",
      "ep 2: ep_len:655 episode reward: total was -49.240000. running mean: -65.070329\n",
      "ep 2: ep_len:735 episode reward: total was -98.050000. running mean: -65.400125\n",
      "ep 2: ep_len:500 episode reward: total was -53.180000. running mean: -65.277924\n",
      "ep 2: ep_len:875 episode reward: total was -68.970000. running mean: -65.314845\n",
      "ep 2: ep_len:1005 episode reward: total was -65.120000. running mean: -65.312896\n",
      "ep 2: ep_len:805 episode reward: total was -63.570000. running mean: -65.295467\n",
      "ep 2: ep_len:116 episode reward: total was -6.000000. running mean: -64.702513\n",
      "ep 2: ep_len:190 episode reward: total was -2.000000. running mean: -64.075488\n",
      "ep 2: ep_len:500 episode reward: total was -18.880000. running mean: -63.623533\n",
      "ep 2: ep_len:775 episode reward: total was -58.090000. running mean: -63.568197\n",
      "ep 2: ep_len:500 episode reward: total was -44.160000. running mean: -63.374115\n",
      "ep 2: ep_len:500 episode reward: total was -11.310000. running mean: -62.853474\n",
      "ep 2: ep_len:500 episode reward: total was -13.820000. running mean: -62.363140\n",
      "ep 2: ep_len:136 episode reward: total was 1.500000. running mean: -61.724508\n",
      "ep 2: ep_len:500 episode reward: total was -17.360000. running mean: -61.280863\n",
      "ep 2: ep_len:210 episode reward: total was -4.500000. running mean: -60.713054\n",
      "ep 2: ep_len:500 episode reward: total was -58.820000. running mean: -60.694124\n",
      "ep 2: ep_len:286 episode reward: total was -4.500000. running mean: -60.132183\n",
      "ep 2: ep_len:655 episode reward: total was -86.610000. running mean: -60.396961\n",
      "ep 2: ep_len:249 episode reward: total was 2.000000. running mean: -59.772991\n",
      "ep 2: ep_len:500 episode reward: total was -11.340000. running mean: -59.288661\n",
      "ep 2: ep_len:195 episode reward: total was -4.000000. running mean: -58.735775\n",
      "ep 2: ep_len:500 episode reward: total was -58.790000. running mean: -58.736317\n",
      "ep 2: ep_len:1005 episode reward: total was -124.910000. running mean: -59.398054\n",
      "ep 2: ep_len:128 episode reward: total was -2.000000. running mean: -58.824073\n",
      "ep 2: ep_len:58 episode reward: total was 4.500000. running mean: -58.190833\n",
      "ep 2: ep_len:500 episode reward: total was -55.820000. running mean: -58.167124\n",
      "ep 2: ep_len:1135 episode reward: total was -106.820000. running mean: -58.653653\n",
      "ep 2: ep_len:515 episode reward: total was -19.440000. running mean: -58.261516\n",
      "ep 2: ep_len:535 episode reward: total was -64.630000. running mean: -58.325201\n",
      "ep 2: ep_len:159 episode reward: total was 2.000000. running mean: -57.721949\n",
      "ep 2: ep_len:505 episode reward: total was -42.860000. running mean: -57.573330\n",
      "ep 2: ep_len:700 episode reward: total was -57.230000. running mean: -57.569896\n",
      "ep 2: ep_len:870 episode reward: total was -72.010000. running mean: -57.714298\n",
      "ep 2: ep_len:755 episode reward: total was -62.170000. running mean: -57.758855\n",
      "ep 2: ep_len:500 episode reward: total was -42.780000. running mean: -57.609066\n",
      "ep 2: ep_len:500 episode reward: total was -21.850000. running mean: -57.251475\n",
      "ep 2: ep_len:565 episode reward: total was -42.350000. running mean: -57.102461\n",
      "ep 2: ep_len:520 episode reward: total was -53.520000. running mean: -57.066636\n",
      "ep 2: ep_len:540 episode reward: total was -53.280000. running mean: -57.028770\n",
      "ep 2: ep_len:500 episode reward: total was -31.000000. running mean: -56.768482\n",
      "ep 2: ep_len:1190 episode reward: total was -146.140000. running mean: -57.662197\n",
      "ep 2: ep_len:139 episode reward: total was -6.500000. running mean: -57.150575\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 2: ep_len:700 episode reward: total was -49.470000. running mean: -57.073769\n",
      "ep 2: ep_len:1695 episode reward: total was -268.180000. running mean: -59.184832\n",
      "ep 2: ep_len:705 episode reward: total was -68.140000. running mean: -59.274383\n",
      "ep 2: ep_len:500 episode reward: total was -44.800000. running mean: -59.129640\n",
      "ep 2: ep_len:500 episode reward: total was -63.290000. running mean: -59.171243\n",
      "ep 2: ep_len:500 episode reward: total was -14.360000. running mean: -58.723131\n",
      "ep 2: ep_len:655 episode reward: total was -49.480000. running mean: -58.630699\n",
      "ep 2: ep_len:510 episode reward: total was -37.250000. running mean: -58.416892\n",
      "ep 2: ep_len:376 episode reward: total was 7.500000. running mean: -57.757723\n",
      "ep 2: ep_len:500 episode reward: total was -26.340000. running mean: -57.443546\n",
      "ep 2: ep_len:500 episode reward: total was -29.610000. running mean: -57.165211\n",
      "ep 2: ep_len:845 episode reward: total was -71.260000. running mean: -57.306159\n",
      "ep 2: ep_len:505 episode reward: total was -6.800000. running mean: -56.801097\n",
      "ep 2: ep_len:695 episode reward: total was -48.150000. running mean: -56.714586\n",
      "ep 2: ep_len:505 episode reward: total was -27.370000. running mean: -56.421140\n",
      "ep 2: ep_len:545 episode reward: total was -40.860000. running mean: -56.265529\n",
      "ep 2: ep_len:500 episode reward: total was -44.820000. running mean: -56.151074\n",
      "ep 2: ep_len:1110 episode reward: total was -100.330000. running mean: -56.592863\n",
      "ep 2: ep_len:1045 episode reward: total was -52.420000. running mean: -56.551134\n",
      "ep 2: ep_len:1185 episode reward: total was -70.180000. running mean: -56.687423\n",
      "ep 2: ep_len:468 episode reward: total was -15.900000. running mean: -56.279549\n",
      "ep 2: ep_len:765 episode reward: total was -113.380000. running mean: -56.850553\n",
      "ep 2: ep_len:500 episode reward: total was -47.910000. running mean: -56.761148\n",
      "ep 2: ep_len:2460 episode reward: total was -438.000000. running mean: -60.573536\n",
      "ep 2: ep_len:740 episode reward: total was -43.500000. running mean: -60.402801\n",
      "ep 2: ep_len:1835 episode reward: total was -231.710000. running mean: -62.115873\n",
      "ep 2: ep_len:500 episode reward: total was 2.500000. running mean: -61.469714\n",
      "ep 2: ep_len:830 episode reward: total was -70.610000. running mean: -61.561117\n",
      "ep 2: ep_len:1005 episode reward: total was -68.620000. running mean: -61.631706\n",
      "ep 2: ep_len:500 episode reward: total was -20.420000. running mean: -61.219589\n",
      "ep 2: ep_len:810 episode reward: total was -51.720000. running mean: -61.124593\n",
      "ep 2: ep_len:820 episode reward: total was -97.880000. running mean: -61.492147\n",
      "ep 2: ep_len:505 episode reward: total was -32.370000. running mean: -61.200925\n",
      "ep 2: ep_len:505 episode reward: total was -35.880000. running mean: -60.947716\n",
      "ep 2: ep_len:500 episode reward: total was -35.490000. running mean: -60.693139\n",
      "ep 2: ep_len:605 episode reward: total was -27.350000. running mean: -60.359708\n",
      "ep 2: ep_len:500 episode reward: total was -48.630000. running mean: -60.242411\n",
      "ep 2: ep_len:875 episode reward: total was -78.560000. running mean: -60.425586\n",
      "ep 2: ep_len:1340 episode reward: total was -130.690000. running mean: -61.128231\n",
      "ep 2: ep_len:463 episode reward: total was 0.000000. running mean: -60.516948\n",
      "ep 2: ep_len:760 episode reward: total was -51.220000. running mean: -60.423979\n",
      "ep 2: ep_len:755 episode reward: total was -71.260000. running mean: -60.532339\n",
      "ep 2: ep_len:870 episode reward: total was -58.510000. running mean: -60.512116\n",
      "ep 2: ep_len:595 episode reward: total was -65.520000. running mean: -60.562194\n",
      "ep 2: ep_len:162 episode reward: total was 2.500000. running mean: -59.931572\n",
      "ep 2: ep_len:500 episode reward: total was -24.780000. running mean: -59.580057\n",
      "ep 2: ep_len:500 episode reward: total was 17.500000. running mean: -58.809256\n",
      "ep 2: ep_len:750 episode reward: total was -38.070000. running mean: -58.601864\n",
      "ep 2: ep_len:505 episode reward: total was -36.790000. running mean: -58.383745\n",
      "ep 2: ep_len:500 episode reward: total was -39.430000. running mean: -58.194208\n",
      "ep 2: ep_len:500 episode reward: total was -39.780000. running mean: -58.010065\n",
      "ep 2: ep_len:163 episode reward: total was 1.000000. running mean: -57.419965\n",
      "ep 2: ep_len:540 episode reward: total was -63.830000. running mean: -57.484065\n",
      "ep 2: ep_len:730 episode reward: total was -54.630000. running mean: -57.455524\n",
      "ep 2: ep_len:1325 episode reward: total was -179.200000. running mean: -58.672969\n",
      "ep 2: ep_len:540 episode reward: total was -47.910000. running mean: -58.565340\n",
      "ep 2: ep_len:500 episode reward: total was -11.270000. running mean: -58.092386\n",
      "ep 2: ep_len:505 episode reward: total was -65.730000. running mean: -58.168762\n",
      "ep 2: ep_len:1180 episode reward: total was -60.880000. running mean: -58.195875\n",
      "ep 2: ep_len:500 episode reward: total was -24.800000. running mean: -57.861916\n",
      "ep 2: ep_len:695 episode reward: total was -40.040000. running mean: -57.683697\n",
      "ep 2: ep_len:500 episode reward: total was -34.210000. running mean: -57.448960\n",
      "ep 2: ep_len:570 episode reward: total was -73.400000. running mean: -57.608470\n",
      "ep 2: ep_len:625 episode reward: total was -65.430000. running mean: -57.686686\n",
      "ep 2: ep_len:820 episode reward: total was -50.930000. running mean: -57.619119\n",
      "ep 2: ep_len:500 episode reward: total was -54.110000. running mean: -57.584027\n",
      "ep 2: ep_len:690 episode reward: total was -62.790000. running mean: -57.636087\n",
      "ep 2: ep_len:705 episode reward: total was -53.670000. running mean: -57.596426\n",
      "ep 2: ep_len:780 episode reward: total was -90.370000. running mean: -57.924162\n",
      "ep 2: ep_len:500 episode reward: total was -13.820000. running mean: -57.483120\n",
      "ep 2: ep_len:745 episode reward: total was -70.220000. running mean: -57.610489\n",
      "ep 2: ep_len:530 episode reward: total was -92.460000. running mean: -57.958984\n",
      "ep 2: ep_len:890 episode reward: total was -85.100000. running mean: -58.230394\n",
      "ep 2: ep_len:500 episode reward: total was 4.000000. running mean: -57.608091\n",
      "ep 2: ep_len:500 episode reward: total was -29.340000. running mean: -57.325410\n",
      "ep 2: ep_len:570 episode reward: total was -61.130000. running mean: -57.363456\n",
      "ep 2: ep_len:500 episode reward: total was -29.850000. running mean: -57.088321\n",
      "ep 2: ep_len:995 episode reward: total was -70.880000. running mean: -57.226238\n",
      "ep 2: ep_len:500 episode reward: total was -30.500000. running mean: -56.958975\n",
      "ep 2: ep_len:685 episode reward: total was -34.020000. running mean: -56.729586\n",
      "ep 2: ep_len:520 episode reward: total was 6.000000. running mean: -56.102290\n",
      "ep 2: ep_len:760 episode reward: total was -71.740000. running mean: -56.258667\n",
      "ep 2: ep_len:505 episode reward: total was -23.780000. running mean: -55.933880\n",
      "ep 2: ep_len:500 episode reward: total was -53.770000. running mean: -55.912241\n",
      "ep 2: ep_len:555 episode reward: total was -74.710000. running mean: -56.100219\n",
      "ep 2: ep_len:835 episode reward: total was -47.020000. running mean: -56.009417\n",
      "ep 2: ep_len:515 episode reward: total was -34.370000. running mean: -55.793023\n",
      "ep 2: ep_len:500 episode reward: total was -35.990000. running mean: -55.594992\n",
      "ep 2: ep_len:725 episode reward: total was -59.690000. running mean: -55.635943\n",
      "ep 2: ep_len:265 episode reward: total was -2.500000. running mean: -55.104583\n",
      "ep 2: ep_len:545 episode reward: total was -48.450000. running mean: -55.038037\n",
      "ep 2: ep_len:930 episode reward: total was -67.430000. running mean: -55.161957\n",
      "ep 2: ep_len:181 episode reward: total was -4.500000. running mean: -54.655337\n",
      "ep 2: ep_len:830 episode reward: total was -50.720000. running mean: -54.615984\n",
      "ep 2: ep_len:510 episode reward: total was -37.440000. running mean: -54.444224\n",
      "ep 2: ep_len:1330 episode reward: total was -217.050000. running mean: -56.070282\n",
      "ep 2: ep_len:500 episode reward: total was -12.270000. running mean: -55.632279\n",
      "ep 2: ep_len:920 episode reward: total was -82.050000. running mean: -55.896456\n",
      "ep 2: ep_len:770 episode reward: total was -84.850000. running mean: -56.185992\n",
      "ep 2: ep_len:665 episode reward: total was -40.710000. running mean: -56.031232\n",
      "ep 2: ep_len:500 episode reward: total was -5.500000. running mean: -55.525919\n",
      "ep 2: ep_len:494 episode reward: total was -16.380000. running mean: -55.134460\n",
      "ep 2: ep_len:695 episode reward: total was -47.630000. running mean: -55.059416\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 2: ep_len:311 episode reward: total was -59.000000. running mean: -55.098821\n",
      "ep 2: ep_len:600 episode reward: total was -46.320000. running mean: -55.011033\n",
      "ep 2: ep_len:605 episode reward: total was -65.990000. running mean: -55.120823\n",
      "ep 2: ep_len:510 episode reward: total was -10.310000. running mean: -54.672715\n",
      "ep 2: ep_len:172 episode reward: total was 8.000000. running mean: -54.045988\n",
      "ep 2: ep_len:500 episode reward: total was -22.820000. running mean: -53.733728\n",
      "ep 2: ep_len:230 episode reward: total was -8.990000. running mean: -53.286290\n",
      "ep 2: ep_len:685 episode reward: total was -54.200000. running mean: -53.295428\n",
      "ep 2: ep_len:226 episode reward: total was 3.500000. running mean: -52.727473\n",
      "ep 2: ep_len:505 episode reward: total was -72.850000. running mean: -52.928699\n",
      "ep 2: ep_len:500 episode reward: total was -10.230000. running mean: -52.501712\n",
      "ep 2: ep_len:800 episode reward: total was -80.750000. running mean: -52.784194\n",
      "ep 2: ep_len:1125 episode reward: total was -166.470000. running mean: -53.921052\n",
      "ep 2: ep_len:510 episode reward: total was 18.500000. running mean: -53.196842\n",
      "ep 2: ep_len:585 episode reward: total was -56.420000. running mean: -53.229074\n",
      "ep 2: ep_len:640 episode reward: total was -61.390000. running mean: -53.310683\n",
      "ep 2: ep_len:123 episode reward: total was 3.000000. running mean: -52.747576\n",
      "ep 2: ep_len:510 episode reward: total was -36.400000. running mean: -52.584100\n",
      "ep 2: ep_len:4400 episode reward: total was -741.160000. running mean: -59.469859\n",
      "ep 2: ep_len:540 episode reward: total was -41.390000. running mean: -59.289061\n",
      "ep 2: ep_len:500 episode reward: total was -19.380000. running mean: -58.889970\n",
      "ep 2: ep_len:630 episode reward: total was -44.730000. running mean: -58.748370\n",
      "ep 2: ep_len:285 episode reward: total was -1.500000. running mean: -58.175887\n",
      "ep 2: ep_len:830 episode reward: total was -64.530000. running mean: -58.239428\n",
      "ep 2: ep_len:1405 episode reward: total was -179.040000. running mean: -59.447433\n",
      "ep 2: ep_len:720 episode reward: total was -65.270000. running mean: -59.505659\n",
      "ep 2: ep_len:500 episode reward: total was -36.310000. running mean: -59.273703\n",
      "ep 2: ep_len:392 episode reward: total was -1.000000. running mean: -58.690965\n",
      "ep 2: ep_len:500 episode reward: total was -25.860000. running mean: -58.362656\n",
      "ep 2: ep_len:216 episode reward: total was 4.000000. running mean: -57.739029\n",
      "ep 2: ep_len:545 episode reward: total was -41.350000. running mean: -57.575139\n",
      "ep 2: ep_len:635 episode reward: total was -38.060000. running mean: -57.379988\n",
      "ep 2: ep_len:750 episode reward: total was -48.040000. running mean: -57.286588\n",
      "ep 2: ep_len:563 episode reward: total was -64.560000. running mean: -57.359322\n",
      "ep 2: ep_len:555 episode reward: total was -49.440000. running mean: -57.280129\n",
      "ep 2: ep_len:615 episode reward: total was -51.830000. running mean: -57.225627\n",
      "ep 2: ep_len:905 episode reward: total was -88.130000. running mean: -57.534671\n",
      "ep 2: ep_len:615 episode reward: total was -55.870000. running mean: -57.518024\n",
      "ep 2: ep_len:500 episode reward: total was -40.030000. running mean: -57.343144\n",
      "ep 2: ep_len:500 episode reward: total was -15.860000. running mean: -56.928313\n",
      "ep 2: ep_len:1135 episode reward: total was -110.900000. running mean: -57.468030\n",
      "ep 2: ep_len:630 episode reward: total was -76.530000. running mean: -57.658649\n",
      "ep 2: ep_len:575 episode reward: total was -20.310000. running mean: -57.285163\n",
      "ep 2: ep_len:991 episode reward: total was -149.060000. running mean: -58.202911\n",
      "ep 2: ep_len:780 episode reward: total was -56.060000. running mean: -58.181482\n",
      "ep 2: ep_len:960 episode reward: total was -106.130000. running mean: -58.660967\n",
      "ep 2: ep_len:515 episode reward: total was -11.790000. running mean: -58.192258\n",
      "ep 2: ep_len:500 episode reward: total was -51.770000. running mean: -58.128035\n",
      "ep 2: ep_len:500 episode reward: total was -36.410000. running mean: -57.910855\n",
      "ep 2: ep_len:505 episode reward: total was -50.240000. running mean: -57.834146\n",
      "ep 2: ep_len:550 episode reward: total was -47.640000. running mean: -57.732205\n",
      "ep 2: ep_len:505 episode reward: total was -20.800000. running mean: -57.362883\n",
      "ep 2: ep_len:685 episode reward: total was -51.890000. running mean: -57.308154\n",
      "ep 2: ep_len:505 episode reward: total was -55.980000. running mean: -57.294872\n",
      "ep 2: ep_len:1060 episode reward: total was -87.080000. running mean: -57.592723\n",
      "ep 2: ep_len:276 episode reward: total was -0.500000. running mean: -57.021796\n",
      "ep 2: ep_len:1265 episode reward: total was -238.910000. running mean: -58.840678\n",
      "ep 2: ep_len:1035 episode reward: total was -152.040000. running mean: -59.772671\n",
      "ep 2: ep_len:685 episode reward: total was -72.410000. running mean: -59.899045\n",
      "ep 2: ep_len:1005 episode reward: total was -83.310000. running mean: -60.133154\n",
      "ep 2: ep_len:615 episode reward: total was -44.410000. running mean: -59.975923\n",
      "ep 2: ep_len:191 episode reward: total was -15.000000. running mean: -59.526164\n",
      "ep 2: ep_len:835 episode reward: total was -49.580000. running mean: -59.426702\n",
      "ep 2: ep_len:520 episode reward: total was -55.740000. running mean: -59.389835\n",
      "ep 2: ep_len:1495 episode reward: total was -232.880000. running mean: -61.124737\n",
      "ep 2: ep_len:500 episode reward: total was -55.390000. running mean: -61.067389\n",
      "ep 2: ep_len:650 episode reward: total was -65.500000. running mean: -61.111715\n",
      "ep 2: ep_len:795 episode reward: total was -57.040000. running mean: -61.070998\n",
      "ep 2: ep_len:890 episode reward: total was -47.580000. running mean: -60.936088\n",
      "ep 2: ep_len:515 episode reward: total was -45.470000. running mean: -60.781427\n",
      "ep 2: ep_len:192 episode reward: total was 1.500000. running mean: -60.158613\n",
      "ep 2: ep_len:500 episode reward: total was -17.280000. running mean: -59.729827\n",
      "ep 2: ep_len:750 episode reward: total was -52.080000. running mean: -59.653329\n",
      "ep 2: ep_len:1135 episode reward: total was -147.280000. running mean: -60.529595\n",
      "ep 2: ep_len:700 episode reward: total was -36.740000. running mean: -60.291699\n",
      "ep 2: ep_len:500 episode reward: total was -29.830000. running mean: -59.987082\n",
      "ep 2: ep_len:500 episode reward: total was -41.220000. running mean: -59.799412\n",
      "ep 2: ep_len:770 episode reward: total was -65.170000. running mean: -59.853117\n",
      "ep 2: ep_len:575 episode reward: total was -46.370000. running mean: -59.718286\n",
      "ep 2: ep_len:1085 episode reward: total was -65.230000. running mean: -59.773403\n",
      "ep 2: ep_len:500 episode reward: total was -14.430000. running mean: -59.319969\n",
      "ep 2: ep_len:780 episode reward: total was -62.210000. running mean: -59.348870\n",
      "ep 2: ep_len:605 episode reward: total was -44.730000. running mean: -59.202681\n",
      "ep 2: ep_len:515 episode reward: total was -39.830000. running mean: -59.008954\n",
      "ep 2: ep_len:500 episode reward: total was -57.770000. running mean: -58.996565\n",
      "ep 2: ep_len:540 episode reward: total was -49.470000. running mean: -58.901299\n",
      "ep 2: ep_len:735 episode reward: total was -31.410000. running mean: -58.626386\n",
      "ep 2: ep_len:530 episode reward: total was -42.420000. running mean: -58.464322\n",
      "ep 2: ep_len:443 episode reward: total was -15.260000. running mean: -58.032279\n",
      "ep 2: ep_len:510 episode reward: total was -64.160000. running mean: -58.093556\n",
      "ep 2: ep_len:510 episode reward: total was -77.290000. running mean: -58.285521\n",
      "ep 2: ep_len:595 episode reward: total was -44.890000. running mean: -58.151565\n",
      "ep 2: ep_len:500 episode reward: total was -33.020000. running mean: -57.900250\n",
      "ep 2: ep_len:500 episode reward: total was -32.730000. running mean: -57.648547\n",
      "ep 2: ep_len:2822 episode reward: total was -396.060000. running mean: -61.032662\n",
      "ep 2: ep_len:895 episode reward: total was -79.040000. running mean: -61.212735\n",
      "ep 2: ep_len:5470 episode reward: total was -766.960000. running mean: -68.270208\n",
      "ep 2: ep_len:865 episode reward: total was -102.330000. running mean: -68.610806\n",
      "ep 2: ep_len:178 episode reward: total was 3.500000. running mean: -67.889698\n",
      "ep 2: ep_len:500 episode reward: total was -47.860000. running mean: -67.689401\n",
      "ep 2: ep_len:505 episode reward: total was -57.270000. running mean: -67.585207\n",
      "ep 2: ep_len:465 episode reward: total was -53.870000. running mean: -67.448055\n",
      "ep 2: ep_len:565 episode reward: total was -31.400000. running mean: -67.087574\n",
      "epsilon:0.353902 episode_count: 2364. steps_count: 1762870.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 3: ep_len:500 episode reward: total was -21.390000. running mean: -66.630598\n",
      "ep 3: ep_len:1120 episode reward: total was -62.490000. running mean: -66.589192\n",
      "ep 3: ep_len:725 episode reward: total was -60.700000. running mean: -66.530300\n",
      "ep 3: ep_len:995 episode reward: total was -78.780000. running mean: -66.652797\n",
      "ep 3: ep_len:545 episode reward: total was -44.410000. running mean: -66.430369\n",
      "ep 3: ep_len:920 episode reward: total was -60.310000. running mean: -66.369166\n",
      "ep 3: ep_len:925 episode reward: total was -62.730000. running mean: -66.332774\n",
      "ep 3: ep_len:635 episode reward: total was -17.760000. running mean: -65.847046\n",
      "ep 3: ep_len:750 episode reward: total was -70.750000. running mean: -65.896076\n",
      "ep 3: ep_len:500 episode reward: total was -24.540000. running mean: -65.482515\n",
      "ep 3: ep_len:500 episode reward: total was -29.410000. running mean: -65.121790\n",
      "ep 3: ep_len:500 episode reward: total was -19.790000. running mean: -64.668472\n",
      "ep 3: ep_len:500 episode reward: total was -31.000000. running mean: -64.331787\n",
      "ep 3: ep_len:840 episode reward: total was -74.120000. running mean: -64.429669\n",
      "ep 3: ep_len:1155 episode reward: total was -67.050000. running mean: -64.455873\n",
      "ep 3: ep_len:500 episode reward: total was -15.870000. running mean: -63.970014\n",
      "ep 3: ep_len:500 episode reward: total was -48.980000. running mean: -63.820114\n",
      "ep 3: ep_len:685 episode reward: total was -57.750000. running mean: -63.759413\n",
      "ep 3: ep_len:163 episode reward: total was 1.000000. running mean: -63.111819\n",
      "ep 3: ep_len:765 episode reward: total was -68.580000. running mean: -63.166500\n",
      "ep 3: ep_len:500 episode reward: total was -38.420000. running mean: -62.919035\n",
      "ep 3: ep_len:1500 episode reward: total was -132.360000. running mean: -63.613445\n",
      "ep 3: ep_len:1085 episode reward: total was -68.640000. running mean: -63.663711\n",
      "ep 3: ep_len:500 episode reward: total was -22.750000. running mean: -63.254574\n",
      "ep 3: ep_len:545 episode reward: total was -32.620000. running mean: -62.948228\n",
      "ep 3: ep_len:1345 episode reward: total was -224.230000. running mean: -64.561046\n",
      "ep 3: ep_len:500 episode reward: total was -22.520000. running mean: -64.140635\n",
      "ep 3: ep_len:14155 episode reward: total was -1019.690000. running mean: -73.696129\n",
      "ep 3: ep_len:760 episode reward: total was -63.660000. running mean: -73.595767\n",
      "ep 3: ep_len:540 episode reward: total was -39.370000. running mean: -73.253510\n",
      "ep 3: ep_len:810 episode reward: total was -48.390000. running mean: -73.004875\n",
      "ep 3: ep_len:242 episode reward: total was 12.500000. running mean: -72.149826\n",
      "ep 3: ep_len:510 episode reward: total was -41.940000. running mean: -71.847728\n",
      "ep 3: ep_len:500 episode reward: total was -5.920000. running mean: -71.188450\n",
      "ep 3: ep_len:725 episode reward: total was -29.920000. running mean: -70.775766\n",
      "ep 3: ep_len:525 episode reward: total was -30.310000. running mean: -70.371108\n",
      "ep 3: ep_len:1120 episode reward: total was -148.930000. running mean: -71.156697\n",
      "ep 3: ep_len:525 episode reward: total was -69.700000. running mean: -71.142130\n",
      "ep 3: ep_len:462 episode reward: total was -9.890000. running mean: -70.529609\n",
      "ep 3: ep_len:798 episode reward: total was -98.920000. running mean: -70.813513\n",
      "ep 3: ep_len:685 episode reward: total was -63.690000. running mean: -70.742278\n",
      "ep 3: ep_len:505 episode reward: total was -34.420000. running mean: -70.379055\n",
      "ep 3: ep_len:610 episode reward: total was -38.860000. running mean: -70.063864\n",
      "ep 3: ep_len:500 episode reward: total was -19.330000. running mean: -69.556526\n",
      "ep 3: ep_len:795 episode reward: total was -65.330000. running mean: -69.514260\n",
      "ep 3: ep_len:19335 episode reward: total was -3649.580000. running mean: -105.314918\n",
      "ep 3: ep_len:710 episode reward: total was -82.430000. running mean: -105.086069\n",
      "ep 3: ep_len:945 episode reward: total was -116.300000. running mean: -105.198208\n",
      "ep 3: ep_len:152 episode reward: total was -2.000000. running mean: -104.166226\n",
      "ep 3: ep_len:795 episode reward: total was -106.740000. running mean: -104.191964\n",
      "ep 3: ep_len:234 episode reward: total was 9.500000. running mean: -103.055044\n",
      "ep 3: ep_len:139 episode reward: total was -3.000000. running mean: -102.054494\n",
      "ep 3: ep_len:815 episode reward: total was -128.770000. running mean: -102.321649\n",
      "ep 3: ep_len:745 episode reward: total was -92.890000. running mean: -102.227332\n",
      "ep 3: ep_len:500 episode reward: total was -30.460000. running mean: -101.509659\n",
      "ep 3: ep_len:660 episode reward: total was -47.210000. running mean: -100.966662\n",
      "ep 3: ep_len:506 episode reward: total was -73.950000. running mean: -100.696496\n",
      "ep 3: ep_len:820 episode reward: total was -54.190000. running mean: -100.231431\n",
      "ep 3: ep_len:500 episode reward: total was -57.870000. running mean: -99.807816\n",
      "ep 3: ep_len:860 episode reward: total was -56.390000. running mean: -99.373638\n",
      "ep 3: ep_len:665 episode reward: total was -57.790000. running mean: -98.957802\n",
      "ep 3: ep_len:560 episode reward: total was -76.700000. running mean: -98.735224\n",
      "ep 3: ep_len:115 episode reward: total was 1.000000. running mean: -97.737872\n",
      "ep 3: ep_len:865 episode reward: total was -83.660000. running mean: -97.597093\n",
      "ep 3: ep_len:505 episode reward: total was -19.470000. running mean: -96.815822\n",
      "ep 3: ep_len:1315 episode reward: total was -167.480000. running mean: -97.522464\n",
      "ep 3: ep_len:550 episode reward: total was -72.680000. running mean: -97.274039\n",
      "ep 3: ep_len:500 episode reward: total was -68.800000. running mean: -96.989299\n",
      "ep 3: ep_len:615 episode reward: total was -55.350000. running mean: -96.572906\n",
      "ep 3: ep_len:805 episode reward: total was -96.380000. running mean: -96.570977\n",
      "ep 3: ep_len:500 episode reward: total was -14.300000. running mean: -95.748267\n",
      "ep 3: ep_len:505 episode reward: total was -27.850000. running mean: -95.069284\n",
      "ep 3: ep_len:500 episode reward: total was -54.680000. running mean: -94.665391\n",
      "ep 3: ep_len:760 episode reward: total was -53.180000. running mean: -94.250537\n",
      "ep 3: ep_len:500 episode reward: total was -25.910000. running mean: -93.567132\n",
      "ep 3: ep_len:525 episode reward: total was -66.150000. running mean: -93.292961\n",
      "ep 3: ep_len:610 episode reward: total was -80.480000. running mean: -93.164831\n",
      "ep 3: ep_len:500 episode reward: total was -72.870000. running mean: -92.961883\n",
      "ep 3: ep_len:655 episode reward: total was -62.370000. running mean: -92.655964\n",
      "ep 3: ep_len:500 episode reward: total was -32.970000. running mean: -92.059104\n",
      "ep 3: ep_len:665 episode reward: total was -66.940000. running mean: -91.807913\n",
      "ep 3: ep_len:535 episode reward: total was -57.710000. running mean: -91.466934\n",
      "ep 3: ep_len:247 episode reward: total was 0.500000. running mean: -90.547265\n",
      "ep 3: ep_len:675 episode reward: total was -65.780000. running mean: -90.299592\n",
      "ep 3: ep_len:570 episode reward: total was -67.590000. running mean: -90.072496\n",
      "ep 3: ep_len:680 episode reward: total was -50.240000. running mean: -89.674171\n",
      "ep 3: ep_len:745 episode reward: total was -100.050000. running mean: -89.777930\n",
      "ep 3: ep_len:830 episode reward: total was -42.230000. running mean: -89.302450\n",
      "ep 3: ep_len:780 episode reward: total was -81.310000. running mean: -89.222526\n",
      "ep 3: ep_len:1705 episode reward: total was -212.260000. running mean: -90.452900\n",
      "ep 3: ep_len:820 episode reward: total was -90.810000. running mean: -90.456471\n",
      "ep 3: ep_len:500 episode reward: total was -20.750000. running mean: -89.759407\n",
      "ep 3: ep_len:500 episode reward: total was -3.000000. running mean: -88.891813\n",
      "ep 3: ep_len:755 episode reward: total was -64.160000. running mean: -88.644495\n",
      "ep 3: ep_len:500 episode reward: total was -23.820000. running mean: -87.996250\n",
      "ep 3: ep_len:970 episode reward: total was -35.980000. running mean: -87.476087\n",
      "ep 3: ep_len:505 episode reward: total was -16.830000. running mean: -86.769626\n",
      "ep 3: ep_len:660 episode reward: total was -44.150000. running mean: -86.343430\n",
      "ep 3: ep_len:685 episode reward: total was -106.230000. running mean: -86.542296\n",
      "ep 3: ep_len:1120 episode reward: total was -147.250000. running mean: -87.149373\n",
      "ep 3: ep_len:545 episode reward: total was -101.980000. running mean: -87.297679\n",
      "ep 3: ep_len:500 episode reward: total was -64.730000. running mean: -87.072002\n",
      "ep 3: ep_len:260 episode reward: total was 12.500000. running mean: -86.076282\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 3: ep_len:560 episode reward: total was -56.500000. running mean: -85.780519\n",
      "ep 3: ep_len:630 episode reward: total was -45.740000. running mean: -85.380114\n",
      "ep 3: ep_len:500 episode reward: total was -33.450000. running mean: -84.860813\n",
      "ep 3: ep_len:251 episode reward: total was 4.500000. running mean: -83.967205\n",
      "ep 3: ep_len:630 episode reward: total was -44.730000. running mean: -83.574833\n",
      "ep 3: ep_len:505 episode reward: total was -20.260000. running mean: -82.941685\n",
      "ep 3: ep_len:680 episode reward: total was -25.400000. running mean: -82.366268\n",
      "ep 3: ep_len:500 episode reward: total was -6.860000. running mean: -81.611205\n",
      "ep 3: ep_len:875 episode reward: total was -83.990000. running mean: -81.634993\n",
      "ep 3: ep_len:1190 episode reward: total was -68.600000. running mean: -81.504643\n",
      "ep 3: ep_len:500 episode reward: total was -35.870000. running mean: -81.048297\n",
      "ep 3: ep_len:1450 episode reward: total was -244.830000. running mean: -82.686114\n",
      "ep 3: ep_len:720 episode reward: total was -67.290000. running mean: -82.532153\n",
      "ep 3: ep_len:880 episode reward: total was -78.370000. running mean: -82.490531\n",
      "ep 3: ep_len:610 episode reward: total was -26.920000. running mean: -81.934826\n",
      "ep 3: ep_len:560 episode reward: total was -76.700000. running mean: -81.882477\n",
      "ep 3: ep_len:750 episode reward: total was -50.150000. running mean: -81.565153\n",
      "ep 3: ep_len:750 episode reward: total was -50.060000. running mean: -81.250101\n",
      "ep 3: ep_len:925 episode reward: total was -89.100000. running mean: -81.328600\n",
      "ep 3: ep_len:500 episode reward: total was -43.870000. running mean: -80.954014\n",
      "ep 3: ep_len:835 episode reward: total was -82.950000. running mean: -80.973974\n",
      "ep 3: ep_len:96 episode reward: total was 5.500000. running mean: -80.109234\n",
      "ep 3: ep_len:505 episode reward: total was -69.890000. running mean: -80.007042\n",
      "ep 3: ep_len:930 episode reward: total was -85.540000. running mean: -80.062371\n",
      "ep 3: ep_len:780 episode reward: total was -59.580000. running mean: -79.857548\n",
      "ep 3: ep_len:680 episode reward: total was -107.250000. running mean: -80.131472\n",
      "ep 3: ep_len:720 episode reward: total was -43.790000. running mean: -79.768058\n",
      "ep 3: ep_len:1440 episode reward: total was -163.820000. running mean: -80.608577\n",
      "ep 3: ep_len:1545 episode reward: total was -200.980000. running mean: -81.812291\n",
      "ep 3: ep_len:500 episode reward: total was -26.300000. running mean: -81.257168\n",
      "ep 3: ep_len:500 episode reward: total was -79.480000. running mean: -81.239397\n",
      "ep 3: ep_len:815 episode reward: total was -42.990000. running mean: -80.856903\n",
      "ep 3: ep_len:2550 episode reward: total was -276.740000. running mean: -82.815734\n",
      "ep 3: ep_len:505 episode reward: total was -15.800000. running mean: -82.145576\n",
      "ep 3: ep_len:900 episode reward: total was -44.810000. running mean: -81.772221\n",
      "ep 3: ep_len:1540 episode reward: total was -165.610000. running mean: -82.610598\n",
      "ep 3: ep_len:535 episode reward: total was -33.870000. running mean: -82.123192\n",
      "ep 3: ep_len:500 episode reward: total was -32.410000. running mean: -81.626060\n",
      "ep 3: ep_len:500 episode reward: total was 13.000000. running mean: -80.679800\n",
      "ep 3: ep_len:500 episode reward: total was -38.650000. running mean: -80.259502\n",
      "ep 3: ep_len:835 episode reward: total was -66.540000. running mean: -80.122307\n",
      "ep 3: ep_len:510 episode reward: total was -36.880000. running mean: -79.689884\n",
      "ep 3: ep_len:500 episode reward: total was -23.910000. running mean: -79.132085\n",
      "ep 3: ep_len:670 episode reward: total was -49.210000. running mean: -78.832864\n",
      "ep 3: ep_len:500 episode reward: total was -92.460000. running mean: -78.969135\n",
      "ep 3: ep_len:550 episode reward: total was -38.340000. running mean: -78.562844\n",
      "ep 3: ep_len:237 episode reward: total was -4.000000. running mean: -77.817216\n",
      "ep 3: ep_len:505 episode reward: total was -35.120000. running mean: -77.390243\n",
      "ep 3: ep_len:500 episode reward: total was -59.280000. running mean: -77.209141\n",
      "ep 3: ep_len:830 episode reward: total was -74.140000. running mean: -77.178450\n",
      "ep 3: ep_len:1255 episode reward: total was -106.060000. running mean: -77.467265\n",
      "ep 3: ep_len:790 episode reward: total was -65.100000. running mean: -77.343592\n",
      "ep 3: ep_len:317 episode reward: total was -10.820000. running mean: -76.678357\n",
      "ep 3: ep_len:975 episode reward: total was -55.950000. running mean: -76.471073\n",
      "ep 3: ep_len:500 episode reward: total was 6.260000. running mean: -75.643762\n",
      "ep 3: ep_len:660 episode reward: total was -59.820000. running mean: -75.485525\n",
      "ep 3: ep_len:595 episode reward: total was -84.390000. running mean: -75.574569\n",
      "ep 3: ep_len:915 episode reward: total was -54.090000. running mean: -75.359724\n",
      "ep 3: ep_len:815 episode reward: total was -35.830000. running mean: -74.964426\n",
      "ep 3: ep_len:495 episode reward: total was -10.880000. running mean: -74.323582\n",
      "ep 3: ep_len:500 episode reward: total was -29.680000. running mean: -73.877146\n",
      "ep 3: ep_len:730 episode reward: total was -55.120000. running mean: -73.689575\n",
      "ep 3: ep_len:505 episode reward: total was -27.330000. running mean: -73.225979\n",
      "ep 3: ep_len:1060 episode reward: total was -110.100000. running mean: -73.594719\n",
      "ep 3: ep_len:500 episode reward: total was -26.670000. running mean: -73.125472\n",
      "ep 3: ep_len:685 episode reward: total was -63.810000. running mean: -73.032317\n",
      "ep 3: ep_len:770 episode reward: total was -63.640000. running mean: -72.938394\n",
      "ep 3: ep_len:177 episode reward: total was 4.500000. running mean: -72.164010\n",
      "ep 3: ep_len:715 episode reward: total was -61.790000. running mean: -72.060270\n",
      "ep 3: ep_len:680 episode reward: total was -33.000000. running mean: -71.669668\n",
      "ep 3: ep_len:500 episode reward: total was -18.300000. running mean: -71.135971\n",
      "ep 3: ep_len:505 episode reward: total was -60.760000. running mean: -71.032211\n",
      "ep 3: ep_len:505 episode reward: total was -62.670000. running mean: -70.948589\n",
      "ep 3: ep_len:540 episode reward: total was -26.500000. running mean: -70.504103\n",
      "ep 3: ep_len:505 episode reward: total was -36.240000. running mean: -70.161462\n",
      "ep 3: ep_len:545 episode reward: total was -64.500000. running mean: -70.104847\n",
      "ep 3: ep_len:500 episode reward: total was -12.290000. running mean: -69.526699\n",
      "ep 3: ep_len:500 episode reward: total was -25.580000. running mean: -69.087232\n",
      "ep 3: ep_len:590 episode reward: total was -43.800000. running mean: -68.834360\n",
      "ep 3: ep_len:500 episode reward: total was -20.900000. running mean: -68.355016\n",
      "ep 3: ep_len:500 episode reward: total was -34.890000. running mean: -68.020366\n",
      "ep 3: ep_len:555 episode reward: total was -31.960000. running mean: -67.659762\n",
      "ep 3: ep_len:625 episode reward: total was -17.150000. running mean: -67.154665\n",
      "ep 3: ep_len:705 episode reward: total was -43.080000. running mean: -66.913918\n",
      "ep 3: ep_len:805 episode reward: total was -50.960000. running mean: -66.754379\n",
      "ep 3: ep_len:1050 episode reward: total was -177.210000. running mean: -67.858935\n",
      "ep 3: ep_len:500 episode reward: total was -19.670000. running mean: -67.377046\n",
      "ep 3: ep_len:1810 episode reward: total was -309.010000. running mean: -69.793375\n",
      "ep 3: ep_len:382 episode reward: total was -16.500000. running mean: -69.260441\n",
      "ep 3: ep_len:600 episode reward: total was -42.770000. running mean: -68.995537\n",
      "ep 3: ep_len:950 episode reward: total was -64.600000. running mean: -68.951582\n",
      "ep 3: ep_len:745 episode reward: total was -61.180000. running mean: -68.873866\n",
      "ep 3: ep_len:980 episode reward: total was -55.140000. running mean: -68.736527\n",
      "ep 3: ep_len:305 episode reward: total was 3.510000. running mean: -68.014062\n",
      "ep 3: ep_len:810 episode reward: total was -59.340000. running mean: -67.927321\n",
      "ep 3: ep_len:575 episode reward: total was -38.290000. running mean: -67.630948\n",
      "ep 3: ep_len:520 episode reward: total was -31.970000. running mean: -67.274339\n",
      "ep 3: ep_len:505 episode reward: total was -46.800000. running mean: -67.069595\n",
      "ep 3: ep_len:760 episode reward: total was -65.680000. running mean: -67.055699\n",
      "ep 3: ep_len:4400 episode reward: total was -633.900000. running mean: -72.724142\n",
      "ep 3: ep_len:500 episode reward: total was -12.400000. running mean: -72.120901\n",
      "ep 3: ep_len:950 episode reward: total was -44.420000. running mean: -71.843892\n",
      "ep 3: ep_len:1005 episode reward: total was -57.030000. running mean: -71.695753\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 3: ep_len:555 episode reward: total was -63.060000. running mean: -71.609395\n",
      "ep 3: ep_len:173 episode reward: total was -2.000000. running mean: -70.913301\n",
      "ep 3: ep_len:500 episode reward: total was -30.260000. running mean: -70.506768\n",
      "ep 3: ep_len:650 episode reward: total was -43.680000. running mean: -70.238501\n",
      "ep 3: ep_len:500 episode reward: total was -30.320000. running mean: -69.839316\n",
      "ep 3: ep_len:705 episode reward: total was -84.490000. running mean: -69.985823\n",
      "ep 3: ep_len:615 episode reward: total was -43.320000. running mean: -69.719164\n",
      "ep 3: ep_len:680 episode reward: total was -45.450000. running mean: -69.476473\n",
      "ep 3: ep_len:865 episode reward: total was -77.430000. running mean: -69.556008\n",
      "ep 3: ep_len:990 episode reward: total was -66.440000. running mean: -69.524848\n",
      "ep 3: ep_len:720 episode reward: total was -43.110000. running mean: -69.260699\n",
      "ep 3: ep_len:500 episode reward: total was -33.350000. running mean: -68.901592\n",
      "ep 3: ep_len:965 episode reward: total was -61.740000. running mean: -68.829977\n",
      "ep 3: ep_len:500 episode reward: total was -51.690000. running mean: -68.658577\n",
      "ep 3: ep_len:500 episode reward: total was -27.990000. running mean: -68.251891\n",
      "ep 3: ep_len:635 episode reward: total was -46.220000. running mean: -68.031572\n",
      "ep 3: ep_len:500 episode reward: total was -28.460000. running mean: -67.635856\n",
      "ep 3: ep_len:500 episode reward: total was -28.920000. running mean: -67.248698\n",
      "ep 3: ep_len:500 episode reward: total was -29.960000. running mean: -66.875811\n",
      "ep 3: ep_len:500 episode reward: total was -26.330000. running mean: -66.470353\n",
      "ep 3: ep_len:500 episode reward: total was -15.840000. running mean: -65.964049\n",
      "ep 3: ep_len:880 episode reward: total was -68.990000. running mean: -65.994309\n",
      "ep 3: ep_len:680 episode reward: total was -41.220000. running mean: -65.746566\n",
      "ep 3: ep_len:695 episode reward: total was -84.690000. running mean: -65.936000\n",
      "ep 3: ep_len:510 episode reward: total was -69.320000. running mean: -65.969840\n",
      "ep 3: ep_len:775 episode reward: total was -41.530000. running mean: -65.725442\n",
      "ep 3: ep_len:1765 episode reward: total was -187.380000. running mean: -66.941987\n",
      "ep 3: ep_len:790 episode reward: total was -48.340000. running mean: -66.755967\n",
      "ep 3: ep_len:500 episode reward: total was 15.500000. running mean: -65.933408\n",
      "ep 3: ep_len:705 episode reward: total was -63.280000. running mean: -65.906874\n",
      "ep 3: ep_len:500 episode reward: total was -41.800000. running mean: -65.665805\n",
      "ep 3: ep_len:500 episode reward: total was -33.910000. running mean: -65.348247\n",
      "ep 3: ep_len:1145 episode reward: total was -72.050000. running mean: -65.415264\n",
      "ep 3: ep_len:535 episode reward: total was -49.970000. running mean: -65.260812\n",
      "ep 3: ep_len:500 episode reward: total was -25.320000. running mean: -64.861403\n",
      "ep 3: ep_len:630 episode reward: total was -42.860000. running mean: -64.641389\n",
      "ep 3: ep_len:500 episode reward: total was -28.950000. running mean: -64.284476\n",
      "ep 3: ep_len:329 episode reward: total was -20.890000. running mean: -63.850531\n",
      "ep 3: ep_len:505 episode reward: total was -32.400000. running mean: -63.536026\n",
      "ep 3: ep_len:70 episode reward: total was 1.000000. running mean: -62.890665\n",
      "ep 3: ep_len:825 episode reward: total was -60.500000. running mean: -62.866759\n",
      "ep 3: ep_len:500 episode reward: total was -39.110000. running mean: -62.629191\n",
      "ep 3: ep_len:505 episode reward: total was -15.310000. running mean: -62.155999\n",
      "ep 3: ep_len:1076 episode reward: total was -96.860000. running mean: -62.503039\n",
      "ep 3: ep_len:1025 episode reward: total was -110.600000. running mean: -62.984009\n",
      "ep 3: ep_len:210 episode reward: total was -1.500000. running mean: -62.369169\n",
      "ep 3: ep_len:685 episode reward: total was -40.040000. running mean: -62.145877\n",
      "ep 3: ep_len:730 episode reward: total was -87.470000. running mean: -62.399118\n",
      "ep 3: ep_len:237 episode reward: total was 1.000000. running mean: -61.765127\n",
      "ep 3: ep_len:116 episode reward: total was 6.000000. running mean: -61.087476\n",
      "ep 3: ep_len:950 episode reward: total was -55.300000. running mean: -61.029601\n",
      "ep 3: ep_len:500 episode reward: total was -24.370000. running mean: -60.663005\n",
      "ep 3: ep_len:500 episode reward: total was -32.640000. running mean: -60.382775\n",
      "ep 3: ep_len:510 episode reward: total was -23.790000. running mean: -60.016847\n",
      "ep 3: ep_len:505 episode reward: total was -10.820000. running mean: -59.524879\n",
      "ep 3: ep_len:132 episode reward: total was -4.500000. running mean: -58.974630\n",
      "ep 3: ep_len:223 episode reward: total was 4.500000. running mean: -58.339884\n",
      "ep 3: ep_len:500 episode reward: total was -70.790000. running mean: -58.464385\n",
      "ep 3: ep_len:715 episode reward: total was -68.280000. running mean: -58.562541\n",
      "ep 3: ep_len:780 episode reward: total was -25.460000. running mean: -58.231516\n",
      "ep 3: ep_len:299 episode reward: total was -2.500000. running mean: -57.674200\n",
      "ep 3: ep_len:510 episode reward: total was 1.000000. running mean: -57.087458\n",
      "ep 3: ep_len:500 episode reward: total was -7.390000. running mean: -56.590484\n",
      "ep 3: ep_len:500 episode reward: total was -4.500000. running mean: -56.069579\n",
      "ep 3: ep_len:570 episode reward: total was -53.420000. running mean: -56.043083\n",
      "ep 3: ep_len:163 episode reward: total was 5.500000. running mean: -55.427652\n",
      "ep 3: ep_len:500 episode reward: total was -28.870000. running mean: -55.162076\n",
      "ep 3: ep_len:500 episode reward: total was -51.140000. running mean: -55.121855\n",
      "ep 3: ep_len:500 episode reward: total was -41.930000. running mean: -54.989936\n",
      "ep 3: ep_len:915 episode reward: total was -52.910000. running mean: -54.969137\n",
      "ep 3: ep_len:940 episode reward: total was -52.520000. running mean: -54.944646\n",
      "ep 3: ep_len:1225 episode reward: total was -182.920000. running mean: -56.224399\n",
      "ep 3: ep_len:845 episode reward: total was -72.190000. running mean: -56.384055\n",
      "ep 3: ep_len:500 episode reward: total was -49.550000. running mean: -56.315715\n",
      "ep 3: ep_len:500 episode reward: total was -35.440000. running mean: -56.106958\n",
      "ep 3: ep_len:294 episode reward: total was -4.000000. running mean: -55.585888\n",
      "ep 3: ep_len:660 episode reward: total was -44.180000. running mean: -55.471829\n",
      "ep 3: ep_len:1050 episode reward: total was -134.300000. running mean: -56.260111\n",
      "ep 3: ep_len:500 episode reward: total was -13.760000. running mean: -55.835110\n",
      "ep 3: ep_len:665 episode reward: total was -60.900000. running mean: -55.885759\n",
      "ep 3: ep_len:805 episode reward: total was -78.770000. running mean: -56.114601\n",
      "ep 3: ep_len:770 episode reward: total was -115.150000. running mean: -56.704955\n",
      "ep 3: ep_len:1605 episode reward: total was -210.710000. running mean: -58.245005\n",
      "ep 3: ep_len:1050 episode reward: total was -72.720000. running mean: -58.389755\n",
      "ep 3: ep_len:535 episode reward: total was -26.820000. running mean: -58.074058\n",
      "ep 3: ep_len:520 episode reward: total was -51.530000. running mean: -58.008617\n",
      "ep 3: ep_len:620 episode reward: total was -43.740000. running mean: -57.865931\n",
      "ep 3: ep_len:745 episode reward: total was -75.320000. running mean: -58.040472\n",
      "ep 3: ep_len:1320 episode reward: total was -64.170000. running mean: -58.101767\n",
      "ep 3: ep_len:500 episode reward: total was -27.320000. running mean: -57.793949\n",
      "ep 3: ep_len:500 episode reward: total was -53.160000. running mean: -57.747610\n",
      "ep 3: ep_len:720 episode reward: total was -50.080000. running mean: -57.670934\n",
      "ep 3: ep_len:119 episode reward: total was -4.500000. running mean: -57.139224\n",
      "ep 3: ep_len:500 episode reward: total was -22.210000. running mean: -56.789932\n",
      "ep 3: ep_len:790 episode reward: total was -83.310000. running mean: -57.055133\n",
      "ep 3: ep_len:730 episode reward: total was -49.540000. running mean: -56.979982\n",
      "ep 3: ep_len:545 episode reward: total was -31.080000. running mean: -56.720982\n",
      "ep 3: ep_len:600 episode reward: total was -73.070000. running mean: -56.884472\n",
      "ep 3: ep_len:271 episode reward: total was 1.500000. running mean: -56.300627\n",
      "ep 3: ep_len:400 episode reward: total was -1.000000. running mean: -55.747621\n",
      "ep 3: ep_len:735 episode reward: total was -69.280000. running mean: -55.882945\n",
      "ep 3: ep_len:505 episode reward: total was -24.900000. running mean: -55.573115\n",
      "ep 3: ep_len:580 episode reward: total was -52.420000. running mean: -55.541584\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 3: ep_len:575 episode reward: total was -66.570000. running mean: -55.651868\n",
      "ep 3: ep_len:510 episode reward: total was -38.690000. running mean: -55.482250\n",
      "ep 3: ep_len:500 episode reward: total was -35.000000. running mean: -55.277427\n",
      "ep 3: ep_len:505 episode reward: total was -23.480000. running mean: -54.959453\n",
      "ep 3: ep_len:680 episode reward: total was -67.370000. running mean: -55.083558\n",
      "ep 3: ep_len:850 episode reward: total was -65.730000. running mean: -55.190023\n",
      "ep 3: ep_len:805 episode reward: total was -79.240000. running mean: -55.430523\n",
      "ep 3: ep_len:1040 episode reward: total was -65.570000. running mean: -55.531917\n",
      "ep 3: ep_len:500 episode reward: total was -29.350000. running mean: -55.270098\n",
      "ep 3: ep_len:995 episode reward: total was -71.220000. running mean: -55.429597\n",
      "ep 3: ep_len:845 episode reward: total was -84.210000. running mean: -55.717401\n",
      "ep 3: ep_len:680 episode reward: total was -31.950000. running mean: -55.479727\n",
      "ep 3: ep_len:675 episode reward: total was -42.370000. running mean: -55.348630\n",
      "ep 3: ep_len:500 episode reward: total was -54.870000. running mean: -55.343844\n",
      "ep 3: ep_len:580 episode reward: total was -64.540000. running mean: -55.435805\n",
      "ep 3: ep_len:2190 episode reward: total was -354.990000. running mean: -58.431347\n",
      "ep 3: ep_len:1205 episode reward: total was -110.210000. running mean: -58.949134\n",
      "ep 3: ep_len:500 episode reward: total was -41.500000. running mean: -58.774642\n",
      "ep 3: ep_len:630 episode reward: total was -44.240000. running mean: -58.629296\n",
      "ep 3: ep_len:940 episode reward: total was -56.730000. running mean: -58.610303\n",
      "ep 3: ep_len:500 episode reward: total was -60.170000. running mean: -58.625900\n",
      "ep 3: ep_len:740 episode reward: total was -53.600000. running mean: -58.575641\n",
      "ep 3: ep_len:505 episode reward: total was -54.070000. running mean: -58.530584\n",
      "ep 3: ep_len:318 episode reward: total was 3.000000. running mean: -57.915279\n",
      "ep 3: ep_len:505 episode reward: total was -49.050000. running mean: -57.826626\n",
      "ep 3: ep_len:500 episode reward: total was -27.500000. running mean: -57.523360\n",
      "ep 3: ep_len:1410 episode reward: total was -182.030000. running mean: -58.768426\n",
      "ep 3: ep_len:1095 episode reward: total was -139.750000. running mean: -59.578242\n",
      "ep 3: ep_len:555 episode reward: total was -87.790000. running mean: -59.860359\n",
      "ep 3: ep_len:515 episode reward: total was -96.470000. running mean: -60.226456\n",
      "ep 3: ep_len:505 episode reward: total was -16.750000. running mean: -59.791691\n",
      "ep 3: ep_len:505 episode reward: total was -52.630000. running mean: -59.720074\n",
      "ep 3: ep_len:755 episode reward: total was -69.730000. running mean: -59.820174\n",
      "ep 3: ep_len:550 episode reward: total was -40.330000. running mean: -59.625272\n",
      "ep 3: ep_len:189 episode reward: total was 4.000000. running mean: -58.989019\n",
      "ep 3: ep_len:740 episode reward: total was -80.780000. running mean: -59.206929\n",
      "ep 3: ep_len:510 episode reward: total was -38.470000. running mean: -58.999560\n",
      "ep 3: ep_len:590 episode reward: total was -34.220000. running mean: -58.751764\n",
      "ep 3: ep_len:505 episode reward: total was -48.420000. running mean: -58.648446\n",
      "ep 3: ep_len:500 episode reward: total was 10.500000. running mean: -57.956962\n",
      "ep 3: ep_len:500 episode reward: total was -3.260000. running mean: -57.409992\n",
      "ep 3: ep_len:945 episode reward: total was -61.290000. running mean: -57.448792\n",
      "ep 3: ep_len:670 episode reward: total was -40.420000. running mean: -57.278504\n",
      "ep 3: ep_len:535 episode reward: total was -44.400000. running mean: -57.149719\n",
      "ep 3: ep_len:630 episode reward: total was -24.400000. running mean: -56.822222\n",
      "ep 3: ep_len:505 episode reward: total was -20.330000. running mean: -56.457300\n",
      "ep 3: ep_len:373 episode reward: total was -16.230000. running mean: -56.055027\n",
      "ep 3: ep_len:705 episode reward: total was -46.080000. running mean: -55.955277\n",
      "ep 3: ep_len:545 episode reward: total was -48.450000. running mean: -55.880224\n",
      "ep 3: ep_len:845 episode reward: total was -65.740000. running mean: -55.978822\n",
      "ep 3: ep_len:500 episode reward: total was -52.360000. running mean: -55.942633\n",
      "ep 3: ep_len:457 episode reward: total was -65.280000. running mean: -56.036007\n",
      "ep 3: ep_len:500 episode reward: total was -41.000000. running mean: -55.885647\n",
      "ep 3: ep_len:755 episode reward: total was -47.380000. running mean: -55.800591\n",
      "ep 3: ep_len:1565 episode reward: total was -130.720000. running mean: -56.549785\n",
      "ep 3: ep_len:670 episode reward: total was -30.870000. running mean: -56.292987\n",
      "ep 3: ep_len:500 episode reward: total was -45.140000. running mean: -56.181457\n",
      "ep 3: ep_len:705 episode reward: total was -64.780000. running mean: -56.267442\n",
      "ep 3: ep_len:259 episode reward: total was -7.000000. running mean: -55.774768\n",
      "ep 3: ep_len:965 episode reward: total was -120.330000. running mean: -56.420320\n",
      "ep 3: ep_len:1110 episode reward: total was -108.670000. running mean: -56.942817\n",
      "ep 3: ep_len:500 episode reward: total was -26.820000. running mean: -56.641589\n",
      "ep 3: ep_len:690 episode reward: total was -25.120000. running mean: -56.326373\n",
      "ep 3: ep_len:235 episode reward: total was 5.500000. running mean: -55.708109\n",
      "ep 3: ep_len:500 episode reward: total was -18.750000. running mean: -55.338528\n",
      "ep 3: ep_len:725 episode reward: total was -80.410000. running mean: -55.589243\n",
      "ep 3: ep_len:745 episode reward: total was -31.320000. running mean: -55.346550\n",
      "ep 3: ep_len:525 episode reward: total was -83.380000. running mean: -55.626885\n",
      "ep 3: ep_len:2095 episode reward: total was -322.060000. running mean: -58.291216\n",
      "ep 3: ep_len:500 episode reward: total was -14.800000. running mean: -57.856304\n",
      "ep 3: ep_len:500 episode reward: total was -16.840000. running mean: -57.446141\n",
      "ep 3: ep_len:1515 episode reward: total was -188.920000. running mean: -58.760880\n",
      "ep 3: ep_len:505 episode reward: total was -25.860000. running mean: -58.431871\n",
      "ep 3: ep_len:735 episode reward: total was -78.370000. running mean: -58.631252\n",
      "ep 3: ep_len:730 episode reward: total was -63.350000. running mean: -58.678440\n",
      "ep 3: ep_len:1305 episode reward: total was -183.920000. running mean: -59.930855\n",
      "ep 3: ep_len:1030 episode reward: total was -134.990000. running mean: -60.681447\n",
      "ep 3: ep_len:1725 episode reward: total was -146.990000. running mean: -61.544532\n",
      "ep 3: ep_len:500 episode reward: total was -47.710000. running mean: -61.406187\n",
      "ep 3: ep_len:515 episode reward: total was -52.640000. running mean: -61.318525\n",
      "ep 3: ep_len:550 episode reward: total was -63.560000. running mean: -61.340940\n",
      "ep 3: ep_len:805 episode reward: total was -57.630000. running mean: -61.303830\n",
      "ep 3: ep_len:685 episode reward: total was -50.700000. running mean: -61.197792\n",
      "ep 3: ep_len:214 episode reward: total was -0.500000. running mean: -60.590814\n",
      "ep 3: ep_len:152 episode reward: total was -2.500000. running mean: -60.009906\n",
      "ep 3: ep_len:850 episode reward: total was -62.990000. running mean: -60.039707\n",
      "ep 3: ep_len:241 episode reward: total was 3.000000. running mean: -59.409310\n",
      "ep 3: ep_len:500 episode reward: total was 3.500000. running mean: -58.780217\n",
      "ep 3: ep_len:1025 episode reward: total was -32.420000. running mean: -58.516615\n",
      "ep 3: ep_len:505 episode reward: total was -48.730000. running mean: -58.418748\n",
      "ep 3: ep_len:329 episode reward: total was -6.500000. running mean: -57.899561\n",
      "ep 3: ep_len:505 episode reward: total was 0.190000. running mean: -57.318665\n",
      "ep 3: ep_len:1110 episode reward: total was -56.770000. running mean: -57.313179\n",
      "ep 3: ep_len:500 episode reward: total was -31.980000. running mean: -57.059847\n",
      "ep 3: ep_len:205 episode reward: total was -5.000000. running mean: -56.539248\n",
      "ep 3: ep_len:1095 episode reward: total was -96.810000. running mean: -56.941956\n",
      "ep 3: ep_len:680 episode reward: total was -105.230000. running mean: -57.424836\n",
      "ep 3: ep_len:207 episode reward: total was 4.000000. running mean: -56.810588\n",
      "ep 3: ep_len:500 episode reward: total was -40.390000. running mean: -56.646382\n",
      "ep 3: ep_len:875 episode reward: total was -51.170000. running mean: -56.591618\n",
      "ep 3: ep_len:735 episode reward: total was -68.530000. running mean: -56.711002\n",
      "ep 3: ep_len:505 episode reward: total was -46.540000. running mean: -56.609292\n",
      "ep 3: ep_len:510 episode reward: total was -50.540000. running mean: -56.548599\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 3: ep_len:795 episode reward: total was -50.980000. running mean: -56.492913\n",
      "ep 3: ep_len:500 episode reward: total was -23.290000. running mean: -56.160884\n",
      "ep 3: ep_len:1015 episode reward: total was -104.070000. running mean: -56.639975\n",
      "ep 3: ep_len:1675 episode reward: total was -200.740000. running mean: -58.080975\n",
      "ep 3: ep_len:500 episode reward: total was -14.790000. running mean: -57.648066\n",
      "ep 3: ep_len:520 episode reward: total was -53.630000. running mean: -57.607885\n",
      "ep 3: ep_len:800 episode reward: total was -57.930000. running mean: -57.611106\n",
      "ep 3: ep_len:500 episode reward: total was -24.440000. running mean: -57.279395\n",
      "ep 3: ep_len:1305 episode reward: total was -138.740000. running mean: -58.094001\n",
      "ep 3: ep_len:505 episode reward: total was -67.690000. running mean: -58.189961\n",
      "ep 3: ep_len:585 episode reward: total was -32.130000. running mean: -57.929362\n",
      "ep 3: ep_len:500 episode reward: total was -31.350000. running mean: -57.663568\n",
      "ep 3: ep_len:821 episode reward: total was -73.550000. running mean: -57.822432\n",
      "ep 3: ep_len:940 episode reward: total was -58.770000. running mean: -57.831908\n",
      "ep 3: ep_len:685 episode reward: total was -61.790000. running mean: -57.871489\n",
      "ep 3: ep_len:246 episode reward: total was 9.500000. running mean: -57.197774\n",
      "ep 3: ep_len:500 episode reward: total was -74.950000. running mean: -57.375296\n",
      "ep 3: ep_len:640 episode reward: total was -72.480000. running mean: -57.526343\n",
      "ep 3: ep_len:900 episode reward: total was -64.880000. running mean: -57.599880\n",
      "ep 3: ep_len:715 episode reward: total was -66.290000. running mean: -57.686781\n",
      "ep 3: ep_len:500 episode reward: total was -38.530000. running mean: -57.495213\n",
      "ep 3: ep_len:550 episode reward: total was -51.400000. running mean: -57.434261\n",
      "ep 3: ep_len:1185 episode reward: total was -103.300000. running mean: -57.892918\n",
      "ep 3: ep_len:765 episode reward: total was -83.330000. running mean: -58.147289\n",
      "ep 3: ep_len:500 episode reward: total was -37.120000. running mean: -57.937016\n",
      "ep 3: ep_len:605 episode reward: total was -70.030000. running mean: -58.057946\n",
      "ep 3: ep_len:426 episode reward: total was -7.500000. running mean: -57.552367\n",
      "ep 3: ep_len:500 episode reward: total was -0.750000. running mean: -56.984343\n",
      "ep 3: ep_len:500 episode reward: total was -50.830000. running mean: -56.922800\n",
      "ep 3: ep_len:500 episode reward: total was -23.340000. running mean: -56.586972\n",
      "ep 3: ep_len:500 episode reward: total was -11.850000. running mean: -56.139602\n",
      "ep 3: ep_len:600 episode reward: total was -48.310000. running mean: -56.061306\n",
      "ep 3: ep_len:505 episode reward: total was -19.380000. running mean: -55.694493\n",
      "ep 3: ep_len:500 episode reward: total was -16.240000. running mean: -55.299948\n",
      "ep 3: ep_len:660 episode reward: total was -54.280000. running mean: -55.289748\n",
      "ep 3: ep_len:755 episode reward: total was -65.690000. running mean: -55.393751\n",
      "ep 3: ep_len:505 episode reward: total was -49.050000. running mean: -55.330313\n",
      "ep 3: ep_len:700 episode reward: total was -52.670000. running mean: -55.303710\n",
      "ep 3: ep_len:645 episode reward: total was -40.000000. running mean: -55.150673\n",
      "ep 3: ep_len:500 episode reward: total was -38.400000. running mean: -54.983166\n",
      "ep 3: ep_len:845 episode reward: total was -66.470000. running mean: -55.098035\n",
      "ep 3: ep_len:1080 episode reward: total was -62.650000. running mean: -55.173554\n",
      "ep 3: ep_len:990 episode reward: total was -116.730000. running mean: -55.789119\n",
      "ep 3: ep_len:570 episode reward: total was -52.600000. running mean: -55.757228\n",
      "ep 3: ep_len:515 episode reward: total was -47.810000. running mean: -55.677755\n",
      "ep 3: ep_len:1075 episode reward: total was -141.760000. running mean: -56.538578\n",
      "ep 3: ep_len:658 episode reward: total was -81.510000. running mean: -56.788292\n",
      "ep 3: ep_len:755 episode reward: total was -36.330000. running mean: -56.583709\n",
      "ep 3: ep_len:530 episode reward: total was -35.350000. running mean: -56.371372\n",
      "ep 3: ep_len:585 episode reward: total was -53.910000. running mean: -56.346758\n",
      "ep 3: ep_len:505 episode reward: total was -24.930000. running mean: -56.032591\n",
      "ep 3: ep_len:505 episode reward: total was -65.730000. running mean: -56.129565\n",
      "ep 3: ep_len:500 episode reward: total was -16.840000. running mean: -55.736669\n",
      "ep 3: ep_len:665 episode reward: total was -69.320000. running mean: -55.872503\n",
      "ep 3: ep_len:505 episode reward: total was -13.290000. running mean: -55.446678\n",
      "ep 3: ep_len:166 episode reward: total was -1.500000. running mean: -54.907211\n",
      "ep 3: ep_len:201 episode reward: total was 7.000000. running mean: -54.288139\n",
      "ep 3: ep_len:570 episode reward: total was -50.420000. running mean: -54.249457\n",
      "ep 3: ep_len:510 episode reward: total was -50.020000. running mean: -54.207163\n",
      "ep 3: ep_len:940 episode reward: total was -86.190000. running mean: -54.526991\n",
      "ep 3: ep_len:1035 episode reward: total was -38.880000. running mean: -54.370521\n",
      "ep 3: ep_len:505 episode reward: total was -17.500000. running mean: -54.001816\n",
      "ep 3: ep_len:127 episode reward: total was 2.000000. running mean: -53.441798\n",
      "ep 3: ep_len:510 episode reward: total was -47.570000. running mean: -53.383080\n",
      "ep 3: ep_len:720 episode reward: total was -43.050000. running mean: -53.279749\n",
      "ep 3: ep_len:500 episode reward: total was -33.450000. running mean: -53.081452\n",
      "ep 3: ep_len:680 episode reward: total was -50.170000. running mean: -53.052337\n",
      "ep 3: ep_len:500 episode reward: total was -33.260000. running mean: -52.854414\n",
      "ep 3: ep_len:1205 episode reward: total was -122.360000. running mean: -53.549469\n",
      "ep 3: ep_len:650 episode reward: total was -79.030000. running mean: -53.804275\n",
      "ep 3: ep_len:850 episode reward: total was -95.510000. running mean: -54.221332\n",
      "ep 3: ep_len:477 episode reward: total was -19.920000. running mean: -53.878319\n",
      "ep 3: ep_len:500 episode reward: total was -38.370000. running mean: -53.723236\n",
      "ep 3: ep_len:500 episode reward: total was -20.440000. running mean: -53.390403\n",
      "ep 3: ep_len:42450 episode reward: total was -8072.650000. running mean: -133.582999\n",
      "ep 3: ep_len:840 episode reward: total was -143.290000. running mean: -133.680069\n",
      "ep 3: ep_len:500 episode reward: total was -53.310000. running mean: -132.876368\n",
      "ep 3: ep_len:500 episode reward: total was -55.410000. running mean: -132.101705\n",
      "ep 3: ep_len:565 episode reward: total was -32.860000. running mean: -131.109288\n",
      "ep 3: ep_len:595 episode reward: total was -95.300000. running mean: -130.751195\n",
      "ep 3: ep_len:1030 episode reward: total was -137.920000. running mean: -130.822883\n",
      "ep 3: ep_len:1095 episode reward: total was -156.440000. running mean: -131.079054\n",
      "ep 3: ep_len:449 episode reward: total was -44.480000. running mean: -130.213064\n",
      "ep 3: ep_len:358 episode reward: total was -30.500000. running mean: -129.215933\n",
      "ep 3: ep_len:555 episode reward: total was -99.940000. running mean: -128.923174\n",
      "ep 3: ep_len:830 episode reward: total was -70.960000. running mean: -128.343542\n",
      "ep 3: ep_len:500 episode reward: total was -41.000000. running mean: -127.470106\n",
      "ep 3: ep_len:224 episode reward: total was 5.000000. running mean: -126.145405\n",
      "ep 3: ep_len:850 episode reward: total was -83.210000. running mean: -125.716051\n",
      "ep 3: ep_len:500 episode reward: total was -1.740000. running mean: -124.476291\n",
      "ep 3: ep_len:1120 episode reward: total was -96.880000. running mean: -124.200328\n",
      "ep 3: ep_len:1120 episode reward: total was -121.030000. running mean: -124.168625\n",
      "ep 3: ep_len:505 episode reward: total was -27.280000. running mean: -123.199738\n",
      "ep 3: ep_len:500 episode reward: total was -26.880000. running mean: -122.236541\n",
      "ep 3: ep_len:555 episode reward: total was -69.640000. running mean: -121.710576\n",
      "ep 3: ep_len:500 episode reward: total was -22.440000. running mean: -120.717870\n",
      "ep 3: ep_len:1195 episode reward: total was -192.970000. running mean: -121.440391\n",
      "ep 3: ep_len:520 episode reward: total was -83.820000. running mean: -121.064187\n",
      "ep 3: ep_len:855 episode reward: total was -53.740000. running mean: -120.390945\n",
      "ep 3: ep_len:505 episode reward: total was -91.440000. running mean: -120.101436\n",
      "ep 3: ep_len:710 episode reward: total was -91.780000. running mean: -119.818222\n",
      "ep 3: ep_len:700 episode reward: total was -128.940000. running mean: -119.909439\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 3: ep_len:570 episode reward: total was -36.440000. running mean: -119.074745\n",
      "ep 3: ep_len:640 episode reward: total was -76.510000. running mean: -118.649097\n",
      "ep 3: ep_len:500 episode reward: total was -22.320000. running mean: -117.685806\n",
      "ep 3: ep_len:530 episode reward: total was -71.710000. running mean: -117.226048\n",
      "ep 3: ep_len:2380 episode reward: total was -360.910000. running mean: -119.662888\n",
      "ep 3: ep_len:510 episode reward: total was -20.280000. running mean: -118.669059\n",
      "ep 3: ep_len:205 episode reward: total was 0.000000. running mean: -117.482368\n",
      "ep 3: ep_len:1645 episode reward: total was -174.390000. running mean: -118.051445\n",
      "ep 3: ep_len:1295 episode reward: total was -111.660000. running mean: -117.987530\n",
      "ep 3: ep_len:815 episode reward: total was -65.570000. running mean: -117.463355\n",
      "ep 3: ep_len:500 episode reward: total was -39.480000. running mean: -116.683521\n",
      "ep 3: ep_len:770 episode reward: total was -72.260000. running mean: -116.239286\n",
      "ep 3: ep_len:520 episode reward: total was -39.410000. running mean: -115.470993\n",
      "ep 3: ep_len:383 episode reward: total was -23.340000. running mean: -114.549683\n",
      "ep 3: ep_len:630 episode reward: total was -72.000000. running mean: -114.124187\n",
      "ep 3: ep_len:580 episode reward: total was -50.370000. running mean: -113.486645\n",
      "ep 3: ep_len:500 episode reward: total was -42.660000. running mean: -112.778378\n",
      "ep 3: ep_len:500 episode reward: total was -30.320000. running mean: -111.953795\n",
      "ep 3: ep_len:800 episode reward: total was -110.320000. running mean: -111.937457\n",
      "ep 3: ep_len:500 episode reward: total was -32.310000. running mean: -111.141182\n",
      "ep 3: ep_len:500 episode reward: total was -28.000000. running mean: -110.309770\n",
      "ep 3: ep_len:730 episode reward: total was -70.790000. running mean: -109.914573\n",
      "ep 3: ep_len:500 episode reward: total was -23.980000. running mean: -109.055227\n",
      "ep 3: ep_len:900 episode reward: total was -104.540000. running mean: -109.010075\n",
      "ep 3: ep_len:409 episode reward: total was -11.720000. running mean: -108.037174\n",
      "ep 3: ep_len:750 episode reward: total was -40.070000. running mean: -107.357502\n",
      "ep 3: ep_len:585 episode reward: total was -25.800000. running mean: -106.541927\n",
      "ep 3: ep_len:191 episode reward: total was -5.500000. running mean: -105.531508\n",
      "ep 3: ep_len:955 episode reward: total was -87.370000. running mean: -105.349893\n",
      "ep 3: ep_len:78 episode reward: total was 4.500000. running mean: -104.251394\n",
      "ep 3: ep_len:126 episode reward: total was -1.000000. running mean: -103.218880\n",
      "ep 3: ep_len:493 episode reward: total was -24.310000. running mean: -102.429791\n",
      "ep 3: ep_len:825 episode reward: total was -81.710000. running mean: -102.222593\n",
      "ep 3: ep_len:665 episode reward: total was -25.740000. running mean: -101.457767\n",
      "ep 3: ep_len:236 episode reward: total was 6.000000. running mean: -100.383189\n",
      "ep 3: ep_len:600 episode reward: total was -43.960000. running mean: -99.818958\n",
      "ep 3: ep_len:875 episode reward: total was -50.490000. running mean: -99.325668\n",
      "ep 3: ep_len:505 episode reward: total was -46.070000. running mean: -98.793111\n",
      "ep 3: ep_len:203 episode reward: total was -1.000000. running mean: -97.815180\n",
      "ep 3: ep_len:150 episode reward: total was 2.000000. running mean: -96.817028\n",
      "ep 3: ep_len:570 episode reward: total was -46.760000. running mean: -96.316458\n",
      "ep 3: ep_len:500 episode reward: total was -32.130000. running mean: -95.674594\n",
      "ep 3: ep_len:500 episode reward: total was -34.490000. running mean: -95.062748\n",
      "ep 3: ep_len:196 episode reward: total was -1.000000. running mean: -94.122120\n",
      "ep 3: ep_len:650 episode reward: total was -37.140000. running mean: -93.552299\n",
      "ep 3: ep_len:855 episode reward: total was -52.200000. running mean: -93.138776\n",
      "ep 3: ep_len:143 episode reward: total was 0.500000. running mean: -92.202388\n",
      "ep 3: ep_len:500 episode reward: total was -19.520000. running mean: -91.475564\n",
      "ep 3: ep_len:955 episode reward: total was -64.170000. running mean: -91.202509\n",
      "ep 3: ep_len:510 episode reward: total was -5.820000. running mean: -90.348684\n",
      "ep 3: ep_len:343 episode reward: total was -0.500000. running mean: -89.450197\n",
      "ep 3: ep_len:500 episode reward: total was -14.760000. running mean: -88.703295\n",
      "ep 3: ep_len:860 episode reward: total was -79.510000. running mean: -88.611362\n",
      "ep 3: ep_len:745 episode reward: total was -49.000000. running mean: -88.215248\n",
      "ep 3: ep_len:1140 episode reward: total was -71.070000. running mean: -88.043796\n",
      "ep 3: ep_len:750 episode reward: total was -53.090000. running mean: -87.694258\n",
      "ep 3: ep_len:735 episode reward: total was -54.180000. running mean: -87.359115\n",
      "ep 3: ep_len:500 episode reward: total was -8.330000. running mean: -86.568824\n",
      "ep 3: ep_len:575 episode reward: total was -34.770000. running mean: -86.050836\n",
      "ep 3: ep_len:500 episode reward: total was -15.230000. running mean: -85.342627\n",
      "ep 3: ep_len:323 episode reward: total was -24.810000. running mean: -84.737301\n",
      "ep 3: ep_len:505 episode reward: total was -50.090000. running mean: -84.390828\n",
      "ep 3: ep_len:595 episode reward: total was -26.880000. running mean: -83.815720\n",
      "ep 3: ep_len:246 episode reward: total was 2.000000. running mean: -82.957563\n",
      "ep 3: ep_len:625 episode reward: total was -20.670000. running mean: -82.334687\n",
      "ep 3: ep_len:595 episode reward: total was -49.330000. running mean: -82.004640\n",
      "ep 3: ep_len:500 episode reward: total was -14.160000. running mean: -81.326194\n",
      "ep 3: ep_len:685 episode reward: total was -54.810000. running mean: -81.061032\n",
      "ep 3: ep_len:500 episode reward: total was -47.620000. running mean: -80.726622\n",
      "ep 3: ep_len:710 episode reward: total was -51.180000. running mean: -80.431155\n",
      "ep 3: ep_len:500 episode reward: total was -19.920000. running mean: -79.826044\n",
      "ep 3: ep_len:500 episode reward: total was -19.330000. running mean: -79.221083\n",
      "ep 3: ep_len:500 episode reward: total was -19.730000. running mean: -78.626172\n",
      "ep 3: ep_len:860 episode reward: total was -51.920000. running mean: -78.359111\n",
      "ep 3: ep_len:815 episode reward: total was -46.770000. running mean: -78.043220\n",
      "ep 3: ep_len:650 episode reward: total was -37.730000. running mean: -77.640087\n",
      "ep 3: ep_len:339 episode reward: total was 1.000000. running mean: -76.853687\n",
      "ep 3: ep_len:1030 episode reward: total was -85.110000. running mean: -76.936250\n",
      "ep 3: ep_len:500 episode reward: total was -26.870000. running mean: -76.435587\n",
      "ep 3: ep_len:610 episode reward: total was -23.680000. running mean: -75.908031\n",
      "ep 3: ep_len:510 episode reward: total was 6.500000. running mean: -75.083951\n",
      "ep 3: ep_len:1070 episode reward: total was -34.890000. running mean: -74.682012\n",
      "ep 3: ep_len:500 episode reward: total was -19.600000. running mean: -74.131191\n",
      "ep 3: ep_len:309 episode reward: total was -11.790000. running mean: -73.507779\n",
      "ep 3: ep_len:745 episode reward: total was -85.020000. running mean: -73.622902\n",
      "ep 3: ep_len:745 episode reward: total was -64.210000. running mean: -73.528773\n",
      "ep 3: ep_len:1215 episode reward: total was -157.440000. running mean: -74.367885\n",
      "ep 3: ep_len:268 episode reward: total was 2.500000. running mean: -73.599206\n",
      "ep 3: ep_len:935 episode reward: total was -35.130000. running mean: -73.214514\n",
      "ep 3: ep_len:2141 episode reward: total was -366.390000. running mean: -76.146269\n",
      "ep 3: ep_len:500 episode reward: total was 8.500000. running mean: -75.299806\n",
      "ep 3: ep_len:730 episode reward: total was -63.200000. running mean: -75.178808\n",
      "ep 3: ep_len:795 episode reward: total was -67.140000. running mean: -75.098420\n",
      "ep 3: ep_len:520 episode reward: total was -48.680000. running mean: -74.834236\n",
      "ep 3: ep_len:500 episode reward: total was -41.590000. running mean: -74.501794\n",
      "ep 3: ep_len:850 episode reward: total was -66.020000. running mean: -74.416976\n",
      "ep 3: ep_len:790 episode reward: total was -79.380000. running mean: -74.466606\n",
      "ep 3: ep_len:600 episode reward: total was -40.800000. running mean: -74.129940\n",
      "ep 3: ep_len:505 episode reward: total was -41.980000. running mean: -73.808440\n",
      "ep 3: ep_len:500 episode reward: total was -6.310000. running mean: -73.133456\n",
      "ep 3: ep_len:535 episode reward: total was -29.210000. running mean: -72.694221\n",
      "ep 3: ep_len:500 episode reward: total was -35.500000. running mean: -72.322279\n",
      "ep 3: ep_len:1360 episode reward: total was -148.310000. running mean: -73.082156\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 3: ep_len:895 episode reward: total was -66.940000. running mean: -73.020735\n",
      "ep 3: ep_len:500 episode reward: total was -32.190000. running mean: -72.612427\n",
      "ep 3: ep_len:750 episode reward: total was -56.610000. running mean: -72.452403\n",
      "ep 3: ep_len:925 episode reward: total was -33.300000. running mean: -72.060879\n",
      "ep 3: ep_len:530 episode reward: total was -27.420000. running mean: -71.614470\n",
      "ep 3: ep_len:640 episode reward: total was -60.350000. running mean: -71.501826\n",
      "ep 3: ep_len:715 episode reward: total was -41.020000. running mean: -71.197007\n",
      "ep 3: ep_len:500 episode reward: total was -34.670000. running mean: -70.831737\n",
      "ep 3: ep_len:500 episode reward: total was -25.170000. running mean: -70.375120\n",
      "ep 3: ep_len:910 episode reward: total was -51.240000. running mean: -70.183769\n",
      "ep 3: ep_len:500 episode reward: total was -55.290000. running mean: -70.034831\n",
      "ep 3: ep_len:500 episode reward: total was -12.380000. running mean: -69.458283\n",
      "ep 3: ep_len:1515 episode reward: total was -135.410000. running mean: -70.117800\n",
      "ep 3: ep_len:1280 episode reward: total was -130.290000. running mean: -70.719522\n",
      "ep 3: ep_len:408 episode reward: total was 0.000000. running mean: -70.012327\n",
      "ep 3: ep_len:505 episode reward: total was -1.330000. running mean: -69.325503\n",
      "ep 3: ep_len:600 episode reward: total was -39.220000. running mean: -69.024448\n",
      "ep 3: ep_len:785 episode reward: total was -53.020000. running mean: -68.864404\n",
      "ep 3: ep_len:1020 episode reward: total was -82.510000. running mean: -69.000860\n",
      "ep 3: ep_len:500 episode reward: total was -28.840000. running mean: -68.599251\n",
      "ep 3: ep_len:710 episode reward: total was -48.610000. running mean: -68.399359\n",
      "ep 3: ep_len:500 episode reward: total was -7.290000. running mean: -67.788265\n",
      "ep 3: ep_len:790 episode reward: total was -42.020000. running mean: -67.530583\n",
      "ep 3: ep_len:500 episode reward: total was -12.830000. running mean: -66.983577\n",
      "ep 3: ep_len:177 episode reward: total was -4.500000. running mean: -66.358741\n",
      "ep 3: ep_len:825 episode reward: total was -68.090000. running mean: -66.376054\n",
      "ep 3: ep_len:236 episode reward: total was -2.500000. running mean: -65.737293\n",
      "ep 3: ep_len:500 episode reward: total was -49.550000. running mean: -65.575420\n",
      "ep 3: ep_len:500 episode reward: total was -38.260000. running mean: -65.302266\n",
      "ep 3: ep_len:378 episode reward: total was 8.000000. running mean: -64.569243\n",
      "ep 3: ep_len:595 episode reward: total was -87.300000. running mean: -64.796551\n",
      "ep 3: ep_len:585 episode reward: total was -35.360000. running mean: -64.502185\n",
      "ep 3: ep_len:575 episode reward: total was -36.760000. running mean: -64.224763\n",
      "ep 3: ep_len:500 episode reward: total was -20.560000. running mean: -63.788116\n",
      "ep 3: ep_len:890 episode reward: total was -70.990000. running mean: -63.860135\n",
      "ep 3: ep_len:980 episode reward: total was -63.740000. running mean: -63.858933\n",
      "ep 3: ep_len:500 episode reward: total was -33.430000. running mean: -63.554644\n",
      "ep 3: ep_len:595 episode reward: total was -35.050000. running mean: -63.269598\n",
      "ep 3: ep_len:360 episode reward: total was 11.000000. running mean: -62.526902\n",
      "ep 3: ep_len:132 episode reward: total was 6.000000. running mean: -61.841633\n",
      "ep 3: ep_len:500 episode reward: total was -14.850000. running mean: -61.371716\n",
      "ep 3: ep_len:640 episode reward: total was -23.690000. running mean: -60.994899\n",
      "ep 3: ep_len:425 episode reward: total was -16.430000. running mean: -60.549250\n",
      "ep 3: ep_len:560 episode reward: total was -42.330000. running mean: -60.367058\n",
      "ep 3: ep_len:500 episode reward: total was -41.090000. running mean: -60.174287\n",
      "ep 3: ep_len:805 episode reward: total was -53.960000. running mean: -60.112144\n",
      "ep 3: ep_len:700 episode reward: total was -56.220000. running mean: -60.073223\n",
      "ep 3: ep_len:505 episode reward: total was -56.240000. running mean: -60.034890\n",
      "ep 3: ep_len:500 episode reward: total was -33.510000. running mean: -59.769642\n",
      "ep 3: ep_len:500 episode reward: total was -27.940000. running mean: -59.451345\n",
      "ep 3: ep_len:650 episode reward: total was -19.310000. running mean: -59.049932\n",
      "ep 3: ep_len:500 episode reward: total was -6.890000. running mean: -58.528332\n",
      "ep 3: ep_len:710 episode reward: total was -53.170000. running mean: -58.474749\n",
      "ep 3: ep_len:640 episode reward: total was -47.740000. running mean: -58.367402\n",
      "ep 3: ep_len:960 episode reward: total was -46.500000. running mean: -58.248728\n",
      "ep 3: ep_len:500 episode reward: total was -20.870000. running mean: -57.874940\n",
      "ep 3: ep_len:515 episode reward: total was -28.880000. running mean: -57.584991\n",
      "ep 3: ep_len:190 episode reward: total was 3.000000. running mean: -56.979141\n",
      "ep 3: ep_len:500 episode reward: total was -40.230000. running mean: -56.811650\n",
      "ep 3: ep_len:580 episode reward: total was -35.250000. running mean: -56.596033\n",
      "ep 3: ep_len:505 episode reward: total was -20.700000. running mean: -56.237073\n",
      "ep 3: ep_len:500 episode reward: total was -38.750000. running mean: -56.062202\n",
      "ep 3: ep_len:645 episode reward: total was -48.740000. running mean: -55.988980\n",
      "ep 3: ep_len:500 episode reward: total was 8.000000. running mean: -55.349090\n",
      "ep 3: ep_len:500 episode reward: total was -25.980000. running mean: -55.055399\n",
      "ep 3: ep_len:685 episode reward: total was -59.250000. running mean: -55.097345\n",
      "ep 3: ep_len:286 episode reward: total was -5.000000. running mean: -54.596372\n",
      "ep 3: ep_len:995 episode reward: total was -46.270000. running mean: -54.513108\n",
      "ep 3: ep_len:715 episode reward: total was -77.400000. running mean: -54.741977\n",
      "ep 3: ep_len:865 episode reward: total was -63.290000. running mean: -54.827457\n",
      "ep 3: ep_len:201 episode reward: total was 3.500000. running mean: -54.244183\n",
      "ep 3: ep_len:500 episode reward: total was -36.450000. running mean: -54.066241\n",
      "ep 3: ep_len:735 episode reward: total was -51.590000. running mean: -54.041478\n",
      "ep 3: ep_len:500 episode reward: total was -15.270000. running mean: -53.653764\n",
      "ep 3: ep_len:500 episode reward: total was -25.790000. running mean: -53.375126\n",
      "ep 3: ep_len:500 episode reward: total was -25.280000. running mean: -53.094175\n",
      "ep 3: ep_len:785 episode reward: total was -43.930000. running mean: -53.002533\n",
      "ep 3: ep_len:580 episode reward: total was -37.720000. running mean: -52.849708\n",
      "ep 3: ep_len:210 episode reward: total was -2.500000. running mean: -52.346211\n",
      "ep 3: ep_len:540 episode reward: total was -48.020000. running mean: -52.302948\n",
      "ep 3: ep_len:635 episode reward: total was -41.170000. running mean: -52.191619\n",
      "ep 3: ep_len:500 episode reward: total was -1.840000. running mean: -51.688103\n",
      "ep 3: ep_len:500 episode reward: total was 0.500000. running mean: -51.166222\n",
      "ep 3: ep_len:505 episode reward: total was -8.300000. running mean: -50.737560\n",
      "ep 3: ep_len:164 episode reward: total was -6.000000. running mean: -50.290184\n",
      "ep 3: ep_len:371 episode reward: total was -37.840000. running mean: -50.165682\n",
      "ep 3: ep_len:705 episode reward: total was -50.270000. running mean: -50.166725\n",
      "ep 3: ep_len:261 episode reward: total was -3.000000. running mean: -49.695058\n",
      "ep 3: ep_len:500 episode reward: total was -44.170000. running mean: -49.639807\n",
      "ep 3: ep_len:500 episode reward: total was -5.000000. running mean: -49.193409\n",
      "ep 3: ep_len:755 episode reward: total was -46.500000. running mean: -49.166475\n",
      "ep 3: ep_len:419 episode reward: total was -8.000000. running mean: -48.754811\n",
      "ep 3: ep_len:335 episode reward: total was -0.500000. running mean: -48.272262\n",
      "ep 3: ep_len:500 episode reward: total was -16.810000. running mean: -47.957640\n",
      "ep 3: ep_len:565 episode reward: total was -31.240000. running mean: -47.790463\n",
      "ep 3: ep_len:500 episode reward: total was -31.010000. running mean: -47.622659\n",
      "ep 3: ep_len:510 episode reward: total was -28.310000. running mean: -47.429532\n",
      "ep 3: ep_len:800 episode reward: total was -26.990000. running mean: -47.225137\n",
      "ep 3: ep_len:705 episode reward: total was -73.620000. running mean: -47.489086\n",
      "ep 3: ep_len:500 episode reward: total was -20.780000. running mean: -47.221995\n",
      "ep 3: ep_len:1425 episode reward: total was -148.200000. running mean: -48.231775\n",
      "ep 3: ep_len:655 episode reward: total was -68.380000. running mean: -48.433257\n",
      "ep 3: ep_len:505 episode reward: total was -12.300000. running mean: -48.071924\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 3: ep_len:520 episode reward: total was -45.470000. running mean: -48.045905\n",
      "ep 3: ep_len:1175 episode reward: total was -136.560000. running mean: -48.931046\n",
      "ep 3: ep_len:520 episode reward: total was -9.300000. running mean: -48.534736\n",
      "ep 3: ep_len:500 episode reward: total was -36.350000. running mean: -48.412888\n",
      "ep 3: ep_len:327 episode reward: total was -3.500000. running mean: -47.963759\n",
      "ep 3: ep_len:445 episode reward: total was -57.220000. running mean: -48.056322\n",
      "ep 3: ep_len:680 episode reward: total was -21.910000. running mean: -47.794859\n",
      "ep 3: ep_len:540 episode reward: total was -31.290000. running mean: -47.629810\n",
      "ep 3: ep_len:585 episode reward: total was -68.050000. running mean: -47.834012\n",
      "ep 3: ep_len:505 episode reward: total was -22.270000. running mean: -47.578372\n",
      "ep 3: ep_len:500 episode reward: total was -31.460000. running mean: -47.417188\n",
      "ep 3: ep_len:600 episode reward: total was -72.150000. running mean: -47.664516\n",
      "ep 3: ep_len:35 episode reward: total was 0.500000. running mean: -47.182871\n",
      "ep 3: ep_len:500 episode reward: total was -31.890000. running mean: -47.029942\n",
      "ep 3: ep_len:505 episode reward: total was -21.780000. running mean: -46.777443\n",
      "ep 3: ep_len:500 episode reward: total was -41.190000. running mean: -46.721568\n",
      "ep 3: ep_len:500 episode reward: total was -33.630000. running mean: -46.590653\n",
      "ep 3: ep_len:1638 episode reward: total was -282.590000. running mean: -48.950646\n",
      "ep 3: ep_len:505 episode reward: total was -35.400000. running mean: -48.815140\n",
      "ep 3: ep_len:690 episode reward: total was -68.330000. running mean: -49.010288\n",
      "ep 3: ep_len:1100 episode reward: total was -97.330000. running mean: -49.493486\n",
      "ep 3: ep_len:560 episode reward: total was -44.350000. running mean: -49.442051\n",
      "ep 3: ep_len:540 episode reward: total was -38.020000. running mean: -49.327830\n",
      "ep 3: ep_len:515 episode reward: total was -38.340000. running mean: -49.217952\n",
      "ep 3: ep_len:1650 episode reward: total was -229.020000. running mean: -51.015972\n",
      "ep 3: ep_len:625 episode reward: total was -51.180000. running mean: -51.017613\n",
      "ep 3: ep_len:429 episode reward: total was -6.340000. running mean: -50.570836\n",
      "ep 3: ep_len:460 episode reward: total was 5.000000. running mean: -50.015128\n",
      "ep 3: ep_len:660 episode reward: total was -46.200000. running mean: -49.976977\n",
      "ep 3: ep_len:693 episode reward: total was -70.380000. running mean: -50.181007\n",
      "ep 3: ep_len:303 episode reward: total was -2.000000. running mean: -49.699197\n",
      "ep 3: ep_len:500 episode reward: total was -21.770000. running mean: -49.419905\n",
      "ep 3: ep_len:980 episode reward: total was -51.980000. running mean: -49.445506\n",
      "ep 3: ep_len:870 episode reward: total was -119.510000. running mean: -50.146151\n",
      "ep 3: ep_len:545 episode reward: total was -35.290000. running mean: -49.997589\n",
      "ep 3: ep_len:640 episode reward: total was -53.800000. running mean: -50.035614\n",
      "ep 3: ep_len:550 episode reward: total was -48.190000. running mean: -50.017157\n",
      "ep 3: ep_len:750 episode reward: total was -63.680000. running mean: -50.153786\n",
      "ep 3: ep_len:585 episode reward: total was -54.430000. running mean: -50.196548\n",
      "ep 3: ep_len:760 episode reward: total was -61.790000. running mean: -50.312482\n",
      "ep 3: ep_len:510 episode reward: total was -34.530000. running mean: -50.154658\n",
      "ep 3: ep_len:770 episode reward: total was -92.440000. running mean: -50.577511\n",
      "ep 3: ep_len:755 episode reward: total was -85.890000. running mean: -50.930636\n",
      "ep 3: ep_len:900 episode reward: total was -47.420000. running mean: -50.895530\n",
      "ep 3: ep_len:500 episode reward: total was -26.380000. running mean: -50.650374\n",
      "ep 3: ep_len:500 episode reward: total was -35.440000. running mean: -50.498271\n",
      "ep 3: ep_len:500 episode reward: total was -38.960000. running mean: -50.382888\n",
      "ep 3: ep_len:123 episode reward: total was 9.500000. running mean: -49.784059\n",
      "ep 3: ep_len:500 episode reward: total was -13.870000. running mean: -49.424918\n",
      "ep 3: ep_len:473 episode reward: total was -27.960000. running mean: -49.210269\n",
      "ep 3: ep_len:605 episode reward: total was -39.880000. running mean: -49.116967\n",
      "ep 3: ep_len:530 episode reward: total was -52.000000. running mean: -49.145797\n",
      "ep 3: ep_len:505 episode reward: total was -34.970000. running mean: -49.004039\n",
      "ep 3: ep_len:500 episode reward: total was -22.370000. running mean: -48.737698\n",
      "ep 3: ep_len:510 episode reward: total was -31.210000. running mean: -48.562421\n",
      "ep 3: ep_len:2930 episode reward: total was -394.430000. running mean: -52.021097\n",
      "ep 3: ep_len:500 episode reward: total was -58.180000. running mean: -52.082686\n",
      "ep 3: ep_len:5430 episode reward: total was -712.730000. running mean: -58.689159\n",
      "ep 3: ep_len:630 episode reward: total was -55.320000. running mean: -58.655468\n",
      "ep 3: ep_len:500 episode reward: total was -44.010000. running mean: -58.509013\n",
      "ep 3: ep_len:1205 episode reward: total was -136.500000. running mean: -59.288923\n",
      "ep 3: ep_len:500 episode reward: total was 17.000000. running mean: -58.526034\n",
      "ep 3: ep_len:515 episode reward: total was -56.340000. running mean: -58.504173\n",
      "ep 3: ep_len:500 episode reward: total was -67.960000. running mean: -58.598732\n",
      "ep 3: ep_len:203 episode reward: total was -3.500000. running mean: -58.047744\n",
      "epsilon:0.338594 episode_count: 3149. steps_count: 2355101.000000\n",
      "ep 4: ep_len:1745 episode reward: total was -206.130000. running mean: -59.528567\n",
      "ep 4: ep_len:805 episode reward: total was -66.600000. running mean: -59.599281\n",
      "ep 4: ep_len:500 episode reward: total was -60.350000. running mean: -59.606788\n",
      "ep 4: ep_len:500 episode reward: total was -69.230000. running mean: -59.703021\n",
      "ep 4: ep_len:790 episode reward: total was -61.960000. running mean: -59.725590\n",
      "ep 4: ep_len:980 episode reward: total was -90.490000. running mean: -60.033234\n",
      "ep 4: ep_len:790 episode reward: total was -48.170000. running mean: -59.914602\n",
      "ep 4: ep_len:555 episode reward: total was -29.340000. running mean: -59.608856\n",
      "ep 4: ep_len:975 episode reward: total was -117.770000. running mean: -60.190468\n",
      "ep 4: ep_len:1025 episode reward: total was -54.190000. running mean: -60.130463\n",
      "ep 4: ep_len:770 episode reward: total was -64.650000. running mean: -60.175658\n",
      "ep 4: ep_len:505 episode reward: total was -27.820000. running mean: -59.852102\n",
      "ep 4: ep_len:985 episode reward: total was -44.750000. running mean: -59.701081\n",
      "ep 4: ep_len:950 episode reward: total was -83.480000. running mean: -59.938870\n",
      "ep 4: ep_len:1140 episode reward: total was -82.100000. running mean: -60.160481\n",
      "ep 4: ep_len:500 episode reward: total was -8.860000. running mean: -59.647476\n",
      "ep 4: ep_len:500 episode reward: total was -36.340000. running mean: -59.414402\n",
      "ep 4: ep_len:570 episode reward: total was -53.820000. running mean: -59.358458\n",
      "ep 4: ep_len:560 episode reward: total was -41.840000. running mean: -59.183273\n",
      "ep 4: ep_len:505 episode reward: total was -30.870000. running mean: -58.900140\n",
      "ep 4: ep_len:1540 episode reward: total was -159.580000. running mean: -59.906939\n",
      "ep 4: ep_len:1025 episode reward: total was -105.550000. running mean: -60.363369\n",
      "ep 4: ep_len:1735 episode reward: total was -222.820000. running mean: -61.987936\n",
      "ep 4: ep_len:550 episode reward: total was -59.030000. running mean: -61.958356\n",
      "ep 4: ep_len:165 episode reward: total was -3.000000. running mean: -61.368773\n",
      "ep 4: ep_len:850 episode reward: total was -74.930000. running mean: -61.504385\n",
      "ep 4: ep_len:505 episode reward: total was -39.610000. running mean: -61.285441\n",
      "ep 4: ep_len:505 episode reward: total was -25.230000. running mean: -60.924887\n",
      "ep 4: ep_len:500 episode reward: total was -23.890000. running mean: -60.554538\n",
      "ep 4: ep_len:500 episode reward: total was -14.370000. running mean: -60.092693\n",
      "ep 4: ep_len:500 episode reward: total was -29.640000. running mean: -59.788166\n",
      "ep 4: ep_len:500 episode reward: total was -31.970000. running mean: -59.509984\n",
      "ep 4: ep_len:840 episode reward: total was -61.480000. running mean: -59.529684\n",
      "ep 4: ep_len:765 episode reward: total was -28.500000. running mean: -59.219387\n",
      "ep 4: ep_len:545 episode reward: total was -41.380000. running mean: -59.040993\n",
      "ep 4: ep_len:750 episode reward: total was -55.080000. running mean: -59.001384\n",
      "ep 4: ep_len:580 episode reward: total was -36.260000. running mean: -58.773970\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 4: ep_len:600 episode reward: total was -36.010000. running mean: -58.546330\n",
      "ep 4: ep_len:505 episode reward: total was -38.790000. running mean: -58.348767\n",
      "ep 4: ep_len:500 episode reward: total was -19.800000. running mean: -57.963279\n",
      "ep 4: ep_len:198 episode reward: total was 4.500000. running mean: -57.338646\n",
      "ep 4: ep_len:860 episode reward: total was -40.900000. running mean: -57.174260\n",
      "ep 4: ep_len:570 episode reward: total was -40.320000. running mean: -57.005717\n",
      "ep 4: ep_len:850 episode reward: total was -25.670000. running mean: -56.692360\n",
      "ep 4: ep_len:705 episode reward: total was -44.060000. running mean: -56.566036\n",
      "ep 4: ep_len:19425 episode reward: total was -3657.330000. running mean: -92.573676\n",
      "ep 4: ep_len:895 episode reward: total was -69.260000. running mean: -92.340539\n",
      "ep 4: ep_len:1040 episode reward: total was -92.160000. running mean: -92.338734\n",
      "ep 4: ep_len:215 episode reward: total was -1.000000. running mean: -91.425347\n",
      "ep 4: ep_len:500 episode reward: total was -51.260000. running mean: -91.023693\n",
      "ep 4: ep_len:515 episode reward: total was -68.190000. running mean: -90.795356\n",
      "ep 4: ep_len:755 episode reward: total was -76.840000. running mean: -90.655803\n",
      "ep 4: ep_len:525 episode reward: total was -36.440000. running mean: -90.113645\n",
      "ep 4: ep_len:875 episode reward: total was -61.260000. running mean: -89.825108\n",
      "ep 4: ep_len:635 episode reward: total was -41.920000. running mean: -89.346057\n",
      "ep 4: ep_len:950 episode reward: total was -55.700000. running mean: -89.009596\n",
      "ep 4: ep_len:500 episode reward: total was -55.320000. running mean: -88.672701\n",
      "ep 4: ep_len:469 episode reward: total was 12.500000. running mean: -87.660974\n",
      "ep 4: ep_len:905 episode reward: total was -88.130000. running mean: -87.665664\n",
      "ep 4: ep_len:500 episode reward: total was -54.630000. running mean: -87.335307\n",
      "ep 4: ep_len:580 episode reward: total was -66.040000. running mean: -87.122354\n",
      "ep 4: ep_len:217 episode reward: total was -3.000000. running mean: -86.281131\n",
      "ep 4: ep_len:187 episode reward: total was 1.000000. running mean: -85.408319\n",
      "ep 4: ep_len:910 episode reward: total was -94.280000. running mean: -85.497036\n",
      "ep 4: ep_len:515 episode reward: total was -51.020000. running mean: -85.152266\n",
      "ep 4: ep_len:1125 episode reward: total was -159.890000. running mean: -85.899643\n",
      "ep 4: ep_len:845 episode reward: total was -60.490000. running mean: -85.645547\n",
      "ep 4: ep_len:505 episode reward: total was -21.300000. running mean: -85.002091\n",
      "ep 4: ep_len:620 episode reward: total was -48.270000. running mean: -84.634770\n",
      "ep 4: ep_len:760 episode reward: total was -75.290000. running mean: -84.541323\n",
      "ep 4: ep_len:910 episode reward: total was -83.560000. running mean: -84.531509\n",
      "ep 4: ep_len:975 episode reward: total was -167.840000. running mean: -85.364594\n",
      "ep 4: ep_len:500 episode reward: total was -45.600000. running mean: -84.966948\n",
      "ep 4: ep_len:505 episode reward: total was -27.830000. running mean: -84.395579\n",
      "ep 4: ep_len:525 episode reward: total was -47.450000. running mean: -84.026123\n",
      "ep 4: ep_len:500 episode reward: total was -38.930000. running mean: -83.575162\n",
      "ep 4: ep_len:500 episode reward: total was -23.650000. running mean: -82.975910\n",
      "ep 4: ep_len:520 episode reward: total was -20.830000. running mean: -82.354451\n",
      "ep 4: ep_len:675 episode reward: total was -79.470000. running mean: -82.325607\n",
      "ep 4: ep_len:500 episode reward: total was -33.410000. running mean: -81.836450\n",
      "ep 4: ep_len:660 episode reward: total was -55.290000. running mean: -81.570986\n",
      "ep 4: ep_len:61 episode reward: total was 1.500000. running mean: -80.740276\n",
      "ep 4: ep_len:500 episode reward: total was -33.390000. running mean: -80.266773\n",
      "ep 4: ep_len:201 episode reward: total was 2.000000. running mean: -79.444106\n",
      "ep 4: ep_len:505 episode reward: total was -17.290000. running mean: -78.822565\n",
      "ep 4: ep_len:550 episode reward: total was -67.110000. running mean: -78.705439\n",
      "ep 4: ep_len:565 episode reward: total was -58.460000. running mean: -78.502984\n",
      "ep 4: ep_len:500 episode reward: total was -23.790000. running mean: -77.955855\n",
      "ep 4: ep_len:505 episode reward: total was -2.850000. running mean: -77.204796\n",
      "ep 4: ep_len:500 episode reward: total was -46.940000. running mean: -76.902148\n",
      "ep 4: ep_len:510 episode reward: total was -17.360000. running mean: -76.306727\n",
      "ep 4: ep_len:770 episode reward: total was -74.810000. running mean: -76.291759\n",
      "ep 4: ep_len:530 episode reward: total was -77.250000. running mean: -76.301342\n",
      "ep 4: ep_len:540 episode reward: total was -53.310000. running mean: -76.071428\n",
      "ep 4: ep_len:930 episode reward: total was -81.360000. running mean: -76.124314\n",
      "ep 4: ep_len:500 episode reward: total was -33.340000. running mean: -75.696471\n",
      "ep 4: ep_len:890 episode reward: total was -66.510000. running mean: -75.604606\n",
      "ep 4: ep_len:915 episode reward: total was -79.520000. running mean: -75.643760\n",
      "ep 4: ep_len:715 episode reward: total was -59.710000. running mean: -75.484423\n",
      "ep 4: ep_len:510 episode reward: total was -33.920000. running mean: -75.068778\n",
      "ep 4: ep_len:229 episode reward: total was 3.000000. running mean: -74.288091\n",
      "ep 4: ep_len:730 episode reward: total was -104.640000. running mean: -74.591610\n",
      "ep 4: ep_len:505 episode reward: total was -48.620000. running mean: -74.331894\n",
      "ep 4: ep_len:510 episode reward: total was -82.340000. running mean: -74.411975\n",
      "ep 4: ep_len:229 episode reward: total was 12.000000. running mean: -73.547855\n",
      "ep 4: ep_len:660 episode reward: total was -71.450000. running mean: -73.526876\n",
      "ep 4: ep_len:595 episode reward: total was -53.400000. running mean: -73.325608\n",
      "ep 4: ep_len:505 episode reward: total was -22.320000. running mean: -72.815552\n",
      "ep 4: ep_len:239 episode reward: total was 4.000000. running mean: -72.047396\n",
      "ep 4: ep_len:216 episode reward: total was 5.500000. running mean: -71.271922\n",
      "ep 4: ep_len:505 episode reward: total was -59.770000. running mean: -71.156903\n",
      "ep 4: ep_len:500 episode reward: total was -20.350000. running mean: -70.648834\n",
      "ep 4: ep_len:500 episode reward: total was 5.000000. running mean: -69.892345\n",
      "ep 4: ep_len:500 episode reward: total was -35.090000. running mean: -69.544322\n",
      "ep 4: ep_len:555 episode reward: total was -53.480000. running mean: -69.383679\n",
      "ep 4: ep_len:840 episode reward: total was -86.210000. running mean: -69.551942\n",
      "ep 4: ep_len:855 episode reward: total was -43.240000. running mean: -69.288823\n",
      "ep 4: ep_len:995 episode reward: total was -173.800000. running mean: -70.333934\n",
      "ep 4: ep_len:915 episode reward: total was -68.150000. running mean: -70.312095\n",
      "ep 4: ep_len:500 episode reward: total was -14.880000. running mean: -69.757774\n",
      "ep 4: ep_len:815 episode reward: total was -27.910000. running mean: -69.339296\n",
      "ep 4: ep_len:1445 episode reward: total was -249.660000. running mean: -71.142503\n",
      "ep 4: ep_len:500 episode reward: total was -68.370000. running mean: -71.114778\n",
      "ep 4: ep_len:1015 episode reward: total was -56.190000. running mean: -70.965531\n",
      "ep 4: ep_len:500 episode reward: total was 4.000000. running mean: -70.215875\n",
      "ep 4: ep_len:720 episode reward: total was -66.280000. running mean: -70.176516\n",
      "ep 4: ep_len:760 episode reward: total was -47.010000. running mean: -69.944851\n",
      "ep 4: ep_len:570 episode reward: total was -37.290000. running mean: -69.618303\n",
      "ep 4: ep_len:850 episode reward: total was -71.560000. running mean: -69.637720\n",
      "ep 4: ep_len:505 episode reward: total was -23.140000. running mean: -69.172743\n",
      "ep 4: ep_len:500 episode reward: total was -32.430000. running mean: -68.805315\n",
      "ep 4: ep_len:520 episode reward: total was -47.980000. running mean: -68.597062\n",
      "ep 4: ep_len:505 episode reward: total was -25.470000. running mean: -68.165791\n",
      "ep 4: ep_len:520 episode reward: total was -36.560000. running mean: -67.849733\n",
      "ep 4: ep_len:845 episode reward: total was -106.430000. running mean: -68.235536\n",
      "ep 4: ep_len:505 episode reward: total was -35.090000. running mean: -67.904081\n",
      "ep 4: ep_len:500 episode reward: total was -19.320000. running mean: -67.418240\n",
      "ep 4: ep_len:2320 episode reward: total was -191.350000. running mean: -68.657558\n",
      "ep 4: ep_len:500 episode reward: total was -15.500000. running mean: -68.125982\n",
      "ep 4: ep_len:500 episode reward: total was -33.970000. running mean: -67.784422\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 4: ep_len:2115 episode reward: total was -228.040000. running mean: -69.386978\n",
      "ep 4: ep_len:515 episode reward: total was -32.840000. running mean: -69.021508\n",
      "ep 4: ep_len:500 episode reward: total was -11.370000. running mean: -68.444993\n",
      "ep 4: ep_len:71 episode reward: total was 1.000000. running mean: -67.750543\n",
      "ep 4: ep_len:196 episode reward: total was 3.500000. running mean: -67.038038\n",
      "ep 4: ep_len:615 episode reward: total was -44.270000. running mean: -66.810357\n",
      "ep 4: ep_len:500 episode reward: total was -36.220000. running mean: -66.504454\n",
      "ep 4: ep_len:745 episode reward: total was -49.060000. running mean: -66.330009\n",
      "ep 4: ep_len:500 episode reward: total was -29.460000. running mean: -65.961309\n",
      "ep 4: ep_len:520 episode reward: total was -34.990000. running mean: -65.651596\n",
      "ep 4: ep_len:645 episode reward: total was -50.270000. running mean: -65.497780\n",
      "ep 4: ep_len:560 episode reward: total was -64.550000. running mean: -65.488302\n",
      "ep 4: ep_len:500 episode reward: total was -20.550000. running mean: -65.038919\n",
      "ep 4: ep_len:165 episode reward: total was -28.990000. running mean: -64.678430\n",
      "ep 4: ep_len:550 episode reward: total was -67.770000. running mean: -64.709346\n",
      "ep 4: ep_len:500 episode reward: total was -41.070000. running mean: -64.472952\n",
      "ep 4: ep_len:740 episode reward: total was -43.040000. running mean: -64.258623\n",
      "ep 4: ep_len:505 episode reward: total was -73.890000. running mean: -64.354937\n",
      "ep 4: ep_len:920 episode reward: total was -106.520000. running mean: -64.776587\n",
      "ep 4: ep_len:323 episode reward: total was -12.830000. running mean: -64.257121\n",
      "ep 4: ep_len:500 episode reward: total was -23.960000. running mean: -63.854150\n",
      "ep 4: ep_len:730 episode reward: total was -19.880000. running mean: -63.414409\n",
      "ep 4: ep_len:630 episode reward: total was -20.680000. running mean: -62.987065\n",
      "ep 4: ep_len:855 episode reward: total was -62.580000. running mean: -62.982994\n",
      "ep 4: ep_len:670 episode reward: total was -39.600000. running mean: -62.749164\n",
      "ep 4: ep_len:625 episode reward: total was -57.500000. running mean: -62.696672\n",
      "ep 4: ep_len:500 episode reward: total was -16.330000. running mean: -62.233006\n",
      "ep 4: ep_len:500 episode reward: total was -38.210000. running mean: -61.992776\n",
      "ep 4: ep_len:635 episode reward: total was -46.220000. running mean: -61.835048\n",
      "ep 4: ep_len:560 episode reward: total was -58.540000. running mean: -61.802097\n",
      "ep 4: ep_len:1035 episode reward: total was -97.280000. running mean: -62.156876\n",
      "ep 4: ep_len:346 episode reward: total was 2.000000. running mean: -61.515308\n",
      "ep 4: ep_len:560 episode reward: total was -30.850000. running mean: -61.208654\n",
      "ep 4: ep_len:720 episode reward: total was -62.730000. running mean: -61.223868\n",
      "ep 4: ep_len:170 episode reward: total was 7.500000. running mean: -60.536629\n",
      "ep 4: ep_len:855 episode reward: total was -75.100000. running mean: -60.682263\n",
      "ep 4: ep_len:705 episode reward: total was -39.040000. running mean: -60.465840\n",
      "ep 4: ep_len:246 episode reward: total was -1.000000. running mean: -59.871182\n",
      "ep 4: ep_len:500 episode reward: total was -23.440000. running mean: -59.506870\n",
      "ep 4: ep_len:138 episode reward: total was 1.000000. running mean: -58.901801\n",
      "ep 4: ep_len:500 episode reward: total was -15.860000. running mean: -58.471383\n",
      "ep 4: ep_len:500 episode reward: total was -12.750000. running mean: -58.014170\n",
      "ep 4: ep_len:610 episode reward: total was -67.050000. running mean: -58.104528\n",
      "ep 4: ep_len:520 episode reward: total was -29.220000. running mean: -57.815683\n",
      "ep 4: ep_len:930 episode reward: total was -82.120000. running mean: -58.058726\n",
      "ep 4: ep_len:510 episode reward: total was -37.470000. running mean: -57.852838\n",
      "ep 4: ep_len:525 episode reward: total was -48.080000. running mean: -57.755110\n",
      "ep 4: ep_len:630 episode reward: total was -37.140000. running mean: -57.548959\n",
      "ep 4: ep_len:500 episode reward: total was -11.370000. running mean: -57.087169\n",
      "ep 4: ep_len:500 episode reward: total was -3.820000. running mean: -56.554498\n",
      "ep 4: ep_len:505 episode reward: total was -32.520000. running mean: -56.314153\n",
      "ep 4: ep_len:735 episode reward: total was -33.250000. running mean: -56.083511\n",
      "ep 4: ep_len:715 episode reward: total was -43.030000. running mean: -55.952976\n",
      "ep 4: ep_len:166 episode reward: total was 3.500000. running mean: -55.358446\n",
      "ep 4: ep_len:745 episode reward: total was -66.720000. running mean: -55.472062\n",
      "ep 4: ep_len:227 episode reward: total was 6.000000. running mean: -54.857341\n",
      "ep 4: ep_len:960 episode reward: total was -147.580000. running mean: -55.784568\n",
      "ep 4: ep_len:590 episode reward: total was -42.790000. running mean: -55.654622\n",
      "ep 4: ep_len:439 episode reward: total was -2.500000. running mean: -55.123076\n",
      "ep 4: ep_len:510 episode reward: total was -16.350000. running mean: -54.735345\n",
      "ep 4: ep_len:500 episode reward: total was -15.810000. running mean: -54.346092\n",
      "ep 4: ep_len:780 episode reward: total was -47.460000. running mean: -54.277231\n",
      "ep 4: ep_len:990 episode reward: total was -44.510000. running mean: -54.179559\n",
      "ep 4: ep_len:500 episode reward: total was -33.940000. running mean: -53.977163\n",
      "ep 4: ep_len:343 episode reward: total was 7.500000. running mean: -53.362391\n",
      "ep 4: ep_len:600 episode reward: total was -42.250000. running mean: -53.251267\n",
      "ep 4: ep_len:560 episode reward: total was -31.250000. running mean: -53.031255\n",
      "ep 4: ep_len:560 episode reward: total was -42.360000. running mean: -52.924542\n",
      "ep 4: ep_len:500 episode reward: total was -35.240000. running mean: -52.747697\n",
      "ep 4: ep_len:820 episode reward: total was -75.170000. running mean: -52.971920\n",
      "ep 4: ep_len:4170 episode reward: total was -725.950000. running mean: -59.701701\n",
      "ep 4: ep_len:500 episode reward: total was -16.950000. running mean: -59.274184\n",
      "ep 4: ep_len:510 episode reward: total was -11.160000. running mean: -58.793042\n",
      "ep 4: ep_len:945 episode reward: total was -41.490000. running mean: -58.620011\n",
      "ep 4: ep_len:925 episode reward: total was -98.310000. running mean: -59.016911\n",
      "ep 4: ep_len:164 episode reward: total was 4.000000. running mean: -58.386742\n",
      "ep 4: ep_len:515 episode reward: total was -23.650000. running mean: -58.039375\n",
      "ep 4: ep_len:860 episode reward: total was -99.990000. running mean: -58.458881\n",
      "ep 4: ep_len:530 episode reward: total was -20.220000. running mean: -58.076492\n",
      "ep 4: ep_len:690 episode reward: total was -45.620000. running mean: -57.951927\n",
      "ep 4: ep_len:990 episode reward: total was -59.140000. running mean: -57.963808\n",
      "ep 4: ep_len:500 episode reward: total was -54.720000. running mean: -57.931370\n",
      "ep 4: ep_len:500 episode reward: total was -22.370000. running mean: -57.575756\n",
      "ep 4: ep_len:203 episode reward: total was 2.500000. running mean: -56.974999\n",
      "ep 4: ep_len:500 episode reward: total was -26.150000. running mean: -56.666749\n",
      "ep 4: ep_len:715 episode reward: total was -34.980000. running mean: -56.449881\n",
      "ep 4: ep_len:500 episode reward: total was -45.720000. running mean: -56.342582\n",
      "ep 4: ep_len:1030 episode reward: total was -56.790000. running mean: -56.347056\n",
      "ep 4: ep_len:785 episode reward: total was -68.660000. running mean: -56.470186\n",
      "ep 4: ep_len:520 episode reward: total was -7.780000. running mean: -55.983284\n",
      "ep 4: ep_len:500 episode reward: total was -18.840000. running mean: -55.611851\n",
      "ep 4: ep_len:500 episode reward: total was -19.880000. running mean: -55.254533\n",
      "ep 4: ep_len:505 episode reward: total was -16.840000. running mean: -54.870387\n",
      "ep 4: ep_len:510 episode reward: total was -14.900000. running mean: -54.470684\n",
      "ep 4: ep_len:730 episode reward: total was -70.800000. running mean: -54.633977\n",
      "ep 4: ep_len:505 episode reward: total was -1.290000. running mean: -54.100537\n",
      "ep 4: ep_len:1050 episode reward: total was -54.430000. running mean: -54.103832\n",
      "ep 4: ep_len:500 episode reward: total was -19.320000. running mean: -53.755993\n",
      "ep 4: ep_len:555 episode reward: total was -76.190000. running mean: -53.980333\n",
      "ep 4: ep_len:500 episode reward: total was -45.680000. running mean: -53.897330\n",
      "ep 4: ep_len:870 episode reward: total was -63.160000. running mean: -53.989957\n",
      "ep 4: ep_len:1365 episode reward: total was -160.420000. running mean: -55.054257\n",
      "ep 4: ep_len:500 episode reward: total was -11.880000. running mean: -54.622515\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 4: ep_len:500 episode reward: total was 3.500000. running mean: -54.041289\n",
      "ep 4: ep_len:875 episode reward: total was -43.130000. running mean: -53.932176\n",
      "ep 4: ep_len:500 episode reward: total was -30.710000. running mean: -53.699955\n",
      "ep 4: ep_len:500 episode reward: total was -31.790000. running mean: -53.480855\n",
      "ep 4: ep_len:510 episode reward: total was -45.490000. running mean: -53.400947\n",
      "ep 4: ep_len:500 episode reward: total was -22.180000. running mean: -53.088737\n",
      "ep 4: ep_len:845 episode reward: total was -54.920000. running mean: -53.107050\n",
      "ep 4: ep_len:515 episode reward: total was -34.240000. running mean: -52.918379\n",
      "ep 4: ep_len:585 episode reward: total was -72.290000. running mean: -53.112095\n",
      "ep 4: ep_len:500 episode reward: total was -10.930000. running mean: -52.690275\n",
      "ep 4: ep_len:700 episode reward: total was -40.940000. running mean: -52.572772\n",
      "ep 4: ep_len:78 episode reward: total was 4.500000. running mean: -52.002044\n",
      "ep 4: ep_len:605 episode reward: total was -63.450000. running mean: -52.116524\n",
      "ep 4: ep_len:505 episode reward: total was -23.640000. running mean: -51.831758\n",
      "ep 4: ep_len:575 episode reward: total was -5.300000. running mean: -51.366441\n",
      "ep 4: ep_len:805 episode reward: total was -64.090000. running mean: -51.493676\n",
      "ep 4: ep_len:940 episode reward: total was -30.270000. running mean: -51.281440\n",
      "ep 4: ep_len:520 episode reward: total was -66.160000. running mean: -51.430225\n",
      "ep 4: ep_len:500 episode reward: total was -23.720000. running mean: -51.153123\n",
      "ep 4: ep_len:258 episode reward: total was 6.000000. running mean: -50.581592\n",
      "ep 4: ep_len:530 episode reward: total was -50.060000. running mean: -50.576376\n",
      "ep 4: ep_len:540 episode reward: total was -57.030000. running mean: -50.640912\n",
      "ep 4: ep_len:246 episode reward: total was 6.500000. running mean: -50.069503\n",
      "ep 4: ep_len:575 episode reward: total was -44.350000. running mean: -50.012308\n",
      "ep 4: ep_len:535 episode reward: total was -35.830000. running mean: -49.870485\n",
      "ep 4: ep_len:500 episode reward: total was -17.270000. running mean: -49.544480\n",
      "ep 4: ep_len:222 episode reward: total was 8.500000. running mean: -48.964035\n",
      "ep 4: ep_len:239 episode reward: total was -12.000000. running mean: -48.594395\n",
      "ep 4: ep_len:750 episode reward: total was -42.330000. running mean: -48.531751\n",
      "ep 4: ep_len:205 episode reward: total was 4.000000. running mean: -48.006433\n",
      "ep 4: ep_len:755 episode reward: total was -31.740000. running mean: -47.843769\n",
      "ep 4: ep_len:500 episode reward: total was -20.360000. running mean: -47.568931\n",
      "ep 4: ep_len:545 episode reward: total was -47.440000. running mean: -47.567642\n",
      "ep 4: ep_len:825 episode reward: total was -48.800000. running mean: -47.579966\n",
      "ep 4: ep_len:650 episode reward: total was -55.800000. running mean: -47.662166\n",
      "ep 4: ep_len:695 episode reward: total was -30.480000. running mean: -47.490344\n",
      "ep 4: ep_len:500 episode reward: total was -25.230000. running mean: -47.267741\n",
      "ep 4: ep_len:500 episode reward: total was -19.310000. running mean: -46.988163\n",
      "ep 4: ep_len:500 episode reward: total was -35.380000. running mean: -46.872082\n",
      "ep 4: ep_len:510 episode reward: total was -50.020000. running mean: -46.903561\n",
      "ep 4: ep_len:1260 episode reward: total was -189.920000. running mean: -48.333725\n",
      "ep 4: ep_len:910 episode reward: total was -50.760000. running mean: -48.357988\n",
      "ep 4: ep_len:505 episode reward: total was -39.370000. running mean: -48.268108\n",
      "ep 4: ep_len:575 episode reward: total was -40.800000. running mean: -48.193427\n",
      "ep 4: ep_len:183 episode reward: total was 4.500000. running mean: -47.666493\n",
      "ep 4: ep_len:134 episode reward: total was 3.000000. running mean: -47.159828\n",
      "ep 4: ep_len:635 episode reward: total was -49.250000. running mean: -47.180730\n",
      "ep 4: ep_len:1065 episode reward: total was -113.180000. running mean: -47.840722\n",
      "ep 4: ep_len:525 episode reward: total was -46.960000. running mean: -47.831915\n",
      "ep 4: ep_len:472 episode reward: total was -35.640000. running mean: -47.709996\n",
      "ep 4: ep_len:825 episode reward: total was -39.090000. running mean: -47.623796\n",
      "ep 4: ep_len:975 episode reward: total was -82.210000. running mean: -47.969658\n",
      "ep 4: ep_len:1815 episode reward: total was -258.520000. running mean: -50.075162\n",
      "ep 4: ep_len:700 episode reward: total was -60.750000. running mean: -50.181910\n",
      "ep 4: ep_len:500 episode reward: total was 14.000000. running mean: -49.540091\n",
      "ep 4: ep_len:805 episode reward: total was -46.400000. running mean: -49.508690\n",
      "ep 4: ep_len:600 episode reward: total was -17.420000. running mean: -49.187803\n",
      "ep 4: ep_len:680 episode reward: total was -71.600000. running mean: -49.411925\n",
      "ep 4: ep_len:840 episode reward: total was -57.560000. running mean: -49.493406\n",
      "ep 4: ep_len:1035 episode reward: total was -93.410000. running mean: -49.932572\n",
      "ep 4: ep_len:520 episode reward: total was -78.800000. running mean: -50.221246\n",
      "ep 4: ep_len:500 episode reward: total was -39.570000. running mean: -50.114733\n",
      "ep 4: ep_len:500 episode reward: total was -18.320000. running mean: -49.796786\n",
      "ep 4: ep_len:143 episode reward: total was -0.500000. running mean: -49.303818\n",
      "ep 4: ep_len:217 episode reward: total was 9.500000. running mean: -48.715780\n",
      "ep 4: ep_len:500 episode reward: total was -33.820000. running mean: -48.566822\n",
      "ep 4: ep_len:795 episode reward: total was -66.240000. running mean: -48.743554\n",
      "ep 4: ep_len:680 episode reward: total was -48.020000. running mean: -48.736319\n",
      "ep 4: ep_len:500 episode reward: total was -4.550000. running mean: -48.294455\n",
      "ep 4: ep_len:510 episode reward: total was -33.370000. running mean: -48.145211\n",
      "ep 4: ep_len:192 episode reward: total was 1.500000. running mean: -47.648759\n",
      "ep 4: ep_len:313 episode reward: total was 10.510000. running mean: -47.067171\n",
      "ep 4: ep_len:750 episode reward: total was -80.850000. running mean: -47.404999\n",
      "ep 4: ep_len:730 episode reward: total was -48.430000. running mean: -47.415249\n",
      "ep 4: ep_len:214 episode reward: total was 9.000000. running mean: -46.851097\n",
      "ep 4: ep_len:895 episode reward: total was -54.000000. running mean: -46.922586\n",
      "ep 4: ep_len:610 episode reward: total was -20.380000. running mean: -46.657160\n",
      "ep 4: ep_len:71 episode reward: total was 2.000000. running mean: -46.170588\n",
      "ep 4: ep_len:500 episode reward: total was -33.890000. running mean: -46.047783\n",
      "ep 4: ep_len:500 episode reward: total was 11.500000. running mean: -45.472305\n",
      "ep 4: ep_len:500 episode reward: total was -24.860000. running mean: -45.266182\n",
      "ep 4: ep_len:500 episode reward: total was -36.370000. running mean: -45.177220\n",
      "ep 4: ep_len:442 episode reward: total was -13.300000. running mean: -44.858448\n",
      "ep 4: ep_len:1010 episode reward: total was -38.390000. running mean: -44.793763\n",
      "ep 4: ep_len:565 episode reward: total was -54.960000. running mean: -44.895426\n",
      "ep 4: ep_len:795 episode reward: total was -96.230000. running mean: -45.408771\n",
      "ep 4: ep_len:500 episode reward: total was -11.850000. running mean: -45.073184\n",
      "ep 4: ep_len:885 episode reward: total was -70.480000. running mean: -45.327252\n",
      "ep 4: ep_len:515 episode reward: total was -50.530000. running mean: -45.379279\n",
      "ep 4: ep_len:535 episode reward: total was -43.420000. running mean: -45.359686\n",
      "ep 4: ep_len:575 episode reward: total was -75.630000. running mean: -45.662390\n",
      "ep 4: ep_len:995 episode reward: total was -116.720000. running mean: -46.372966\n",
      "ep 4: ep_len:655 episode reward: total was -56.650000. running mean: -46.475736\n",
      "ep 4: ep_len:980 episode reward: total was -62.730000. running mean: -46.638279\n",
      "ep 4: ep_len:505 episode reward: total was -36.900000. running mean: -46.540896\n",
      "ep 4: ep_len:665 episode reward: total was -57.440000. running mean: -46.649887\n",
      "ep 4: ep_len:332 episode reward: total was 6.500000. running mean: -46.118388\n",
      "ep 4: ep_len:900 episode reward: total was -108.450000. running mean: -46.741704\n",
      "ep 4: ep_len:500 episode reward: total was -32.590000. running mean: -46.600187\n",
      "ep 4: ep_len:750 episode reward: total was -54.070000. running mean: -46.674885\n",
      "ep 4: ep_len:500 episode reward: total was -39.480000. running mean: -46.602936\n",
      "ep 4: ep_len:355 episode reward: total was -69.000000. running mean: -46.826907\n",
      "ep 4: ep_len:124 episode reward: total was 1.500000. running mean: -46.343638\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 4: ep_len:530 episode reward: total was -32.990000. running mean: -46.210102\n",
      "ep 4: ep_len:500 episode reward: total was -30.420000. running mean: -46.052201\n",
      "ep 4: ep_len:1455 episode reward: total was -136.520000. running mean: -46.956879\n",
      "ep 4: ep_len:1030 episode reward: total was -148.970000. running mean: -47.977010\n",
      "ep 4: ep_len:515 episode reward: total was -69.720000. running mean: -48.194440\n",
      "ep 4: ep_len:500 episode reward: total was -27.300000. running mean: -47.985495\n",
      "ep 4: ep_len:208 episode reward: total was -0.500000. running mean: -47.510640\n",
      "ep 4: ep_len:500 episode reward: total was -49.350000. running mean: -47.529034\n",
      "ep 4: ep_len:500 episode reward: total was -48.050000. running mean: -47.534244\n",
      "ep 4: ep_len:500 episode reward: total was -48.890000. running mean: -47.547801\n",
      "ep 4: ep_len:500 episode reward: total was -24.430000. running mean: -47.316623\n",
      "ep 4: ep_len:695 episode reward: total was -105.690000. running mean: -47.900357\n",
      "ep 4: ep_len:178 episode reward: total was 0.000000. running mean: -47.421353\n",
      "ep 4: ep_len:500 episode reward: total was -36.950000. running mean: -47.316640\n",
      "ep 4: ep_len:500 episode reward: total was -14.240000. running mean: -46.985873\n",
      "ep 4: ep_len:500 episode reward: total was -15.780000. running mean: -46.673815\n",
      "ep 4: ep_len:500 episode reward: total was 4.000000. running mean: -46.167077\n",
      "ep 4: ep_len:685 episode reward: total was -77.460000. running mean: -46.480006\n",
      "ep 4: ep_len:665 episode reward: total was -53.750000. running mean: -46.552706\n",
      "ep 4: ep_len:535 episode reward: total was -38.370000. running mean: -46.470879\n",
      "ep 4: ep_len:505 episode reward: total was -32.430000. running mean: -46.330470\n",
      "ep 4: ep_len:690 episode reward: total was -44.450000. running mean: -46.311665\n",
      "ep 4: ep_len:510 episode reward: total was -40.820000. running mean: -46.256749\n",
      "ep 4: ep_len:510 episode reward: total was -22.010000. running mean: -46.014281\n",
      "ep 4: ep_len:660 episode reward: total was -48.190000. running mean: -46.036038\n",
      "ep 4: ep_len:540 episode reward: total was -16.500000. running mean: -45.740678\n",
      "ep 4: ep_len:500 episode reward: total was -21.730000. running mean: -45.500571\n",
      "ep 4: ep_len:975 episode reward: total was -68.460000. running mean: -45.730165\n",
      "ep 4: ep_len:433 episode reward: total was -57.340000. running mean: -45.846264\n",
      "ep 4: ep_len:439 episode reward: total was -1.500000. running mean: -45.402801\n",
      "ep 4: ep_len:1210 episode reward: total was -175.030000. running mean: -46.699073\n",
      "ep 4: ep_len:500 episode reward: total was -67.790000. running mean: -46.909982\n",
      "ep 4: ep_len:690 episode reward: total was -45.060000. running mean: -46.891483\n",
      "ep 4: ep_len:575 episode reward: total was -49.890000. running mean: -46.921468\n",
      "ep 4: ep_len:715 episode reward: total was -42.540000. running mean: -46.877653\n",
      "ep 4: ep_len:253 episode reward: total was 2.500000. running mean: -46.383876\n",
      "ep 4: ep_len:880 episode reward: total was -53.470000. running mean: -46.454738\n",
      "ep 4: ep_len:945 episode reward: total was -91.570000. running mean: -46.905890\n",
      "ep 4: ep_len:283 episode reward: total was 0.000000. running mean: -46.436831\n",
      "ep 4: ep_len:500 episode reward: total was -24.950000. running mean: -46.221963\n",
      "ep 4: ep_len:500 episode reward: total was -26.680000. running mean: -46.026543\n",
      "ep 4: ep_len:346 episode reward: total was 3.000000. running mean: -45.536278\n",
      "ep 4: ep_len:500 episode reward: total was -41.990000. running mean: -45.500815\n",
      "ep 4: ep_len:565 episode reward: total was -65.790000. running mean: -45.703707\n",
      "ep 4: ep_len:500 episode reward: total was -58.420000. running mean: -45.830870\n",
      "ep 4: ep_len:500 episode reward: total was -34.700000. running mean: -45.719561\n",
      "ep 4: ep_len:2335 episode reward: total was -282.150000. running mean: -48.083866\n",
      "ep 4: ep_len:500 episode reward: total was -25.420000. running mean: -47.857227\n",
      "ep 4: ep_len:765 episode reward: total was -48.500000. running mean: -47.863655\n",
      "ep 4: ep_len:1720 episode reward: total was -172.840000. running mean: -49.113418\n",
      "ep 4: ep_len:575 episode reward: total was -33.420000. running mean: -48.956484\n",
      "ep 4: ep_len:695 episode reward: total was -77.930000. running mean: -49.246219\n",
      "ep 4: ep_len:700 episode reward: total was -54.900000. running mean: -49.302757\n",
      "ep 4: ep_len:500 episode reward: total was 11.500000. running mean: -48.694729\n",
      "ep 4: ep_len:1050 episode reward: total was -134.790000. running mean: -49.555682\n",
      "ep 4: ep_len:505 episode reward: total was -38.980000. running mean: -49.449925\n",
      "ep 4: ep_len:1400 episode reward: total was -178.530000. running mean: -50.740726\n",
      "ep 4: ep_len:500 episode reward: total was -54.230000. running mean: -50.775619\n",
      "ep 4: ep_len:500 episode reward: total was -2.500000. running mean: -50.292863\n",
      "ep 4: ep_len:1015 episode reward: total was -56.500000. running mean: -50.354934\n",
      "ep 4: ep_len:585 episode reward: total was -48.860000. running mean: -50.339985\n",
      "ep 4: ep_len:515 episode reward: total was -45.480000. running mean: -50.291385\n",
      "ep 4: ep_len:237 episode reward: total was 11.500000. running mean: -49.673471\n",
      "ep 4: ep_len:97 episode reward: total was 0.500000. running mean: -49.171736\n",
      "ep 4: ep_len:218 episode reward: total was -12.500000. running mean: -48.805019\n",
      "ep 4: ep_len:795 episode reward: total was -71.670000. running mean: -49.033669\n",
      "ep 4: ep_len:238 episode reward: total was 9.000000. running mean: -48.453332\n",
      "ep 4: ep_len:805 episode reward: total was -65.220000. running mean: -48.620999\n",
      "ep 4: ep_len:670 episode reward: total was -45.170000. running mean: -48.586489\n",
      "ep 4: ep_len:500 episode reward: total was -46.180000. running mean: -48.562424\n",
      "ep 4: ep_len:332 episode reward: total was -2.000000. running mean: -48.096800\n",
      "ep 4: ep_len:540 episode reward: total was -32.410000. running mean: -47.939932\n",
      "ep 4: ep_len:1290 episode reward: total was -54.780000. running mean: -48.008332\n",
      "ep 4: ep_len:500 episode reward: total was -24.160000. running mean: -47.769849\n",
      "ep 4: ep_len:167 episode reward: total was 4.500000. running mean: -47.247150\n",
      "ep 4: ep_len:1290 episode reward: total was -106.060000. running mean: -47.835279\n",
      "ep 4: ep_len:505 episode reward: total was -33.270000. running mean: -47.689626\n",
      "ep 4: ep_len:205 episode reward: total was -0.500000. running mean: -47.217730\n",
      "ep 4: ep_len:789 episode reward: total was -107.130000. running mean: -47.816853\n",
      "ep 4: ep_len:780 episode reward: total was -45.560000. running mean: -47.794284\n",
      "ep 4: ep_len:885 episode reward: total was -69.960000. running mean: -48.015941\n",
      "ep 4: ep_len:600 episode reward: total was -47.570000. running mean: -48.011482\n",
      "ep 4: ep_len:775 episode reward: total was -37.920000. running mean: -47.910567\n",
      "ep 4: ep_len:920 episode reward: total was -74.450000. running mean: -48.175961\n",
      "ep 4: ep_len:525 episode reward: total was -47.650000. running mean: -48.170702\n",
      "ep 4: ep_len:1055 episode reward: total was -133.770000. running mean: -49.026695\n",
      "ep 4: ep_len:1445 episode reward: total was -239.530000. running mean: -50.931728\n",
      "ep 4: ep_len:500 episode reward: total was -18.330000. running mean: -50.605711\n",
      "ep 4: ep_len:510 episode reward: total was -63.690000. running mean: -50.736553\n",
      "ep 4: ep_len:1025 episode reward: total was -145.950000. running mean: -51.688688\n",
      "ep 4: ep_len:500 episode reward: total was -56.240000. running mean: -51.734201\n",
      "ep 4: ep_len:1435 episode reward: total was -81.450000. running mean: -52.031359\n",
      "ep 4: ep_len:1140 episode reward: total was -156.490000. running mean: -53.075945\n",
      "ep 4: ep_len:1010 episode reward: total was -135.010000. running mean: -53.895286\n",
      "ep 4: ep_len:500 episode reward: total was -43.210000. running mean: -53.788433\n",
      "ep 4: ep_len:600 episode reward: total was -42.030000. running mean: -53.670849\n",
      "ep 4: ep_len:725 episode reward: total was -47.570000. running mean: -53.609840\n",
      "ep 4: ep_len:695 episode reward: total was -69.450000. running mean: -53.768242\n",
      "ep 4: ep_len:680 episode reward: total was -82.380000. running mean: -54.054359\n",
      "ep 4: ep_len:730 episode reward: total was -56.160000. running mean: -54.075416\n",
      "ep 4: ep_len:865 episode reward: total was -63.970000. running mean: -54.174362\n",
      "ep 4: ep_len:500 episode reward: total was -28.660000. running mean: -53.919218\n",
      "ep 4: ep_len:500 episode reward: total was -23.380000. running mean: -53.613826\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 4: ep_len:510 episode reward: total was -40.930000. running mean: -53.486988\n",
      "ep 4: ep_len:1140 episode reward: total was -103.330000. running mean: -53.985418\n",
      "ep 4: ep_len:825 episode reward: total was -57.070000. running mean: -54.016264\n",
      "ep 4: ep_len:1010 episode reward: total was -115.330000. running mean: -54.629401\n",
      "ep 4: ep_len:575 episode reward: total was -68.070000. running mean: -54.763807\n",
      "ep 4: ep_len:500 episode reward: total was -52.580000. running mean: -54.741969\n",
      "ep 4: ep_len:1050 episode reward: total was -117.130000. running mean: -55.365849\n",
      "ep 4: ep_len:1100 episode reward: total was -132.670000. running mean: -56.138891\n",
      "ep 4: ep_len:715 episode reward: total was -46.090000. running mean: -56.038402\n",
      "ep 4: ep_len:500 episode reward: total was -35.930000. running mean: -55.837318\n",
      "ep 4: ep_len:595 episode reward: total was -47.340000. running mean: -55.752345\n",
      "ep 4: ep_len:635 episode reward: total was -73.460000. running mean: -55.929421\n",
      "ep 4: ep_len:500 episode reward: total was -37.450000. running mean: -55.744627\n",
      "ep 4: ep_len:660 episode reward: total was -53.760000. running mean: -55.724781\n",
      "ep 4: ep_len:905 episode reward: total was -34.590000. running mean: -55.513433\n",
      "ep 4: ep_len:525 episode reward: total was -26.870000. running mean: -55.226999\n",
      "ep 4: ep_len:261 episode reward: total was 0.500000. running mean: -54.669729\n",
      "ep 4: ep_len:500 episode reward: total was -28.690000. running mean: -54.409931\n",
      "ep 4: ep_len:500 episode reward: total was -37.490000. running mean: -54.240732\n",
      "ep 4: ep_len:500 episode reward: total was -36.750000. running mean: -54.065825\n",
      "ep 4: ep_len:985 episode reward: total was -78.880000. running mean: -54.313966\n",
      "ep 4: ep_len:560 episode reward: total was -13.350000. running mean: -53.904327\n",
      "ep 4: ep_len:695 episode reward: total was -41.930000. running mean: -53.784583\n",
      "ep 4: ep_len:835 episode reward: total was -52.410000. running mean: -53.770838\n",
      "ep 4: ep_len:243 episode reward: total was 3.500000. running mean: -53.198129\n",
      "ep 4: ep_len:500 episode reward: total was -50.210000. running mean: -53.168248\n",
      "ep 4: ep_len:500 episode reward: total was -20.410000. running mean: -52.840665\n",
      "ep 4: ep_len:535 episode reward: total was -48.520000. running mean: -52.797459\n",
      "ep 4: ep_len:515 episode reward: total was -50.010000. running mean: -52.769584\n",
      "ep 4: ep_len:530 episode reward: total was -37.370000. running mean: -52.615588\n",
      "ep 4: ep_len:505 episode reward: total was -34.910000. running mean: -52.438532\n",
      "ep 4: ep_len:500 episode reward: total was -24.970000. running mean: -52.163847\n",
      "ep 4: ep_len:500 episode reward: total was -45.050000. running mean: -52.092709\n",
      "ep 4: ep_len:500 episode reward: total was -63.720000. running mean: -52.208982\n",
      "ep 4: ep_len:500 episode reward: total was -8.220000. running mean: -51.769092\n",
      "ep 4: ep_len:500 episode reward: total was -35.990000. running mean: -51.611301\n",
      "ep 4: ep_len:287 episode reward: total was -5.500000. running mean: -51.150188\n",
      "ep 4: ep_len:500 episode reward: total was -30.810000. running mean: -50.946786\n",
      "ep 4: ep_len:685 episode reward: total was -43.880000. running mean: -50.876118\n",
      "ep 4: ep_len:860 episode reward: total was -64.940000. running mean: -51.016757\n",
      "ep 4: ep_len:640 episode reward: total was -37.880000. running mean: -50.885389\n",
      "ep 4: ep_len:500 episode reward: total was 4.000000. running mean: -50.336535\n",
      "ep 4: ep_len:167 episode reward: total was -2.500000. running mean: -49.858170\n",
      "ep 4: ep_len:500 episode reward: total was -21.840000. running mean: -49.577988\n",
      "ep 4: ep_len:855 episode reward: total was -62.630000. running mean: -49.708509\n",
      "ep 4: ep_len:500 episode reward: total was -7.820000. running mean: -49.289623\n",
      "ep 4: ep_len:500 episode reward: total was -21.560000. running mean: -49.012327\n",
      "ep 4: ep_len:510 episode reward: total was -33.690000. running mean: -48.859104\n",
      "ep 4: ep_len:955 episode reward: total was -56.720000. running mean: -48.937713\n",
      "ep 4: ep_len:840 episode reward: total was -45.680000. running mean: -48.905136\n",
      "ep 4: ep_len:500 episode reward: total was -25.320000. running mean: -48.669284\n",
      "ep 4: ep_len:267 episode reward: total was 4.000000. running mean: -48.142592\n",
      "ep 4: ep_len:500 episode reward: total was -33.320000. running mean: -47.994366\n",
      "ep 4: ep_len:505 episode reward: total was -12.880000. running mean: -47.643222\n",
      "ep 4: ep_len:42275 episode reward: total was -8073.390000. running mean: -127.900690\n",
      "ep 4: ep_len:770 episode reward: total was -106.580000. running mean: -127.687483\n",
      "ep 4: ep_len:505 episode reward: total was -49.160000. running mean: -126.902208\n",
      "ep 4: ep_len:675 episode reward: total was -63.370000. running mean: -126.266886\n",
      "ep 4: ep_len:870 episode reward: total was -165.450000. running mean: -126.658717\n",
      "ep 4: ep_len:570 episode reward: total was -104.960000. running mean: -126.441730\n",
      "ep 4: ep_len:560 episode reward: total was -107.980000. running mean: -126.257113\n",
      "ep 4: ep_len:1080 episode reward: total was -140.450000. running mean: -126.399042\n",
      "ep 4: ep_len:432 episode reward: total was -79.470000. running mean: -125.929751\n",
      "ep 4: ep_len:500 episode reward: total was -63.980000. running mean: -125.310254\n",
      "ep 4: ep_len:510 episode reward: total was -41.500000. running mean: -124.472151\n",
      "ep 4: ep_len:625 episode reward: total was -117.460000. running mean: -124.402030\n",
      "ep 4: ep_len:870 episode reward: total was -166.440000. running mean: -124.822409\n",
      "ep 4: ep_len:262 episode reward: total was 0.500000. running mean: -123.569185\n",
      "ep 4: ep_len:830 episode reward: total was -83.270000. running mean: -123.166193\n",
      "ep 4: ep_len:478 episode reward: total was -13.380000. running mean: -122.068331\n",
      "ep 4: ep_len:900 episode reward: total was -88.170000. running mean: -121.729348\n",
      "ep 4: ep_len:1355 episode reward: total was -222.160000. running mean: -122.733655\n",
      "ep 4: ep_len:500 episode reward: total was -32.720000. running mean: -121.833518\n",
      "ep 4: ep_len:565 episode reward: total was -106.450000. running mean: -121.679683\n",
      "ep 4: ep_len:515 episode reward: total was -34.910000. running mean: -120.811986\n",
      "ep 4: ep_len:500 episode reward: total was -70.450000. running mean: -120.308366\n",
      "ep 4: ep_len:505 episode reward: total was -88.930000. running mean: -119.994583\n",
      "ep 4: ep_len:515 episode reward: total was -93.960000. running mean: -119.734237\n",
      "ep 4: ep_len:500 episode reward: total was -30.470000. running mean: -118.841594\n",
      "ep 4: ep_len:1495 episode reward: total was -276.310000. running mean: -120.416278\n",
      "ep 4: ep_len:830 episode reward: total was -82.980000. running mean: -120.041916\n",
      "ep 4: ep_len:885 episode reward: total was -131.350000. running mean: -120.154996\n",
      "ep 4: ep_len:500 episode reward: total was -40.440000. running mean: -119.357846\n",
      "ep 4: ep_len:565 episode reward: total was -40.300000. running mean: -118.567268\n",
      "ep 4: ep_len:500 episode reward: total was -32.450000. running mean: -117.706095\n",
      "ep 4: ep_len:670 episode reward: total was -65.120000. running mean: -117.180234\n",
      "ep 4: ep_len:2215 episode reward: total was -333.970000. running mean: -119.348132\n",
      "ep 4: ep_len:515 episode reward: total was -31.700000. running mean: -118.471651\n",
      "ep 4: ep_len:342 episode reward: total was 0.000000. running mean: -117.286934\n",
      "ep 4: ep_len:1740 episode reward: total was -162.870000. running mean: -117.742765\n",
      "ep 4: ep_len:1260 episode reward: total was -124.840000. running mean: -117.813737\n",
      "ep 4: ep_len:505 episode reward: total was -26.610000. running mean: -116.901700\n",
      "ep 4: ep_len:500 episode reward: total was -37.670000. running mean: -116.109383\n",
      "ep 4: ep_len:830 episode reward: total was -72.120000. running mean: -115.669489\n",
      "ep 4: ep_len:500 episode reward: total was -26.480000. running mean: -114.777594\n",
      "ep 4: ep_len:456 episode reward: total was -25.840000. running mean: -113.888218\n",
      "ep 4: ep_len:565 episode reward: total was -74.150000. running mean: -113.490836\n",
      "ep 4: ep_len:815 episode reward: total was -81.190000. running mean: -113.167828\n",
      "ep 4: ep_len:500 episode reward: total was -41.530000. running mean: -112.451449\n",
      "ep 4: ep_len:198 episode reward: total was -21.000000. running mean: -111.536935\n",
      "ep 4: ep_len:505 episode reward: total was -16.650000. running mean: -110.588066\n",
      "ep 4: ep_len:520 episode reward: total was -29.850000. running mean: -109.780685\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 4: ep_len:620 episode reward: total was -33.640000. running mean: -109.019278\n",
      "ep 4: ep_len:500 episode reward: total was -37.970000. running mean: -108.308785\n",
      "ep 4: ep_len:500 episode reward: total was -36.510000. running mean: -107.590797\n",
      "ep 4: ep_len:670 episode reward: total was -65.340000. running mean: -107.168289\n",
      "ep 4: ep_len:785 episode reward: total was -100.640000. running mean: -107.103007\n",
      "ep 4: ep_len:500 episode reward: total was -20.590000. running mean: -106.237876\n",
      "ep 4: ep_len:500 episode reward: total was -39.550000. running mean: -105.570998\n",
      "ep 4: ep_len:830 episode reward: total was -38.590000. running mean: -104.901188\n",
      "ep 4: ep_len:177 episode reward: total was 1.000000. running mean: -103.842176\n",
      "ep 4: ep_len:1205 episode reward: total was -69.920000. running mean: -103.502954\n",
      "ep 4: ep_len:136 episode reward: total was 4.500000. running mean: -102.422925\n",
      "ep 4: ep_len:500 episode reward: total was -20.860000. running mean: -101.607295\n",
      "ep 4: ep_len:1110 episode reward: total was -26.310000. running mean: -100.854322\n",
      "ep 4: ep_len:520 episode reward: total was -34.850000. running mean: -100.194279\n",
      "ep 4: ep_len:172 episode reward: total was 6.500000. running mean: -99.127336\n",
      "ep 4: ep_len:515 episode reward: total was -57.600000. running mean: -98.712063\n",
      "ep 4: ep_len:500 episode reward: total was -51.200000. running mean: -98.236942\n",
      "ep 4: ep_len:2115 episode reward: total was -257.220000. running mean: -99.826773\n",
      "ep 4: ep_len:138 episode reward: total was -3.000000. running mean: -98.858505\n",
      "ep 4: ep_len:139 episode reward: total was -3.000000. running mean: -97.899920\n",
      "ep 4: ep_len:505 episode reward: total was -42.640000. running mean: -97.347321\n",
      "ep 4: ep_len:730 episode reward: total was -65.250000. running mean: -97.026348\n",
      "ep 4: ep_len:186 episode reward: total was -6.500000. running mean: -96.121084\n",
      "ep 4: ep_len:505 episode reward: total was -38.120000. running mean: -95.541073\n",
      "ep 4: ep_len:500 episode reward: total was -20.210000. running mean: -94.787763\n",
      "ep 4: ep_len:735 episode reward: total was -53.120000. running mean: -94.371085\n",
      "ep 4: ep_len:65 episode reward: total was 2.000000. running mean: -93.407374\n",
      "ep 4: ep_len:500 episode reward: total was -58.850000. running mean: -93.061800\n",
      "ep 4: ep_len:820 episode reward: total was -87.290000. running mean: -93.004082\n",
      "ep 4: ep_len:500 episode reward: total was -32.930000. running mean: -92.403342\n",
      "ep 4: ep_len:590 episode reward: total was -59.960000. running mean: -92.078908\n",
      "ep 4: ep_len:180 episode reward: total was 2.000000. running mean: -91.138119\n",
      "ep 4: ep_len:500 episode reward: total was -16.050000. running mean: -90.387238\n",
      "ep 4: ep_len:665 episode reward: total was -46.680000. running mean: -89.950166\n",
      "ep 4: ep_len:855 episode reward: total was -55.390000. running mean: -89.604564\n",
      "ep 4: ep_len:955 episode reward: total was -60.540000. running mean: -89.313918\n",
      "ep 4: ep_len:640 episode reward: total was -17.580000. running mean: -88.596579\n",
      "ep 4: ep_len:580 episode reward: total was -37.270000. running mean: -88.083313\n",
      "ep 4: ep_len:805 episode reward: total was -44.300000. running mean: -87.645480\n",
      "ep 4: ep_len:500 episode reward: total was -37.950000. running mean: -87.148525\n",
      "ep 4: ep_len:619 episode reward: total was -62.690000. running mean: -86.903940\n",
      "ep 4: ep_len:800 episode reward: total was -37.110000. running mean: -86.406001\n",
      "ep 4: ep_len:1190 episode reward: total was -97.630000. running mean: -86.518241\n",
      "ep 4: ep_len:500 episode reward: total was -11.860000. running mean: -85.771658\n",
      "ep 4: ep_len:1500 episode reward: total was -246.520000. running mean: -87.379142\n",
      "ep 4: ep_len:565 episode reward: total was -75.650000. running mean: -87.261850\n",
      "ep 4: ep_len:810 episode reward: total was -67.110000. running mean: -87.060332\n",
      "ep 4: ep_len:267 episode reward: total was 5.500000. running mean: -86.134728\n",
      "ep 4: ep_len:500 episode reward: total was -48.630000. running mean: -85.759681\n",
      "ep 4: ep_len:905 episode reward: total was -51.290000. running mean: -85.414984\n",
      "ep 4: ep_len:605 episode reward: total was -75.600000. running mean: -85.316835\n",
      "ep 4: ep_len:505 episode reward: total was -20.190000. running mean: -84.665566\n",
      "ep 4: ep_len:580 episode reward: total was -16.810000. running mean: -83.987011\n",
      "ep 4: ep_len:505 episode reward: total was -42.470000. running mean: -83.571840\n",
      "ep 4: ep_len:820 episode reward: total was -30.250000. running mean: -83.038622\n",
      "ep 4: ep_len:505 episode reward: total was -23.890000. running mean: -82.447136\n",
      "ep 4: ep_len:660 episode reward: total was -52.750000. running mean: -82.150164\n",
      "ep 4: ep_len:500 episode reward: total was -60.380000. running mean: -81.932463\n",
      "ep 4: ep_len:500 episode reward: total was -24.920000. running mean: -81.362338\n",
      "ep 4: ep_len:765 episode reward: total was -57.100000. running mean: -81.119715\n",
      "ep 4: ep_len:910 episode reward: total was -78.020000. running mean: -81.088718\n",
      "ep 4: ep_len:545 episode reward: total was -51.970000. running mean: -80.797530\n",
      "ep 4: ep_len:224 episode reward: total was 1.500000. running mean: -79.974555\n",
      "ep 4: ep_len:500 episode reward: total was -63.200000. running mean: -79.806810\n",
      "ep 4: ep_len:500 episode reward: total was -20.370000. running mean: -79.212441\n",
      "ep 4: ep_len:1040 episode reward: total was -98.500000. running mean: -79.405317\n",
      "ep 4: ep_len:500 episode reward: total was -18.940000. running mean: -78.800664\n",
      "ep 4: ep_len:1360 episode reward: total was -155.270000. running mean: -79.565357\n",
      "ep 4: ep_len:500 episode reward: total was -44.100000. running mean: -79.210704\n",
      "ep 4: ep_len:2000 episode reward: total was -201.080000. running mean: -80.429397\n",
      "ep 4: ep_len:500 episode reward: total was 16.000000. running mean: -79.465103\n",
      "ep 4: ep_len:785 episode reward: total was -38.420000. running mean: -79.054652\n",
      "ep 4: ep_len:750 episode reward: total was -42.960000. running mean: -78.693705\n",
      "ep 4: ep_len:233 episode reward: total was 5.000000. running mean: -77.856768\n",
      "ep 4: ep_len:615 episode reward: total was -35.540000. running mean: -77.433600\n",
      "ep 4: ep_len:500 episode reward: total was -39.080000. running mean: -77.050064\n",
      "ep 4: ep_len:840 episode reward: total was -66.010000. running mean: -76.939664\n",
      "ep 4: ep_len:550 episode reward: total was -38.310000. running mean: -76.553367\n",
      "ep 4: ep_len:520 episode reward: total was -43.330000. running mean: -76.221133\n",
      "ep 4: ep_len:590 episode reward: total was -35.470000. running mean: -75.813622\n",
      "ep 4: ep_len:500 episode reward: total was -6.350000. running mean: -75.118986\n",
      "ep 4: ep_len:500 episode reward: total was -15.660000. running mean: -74.524396\n",
      "ep 4: ep_len:865 episode reward: total was -50.850000. running mean: -74.287652\n",
      "ep 4: ep_len:500 episode reward: total was -25.080000. running mean: -73.795576\n",
      "ep 4: ep_len:1095 episode reward: total was -73.080000. running mean: -73.788420\n",
      "ep 4: ep_len:570 episode reward: total was -74.140000. running mean: -73.791936\n",
      "ep 4: ep_len:745 episode reward: total was -48.080000. running mean: -73.534816\n",
      "ep 4: ep_len:510 episode reward: total was -38.540000. running mean: -73.184868\n",
      "ep 4: ep_len:236 episode reward: total was 4.500000. running mean: -72.408019\n",
      "ep 4: ep_len:268 episode reward: total was 1.500000. running mean: -71.668939\n",
      "ep 4: ep_len:505 episode reward: total was -26.580000. running mean: -71.218050\n",
      "ep 4: ep_len:500 episode reward: total was 8.000000. running mean: -70.425869\n",
      "ep 4: ep_len:600 episode reward: total was -40.260000. running mean: -70.124211\n",
      "ep 4: ep_len:505 episode reward: total was -17.510000. running mean: -69.598069\n",
      "ep 4: ep_len:540 episode reward: total was -46.930000. running mean: -69.371388\n",
      "ep 4: ep_len:500 episode reward: total was -50.340000. running mean: -69.181074\n",
      "ep 4: ep_len:500 episode reward: total was -13.420000. running mean: -68.623463\n",
      "ep 4: ep_len:950 episode reward: total was -58.700000. running mean: -68.524229\n",
      "ep 4: ep_len:1240 episode reward: total was -112.710000. running mean: -68.966086\n",
      "ep 4: ep_len:1065 episode reward: total was -46.530000. running mean: -68.741725\n",
      "ep 4: ep_len:610 episode reward: total was -24.650000. running mean: -68.300808\n",
      "ep 4: ep_len:935 episode reward: total was -55.780000. running mean: -68.175600\n",
      "ep 4: ep_len:855 episode reward: total was -70.540000. running mean: -68.199244\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 4: ep_len:500 episode reward: total was -24.290000. running mean: -67.760152\n",
      "ep 4: ep_len:925 episode reward: total was -71.190000. running mean: -67.794450\n",
      "ep 4: ep_len:1100 episode reward: total was -52.520000. running mean: -67.641706\n",
      "ep 4: ep_len:855 episode reward: total was -48.650000. running mean: -67.451789\n",
      "ep 4: ep_len:605 episode reward: total was -47.810000. running mean: -67.255371\n",
      "ep 4: ep_len:770 episode reward: total was -61.620000. running mean: -67.199017\n",
      "ep 4: ep_len:940 episode reward: total was -46.060000. running mean: -66.987627\n",
      "ep 4: ep_len:670 episode reward: total was -37.030000. running mean: -66.688051\n",
      "ep 4: ep_len:910 episode reward: total was -35.590000. running mean: -66.377070\n",
      "ep 4: ep_len:500 episode reward: total was -26.010000. running mean: -65.973399\n",
      "ep 4: ep_len:600 episode reward: total was -39.370000. running mean: -65.707365\n",
      "ep 4: ep_len:500 episode reward: total was -41.120000. running mean: -65.461492\n",
      "ep 4: ep_len:675 episode reward: total was -28.190000. running mean: -65.088777\n",
      "ep 4: ep_len:950 episode reward: total was -83.510000. running mean: -65.272989\n",
      "ep 4: ep_len:555 episode reward: total was -59.290000. running mean: -65.213159\n",
      "ep 4: ep_len:500 episode reward: total was -14.360000. running mean: -64.704628\n",
      "ep 4: ep_len:545 episode reward: total was -52.660000. running mean: -64.584181\n",
      "ep 4: ep_len:404 episode reward: total was -19.500000. running mean: -64.133339\n",
      "ep 4: ep_len:605 episode reward: total was -50.120000. running mean: -63.993206\n",
      "ep 4: ep_len:500 episode reward: total was -28.340000. running mean: -63.636674\n",
      "ep 4: ep_len:505 episode reward: total was -0.450000. running mean: -63.004807\n",
      "ep 4: ep_len:505 episode reward: total was -22.830000. running mean: -62.603059\n",
      "ep 4: ep_len:505 episode reward: total was 3.000000. running mean: -61.947029\n",
      "ep 4: ep_len:505 episode reward: total was -30.140000. running mean: -61.628958\n",
      "ep 4: ep_len:505 episode reward: total was -25.810000. running mean: -61.270769\n",
      "ep 4: ep_len:640 episode reward: total was -47.740000. running mean: -61.135461\n",
      "ep 4: ep_len:890 episode reward: total was -43.290000. running mean: -60.957006\n",
      "ep 4: ep_len:573 episode reward: total was -37.400000. running mean: -60.721436\n",
      "ep 4: ep_len:500 episode reward: total was -3.310000. running mean: -60.147322\n",
      "ep 4: ep_len:500 episode reward: total was -11.830000. running mean: -59.664149\n",
      "ep 4: ep_len:1105 episode reward: total was -57.060000. running mean: -59.638107\n",
      "ep 4: ep_len:570 episode reward: total was -44.360000. running mean: -59.485326\n",
      "ep 4: ep_len:144 episode reward: total was 3.500000. running mean: -58.855473\n",
      "ep 4: ep_len:795 episode reward: total was -60.070000. running mean: -58.867618\n",
      "ep 4: ep_len:108 episode reward: total was -2.500000. running mean: -58.303942\n",
      "ep 4: ep_len:505 episode reward: total was -14.770000. running mean: -57.868603\n",
      "ep 4: ep_len:640 episode reward: total was -55.820000. running mean: -57.848117\n",
      "ep 4: ep_len:169 episode reward: total was -6.000000. running mean: -57.329635\n",
      "ep 4: ep_len:500 episode reward: total was -21.020000. running mean: -56.966539\n",
      "ep 4: ep_len:665 episode reward: total was -28.710000. running mean: -56.683974\n",
      "ep 4: ep_len:500 episode reward: total was -30.830000. running mean: -56.425434\n",
      "ep 4: ep_len:500 episode reward: total was -32.470000. running mean: -56.185880\n",
      "ep 4: ep_len:640 episode reward: total was -51.780000. running mean: -56.141821\n",
      "ep 4: ep_len:500 episode reward: total was -84.500000. running mean: -56.425403\n",
      "ep 4: ep_len:500 episode reward: total was -5.850000. running mean: -55.919649\n",
      "ep 4: ep_len:695 episode reward: total was -46.620000. running mean: -55.826652\n",
      "ep 4: ep_len:635 episode reward: total was -50.290000. running mean: -55.771286\n",
      "ep 4: ep_len:722 episode reward: total was -73.820000. running mean: -55.951773\n",
      "ep 4: ep_len:505 episode reward: total was -13.920000. running mean: -55.531455\n",
      "ep 4: ep_len:785 episode reward: total was -25.520000. running mean: -55.231340\n",
      "ep 4: ep_len:1065 episode reward: total was -60.060000. running mean: -55.279627\n",
      "ep 4: ep_len:286 episode reward: total was 9.500000. running mean: -54.631831\n",
      "ep 4: ep_len:505 episode reward: total was -6.320000. running mean: -54.148712\n",
      "ep 4: ep_len:500 episode reward: total was -40.000000. running mean: -54.007225\n",
      "ep 4: ep_len:1495 episode reward: total was -238.450000. running mean: -55.851653\n",
      "ep 4: ep_len:725 episode reward: total was -43.040000. running mean: -55.723537\n",
      "ep 4: ep_len:635 episode reward: total was -79.550000. running mean: -55.961801\n",
      "ep 4: ep_len:505 episode reward: total was -42.470000. running mean: -55.826883\n",
      "ep 4: ep_len:955 episode reward: total was -58.610000. running mean: -55.854714\n",
      "ep 4: ep_len:218 episode reward: total was 6.500000. running mean: -55.231167\n",
      "ep 4: ep_len:500 episode reward: total was 2.740000. running mean: -54.651456\n",
      "ep 4: ep_len:500 episode reward: total was -27.200000. running mean: -54.376941\n",
      "ep 4: ep_len:500 episode reward: total was -5.280000. running mean: -53.885972\n",
      "ep 4: ep_len:500 episode reward: total was -21.320000. running mean: -53.560312\n",
      "ep 4: ep_len:855 episode reward: total was -48.790000. running mean: -53.512609\n",
      "ep 4: ep_len:323 episode reward: total was -2.500000. running mean: -53.002483\n",
      "ep 4: ep_len:505 episode reward: total was -39.100000. running mean: -52.863458\n",
      "ep 4: ep_len:1850 episode reward: total was -281.660000. running mean: -55.151423\n",
      "ep 4: ep_len:203 episode reward: total was 0.500000. running mean: -54.594909\n",
      "ep 4: ep_len:730 episode reward: total was -56.650000. running mean: -54.615460\n",
      "ep 4: ep_len:414 episode reward: total was 3.500000. running mean: -54.034305\n",
      "ep 4: ep_len:660 episode reward: total was -51.800000. running mean: -54.011962\n",
      "ep 4: ep_len:312 episode reward: total was 1.000000. running mean: -53.461843\n",
      "ep 4: ep_len:875 episode reward: total was -44.810000. running mean: -53.375324\n",
      "ep 4: ep_len:500 episode reward: total was -27.500000. running mean: -53.116571\n",
      "ep 4: ep_len:500 episode reward: total was -22.180000. running mean: -52.807205\n",
      "ep 4: ep_len:500 episode reward: total was -30.940000. running mean: -52.588533\n",
      "ep 4: ep_len:515 episode reward: total was -35.400000. running mean: -52.416648\n",
      "ep 4: ep_len:500 episode reward: total was -35.500000. running mean: -52.247481\n",
      "ep 4: ep_len:1180 episode reward: total was -122.900000. running mean: -52.954007\n",
      "ep 4: ep_len:555 episode reward: total was -53.450000. running mean: -52.958967\n",
      "ep 4: ep_len:780 episode reward: total was -77.940000. running mean: -53.208777\n",
      "ep 4: ep_len:610 episode reward: total was -21.440000. running mean: -52.891089\n",
      "ep 4: ep_len:1220 episode reward: total was -161.720000. running mean: -53.979378\n",
      "ep 4: ep_len:780 episode reward: total was -51.370000. running mean: -53.953284\n",
      "ep 4: ep_len:505 episode reward: total was -29.720000. running mean: -53.710952\n",
      "ep 4: ep_len:443 episode reward: total was 8.000000. running mean: -53.093842\n",
      "ep 4: ep_len:770 episode reward: total was -62.630000. running mean: -53.189204\n",
      "ep 4: ep_len:505 episode reward: total was -25.360000. running mean: -52.910912\n",
      "ep 4: ep_len:550 episode reward: total was -38.830000. running mean: -52.770102\n",
      "ep 4: ep_len:505 episode reward: total was -32.490000. running mean: -52.567301\n",
      "ep 4: ep_len:695 episode reward: total was -52.680000. running mean: -52.568428\n",
      "ep 4: ep_len:875 episode reward: total was -50.830000. running mean: -52.551044\n",
      "ep 4: ep_len:695 episode reward: total was -51.050000. running mean: -52.536034\n",
      "ep 4: ep_len:41 episode reward: total was -8.000000. running mean: -52.090673\n",
      "ep 4: ep_len:505 episode reward: total was -15.230000. running mean: -51.722067\n",
      "ep 4: ep_len:500 episode reward: total was -35.440000. running mean: -51.559246\n",
      "ep 4: ep_len:515 episode reward: total was -51.020000. running mean: -51.553854\n",
      "ep 4: ep_len:680 episode reward: total was -48.310000. running mean: -51.521415\n",
      "ep 4: ep_len:500 episode reward: total was -30.590000. running mean: -51.312101\n",
      "ep 4: ep_len:515 episode reward: total was -52.110000. running mean: -51.320080\n",
      "ep 4: ep_len:680 episode reward: total was -67.370000. running mean: -51.480579\n",
      "ep 4: ep_len:800 episode reward: total was -79.740000. running mean: -51.763173\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 4: ep_len:555 episode reward: total was -44.390000. running mean: -51.689441\n",
      "ep 4: ep_len:505 episode reward: total was -10.230000. running mean: -51.274847\n",
      "ep 4: ep_len:540 episode reward: total was -42.180000. running mean: -51.183899\n",
      "ep 4: ep_len:1555 episode reward: total was -283.260000. running mean: -53.504660\n",
      "ep 4: ep_len:500 episode reward: total was -25.760000. running mean: -53.227213\n",
      "ep 4: ep_len:510 episode reward: total was -31.890000. running mean: -53.013841\n",
      "ep 4: ep_len:925 episode reward: total was -50.620000. running mean: -52.989902\n",
      "ep 4: ep_len:505 episode reward: total was -14.750000. running mean: -52.607503\n",
      "ep 4: ep_len:610 episode reward: total was -34.470000. running mean: -52.426128\n",
      "ep 4: ep_len:500 episode reward: total was -13.780000. running mean: -52.039667\n",
      "ep 4: ep_len:860 episode reward: total was -60.610000. running mean: -52.125370\n",
      "ep 4: ep_len:940 episode reward: total was -106.410000. running mean: -52.668217\n",
      "ep 4: ep_len:615 episode reward: total was -39.770000. running mean: -52.539235\n",
      "ep 4: ep_len:500 episode reward: total was -25.170000. running mean: -52.265542\n",
      "ep 4: ep_len:500 episode reward: total was -35.060000. running mean: -52.093487\n",
      "ep 4: ep_len:765 episode reward: total was -53.030000. running mean: -52.102852\n",
      "ep 4: ep_len:148 episode reward: total was 2.500000. running mean: -51.556823\n",
      "ep 4: ep_len:144 episode reward: total was 3.500000. running mean: -51.006255\n",
      "ep 4: ep_len:520 episode reward: total was -48.500000. running mean: -50.981193\n",
      "ep 4: ep_len:715 episode reward: total was -58.180000. running mean: -51.053181\n",
      "ep 4: ep_len:500 episode reward: total was -32.070000. running mean: -50.863349\n",
      "ep 4: ep_len:310 episode reward: total was 1.000000. running mean: -50.344715\n",
      "ep 4: ep_len:730 episode reward: total was -58.180000. running mean: -50.423068\n",
      "ep 4: ep_len:735 episode reward: total was -92.510000. running mean: -50.843938\n",
      "ep 4: ep_len:500 episode reward: total was -31.950000. running mean: -50.654998\n",
      "ep 4: ep_len:233 episode reward: total was 9.500000. running mean: -50.053448\n",
      "ep 4: ep_len:500 episode reward: total was -36.960000. running mean: -49.922514\n",
      "ep 4: ep_len:500 episode reward: total was -5.850000. running mean: -49.481789\n",
      "ep 4: ep_len:505 episode reward: total was -29.360000. running mean: -49.280571\n",
      "ep 4: ep_len:500 episode reward: total was -37.430000. running mean: -49.162065\n",
      "ep 4: ep_len:476 episode reward: total was -16.750000. running mean: -48.837944\n",
      "ep 4: ep_len:500 episode reward: total was -49.090000. running mean: -48.840465\n",
      "ep 4: ep_len:505 episode reward: total was -53.060000. running mean: -48.882660\n",
      "ep 4: ep_len:750 episode reward: total was -33.020000. running mean: -48.724034\n",
      "ep 4: ep_len:500 episode reward: total was -40.000000. running mean: -48.636793\n",
      "ep 4: ep_len:500 episode reward: total was -25.120000. running mean: -48.401625\n",
      "ep 4: ep_len:2760 episode reward: total was -399.830000. running mean: -51.915909\n",
      "ep 4: ep_len:500 episode reward: total was -38.470000. running mean: -51.781450\n",
      "ep 4: ep_len:5695 episode reward: total was -946.090000. running mean: -60.724536\n",
      "ep 4: ep_len:775 episode reward: total was -50.680000. running mean: -60.624090\n",
      "ep 4: ep_len:575 episode reward: total was -44.350000. running mean: -60.461349\n",
      "ep 4: ep_len:1260 episode reward: total was -142.590000. running mean: -61.282636\n",
      "ep 4: ep_len:505 episode reward: total was -45.360000. running mean: -61.123409\n",
      "ep 4: ep_len:500 episode reward: total was -51.720000. running mean: -61.029375\n",
      "ep 4: ep_len:660 episode reward: total was -42.650000. running mean: -60.845582\n",
      "ep 4: ep_len:267 episode reward: total was 1.500000. running mean: -60.222126\n",
      "epsilon:0.322936 episode_count: 3952. steps_count: 2932413.000000\n",
      "ep 5: ep_len:505 episode reward: total was -17.810000. running mean: -59.798005\n",
      "ep 5: ep_len:935 episode reward: total was -62.080000. running mean: -59.820824\n",
      "ep 5: ep_len:695 episode reward: total was -77.440000. running mean: -59.997016\n",
      "ep 5: ep_len:1005 episode reward: total was -129.340000. running mean: -60.690446\n",
      "ep 5: ep_len:500 episode reward: total was -26.310000. running mean: -60.346642\n",
      "ep 5: ep_len:1230 episode reward: total was -182.420000. running mean: -61.567375\n",
      "ep 5: ep_len:685 episode reward: total was -43.120000. running mean: -61.382901\n",
      "ep 5: ep_len:940 episode reward: total was -99.440000. running mean: -61.763472\n",
      "ep 5: ep_len:790 episode reward: total was -64.090000. running mean: -61.786738\n",
      "ep 5: ep_len:1045 episode reward: total was -54.620000. running mean: -61.715070\n",
      "ep 5: ep_len:595 episode reward: total was -73.600000. running mean: -61.833920\n",
      "ep 5: ep_len:630 episode reward: total was -88.650000. running mean: -62.102080\n",
      "ep 5: ep_len:835 episode reward: total was -14.980000. running mean: -61.630860\n",
      "ep 5: ep_len:870 episode reward: total was -74.060000. running mean: -61.755151\n",
      "ep 5: ep_len:850 episode reward: total was -79.640000. running mean: -61.934000\n",
      "ep 5: ep_len:510 episode reward: total was -11.370000. running mean: -61.428360\n",
      "ep 5: ep_len:500 episode reward: total was -36.720000. running mean: -61.181276\n",
      "ep 5: ep_len:510 episode reward: total was -30.780000. running mean: -60.877263\n",
      "ep 5: ep_len:600 episode reward: total was -47.330000. running mean: -60.741791\n",
      "ep 5: ep_len:795 episode reward: total was -86.530000. running mean: -60.999673\n",
      "ep 5: ep_len:1430 episode reward: total was -168.860000. running mean: -62.078276\n",
      "ep 5: ep_len:970 episode reward: total was -101.130000. running mean: -62.468793\n",
      "ep 5: ep_len:510 episode reward: total was -37.850000. running mean: -62.222605\n",
      "ep 5: ep_len:500 episode reward: total was -22.080000. running mean: -61.821179\n",
      "ep 5: ep_len:1260 episode reward: total was -212.190000. running mean: -63.324867\n",
      "ep 5: ep_len:500 episode reward: total was -28.120000. running mean: -62.972819\n",
      "ep 5: ep_len:500 episode reward: total was -35.990000. running mean: -62.702991\n",
      "ep 5: ep_len:500 episode reward: total was -16.670000. running mean: -62.242661\n",
      "ep 5: ep_len:525 episode reward: total was -39.400000. running mean: -62.014234\n",
      "ep 5: ep_len:505 episode reward: total was -23.840000. running mean: -61.632492\n",
      "ep 5: ep_len:285 episode reward: total was 4.500000. running mean: -60.971167\n",
      "ep 5: ep_len:500 episode reward: total was 2.140000. running mean: -60.340055\n",
      "ep 5: ep_len:805 episode reward: total was -58.560000. running mean: -60.322255\n",
      "ep 5: ep_len:520 episode reward: total was -27.840000. running mean: -59.997432\n",
      "ep 5: ep_len:590 episode reward: total was -22.710000. running mean: -59.624558\n",
      "ep 5: ep_len:500 episode reward: total was -40.580000. running mean: -59.434112\n",
      "ep 5: ep_len:615 episode reward: total was -30.160000. running mean: -59.141371\n",
      "ep 5: ep_len:500 episode reward: total was -4.390000. running mean: -58.593857\n",
      "ep 5: ep_len:813 episode reward: total was -95.370000. running mean: -58.961619\n",
      "ep 5: ep_len:500 episode reward: total was -9.810000. running mean: -58.470102\n",
      "ep 5: ep_len:261 episode reward: total was -1.000000. running mean: -57.895401\n",
      "ep 5: ep_len:735 episode reward: total was -45.390000. running mean: -57.770347\n",
      "ep 5: ep_len:945 episode reward: total was -35.800000. running mean: -57.550644\n",
      "ep 5: ep_len:505 episode reward: total was -21.820000. running mean: -57.193338\n",
      "ep 5: ep_len:500 episode reward: total was -34.980000. running mean: -56.971204\n",
      "ep 5: ep_len:226 episode reward: total was 0.000000. running mean: -56.401492\n",
      "ep 5: ep_len:740 episode reward: total was -76.340000. running mean: -56.600877\n",
      "ep 5: ep_len:925 episode reward: total was -50.280000. running mean: -56.537668\n",
      "ep 5: ep_len:890 episode reward: total was -79.070000. running mean: -56.762992\n",
      "ep 5: ep_len:735 episode reward: total was -51.070000. running mean: -56.706062\n",
      "ep 5: ep_len:710 episode reward: total was -56.730000. running mean: -56.706301\n",
      "ep 5: ep_len:500 episode reward: total was -21.220000. running mean: -56.351438\n",
      "ep 5: ep_len:505 episode reward: total was -46.200000. running mean: -56.249924\n",
      "ep 5: ep_len:685 episode reward: total was -52.760000. running mean: -56.215025\n",
      "ep 5: ep_len:505 episode reward: total was -14.280000. running mean: -55.795674\n",
      "ep 5: ep_len:950 episode reward: total was -78.500000. running mean: -56.022718\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 5: ep_len:500 episode reward: total was -31.700000. running mean: -55.779490\n",
      "ep 5: ep_len:337 episode reward: total was -4.500000. running mean: -55.266696\n",
      "ep 5: ep_len:1070 episode reward: total was -72.020000. running mean: -55.434229\n",
      "ep 5: ep_len:515 episode reward: total was -50.530000. running mean: -55.385186\n",
      "ep 5: ep_len:570 episode reward: total was -28.200000. running mean: -55.113334\n",
      "ep 5: ep_len:150 episode reward: total was 0.000000. running mean: -54.562201\n",
      "ep 5: ep_len:505 episode reward: total was -27.310000. running mean: -54.289679\n",
      "ep 5: ep_len:500 episode reward: total was -45.020000. running mean: -54.196982\n",
      "ep 5: ep_len:1305 episode reward: total was -103.930000. running mean: -54.694312\n",
      "ep 5: ep_len:530 episode reward: total was -37.860000. running mean: -54.525969\n",
      "ep 5: ep_len:530 episode reward: total was -22.820000. running mean: -54.208910\n",
      "ep 5: ep_len:665 episode reward: total was -46.190000. running mean: -54.128721\n",
      "ep 5: ep_len:690 episode reward: total was -50.670000. running mean: -54.094133\n",
      "ep 5: ep_len:530 episode reward: total was 5.720000. running mean: -53.495992\n",
      "ep 5: ep_len:800 episode reward: total was -69.640000. running mean: -53.657432\n",
      "ep 5: ep_len:500 episode reward: total was -24.680000. running mean: -53.367658\n",
      "ep 5: ep_len:555 episode reward: total was -72.670000. running mean: -53.560681\n",
      "ep 5: ep_len:500 episode reward: total was -23.910000. running mean: -53.264174\n",
      "ep 5: ep_len:500 episode reward: total was -43.030000. running mean: -53.161833\n",
      "ep 5: ep_len:685 episode reward: total was -55.420000. running mean: -53.184414\n",
      "ep 5: ep_len:510 episode reward: total was -49.750000. running mean: -53.150070\n",
      "ep 5: ep_len:505 episode reward: total was -22.870000. running mean: -52.847269\n",
      "ep 5: ep_len:500 episode reward: total was -29.420000. running mean: -52.612997\n",
      "ep 5: ep_len:660 episode reward: total was -44.180000. running mean: -52.528667\n",
      "ep 5: ep_len:500 episode reward: total was -34.370000. running mean: -52.347080\n",
      "ep 5: ep_len:500 episode reward: total was -44.120000. running mean: -52.264809\n",
      "ep 5: ep_len:865 episode reward: total was -37.810000. running mean: -52.120261\n",
      "ep 5: ep_len:500 episode reward: total was -40.720000. running mean: -52.006259\n",
      "ep 5: ep_len:890 episode reward: total was -123.630000. running mean: -52.722496\n",
      "ep 5: ep_len:650 episode reward: total was -43.190000. running mean: -52.627171\n",
      "ep 5: ep_len:500 episode reward: total was -43.240000. running mean: -52.533299\n",
      "ep 5: ep_len:690 episode reward: total was -46.120000. running mean: -52.469166\n",
      "ep 5: ep_len:565 episode reward: total was -45.380000. running mean: -52.398275\n",
      "ep 5: ep_len:1135 episode reward: total was -150.200000. running mean: -53.376292\n",
      "ep 5: ep_len:500 episode reward: total was 7.500000. running mean: -52.767529\n",
      "ep 5: ep_len:500 episode reward: total was -18.850000. running mean: -52.428354\n",
      "ep 5: ep_len:234 episode reward: total was 7.000000. running mean: -51.834070\n",
      "ep 5: ep_len:505 episode reward: total was -9.890000. running mean: -51.414629\n",
      "ep 5: ep_len:500 episode reward: total was -25.440000. running mean: -51.154883\n",
      "ep 5: ep_len:500 episode reward: total was -18.840000. running mean: -50.831734\n",
      "ep 5: ep_len:670 episode reward: total was -49.700000. running mean: -50.820417\n",
      "ep 5: ep_len:500 episode reward: total was -24.890000. running mean: -50.561113\n",
      "ep 5: ep_len:1070 episode reward: total was -81.170000. running mean: -50.867202\n",
      "ep 5: ep_len:565 episode reward: total was -63.560000. running mean: -50.994130\n",
      "ep 5: ep_len:515 episode reward: total was -70.700000. running mean: -51.191188\n",
      "ep 5: ep_len:260 episode reward: total was 5.000000. running mean: -50.629277\n",
      "ep 5: ep_len:795 episode reward: total was -19.840000. running mean: -50.321384\n",
      "ep 5: ep_len:605 episode reward: total was -43.280000. running mean: -50.250970\n",
      "ep 5: ep_len:500 episode reward: total was -14.350000. running mean: -49.891960\n",
      "ep 5: ep_len:184 episode reward: total was -1.000000. running mean: -49.403041\n",
      "ep 5: ep_len:880 episode reward: total was -109.000000. running mean: -49.999010\n",
      "ep 5: ep_len:500 episode reward: total was -40.980000. running mean: -49.908820\n",
      "ep 5: ep_len:500 episode reward: total was -45.500000. running mean: -49.864732\n",
      "ep 5: ep_len:510 episode reward: total was -13.450000. running mean: -49.500585\n",
      "ep 5: ep_len:880 episode reward: total was -54.850000. running mean: -49.554079\n",
      "ep 5: ep_len:275 episode reward: total was 8.500000. running mean: -48.973538\n",
      "ep 5: ep_len:890 episode reward: total was -59.880000. running mean: -49.082603\n",
      "ep 5: ep_len:510 episode reward: total was -33.640000. running mean: -48.928177\n",
      "ep 5: ep_len:730 episode reward: total was -54.270000. running mean: -48.981595\n",
      "ep 5: ep_len:810 episode reward: total was -58.510000. running mean: -49.076879\n",
      "ep 5: ep_len:865 episode reward: total was -55.990000. running mean: -49.146010\n",
      "ep 5: ep_len:860 episode reward: total was -38.650000. running mean: -49.041050\n",
      "ep 5: ep_len:7485 episode reward: total was -847.670000. running mean: -57.027339\n",
      "ep 5: ep_len:500 episode reward: total was -51.230000. running mean: -56.969366\n",
      "ep 5: ep_len:735 episode reward: total was -46.050000. running mean: -56.860172\n",
      "ep 5: ep_len:1580 episode reward: total was -250.370000. running mean: -58.795271\n",
      "ep 5: ep_len:500 episode reward: total was -30.290000. running mean: -58.510218\n",
      "ep 5: ep_len:710 episode reward: total was -52.160000. running mean: -58.446716\n",
      "ep 5: ep_len:760 episode reward: total was -84.200000. running mean: -58.704249\n",
      "ep 5: ep_len:905 episode reward: total was -69.950000. running mean: -58.816706\n",
      "ep 5: ep_len:815 episode reward: total was -67.590000. running mean: -58.904439\n",
      "ep 5: ep_len:148 episode reward: total was 1.500000. running mean: -58.300395\n",
      "ep 5: ep_len:685 episode reward: total was -76.130000. running mean: -58.478691\n",
      "ep 5: ep_len:500 episode reward: total was -7.770000. running mean: -57.971604\n",
      "ep 5: ep_len:2055 episode reward: total was -220.110000. running mean: -59.592988\n",
      "ep 5: ep_len:1395 episode reward: total was -161.370000. running mean: -60.610758\n",
      "ep 5: ep_len:1035 episode reward: total was -72.550000. running mean: -60.730150\n",
      "ep 5: ep_len:505 episode reward: total was -39.770000. running mean: -60.520549\n",
      "ep 5: ep_len:500 episode reward: total was -16.870000. running mean: -60.084043\n",
      "ep 5: ep_len:500 episode reward: total was 10.500000. running mean: -59.378203\n",
      "ep 5: ep_len:500 episode reward: total was -20.360000. running mean: -58.988021\n",
      "ep 5: ep_len:925 episode reward: total was -66.970000. running mean: -59.067841\n",
      "ep 5: ep_len:1600 episode reward: total was -206.930000. running mean: -60.546462\n",
      "ep 5: ep_len:500 episode reward: total was -14.940000. running mean: -60.090398\n",
      "ep 5: ep_len:505 episode reward: total was -4.380000. running mean: -59.533294\n",
      "ep 5: ep_len:116 episode reward: total was 1.000000. running mean: -58.927961\n",
      "ep 5: ep_len:165 episode reward: total was -1.500000. running mean: -58.353681\n",
      "ep 5: ep_len:500 episode reward: total was 7.000000. running mean: -57.700144\n",
      "ep 5: ep_len:500 episode reward: total was -39.710000. running mean: -57.520243\n",
      "ep 5: ep_len:1005 episode reward: total was -43.600000. running mean: -57.381040\n",
      "ep 5: ep_len:690 episode reward: total was -50.550000. running mean: -57.312730\n",
      "ep 5: ep_len:114 episode reward: total was 5.000000. running mean: -56.689603\n",
      "ep 5: ep_len:500 episode reward: total was -16.440000. running mean: -56.287107\n",
      "ep 5: ep_len:645 episode reward: total was -59.360000. running mean: -56.317836\n",
      "ep 5: ep_len:500 episode reward: total was 4.000000. running mean: -55.714657\n",
      "ep 5: ep_len:505 episode reward: total was -20.550000. running mean: -55.363011\n",
      "ep 5: ep_len:570 episode reward: total was -46.870000. running mean: -55.278081\n",
      "ep 5: ep_len:500 episode reward: total was -18.320000. running mean: -54.908500\n",
      "ep 5: ep_len:730 episode reward: total was -45.050000. running mean: -54.809915\n",
      "ep 5: ep_len:865 episode reward: total was -43.280000. running mean: -54.694616\n",
      "ep 5: ep_len:950 episode reward: total was -48.100000. running mean: -54.628670\n",
      "ep 5: ep_len:313 episode reward: total was -14.330000. running mean: -54.225683\n",
      "ep 5: ep_len:835 episode reward: total was -68.760000. running mean: -54.371026\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 5: ep_len:500 episode reward: total was -9.280000. running mean: -53.920116\n",
      "ep 5: ep_len:585 episode reward: total was -25.240000. running mean: -53.633315\n",
      "ep 5: ep_len:1165 episode reward: total was -53.090000. running mean: -53.627881\n",
      "ep 5: ep_len:715 episode reward: total was -44.560000. running mean: -53.537203\n",
      "ep 5: ep_len:500 episode reward: total was -22.410000. running mean: -53.225931\n",
      "ep 5: ep_len:500 episode reward: total was -18.950000. running mean: -52.883171\n",
      "ep 5: ep_len:505 episode reward: total was -24.690000. running mean: -52.601240\n",
      "ep 5: ep_len:690 episode reward: total was -42.590000. running mean: -52.501127\n",
      "ep 5: ep_len:505 episode reward: total was -16.990000. running mean: -52.146016\n",
      "ep 5: ep_len:500 episode reward: total was -10.330000. running mean: -51.727856\n",
      "ep 5: ep_len:545 episode reward: total was -41.740000. running mean: -51.627977\n",
      "ep 5: ep_len:585 episode reward: total was -33.940000. running mean: -51.451097\n",
      "ep 5: ep_len:830 episode reward: total was -62.510000. running mean: -51.561686\n",
      "ep 5: ep_len:1075 episode reward: total was -58.360000. running mean: -51.629670\n",
      "ep 5: ep_len:725 episode reward: total was -49.590000. running mean: -51.609273\n",
      "ep 5: ep_len:181 episode reward: total was 0.000000. running mean: -51.093180\n",
      "ep 5: ep_len:505 episode reward: total was -35.580000. running mean: -50.938048\n",
      "ep 5: ep_len:145 episode reward: total was -5.500000. running mean: -50.483668\n",
      "ep 5: ep_len:500 episode reward: total was -25.950000. running mean: -50.238331\n",
      "ep 5: ep_len:510 episode reward: total was 0.500000. running mean: -49.730948\n",
      "ep 5: ep_len:500 episode reward: total was -70.300000. running mean: -49.936638\n",
      "ep 5: ep_len:505 episode reward: total was -13.380000. running mean: -49.571072\n",
      "ep 5: ep_len:535 episode reward: total was -51.500000. running mean: -49.590361\n",
      "ep 5: ep_len:505 episode reward: total was -56.670000. running mean: -49.661158\n",
      "ep 5: ep_len:500 episode reward: total was -28.830000. running mean: -49.452846\n",
      "ep 5: ep_len:492 episode reward: total was -25.800000. running mean: -49.216318\n",
      "ep 5: ep_len:555 episode reward: total was -39.340000. running mean: -49.117554\n",
      "ep 5: ep_len:500 episode reward: total was -17.420000. running mean: -48.800579\n",
      "ep 5: ep_len:500 episode reward: total was -37.000000. running mean: -48.682573\n",
      "ep 5: ep_len:575 episode reward: total was -33.450000. running mean: -48.530247\n",
      "ep 5: ep_len:500 episode reward: total was -38.760000. running mean: -48.432545\n",
      "ep 5: ep_len:990 episode reward: total was -52.620000. running mean: -48.474419\n",
      "ep 5: ep_len:225 episode reward: total was 5.000000. running mean: -47.939675\n",
      "ep 5: ep_len:231 episode reward: total was 2.000000. running mean: -47.440279\n",
      "ep 5: ep_len:1095 episode reward: total was -49.040000. running mean: -47.456276\n",
      "ep 5: ep_len:525 episode reward: total was -8.810000. running mean: -47.069813\n",
      "ep 5: ep_len:585 episode reward: total was -55.930000. running mean: -47.158415\n",
      "ep 5: ep_len:1954 episode reward: total was -348.590000. running mean: -50.172731\n",
      "ep 5: ep_len:505 episode reward: total was -23.400000. running mean: -49.905003\n",
      "ep 5: ep_len:590 episode reward: total was -47.320000. running mean: -49.879153\n",
      "ep 5: ep_len:1010 episode reward: total was -15.890000. running mean: -49.539262\n",
      "ep 5: ep_len:760 episode reward: total was -51.540000. running mean: -49.559269\n",
      "ep 5: ep_len:705 episode reward: total was -54.190000. running mean: -49.605577\n",
      "ep 5: ep_len:605 episode reward: total was -40.740000. running mean: -49.516921\n",
      "ep 5: ep_len:800 episode reward: total was -35.250000. running mean: -49.374252\n",
      "ep 5: ep_len:505 episode reward: total was -25.020000. running mean: -49.130709\n",
      "ep 5: ep_len:500 episode reward: total was -35.680000. running mean: -48.996202\n",
      "ep 5: ep_len:500 episode reward: total was -25.240000. running mean: -48.758640\n",
      "ep 5: ep_len:500 episode reward: total was -16.290000. running mean: -48.433954\n",
      "ep 5: ep_len:505 episode reward: total was -31.910000. running mean: -48.268714\n",
      "ep 5: ep_len:1070 episode reward: total was -40.680000. running mean: -48.192827\n",
      "ep 5: ep_len:500 episode reward: total was -30.810000. running mean: -48.018999\n",
      "ep 5: ep_len:600 episode reward: total was -51.950000. running mean: -48.058309\n",
      "ep 5: ep_len:500 episode reward: total was -13.720000. running mean: -47.714926\n",
      "ep 5: ep_len:349 episode reward: total was -6.000000. running mean: -47.297776\n",
      "ep 5: ep_len:625 episode reward: total was -39.690000. running mean: -47.221698\n",
      "ep 5: ep_len:510 episode reward: total was -32.160000. running mean: -47.071082\n",
      "ep 5: ep_len:510 episode reward: total was -33.580000. running mean: -46.936171\n",
      "ep 5: ep_len:560 episode reward: total was -60.560000. running mean: -47.072409\n",
      "ep 5: ep_len:670 episode reward: total was -29.490000. running mean: -46.896585\n",
      "ep 5: ep_len:725 episode reward: total was -39.910000. running mean: -46.826719\n",
      "ep 5: ep_len:500 episode reward: total was -61.960000. running mean: -46.978052\n",
      "ep 5: ep_len:950 episode reward: total was -60.680000. running mean: -47.115071\n",
      "ep 5: ep_len:505 episode reward: total was -17.710000. running mean: -46.821021\n",
      "ep 5: ep_len:590 episode reward: total was -19.560000. running mean: -46.548410\n",
      "ep 5: ep_len:840 episode reward: total was -89.240000. running mean: -46.975326\n",
      "ep 5: ep_len:505 episode reward: total was -11.270000. running mean: -46.618273\n",
      "ep 5: ep_len:660 episode reward: total was -53.760000. running mean: -46.689690\n",
      "ep 5: ep_len:1000 episode reward: total was -110.370000. running mean: -47.326493\n",
      "ep 5: ep_len:500 episode reward: total was -34.000000. running mean: -47.193228\n",
      "ep 5: ep_len:500 episode reward: total was -42.070000. running mean: -47.141996\n",
      "ep 5: ep_len:740 episode reward: total was -48.090000. running mean: -47.151476\n",
      "ep 5: ep_len:500 episode reward: total was -21.960000. running mean: -46.899561\n",
      "ep 5: ep_len:1150 episode reward: total was -68.610000. running mean: -47.116666\n",
      "ep 5: ep_len:500 episode reward: total was -16.450000. running mean: -46.809999\n",
      "ep 5: ep_len:565 episode reward: total was -99.920000. running mean: -47.341099\n",
      "ep 5: ep_len:685 episode reward: total was -58.240000. running mean: -47.450088\n",
      "ep 5: ep_len:780 episode reward: total was -59.090000. running mean: -47.566487\n",
      "ep 5: ep_len:1345 episode reward: total was -146.840000. running mean: -48.559222\n",
      "ep 5: ep_len:500 episode reward: total was -20.860000. running mean: -48.282230\n",
      "ep 5: ep_len:695 episode reward: total was -57.240000. running mean: -48.371808\n",
      "ep 5: ep_len:900 episode reward: total was -49.640000. running mean: -48.384490\n",
      "ep 5: ep_len:560 episode reward: total was -50.440000. running mean: -48.405045\n",
      "ep 5: ep_len:500 episode reward: total was -32.900000. running mean: -48.249995\n",
      "ep 5: ep_len:505 episode reward: total was -49.540000. running mean: -48.262895\n",
      "ep 5: ep_len:580 episode reward: total was -38.280000. running mean: -48.163066\n",
      "ep 5: ep_len:174 episode reward: total was 8.000000. running mean: -47.601435\n",
      "ep 5: ep_len:820 episode reward: total was -58.980000. running mean: -47.715221\n",
      "ep 5: ep_len:505 episode reward: total was -31.060000. running mean: -47.548668\n",
      "ep 5: ep_len:695 episode reward: total was -29.020000. running mean: -47.363382\n",
      "ep 5: ep_len:500 episode reward: total was -14.040000. running mean: -47.030148\n",
      "ep 5: ep_len:505 episode reward: total was -37.440000. running mean: -46.934246\n",
      "ep 5: ep_len:880 episode reward: total was -86.160000. running mean: -47.326504\n",
      "ep 5: ep_len:540 episode reward: total was -43.490000. running mean: -47.288139\n",
      "ep 5: ep_len:500 episode reward: total was -54.630000. running mean: -47.361558\n",
      "ep 5: ep_len:895 episode reward: total was -74.990000. running mean: -47.637842\n",
      "ep 5: ep_len:640 episode reward: total was -39.780000. running mean: -47.559264\n",
      "ep 5: ep_len:245 episode reward: total was -0.500000. running mean: -47.088671\n",
      "ep 5: ep_len:820 episode reward: total was -91.990000. running mean: -47.537684\n",
      "ep 5: ep_len:680 episode reward: total was -38.640000. running mean: -47.448707\n",
      "ep 5: ep_len:211 episode reward: total was 9.500000. running mean: -46.879220\n",
      "ep 5: ep_len:505 episode reward: total was -13.850000. running mean: -46.548928\n",
      "ep 5: ep_len:775 episode reward: total was -66.140000. running mean: -46.744839\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 5: ep_len:185 episode reward: total was -0.500000. running mean: -46.282390\n",
      "ep 5: ep_len:500 episode reward: total was -42.160000. running mean: -46.241166\n",
      "ep 5: ep_len:955 episode reward: total was -70.670000. running mean: -46.485455\n",
      "ep 5: ep_len:500 episode reward: total was -44.680000. running mean: -46.467400\n",
      "ep 5: ep_len:605 episode reward: total was -38.230000. running mean: -46.385026\n",
      "ep 5: ep_len:239 episode reward: total was 10.000000. running mean: -45.821176\n",
      "ep 5: ep_len:710 episode reward: total was -50.140000. running mean: -45.864364\n",
      "ep 5: ep_len:1060 episode reward: total was -93.840000. running mean: -46.344121\n",
      "ep 5: ep_len:740 episode reward: total was -51.210000. running mean: -46.392779\n",
      "ep 5: ep_len:795 episode reward: total was -39.820000. running mean: -46.327052\n",
      "ep 5: ep_len:500 episode reward: total was 13.000000. running mean: -45.733781\n",
      "ep 5: ep_len:680 episode reward: total was -31.550000. running mean: -45.591943\n",
      "ep 5: ep_len:660 episode reward: total was -49.200000. running mean: -45.628024\n",
      "ep 5: ep_len:500 episode reward: total was -27.110000. running mean: -45.442844\n",
      "ep 5: ep_len:780 episode reward: total was -38.960000. running mean: -45.378015\n",
      "ep 5: ep_len:500 episode reward: total was -34.400000. running mean: -45.268235\n",
      "ep 5: ep_len:500 episode reward: total was -39.260000. running mean: -45.208153\n",
      "ep 5: ep_len:500 episode reward: total was -7.000000. running mean: -44.826071\n",
      "ep 5: ep_len:725 episode reward: total was -40.100000. running mean: -44.778810\n",
      "ep 5: ep_len:500 episode reward: total was -28.490000. running mean: -44.615922\n",
      "ep 5: ep_len:575 episode reward: total was -41.290000. running mean: -44.582663\n",
      "ep 5: ep_len:320 episode reward: total was -6.500000. running mean: -44.201836\n",
      "ep 5: ep_len:1020 episode reward: total was -43.700000. running mean: -44.196818\n",
      "ep 5: ep_len:1270 episode reward: total was -110.560000. running mean: -44.860450\n",
      "ep 5: ep_len:510 episode reward: total was -22.880000. running mean: -44.640645\n",
      "ep 5: ep_len:595 episode reward: total was -26.240000. running mean: -44.456639\n",
      "ep 5: ep_len:525 episode reward: total was -44.940000. running mean: -44.461473\n",
      "ep 5: ep_len:955 episode reward: total was -115.970000. running mean: -45.176558\n",
      "ep 5: ep_len:1480 episode reward: total was -149.600000. running mean: -46.220792\n",
      "ep 5: ep_len:790 episode reward: total was -48.690000. running mean: -46.245484\n",
      "ep 5: ep_len:795 episode reward: total was -48.930000. running mean: -46.272330\n",
      "ep 5: ep_len:590 episode reward: total was -41.780000. running mean: -46.227406\n",
      "ep 5: ep_len:560 episode reward: total was -38.810000. running mean: -46.153232\n",
      "ep 5: ep_len:695 episode reward: total was -51.180000. running mean: -46.203500\n",
      "ep 5: ep_len:185 episode reward: total was -3.500000. running mean: -45.776465\n",
      "ep 5: ep_len:1300 episode reward: total was -84.720000. running mean: -46.165900\n",
      "ep 5: ep_len:935 episode reward: total was -72.830000. running mean: -46.432541\n",
      "ep 5: ep_len:690 episode reward: total was -80.900000. running mean: -46.777216\n",
      "ep 5: ep_len:550 episode reward: total was -40.850000. running mean: -46.717944\n",
      "ep 5: ep_len:191 episode reward: total was 4.000000. running mean: -46.210764\n",
      "ep 5: ep_len:595 episode reward: total was -37.210000. running mean: -46.120757\n",
      "ep 5: ep_len:895 episode reward: total was -54.200000. running mean: -46.201549\n",
      "ep 5: ep_len:525 episode reward: total was -39.890000. running mean: -46.138433\n",
      "ep 5: ep_len:520 episode reward: total was -36.710000. running mean: -46.044149\n",
      "ep 5: ep_len:560 episode reward: total was -38.900000. running mean: -45.972708\n",
      "ep 5: ep_len:179 episode reward: total was -1.500000. running mean: -45.527981\n",
      "ep 5: ep_len:153 episode reward: total was -3.500000. running mean: -45.107701\n",
      "ep 5: ep_len:188 episode reward: total was -3.500000. running mean: -44.691624\n",
      "ep 5: ep_len:293 episode reward: total was 9.000000. running mean: -44.154708\n",
      "ep 5: ep_len:500 episode reward: total was -49.360000. running mean: -44.206760\n",
      "ep 5: ep_len:785 episode reward: total was -63.500000. running mean: -44.399693\n",
      "ep 5: ep_len:273 episode reward: total was 0.500000. running mean: -43.950696\n",
      "ep 5: ep_len:610 episode reward: total was -21.500000. running mean: -43.726189\n",
      "ep 5: ep_len:530 episode reward: total was -11.230000. running mean: -43.401227\n",
      "ep 5: ep_len:500 episode reward: total was -42.630000. running mean: -43.393515\n",
      "ep 5: ep_len:505 episode reward: total was 10.500000. running mean: -42.854580\n",
      "ep 5: ep_len:565 episode reward: total was -25.790000. running mean: -42.683934\n",
      "ep 5: ep_len:313 episode reward: total was -2.500000. running mean: -42.282095\n",
      "ep 5: ep_len:670 episode reward: total was -56.280000. running mean: -42.422074\n",
      "ep 5: ep_len:780 episode reward: total was -51.990000. running mean: -42.517753\n",
      "ep 5: ep_len:800 episode reward: total was -58.040000. running mean: -42.672975\n",
      "ep 5: ep_len:985 episode reward: total was -52.020000. running mean: -42.766446\n",
      "ep 5: ep_len:500 episode reward: total was -29.840000. running mean: -42.637181\n",
      "ep 5: ep_len:2195 episode reward: total was -265.140000. running mean: -44.862209\n",
      "ep 5: ep_len:1000 episode reward: total was -56.440000. running mean: -44.977987\n",
      "ep 5: ep_len:505 episode reward: total was -44.000000. running mean: -44.968207\n",
      "ep 5: ep_len:500 episode reward: total was -23.490000. running mean: -44.753425\n",
      "ep 5: ep_len:505 episode reward: total was -64.170000. running mean: -44.947591\n",
      "ep 5: ep_len:1080 episode reward: total was -177.790000. running mean: -46.276015\n",
      "ep 5: ep_len:500 episode reward: total was -30.740000. running mean: -46.120655\n",
      "ep 5: ep_len:1080 episode reward: total was -93.810000. running mean: -46.597548\n",
      "ep 5: ep_len:505 episode reward: total was -21.360000. running mean: -46.345173\n",
      "ep 5: ep_len:700 episode reward: total was -62.280000. running mean: -46.504521\n",
      "ep 5: ep_len:320 episode reward: total was 11.000000. running mean: -45.929476\n",
      "ep 5: ep_len:585 episode reward: total was -54.400000. running mean: -46.014181\n",
      "ep 5: ep_len:590 episode reward: total was -54.130000. running mean: -46.095339\n",
      "ep 5: ep_len:715 episode reward: total was -45.080000. running mean: -46.085186\n",
      "ep 5: ep_len:510 episode reward: total was -34.870000. running mean: -45.973034\n",
      "ep 5: ep_len:505 episode reward: total was -27.950000. running mean: -45.792804\n",
      "ep 5: ep_len:505 episode reward: total was -31.940000. running mean: -45.654276\n",
      "ep 5: ep_len:322 episode reward: total was -8.860000. running mean: -45.286333\n",
      "ep 5: ep_len:275 episode reward: total was -4.000000. running mean: -44.873470\n",
      "ep 5: ep_len:1090 episode reward: total was -136.730000. running mean: -45.792035\n",
      "ep 5: ep_len:820 episode reward: total was -85.760000. running mean: -46.191715\n",
      "ep 5: ep_len:555 episode reward: total was -93.360000. running mean: -46.663397\n",
      "ep 5: ep_len:1060 episode reward: total was -98.280000. running mean: -47.179564\n",
      "ep 5: ep_len:505 episode reward: total was -35.490000. running mean: -47.062668\n",
      "ep 5: ep_len:510 episode reward: total was -41.370000. running mean: -47.005741\n",
      "ep 5: ep_len:610 episode reward: total was -65.980000. running mean: -47.195484\n",
      "ep 5: ep_len:228 episode reward: total was 1.500000. running mean: -46.708529\n",
      "ep 5: ep_len:703 episode reward: total was -121.330000. running mean: -47.454744\n",
      "ep 5: ep_len:217 episode reward: total was 5.000000. running mean: -46.930196\n",
      "ep 5: ep_len:590 episode reward: total was -55.920000. running mean: -47.020094\n",
      "ep 5: ep_len:510 episode reward: total was -41.380000. running mean: -46.963693\n",
      "ep 5: ep_len:635 episode reward: total was -59.980000. running mean: -47.093856\n",
      "ep 5: ep_len:146 episode reward: total was 5.500000. running mean: -46.567918\n",
      "ep 5: ep_len:186 episode reward: total was -3.000000. running mean: -46.132239\n",
      "ep 5: ep_len:565 episode reward: total was -94.350000. running mean: -46.614416\n",
      "ep 5: ep_len:505 episode reward: total was -11.350000. running mean: -46.261772\n",
      "ep 5: ep_len:680 episode reward: total was -40.100000. running mean: -46.200154\n",
      "ep 5: ep_len:530 episode reward: total was -34.360000. running mean: -46.081753\n",
      "ep 5: ep_len:550 episode reward: total was -45.410000. running mean: -46.075035\n",
      "ep 5: ep_len:505 episode reward: total was -1.250000. running mean: -45.626785\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 5: ep_len:134 episode reward: total was 4.000000. running mean: -45.130517\n",
      "ep 5: ep_len:985 episode reward: total was -45.410000. running mean: -45.133312\n",
      "ep 5: ep_len:720 episode reward: total was -59.480000. running mean: -45.276779\n",
      "ep 5: ep_len:525 episode reward: total was -21.940000. running mean: -45.043411\n",
      "ep 5: ep_len:500 episode reward: total was -19.000000. running mean: -44.782977\n",
      "ep 5: ep_len:500 episode reward: total was -33.780000. running mean: -44.672947\n",
      "ep 5: ep_len:500 episode reward: total was -48.950000. running mean: -44.715718\n",
      "ep 5: ep_len:500 episode reward: total was -43.020000. running mean: -44.698760\n",
      "ep 5: ep_len:181 episode reward: total was 13.500000. running mean: -44.116773\n",
      "ep 5: ep_len:500 episode reward: total was -50.320000. running mean: -44.178805\n",
      "ep 5: ep_len:500 episode reward: total was 8.500000. running mean: -43.652017\n",
      "ep 5: ep_len:500 episode reward: total was -40.550000. running mean: -43.620997\n",
      "ep 5: ep_len:755 episode reward: total was -51.980000. running mean: -43.704587\n",
      "ep 5: ep_len:730 episode reward: total was -57.660000. running mean: -43.844141\n",
      "ep 5: ep_len:223 episode reward: total was 4.000000. running mean: -43.365700\n",
      "ep 5: ep_len:1850 episode reward: total was -135.440000. running mean: -44.286443\n",
      "ep 5: ep_len:500 episode reward: total was -61.440000. running mean: -44.457978\n",
      "ep 5: ep_len:500 episode reward: total was -33.440000. running mean: -44.347798\n",
      "ep 5: ep_len:500 episode reward: total was -31.900000. running mean: -44.223320\n",
      "ep 5: ep_len:201 episode reward: total was 0.500000. running mean: -43.776087\n",
      "ep 5: ep_len:745 episode reward: total was -36.990000. running mean: -43.708226\n",
      "ep 5: ep_len:740 episode reward: total was -71.290000. running mean: -43.984044\n",
      "ep 5: ep_len:500 episode reward: total was -48.280000. running mean: -44.027004\n",
      "ep 5: ep_len:500 episode reward: total was -23.670000. running mean: -43.823434\n",
      "ep 5: ep_len:2135 episode reward: total was -236.160000. running mean: -45.746799\n",
      "ep 5: ep_len:645 episode reward: total was -49.750000. running mean: -45.786831\n",
      "ep 5: ep_len:500 episode reward: total was -19.830000. running mean: -45.527263\n",
      "ep 5: ep_len:2104 episode reward: total was -188.700000. running mean: -46.958990\n",
      "ep 5: ep_len:505 episode reward: total was -16.370000. running mean: -46.653100\n",
      "ep 5: ep_len:820 episode reward: total was -31.580000. running mean: -46.502369\n",
      "ep 5: ep_len:935 episode reward: total was -47.630000. running mean: -46.513646\n",
      "ep 5: ep_len:1135 episode reward: total was -109.890000. running mean: -47.147409\n",
      "ep 5: ep_len:715 episode reward: total was -25.020000. running mean: -46.926135\n",
      "ep 5: ep_len:1740 episode reward: total was -270.770000. running mean: -49.164574\n",
      "ep 5: ep_len:500 episode reward: total was -17.760000. running mean: -48.850528\n",
      "ep 5: ep_len:505 episode reward: total was 16.000000. running mean: -48.202023\n",
      "ep 5: ep_len:1195 episode reward: total was -51.330000. running mean: -48.233303\n",
      "ep 5: ep_len:500 episode reward: total was -24.900000. running mean: -47.999970\n",
      "ep 5: ep_len:755 episode reward: total was -44.530000. running mean: -47.965270\n",
      "ep 5: ep_len:105 episode reward: total was 4.500000. running mean: -47.440617\n",
      "ep 5: ep_len:850 episode reward: total was -58.920000. running mean: -47.555411\n",
      "ep 5: ep_len:240 episode reward: total was 9.000000. running mean: -46.989857\n",
      "ep 5: ep_len:500 episode reward: total was -39.370000. running mean: -46.913658\n",
      "ep 5: ep_len:700 episode reward: total was -53.310000. running mean: -46.977622\n",
      "ep 5: ep_len:500 episode reward: total was -48.230000. running mean: -46.990146\n",
      "ep 5: ep_len:500 episode reward: total was -25.430000. running mean: -46.774544\n",
      "ep 5: ep_len:880 episode reward: total was -91.210000. running mean: -47.218899\n",
      "ep 5: ep_len:925 episode reward: total was -43.190000. running mean: -47.178610\n",
      "ep 5: ep_len:1970 episode reward: total was -191.010000. running mean: -48.616924\n",
      "ep 5: ep_len:1145 episode reward: total was -79.570000. running mean: -48.926454\n",
      "ep 5: ep_len:660 episode reward: total was -45.470000. running mean: -48.891890\n",
      "ep 5: ep_len:255 episode reward: total was -0.490000. running mean: -48.407871\n",
      "ep 5: ep_len:500 episode reward: total was -23.590000. running mean: -48.159692\n",
      "ep 5: ep_len:725 episode reward: total was -40.010000. running mean: -48.078195\n",
      "ep 5: ep_len:660 episode reward: total was -73.090000. running mean: -48.328313\n",
      "ep 5: ep_len:515 episode reward: total was -54.540000. running mean: -48.390430\n",
      "ep 5: ep_len:746 episode reward: total was -97.490000. running mean: -48.881426\n",
      "ep 5: ep_len:795 episode reward: total was -50.950000. running mean: -48.902112\n",
      "ep 5: ep_len:505 episode reward: total was -27.810000. running mean: -48.691191\n",
      "ep 5: ep_len:500 episode reward: total was 5.500000. running mean: -48.149279\n",
      "ep 5: ep_len:1645 episode reward: total was -224.130000. running mean: -49.909086\n",
      "ep 5: ep_len:510 episode reward: total was -9.250000. running mean: -49.502495\n",
      "ep 5: ep_len:500 episode reward: total was -44.160000. running mean: -49.449070\n",
      "ep 5: ep_len:735 episode reward: total was -63.010000. running mean: -49.584679\n",
      "ep 5: ep_len:555 episode reward: total was -26.390000. running mean: -49.352733\n",
      "ep 5: ep_len:1065 episode reward: total was -101.430000. running mean: -49.873505\n",
      "ep 5: ep_len:500 episode reward: total was -50.620000. running mean: -49.880970\n",
      "ep 5: ep_len:540 episode reward: total was -49.090000. running mean: -49.873060\n",
      "ep 5: ep_len:500 episode reward: total was -20.070000. running mean: -49.575030\n",
      "ep 5: ep_len:646 episode reward: total was -54.990000. running mean: -49.629180\n",
      "ep 5: ep_len:925 episode reward: total was -77.480000. running mean: -49.907688\n",
      "ep 5: ep_len:605 episode reward: total was -47.810000. running mean: -49.886711\n",
      "ep 5: ep_len:301 episode reward: total was 0.500000. running mean: -49.382844\n",
      "ep 5: ep_len:515 episode reward: total was -13.820000. running mean: -49.027215\n",
      "ep 5: ep_len:500 episode reward: total was -38.680000. running mean: -48.923743\n",
      "ep 5: ep_len:1225 episode reward: total was -50.400000. running mean: -48.938506\n",
      "ep 5: ep_len:500 episode reward: total was -53.760000. running mean: -48.986721\n",
      "ep 5: ep_len:625 episode reward: total was -41.460000. running mean: -48.911453\n",
      "ep 5: ep_len:565 episode reward: total was -43.330000. running mean: -48.855639\n",
      "ep 5: ep_len:1120 episode reward: total was -104.390000. running mean: -49.410983\n",
      "ep 5: ep_len:775 episode reward: total was -59.620000. running mean: -49.513073\n",
      "ep 5: ep_len:471 episode reward: total was -23.860000. running mean: -49.256542\n",
      "ep 5: ep_len:595 episode reward: total was -74.090000. running mean: -49.504877\n",
      "ep 5: ep_len:645 episode reward: total was -46.620000. running mean: -49.476028\n",
      "ep 5: ep_len:520 episode reward: total was -68.670000. running mean: -49.667968\n",
      "ep 5: ep_len:1302 episode reward: total was -179.230000. running mean: -50.963588\n",
      "ep 5: ep_len:500 episode reward: total was -28.820000. running mean: -50.742152\n",
      "ep 5: ep_len:505 episode reward: total was -57.220000. running mean: -50.806930\n",
      "ep 5: ep_len:500 episode reward: total was 0.730000. running mean: -50.291561\n",
      "ep 5: ep_len:885 episode reward: total was -46.320000. running mean: -50.251846\n",
      "ep 5: ep_len:905 episode reward: total was -55.490000. running mean: -50.304227\n",
      "ep 5: ep_len:640 episode reward: total was -90.160000. running mean: -50.702785\n",
      "ep 5: ep_len:690 episode reward: total was -47.150000. running mean: -50.667257\n",
      "ep 5: ep_len:500 episode reward: total was -17.280000. running mean: -50.333384\n",
      "ep 5: ep_len:795 episode reward: total was -69.650000. running mean: -50.526551\n",
      "ep 5: ep_len:740 episode reward: total was -53.750000. running mean: -50.558785\n",
      "ep 5: ep_len:600 episode reward: total was -45.310000. running mean: -50.506297\n",
      "ep 5: ep_len:635 episode reward: total was -86.650000. running mean: -50.867734\n",
      "ep 5: ep_len:840 episode reward: total was -66.620000. running mean: -51.025257\n",
      "ep 5: ep_len:570 episode reward: total was -42.950000. running mean: -50.944504\n",
      "ep 5: ep_len:560 episode reward: total was -53.730000. running mean: -50.972359\n",
      "ep 5: ep_len:500 episode reward: total was -38.770000. running mean: -50.850336\n",
      "ep 5: ep_len:500 episode reward: total was -31.880000. running mean: -50.660632\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 5: ep_len:500 episode reward: total was -24.980000. running mean: -50.403826\n",
      "ep 5: ep_len:590 episode reward: total was -40.250000. running mean: -50.302288\n",
      "ep 5: ep_len:985 episode reward: total was -88.760000. running mean: -50.686865\n",
      "ep 5: ep_len:500 episode reward: total was -47.980000. running mean: -50.659796\n",
      "ep 5: ep_len:318 episode reward: total was 12.000000. running mean: -50.033198\n",
      "ep 5: ep_len:446 episode reward: total was 11.500000. running mean: -49.417866\n",
      "ep 5: ep_len:505 episode reward: total was -37.440000. running mean: -49.298088\n",
      "ep 5: ep_len:560 episode reward: total was -39.330000. running mean: -49.198407\n",
      "ep 5: ep_len:500 episode reward: total was -35.100000. running mean: -49.057423\n",
      "ep 5: ep_len:267 episode reward: total was 8.500000. running mean: -48.481848\n",
      "ep 5: ep_len:140 episode reward: total was -8.000000. running mean: -48.077030\n",
      "ep 5: ep_len:500 episode reward: total was -25.270000. running mean: -47.848960\n",
      "ep 5: ep_len:795 episode reward: total was -59.550000. running mean: -47.965970\n",
      "ep 5: ep_len:865 episode reward: total was -40.730000. running mean: -47.893610\n",
      "ep 5: ep_len:560 episode reward: total was -34.790000. running mean: -47.762574\n",
      "ep 5: ep_len:810 episode reward: total was -75.190000. running mean: -48.036849\n",
      "ep 5: ep_len:525 episode reward: total was -11.200000. running mean: -47.668480\n",
      "ep 5: ep_len:935 episode reward: total was -39.610000. running mean: -47.587895\n",
      "ep 5: ep_len:500 episode reward: total was -9.360000. running mean: -47.205616\n",
      "ep 5: ep_len:940 episode reward: total was -71.700000. running mean: -47.450560\n",
      "ep 5: ep_len:500 episode reward: total was -45.740000. running mean: -47.433455\n",
      "ep 5: ep_len:965 episode reward: total was -78.920000. running mean: -47.748320\n",
      "ep 5: ep_len:725 episode reward: total was -49.280000. running mean: -47.763637\n",
      "ep 5: ep_len:630 episode reward: total was -36.160000. running mean: -47.647600\n",
      "ep 5: ep_len:498 episode reward: total was 0.680000. running mean: -47.164324\n",
      "ep 5: ep_len:1290 episode reward: total was -88.910000. running mean: -47.581781\n",
      "ep 5: ep_len:500 episode reward: total was -33.100000. running mean: -47.436963\n",
      "ep 5: ep_len:880 episode reward: total was -84.110000. running mean: -47.803694\n",
      "ep 5: ep_len:875 episode reward: total was -126.570000. running mean: -48.591357\n",
      "ep 5: ep_len:800 episode reward: total was -57.280000. running mean: -48.678243\n",
      "ep 5: ep_len:510 episode reward: total was -39.270000. running mean: -48.584161\n",
      "ep 5: ep_len:915 episode reward: total was -147.300000. running mean: -49.571319\n",
      "ep 5: ep_len:665 episode reward: total was -36.640000. running mean: -49.442006\n",
      "ep 5: ep_len:555 episode reward: total was -78.880000. running mean: -49.736386\n",
      "ep 5: ep_len:935 episode reward: total was -49.960000. running mean: -49.738622\n",
      "ep 5: ep_len:535 episode reward: total was -58.310000. running mean: -49.824336\n",
      "ep 5: ep_len:360 episode reward: total was -39.480000. running mean: -49.720892\n",
      "ep 5: ep_len:660 episode reward: total was -45.920000. running mean: -49.682884\n",
      "ep 5: ep_len:700 episode reward: total was -39.240000. running mean: -49.578455\n",
      "ep 5: ep_len:1075 episode reward: total was -76.640000. running mean: -49.849070\n",
      "ep 5: ep_len:500 episode reward: total was -14.830000. running mean: -49.498879\n",
      "ep 5: ep_len:500 episode reward: total was -25.120000. running mean: -49.255091\n",
      "ep 5: ep_len:940 episode reward: total was -77.440000. running mean: -49.536940\n",
      "ep 5: ep_len:1620 episode reward: total was -226.500000. running mean: -51.306570\n",
      "ep 5: ep_len:500 episode reward: total was -30.630000. running mean: -51.099805\n",
      "ep 5: ep_len:500 episode reward: total was -16.320000. running mean: -50.752007\n",
      "ep 5: ep_len:640 episode reward: total was -38.400000. running mean: -50.628487\n",
      "ep 5: ep_len:500 episode reward: total was -9.890000. running mean: -50.221102\n",
      "ep 5: ep_len:715 episode reward: total was -47.100000. running mean: -50.189891\n",
      "ep 5: ep_len:610 episode reward: total was -45.410000. running mean: -50.142092\n",
      "ep 5: ep_len:755 episode reward: total was -38.060000. running mean: -50.021271\n",
      "ep 5: ep_len:1520 episode reward: total was -182.330000. running mean: -51.344358\n",
      "ep 5: ep_len:505 episode reward: total was -22.900000. running mean: -51.059915\n",
      "ep 5: ep_len:885 episode reward: total was -60.310000. running mean: -51.152415\n",
      "ep 5: ep_len:695 episode reward: total was -42.090000. running mean: -51.061791\n",
      "ep 5: ep_len:585 episode reward: total was -53.910000. running mean: -51.090273\n",
      "ep 5: ep_len:500 episode reward: total was -26.610000. running mean: -50.845471\n",
      "ep 5: ep_len:500 episode reward: total was -53.560000. running mean: -50.872616\n",
      "ep 5: ep_len:625 episode reward: total was -39.580000. running mean: -50.759690\n",
      "ep 5: ep_len:685 episode reward: total was -46.690000. running mean: -50.718993\n",
      "ep 5: ep_len:1470 episode reward: total was -185.000000. running mean: -52.061803\n",
      "ep 5: ep_len:1045 episode reward: total was -127.240000. running mean: -52.813585\n",
      "ep 5: ep_len:785 episode reward: total was -64.130000. running mean: -52.926749\n",
      "ep 5: ep_len:486 episode reward: total was -58.650000. running mean: -52.983982\n",
      "ep 5: ep_len:680 episode reward: total was -43.130000. running mean: -52.885442\n",
      "ep 5: ep_len:500 episode reward: total was -14.420000. running mean: -52.500787\n",
      "ep 5: ep_len:371 episode reward: total was -15.830000. running mean: -52.134079\n",
      "ep 5: ep_len:500 episode reward: total was -19.900000. running mean: -51.811739\n",
      "ep 5: ep_len:500 episode reward: total was -29.010000. running mean: -51.583721\n",
      "ep 5: ep_len:476 episode reward: total was 12.000000. running mean: -50.947884\n",
      "ep 5: ep_len:500 episode reward: total was -14.610000. running mean: -50.584505\n",
      "ep 5: ep_len:620 episode reward: total was -19.290000. running mean: -50.271560\n",
      "ep 5: ep_len:580 episode reward: total was -54.440000. running mean: -50.313245\n",
      "ep 5: ep_len:500 episode reward: total was -20.370000. running mean: -50.013812\n",
      "ep 5: ep_len:980 episode reward: total was -40.520000. running mean: -49.918874\n",
      "ep 5: ep_len:500 episode reward: total was -13.360000. running mean: -49.553285\n",
      "ep 5: ep_len:825 episode reward: total was -60.010000. running mean: -49.657852\n",
      "ep 5: ep_len:580 episode reward: total was -46.540000. running mean: -49.626674\n",
      "ep 5: ep_len:510 episode reward: total was -36.330000. running mean: -49.493707\n",
      "ep 5: ep_len:500 episode reward: total was -23.280000. running mean: -49.231570\n",
      "ep 5: ep_len:231 episode reward: total was 7.000000. running mean: -48.669254\n",
      "ep 5: ep_len:347 episode reward: total was -10.400000. running mean: -48.286562\n",
      "ep 5: ep_len:500 episode reward: total was -10.350000. running mean: -47.907196\n",
      "ep 5: ep_len:1145 episode reward: total was -58.610000. running mean: -48.014224\n",
      "ep 5: ep_len:500 episode reward: total was -30.510000. running mean: -47.839182\n",
      "ep 5: ep_len:190 episode reward: total was 1.500000. running mean: -47.345790\n",
      "ep 5: ep_len:515 episode reward: total was -34.370000. running mean: -47.216032\n",
      "ep 5: ep_len:700 episode reward: total was -19.910000. running mean: -46.942972\n",
      "ep 5: ep_len:580 episode reward: total was -68.550000. running mean: -47.159042\n",
      "ep 5: ep_len:133 episode reward: total was 5.500000. running mean: -46.632452\n",
      "ep 5: ep_len:640 episode reward: total was -26.050000. running mean: -46.426627\n",
      "ep 5: ep_len:175 episode reward: total was -5.000000. running mean: -46.012361\n",
      "ep 5: ep_len:500 episode reward: total was -14.670000. running mean: -45.698937\n",
      "ep 5: ep_len:500 episode reward: total was -20.810000. running mean: -45.450048\n",
      "ep 5: ep_len:163 episode reward: total was 7.000000. running mean: -44.925548\n",
      "ep 5: ep_len:500 episode reward: total was -37.750000. running mean: -44.853792\n",
      "ep 5: ep_len:685 episode reward: total was -49.180000. running mean: -44.897054\n",
      "ep 5: ep_len:610 episode reward: total was -40.210000. running mean: -44.850184\n",
      "ep 5: ep_len:775 episode reward: total was -66.660000. running mean: -45.068282\n",
      "ep 5: ep_len:500 episode reward: total was -2.770000. running mean: -44.645299\n",
      "ep 5: ep_len:304 episode reward: total was 6.000000. running mean: -44.138846\n",
      "ep 5: ep_len:620 episode reward: total was -72.540000. running mean: -44.422858\n",
      "ep 5: ep_len:500 episode reward: total was -23.620000. running mean: -44.214829\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 5: ep_len:905 episode reward: total was -63.580000. running mean: -44.408481\n",
      "ep 5: ep_len:810 episode reward: total was -62.030000. running mean: -44.584696\n",
      "ep 5: ep_len:830 episode reward: total was -55.070000. running mean: -44.689549\n",
      "ep 5: ep_len:660 episode reward: total was -49.090000. running mean: -44.733553\n",
      "ep 5: ep_len:560 episode reward: total was -45.880000. running mean: -44.745018\n",
      "ep 5: ep_len:500 episode reward: total was -29.420000. running mean: -44.591768\n",
      "ep 5: ep_len:590 episode reward: total was -28.330000. running mean: -44.429150\n",
      "ep 5: ep_len:325 episode reward: total was -28.840000. running mean: -44.273259\n",
      "ep 5: ep_len:620 episode reward: total was -43.290000. running mean: -44.263426\n",
      "ep 5: ep_len:975 episode reward: total was -130.380000. running mean: -45.124592\n",
      "ep 5: ep_len:127 episode reward: total was -1.000000. running mean: -44.683346\n",
      "ep 5: ep_len:685 episode reward: total was -20.080000. running mean: -44.437312\n",
      "ep 5: ep_len:660 episode reward: total was -35.880000. running mean: -44.351739\n",
      "ep 5: ep_len:575 episode reward: total was -78.170000. running mean: -44.689922\n",
      "ep 5: ep_len:500 episode reward: total was -25.510000. running mean: -44.498123\n",
      "ep 5: ep_len:180 episode reward: total was 6.000000. running mean: -43.993141\n",
      "ep 5: ep_len:600 episode reward: total was -44.630000. running mean: -43.999510\n",
      "ep 5: ep_len:505 episode reward: total was -12.270000. running mean: -43.682215\n",
      "ep 5: ep_len:500 episode reward: total was -36.090000. running mean: -43.606293\n",
      "ep 5: ep_len:500 episode reward: total was -5.680000. running mean: -43.227030\n",
      "ep 5: ep_len:655 episode reward: total was -28.350000. running mean: -43.078259\n",
      "ep 5: ep_len:500 episode reward: total was -31.150000. running mean: -42.958977\n",
      "ep 5: ep_len:910 episode reward: total was -68.840000. running mean: -43.217787\n",
      "ep 5: ep_len:585 episode reward: total was -44.820000. running mean: -43.233809\n",
      "ep 5: ep_len:665 episode reward: total was -42.640000. running mean: -43.227871\n",
      "ep 5: ep_len:510 episode reward: total was -35.890000. running mean: -43.154492\n",
      "ep 5: ep_len:555 episode reward: total was -53.540000. running mean: -43.258347\n",
      "ep 5: ep_len:675 episode reward: total was -19.180000. running mean: -43.017564\n",
      "ep 5: ep_len:1260 episode reward: total was -78.920000. running mean: -43.376588\n",
      "ep 5: ep_len:895 episode reward: total was -59.930000. running mean: -43.542122\n",
      "ep 5: ep_len:710 episode reward: total was -31.440000. running mean: -43.421101\n",
      "ep 5: ep_len:500 episode reward: total was -3.850000. running mean: -43.025390\n",
      "ep 5: ep_len:900 episode reward: total was -90.630000. running mean: -43.501436\n",
      "ep 5: ep_len:520 episode reward: total was -34.220000. running mean: -43.408622\n",
      "ep 5: ep_len:680 episode reward: total was -53.230000. running mean: -43.506836\n",
      "ep 5: ep_len:510 episode reward: total was -13.790000. running mean: -43.209667\n",
      "ep 5: ep_len:500 episode reward: total was -8.790000. running mean: -42.865471\n",
      "ep 5: ep_len:500 episode reward: total was 5.500000. running mean: -42.381816\n",
      "ep 5: ep_len:805 episode reward: total was -50.870000. running mean: -42.466698\n",
      "ep 5: ep_len:945 episode reward: total was -45.960000. running mean: -42.501631\n",
      "ep 5: ep_len:155 episode reward: total was -2.000000. running mean: -42.096615\n",
      "ep 5: ep_len:505 episode reward: total was -8.870000. running mean: -41.764348\n",
      "ep 5: ep_len:500 episode reward: total was -37.580000. running mean: -41.722505\n",
      "ep 5: ep_len:830 episode reward: total was -55.440000. running mean: -41.859680\n",
      "ep 5: ep_len:630 episode reward: total was -49.780000. running mean: -41.938883\n",
      "ep 5: ep_len:500 episode reward: total was 7.500000. running mean: -41.444494\n",
      "ep 5: ep_len:138 episode reward: total was 1.500000. running mean: -41.015049\n",
      "ep 5: ep_len:500 episode reward: total was -29.350000. running mean: -40.898399\n",
      "ep 5: ep_len:525 episode reward: total was -23.210000. running mean: -40.721515\n",
      "ep 5: ep_len:500 episode reward: total was -25.790000. running mean: -40.572200\n",
      "ep 5: ep_len:940 episode reward: total was -61.840000. running mean: -40.784878\n",
      "ep 5: ep_len:500 episode reward: total was -21.050000. running mean: -40.587529\n",
      "ep 5: ep_len:810 episode reward: total was -65.090000. running mean: -40.832554\n",
      "ep 5: ep_len:840 episode reward: total was -47.380000. running mean: -40.898028\n",
      "ep 5: ep_len:1180 episode reward: total was -151.320000. running mean: -42.002248\n",
      "ep 5: ep_len:615 episode reward: total was -42.250000. running mean: -42.004725\n",
      "ep 5: ep_len:500 episode reward: total was -30.910000. running mean: -41.893778\n",
      "ep 5: ep_len:600 episode reward: total was -14.510000. running mean: -41.619940\n",
      "ep 5: ep_len:705 episode reward: total was -39.020000. running mean: -41.593941\n",
      "ep 5: ep_len:500 episode reward: total was -22.610000. running mean: -41.404101\n",
      "ep 5: ep_len:500 episode reward: total was -22.090000. running mean: -41.210960\n",
      "ep 5: ep_len:1015 episode reward: total was -58.750000. running mean: -41.386351\n",
      "ep 5: ep_len:510 episode reward: total was -37.190000. running mean: -41.344387\n",
      "ep 5: ep_len:194 episode reward: total was 7.500000. running mean: -40.855943\n",
      "ep 5: ep_len:595 episode reward: total was -46.800000. running mean: -40.915384\n",
      "ep 5: ep_len:505 episode reward: total was -30.320000. running mean: -40.809430\n",
      "ep 5: ep_len:1335 episode reward: total was -177.310000. running mean: -42.174436\n",
      "ep 5: ep_len:540 episode reward: total was -65.110000. running mean: -42.403792\n",
      "ep 5: ep_len:570 episode reward: total was -41.820000. running mean: -42.397954\n",
      "ep 5: ep_len:945 episode reward: total was -32.080000. running mean: -42.294774\n",
      "ep 5: ep_len:444 episode reward: total was -21.780000. running mean: -42.089626\n",
      "ep 5: ep_len:505 episode reward: total was -30.310000. running mean: -41.971830\n",
      "ep 5: ep_len:720 episode reward: total was -62.730000. running mean: -42.179412\n",
      "ep 5: ep_len:500 episode reward: total was -2.210000. running mean: -41.779718\n",
      "ep 5: ep_len:500 episode reward: total was -32.270000. running mean: -41.684620\n",
      "ep 5: ep_len:505 episode reward: total was -4.770000. running mean: -41.315474\n",
      "ep 5: ep_len:915 episode reward: total was -53.340000. running mean: -41.435720\n",
      "ep 5: ep_len:850 episode reward: total was -53.970000. running mean: -41.561062\n",
      "ep 5: ep_len:500 episode reward: total was -46.580000. running mean: -41.611252\n",
      "ep 5: ep_len:970 episode reward: total was -50.520000. running mean: -41.700339\n",
      "ep 5: ep_len:505 episode reward: total was -36.070000. running mean: -41.644036\n",
      "ep 5: ep_len:500 episode reward: total was -26.760000. running mean: -41.495195\n",
      "ep 5: ep_len:505 episode reward: total was -19.910000. running mean: -41.279344\n",
      "ep 5: ep_len:500 episode reward: total was -25.810000. running mean: -41.124650\n",
      "ep 5: ep_len:920 episode reward: total was -83.540000. running mean: -41.548804\n",
      "ep 5: ep_len:500 episode reward: total was -46.720000. running mean: -41.600516\n",
      "ep 5: ep_len:600 episode reward: total was -38.910000. running mean: -41.573610\n",
      "ep 5: ep_len:500 episode reward: total was -50.150000. running mean: -41.659374\n",
      "ep 5: ep_len:720 episode reward: total was -27.400000. running mean: -41.516781\n",
      "ep 5: ep_len:500 episode reward: total was -24.240000. running mean: -41.344013\n",
      "ep 5: ep_len:540 episode reward: total was -51.980000. running mean: -41.450373\n",
      "ep 5: ep_len:500 episode reward: total was -13.300000. running mean: -41.168869\n",
      "ep 5: ep_len:845 episode reward: total was -83.680000. running mean: -41.593980\n",
      "ep 5: ep_len:500 episode reward: total was -33.320000. running mean: -41.511240\n",
      "ep 5: ep_len:1455 episode reward: total was -243.750000. running mean: -43.533628\n",
      "ep 5: ep_len:570 episode reward: total was -34.260000. running mean: -43.440892\n",
      "ep 5: ep_len:505 episode reward: total was -8.880000. running mean: -43.095283\n",
      "ep 5: ep_len:795 episode reward: total was -40.590000. running mean: -43.070230\n",
      "ep 5: ep_len:665 episode reward: total was -21.330000. running mean: -42.852828\n",
      "ep 5: ep_len:505 episode reward: total was -16.460000. running mean: -42.588899\n",
      "ep 5: ep_len:765 episode reward: total was -66.680000. running mean: -42.829810\n",
      "ep 5: ep_len:845 episode reward: total was -26.290000. running mean: -42.664412\n",
      "ep 5: ep_len:241 episode reward: total was 3.500000. running mean: -42.202768\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 5: ep_len:1005 episode reward: total was -45.170000. running mean: -42.232440\n",
      "ep 5: ep_len:500 episode reward: total was -36.980000. running mean: -42.179916\n",
      "ep 5: ep_len:515 episode reward: total was -34.370000. running mean: -42.101817\n",
      "ep 5: ep_len:575 episode reward: total was -28.130000. running mean: -41.962099\n",
      "ep 5: ep_len:505 episode reward: total was -23.850000. running mean: -41.780978\n",
      "ep 5: ep_len:520 episode reward: total was -24.270000. running mean: -41.605868\n",
      "ep 5: ep_len:505 episode reward: total was -58.840000. running mean: -41.778209\n",
      "ep 5: ep_len:500 episode reward: total was -15.840000. running mean: -41.518827\n",
      "ep 5: ep_len:690 episode reward: total was -86.020000. running mean: -41.963839\n",
      "ep 5: ep_len:505 episode reward: total was -20.340000. running mean: -41.747601\n",
      "ep 5: ep_len:715 episode reward: total was -53.130000. running mean: -41.861425\n",
      "ep 5: ep_len:595 episode reward: total was -47.340000. running mean: -41.916210\n",
      "ep 5: ep_len:530 episode reward: total was -43.400000. running mean: -41.931048\n",
      "ep 5: ep_len:500 episode reward: total was -29.960000. running mean: -41.811338\n",
      "ep 5: ep_len:158 episode reward: total was 5.500000. running mean: -41.338224\n",
      "ep 5: ep_len:845 episode reward: total was -35.610000. running mean: -41.280942\n",
      "ep 5: ep_len:820 episode reward: total was -44.620000. running mean: -41.314333\n",
      "ep 5: ep_len:500 episode reward: total was -15.870000. running mean: -41.059889\n",
      "ep 5: ep_len:765 episode reward: total was -30.950000. running mean: -40.958790\n",
      "ep 5: ep_len:1515 episode reward: total was -257.600000. running mean: -43.125203\n",
      "ep 5: ep_len:800 episode reward: total was -58.070000. running mean: -43.274651\n",
      "ep 5: ep_len:17940 episode reward: total was -3373.150000. running mean: -76.573404\n",
      "ep 5: ep_len:880 episode reward: total was -22.440000. running mean: -76.032070\n",
      "ep 5: ep_len:645 episode reward: total was -48.740000. running mean: -75.759149\n",
      "ep 5: ep_len:159 episode reward: total was -2.500000. running mean: -75.026558\n",
      "ep 5: ep_len:500 episode reward: total was -49.060000. running mean: -74.766892\n",
      "ep 5: ep_len:4725 episode reward: total was -758.560000. running mean: -81.604823\n",
      "ep 5: ep_len:515 episode reward: total was -57.660000. running mean: -81.365375\n",
      "ep 5: ep_len:173 episode reward: total was 11.000000. running mean: -80.441721\n",
      "ep 5: ep_len:500 episode reward: total was -17.420000. running mean: -79.811504\n",
      "ep 5: ep_len:790 episode reward: total was -63.840000. running mean: -79.651789\n",
      "ep 5: ep_len:865 episode reward: total was -104.860000. running mean: -79.903871\n",
      "ep 5: ep_len:505 episode reward: total was -60.860000. running mean: -79.713432\n",
      "ep 5: ep_len:183 episode reward: total was 1.500000. running mean: -78.901298\n",
      "ep 5: ep_len:1060 episode reward: total was -82.940000. running mean: -78.941685\n",
      "ep 5: ep_len:515 episode reward: total was -35.430000. running mean: -78.506568\n",
      "ep 5: ep_len:350 episode reward: total was 20.500000. running mean: -77.516503\n",
      "ep 5: ep_len:500 episode reward: total was -24.890000. running mean: -76.990238\n",
      "ep 5: ep_len:530 episode reward: total was -32.400000. running mean: -76.544335\n",
      "ep 5: ep_len:630 episode reward: total was -37.620000. running mean: -76.155092\n",
      "ep 5: ep_len:500 episode reward: total was -55.870000. running mean: -75.952241\n",
      "ep 5: ep_len:500 episode reward: total was -28.980000. running mean: -75.482519\n",
      "ep 5: ep_len:197 episode reward: total was 3.000000. running mean: -74.697693\n",
      "ep 5: ep_len:660 episode reward: total was -33.550000. running mean: -74.286216\n",
      "ep 5: ep_len:850 episode reward: total was -154.900000. running mean: -75.092354\n",
      "ep 5: ep_len:695 episode reward: total was -74.160000. running mean: -75.083031\n",
      "ep 5: ep_len:910 episode reward: total was -135.840000. running mean: -75.690600\n",
      "ep 5: ep_len:500 episode reward: total was -23.650000. running mean: -75.170194\n",
      "ep 5: ep_len:1135 episode reward: total was -127.550000. running mean: -75.693992\n",
      "ep 5: ep_len:505 episode reward: total was -13.390000. running mean: -75.070953\n",
      "ep 5: ep_len:505 episode reward: total was -27.370000. running mean: -74.593943\n",
      "ep 5: ep_len:500 episode reward: total was -30.910000. running mean: -74.157104\n",
      "ep 5: ep_len:710 episode reward: total was -40.530000. running mean: -73.820833\n",
      "ep 5: ep_len:540 episode reward: total was -37.990000. running mean: -73.462524\n",
      "ep 5: ep_len:600 episode reward: total was -39.950000. running mean: -73.127399\n",
      "ep 5: ep_len:550 episode reward: total was -67.600000. running mean: -73.072125\n",
      "ep 5: ep_len:660 episode reward: total was -38.120000. running mean: -72.722604\n",
      "ep 5: ep_len:765 episode reward: total was -72.260000. running mean: -72.717978\n",
      "ep 5: ep_len:505 episode reward: total was -48.100000. running mean: -72.471798\n",
      "ep 5: ep_len:500 episode reward: total was -39.980000. running mean: -72.146880\n",
      "ep 5: ep_len:500 episode reward: total was -16.300000. running mean: -71.588411\n",
      "ep 5: ep_len:560 episode reward: total was -71.130000. running mean: -71.583827\n",
      "ep 5: ep_len:510 episode reward: total was -52.370000. running mean: -71.391689\n",
      "ep 5: ep_len:258 episode reward: total was -10.000000. running mean: -70.777772\n",
      "ep 5: ep_len:500 episode reward: total was -14.040000. running mean: -70.210394\n",
      "ep 5: ep_len:805 episode reward: total was -65.560000. running mean: -70.163890\n",
      "ep 5: ep_len:650 episode reward: total was -59.350000. running mean: -70.055751\n",
      "ep 5: ep_len:815 episode reward: total was -108.510000. running mean: -70.440294\n",
      "ep 5: ep_len:785 episode reward: total was -46.880000. running mean: -70.204691\n",
      "ep 5: ep_len:500 episode reward: total was -37.000000. running mean: -69.872644\n",
      "ep 5: ep_len:500 episode reward: total was -56.740000. running mean: -69.741317\n",
      "ep 5: ep_len:2240 episode reward: total was -282.920000. running mean: -71.873104\n",
      "ep 5: ep_len:615 episode reward: total was -72.830000. running mean: -71.882673\n",
      "ep 5: ep_len:500 episode reward: total was -28.490000. running mean: -71.448747\n",
      "ep 5: ep_len:1035 episode reward: total was -49.560000. running mean: -71.229859\n",
      "ep 5: ep_len:890 episode reward: total was -48.060000. running mean: -70.998160\n",
      "ep 5: ep_len:505 episode reward: total was -42.030000. running mean: -70.708479\n",
      "ep 5: ep_len:309 episode reward: total was 12.500000. running mean: -69.876394\n",
      "ep 5: ep_len:500 episode reward: total was -19.360000. running mean: -69.371230\n",
      "ep 5: ep_len:995 episode reward: total was -73.270000. running mean: -69.410218\n",
      "ep 5: ep_len:930 episode reward: total was -127.470000. running mean: -69.990816\n",
      "ep 5: ep_len:650 episode reward: total was -34.100000. running mean: -69.631908\n",
      "ep 5: ep_len:600 episode reward: total was -96.790000. running mean: -69.903488\n",
      "ep 5: ep_len:525 episode reward: total was -38.110000. running mean: -69.585554\n",
      "ep 5: ep_len:1005 episode reward: total was -53.670000. running mean: -69.426398\n",
      "ep 5: ep_len:790 episode reward: total was -50.890000. running mean: -69.241034\n",
      "ep 5: ep_len:750 episode reward: total was -54.070000. running mean: -69.089324\n",
      "ep 5: ep_len:500 episode reward: total was -27.940000. running mean: -68.677830\n",
      "ep 5: ep_len:920 episode reward: total was -56.590000. running mean: -68.556952\n",
      "ep 5: ep_len:730 episode reward: total was -14.550000. running mean: -68.016883\n",
      "ep 5: ep_len:500 episode reward: total was -37.000000. running mean: -67.706714\n",
      "ep 5: ep_len:500 episode reward: total was -34.490000. running mean: -67.374547\n",
      "ep 5: ep_len:500 episode reward: total was 2.160000. running mean: -66.679201\n",
      "ep 5: ep_len:505 episode reward: total was -15.280000. running mean: -66.165209\n",
      "ep 5: ep_len:153 episode reward: total was 3.000000. running mean: -65.473557\n",
      "ep 5: ep_len:500 episode reward: total was -5.340000. running mean: -64.872222\n",
      "ep 5: ep_len:500 episode reward: total was -9.400000. running mean: -64.317499\n",
      "ep 5: ep_len:675 episode reward: total was -69.870000. running mean: -64.373024\n",
      "ep 5: ep_len:238 episode reward: total was 5.000000. running mean: -63.679294\n",
      "ep 5: ep_len:540 episode reward: total was -42.400000. running mean: -63.466501\n",
      "ep 5: ep_len:500 episode reward: total was -12.800000. running mean: -62.959836\n",
      "ep 5: ep_len:830 episode reward: total was -44.980000. running mean: -62.780038\n",
      "ep 5: ep_len:500 episode reward: total was -36.350000. running mean: -62.515737\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 5: ep_len:2620 episode reward: total was -367.570000. running mean: -65.566280\n",
      "ep 5: ep_len:515 episode reward: total was -36.940000. running mean: -65.280017\n",
      "ep 5: ep_len:5610 episode reward: total was -947.080000. running mean: -74.098017\n",
      "ep 5: ep_len:620 episode reward: total was -40.220000. running mean: -73.759237\n",
      "ep 5: ep_len:500 episode reward: total was -31.890000. running mean: -73.340545\n",
      "ep 5: ep_len:1670 episode reward: total was -202.720000. running mean: -74.634339\n",
      "ep 5: ep_len:620 episode reward: total was -76.060000. running mean: -74.648596\n",
      "ep 5: ep_len:500 episode reward: total was -41.010000. running mean: -74.312210\n",
      "ep 5: ep_len:520 episode reward: total was -18.310000. running mean: -73.752188\n",
      "ep 5: ep_len:266 episode reward: total was 10.000000. running mean: -72.914666\n",
      "epsilon:0.307589 episode_count: 4739. steps_count: 3471769.000000\n",
      "ep 6: ep_len:510 episode reward: total was -21.320000. running mean: -72.398719\n",
      "ep 6: ep_len:820 episode reward: total was -68.100000. running mean: -72.355732\n",
      "ep 6: ep_len:500 episode reward: total was -33.660000. running mean: -71.968775\n",
      "ep 6: ep_len:800 episode reward: total was -46.420000. running mean: -71.713287\n",
      "ep 6: ep_len:675 episode reward: total was -69.890000. running mean: -71.695054\n",
      "ep 6: ep_len:505 episode reward: total was -42.370000. running mean: -71.401803\n",
      "ep 6: ep_len:930 episode reward: total was -44.110000. running mean: -71.128885\n",
      "ep 6: ep_len:500 episode reward: total was -29.760000. running mean: -70.715197\n",
      "ep 6: ep_len:790 episode reward: total was -52.980000. running mean: -70.537845\n",
      "ep 6: ep_len:690 episode reward: total was -12.600000. running mean: -69.958466\n",
      "ep 6: ep_len:500 episode reward: total was -34.950000. running mean: -69.608381\n",
      "ep 6: ep_len:505 episode reward: total was -17.730000. running mean: -69.089598\n",
      "ep 6: ep_len:505 episode reward: total was -27.960000. running mean: -68.678302\n",
      "ep 6: ep_len:880 episode reward: total was -50.900000. running mean: -68.500519\n",
      "ep 6: ep_len:1235 episode reward: total was -59.030000. running mean: -68.405813\n",
      "ep 6: ep_len:500 episode reward: total was -3.290000. running mean: -67.754655\n",
      "ep 6: ep_len:500 episode reward: total was -44.260000. running mean: -67.519709\n",
      "ep 6: ep_len:745 episode reward: total was -83.890000. running mean: -67.683412\n",
      "ep 6: ep_len:555 episode reward: total was -42.370000. running mean: -67.430278\n",
      "ep 6: ep_len:530 episode reward: total was -19.320000. running mean: -66.949175\n",
      "ep 6: ep_len:1805 episode reward: total was -155.990000. running mean: -67.839583\n",
      "ep 6: ep_len:935 episode reward: total was -90.090000. running mean: -68.062087\n",
      "ep 6: ep_len:1845 episode reward: total was -203.950000. running mean: -69.420966\n",
      "ep 6: ep_len:500 episode reward: total was -19.550000. running mean: -68.922257\n",
      "ep 6: ep_len:950 episode reward: total was -51.750000. running mean: -68.750534\n",
      "ep 6: ep_len:1960 episode reward: total was -322.890000. running mean: -71.291929\n",
      "ep 6: ep_len:500 episode reward: total was -10.550000. running mean: -70.684509\n",
      "ep 6: ep_len:505 episode reward: total was -25.280000. running mean: -70.230464\n",
      "ep 6: ep_len:500 episode reward: total was -3.790000. running mean: -69.566060\n",
      "ep 6: ep_len:795 episode reward: total was -22.770000. running mean: -69.098099\n",
      "ep 6: ep_len:278 episode reward: total was 5.000000. running mean: -68.357118\n",
      "ep 6: ep_len:665 episode reward: total was -25.410000. running mean: -67.927647\n",
      "ep 6: ep_len:680 episode reward: total was -52.710000. running mean: -67.775471\n",
      "ep 6: ep_len:745 episode reward: total was -40.480000. running mean: -67.502516\n",
      "ep 6: ep_len:500 episode reward: total was -9.320000. running mean: -66.920691\n",
      "ep 6: ep_len:725 episode reward: total was -39.490000. running mean: -66.646384\n",
      "ep 6: ep_len:520 episode reward: total was -45.960000. running mean: -66.439520\n",
      "ep 6: ep_len:500 episode reward: total was -25.980000. running mean: -66.034925\n",
      "ep 6: ep_len:500 episode reward: total was -17.590000. running mean: -65.550475\n",
      "ep 6: ep_len:500 episode reward: total was -29.900000. running mean: -65.193971\n",
      "ep 6: ep_len:580 episode reward: total was -49.930000. running mean: -65.041331\n",
      "ep 6: ep_len:500 episode reward: total was -3.840000. running mean: -64.429318\n",
      "ep 6: ep_len:500 episode reward: total was -12.780000. running mean: -63.912825\n",
      "ep 6: ep_len:500 episode reward: total was -41.500000. running mean: -63.688696\n",
      "ep 6: ep_len:1160 episode reward: total was -181.110000. running mean: -64.862909\n",
      "ep 6: ep_len:955 episode reward: total was -58.560000. running mean: -64.799880\n",
      "ep 6: ep_len:880 episode reward: total was -72.510000. running mean: -64.876981\n",
      "ep 6: ep_len:207 episode reward: total was 1.000000. running mean: -64.218212\n",
      "ep 6: ep_len:500 episode reward: total was -33.350000. running mean: -63.909529\n",
      "ep 6: ep_len:168 episode reward: total was 1.500000. running mean: -63.255434\n",
      "ep 6: ep_len:700 episode reward: total was -85.590000. running mean: -63.478780\n",
      "ep 6: ep_len:500 episode reward: total was -8.850000. running mean: -62.932492\n",
      "ep 6: ep_len:500 episode reward: total was -13.770000. running mean: -62.440867\n",
      "ep 6: ep_len:670 episode reward: total was -50.220000. running mean: -62.318658\n",
      "ep 6: ep_len:505 episode reward: total was -20.260000. running mean: -61.898072\n",
      "ep 6: ep_len:535 episode reward: total was -63.360000. running mean: -61.912691\n",
      "ep 6: ep_len:755 episode reward: total was -14.540000. running mean: -61.438964\n",
      "ep 6: ep_len:18045 episode reward: total was -3386.470000. running mean: -94.689275\n",
      "ep 6: ep_len:815 episode reward: total was -27.720000. running mean: -94.019582\n",
      "ep 6: ep_len:550 episode reward: total was -31.270000. running mean: -93.392086\n",
      "ep 6: ep_len:500 episode reward: total was -41.130000. running mean: -92.869465\n",
      "ep 6: ep_len:500 episode reward: total was -4.900000. running mean: -91.989771\n",
      "ep 6: ep_len:1095 episode reward: total was -155.420000. running mean: -92.624073\n",
      "ep 6: ep_len:695 episode reward: total was -71.380000. running mean: -92.411632\n",
      "ep 6: ep_len:980 episode reward: total was -162.200000. running mean: -93.109516\n",
      "ep 6: ep_len:560 episode reward: total was -34.770000. running mean: -92.526121\n",
      "ep 6: ep_len:720 episode reward: total was -62.240000. running mean: -92.223259\n",
      "ep 6: ep_len:910 episode reward: total was -88.640000. running mean: -92.187427\n",
      "ep 6: ep_len:500 episode reward: total was -5.870000. running mean: -91.324253\n",
      "ep 6: ep_len:500 episode reward: total was -31.170000. running mean: -90.722710\n",
      "ep 6: ep_len:500 episode reward: total was -32.810000. running mean: -90.143583\n",
      "ep 6: ep_len:500 episode reward: total was -16.410000. running mean: -89.406247\n",
      "ep 6: ep_len:925 episode reward: total was -47.760000. running mean: -88.989785\n",
      "ep 6: ep_len:1915 episode reward: total was -262.860000. running mean: -90.728487\n",
      "ep 6: ep_len:500 episode reward: total was -32.010000. running mean: -90.141302\n",
      "ep 6: ep_len:1255 episode reward: total was -228.310000. running mean: -91.522989\n",
      "ep 6: ep_len:505 episode reward: total was -20.820000. running mean: -90.815959\n",
      "ep 6: ep_len:890 episode reward: total was -34.210000. running mean: -90.249899\n",
      "ep 6: ep_len:620 episode reward: total was -31.790000. running mean: -89.665300\n",
      "ep 6: ep_len:173 episode reward: total was 5.000000. running mean: -88.718647\n",
      "ep 6: ep_len:750 episode reward: total was -47.120000. running mean: -88.302661\n",
      "ep 6: ep_len:605 episode reward: total was -42.760000. running mean: -87.847234\n",
      "ep 6: ep_len:500 episode reward: total was -22.570000. running mean: -87.194462\n",
      "ep 6: ep_len:1650 episode reward: total was -182.780000. running mean: -88.150317\n",
      "ep 6: ep_len:665 episode reward: total was -86.590000. running mean: -88.134714\n",
      "ep 6: ep_len:500 episode reward: total was -26.800000. running mean: -87.521367\n",
      "ep 6: ep_len:640 episode reward: total was -55.750000. running mean: -87.203653\n",
      "ep 6: ep_len:500 episode reward: total was -24.370000. running mean: -86.575317\n",
      "ep 6: ep_len:855 episode reward: total was -43.930000. running mean: -86.148864\n",
      "ep 6: ep_len:500 episode reward: total was -11.780000. running mean: -85.405175\n",
      "ep 6: ep_len:1915 episode reward: total was -169.520000. running mean: -86.246323\n",
      "ep 6: ep_len:500 episode reward: total was -52.690000. running mean: -85.910760\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 6: ep_len:500 episode reward: total was -15.370000. running mean: -85.205352\n",
      "ep 6: ep_len:505 episode reward: total was -48.190000. running mean: -84.835199\n",
      "ep 6: ep_len:645 episode reward: total was -43.200000. running mean: -84.418847\n",
      "ep 6: ep_len:510 episode reward: total was -3.360000. running mean: -83.608258\n",
      "ep 6: ep_len:890 episode reward: total was -135.630000. running mean: -84.128476\n",
      "ep 6: ep_len:750 episode reward: total was -108.240000. running mean: -84.369591\n",
      "ep 6: ep_len:685 episode reward: total was -57.120000. running mean: -84.097095\n",
      "ep 6: ep_len:974 episode reward: total was -82.800000. running mean: -84.084124\n",
      "ep 6: ep_len:920 episode reward: total was -37.800000. running mean: -83.621283\n",
      "ep 6: ep_len:705 episode reward: total was -58.470000. running mean: -83.369770\n",
      "ep 6: ep_len:500 episode reward: total was -44.800000. running mean: -82.984072\n",
      "ep 6: ep_len:500 episode reward: total was -13.210000. running mean: -82.286332\n",
      "ep 6: ep_len:5695 episode reward: total was -1009.120000. running mean: -91.554668\n",
      "ep 6: ep_len:510 episode reward: total was -20.450000. running mean: -90.843622\n",
      "ep 6: ep_len:505 episode reward: total was -37.040000. running mean: -90.305586\n",
      "ep 6: ep_len:865 episode reward: total was -90.200000. running mean: -90.304530\n",
      "ep 6: ep_len:500 episode reward: total was -24.510000. running mean: -89.646584\n",
      "ep 6: ep_len:515 episode reward: total was -55.060000. running mean: -89.300719\n",
      "ep 6: ep_len:745 episode reward: total was -54.110000. running mean: -88.948811\n",
      "ep 6: ep_len:685 episode reward: total was -22.000000. running mean: -88.279323\n",
      "ep 6: ep_len:505 episode reward: total was -45.560000. running mean: -87.852130\n",
      "ep 6: ep_len:1435 episode reward: total was -139.590000. running mean: -88.369509\n",
      "ep 6: ep_len:500 episode reward: total was -67.240000. running mean: -88.158214\n",
      "ep 6: ep_len:1025 episode reward: total was -66.770000. running mean: -87.944331\n",
      "ep 6: ep_len:840 episode reward: total was -91.290000. running mean: -87.977788\n",
      "ep 6: ep_len:820 episode reward: total was -61.760000. running mean: -87.715610\n",
      "ep 6: ep_len:755 episode reward: total was -69.210000. running mean: -87.530554\n",
      "ep 6: ep_len:770 episode reward: total was -44.980000. running mean: -87.105049\n",
      "ep 6: ep_len:945 episode reward: total was -92.150000. running mean: -87.155498\n",
      "ep 6: ep_len:500 episode reward: total was -30.800000. running mean: -86.591943\n",
      "ep 6: ep_len:515 episode reward: total was -40.950000. running mean: -86.135524\n",
      "ep 6: ep_len:500 episode reward: total was -46.060000. running mean: -85.734769\n",
      "ep 6: ep_len:500 episode reward: total was -12.800000. running mean: -85.005421\n",
      "ep 6: ep_len:1595 episode reward: total was -130.480000. running mean: -85.460167\n",
      "ep 6: ep_len:525 episode reward: total was -52.750000. running mean: -85.133065\n",
      "ep 6: ep_len:500 episode reward: total was -28.030000. running mean: -84.562034\n",
      "ep 6: ep_len:693 episode reward: total was -66.860000. running mean: -84.385014\n",
      "ep 6: ep_len:505 episode reward: total was 13.000000. running mean: -83.411164\n",
      "ep 6: ep_len:500 episode reward: total was -7.820000. running mean: -82.655252\n",
      "ep 6: ep_len:860 episode reward: total was -77.680000. running mean: -82.605500\n",
      "ep 6: ep_len:1785 episode reward: total was -123.840000. running mean: -83.017845\n",
      "ep 6: ep_len:540 episode reward: total was -54.000000. running mean: -82.727666\n",
      "ep 6: ep_len:505 episode reward: total was 12.210000. running mean: -81.778290\n",
      "ep 6: ep_len:500 episode reward: total was 23.500000. running mean: -80.725507\n",
      "ep 6: ep_len:212 episode reward: total was 10.500000. running mean: -79.813252\n",
      "ep 6: ep_len:695 episode reward: total was -12.970000. running mean: -79.144819\n",
      "ep 6: ep_len:940 episode reward: total was -42.050000. running mean: -78.773871\n",
      "ep 6: ep_len:520 episode reward: total was -48.500000. running mean: -78.471132\n",
      "ep 6: ep_len:520 episode reward: total was -40.420000. running mean: -78.090621\n",
      "ep 6: ep_len:1040 episode reward: total was -53.320000. running mean: -77.842915\n",
      "ep 6: ep_len:500 episode reward: total was -0.500000. running mean: -77.069485\n",
      "ep 6: ep_len:715 episode reward: total was -17.060000. running mean: -76.469391\n",
      "ep 6: ep_len:590 episode reward: total was -58.460000. running mean: -76.289297\n",
      "ep 6: ep_len:500 episode reward: total was -29.410000. running mean: -75.820504\n",
      "ep 6: ep_len:505 episode reward: total was -25.740000. running mean: -75.319699\n",
      "ep 6: ep_len:500 episode reward: total was -39.540000. running mean: -74.961902\n",
      "ep 6: ep_len:960 episode reward: total was -60.890000. running mean: -74.821183\n",
      "ep 6: ep_len:630 episode reward: total was -39.190000. running mean: -74.464871\n",
      "ep 6: ep_len:800 episode reward: total was -27.110000. running mean: -73.991322\n",
      "ep 6: ep_len:500 episode reward: total was -9.830000. running mean: -73.349709\n",
      "ep 6: ep_len:500 episode reward: total was -34.840000. running mean: -72.964612\n",
      "ep 6: ep_len:1005 episode reward: total was -41.770000. running mean: -72.652666\n",
      "ep 6: ep_len:695 episode reward: total was -37.040000. running mean: -72.296539\n",
      "ep 6: ep_len:620 episode reward: total was -31.220000. running mean: -71.885774\n",
      "ep 6: ep_len:500 episode reward: total was -38.440000. running mean: -71.551316\n",
      "ep 6: ep_len:500 episode reward: total was -16.750000. running mean: -71.003303\n",
      "ep 6: ep_len:650 episode reward: total was -46.710000. running mean: -70.760370\n",
      "ep 6: ep_len:500 episode reward: total was -22.580000. running mean: -70.278566\n",
      "ep 6: ep_len:500 episode reward: total was -11.360000. running mean: -69.689380\n",
      "ep 6: ep_len:505 episode reward: total was -18.090000. running mean: -69.173387\n",
      "ep 6: ep_len:500 episode reward: total was -26.310000. running mean: -68.744753\n",
      "ep 6: ep_len:720 episode reward: total was -49.110000. running mean: -68.548405\n",
      "ep 6: ep_len:975 episode reward: total was -40.760000. running mean: -68.270521\n",
      "ep 6: ep_len:1035 episode reward: total was -24.980000. running mean: -67.837616\n",
      "ep 6: ep_len:500 episode reward: total was -26.310000. running mean: -67.422340\n",
      "ep 6: ep_len:500 episode reward: total was -37.520000. running mean: -67.123316\n",
      "ep 6: ep_len:500 episode reward: total was -20.860000. running mean: -66.660683\n",
      "ep 6: ep_len:800 episode reward: total was -46.870000. running mean: -66.462776\n",
      "ep 6: ep_len:505 episode reward: total was -40.810000. running mean: -66.206249\n",
      "ep 6: ep_len:500 episode reward: total was -7.760000. running mean: -65.621786\n",
      "ep 6: ep_len:505 episode reward: total was -15.340000. running mean: -65.118968\n",
      "ep 6: ep_len:145 episode reward: total was -1.500000. running mean: -64.482779\n",
      "ep 6: ep_len:500 episode reward: total was -48.800000. running mean: -64.325951\n",
      "ep 6: ep_len:575 episode reward: total was -55.950000. running mean: -64.242191\n",
      "ep 6: ep_len:505 episode reward: total was -37.910000. running mean: -63.978869\n",
      "ep 6: ep_len:500 episode reward: total was -11.340000. running mean: -63.452481\n",
      "ep 6: ep_len:500 episode reward: total was -18.880000. running mean: -63.006756\n",
      "ep 6: ep_len:520 episode reward: total was -29.760000. running mean: -62.674288\n",
      "ep 6: ep_len:770 episode reward: total was -39.520000. running mean: -62.442745\n",
      "ep 6: ep_len:161 episode reward: total was 0.000000. running mean: -61.818318\n",
      "ep 6: ep_len:790 episode reward: total was -62.100000. running mean: -61.821135\n",
      "ep 6: ep_len:620 episode reward: total was -29.280000. running mean: -61.495723\n",
      "ep 6: ep_len:500 episode reward: total was -17.610000. running mean: -61.056866\n",
      "ep 6: ep_len:1490 episode reward: total was -229.860000. running mean: -62.744898\n",
      "ep 6: ep_len:500 episode reward: total was -20.800000. running mean: -62.325449\n",
      "ep 6: ep_len:610 episode reward: total was -48.320000. running mean: -62.185394\n",
      "ep 6: ep_len:930 episode reward: total was -28.040000. running mean: -61.843940\n",
      "ep 6: ep_len:790 episode reward: total was -41.900000. running mean: -61.644501\n",
      "ep 6: ep_len:500 episode reward: total was -37.490000. running mean: -61.402956\n",
      "ep 6: ep_len:630 episode reward: total was -54.340000. running mean: -61.332326\n",
      "ep 6: ep_len:565 episode reward: total was -36.290000. running mean: -61.081903\n",
      "ep 6: ep_len:610 episode reward: total was -22.880000. running mean: -60.699884\n",
      "ep 6: ep_len:505 episode reward: total was -32.140000. running mean: -60.414285\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 6: ep_len:670 episode reward: total was -16.560000. running mean: -59.975742\n",
      "ep 6: ep_len:555 episode reward: total was -57.520000. running mean: -59.951185\n",
      "ep 6: ep_len:500 episode reward: total was -18.880000. running mean: -59.540473\n",
      "ep 6: ep_len:515 episode reward: total was -14.660000. running mean: -59.091668\n",
      "ep 6: ep_len:930 episode reward: total was -40.100000. running mean: -58.901752\n",
      "ep 6: ep_len:835 episode reward: total was -62.820000. running mean: -58.940934\n",
      "ep 6: ep_len:500 episode reward: total was -34.250000. running mean: -58.694025\n",
      "ep 6: ep_len:660 episode reward: total was -42.650000. running mean: -58.533584\n",
      "ep 6: ep_len:735 episode reward: total was -51.100000. running mean: -58.459249\n",
      "ep 6: ep_len:695 episode reward: total was -57.730000. running mean: -58.451956\n",
      "ep 6: ep_len:665 episode reward: total was -54.270000. running mean: -58.410137\n",
      "ep 6: ep_len:1101 episode reward: total was -170.560000. running mean: -59.531635\n",
      "ep 6: ep_len:620 episode reward: total was -21.300000. running mean: -59.149319\n",
      "ep 6: ep_len:130 episode reward: total was 7.500000. running mean: -58.482826\n",
      "ep 6: ep_len:500 episode reward: total was -16.030000. running mean: -58.058297\n",
      "ep 6: ep_len:715 episode reward: total was -47.590000. running mean: -57.953614\n",
      "ep 6: ep_len:505 episode reward: total was -10.770000. running mean: -57.481778\n",
      "ep 6: ep_len:950 episode reward: total was -43.210000. running mean: -57.339060\n",
      "ep 6: ep_len:530 episode reward: total was -27.500000. running mean: -57.040670\n",
      "ep 6: ep_len:413 episode reward: total was -12.320000. running mean: -56.593463\n",
      "ep 6: ep_len:960 episode reward: total was -59.820000. running mean: -56.625729\n",
      "ep 6: ep_len:441 episode reward: total was -0.350000. running mean: -56.062971\n",
      "ep 6: ep_len:461 episode reward: total was -4.870000. running mean: -55.551042\n",
      "ep 6: ep_len:505 episode reward: total was -25.480000. running mean: -55.250331\n",
      "ep 6: ep_len:925 episode reward: total was -36.040000. running mean: -55.058228\n",
      "ep 6: ep_len:500 episode reward: total was -15.280000. running mean: -54.660446\n",
      "ep 6: ep_len:825 episode reward: total was -73.630000. running mean: -54.850141\n",
      "ep 6: ep_len:500 episode reward: total was -12.320000. running mean: -54.424840\n",
      "ep 6: ep_len:500 episode reward: total was -30.260000. running mean: -54.183191\n",
      "ep 6: ep_len:500 episode reward: total was -30.200000. running mean: -53.943359\n",
      "ep 6: ep_len:985 episode reward: total was -127.530000. running mean: -54.679226\n",
      "ep 6: ep_len:1665 episode reward: total was -105.080000. running mean: -55.183234\n",
      "ep 6: ep_len:505 episode reward: total was -0.830000. running mean: -54.639701\n",
      "ep 6: ep_len:510 episode reward: total was 12.500000. running mean: -53.968304\n",
      "ep 6: ep_len:755 episode reward: total was -53.080000. running mean: -53.959421\n",
      "ep 6: ep_len:500 episode reward: total was -20.620000. running mean: -53.626027\n",
      "ep 6: ep_len:500 episode reward: total was -24.280000. running mean: -53.332567\n",
      "ep 6: ep_len:915 episode reward: total was -42.790000. running mean: -53.227141\n",
      "ep 6: ep_len:500 episode reward: total was -36.790000. running mean: -53.062770\n",
      "ep 6: ep_len:178 episode reward: total was 5.500000. running mean: -52.477142\n",
      "ep 6: ep_len:202 episode reward: total was 3.500000. running mean: -51.917370\n",
      "ep 6: ep_len:880 episode reward: total was -59.900000. running mean: -51.997197\n",
      "ep 6: ep_len:605 episode reward: total was -41.230000. running mean: -51.889525\n",
      "ep 6: ep_len:505 episode reward: total was -57.190000. running mean: -51.942530\n",
      "ep 6: ep_len:600 episode reward: total was -107.410000. running mean: -52.497204\n",
      "ep 6: ep_len:500 episode reward: total was -62.680000. running mean: -52.599032\n",
      "ep 6: ep_len:500 episode reward: total was -30.930000. running mean: -52.382342\n",
      "ep 6: ep_len:955 episode reward: total was -155.300000. running mean: -53.411518\n",
      "ep 6: ep_len:500 episode reward: total was -1.730000. running mean: -52.894703\n",
      "ep 6: ep_len:935 episode reward: total was -80.110000. running mean: -53.166856\n",
      "ep 6: ep_len:500 episode reward: total was -23.470000. running mean: -52.869888\n",
      "ep 6: ep_len:995 episode reward: total was -161.310000. running mean: -53.954289\n",
      "ep 6: ep_len:500 episode reward: total was -15.190000. running mean: -53.566646\n",
      "ep 6: ep_len:500 episode reward: total was -14.730000. running mean: -53.178279\n",
      "ep 6: ep_len:500 episode reward: total was -28.420000. running mean: -52.930697\n",
      "ep 6: ep_len:1240 episode reward: total was -203.180000. running mean: -54.433190\n",
      "ep 6: ep_len:540 episode reward: total was -40.850000. running mean: -54.297358\n",
      "ep 6: ep_len:505 episode reward: total was -27.320000. running mean: -54.027584\n",
      "ep 6: ep_len:153 episode reward: total was 3.000000. running mean: -53.457308\n",
      "ep 6: ep_len:575 episode reward: total was -38.780000. running mean: -53.310535\n",
      "ep 6: ep_len:575 episode reward: total was -32.200000. running mean: -53.099430\n",
      "ep 6: ep_len:725 episode reward: total was -65.150000. running mean: -53.219936\n",
      "ep 6: ep_len:500 episode reward: total was 6.000000. running mean: -52.627736\n",
      "ep 6: ep_len:840 episode reward: total was -42.820000. running mean: -52.529659\n",
      "ep 6: ep_len:500 episode reward: total was 13.000000. running mean: -51.874362\n",
      "ep 6: ep_len:500 episode reward: total was -7.810000. running mean: -51.433719\n",
      "ep 6: ep_len:195 episode reward: total was -8.500000. running mean: -51.004382\n",
      "ep 6: ep_len:500 episode reward: total was -31.810000. running mean: -50.812438\n",
      "ep 6: ep_len:670 episode reward: total was -50.710000. running mean: -50.811413\n",
      "ep 6: ep_len:505 episode reward: total was -15.670000. running mean: -50.459999\n",
      "ep 6: ep_len:510 episode reward: total was -27.880000. running mean: -50.234199\n",
      "ep 6: ep_len:500 episode reward: total was -44.530000. running mean: -50.177157\n",
      "ep 6: ep_len:1170 episode reward: total was -181.010000. running mean: -51.485486\n",
      "ep 6: ep_len:750 episode reward: total was -41.570000. running mean: -51.386331\n",
      "ep 6: ep_len:540 episode reward: total was -30.280000. running mean: -51.175267\n",
      "ep 6: ep_len:570 episode reward: total was -37.260000. running mean: -51.036115\n",
      "ep 6: ep_len:180 episode reward: total was -1.500000. running mean: -50.540754\n",
      "ep 6: ep_len:228 episode reward: total was -24.000000. running mean: -50.275346\n",
      "ep 6: ep_len:164 episode reward: total was 9.000000. running mean: -49.682593\n",
      "ep 6: ep_len:670 episode reward: total was -50.280000. running mean: -49.688567\n",
      "ep 6: ep_len:1025 episode reward: total was -97.990000. running mean: -50.171581\n",
      "ep 6: ep_len:510 episode reward: total was -50.720000. running mean: -50.177065\n",
      "ep 6: ep_len:545 episode reward: total was -6.110000. running mean: -49.736395\n",
      "ep 6: ep_len:785 episode reward: total was -57.030000. running mean: -49.809331\n",
      "ep 6: ep_len:1025 episode reward: total was -98.380000. running mean: -50.295037\n",
      "ep 6: ep_len:1450 episode reward: total was -193.090000. running mean: -51.722987\n",
      "ep 6: ep_len:740 episode reward: total was -50.080000. running mean: -51.706557\n",
      "ep 6: ep_len:555 episode reward: total was -5.000000. running mean: -51.239492\n",
      "ep 6: ep_len:800 episode reward: total was -55.010000. running mean: -51.277197\n",
      "ep 6: ep_len:500 episode reward: total was -46.350000. running mean: -51.227925\n",
      "ep 6: ep_len:630 episode reward: total was -33.270000. running mean: -51.048345\n",
      "ep 6: ep_len:805 episode reward: total was -50.990000. running mean: -51.047762\n",
      "ep 6: ep_len:345 episode reward: total was 3.500000. running mean: -50.502284\n",
      "ep 6: ep_len:975 episode reward: total was -79.910000. running mean: -50.796361\n",
      "ep 6: ep_len:1080 episode reward: total was -155.770000. running mean: -51.846098\n",
      "ep 6: ep_len:500 episode reward: total was -55.700000. running mean: -51.884637\n",
      "ep 6: ep_len:505 episode reward: total was -18.430000. running mean: -51.550091\n",
      "ep 6: ep_len:148 episode reward: total was 7.000000. running mean: -50.964590\n",
      "ep 6: ep_len:500 episode reward: total was -25.120000. running mean: -50.706144\n",
      "ep 6: ep_len:710 episode reward: total was -56.690000. running mean: -50.765982\n",
      "ep 6: ep_len:500 episode reward: total was -16.830000. running mean: -50.426622\n",
      "ep 6: ep_len:520 episode reward: total was -32.090000. running mean: -50.243256\n",
      "ep 6: ep_len:680 episode reward: total was -32.410000. running mean: -50.064924\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 6: ep_len:209 episode reward: total was 6.000000. running mean: -49.504274\n",
      "ep 6: ep_len:316 episode reward: total was 9.500000. running mean: -48.914232\n",
      "ep 6: ep_len:500 episode reward: total was -32.650000. running mean: -48.751589\n",
      "ep 6: ep_len:595 episode reward: total was -31.670000. running mean: -48.580773\n",
      "ep 6: ep_len:500 episode reward: total was -19.970000. running mean: -48.294666\n",
      "ep 6: ep_len:525 episode reward: total was -75.760000. running mean: -48.569319\n",
      "ep 6: ep_len:500 episode reward: total was -17.830000. running mean: -48.261926\n",
      "ep 6: ep_len:500 episode reward: total was 15.500000. running mean: -47.624307\n",
      "ep 6: ep_len:500 episode reward: total was -37.950000. running mean: -47.527564\n",
      "ep 6: ep_len:605 episode reward: total was -67.000000. running mean: -47.722288\n",
      "ep 6: ep_len:412 episode reward: total was -10.770000. running mean: -47.352765\n",
      "ep 6: ep_len:830 episode reward: total was -57.980000. running mean: -47.459037\n",
      "ep 6: ep_len:500 episode reward: total was -17.340000. running mean: -47.157847\n",
      "ep 6: ep_len:560 episode reward: total was -45.390000. running mean: -47.140169\n",
      "ep 6: ep_len:500 episode reward: total was -44.010000. running mean: -47.108867\n",
      "ep 6: ep_len:1145 episode reward: total was -53.420000. running mean: -47.171978\n",
      "ep 6: ep_len:505 episode reward: total was -37.440000. running mean: -47.074658\n",
      "ep 6: ep_len:500 episode reward: total was -14.330000. running mean: -46.747212\n",
      "ep 6: ep_len:1065 episode reward: total was -132.560000. running mean: -47.605340\n",
      "ep 6: ep_len:1290 episode reward: total was -195.920000. running mean: -49.088486\n",
      "ep 6: ep_len:2654 episode reward: total was -425.190000. running mean: -52.849501\n",
      "ep 6: ep_len:1575 episode reward: total was -136.870000. running mean: -53.689706\n",
      "ep 6: ep_len:500 episode reward: total was -27.940000. running mean: -53.432209\n",
      "ep 6: ep_len:645 episode reward: total was -54.310000. running mean: -53.440987\n",
      "ep 6: ep_len:322 episode reward: total was 0.000000. running mean: -52.906577\n",
      "ep 6: ep_len:580 episode reward: total was -54.040000. running mean: -52.917912\n",
      "ep 6: ep_len:695 episode reward: total was -40.560000. running mean: -52.794333\n",
      "ep 6: ep_len:865 episode reward: total was -50.130000. running mean: -52.767689\n",
      "ep 6: ep_len:500 episode reward: total was -4.850000. running mean: -52.288512\n",
      "ep 6: ep_len:500 episode reward: total was -17.770000. running mean: -51.943327\n",
      "ep 6: ep_len:500 episode reward: total was -29.410000. running mean: -51.717994\n",
      "ep 6: ep_len:324 episode reward: total was -10.330000. running mean: -51.304114\n",
      "ep 6: ep_len:500 episode reward: total was -7.500000. running mean: -50.866073\n",
      "ep 6: ep_len:575 episode reward: total was -52.430000. running mean: -50.881712\n",
      "ep 6: ep_len:505 episode reward: total was -38.320000. running mean: -50.756095\n",
      "ep 6: ep_len:540 episode reward: total was -26.780000. running mean: -50.516334\n",
      "ep 6: ep_len:860 episode reward: total was -43.040000. running mean: -50.441571\n",
      "ep 6: ep_len:500 episode reward: total was -38.820000. running mean: -50.325355\n",
      "ep 6: ep_len:500 episode reward: total was -19.820000. running mean: -50.020301\n",
      "ep 6: ep_len:664 episode reward: total was -97.690000. running mean: -50.496998\n",
      "ep 6: ep_len:265 episode reward: total was 11.500000. running mean: -49.877028\n",
      "ep 6: ep_len:640 episode reward: total was -57.530000. running mean: -49.953558\n",
      "ep 6: ep_len:500 episode reward: total was -26.190000. running mean: -49.715923\n",
      "ep 6: ep_len:510 episode reward: total was -54.580000. running mean: -49.764563\n",
      "ep 6: ep_len:123 episode reward: total was 0.500000. running mean: -49.261918\n",
      "ep 6: ep_len:505 episode reward: total was -25.840000. running mean: -49.027699\n",
      "ep 6: ep_len:500 episode reward: total was -20.480000. running mean: -48.742222\n",
      "ep 6: ep_len:302 episode reward: total was 8.000000. running mean: -48.174799\n",
      "ep 6: ep_len:530 episode reward: total was -34.340000. running mean: -48.036451\n",
      "ep 6: ep_len:515 episode reward: total was -60.110000. running mean: -48.157187\n",
      "ep 6: ep_len:500 episode reward: total was -31.400000. running mean: -47.989615\n",
      "ep 6: ep_len:161 episode reward: total was 2.500000. running mean: -47.484719\n",
      "ep 6: ep_len:505 episode reward: total was -35.770000. running mean: -47.367572\n",
      "ep 6: ep_len:505 episode reward: total was -30.010000. running mean: -47.193996\n",
      "ep 6: ep_len:332 episode reward: total was -9.300000. running mean: -46.815056\n",
      "ep 6: ep_len:500 episode reward: total was -24.490000. running mean: -46.591805\n",
      "ep 6: ep_len:500 episode reward: total was -19.300000. running mean: -46.318887\n",
      "ep 6: ep_len:1295 episode reward: total was -128.940000. running mean: -47.145098\n",
      "ep 6: ep_len:750 episode reward: total was -12.460000. running mean: -46.798247\n",
      "ep 6: ep_len:770 episode reward: total was -58.530000. running mean: -46.915565\n",
      "ep 6: ep_len:1536 episode reward: total was -253.500000. running mean: -48.981409\n",
      "ep 6: ep_len:515 episode reward: total was -18.780000. running mean: -48.679395\n",
      "ep 6: ep_len:505 episode reward: total was -21.950000. running mean: -48.412101\n",
      "ep 6: ep_len:690 episode reward: total was -32.000000. running mean: -48.247980\n",
      "ep 6: ep_len:500 episode reward: total was -14.330000. running mean: -47.908800\n",
      "ep 6: ep_len:500 episode reward: total was -37.150000. running mean: -47.801212\n",
      "ep 6: ep_len:222 episode reward: total was 10.000000. running mean: -47.223200\n",
      "ep 6: ep_len:155 episode reward: total was 3.500000. running mean: -46.715968\n",
      "ep 6: ep_len:605 episode reward: total was -32.660000. running mean: -46.575409\n",
      "ep 6: ep_len:500 episode reward: total was -45.720000. running mean: -46.566855\n",
      "ep 6: ep_len:670 episode reward: total was -42.970000. running mean: -46.530886\n",
      "ep 6: ep_len:505 episode reward: total was -47.180000. running mean: -46.537377\n",
      "ep 6: ep_len:650 episode reward: total was -86.330000. running mean: -46.935303\n",
      "ep 6: ep_len:580 episode reward: total was -44.730000. running mean: -46.913250\n",
      "ep 6: ep_len:500 episode reward: total was -43.980000. running mean: -46.883918\n",
      "ep 6: ep_len:795 episode reward: total was -32.530000. running mean: -46.740379\n",
      "ep 6: ep_len:940 episode reward: total was -62.830000. running mean: -46.901275\n",
      "ep 6: ep_len:1785 episode reward: total was -145.140000. running mean: -47.883662\n",
      "ep 6: ep_len:500 episode reward: total was -89.470000. running mean: -48.299526\n",
      "ep 6: ep_len:745 episode reward: total was -67.850000. running mean: -48.495030\n",
      "ep 6: ep_len:685 episode reward: total was -57.260000. running mean: -48.582680\n",
      "ep 6: ep_len:500 episode reward: total was 8.000000. running mean: -48.016853\n",
      "ep 6: ep_len:1015 episode reward: total was -144.960000. running mean: -48.986285\n",
      "ep 6: ep_len:500 episode reward: total was -16.490000. running mean: -48.661322\n",
      "ep 6: ep_len:1370 episode reward: total was -135.680000. running mean: -49.531509\n",
      "ep 6: ep_len:159 episode reward: total was 2.000000. running mean: -49.016193\n",
      "ep 6: ep_len:500 episode reward: total was -21.830000. running mean: -48.744332\n",
      "ep 6: ep_len:925 episode reward: total was -82.030000. running mean: -49.077188\n",
      "ep 6: ep_len:900 episode reward: total was -50.450000. running mean: -49.090916\n",
      "ep 6: ep_len:500 episode reward: total was -10.300000. running mean: -48.703007\n",
      "ep 6: ep_len:500 episode reward: total was -26.340000. running mean: -48.479377\n",
      "ep 6: ep_len:180 episode reward: total was -1.000000. running mean: -48.004583\n",
      "ep 6: ep_len:795 episode reward: total was -59.060000. running mean: -48.115138\n",
      "ep 6: ep_len:196 episode reward: total was 6.000000. running mean: -47.573986\n",
      "ep 6: ep_len:555 episode reward: total was -29.810000. running mean: -47.396346\n",
      "ep 6: ep_len:1000 episode reward: total was -33.500000. running mean: -47.257383\n",
      "ep 6: ep_len:1285 episode reward: total was -138.880000. running mean: -48.173609\n",
      "ep 6: ep_len:500 episode reward: total was -4.860000. running mean: -47.740473\n",
      "ep 6: ep_len:870 episode reward: total was -93.220000. running mean: -48.195268\n",
      "ep 6: ep_len:500 episode reward: total was -8.740000. running mean: -47.800715\n",
      "ep 6: ep_len:199 episode reward: total was -5.500000. running mean: -47.377708\n",
      "ep 6: ep_len:1160 episode reward: total was -147.210000. running mean: -48.376031\n",
      "ep 6: ep_len:500 episode reward: total was -29.220000. running mean: -48.184471\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 6: ep_len:755 episode reward: total was -58.100000. running mean: -48.283626\n",
      "ep 6: ep_len:500 episode reward: total was -26.610000. running mean: -48.066890\n",
      "ep 6: ep_len:1715 episode reward: total was -222.860000. running mean: -49.814821\n",
      "ep 6: ep_len:233 episode reward: total was 14.000000. running mean: -49.176673\n",
      "ep 6: ep_len:520 episode reward: total was -48.500000. running mean: -49.169906\n",
      "ep 6: ep_len:755 episode reward: total was -90.430000. running mean: -49.582507\n",
      "ep 6: ep_len:555 episode reward: total was -7.220000. running mean: -49.158882\n",
      "ep 6: ep_len:489 episode reward: total was 7.000000. running mean: -48.597293\n",
      "ep 6: ep_len:715 episode reward: total was -22.030000. running mean: -48.331620\n",
      "ep 6: ep_len:1050 episode reward: total was -113.060000. running mean: -48.978904\n",
      "ep 6: ep_len:1440 episode reward: total was -189.040000. running mean: -50.379515\n",
      "ep 6: ep_len:505 episode reward: total was -4.820000. running mean: -49.923920\n",
      "ep 6: ep_len:500 episode reward: total was -13.580000. running mean: -49.560481\n",
      "ep 6: ep_len:1020 episode reward: total was -103.120000. running mean: -50.096076\n",
      "ep 6: ep_len:530 episode reward: total was -41.380000. running mean: -50.008915\n",
      "ep 6: ep_len:1045 episode reward: total was -62.080000. running mean: -50.129626\n",
      "ep 6: ep_len:660 episode reward: total was -79.530000. running mean: -50.423630\n",
      "ep 6: ep_len:500 episode reward: total was -37.200000. running mean: -50.291393\n",
      "ep 6: ep_len:505 episode reward: total was -22.720000. running mean: -50.015679\n",
      "ep 6: ep_len:727 episode reward: total was -59.020000. running mean: -50.105723\n",
      "ep 6: ep_len:182 episode reward: total was 8.000000. running mean: -49.524665\n",
      "ep 6: ep_len:805 episode reward: total was -51.940000. running mean: -49.548819\n",
      "ep 6: ep_len:635 episode reward: total was -72.480000. running mean: -49.778131\n",
      "ep 6: ep_len:252 episode reward: total was 4.000000. running mean: -49.240349\n",
      "ep 6: ep_len:500 episode reward: total was -44.470000. running mean: -49.192646\n",
      "ep 6: ep_len:500 episode reward: total was -39.200000. running mean: -49.092719\n",
      "ep 6: ep_len:1145 episode reward: total was -48.400000. running mean: -49.085792\n",
      "ep 6: ep_len:745 episode reward: total was -41.960000. running mean: -49.014534\n",
      "ep 6: ep_len:500 episode reward: total was -50.620000. running mean: -49.030589\n",
      "ep 6: ep_len:1045 episode reward: total was -68.170000. running mean: -49.221983\n",
      "ep 6: ep_len:900 episode reward: total was -96.220000. running mean: -49.691963\n",
      "ep 6: ep_len:890 episode reward: total was -48.540000. running mean: -49.680444\n",
      "ep 6: ep_len:479 episode reward: total was 0.200000. running mean: -49.181639\n",
      "ep 6: ep_len:530 episode reward: total was -50.470000. running mean: -49.194523\n",
      "ep 6: ep_len:10 episode reward: total was -2.000000. running mean: -48.722577\n",
      "ep 6: ep_len:540 episode reward: total was -25.720000. running mean: -48.492552\n",
      "ep 6: ep_len:585 episode reward: total was -22.130000. running mean: -48.228926\n",
      "ep 6: ep_len:680 episode reward: total was -46.650000. running mean: -48.213137\n",
      "ep 6: ep_len:560 episode reward: total was -28.890000. running mean: -48.019906\n",
      "ep 6: ep_len:515 episode reward: total was -39.370000. running mean: -47.933406\n",
      "ep 6: ep_len:885 episode reward: total was -59.760000. running mean: -48.051672\n",
      "ep 6: ep_len:590 episode reward: total was -47.350000. running mean: -48.044656\n",
      "ep 6: ep_len:500 episode reward: total was -27.280000. running mean: -47.837009\n",
      "ep 6: ep_len:690 episode reward: total was -45.100000. running mean: -47.809639\n",
      "ep 6: ep_len:760 episode reward: total was -28.910000. running mean: -47.620643\n",
      "ep 6: ep_len:505 episode reward: total was -41.520000. running mean: -47.559636\n",
      "ep 6: ep_len:795 episode reward: total was -40.600000. running mean: -47.490040\n",
      "ep 6: ep_len:585 episode reward: total was -63.650000. running mean: -47.651639\n",
      "ep 6: ep_len:950 episode reward: total was -48.360000. running mean: -47.658723\n",
      "ep 6: ep_len:515 episode reward: total was -11.240000. running mean: -47.294536\n",
      "ep 6: ep_len:500 episode reward: total was -23.830000. running mean: -47.059890\n",
      "ep 6: ep_len:690 episode reward: total was -39.800000. running mean: -46.987292\n",
      "ep 6: ep_len:243 episode reward: total was 6.000000. running mean: -46.457419\n",
      "ep 6: ep_len:364 episode reward: total was -9.360000. running mean: -46.086444\n",
      "ep 6: ep_len:500 episode reward: total was -22.270000. running mean: -45.848280\n",
      "ep 6: ep_len:560 episode reward: total was -20.590000. running mean: -45.595697\n",
      "ep 6: ep_len:515 episode reward: total was -30.330000. running mean: -45.443040\n",
      "ep 6: ep_len:900 episode reward: total was -66.930000. running mean: -45.657910\n",
      "ep 6: ep_len:500 episode reward: total was -64.490000. running mean: -45.846231\n",
      "ep 6: ep_len:1180 episode reward: total was -192.740000. running mean: -47.315168\n",
      "ep 6: ep_len:500 episode reward: total was -39.480000. running mean: -47.236817\n",
      "ep 6: ep_len:950 episode reward: total was -51.190000. running mean: -47.276349\n",
      "ep 6: ep_len:510 episode reward: total was -20.090000. running mean: -47.004485\n",
      "ep 6: ep_len:500 episode reward: total was -14.980000. running mean: -46.684240\n",
      "ep 6: ep_len:515 episode reward: total was -44.500000. running mean: -46.662398\n",
      "ep 6: ep_len:780 episode reward: total was -39.050000. running mean: -46.586274\n",
      "ep 6: ep_len:500 episode reward: total was -29.350000. running mean: -46.413911\n",
      "ep 6: ep_len:675 episode reward: total was -38.330000. running mean: -46.333072\n",
      "ep 6: ep_len:500 episode reward: total was -48.110000. running mean: -46.350841\n",
      "ep 6: ep_len:500 episode reward: total was -37.980000. running mean: -46.267133\n",
      "ep 6: ep_len:745 episode reward: total was -45.510000. running mean: -46.259562\n",
      "ep 6: ep_len:590 episode reward: total was -22.220000. running mean: -46.019166\n",
      "ep 6: ep_len:500 episode reward: total was -49.580000. running mean: -46.054774\n",
      "ep 6: ep_len:775 episode reward: total was -91.390000. running mean: -46.508127\n",
      "ep 6: ep_len:1225 episode reward: total was -155.220000. running mean: -47.595245\n",
      "ep 6: ep_len:605 episode reward: total was -38.720000. running mean: -47.506493\n",
      "ep 6: ep_len:890 episode reward: total was -14.020000. running mean: -47.171628\n",
      "ep 6: ep_len:500 episode reward: total was -22.470000. running mean: -46.924612\n",
      "ep 6: ep_len:500 episode reward: total was -44.100000. running mean: -46.896366\n",
      "ep 6: ep_len:500 episode reward: total was -21.440000. running mean: -46.641802\n",
      "ep 6: ep_len:1055 episode reward: total was -22.500000. running mean: -46.400384\n",
      "ep 6: ep_len:1200 episode reward: total was -108.230000. running mean: -47.018680\n",
      "ep 6: ep_len:525 episode reward: total was -35.360000. running mean: -46.902093\n",
      "ep 6: ep_len:555 episode reward: total was -11.740000. running mean: -46.550472\n",
      "ep 6: ep_len:925 episode reward: total was -117.350000. running mean: -47.258468\n",
      "ep 6: ep_len:625 episode reward: total was -35.160000. running mean: -47.137483\n",
      "ep 6: ep_len:500 episode reward: total was -8.590000. running mean: -46.752008\n",
      "ep 6: ep_len:830 episode reward: total was -63.520000. running mean: -46.919688\n",
      "ep 6: ep_len:635 episode reward: total was -33.090000. running mean: -46.781391\n",
      "ep 6: ep_len:585 episode reward: total was -97.340000. running mean: -47.286977\n",
      "ep 6: ep_len:520 episode reward: total was -38.400000. running mean: -47.198107\n",
      "ep 6: ep_len:500 episode reward: total was -20.270000. running mean: -46.928826\n",
      "ep 6: ep_len:880 episode reward: total was -60.910000. running mean: -47.068638\n",
      "ep 6: ep_len:194 episode reward: total was 2.500000. running mean: -46.572952\n",
      "ep 6: ep_len:905 episode reward: total was -27.200000. running mean: -46.379222\n",
      "ep 6: ep_len:500 episode reward: total was -15.470000. running mean: -46.070130\n",
      "ep 6: ep_len:910 episode reward: total was -67.920000. running mean: -46.288629\n",
      "ep 6: ep_len:1090 episode reward: total was -111.970000. running mean: -46.945442\n",
      "ep 6: ep_len:570 episode reward: total was -46.350000. running mean: -46.939488\n",
      "ep 6: ep_len:500 episode reward: total was -43.960000. running mean: -46.909693\n",
      "ep 6: ep_len:550 episode reward: total was -31.270000. running mean: -46.753296\n",
      "ep 6: ep_len:500 episode reward: total was -47.160000. running mean: -46.757363\n",
      "ep 6: ep_len:690 episode reward: total was -41.580000. running mean: -46.705590\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 6: ep_len:640 episode reward: total was -32.940000. running mean: -46.567934\n",
      "ep 6: ep_len:685 episode reward: total was -32.150000. running mean: -46.423754\n",
      "ep 6: ep_len:500 episode reward: total was -49.120000. running mean: -46.450717\n",
      "ep 6: ep_len:500 episode reward: total was -43.060000. running mean: -46.416810\n",
      "ep 6: ep_len:750 episode reward: total was -42.960000. running mean: -46.382241\n",
      "ep 6: ep_len:795 episode reward: total was -90.370000. running mean: -46.822119\n",
      "ep 6: ep_len:820 episode reward: total was -29.330000. running mean: -46.647198\n",
      "ep 6: ep_len:500 episode reward: total was -17.130000. running mean: -46.352026\n",
      "ep 6: ep_len:500 episode reward: total was -19.970000. running mean: -46.088206\n",
      "ep 6: ep_len:1510 episode reward: total was -163.340000. running mean: -47.260724\n",
      "ep 6: ep_len:500 episode reward: total was -32.230000. running mean: -47.110416\n",
      "ep 6: ep_len:1420 episode reward: total was -164.870000. running mean: -48.288012\n",
      "ep 6: ep_len:1075 episode reward: total was -77.930000. running mean: -48.584432\n",
      "ep 6: ep_len:500 episode reward: total was -40.320000. running mean: -48.501788\n",
      "ep 6: ep_len:515 episode reward: total was -58.610000. running mean: -48.602870\n",
      "ep 6: ep_len:725 episode reward: total was -40.010000. running mean: -48.516941\n",
      "ep 6: ep_len:505 episode reward: total was -32.930000. running mean: -48.361072\n",
      "ep 6: ep_len:346 episode reward: total was -32.330000. running mean: -48.200761\n",
      "ep 6: ep_len:625 episode reward: total was -41.220000. running mean: -48.130953\n",
      "ep 6: ep_len:500 episode reward: total was -9.780000. running mean: -47.747444\n",
      "ep 6: ep_len:500 episode reward: total was -45.570000. running mean: -47.725669\n",
      "ep 6: ep_len:500 episode reward: total was -29.200000. running mean: -47.540413\n",
      "ep 6: ep_len:500 episode reward: total was -26.300000. running mean: -47.328009\n",
      "ep 6: ep_len:555 episode reward: total was -7.750000. running mean: -46.932229\n",
      "ep 6: ep_len:500 episode reward: total was -35.960000. running mean: -46.822506\n",
      "ep 6: ep_len:500 episode reward: total was -21.880000. running mean: -46.573081\n",
      "ep 6: ep_len:640 episode reward: total was -69.960000. running mean: -46.806950\n",
      "ep 6: ep_len:890 episode reward: total was -121.730000. running mean: -47.556181\n",
      "ep 6: ep_len:190 episode reward: total was 1.000000. running mean: -47.070619\n",
      "ep 6: ep_len:535 episode reward: total was -55.340000. running mean: -47.153313\n",
      "ep 6: ep_len:500 episode reward: total was -23.560000. running mean: -46.917380\n",
      "ep 6: ep_len:1215 episode reward: total was -156.830000. running mean: -48.016506\n",
      "ep 6: ep_len:765 episode reward: total was -60.620000. running mean: -48.142541\n",
      "ep 6: ep_len:492 episode reward: total was -3.360000. running mean: -47.694715\n",
      "ep 6: ep_len:810 episode reward: total was -54.990000. running mean: -47.767668\n",
      "ep 6: ep_len:755 episode reward: total was -55.270000. running mean: -47.842692\n",
      "ep 6: ep_len:500 episode reward: total was -20.420000. running mean: -47.568465\n",
      "ep 6: ep_len:505 episode reward: total was -20.460000. running mean: -47.297380\n",
      "ep 6: ep_len:154 episode reward: total was 0.500000. running mean: -46.819406\n",
      "ep 6: ep_len:500 episode reward: total was -12.380000. running mean: -46.475012\n",
      "ep 6: ep_len:141 episode reward: total was 7.000000. running mean: -45.940262\n",
      "ep 6: ep_len:163 episode reward: total was 3.500000. running mean: -45.445859\n",
      "ep 6: ep_len:500 episode reward: total was -34.640000. running mean: -45.337801\n",
      "ep 6: ep_len:690 episode reward: total was -28.050000. running mean: -45.164923\n",
      "ep 6: ep_len:500 episode reward: total was -11.890000. running mean: -44.832174\n",
      "ep 6: ep_len:185 episode reward: total was 8.000000. running mean: -44.303852\n",
      "ep 6: ep_len:500 episode reward: total was -24.290000. running mean: -44.103713\n",
      "ep 6: ep_len:845 episode reward: total was -65.870000. running mean: -44.321376\n",
      "ep 6: ep_len:500 episode reward: total was -28.110000. running mean: -44.159263\n",
      "ep 6: ep_len:990 episode reward: total was -42.430000. running mean: -44.141970\n",
      "ep 6: ep_len:500 episode reward: total was -1.850000. running mean: -43.719050\n",
      "ep 6: ep_len:555 episode reward: total was -51.950000. running mean: -43.801360\n",
      "ep 6: ep_len:226 episode reward: total was 3.000000. running mean: -43.333346\n",
      "ep 6: ep_len:169 episode reward: total was 4.500000. running mean: -42.855013\n",
      "ep 6: ep_len:540 episode reward: total was -21.640000. running mean: -42.642862\n",
      "ep 6: ep_len:505 episode reward: total was -52.570000. running mean: -42.742134\n",
      "ep 6: ep_len:860 episode reward: total was -84.670000. running mean: -43.161413\n",
      "ep 6: ep_len:1005 episode reward: total was -42.440000. running mean: -43.154198\n",
      "ep 6: ep_len:560 episode reward: total was -34.280000. running mean: -43.065456\n",
      "ep 6: ep_len:500 episode reward: total was -14.810000. running mean: -42.782902\n",
      "ep 6: ep_len:500 episode reward: total was -28.360000. running mean: -42.638673\n",
      "ep 6: ep_len:505 episode reward: total was -63.190000. running mean: -42.844186\n",
      "ep 6: ep_len:530 episode reward: total was -32.630000. running mean: -42.742044\n",
      "ep 6: ep_len:500 episode reward: total was -40.820000. running mean: -42.722824\n",
      "ep 6: ep_len:1275 episode reward: total was -184.950000. running mean: -44.145096\n",
      "ep 6: ep_len:505 episode reward: total was -32.000000. running mean: -44.023645\n",
      "ep 6: ep_len:1885 episode reward: total was -358.840000. running mean: -47.171808\n",
      "ep 6: ep_len:500 episode reward: total was -29.280000. running mean: -46.992890\n",
      "ep 6: ep_len:555 episode reward: total was -30.270000. running mean: -46.825661\n",
      "ep 6: ep_len:790 episode reward: total was -44.050000. running mean: -46.797905\n",
      "ep 6: ep_len:600 episode reward: total was -34.200000. running mean: -46.671926\n",
      "ep 6: ep_len:510 episode reward: total was -31.530000. running mean: -46.520506\n",
      "ep 6: ep_len:510 episode reward: total was -27.980000. running mean: -46.335101\n",
      "ep 6: ep_len:505 episode reward: total was -37.870000. running mean: -46.250450\n",
      "ep 6: ep_len:675 episode reward: total was -5.600000. running mean: -45.843946\n",
      "ep 6: ep_len:850 episode reward: total was -36.300000. running mean: -45.748506\n",
      "ep 6: ep_len:505 episode reward: total was -10.860000. running mean: -45.399621\n",
      "ep 6: ep_len:650 episode reward: total was -41.220000. running mean: -45.357825\n",
      "ep 6: ep_len:500 episode reward: total was -34.730000. running mean: -45.251547\n",
      "ep 6: ep_len:590 episode reward: total was -46.830000. running mean: -45.267331\n",
      "ep 6: ep_len:505 episode reward: total was -39.040000. running mean: -45.205058\n",
      "ep 6: ep_len:1035 episode reward: total was -130.840000. running mean: -46.061407\n",
      "ep 6: ep_len:985 episode reward: total was -37.590000. running mean: -45.976693\n",
      "ep 6: ep_len:615 episode reward: total was -69.520000. running mean: -46.212126\n",
      "ep 6: ep_len:500 episode reward: total was -0.350000. running mean: -45.753505\n",
      "ep 6: ep_len:858 episode reward: total was -132.130000. running mean: -46.617270\n",
      "ep 6: ep_len:500 episode reward: total was -9.560000. running mean: -46.246697\n",
      "ep 6: ep_len:575 episode reward: total was -74.650000. running mean: -46.530730\n",
      "ep 6: ep_len:740 episode reward: total was -38.070000. running mean: -46.446123\n",
      "ep 6: ep_len:500 episode reward: total was -12.320000. running mean: -46.104862\n",
      "ep 6: ep_len:500 episode reward: total was 15.000000. running mean: -45.493813\n",
      "ep 6: ep_len:500 episode reward: total was -16.860000. running mean: -45.207475\n",
      "ep 6: ep_len:780 episode reward: total was -66.650000. running mean: -45.421900\n",
      "ep 6: ep_len:127 episode reward: total was 0.500000. running mean: -44.962681\n",
      "ep 6: ep_len:860 episode reward: total was -75.500000. running mean: -45.268055\n",
      "ep 6: ep_len:665 episode reward: total was -58.310000. running mean: -45.398474\n",
      "ep 6: ep_len:770 episode reward: total was -54.550000. running mean: -45.489989\n",
      "ep 6: ep_len:500 episode reward: total was -28.400000. running mean: -45.319089\n",
      "ep 6: ep_len:625 episode reward: total was -28.800000. running mean: -45.153898\n",
      "ep 6: ep_len:159 episode reward: total was 5.000000. running mean: -44.652359\n",
      "ep 6: ep_len:152 episode reward: total was 2.500000. running mean: -44.180836\n",
      "ep 6: ep_len:535 episode reward: total was -38.400000. running mean: -44.123027\n",
      "ep 6: ep_len:515 episode reward: total was -32.350000. running mean: -44.005297\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 6: ep_len:565 episode reward: total was -23.180000. running mean: -43.797044\n",
      "ep 6: ep_len:500 episode reward: total was -13.410000. running mean: -43.493174\n",
      "ep 6: ep_len:545 episode reward: total was -16.000000. running mean: -43.218242\n",
      "ep 6: ep_len:850 episode reward: total was -60.450000. running mean: -43.390560\n",
      "ep 6: ep_len:600 episode reward: total was -62.970000. running mean: -43.586354\n",
      "ep 6: ep_len:715 episode reward: total was -43.550000. running mean: -43.585991\n",
      "ep 6: ep_len:555 episode reward: total was -30.740000. running mean: -43.457531\n",
      "ep 6: ep_len:221 episode reward: total was 12.000000. running mean: -42.902955\n",
      "ep 6: ep_len:291 episode reward: total was 15.000000. running mean: -42.323926\n",
      "ep 6: ep_len:550 episode reward: total was -70.320000. running mean: -42.603886\n",
      "ep 6: ep_len:505 episode reward: total was 13.500000. running mean: -42.042848\n",
      "ep 6: ep_len:500 episode reward: total was -27.770000. running mean: -41.900119\n",
      "ep 6: ep_len:500 episode reward: total was -18.780000. running mean: -41.668918\n",
      "ep 6: ep_len:500 episode reward: total was -27.470000. running mean: -41.526929\n",
      "ep 6: ep_len:500 episode reward: total was -31.760000. running mean: -41.429259\n",
      "ep 6: ep_len:545 episode reward: total was -17.290000. running mean: -41.187867\n",
      "ep 6: ep_len:915 episode reward: total was -130.820000. running mean: -42.084188\n",
      "ep 6: ep_len:1325 episode reward: total was -123.650000. running mean: -42.899846\n",
      "ep 6: ep_len:555 episode reward: total was -45.400000. running mean: -42.924848\n",
      "ep 6: ep_len:575 episode reward: total was -47.350000. running mean: -42.969099\n",
      "ep 6: ep_len:505 episode reward: total was -25.440000. running mean: -42.793808\n",
      "ep 6: ep_len:785 episode reward: total was -69.150000. running mean: -43.057370\n",
      "ep 6: ep_len:500 episode reward: total was -32.340000. running mean: -42.950197\n",
      "ep 6: ep_len:850 episode reward: total was -73.550000. running mean: -43.256195\n",
      "ep 6: ep_len:500 episode reward: total was -36.630000. running mean: -43.189933\n",
      "ep 6: ep_len:500 episode reward: total was -11.580000. running mean: -42.873833\n",
      "ep 6: ep_len:500 episode reward: total was -5.280000. running mean: -42.497895\n",
      "ep 6: ep_len:1070 episode reward: total was -29.790000. running mean: -42.370816\n",
      "ep 6: ep_len:785 episode reward: total was -53.050000. running mean: -42.477608\n",
      "ep 6: ep_len:625 episode reward: total was -61.390000. running mean: -42.666732\n",
      "ep 6: ep_len:805 episode reward: total was -50.960000. running mean: -42.749665\n",
      "ep 6: ep_len:500 episode reward: total was -37.580000. running mean: -42.697968\n",
      "ep 6: ep_len:580 episode reward: total was -27.310000. running mean: -42.544088\n",
      "ep 6: ep_len:550 episode reward: total was -47.400000. running mean: -42.592647\n",
      "ep 6: ep_len:500 episode reward: total was -25.330000. running mean: -42.420021\n",
      "ep 6: ep_len:1115 episode reward: total was -40.740000. running mean: -42.403221\n",
      "ep 6: ep_len:945 episode reward: total was -84.010000. running mean: -42.819288\n",
      "ep 6: ep_len:500 episode reward: total was -10.850000. running mean: -42.499596\n",
      "ep 6: ep_len:510 episode reward: total was -47.710000. running mean: -42.551700\n",
      "ep 6: ep_len:500 episode reward: total was -36.560000. running mean: -42.491783\n",
      "ep 6: ep_len:555 episode reward: total was -89.840000. running mean: -42.965265\n",
      "ep 6: ep_len:484 episode reward: total was -11.920000. running mean: -42.654812\n",
      "ep 6: ep_len:500 episode reward: total was -8.760000. running mean: -42.315864\n",
      "ep 6: ep_len:500 episode reward: total was -48.770000. running mean: -42.380405\n",
      "ep 6: ep_len:800 episode reward: total was -38.850000. running mean: -42.345101\n",
      "ep 6: ep_len:705 episode reward: total was -61.230000. running mean: -42.533950\n",
      "ep 6: ep_len:500 episode reward: total was -40.230000. running mean: -42.510911\n",
      "ep 6: ep_len:745 episode reward: total was -43.640000. running mean: -42.522202\n",
      "ep 6: ep_len:505 episode reward: total was -13.870000. running mean: -42.235680\n",
      "ep 6: ep_len:500 episode reward: total was -9.290000. running mean: -41.906223\n",
      "ep 6: ep_len:500 episode reward: total was -30.940000. running mean: -41.796561\n",
      "ep 6: ep_len:725 episode reward: total was -42.520000. running mean: -41.803795\n",
      "ep 6: ep_len:218 episode reward: total was 8.000000. running mean: -41.305757\n",
      "ep 6: ep_len:865 episode reward: total was -38.340000. running mean: -41.276100\n",
      "ep 6: ep_len:500 episode reward: total was -2.370000. running mean: -40.887039\n",
      "ep 6: ep_len:505 episode reward: total was -22.840000. running mean: -40.706568\n",
      "ep 6: ep_len:500 episode reward: total was -7.760000. running mean: -40.377102\n",
      "ep 6: ep_len:171 episode reward: total was 0.500000. running mean: -39.968331\n",
      "ep 6: ep_len:1355 episode reward: total was -203.380000. running mean: -41.602448\n",
      "ep 6: ep_len:500 episode reward: total was -8.310000. running mean: -41.269524\n",
      "ep 6: ep_len:500 episode reward: total was -43.090000. running mean: -41.287728\n",
      "ep 6: ep_len:585 episode reward: total was -47.100000. running mean: -41.345851\n",
      "ep 6: ep_len:730 episode reward: total was -41.860000. running mean: -41.350993\n",
      "ep 6: ep_len:500 episode reward: total was 3.000000. running mean: -40.907483\n",
      "ep 6: ep_len:500 episode reward: total was -29.930000. running mean: -40.797708\n",
      "ep 6: ep_len:695 episode reward: total was -39.060000. running mean: -40.780331\n",
      "ep 6: ep_len:355 episode reward: total was 16.000000. running mean: -40.212527\n",
      "ep 6: ep_len:169 episode reward: total was 9.500000. running mean: -39.715402\n",
      "ep 6: ep_len:635 episode reward: total was -46.250000. running mean: -39.780748\n",
      "ep 6: ep_len:525 episode reward: total was -43.410000. running mean: -39.817041\n",
      "ep 6: ep_len:505 episode reward: total was -26.440000. running mean: -39.683270\n",
      "ep 6: ep_len:505 episode reward: total was -39.550000. running mean: -39.681938\n",
      "ep 6: ep_len:695 episode reward: total was -48.150000. running mean: -39.766618\n",
      "ep 6: ep_len:505 episode reward: total was -9.310000. running mean: -39.462052\n",
      "ep 6: ep_len:770 episode reward: total was -55.040000. running mean: -39.617832\n",
      "ep 6: ep_len:510 episode reward: total was -19.650000. running mean: -39.418153\n",
      "ep 6: ep_len:515 episode reward: total was -38.180000. running mean: -39.405772\n",
      "ep 6: ep_len:500 episode reward: total was -57.780000. running mean: -39.589514\n",
      "ep 6: ep_len:500 episode reward: total was -7.270000. running mean: -39.266319\n",
      "ep 6: ep_len:650 episode reward: total was -44.200000. running mean: -39.315656\n",
      "ep 6: ep_len:500 episode reward: total was -12.750000. running mean: -39.049999\n",
      "ep 6: ep_len:4345 episode reward: total was -758.440000. running mean: -46.243899\n",
      "ep 6: ep_len:510 episode reward: total was -37.410000. running mean: -46.155560\n",
      "ep 6: ep_len:158 episode reward: total was 0.500000. running mean: -45.689004\n",
      "ep 6: ep_len:358 episode reward: total was -13.900000. running mean: -45.371114\n",
      "ep 6: ep_len:625 episode reward: total was -44.740000. running mean: -45.364803\n",
      "ep 6: ep_len:306 episode reward: total was -0.500000. running mean: -44.916155\n",
      "ep 6: ep_len:860 episode reward: total was -81.640000. running mean: -45.283394\n",
      "ep 6: ep_len:500 episode reward: total was -5.000000. running mean: -44.880560\n",
      "ep 6: ep_len:282 episode reward: total was 10.000000. running mean: -44.331754\n",
      "ep 6: ep_len:695 episode reward: total was -29.940000. running mean: -44.187837\n",
      "ep 6: ep_len:500 episode reward: total was -15.710000. running mean: -43.903058\n",
      "ep 6: ep_len:218 episode reward: total was 1.000000. running mean: -43.454028\n",
      "ep 6: ep_len:755 episode reward: total was -45.800000. running mean: -43.477487\n",
      "ep 6: ep_len:500 episode reward: total was -17.300000. running mean: -43.215713\n",
      "ep 6: ep_len:505 episode reward: total was -20.980000. running mean: -42.993355\n",
      "ep 6: ep_len:755 episode reward: total was -40.010000. running mean: -42.963522\n",
      "ep 6: ep_len:750 episode reward: total was -21.490000. running mean: -42.748787\n",
      "ep 6: ep_len:545 episode reward: total was -49.210000. running mean: -42.813399\n",
      "ep 6: ep_len:500 episode reward: total was -4.240000. running mean: -42.427665\n",
      "ep 6: ep_len:1175 episode reward: total was -119.010000. running mean: -43.193488\n",
      "ep 6: ep_len:575 episode reward: total was -48.360000. running mean: -43.245153\n",
      "ep 6: ep_len:505 episode reward: total was -19.900000. running mean: -43.011702\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 6: ep_len:500 episode reward: total was 2.190000. running mean: -42.559685\n",
      "ep 6: ep_len:1165 episode reward: total was -112.860000. running mean: -43.262688\n",
      "ep 6: ep_len:500 episode reward: total was -13.250000. running mean: -42.962561\n",
      "ep 6: ep_len:500 episode reward: total was -20.250000. running mean: -42.735435\n",
      "ep 6: ep_len:418 episode reward: total was 8.500000. running mean: -42.223081\n",
      "ep 6: ep_len:505 episode reward: total was -4.770000. running mean: -41.848550\n",
      "ep 6: ep_len:500 episode reward: total was -10.350000. running mean: -41.533565\n",
      "ep 6: ep_len:505 episode reward: total was -47.840000. running mean: -41.596629\n",
      "ep 6: ep_len:560 episode reward: total was -50.930000. running mean: -41.689963\n",
      "ep 6: ep_len:500 episode reward: total was -13.640000. running mean: -41.409463\n",
      "ep 6: ep_len:705 episode reward: total was -72.450000. running mean: -41.719868\n",
      "ep 6: ep_len:500 episode reward: total was -36.940000. running mean: -41.672070\n",
      "ep 6: ep_len:505 episode reward: total was -55.140000. running mean: -41.806749\n",
      "ep 6: ep_len:500 episode reward: total was -38.980000. running mean: -41.778482\n",
      "ep 6: ep_len:500 episode reward: total was -9.570000. running mean: -41.456397\n",
      "ep 6: ep_len:965 episode reward: total was -77.050000. running mean: -41.812333\n",
      "ep 6: ep_len:670 episode reward: total was -79.590000. running mean: -42.190110\n",
      "ep 6: ep_len:515 episode reward: total was -30.930000. running mean: -42.077508\n",
      "ep 6: ep_len:665 episode reward: total was -46.680000. running mean: -42.123533\n",
      "ep 6: ep_len:950 episode reward: total was -51.570000. running mean: -42.217998\n",
      "ep 6: ep_len:790 episode reward: total was -27.870000. running mean: -42.074518\n",
      "ep 6: ep_len:176 episode reward: total was 0.000000. running mean: -41.653773\n",
      "ep 6: ep_len:670 episode reward: total was -44.970000. running mean: -41.686935\n",
      "ep 6: ep_len:500 episode reward: total was -35.130000. running mean: -41.621366\n",
      "ep 6: ep_len:187 episode reward: total was 5.000000. running mean: -41.155152\n",
      "ep 6: ep_len:1625 episode reward: total was -167.600000. running mean: -42.419601\n",
      "ep 6: ep_len:933 episode reward: total was -168.830000. running mean: -43.683705\n",
      "ep 6: ep_len:500 episode reward: total was -15.440000. running mean: -43.401268\n",
      "ep 6: ep_len:775 episode reward: total was -48.480000. running mean: -43.452055\n",
      "ep 6: ep_len:870 episode reward: total was -52.030000. running mean: -43.537834\n",
      "ep 6: ep_len:585 episode reward: total was -28.350000. running mean: -43.385956\n",
      "ep 6: ep_len:505 episode reward: total was -25.340000. running mean: -43.205496\n",
      "ep 6: ep_len:750 episode reward: total was -46.020000. running mean: -43.233641\n",
      "ep 6: ep_len:925 episode reward: total was -138.590000. running mean: -44.187205\n",
      "ep 6: ep_len:540 episode reward: total was -28.260000. running mean: -44.027933\n",
      "ep 6: ep_len:500 episode reward: total was -43.210000. running mean: -44.019754\n",
      "ep 6: ep_len:600 episode reward: total was -30.660000. running mean: -43.886156\n",
      "ep 6: ep_len:775 episode reward: total was -39.910000. running mean: -43.846395\n",
      "ep 6: ep_len:137 episode reward: total was 2.000000. running mean: -43.387931\n",
      "ep 6: ep_len:505 episode reward: total was -22.390000. running mean: -43.177951\n",
      "ep 6: ep_len:885 episode reward: total was -52.960000. running mean: -43.275772\n",
      "ep 6: ep_len:500 episode reward: total was -16.410000. running mean: -43.007114\n",
      "ep 6: ep_len:760 episode reward: total was -37.400000. running mean: -42.951043\n",
      "ep 6: ep_len:765 episode reward: total was -67.200000. running mean: -43.193532\n",
      "ep 6: ep_len:855 episode reward: total was -98.360000. running mean: -43.745197\n",
      "ep 6: ep_len:267 episode reward: total was 4.500000. running mean: -43.262745\n",
      "ep 6: ep_len:1110 episode reward: total was -112.750000. running mean: -43.957618\n",
      "ep 6: ep_len:500 episode reward: total was -5.270000. running mean: -43.570742\n",
      "ep 6: ep_len:505 episode reward: total was -28.390000. running mean: -43.418934\n",
      "ep 6: ep_len:119 episode reward: total was 4.000000. running mean: -42.944745\n",
      "ep 6: ep_len:505 episode reward: total was -29.860000. running mean: -42.813897\n",
      "ep 6: ep_len:500 episode reward: total was -34.300000. running mean: -42.728758\n",
      "ep 6: ep_len:520 episode reward: total was -83.330000. running mean: -43.134771\n",
      "ep 6: ep_len:500 episode reward: total was -64.700000. running mean: -43.350423\n",
      "ep 6: ep_len:540 episode reward: total was -27.740000. running mean: -43.194319\n",
      "ep 6: ep_len:855 episode reward: total was -46.310000. running mean: -43.225476\n",
      "ep 6: ep_len:500 episode reward: total was -7.540000. running mean: -42.868621\n",
      "ep 6: ep_len:2735 episode reward: total was -290.210000. running mean: -45.342035\n",
      "ep 6: ep_len:500 episode reward: total was -31.400000. running mean: -45.202614\n",
      "ep 6: ep_len:500 episode reward: total was -43.490000. running mean: -45.185488\n",
      "ep 6: ep_len:675 episode reward: total was -50.700000. running mean: -45.240633\n",
      "ep 6: ep_len:500 episode reward: total was -50.150000. running mean: -45.289727\n",
      "ep 6: ep_len:1450 episode reward: total was -123.120000. running mean: -46.068030\n",
      "ep 6: ep_len:685 episode reward: total was -77.950000. running mean: -46.386849\n",
      "ep 6: ep_len:453 episode reward: total was -13.360000. running mean: -46.056581\n",
      "ep 6: ep_len:905 episode reward: total was -52.710000. running mean: -46.123115\n",
      "epsilon:0.292457 episode_count: 5515. steps_count: 3995356.000000\n",
      "ep 7: ep_len:500 episode reward: total was -33.260000. running mean: -45.994484\n",
      "ep 7: ep_len:985 episode reward: total was -41.490000. running mean: -45.949439\n",
      "ep 7: ep_len:705 episode reward: total was -56.210000. running mean: -46.052045\n",
      "ep 7: ep_len:795 episode reward: total was -40.400000. running mean: -45.995524\n",
      "ep 7: ep_len:935 episode reward: total was -41.200000. running mean: -45.947569\n",
      "ep 7: ep_len:500 episode reward: total was -31.120000. running mean: -45.799293\n",
      "ep 7: ep_len:640 episode reward: total was -28.870000. running mean: -45.630000\n",
      "ep 7: ep_len:630 episode reward: total was -14.780000. running mean: -45.321500\n",
      "ep 7: ep_len:855 episode reward: total was -63.960000. running mean: -45.507885\n",
      "ep 7: ep_len:530 episode reward: total was -37.340000. running mean: -45.426207\n",
      "ep 7: ep_len:500 episode reward: total was -32.070000. running mean: -45.292645\n",
      "ep 7: ep_len:760 episode reward: total was -140.420000. running mean: -46.243918\n",
      "ep 7: ep_len:975 episode reward: total was -34.650000. running mean: -46.127979\n",
      "ep 7: ep_len:280 episode reward: total was -5.000000. running mean: -45.716699\n",
      "ep 7: ep_len:995 episode reward: total was -83.450000. running mean: -46.094032\n",
      "ep 7: ep_len:875 episode reward: total was -60.400000. running mean: -46.237092\n",
      "ep 7: ep_len:500 episode reward: total was -5.800000. running mean: -45.832721\n",
      "ep 7: ep_len:605 episode reward: total was -62.580000. running mean: -46.000194\n",
      "ep 7: ep_len:500 episode reward: total was -22.030000. running mean: -45.760492\n",
      "ep 7: ep_len:283 episode reward: total was 0.000000. running mean: -45.302887\n",
      "ep 7: ep_len:655 episode reward: total was -36.350000. running mean: -45.213358\n",
      "ep 7: ep_len:695 episode reward: total was -70.340000. running mean: -45.464624\n",
      "ep 7: ep_len:1495 episode reward: total was -143.480000. running mean: -46.444778\n",
      "ep 7: ep_len:145 episode reward: total was -0.500000. running mean: -45.985330\n",
      "ep 7: ep_len:348 episode reward: total was 16.500000. running mean: -45.360477\n",
      "ep 7: ep_len:630 episode reward: total was -20.870000. running mean: -45.115572\n",
      "ep 7: ep_len:560 episode reward: total was -21.480000. running mean: -44.879217\n",
      "ep 7: ep_len:158 episode reward: total was 5.000000. running mean: -44.380424\n",
      "ep 7: ep_len:550 episode reward: total was -38.340000. running mean: -44.320020\n",
      "ep 7: ep_len:505 episode reward: total was 3.270000. running mean: -43.844120\n",
      "ep 7: ep_len:14535 episode reward: total was -2422.050000. running mean: -67.626179\n",
      "ep 7: ep_len:500 episode reward: total was -18.320000. running mean: -67.133117\n",
      "ep 7: ep_len:530 episode reward: total was -37.860000. running mean: -66.840386\n",
      "ep 7: ep_len:810 episode reward: total was -37.430000. running mean: -66.546282\n",
      "ep 7: ep_len:505 episode reward: total was -2.300000. running mean: -65.903819\n",
      "ep 7: ep_len:765 episode reward: total was -103.100000. running mean: -66.275781\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 7: ep_len:500 episode reward: total was -92.470000. running mean: -66.537723\n",
      "ep 7: ep_len:565 episode reward: total was -45.010000. running mean: -66.322446\n",
      "ep 7: ep_len:935 episode reward: total was -74.000000. running mean: -66.399221\n",
      "ep 7: ep_len:630 episode reward: total was -50.840000. running mean: -66.243629\n",
      "ep 7: ep_len:500 episode reward: total was -11.790000. running mean: -65.699093\n",
      "ep 7: ep_len:500 episode reward: total was -28.630000. running mean: -65.328402\n",
      "ep 7: ep_len:975 episode reward: total was -89.560000. running mean: -65.570718\n",
      "ep 7: ep_len:595 episode reward: total was -28.880000. running mean: -65.203811\n",
      "ep 7: ep_len:500 episode reward: total was -20.900000. running mean: -64.760773\n",
      "ep 7: ep_len:500 episode reward: total was -10.840000. running mean: -64.221565\n",
      "ep 7: ep_len:505 episode reward: total was -21.460000. running mean: -63.793949\n",
      "ep 7: ep_len:167 episode reward: total was 6.500000. running mean: -63.091010\n",
      "ep 7: ep_len:18995 episode reward: total was -2013.370000. running mean: -82.593800\n",
      "ep 7: ep_len:735 episode reward: total was -71.300000. running mean: -82.480862\n",
      "ep 7: ep_len:875 episode reward: total was -90.180000. running mean: -82.557853\n",
      "ep 7: ep_len:164 episode reward: total was 4.000000. running mean: -81.692275\n",
      "ep 7: ep_len:515 episode reward: total was -13.350000. running mean: -81.008852\n",
      "ep 7: ep_len:193 episode reward: total was -0.500000. running mean: -80.203763\n",
      "ep 7: ep_len:545 episode reward: total was -86.950000. running mean: -80.271226\n",
      "ep 7: ep_len:505 episode reward: total was -48.460000. running mean: -79.953113\n",
      "ep 7: ep_len:520 episode reward: total was -34.960000. running mean: -79.503182\n",
      "ep 7: ep_len:935 episode reward: total was -72.440000. running mean: -79.432550\n",
      "ep 7: ep_len:855 episode reward: total was -100.440000. running mean: -79.642625\n",
      "ep 7: ep_len:500 episode reward: total was -27.960000. running mean: -79.125799\n",
      "ep 7: ep_len:500 episode reward: total was -56.280000. running mean: -78.897341\n",
      "ep 7: ep_len:500 episode reward: total was -49.360000. running mean: -78.601967\n",
      "ep 7: ep_len:955 episode reward: total was -51.610000. running mean: -78.332048\n",
      "ep 7: ep_len:885 episode reward: total was -50.880000. running mean: -78.057527\n",
      "ep 7: ep_len:900 episode reward: total was -66.560000. running mean: -77.942552\n",
      "ep 7: ep_len:500 episode reward: total was -24.500000. running mean: -77.408126\n",
      "ep 7: ep_len:1300 episode reward: total was -141.810000. running mean: -78.052145\n",
      "ep 7: ep_len:665 episode reward: total was -68.980000. running mean: -77.961424\n",
      "ep 7: ep_len:975 episode reward: total was -96.710000. running mean: -78.148909\n",
      "ep 7: ep_len:610 episode reward: total was -44.280000. running mean: -77.810220\n",
      "ep 7: ep_len:830 episode reward: total was -52.070000. running mean: -77.552818\n",
      "ep 7: ep_len:216 episode reward: total was 2.000000. running mean: -76.757290\n",
      "ep 7: ep_len:500 episode reward: total was -85.970000. running mean: -76.849417\n",
      "ep 7: ep_len:500 episode reward: total was -2.330000. running mean: -76.104223\n",
      "ep 7: ep_len:379 episode reward: total was -26.170000. running mean: -75.604881\n",
      "ep 7: ep_len:500 episode reward: total was -23.310000. running mean: -75.081932\n",
      "ep 7: ep_len:530 episode reward: total was -57.540000. running mean: -74.906513\n",
      "ep 7: ep_len:500 episode reward: total was -45.600000. running mean: -74.613447\n",
      "ep 7: ep_len:810 episode reward: total was -36.840000. running mean: -74.235713\n",
      "ep 7: ep_len:500 episode reward: total was -35.090000. running mean: -73.844256\n",
      "ep 7: ep_len:960 episode reward: total was -35.700000. running mean: -73.462813\n",
      "ep 7: ep_len:500 episode reward: total was -25.390000. running mean: -72.982085\n",
      "ep 7: ep_len:850 episode reward: total was -57.750000. running mean: -72.829764\n",
      "ep 7: ep_len:500 episode reward: total was -26.900000. running mean: -72.370467\n",
      "ep 7: ep_len:505 episode reward: total was -11.360000. running mean: -71.760362\n",
      "ep 7: ep_len:535 episode reward: total was -43.420000. running mean: -71.476958\n",
      "ep 7: ep_len:540 episode reward: total was -43.430000. running mean: -71.196489\n",
      "ep 7: ep_len:650 episode reward: total was -28.820000. running mean: -70.772724\n",
      "ep 7: ep_len:620 episode reward: total was -58.370000. running mean: -70.648697\n",
      "ep 7: ep_len:500 episode reward: total was -63.430000. running mean: -70.576510\n",
      "ep 7: ep_len:500 episode reward: total was -14.420000. running mean: -70.014945\n",
      "ep 7: ep_len:840 episode reward: total was -81.680000. running mean: -70.131595\n",
      "ep 7: ep_len:805 episode reward: total was -63.680000. running mean: -70.067079\n",
      "ep 7: ep_len:995 episode reward: total was -141.820000. running mean: -70.784608\n",
      "ep 7: ep_len:595 episode reward: total was -67.540000. running mean: -70.752162\n",
      "ep 7: ep_len:188 episode reward: total was 5.000000. running mean: -69.994641\n",
      "ep 7: ep_len:885 episode reward: total was -48.940000. running mean: -69.784094\n",
      "ep 7: ep_len:895 episode reward: total was -19.320000. running mean: -69.279453\n",
      "ep 7: ep_len:500 episode reward: total was -38.100000. running mean: -68.967659\n",
      "ep 7: ep_len:655 episode reward: total was -36.110000. running mean: -68.639082\n",
      "ep 7: ep_len:500 episode reward: total was -11.830000. running mean: -68.070991\n",
      "ep 7: ep_len:820 episode reward: total was -123.860000. running mean: -68.628881\n",
      "ep 7: ep_len:605 episode reward: total was -114.480000. running mean: -69.087393\n",
      "ep 7: ep_len:740 episode reward: total was -58.720000. running mean: -68.983719\n",
      "ep 7: ep_len:303 episode reward: total was -1.000000. running mean: -68.303882\n",
      "ep 7: ep_len:590 episode reward: total was -54.420000. running mean: -68.165043\n",
      "ep 7: ep_len:575 episode reward: total was -58.460000. running mean: -68.067992\n",
      "ep 7: ep_len:550 episode reward: total was -40.360000. running mean: -67.790912\n",
      "ep 7: ep_len:245 episode reward: total was 6.500000. running mean: -67.048003\n",
      "ep 7: ep_len:252 episode reward: total was 8.500000. running mean: -66.292523\n",
      "ep 7: ep_len:510 episode reward: total was -38.310000. running mean: -66.012698\n",
      "ep 7: ep_len:915 episode reward: total was -60.380000. running mean: -65.956371\n",
      "ep 7: ep_len:705 episode reward: total was -65.670000. running mean: -65.953507\n",
      "ep 7: ep_len:500 episode reward: total was 0.210000. running mean: -65.291872\n",
      "ep 7: ep_len:500 episode reward: total was -5.810000. running mean: -64.697053\n",
      "ep 7: ep_len:815 episode reward: total was -46.870000. running mean: -64.518783\n",
      "ep 7: ep_len:500 episode reward: total was -40.730000. running mean: -64.280895\n",
      "ep 7: ep_len:500 episode reward: total was -32.120000. running mean: -63.959286\n",
      "ep 7: ep_len:990 episode reward: total was -92.000000. running mean: -64.239693\n",
      "ep 7: ep_len:910 episode reward: total was -31.770000. running mean: -63.914996\n",
      "ep 7: ep_len:620 episode reward: total was -26.010000. running mean: -63.535946\n",
      "ep 7: ep_len:665 episode reward: total was -57.530000. running mean: -63.475887\n",
      "ep 7: ep_len:510 episode reward: total was -34.560000. running mean: -63.186728\n",
      "ep 7: ep_len:970 episode reward: total was -31.450000. running mean: -62.869361\n",
      "ep 7: ep_len:800 episode reward: total was -89.350000. running mean: -63.134167\n",
      "ep 7: ep_len:550 episode reward: total was -83.290000. running mean: -63.335726\n",
      "ep 7: ep_len:775 episode reward: total was -45.940000. running mean: -63.161768\n",
      "ep 7: ep_len:570 episode reward: total was -54.430000. running mean: -63.074451\n",
      "ep 7: ep_len:840 episode reward: total was -66.530000. running mean: -63.109006\n",
      "ep 7: ep_len:500 episode reward: total was -56.340000. running mean: -63.041316\n",
      "ep 7: ep_len:895 episode reward: total was -75.930000. running mean: -63.170203\n",
      "ep 7: ep_len:515 episode reward: total was -65.650000. running mean: -63.195001\n",
      "ep 7: ep_len:500 episode reward: total was -11.860000. running mean: -62.681651\n",
      "ep 7: ep_len:500 episode reward: total was -44.830000. running mean: -62.503134\n",
      "ep 7: ep_len:875 episode reward: total was -81.090000. running mean: -62.689003\n",
      "ep 7: ep_len:505 episode reward: total was -46.690000. running mean: -62.529013\n",
      "ep 7: ep_len:730 episode reward: total was -34.560000. running mean: -62.249323\n",
      "ep 7: ep_len:2400 episode reward: total was -393.190000. running mean: -65.558730\n",
      "ep 7: ep_len:505 episode reward: total was -3.830000. running mean: -64.941442\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 7: ep_len:910 episode reward: total was -37.190000. running mean: -64.663928\n",
      "ep 7: ep_len:1475 episode reward: total was -195.550000. running mean: -65.972789\n",
      "ep 7: ep_len:500 episode reward: total was -9.830000. running mean: -65.411361\n",
      "ep 7: ep_len:500 episode reward: total was -0.800000. running mean: -64.765247\n",
      "ep 7: ep_len:126 episode reward: total was -1.000000. running mean: -64.127595\n",
      "ep 7: ep_len:605 episode reward: total was -45.300000. running mean: -63.939319\n",
      "ep 7: ep_len:248 episode reward: total was 0.500000. running mean: -63.294925\n",
      "ep 7: ep_len:500 episode reward: total was -15.540000. running mean: -62.817376\n",
      "ep 7: ep_len:805 episode reward: total was -33.620000. running mean: -62.525402\n",
      "ep 7: ep_len:530 episode reward: total was -41.410000. running mean: -62.314248\n",
      "ep 7: ep_len:595 episode reward: total was -32.950000. running mean: -62.020606\n",
      "ep 7: ep_len:660 episode reward: total was -64.380000. running mean: -62.044200\n",
      "ep 7: ep_len:500 episode reward: total was 8.500000. running mean: -61.338758\n",
      "ep 7: ep_len:500 episode reward: total was -20.290000. running mean: -60.928270\n",
      "ep 7: ep_len:500 episode reward: total was -17.690000. running mean: -60.495888\n",
      "ep 7: ep_len:935 episode reward: total was -54.880000. running mean: -60.439729\n",
      "ep 7: ep_len:510 episode reward: total was -20.590000. running mean: -60.041231\n",
      "ep 7: ep_len:500 episode reward: total was -6.310000. running mean: -59.503919\n",
      "ep 7: ep_len:715 episode reward: total was -43.550000. running mean: -59.344380\n",
      "ep 7: ep_len:710 episode reward: total was -31.100000. running mean: -59.061936\n",
      "ep 7: ep_len:645 episode reward: total was -30.610000. running mean: -58.777417\n",
      "ep 7: ep_len:500 episode reward: total was -22.350000. running mean: -58.413143\n",
      "ep 7: ep_len:580 episode reward: total was -5.180000. running mean: -57.880811\n",
      "ep 7: ep_len:940 episode reward: total was -66.500000. running mean: -57.967003\n",
      "ep 7: ep_len:655 episode reward: total was -45.170000. running mean: -57.839033\n",
      "ep 7: ep_len:500 episode reward: total was -3.840000. running mean: -57.299043\n",
      "ep 7: ep_len:505 episode reward: total was 2.170000. running mean: -56.704352\n",
      "ep 7: ep_len:500 episode reward: total was -8.160000. running mean: -56.218909\n",
      "ep 7: ep_len:700 episode reward: total was -48.630000. running mean: -56.143020\n",
      "ep 7: ep_len:685 episode reward: total was -27.620000. running mean: -55.857789\n",
      "ep 7: ep_len:500 episode reward: total was -6.280000. running mean: -55.362012\n",
      "ep 7: ep_len:500 episode reward: total was -6.580000. running mean: -54.874191\n",
      "ep 7: ep_len:505 episode reward: total was -30.340000. running mean: -54.628850\n",
      "ep 7: ep_len:735 episode reward: total was -73.810000. running mean: -54.820661\n",
      "ep 7: ep_len:197 episode reward: total was 9.000000. running mean: -54.182454\n",
      "ep 7: ep_len:505 episode reward: total was -38.460000. running mean: -54.025230\n",
      "ep 7: ep_len:980 episode reward: total was -56.890000. running mean: -54.053878\n",
      "ep 7: ep_len:505 episode reward: total was -15.850000. running mean: -53.671839\n",
      "ep 7: ep_len:159 episode reward: total was 1.000000. running mean: -53.125120\n",
      "ep 7: ep_len:865 episode reward: total was -61.500000. running mean: -53.208869\n",
      "ep 7: ep_len:505 episode reward: total was -12.890000. running mean: -52.805681\n",
      "ep 7: ep_len:505 episode reward: total was -41.150000. running mean: -52.689124\n",
      "ep 7: ep_len:500 episode reward: total was -44.780000. running mean: -52.610032\n",
      "ep 7: ep_len:745 episode reward: total was -64.660000. running mean: -52.730532\n",
      "ep 7: ep_len:500 episode reward: total was -29.410000. running mean: -52.497327\n",
      "ep 7: ep_len:237 episode reward: total was 10.000000. running mean: -51.872354\n",
      "ep 7: ep_len:505 episode reward: total was -22.440000. running mean: -51.578030\n",
      "ep 7: ep_len:67 episode reward: total was 5.000000. running mean: -51.012250\n",
      "ep 7: ep_len:590 episode reward: total was -34.190000. running mean: -50.844027\n",
      "ep 7: ep_len:500 episode reward: total was -0.290000. running mean: -50.338487\n",
      "ep 7: ep_len:530 episode reward: total was -25.220000. running mean: -50.087302\n",
      "ep 7: ep_len:625 episode reward: total was -21.840000. running mean: -49.804829\n",
      "ep 7: ep_len:510 episode reward: total was -40.420000. running mean: -49.710981\n",
      "ep 7: ep_len:725 episode reward: total was -36.980000. running mean: -49.583671\n",
      "ep 7: ep_len:262 episode reward: total was 1.000000. running mean: -49.077834\n",
      "ep 7: ep_len:760 episode reward: total was -65.680000. running mean: -49.243856\n",
      "ep 7: ep_len:189 episode reward: total was 11.000000. running mean: -48.641417\n",
      "ep 7: ep_len:530 episode reward: total was -37.420000. running mean: -48.529203\n",
      "ep 7: ep_len:590 episode reward: total was -36.240000. running mean: -48.406311\n",
      "ep 7: ep_len:1555 episode reward: total was -252.960000. running mean: -50.451848\n",
      "ep 7: ep_len:505 episode reward: total was -8.320000. running mean: -50.030530\n",
      "ep 7: ep_len:820 episode reward: total was -36.750000. running mean: -49.897724\n",
      "ep 7: ep_len:695 episode reward: total was -41.080000. running mean: -49.809547\n",
      "ep 7: ep_len:710 episode reward: total was -48.120000. running mean: -49.792652\n",
      "ep 7: ep_len:860 episode reward: total was -41.250000. running mean: -49.707225\n",
      "ep 7: ep_len:252 episode reward: total was 1.000000. running mean: -49.200153\n",
      "ep 7: ep_len:740 episode reward: total was -36.230000. running mean: -49.070451\n",
      "ep 7: ep_len:575 episode reward: total was -39.790000. running mean: -48.977647\n",
      "ep 7: ep_len:500 episode reward: total was -25.340000. running mean: -48.741270\n",
      "ep 7: ep_len:605 episode reward: total was -41.260000. running mean: -48.666458\n",
      "ep 7: ep_len:815 episode reward: total was -57.000000. running mean: -48.749793\n",
      "ep 7: ep_len:525 episode reward: total was -45.950000. running mean: -48.721795\n",
      "ep 7: ep_len:500 episode reward: total was 6.210000. running mean: -48.172477\n",
      "ep 7: ep_len:905 episode reward: total was -39.460000. running mean: -48.085352\n",
      "ep 7: ep_len:635 episode reward: total was -25.520000. running mean: -47.859699\n",
      "ep 7: ep_len:920 episode reward: total was -79.010000. running mean: -48.171202\n",
      "ep 7: ep_len:650 episode reward: total was -36.610000. running mean: -48.055590\n",
      "ep 7: ep_len:925 episode reward: total was -34.880000. running mean: -47.923834\n",
      "ep 7: ep_len:705 episode reward: total was -44.060000. running mean: -47.885196\n",
      "ep 7: ep_len:500 episode reward: total was -37.120000. running mean: -47.777544\n",
      "ep 7: ep_len:510 episode reward: total was -23.870000. running mean: -47.538468\n",
      "ep 7: ep_len:510 episode reward: total was -74.960000. running mean: -47.812684\n",
      "ep 7: ep_len:570 episode reward: total was -43.840000. running mean: -47.772957\n",
      "ep 7: ep_len:500 episode reward: total was -31.700000. running mean: -47.612227\n",
      "ep 7: ep_len:755 episode reward: total was -39.430000. running mean: -47.530405\n",
      "ep 7: ep_len:605 episode reward: total was -14.680000. running mean: -47.201901\n",
      "ep 7: ep_len:910 episode reward: total was -24.800000. running mean: -46.977882\n",
      "ep 7: ep_len:505 episode reward: total was -66.880000. running mean: -47.176903\n",
      "ep 7: ep_len:500 episode reward: total was -2.800000. running mean: -46.733134\n",
      "ep 7: ep_len:505 episode reward: total was -27.460000. running mean: -46.540403\n",
      "ep 7: ep_len:500 episode reward: total was -7.360000. running mean: -46.148599\n",
      "ep 7: ep_len:515 episode reward: total was -25.830000. running mean: -45.945413\n",
      "ep 7: ep_len:505 episode reward: total was -14.790000. running mean: -45.633858\n",
      "ep 7: ep_len:690 episode reward: total was -69.360000. running mean: -45.871120\n",
      "ep 7: ep_len:620 episode reward: total was -8.310000. running mean: -45.495509\n",
      "ep 7: ep_len:1045 episode reward: total was -39.820000. running mean: -45.438754\n",
      "ep 7: ep_len:645 episode reward: total was -24.750000. running mean: -45.231866\n",
      "ep 7: ep_len:500 episode reward: total was -26.770000. running mean: -45.047247\n",
      "ep 7: ep_len:720 episode reward: total was -55.170000. running mean: -45.148475\n",
      "ep 7: ep_len:505 episode reward: total was -44.490000. running mean: -45.141890\n",
      "ep 7: ep_len:500 episode reward: total was -28.150000. running mean: -44.971971\n",
      "ep 7: ep_len:575 episode reward: total was -31.360000. running mean: -44.835852\n",
      "ep 7: ep_len:755 episode reward: total was -55.590000. running mean: -44.943393\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 7: ep_len:725 episode reward: total was -45.030000. running mean: -44.944259\n",
      "ep 7: ep_len:500 episode reward: total was -23.610000. running mean: -44.730917\n",
      "ep 7: ep_len:500 episode reward: total was -26.850000. running mean: -44.552107\n",
      "ep 7: ep_len:500 episode reward: total was 2.730000. running mean: -44.079286\n",
      "ep 7: ep_len:620 episode reward: total was -7.090000. running mean: -43.709393\n",
      "ep 7: ep_len:138 episode reward: total was 3.000000. running mean: -43.242299\n",
      "ep 7: ep_len:565 episode reward: total was -47.370000. running mean: -43.283576\n",
      "ep 7: ep_len:555 episode reward: total was -29.240000. running mean: -43.143141\n",
      "ep 7: ep_len:500 episode reward: total was -44.590000. running mean: -43.157609\n",
      "ep 7: ep_len:500 episode reward: total was -22.610000. running mean: -42.952133\n",
      "ep 7: ep_len:500 episode reward: total was -6.350000. running mean: -42.586112\n",
      "ep 7: ep_len:585 episode reward: total was -58.470000. running mean: -42.744951\n",
      "ep 7: ep_len:505 episode reward: total was -23.000000. running mean: -42.547501\n",
      "ep 7: ep_len:500 episode reward: total was -44.040000. running mean: -42.562426\n",
      "ep 7: ep_len:855 episode reward: total was -74.090000. running mean: -42.877702\n",
      "ep 7: ep_len:625 episode reward: total was -25.060000. running mean: -42.699525\n",
      "ep 7: ep_len:187 episode reward: total was 6.500000. running mean: -42.207530\n",
      "ep 7: ep_len:855 episode reward: total was -44.550000. running mean: -42.230954\n",
      "ep 7: ep_len:500 episode reward: total was -41.740000. running mean: -42.226045\n",
      "ep 7: ep_len:760 episode reward: total was -17.240000. running mean: -41.976184\n",
      "ep 7: ep_len:1010 episode reward: total was -63.210000. running mean: -42.188523\n",
      "ep 7: ep_len:545 episode reward: total was -32.290000. running mean: -42.089537\n",
      "ep 7: ep_len:1045 episode reward: total was -44.610000. running mean: -42.114742\n",
      "ep 7: ep_len:960 episode reward: total was -52.800000. running mean: -42.221595\n",
      "ep 7: ep_len:237 episode reward: total was 7.500000. running mean: -41.724379\n",
      "ep 7: ep_len:500 episode reward: total was -4.640000. running mean: -41.353535\n",
      "ep 7: ep_len:615 episode reward: total was -36.680000. running mean: -41.306799\n",
      "ep 7: ep_len:510 episode reward: total was -22.040000. running mean: -41.114131\n",
      "ep 7: ep_len:505 episode reward: total was -20.730000. running mean: -40.910290\n",
      "ep 7: ep_len:825 episode reward: total was -26.710000. running mean: -40.768287\n",
      "ep 7: ep_len:500 episode reward: total was -7.260000. running mean: -40.433204\n",
      "ep 7: ep_len:313 episode reward: total was 1.500000. running mean: -40.013872\n",
      "ep 7: ep_len:510 episode reward: total was -39.460000. running mean: -40.008334\n",
      "ep 7: ep_len:655 episode reward: total was -49.730000. running mean: -40.105550\n",
      "ep 7: ep_len:505 episode reward: total was -42.790000. running mean: -40.132395\n",
      "ep 7: ep_len:500 episode reward: total was -40.460000. running mean: -40.135671\n",
      "ep 7: ep_len:690 episode reward: total was -59.240000. running mean: -40.326714\n",
      "ep 7: ep_len:1585 episode reward: total was -187.560000. running mean: -41.799047\n",
      "ep 7: ep_len:870 episode reward: total was -38.780000. running mean: -41.768857\n",
      "ep 7: ep_len:520 episode reward: total was -25.940000. running mean: -41.610568\n",
      "ep 7: ep_len:500 episode reward: total was -17.680000. running mean: -41.371262\n",
      "ep 7: ep_len:238 episode reward: total was -45.000000. running mean: -41.407550\n",
      "ep 7: ep_len:935 episode reward: total was -42.240000. running mean: -41.415874\n",
      "ep 7: ep_len:1055 episode reward: total was -105.000000. running mean: -42.051715\n",
      "ep 7: ep_len:515 episode reward: total was -31.370000. running mean: -41.944898\n",
      "ep 7: ep_len:500 episode reward: total was -9.080000. running mean: -41.616249\n",
      "ep 7: ep_len:850 episode reward: total was -68.100000. running mean: -41.881087\n",
      "ep 7: ep_len:1015 episode reward: total was -79.880000. running mean: -42.261076\n",
      "ep 7: ep_len:1475 episode reward: total was -182.940000. running mean: -43.667865\n",
      "ep 7: ep_len:730 episode reward: total was -46.550000. running mean: -43.696687\n",
      "ep 7: ep_len:505 episode reward: total was 5.000000. running mean: -43.209720\n",
      "ep 7: ep_len:570 episode reward: total was -27.720000. running mean: -43.054822\n",
      "ep 7: ep_len:505 episode reward: total was 0.850000. running mean: -42.615774\n",
      "ep 7: ep_len:570 episode reward: total was -47.880000. running mean: -42.668416\n",
      "ep 7: ep_len:695 episode reward: total was -40.070000. running mean: -42.642432\n",
      "ep 7: ep_len:351 episode reward: total was 2.500000. running mean: -42.191008\n",
      "ep 7: ep_len:970 episode reward: total was -109.700000. running mean: -42.866098\n",
      "ep 7: ep_len:505 episode reward: total was -29.340000. running mean: -42.730837\n",
      "ep 7: ep_len:525 episode reward: total was -48.060000. running mean: -42.784129\n",
      "ep 7: ep_len:1230 episode reward: total was -179.040000. running mean: -44.146687\n",
      "ep 7: ep_len:500 episode reward: total was -10.750000. running mean: -43.812720\n",
      "ep 7: ep_len:700 episode reward: total was -46.090000. running mean: -43.835493\n",
      "ep 7: ep_len:505 episode reward: total was -48.010000. running mean: -43.877238\n",
      "ep 7: ep_len:865 episode reward: total was -55.310000. running mean: -43.991566\n",
      "ep 7: ep_len:855 episode reward: total was -46.290000. running mean: -44.014550\n",
      "ep 7: ep_len:327 episode reward: total was 0.500000. running mean: -43.569405\n",
      "ep 7: ep_len:505 episode reward: total was -27.030000. running mean: -43.404011\n",
      "ep 7: ep_len:500 episode reward: total was -24.340000. running mean: -43.213371\n",
      "ep 7: ep_len:159 episode reward: total was 2.000000. running mean: -42.761237\n",
      "ep 7: ep_len:500 episode reward: total was -6.750000. running mean: -42.401125\n",
      "ep 7: ep_len:500 episode reward: total was -9.320000. running mean: -42.070313\n",
      "ep 7: ep_len:500 episode reward: total was -20.100000. running mean: -41.850610\n",
      "ep 7: ep_len:500 episode reward: total was 16.000000. running mean: -41.272104\n",
      "ep 7: ep_len:500 episode reward: total was -3.780000. running mean: -40.897183\n",
      "ep 7: ep_len:416 episode reward: total was 12.000000. running mean: -40.368211\n",
      "ep 7: ep_len:670 episode reward: total was -58.790000. running mean: -40.552429\n",
      "ep 7: ep_len:820 episode reward: total was -47.000000. running mean: -40.616905\n",
      "ep 7: ep_len:1155 episode reward: total was -79.050000. running mean: -41.001236\n",
      "ep 7: ep_len:500 episode reward: total was -3.750000. running mean: -40.628723\n",
      "ep 7: ep_len:805 episode reward: total was -40.500000. running mean: -40.627436\n",
      "ep 7: ep_len:1980 episode reward: total was -244.230000. running mean: -42.663462\n",
      "ep 7: ep_len:1070 episode reward: total was -42.400000. running mean: -42.660827\n",
      "ep 7: ep_len:880 episode reward: total was -33.010000. running mean: -42.564319\n",
      "ep 7: ep_len:520 episode reward: total was -39.410000. running mean: -42.532776\n",
      "ep 7: ep_len:595 episode reward: total was -68.030000. running mean: -42.787748\n",
      "ep 7: ep_len:570 episode reward: total was -48.400000. running mean: -42.843870\n",
      "ep 7: ep_len:332 episode reward: total was -5.820000. running mean: -42.473632\n",
      "ep 7: ep_len:1140 episode reward: total was -103.790000. running mean: -43.086795\n",
      "ep 7: ep_len:500 episode reward: total was -9.280000. running mean: -42.748727\n",
      "ep 7: ep_len:655 episode reward: total was -59.340000. running mean: -42.914640\n",
      "ep 7: ep_len:447 episode reward: total was 14.000000. running mean: -42.345494\n",
      "ep 7: ep_len:505 episode reward: total was -33.930000. running mean: -42.261339\n",
      "ep 7: ep_len:730 episode reward: total was -33.940000. running mean: -42.178125\n",
      "ep 7: ep_len:715 episode reward: total was -42.050000. running mean: -42.176844\n",
      "ep 7: ep_len:500 episode reward: total was -4.330000. running mean: -41.798376\n",
      "ep 7: ep_len:172 episode reward: total was 6.500000. running mean: -41.315392\n",
      "ep 7: ep_len:525 episode reward: total was -26.270000. running mean: -41.164938\n",
      "ep 7: ep_len:595 episode reward: total was -20.950000. running mean: -40.962789\n",
      "ep 7: ep_len:334 episode reward: total was -8.320000. running mean: -40.636361\n",
      "ep 7: ep_len:245 episode reward: total was 5.000000. running mean: -40.179997\n",
      "ep 7: ep_len:1025 episode reward: total was -124.740000. running mean: -41.025597\n",
      "ep 7: ep_len:875 episode reward: total was -67.470000. running mean: -41.290041\n",
      "ep 7: ep_len:950 episode reward: total was -119.320000. running mean: -42.070341\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 7: ep_len:186 episode reward: total was 5.000000. running mean: -41.599637\n",
      "ep 7: ep_len:795 episode reward: total was -37.890000. running mean: -41.562541\n",
      "ep 7: ep_len:715 episode reward: total was -42.630000. running mean: -41.573216\n",
      "ep 7: ep_len:500 episode reward: total was -39.340000. running mean: -41.550884\n",
      "ep 7: ep_len:720 episode reward: total was -66.280000. running mean: -41.798175\n",
      "ep 7: ep_len:655 episode reward: total was -73.340000. running mean: -42.113593\n",
      "ep 7: ep_len:500 episode reward: total was -43.480000. running mean: -42.127257\n",
      "ep 7: ep_len:595 episode reward: total was -33.200000. running mean: -42.037984\n",
      "ep 7: ep_len:500 episode reward: total was -18.310000. running mean: -41.800705\n",
      "ep 7: ep_len:715 episode reward: total was -86.490000. running mean: -42.247598\n",
      "ep 7: ep_len:615 episode reward: total was -46.260000. running mean: -42.287722\n",
      "ep 7: ep_len:880 episode reward: total was -39.690000. running mean: -42.261744\n",
      "ep 7: ep_len:545 episode reward: total was -22.280000. running mean: -42.061927\n",
      "ep 7: ep_len:705 episode reward: total was -31.780000. running mean: -41.959108\n",
      "ep 7: ep_len:690 episode reward: total was -23.050000. running mean: -41.770017\n",
      "ep 7: ep_len:184 episode reward: total was 1.500000. running mean: -41.337316\n",
      "ep 7: ep_len:500 episode reward: total was -27.320000. running mean: -41.197143\n",
      "ep 7: ep_len:380 episode reward: total was -39.740000. running mean: -41.182572\n",
      "ep 7: ep_len:305 episode reward: total was -12.370000. running mean: -40.894446\n",
      "ep 7: ep_len:565 episode reward: total was -16.900000. running mean: -40.654502\n",
      "ep 7: ep_len:500 episode reward: total was -27.320000. running mean: -40.521157\n",
      "ep 7: ep_len:900 episode reward: total was -74.980000. running mean: -40.865745\n",
      "ep 7: ep_len:505 episode reward: total was -34.620000. running mean: -40.803288\n",
      "ep 7: ep_len:407 episode reward: total was 2.500000. running mean: -40.370255\n",
      "ep 7: ep_len:211 episode reward: total was 2.000000. running mean: -39.946552\n",
      "ep 7: ep_len:605 episode reward: total was -13.410000. running mean: -39.681187\n",
      "ep 7: ep_len:1420 episode reward: total was -250.700000. running mean: -41.791375\n",
      "ep 7: ep_len:500 episode reward: total was -5.850000. running mean: -41.431961\n",
      "ep 7: ep_len:500 episode reward: total was -26.280000. running mean: -41.280441\n",
      "ep 7: ep_len:750 episode reward: total was -36.930000. running mean: -41.236937\n",
      "ep 7: ep_len:1145 episode reward: total was -124.010000. running mean: -42.064668\n",
      "ep 7: ep_len:625 episode reward: total was -80.090000. running mean: -42.444921\n",
      "ep 7: ep_len:500 episode reward: total was -24.880000. running mean: -42.269272\n",
      "ep 7: ep_len:1055 episode reward: total was -51.990000. running mean: -42.366479\n",
      "ep 7: ep_len:500 episode reward: total was -14.710000. running mean: -42.089914\n",
      "ep 7: ep_len:500 episode reward: total was -45.260000. running mean: -42.121615\n",
      "ep 7: ep_len:500 episode reward: total was -30.260000. running mean: -42.002999\n",
      "ep 7: ep_len:595 episode reward: total was -30.670000. running mean: -41.889669\n",
      "ep 7: ep_len:2385 episode reward: total was -215.080000. running mean: -43.621572\n",
      "ep 7: ep_len:510 episode reward: total was -13.790000. running mean: -43.323257\n",
      "ep 7: ep_len:945 episode reward: total was -45.760000. running mean: -43.347624\n",
      "ep 7: ep_len:1440 episode reward: total was -163.790000. running mean: -44.552048\n",
      "ep 7: ep_len:755 episode reward: total was -45.540000. running mean: -44.561927\n",
      "ep 7: ep_len:665 episode reward: total was -38.600000. running mean: -44.502308\n",
      "ep 7: ep_len:700 episode reward: total was -41.560000. running mean: -44.472885\n",
      "ep 7: ep_len:1360 episode reward: total was -136.660000. running mean: -45.394756\n",
      "ep 7: ep_len:500 episode reward: total was -25.550000. running mean: -45.196308\n",
      "ep 7: ep_len:1570 episode reward: total was -108.010000. running mean: -45.824445\n",
      "ep 7: ep_len:267 episode reward: total was 8.500000. running mean: -45.281201\n",
      "ep 7: ep_len:500 episode reward: total was -7.870000. running mean: -44.907089\n",
      "ep 7: ep_len:9305 episode reward: total was -1628.150000. running mean: -60.739518\n",
      "ep 7: ep_len:500 episode reward: total was -21.880000. running mean: -60.350923\n",
      "ep 7: ep_len:1065 episode reward: total was -59.000000. running mean: -60.337414\n",
      "ep 7: ep_len:500 episode reward: total was -10.750000. running mean: -59.841540\n",
      "ep 7: ep_len:755 episode reward: total was -66.210000. running mean: -59.905224\n",
      "ep 7: ep_len:244 episode reward: total was 12.000000. running mean: -59.186172\n",
      "ep 7: ep_len:500 episode reward: total was -19.270000. running mean: -58.787010\n",
      "ep 7: ep_len:660 episode reward: total was -41.640000. running mean: -58.615540\n",
      "ep 7: ep_len:1300 episode reward: total was -110.570000. running mean: -59.135085\n",
      "ep 7: ep_len:297 episode reward: total was 8.500000. running mean: -58.458734\n",
      "ep 7: ep_len:580 episode reward: total was -36.610000. running mean: -58.240246\n",
      "ep 7: ep_len:920 episode reward: total was -71.940000. running mean: -58.377244\n",
      "ep 7: ep_len:905 episode reward: total was -55.320000. running mean: -58.346672\n",
      "ep 7: ep_len:271 episode reward: total was 6.000000. running mean: -57.703205\n",
      "ep 7: ep_len:1630 episode reward: total was -103.190000. running mean: -58.158073\n",
      "ep 7: ep_len:570 episode reward: total was -53.450000. running mean: -58.110992\n",
      "ep 7: ep_len:184 episode reward: total was 12.000000. running mean: -57.409882\n",
      "ep 7: ep_len:500 episode reward: total was -20.790000. running mean: -57.043683\n",
      "ep 7: ep_len:500 episode reward: total was -16.060000. running mean: -56.633846\n",
      "ep 7: ep_len:1060 episode reward: total was -65.400000. running mean: -56.721508\n",
      "ep 7: ep_len:196 episode reward: total was 7.500000. running mean: -56.079293\n",
      "ep 7: ep_len:540 episode reward: total was -46.950000. running mean: -55.988000\n",
      "ep 7: ep_len:500 episode reward: total was 7.000000. running mean: -55.358120\n",
      "ep 7: ep_len:399 episode reward: total was -22.330000. running mean: -55.027839\n",
      "ep 7: ep_len:500 episode reward: total was -44.560000. running mean: -54.923160\n",
      "ep 7: ep_len:1080 episode reward: total was -82.700000. running mean: -55.200929\n",
      "ep 7: ep_len:1515 episode reward: total was -239.420000. running mean: -57.043120\n",
      "ep 7: ep_len:505 episode reward: total was -20.350000. running mean: -56.676188\n",
      "ep 7: ep_len:500 episode reward: total was -38.210000. running mean: -56.491526\n",
      "ep 7: ep_len:500 episode reward: total was -47.160000. running mean: -56.398211\n",
      "ep 7: ep_len:500 episode reward: total was -20.350000. running mean: -56.037729\n",
      "ep 7: ep_len:915 episode reward: total was -53.770000. running mean: -56.015052\n",
      "ep 7: ep_len:590 episode reward: total was -65.530000. running mean: -56.110201\n",
      "ep 7: ep_len:500 episode reward: total was -25.590000. running mean: -55.804999\n",
      "ep 7: ep_len:500 episode reward: total was -17.280000. running mean: -55.419749\n",
      "ep 7: ep_len:665 episode reward: total was -12.510000. running mean: -54.990652\n",
      "ep 7: ep_len:500 episode reward: total was -34.350000. running mean: -54.784245\n",
      "ep 7: ep_len:500 episode reward: total was -22.760000. running mean: -54.464003\n",
      "ep 7: ep_len:500 episode reward: total was -49.090000. running mean: -54.410263\n",
      "ep 7: ep_len:500 episode reward: total was -37.210000. running mean: -54.238260\n",
      "ep 7: ep_len:1015 episode reward: total was -51.910000. running mean: -54.214978\n",
      "ep 7: ep_len:500 episode reward: total was -24.160000. running mean: -53.914428\n",
      "ep 7: ep_len:500 episode reward: total was -15.840000. running mean: -53.533683\n",
      "ep 7: ep_len:500 episode reward: total was -9.640000. running mean: -53.094747\n",
      "ep 7: ep_len:980 episode reward: total was -33.640000. running mean: -52.900199\n",
      "ep 7: ep_len:760 episode reward: total was -49.520000. running mean: -52.866397\n",
      "ep 7: ep_len:500 episode reward: total was -50.100000. running mean: -52.838733\n",
      "ep 7: ep_len:730 episode reward: total was -52.910000. running mean: -52.839446\n",
      "ep 7: ep_len:530 episode reward: total was -46.430000. running mean: -52.775351\n",
      "ep 7: ep_len:500 episode reward: total was -4.820000. running mean: -52.295798\n",
      "ep 7: ep_len:500 episode reward: total was -29.580000. running mean: -52.068640\n",
      "ep 7: ep_len:505 episode reward: total was -18.650000. running mean: -51.734454\n",
      "ep 7: ep_len:500 episode reward: total was -1.810000. running mean: -51.235209\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 7: ep_len:570 episode reward: total was -47.880000. running mean: -51.201657\n",
      "ep 7: ep_len:865 episode reward: total was -37.290000. running mean: -51.062540\n",
      "ep 7: ep_len:500 episode reward: total was -50.680000. running mean: -51.058715\n",
      "ep 7: ep_len:555 episode reward: total was -3.770000. running mean: -50.585828\n",
      "ep 7: ep_len:665 episode reward: total was -33.060000. running mean: -50.410570\n",
      "ep 7: ep_len:515 episode reward: total was -63.660000. running mean: -50.543064\n",
      "ep 7: ep_len:505 episode reward: total was -12.740000. running mean: -50.165033\n",
      "ep 7: ep_len:825 episode reward: total was -48.870000. running mean: -50.152083\n",
      "ep 7: ep_len:1140 episode reward: total was -60.920000. running mean: -50.259762\n",
      "ep 7: ep_len:500 episode reward: total was -24.310000. running mean: -50.000264\n",
      "ep 7: ep_len:500 episode reward: total was -15.350000. running mean: -49.653762\n",
      "ep 7: ep_len:700 episode reward: total was -24.870000. running mean: -49.405924\n",
      "ep 7: ep_len:565 episode reward: total was -56.490000. running mean: -49.476765\n",
      "ep 7: ep_len:316 episode reward: total was 3.000000. running mean: -48.951997\n",
      "ep 7: ep_len:370 episode reward: total was -27.490000. running mean: -48.737377\n",
      "ep 7: ep_len:530 episode reward: total was -67.150000. running mean: -48.921504\n",
      "ep 7: ep_len:590 episode reward: total was -61.550000. running mean: -49.047788\n",
      "ep 7: ep_len:555 episode reward: total was -48.480000. running mean: -49.042111\n",
      "ep 7: ep_len:615 episode reward: total was -32.420000. running mean: -48.875889\n",
      "ep 7: ep_len:500 episode reward: total was -18.330000. running mean: -48.570431\n",
      "ep 7: ep_len:505 episode reward: total was -61.230000. running mean: -48.697026\n",
      "ep 7: ep_len:500 episode reward: total was -47.530000. running mean: -48.685356\n",
      "ep 7: ep_len:950 episode reward: total was -42.540000. running mean: -48.623902\n",
      "ep 7: ep_len:500 episode reward: total was -10.210000. running mean: -48.239763\n",
      "ep 7: ep_len:505 episode reward: total was -7.750000. running mean: -47.834866\n",
      "ep 7: ep_len:545 episode reward: total was -34.800000. running mean: -47.704517\n",
      "ep 7: ep_len:875 episode reward: total was -61.640000. running mean: -47.843872\n",
      "ep 7: ep_len:940 episode reward: total was -58.050000. running mean: -47.945933\n",
      "ep 7: ep_len:580 episode reward: total was -41.800000. running mean: -47.884474\n",
      "ep 7: ep_len:505 episode reward: total was -33.070000. running mean: -47.736329\n",
      "ep 7: ep_len:183 episode reward: total was 9.000000. running mean: -47.168966\n",
      "ep 7: ep_len:500 episode reward: total was -16.270000. running mean: -46.859976\n",
      "ep 7: ep_len:1010 episode reward: total was -28.980000. running mean: -46.681176\n",
      "ep 7: ep_len:500 episode reward: total was -17.850000. running mean: -46.392865\n",
      "ep 7: ep_len:190 episode reward: total was 2.500000. running mean: -45.903936\n",
      "ep 7: ep_len:10490 episode reward: total was -1935.640000. running mean: -64.801297\n",
      "ep 7: ep_len:500 episode reward: total was -25.170000. running mean: -64.404984\n",
      "ep 7: ep_len:1060 episode reward: total was -60.730000. running mean: -64.368234\n",
      "ep 7: ep_len:650 episode reward: total was -120.930000. running mean: -64.933852\n",
      "ep 7: ep_len:965 episode reward: total was -42.100000. running mean: -64.705513\n",
      "ep 7: ep_len:500 episode reward: total was -13.330000. running mean: -64.191758\n",
      "ep 7: ep_len:925 episode reward: total was -62.840000. running mean: -64.178240\n",
      "ep 7: ep_len:505 episode reward: total was -0.320000. running mean: -63.539658\n",
      "ep 7: ep_len:810 episode reward: total was -49.570000. running mean: -63.399961\n",
      "ep 7: ep_len:840 episode reward: total was -129.150000. running mean: -64.057462\n",
      "ep 7: ep_len:500 episode reward: total was -9.850000. running mean: -63.515387\n",
      "ep 7: ep_len:500 episode reward: total was -50.680000. running mean: -63.387033\n",
      "ep 7: ep_len:975 episode reward: total was -110.940000. running mean: -63.862563\n",
      "ep 7: ep_len:670 episode reward: total was -37.090000. running mean: -63.594837\n",
      "ep 7: ep_len:1030 episode reward: total was -53.550000. running mean: -63.494389\n",
      "ep 7: ep_len:820 episode reward: total was -58.490000. running mean: -63.444345\n",
      "ep 7: ep_len:630 episode reward: total was -48.530000. running mean: -63.295202\n",
      "ep 7: ep_len:500 episode reward: total was -19.360000. running mean: -62.855850\n",
      "ep 7: ep_len:545 episode reward: total was -46.920000. running mean: -62.696491\n",
      "ep 7: ep_len:680 episode reward: total was -59.780000. running mean: -62.667326\n",
      "ep 7: ep_len:940 episode reward: total was -49.990000. running mean: -62.540553\n",
      "ep 7: ep_len:500 episode reward: total was -1.270000. running mean: -61.927847\n",
      "ep 7: ep_len:500 episode reward: total was -14.360000. running mean: -61.452169\n",
      "ep 7: ep_len:930 episode reward: total was -73.940000. running mean: -61.577047\n",
      "ep 7: ep_len:510 episode reward: total was -21.360000. running mean: -61.174877\n",
      "ep 7: ep_len:500 episode reward: total was -44.220000. running mean: -61.005328\n",
      "ep 7: ep_len:400 episode reward: total was 6.000000. running mean: -60.335275\n",
      "ep 7: ep_len:730 episode reward: total was -23.310000. running mean: -59.965022\n",
      "ep 7: ep_len:650 episode reward: total was -56.400000. running mean: -59.929372\n",
      "ep 7: ep_len:860 episode reward: total was -79.020000. running mean: -60.120278\n",
      "ep 7: ep_len:705 episode reward: total was -35.360000. running mean: -59.872675\n",
      "ep 7: ep_len:500 episode reward: total was -16.320000. running mean: -59.437148\n",
      "ep 7: ep_len:1475 episode reward: total was -119.310000. running mean: -60.035877\n",
      "ep 7: ep_len:505 episode reward: total was -12.280000. running mean: -59.558318\n",
      "ep 7: ep_len:700 episode reward: total was -63.780000. running mean: -59.600535\n",
      "ep 7: ep_len:1760 episode reward: total was -135.910000. running mean: -60.363630\n",
      "ep 7: ep_len:1130 episode reward: total was -134.740000. running mean: -61.107393\n",
      "ep 7: ep_len:1005 episode reward: total was -28.520000. running mean: -60.781519\n",
      "ep 7: ep_len:600 episode reward: total was -40.930000. running mean: -60.583004\n",
      "ep 7: ep_len:540 episode reward: total was -34.060000. running mean: -60.317774\n",
      "ep 7: ep_len:835 episode reward: total was -10.020000. running mean: -59.814796\n",
      "ep 7: ep_len:1510 episode reward: total was -190.950000. running mean: -61.126148\n",
      "ep 7: ep_len:1025 episode reward: total was -103.040000. running mean: -61.545287\n",
      "ep 7: ep_len:1135 episode reward: total was -53.440000. running mean: -61.464234\n",
      "ep 7: ep_len:555 episode reward: total was -42.240000. running mean: -61.271992\n",
      "ep 7: ep_len:695 episode reward: total was -34.010000. running mean: -60.999372\n",
      "ep 7: ep_len:500 episode reward: total was -8.780000. running mean: -60.477178\n",
      "ep 7: ep_len:490 episode reward: total was -25.830000. running mean: -60.130706\n",
      "ep 7: ep_len:500 episode reward: total was -16.800000. running mean: -59.697399\n",
      "ep 7: ep_len:740 episode reward: total was -26.200000. running mean: -59.362425\n",
      "ep 7: ep_len:510 episode reward: total was -35.080000. running mean: -59.119601\n",
      "ep 7: ep_len:500 episode reward: total was -10.210000. running mean: -58.630505\n",
      "ep 7: ep_len:505 episode reward: total was -16.320000. running mean: -58.207400\n",
      "ep 7: ep_len:500 episode reward: total was -22.110000. running mean: -57.846426\n",
      "ep 7: ep_len:740 episode reward: total was -82.580000. running mean: -58.093762\n",
      "ep 7: ep_len:935 episode reward: total was -45.090000. running mean: -57.963724\n",
      "ep 7: ep_len:500 episode reward: total was -20.790000. running mean: -57.591987\n",
      "ep 7: ep_len:815 episode reward: total was -80.440000. running mean: -57.820467\n",
      "ep 7: ep_len:775 episode reward: total was -63.150000. running mean: -57.873762\n",
      "ep 7: ep_len:755 episode reward: total was -13.400000. running mean: -57.429025\n",
      "ep 7: ep_len:500 episode reward: total was -30.630000. running mean: -57.161034\n",
      "ep 7: ep_len:435 episode reward: total was -12.210000. running mean: -56.711524\n",
      "ep 7: ep_len:510 episode reward: total was -11.830000. running mean: -56.262709\n",
      "ep 7: ep_len:865 episode reward: total was -73.550000. running mean: -56.435582\n",
      "ep 7: ep_len:540 episode reward: total was -32.300000. running mean: -56.194226\n",
      "ep 7: ep_len:665 episode reward: total was -71.460000. running mean: -56.346884\n",
      "ep 7: ep_len:510 episode reward: total was -12.810000. running mean: -55.911515\n",
      "ep 7: ep_len:1515 episode reward: total was -193.480000. running mean: -57.287200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 7: ep_len:163 episode reward: total was 7.500000. running mean: -56.639328\n",
      "ep 7: ep_len:500 episode reward: total was -23.550000. running mean: -56.308434\n",
      "ep 7: ep_len:550 episode reward: total was -23.060000. running mean: -55.975950\n",
      "ep 7: ep_len:500 episode reward: total was -13.790000. running mean: -55.554091\n",
      "ep 7: ep_len:500 episode reward: total was -29.270000. running mean: -55.291250\n",
      "ep 7: ep_len:500 episode reward: total was -33.320000. running mean: -55.071537\n",
      "ep 7: ep_len:201 episode reward: total was 10.000000. running mean: -54.420822\n",
      "ep 7: ep_len:67 episode reward: total was 2.000000. running mean: -53.856614\n",
      "ep 7: ep_len:500 episode reward: total was -28.090000. running mean: -53.598947\n",
      "ep 7: ep_len:770 episode reward: total was -51.030000. running mean: -53.573258\n",
      "ep 7: ep_len:500 episode reward: total was -27.450000. running mean: -53.312025\n",
      "ep 7: ep_len:500 episode reward: total was -8.800000. running mean: -52.866905\n",
      "ep 7: ep_len:285 episode reward: total was -3.000000. running mean: -52.368236\n",
      "ep 7: ep_len:287 episode reward: total was 6.000000. running mean: -51.784554\n",
      "ep 7: ep_len:500 episode reward: total was -15.070000. running mean: -51.417408\n",
      "ep 7: ep_len:515 episode reward: total was -50.650000. running mean: -51.409734\n",
      "ep 7: ep_len:885 episode reward: total was -74.520000. running mean: -51.640837\n",
      "ep 7: ep_len:1040 episode reward: total was -54.150000. running mean: -51.665928\n",
      "ep 7: ep_len:595 episode reward: total was -13.550000. running mean: -51.284769\n",
      "ep 7: ep_len:500 episode reward: total was -46.550000. running mean: -51.237421\n",
      "ep 7: ep_len:505 episode reward: total was -32.360000. running mean: -51.048647\n",
      "ep 7: ep_len:525 episode reward: total was -1.800000. running mean: -50.556161\n",
      "ep 7: ep_len:595 episode reward: total was -22.990000. running mean: -50.280499\n",
      "ep 7: ep_len:500 episode reward: total was -48.570000. running mean: -50.263394\n",
      "ep 7: ep_len:740 episode reward: total was -35.840000. running mean: -50.119160\n",
      "ep 7: ep_len:138 episode reward: total was 3.000000. running mean: -49.587969\n",
      "ep 7: ep_len:500 episode reward: total was -19.550000. running mean: -49.287589\n",
      "ep 7: ep_len:1620 episode reward: total was -246.810000. running mean: -51.262813\n",
      "ep 7: ep_len:575 episode reward: total was -83.220000. running mean: -51.582385\n",
      "ep 7: ep_len:500 episode reward: total was -11.000000. running mean: -51.176561\n",
      "ep 7: ep_len:660 episode reward: total was -35.470000. running mean: -51.019495\n",
      "ep 7: ep_len:500 episode reward: total was -10.860000. running mean: -50.617901\n",
      "ep 7: ep_len:505 episode reward: total was -24.710000. running mean: -50.358822\n",
      "ep 7: ep_len:291 episode reward: total was 12.500000. running mean: -49.730233\n",
      "ep 7: ep_len:790 episode reward: total was -19.520000. running mean: -49.428131\n",
      "ep 7: ep_len:500 episode reward: total was -10.730000. running mean: -49.041150\n",
      "ep 7: ep_len:500 episode reward: total was -11.530000. running mean: -48.666038\n",
      "ep 7: ep_len:850 episode reward: total was -51.910000. running mean: -48.698478\n",
      "ep 7: ep_len:500 episode reward: total was -14.300000. running mean: -48.354493\n",
      "ep 7: ep_len:795 episode reward: total was -37.200000. running mean: -48.242948\n",
      "ep 7: ep_len:500 episode reward: total was -29.350000. running mean: -48.054019\n",
      "ep 7: ep_len:560 episode reward: total was -59.530000. running mean: -48.168778\n",
      "ep 7: ep_len:650 episode reward: total was -59.200000. running mean: -48.279091\n",
      "ep 7: ep_len:505 episode reward: total was 7.500000. running mean: -47.721300\n",
      "ep 7: ep_len:510 episode reward: total was -51.030000. running mean: -47.754387\n",
      "ep 7: ep_len:965 episode reward: total was -25.110000. running mean: -47.527943\n",
      "ep 7: ep_len:305 episode reward: total was -24.930000. running mean: -47.301963\n",
      "ep 7: ep_len:825 episode reward: total was -93.340000. running mean: -47.762344\n",
      "ep 7: ep_len:500 episode reward: total was -7.090000. running mean: -47.355620\n",
      "ep 7: ep_len:505 episode reward: total was -35.720000. running mean: -47.239264\n",
      "ep 7: ep_len:740 episode reward: total was -48.550000. running mean: -47.252371\n",
      "ep 7: ep_len:500 episode reward: total was -3.230000. running mean: -46.812148\n",
      "ep 7: ep_len:500 episode reward: total was 19.000000. running mean: -46.154026\n",
      "ep 7: ep_len:500 episode reward: total was -58.200000. running mean: -46.274486\n",
      "ep 7: ep_len:760 episode reward: total was -50.040000. running mean: -46.312141\n",
      "ep 7: ep_len:500 episode reward: total was -31.450000. running mean: -46.163520\n",
      "ep 7: ep_len:680 episode reward: total was -55.740000. running mean: -46.259285\n",
      "ep 7: ep_len:830 episode reward: total was -50.910000. running mean: -46.305792\n",
      "ep 7: ep_len:535 episode reward: total was -31.300000. running mean: -46.155734\n",
      "ep 7: ep_len:505 episode reward: total was -37.290000. running mean: -46.067076\n",
      "ep 7: ep_len:482 episode reward: total was -6.820000. running mean: -45.674606\n",
      "ep 7: ep_len:555 episode reward: total was -50.080000. running mean: -45.718660\n",
      "ep 7: ep_len:500 episode reward: total was -11.100000. running mean: -45.372473\n",
      "ep 7: ep_len:500 episode reward: total was -1.850000. running mean: -44.937248\n",
      "ep 7: ep_len:500 episode reward: total was -3.510000. running mean: -44.522976\n",
      "ep 7: ep_len:855 episode reward: total was -50.340000. running mean: -44.581146\n",
      "ep 7: ep_len:1190 episode reward: total was -183.560000. running mean: -45.970935\n",
      "ep 7: ep_len:760 episode reward: total was -43.480000. running mean: -45.946025\n",
      "ep 7: ep_len:765 episode reward: total was -38.770000. running mean: -45.874265\n",
      "ep 7: ep_len:500 episode reward: total was -81.930000. running mean: -46.234822\n",
      "ep 7: ep_len:325 episode reward: total was 13.000000. running mean: -45.642474\n",
      "ep 7: ep_len:505 episode reward: total was -4.570000. running mean: -45.231749\n",
      "ep 7: ep_len:510 episode reward: total was 5.000000. running mean: -44.729432\n",
      "ep 7: ep_len:510 episode reward: total was -18.000000. running mean: -44.462138\n",
      "ep 7: ep_len:515 episode reward: total was -24.200000. running mean: -44.259516\n",
      "ep 7: ep_len:900 episode reward: total was -68.100000. running mean: -44.497921\n",
      "ep 7: ep_len:500 episode reward: total was -45.780000. running mean: -44.510742\n",
      "ep 7: ep_len:545 episode reward: total was -55.310000. running mean: -44.618734\n",
      "ep 7: ep_len:925 episode reward: total was -72.970000. running mean: -44.902247\n",
      "ep 7: ep_len:1205 episode reward: total was -166.800000. running mean: -46.121225\n",
      "ep 7: ep_len:545 episode reward: total was -29.260000. running mean: -45.952612\n",
      "ep 7: ep_len:500 episode reward: total was -16.960000. running mean: -45.662686\n",
      "ep 7: ep_len:505 episode reward: total was -8.820000. running mean: -45.294259\n",
      "ep 7: ep_len:441 episode reward: total was -16.870000. running mean: -45.010017\n",
      "ep 7: ep_len:500 episode reward: total was -39.490000. running mean: -44.954817\n",
      "ep 7: ep_len:875 episode reward: total was -47.560000. running mean: -44.980868\n",
      "ep 7: ep_len:505 episode reward: total was -28.080000. running mean: -44.811860\n",
      "ep 7: ep_len:500 episode reward: total was -51.780000. running mean: -44.881541\n",
      "ep 7: ep_len:610 episode reward: total was -57.380000. running mean: -45.006526\n",
      "ep 7: ep_len:925 episode reward: total was -54.840000. running mean: -45.104860\n",
      "ep 7: ep_len:1055 episode reward: total was -40.030000. running mean: -45.054112\n",
      "ep 7: ep_len:580 episode reward: total was -106.470000. running mean: -45.668271\n",
      "ep 7: ep_len:925 episode reward: total was -55.980000. running mean: -45.771388\n",
      "ep 7: ep_len:615 episode reward: total was -19.070000. running mean: -45.504374\n",
      "ep 7: ep_len:500 episode reward: total was -10.300000. running mean: -45.152330\n",
      "ep 7: ep_len:500 episode reward: total was -36.560000. running mean: -45.066407\n",
      "ep 7: ep_len:605 episode reward: total was -24.100000. running mean: -44.856743\n",
      "ep 7: ep_len:1185 episode reward: total was -71.480000. running mean: -45.122976\n",
      "ep 7: ep_len:500 episode reward: total was -63.800000. running mean: -45.309746\n",
      "ep 7: ep_len:500 episode reward: total was -14.420000. running mean: -45.000848\n",
      "ep 7: ep_len:640 episode reward: total was -62.600000. running mean: -45.176840\n",
      "ep 7: ep_len:1420 episode reward: total was -221.180000. running mean: -46.936872\n",
      "ep 7: ep_len:505 episode reward: total was -5.230000. running mean: -46.519803\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 7: ep_len:224 episode reward: total was -10.900000. running mean: -46.163605\n",
      "ep 7: ep_len:665 episode reward: total was -24.510000. running mean: -45.947069\n",
      "ep 7: ep_len:505 episode reward: total was -60.330000. running mean: -46.090898\n",
      "ep 7: ep_len:785 episode reward: total was -65.110000. running mean: -46.281089\n",
      "ep 7: ep_len:1010 episode reward: total was -43.770000. running mean: -46.255978\n",
      "ep 7: ep_len:655 episode reward: total was -38.130000. running mean: -46.174718\n",
      "ep 7: ep_len:895 episode reward: total was -57.370000. running mean: -46.286671\n",
      "ep 7: ep_len:520 episode reward: total was -47.510000. running mean: -46.298905\n",
      "ep 7: ep_len:500 episode reward: total was -16.320000. running mean: -45.999115\n",
      "ep 7: ep_len:690 episode reward: total was -33.880000. running mean: -45.877924\n",
      "ep 7: ep_len:785 episode reward: total was -62.110000. running mean: -46.040245\n",
      "ep 7: ep_len:630 episode reward: total was -38.150000. running mean: -45.961343\n",
      "ep 7: ep_len:925 episode reward: total was -63.360000. running mean: -46.135329\n",
      "ep 7: ep_len:635 episode reward: total was -66.940000. running mean: -46.343376\n",
      "ep 7: ep_len:510 episode reward: total was -36.890000. running mean: -46.248842\n",
      "ep 7: ep_len:118 episode reward: total was -1.000000. running mean: -45.796354\n",
      "ep 7: ep_len:500 episode reward: total was -10.510000. running mean: -45.443490\n",
      "ep 7: ep_len:505 episode reward: total was -16.310000. running mean: -45.152155\n",
      "ep 7: ep_len:505 episode reward: total was -18.250000. running mean: -44.883134\n",
      "ep 7: ep_len:500 episode reward: total was -22.430000. running mean: -44.658602\n",
      "ep 7: ep_len:620 episode reward: total was -60.910000. running mean: -44.821116\n",
      "ep 7: ep_len:500 episode reward: total was -55.610000. running mean: -44.929005\n",
      "ep 7: ep_len:505 episode reward: total was -21.900000. running mean: -44.698715\n",
      "ep 7: ep_len:745 episode reward: total was -43.030000. running mean: -44.682028\n",
      "ep 7: ep_len:156 episode reward: total was 3.500000. running mean: -44.200208\n",
      "ep 7: ep_len:570 episode reward: total was -42.830000. running mean: -44.186506\n",
      "ep 7: ep_len:500 episode reward: total was -9.750000. running mean: -43.842141\n",
      "ep 7: ep_len:500 episode reward: total was -52.720000. running mean: -43.930919\n",
      "ep 7: ep_len:254 episode reward: total was 8.500000. running mean: -43.406610\n",
      "ep 7: ep_len:625 episode reward: total was -57.870000. running mean: -43.551244\n",
      "ep 7: ep_len:147 episode reward: total was 4.000000. running mean: -43.075731\n",
      "ep 7: ep_len:690 episode reward: total was -40.080000. running mean: -43.045774\n",
      "ep 7: ep_len:500 episode reward: total was -3.790000. running mean: -42.653216\n",
      "ep 7: ep_len:500 episode reward: total was -16.770000. running mean: -42.394384\n",
      "ep 7: ep_len:505 episode reward: total was -23.690000. running mean: -42.207340\n",
      "ep 7: ep_len:555 episode reward: total was -36.310000. running mean: -42.148367\n",
      "ep 7: ep_len:500 episode reward: total was -15.930000. running mean: -41.886183\n",
      "ep 7: ep_len:178 episode reward: total was 3.000000. running mean: -41.437321\n",
      "ep 7: ep_len:500 episode reward: total was -6.810000. running mean: -41.091048\n",
      "ep 7: ep_len:730 episode reward: total was -39.170000. running mean: -41.071838\n",
      "ep 7: ep_len:535 episode reward: total was -25.240000. running mean: -40.913519\n",
      "ep 7: ep_len:500 episode reward: total was -41.240000. running mean: -40.916784\n",
      "ep 7: ep_len:500 episode reward: total was -11.360000. running mean: -40.621216\n",
      "ep 7: ep_len:92 episode reward: total was -2.000000. running mean: -40.235004\n",
      "ep 7: ep_len:363 episode reward: total was -9.420000. running mean: -39.926854\n",
      "ep 7: ep_len:630 episode reward: total was -35.640000. running mean: -39.883986\n",
      "ep 7: ep_len:284 episode reward: total was 4.500000. running mean: -39.440146\n",
      "ep 7: ep_len:500 episode reward: total was -32.990000. running mean: -39.375644\n",
      "ep 7: ep_len:8795 episode reward: total was -1547.680000. running mean: -54.458688\n",
      "ep 7: ep_len:810 episode reward: total was -56.000000. running mean: -54.474101\n",
      "ep 7: ep_len:500 episode reward: total was -23.340000. running mean: -54.162760\n",
      "ep 7: ep_len:585 episode reward: total was -47.850000. running mean: -54.099632\n",
      "ep 7: ep_len:575 episode reward: total was -39.790000. running mean: -53.956536\n",
      "ep 7: ep_len:500 episode reward: total was -25.520000. running mean: -53.672171\n",
      "ep 7: ep_len:500 episode reward: total was -20.760000. running mean: -53.343049\n",
      "ep 7: ep_len:690 episode reward: total was -22.470000. running mean: -53.034318\n",
      "ep 7: ep_len:500 episode reward: total was -33.450000. running mean: -52.838475\n",
      "ep 7: ep_len:500 episode reward: total was -35.510000. running mean: -52.665191\n",
      "ep 7: ep_len:1000 episode reward: total was -85.400000. running mean: -52.992539\n",
      "ep 7: ep_len:605 episode reward: total was -50.350000. running mean: -52.966113\n",
      "ep 7: ep_len:745 episode reward: total was -67.240000. running mean: -53.108852\n",
      "ep 7: ep_len:500 episode reward: total was -1.810000. running mean: -52.595864\n",
      "ep 7: ep_len:1120 episode reward: total was -122.040000. running mean: -53.290305\n",
      "ep 7: ep_len:590 episode reward: total was -39.760000. running mean: -53.155002\n",
      "ep 7: ep_len:500 episode reward: total was -29.360000. running mean: -52.917052\n",
      "ep 7: ep_len:580 episode reward: total was -49.390000. running mean: -52.881781\n",
      "ep 7: ep_len:695 episode reward: total was -46.100000. running mean: -52.813964\n",
      "ep 7: ep_len:505 episode reward: total was -6.740000. running mean: -52.353224\n",
      "ep 7: ep_len:505 episode reward: total was -9.340000. running mean: -51.923092\n",
      "ep 7: ep_len:605 episode reward: total was -93.750000. running mean: -52.341361\n",
      "ep 7: ep_len:500 episode reward: total was -9.050000. running mean: -51.908447\n",
      "ep 7: ep_len:750 episode reward: total was -30.290000. running mean: -51.692263\n",
      "ep 7: ep_len:510 episode reward: total was -58.250000. running mean: -51.757840\n",
      "ep 7: ep_len:41 episode reward: total was -6.500000. running mean: -51.305262\n",
      "ep 7: ep_len:500 episode reward: total was -10.790000. running mean: -50.900109\n",
      "ep 7: ep_len:550 episode reward: total was -26.710000. running mean: -50.658208\n",
      "ep 7: ep_len:505 episode reward: total was -27.800000. running mean: -50.429626\n",
      "ep 7: ep_len:500 episode reward: total was -26.720000. running mean: -50.192530\n",
      "ep 7: ep_len:1395 episode reward: total was -193.470000. running mean: -51.625304\n",
      "ep 7: ep_len:805 episode reward: total was -34.350000. running mean: -51.452551\n",
      "ep 7: ep_len:660 episode reward: total was -35.580000. running mean: -51.293826\n",
      "ep 7: ep_len:795 episode reward: total was -43.390000. running mean: -51.214788\n",
      "ep 7: ep_len:900 episode reward: total was -42.720000. running mean: -51.129840\n",
      "ep 7: ep_len:500 episode reward: total was -0.320000. running mean: -50.621741\n",
      "ep 7: ep_len:675 episode reward: total was -36.200000. running mean: -50.477524\n",
      "ep 7: ep_len:1740 episode reward: total was -247.620000. running mean: -52.448949\n",
      "ep 7: ep_len:685 episode reward: total was -55.430000. running mean: -52.478759\n",
      "ep 7: ep_len:505 episode reward: total was -5.910000. running mean: -52.013072\n",
      "ep 7: ep_len:760 episode reward: total was -39.910000. running mean: -51.892041\n",
      "ep 7: ep_len:500 episode reward: total was -37.030000. running mean: -51.743420\n",
      "ep 7: ep_len:575 episode reward: total was -38.260000. running mean: -51.608586\n",
      "ep 7: ep_len:500 episode reward: total was -18.210000. running mean: -51.274600\n",
      "ep 7: ep_len:745 episode reward: total was -55.610000. running mean: -51.317954\n",
      "ep 7: ep_len:775 episode reward: total was -89.400000. running mean: -51.698775\n",
      "ep 7: ep_len:970 episode reward: total was -44.650000. running mean: -51.628287\n",
      "ep 7: ep_len:570 episode reward: total was -26.690000. running mean: -51.378904\n",
      "ep 7: ep_len:660 episode reward: total was -38.120000. running mean: -51.246315\n",
      "ep 7: ep_len:372 episode reward: total was 8.000000. running mean: -50.653852\n",
      "ep 7: ep_len:500 episode reward: total was -19.820000. running mean: -50.345513\n",
      "ep 7: ep_len:396 episode reward: total was 13.000000. running mean: -49.712058\n",
      "ep 7: ep_len:500 episode reward: total was 1.710000. running mean: -49.197838\n",
      "ep 7: ep_len:995 episode reward: total was -33.890000. running mean: -49.044759\n",
      "ep 7: ep_len:505 episode reward: total was -41.610000. running mean: -48.970412\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 7: ep_len:505 episode reward: total was -50.180000. running mean: -48.982508\n",
      "ep 7: ep_len:183 episode reward: total was 8.000000. running mean: -48.412683\n",
      "ep 7: ep_len:500 episode reward: total was -50.070000. running mean: -48.429256\n",
      "ep 7: ep_len:500 episode reward: total was -4.340000. running mean: -47.988363\n",
      "ep 7: ep_len:500 episode reward: total was -22.890000. running mean: -47.737380\n",
      "ep 7: ep_len:180 episode reward: total was 3.500000. running mean: -47.225006\n",
      "ep 7: ep_len:500 episode reward: total was -9.290000. running mean: -46.845656\n",
      "ep 7: ep_len:436 episode reward: total was -13.270000. running mean: -46.509899\n",
      "ep 7: ep_len:520 episode reward: total was -89.390000. running mean: -46.938700\n",
      "ep 7: ep_len:535 episode reward: total was -56.550000. running mean: -47.034813\n",
      "ep 7: ep_len:565 episode reward: total was -46.880000. running mean: -47.033265\n",
      "ep 7: ep_len:565 episode reward: total was -26.000000. running mean: -46.822932\n",
      "ep 7: ep_len:660 episode reward: total was -45.190000. running mean: -46.806603\n",
      "ep 7: ep_len:2671 episode reward: total was -406.280000. running mean: -50.401337\n",
      "ep 7: ep_len:710 episode reward: total was -33.500000. running mean: -50.232324\n",
      "ep 7: ep_len:505 episode reward: total was -4.000000. running mean: -49.770000\n",
      "ep 7: ep_len:790 episode reward: total was -56.340000. running mean: -49.835700\n",
      "ep 7: ep_len:500 episode reward: total was -40.030000. running mean: -49.737643\n",
      "ep 7: ep_len:505 episode reward: total was -25.590000. running mean: -49.496167\n",
      "ep 7: ep_len:680 episode reward: total was -80.500000. running mean: -49.806205\n",
      "ep 7: ep_len:472 episode reward: total was -21.000000. running mean: -49.518143\n",
      "ep 7: ep_len:875 episode reward: total was -28.490000. running mean: -49.307862\n",
      "epsilon:0.277267 episode_count: 6294. steps_count: 4547232.000000\n",
      "ep 8: ep_len:1750 episode reward: total was -237.450000. running mean: -51.189283\n",
      "ep 8: ep_len:835 episode reward: total was -54.940000. running mean: -51.226790\n",
      "ep 8: ep_len:500 episode reward: total was -20.990000. running mean: -50.924422\n",
      "ep 8: ep_len:545 episode reward: total was -61.550000. running mean: -51.030678\n",
      "ep 8: ep_len:525 episode reward: total was -39.370000. running mean: -50.914071\n",
      "ep 8: ep_len:950 episode reward: total was -92.080000. running mean: -51.325731\n",
      "ep 8: ep_len:500 episode reward: total was -30.630000. running mean: -51.118773\n",
      "ep 8: ep_len:500 episode reward: total was -30.880000. running mean: -50.916386\n",
      "ep 8: ep_len:835 episode reward: total was -50.900000. running mean: -50.916222\n",
      "ep 8: ep_len:500 episode reward: total was -17.470000. running mean: -50.581760\n",
      "ep 8: ep_len:500 episode reward: total was -21.970000. running mean: -50.295642\n",
      "ep 8: ep_len:670 episode reward: total was -40.120000. running mean: -50.193886\n",
      "ep 8: ep_len:500 episode reward: total was -40.060000. running mean: -50.092547\n",
      "ep 8: ep_len:925 episode reward: total was -69.910000. running mean: -50.290721\n",
      "ep 8: ep_len:825 episode reward: total was -52.940000. running mean: -50.317214\n",
      "ep 8: ep_len:500 episode reward: total was -10.350000. running mean: -49.917542\n",
      "ep 8: ep_len:745 episode reward: total was -18.050000. running mean: -49.598867\n",
      "ep 8: ep_len:505 episode reward: total was -10.230000. running mean: -49.205178\n",
      "ep 8: ep_len:590 episode reward: total was -38.230000. running mean: -49.095426\n",
      "ep 8: ep_len:505 episode reward: total was 4.180000. running mean: -48.562672\n",
      "ep 8: ep_len:1435 episode reward: total was -148.160000. running mean: -49.558645\n",
      "ep 8: ep_len:232 episode reward: total was 4.000000. running mean: -49.023059\n",
      "ep 8: ep_len:1000 episode reward: total was -97.000000. running mean: -49.502828\n",
      "ep 8: ep_len:1635 episode reward: total was -258.420000. running mean: -51.592000\n",
      "ep 8: ep_len:500 episode reward: total was -18.540000. running mean: -51.261480\n",
      "ep 8: ep_len:505 episode reward: total was -36.570000. running mean: -51.114565\n",
      "ep 8: ep_len:550 episode reward: total was -30.260000. running mean: -50.906019\n",
      "ep 8: ep_len:15340 episode reward: total was -2735.480000. running mean: -77.751759\n",
      "ep 8: ep_len:820 episode reward: total was -37.340000. running mean: -77.347642\n",
      "ep 8: ep_len:765 episode reward: total was -25.720000. running mean: -76.831365\n",
      "ep 8: ep_len:505 episode reward: total was -26.050000. running mean: -76.323551\n",
      "ep 8: ep_len:500 episode reward: total was -2.310000. running mean: -75.583416\n",
      "ep 8: ep_len:500 episode reward: total was -55.700000. running mean: -75.384582\n",
      "ep 8: ep_len:358 episode reward: total was -10.910000. running mean: -74.739836\n",
      "ep 8: ep_len:500 episode reward: total was -11.820000. running mean: -74.110638\n",
      "ep 8: ep_len:790 episode reward: total was -36.600000. running mean: -73.735531\n",
      "ep 8: ep_len:630 episode reward: total was -56.910000. running mean: -73.567276\n",
      "ep 8: ep_len:500 episode reward: total was -30.480000. running mean: -73.136403\n",
      "ep 8: ep_len:500 episode reward: total was -15.530000. running mean: -72.560339\n",
      "ep 8: ep_len:890 episode reward: total was -25.200000. running mean: -72.086736\n",
      "ep 8: ep_len:281 episode reward: total was 14.500000. running mean: -71.220868\n",
      "ep 8: ep_len:500 episode reward: total was -32.380000. running mean: -70.832460\n",
      "ep 8: ep_len:745 episode reward: total was -27.380000. running mean: -70.397935\n",
      "ep 8: ep_len:500 episode reward: total was -25.360000. running mean: -69.947556\n",
      "ep 8: ep_len:500 episode reward: total was -22.400000. running mean: -69.472080\n",
      "ep 8: ep_len:500 episode reward: total was -22.920000. running mean: -69.006559\n",
      "ep 8: ep_len:800 episode reward: total was -39.580000. running mean: -68.712294\n",
      "ep 8: ep_len:1210 episode reward: total was -71.490000. running mean: -68.740071\n",
      "ep 8: ep_len:266 episode reward: total was 10.000000. running mean: -67.952670\n",
      "ep 8: ep_len:500 episode reward: total was -20.840000. running mean: -67.481543\n",
      "ep 8: ep_len:129 episode reward: total was 1.000000. running mean: -66.796728\n",
      "ep 8: ep_len:500 episode reward: total was -51.290000. running mean: -66.641661\n",
      "ep 8: ep_len:505 episode reward: total was -67.310000. running mean: -66.648344\n",
      "ep 8: ep_len:505 episode reward: total was -26.900000. running mean: -66.250861\n",
      "ep 8: ep_len:975 episode reward: total was -32.060000. running mean: -65.908952\n",
      "ep 8: ep_len:96 episode reward: total was 1.000000. running mean: -65.239863\n",
      "ep 8: ep_len:500 episode reward: total was -5.830000. running mean: -64.645764\n",
      "ep 8: ep_len:500 episode reward: total was -26.390000. running mean: -64.263206\n",
      "ep 8: ep_len:500 episode reward: total was -38.220000. running mean: -64.002774\n",
      "ep 8: ep_len:413 episode reward: total was 16.500000. running mean: -63.197746\n",
      "ep 8: ep_len:1275 episode reward: total was -225.760000. running mean: -64.823369\n",
      "ep 8: ep_len:570 episode reward: total was -21.130000. running mean: -64.386435\n",
      "ep 8: ep_len:880 episode reward: total was -36.230000. running mean: -64.104871\n",
      "ep 8: ep_len:154 episode reward: total was 7.500000. running mean: -63.388822\n",
      "ep 8: ep_len:605 episode reward: total was -57.950000. running mean: -63.334434\n",
      "ep 8: ep_len:515 episode reward: total was -60.630000. running mean: -63.307390\n",
      "ep 8: ep_len:1140 episode reward: total was -162.980000. running mean: -64.304116\n",
      "ep 8: ep_len:590 episode reward: total was -36.210000. running mean: -64.023175\n",
      "ep 8: ep_len:500 episode reward: total was -9.810000. running mean: -63.481043\n",
      "ep 8: ep_len:675 episode reward: total was -45.160000. running mean: -63.297832\n",
      "ep 8: ep_len:387 episode reward: total was 14.500000. running mean: -62.519854\n",
      "ep 8: ep_len:505 episode reward: total was -55.110000. running mean: -62.445756\n",
      "ep 8: ep_len:860 episode reward: total was -24.190000. running mean: -62.063198\n",
      "ep 8: ep_len:700 episode reward: total was -45.610000. running mean: -61.898666\n",
      "ep 8: ep_len:560 episode reward: total was -74.160000. running mean: -62.021279\n",
      "ep 8: ep_len:500 episode reward: total was -9.870000. running mean: -61.499767\n",
      "ep 8: ep_len:500 episode reward: total was -53.620000. running mean: -61.420969\n",
      "ep 8: ep_len:500 episode reward: total was -43.300000. running mean: -61.239759\n",
      "ep 8: ep_len:500 episode reward: total was -62.860000. running mean: -61.255962\n",
      "ep 8: ep_len:895 episode reward: total was -45.260000. running mean: -61.096002\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 8: ep_len:505 episode reward: total was -15.340000. running mean: -60.638442\n",
      "ep 8: ep_len:650 episode reward: total was -51.270000. running mean: -60.544758\n",
      "ep 8: ep_len:500 episode reward: total was -28.890000. running mean: -60.228210\n",
      "ep 8: ep_len:500 episode reward: total was -12.260000. running mean: -59.748528\n",
      "ep 8: ep_len:540 episode reward: total was -32.790000. running mean: -59.478943\n",
      "ep 8: ep_len:500 episode reward: total was -26.860000. running mean: -59.152753\n",
      "ep 8: ep_len:1190 episode reward: total was -124.010000. running mean: -59.801326\n",
      "ep 8: ep_len:795 episode reward: total was -35.870000. running mean: -59.562012\n",
      "ep 8: ep_len:775 episode reward: total was -129.450000. running mean: -60.260892\n",
      "ep 8: ep_len:500 episode reward: total was -15.870000. running mean: -59.816983\n",
      "ep 8: ep_len:1005 episode reward: total was -84.510000. running mean: -60.063914\n",
      "ep 8: ep_len:540 episode reward: total was -61.590000. running mean: -60.079174\n",
      "ep 8: ep_len:500 episode reward: total was -2.270000. running mean: -59.501083\n",
      "ep 8: ep_len:675 episode reward: total was -63.830000. running mean: -59.544372\n",
      "ep 8: ep_len:202 episode reward: total was 2.000000. running mean: -58.928928\n",
      "ep 8: ep_len:930 episode reward: total was -49.710000. running mean: -58.836739\n",
      "ep 8: ep_len:500 episode reward: total was -7.780000. running mean: -58.326171\n",
      "ep 8: ep_len:865 episode reward: total was -45.340000. running mean: -58.196310\n",
      "ep 8: ep_len:815 episode reward: total was -47.810000. running mean: -58.092447\n",
      "ep 8: ep_len:510 episode reward: total was -34.870000. running mean: -57.860222\n",
      "ep 8: ep_len:995 episode reward: total was -70.460000. running mean: -57.986220\n",
      "ep 8: ep_len:695 episode reward: total was -128.490000. running mean: -58.691258\n",
      "ep 8: ep_len:725 episode reward: total was -47.560000. running mean: -58.579945\n",
      "ep 8: ep_len:655 episode reward: total was -51.750000. running mean: -58.511646\n",
      "ep 8: ep_len:575 episode reward: total was -26.170000. running mean: -58.188229\n",
      "ep 8: ep_len:500 episode reward: total was -10.890000. running mean: -57.715247\n",
      "ep 8: ep_len:226 episode reward: total was -4.000000. running mean: -57.178095\n",
      "ep 8: ep_len:500 episode reward: total was -5.670000. running mean: -56.663014\n",
      "ep 8: ep_len:525 episode reward: total was -8.780000. running mean: -56.184183\n",
      "ep 8: ep_len:805 episode reward: total was -66.600000. running mean: -56.288342\n",
      "ep 8: ep_len:500 episode reward: total was -5.500000. running mean: -55.780458\n",
      "ep 8: ep_len:500 episode reward: total was -42.570000. running mean: -55.648354\n",
      "ep 8: ep_len:319 episode reward: total was 13.500000. running mean: -54.956870\n",
      "ep 8: ep_len:1135 episode reward: total was -55.910000. running mean: -54.966401\n",
      "ep 8: ep_len:565 episode reward: total was -33.180000. running mean: -54.748537\n",
      "ep 8: ep_len:780 episode reward: total was -28.620000. running mean: -54.487252\n",
      "ep 8: ep_len:1000 episode reward: total was -90.430000. running mean: -54.846679\n",
      "ep 8: ep_len:730 episode reward: total was -32.450000. running mean: -54.622713\n",
      "ep 8: ep_len:590 episode reward: total was -37.000000. running mean: -54.446486\n",
      "ep 8: ep_len:595 episode reward: total was -56.970000. running mean: -54.471721\n",
      "ep 8: ep_len:640 episode reward: total was -40.630000. running mean: -54.333303\n",
      "ep 8: ep_len:920 episode reward: total was -56.130000. running mean: -54.351270\n",
      "ep 8: ep_len:845 episode reward: total was -72.090000. running mean: -54.528658\n",
      "ep 8: ep_len:505 episode reward: total was -51.610000. running mean: -54.499471\n",
      "ep 8: ep_len:755 episode reward: total was -36.920000. running mean: -54.323676\n",
      "ep 8: ep_len:132 episode reward: total was 1.000000. running mean: -53.770440\n",
      "ep 8: ep_len:500 episode reward: total was -14.430000. running mean: -53.377035\n",
      "ep 8: ep_len:850 episode reward: total was -63.480000. running mean: -53.478065\n",
      "ep 8: ep_len:500 episode reward: total was -26.130000. running mean: -53.204584\n",
      "ep 8: ep_len:875 episode reward: total was -23.530000. running mean: -52.907838\n",
      "ep 8: ep_len:545 episode reward: total was -88.330000. running mean: -53.262060\n",
      "ep 8: ep_len:500 episode reward: total was -5.370000. running mean: -52.783139\n",
      "ep 8: ep_len:505 episode reward: total was -29.090000. running mean: -52.546208\n",
      "ep 8: ep_len:500 episode reward: total was -18.700000. running mean: -52.207746\n",
      "ep 8: ep_len:500 episode reward: total was -35.130000. running mean: -52.036969\n",
      "ep 8: ep_len:520 episode reward: total was -25.270000. running mean: -51.769299\n",
      "ep 8: ep_len:2380 episode reward: total was -403.330000. running mean: -55.284906\n",
      "ep 8: ep_len:500 episode reward: total was -11.310000. running mean: -54.845157\n",
      "ep 8: ep_len:905 episode reward: total was -51.910000. running mean: -54.815805\n",
      "ep 8: ep_len:1425 episode reward: total was -198.190000. running mean: -56.249547\n",
      "ep 8: ep_len:500 episode reward: total was -3.350000. running mean: -55.720552\n",
      "ep 8: ep_len:500 episode reward: total was -20.840000. running mean: -55.371746\n",
      "ep 8: ep_len:177 episode reward: total was 5.500000. running mean: -54.763029\n",
      "ep 8: ep_len:505 episode reward: total was 8.500000. running mean: -54.130398\n",
      "ep 8: ep_len:500 episode reward: total was -20.800000. running mean: -53.797094\n",
      "ep 8: ep_len:760 episode reward: total was -42.020000. running mean: -53.679324\n",
      "ep 8: ep_len:505 episode reward: total was -18.750000. running mean: -53.330030\n",
      "ep 8: ep_len:238 episode reward: total was 7.000000. running mean: -52.726730\n",
      "ep 8: ep_len:500 episode reward: total was -13.450000. running mean: -52.333963\n",
      "ep 8: ep_len:580 episode reward: total was -36.260000. running mean: -52.173223\n",
      "ep 8: ep_len:520 episode reward: total was -38.400000. running mean: -52.035491\n",
      "ep 8: ep_len:995 episode reward: total was -29.990000. running mean: -51.815036\n",
      "ep 8: ep_len:530 episode reward: total was -24.450000. running mean: -51.541386\n",
      "ep 8: ep_len:500 episode reward: total was -31.980000. running mean: -51.345772\n",
      "ep 8: ep_len:1015 episode reward: total was -48.960000. running mean: -51.321914\n",
      "ep 8: ep_len:500 episode reward: total was -28.950000. running mean: -51.098195\n",
      "ep 8: ep_len:865 episode reward: total was -46.830000. running mean: -51.055513\n",
      "ep 8: ep_len:500 episode reward: total was 5.200000. running mean: -50.492958\n",
      "ep 8: ep_len:555 episode reward: total was -28.230000. running mean: -50.270328\n",
      "ep 8: ep_len:500 episode reward: total was -4.850000. running mean: -49.816125\n",
      "ep 8: ep_len:500 episode reward: total was -23.990000. running mean: -49.557864\n",
      "ep 8: ep_len:1135 episode reward: total was -73.110000. running mean: -49.793385\n",
      "ep 8: ep_len:311 episode reward: total was 4.000000. running mean: -49.255451\n",
      "ep 8: ep_len:740 episode reward: total was -42.090000. running mean: -49.183797\n",
      "ep 8: ep_len:510 episode reward: total was -4.270000. running mean: -48.734659\n",
      "ep 8: ep_len:500 episode reward: total was -13.450000. running mean: -48.381812\n",
      "ep 8: ep_len:500 episode reward: total was -10.640000. running mean: -48.004394\n",
      "ep 8: ep_len:660 episode reward: total was -40.630000. running mean: -47.930650\n",
      "ep 8: ep_len:925 episode reward: total was -22.190000. running mean: -47.673244\n",
      "ep 8: ep_len:995 episode reward: total was -51.650000. running mean: -47.713011\n",
      "ep 8: ep_len:389 episode reward: total was 8.500000. running mean: -47.150881\n",
      "ep 8: ep_len:545 episode reward: total was -60.250000. running mean: -47.281872\n",
      "ep 8: ep_len:710 episode reward: total was -38.540000. running mean: -47.194453\n",
      "ep 8: ep_len:500 episode reward: total was -32.470000. running mean: -47.047209\n",
      "ep 8: ep_len:710 episode reward: total was -49.100000. running mean: -47.067737\n",
      "ep 8: ep_len:221 episode reward: total was -0.500000. running mean: -46.602059\n",
      "ep 8: ep_len:500 episode reward: total was -25.460000. running mean: -46.390639\n",
      "ep 8: ep_len:128 episode reward: total was -2.500000. running mean: -45.951732\n",
      "ep 8: ep_len:505 episode reward: total was -15.750000. running mean: -45.649715\n",
      "ep 8: ep_len:500 episode reward: total was -31.340000. running mean: -45.506618\n",
      "ep 8: ep_len:740 episode reward: total was -78.460000. running mean: -45.836152\n",
      "ep 8: ep_len:535 episode reward: total was -48.440000. running mean: -45.862190\n",
      "ep 8: ep_len:580 episode reward: total was -82.720000. running mean: -46.230768\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 8: ep_len:500 episode reward: total was -18.880000. running mean: -45.957261\n",
      "ep 8: ep_len:221 episode reward: total was 5.500000. running mean: -45.442688\n",
      "ep 8: ep_len:665 episode reward: total was -25.970000. running mean: -45.247961\n",
      "ep 8: ep_len:51 episode reward: total was 3.500000. running mean: -44.760482\n",
      "ep 8: ep_len:605 episode reward: total was -35.690000. running mean: -44.669777\n",
      "ep 8: ep_len:505 episode reward: total was -19.380000. running mean: -44.416879\n",
      "ep 8: ep_len:500 episode reward: total was -62.190000. running mean: -44.594610\n",
      "ep 8: ep_len:600 episode reward: total was -47.130000. running mean: -44.619964\n",
      "ep 8: ep_len:700 episode reward: total was -33.280000. running mean: -44.506564\n",
      "ep 8: ep_len:690 episode reward: total was -35.000000. running mean: -44.411499\n",
      "ep 8: ep_len:193 episode reward: total was 11.500000. running mean: -43.852384\n",
      "ep 8: ep_len:785 episode reward: total was -56.020000. running mean: -43.974060\n",
      "ep 8: ep_len:690 episode reward: total was -22.030000. running mean: -43.754619\n",
      "ep 8: ep_len:500 episode reward: total was -2.030000. running mean: -43.337373\n",
      "ep 8: ep_len:1670 episode reward: total was -225.060000. running mean: -45.154600\n",
      "ep 8: ep_len:500 episode reward: total was -8.800000. running mean: -44.791054\n",
      "ep 8: ep_len:605 episode reward: total was -65.500000. running mean: -44.998143\n",
      "ep 8: ep_len:1010 episode reward: total was -37.460000. running mean: -44.922762\n",
      "ep 8: ep_len:895 episode reward: total was -51.110000. running mean: -44.984634\n",
      "ep 8: ep_len:720 episode reward: total was -53.150000. running mean: -45.066288\n",
      "ep 8: ep_len:720 episode reward: total was -25.530000. running mean: -44.870925\n",
      "ep 8: ep_len:605 episode reward: total was -34.680000. running mean: -44.769015\n",
      "ep 8: ep_len:650 episode reward: total was -19.340000. running mean: -44.514725\n",
      "ep 8: ep_len:510 episode reward: total was -23.570000. running mean: -44.305278\n",
      "ep 8: ep_len:500 episode reward: total was -12.710000. running mean: -43.989325\n",
      "ep 8: ep_len:535 episode reward: total was -40.880000. running mean: -43.958232\n",
      "ep 8: ep_len:515 episode reward: total was -9.320000. running mean: -43.611850\n",
      "ep 8: ep_len:635 episode reward: total was -10.190000. running mean: -43.277631\n",
      "ep 8: ep_len:500 episode reward: total was -8.710000. running mean: -42.931955\n",
      "ep 8: ep_len:545 episode reward: total was -43.370000. running mean: -42.936335\n",
      "ep 8: ep_len:500 episode reward: total was -38.480000. running mean: -42.891772\n",
      "ep 8: ep_len:384 episode reward: total was 6.500000. running mean: -42.397854\n",
      "ep 8: ep_len:815 episode reward: total was -26.110000. running mean: -42.234976\n",
      "ep 8: ep_len:910 episode reward: total was -30.380000. running mean: -42.116426\n",
      "ep 8: ep_len:500 episode reward: total was -22.270000. running mean: -41.917962\n",
      "ep 8: ep_len:500 episode reward: total was -20.820000. running mean: -41.706982\n",
      "ep 8: ep_len:535 episode reward: total was -18.350000. running mean: -41.473412\n",
      "ep 8: ep_len:500 episode reward: total was -7.300000. running mean: -41.131678\n",
      "ep 8: ep_len:234 episode reward: total was 0.500000. running mean: -40.715361\n",
      "ep 8: ep_len:770 episode reward: total was -55.070000. running mean: -40.858908\n",
      "ep 8: ep_len:720 episode reward: total was -40.630000. running mean: -40.856619\n",
      "ep 8: ep_len:600 episode reward: total was -18.260000. running mean: -40.630652\n",
      "ep 8: ep_len:925 episode reward: total was -32.080000. running mean: -40.545146\n",
      "ep 8: ep_len:580 episode reward: total was -57.960000. running mean: -40.719295\n",
      "ep 8: ep_len:545 episode reward: total was -11.850000. running mean: -40.430602\n",
      "ep 8: ep_len:655 episode reward: total was -29.940000. running mean: -40.325696\n",
      "ep 8: ep_len:500 episode reward: total was -8.300000. running mean: -40.005439\n",
      "ep 8: ep_len:478 episode reward: total was 5.240000. running mean: -39.552984\n",
      "ep 8: ep_len:595 episode reward: total was -32.430000. running mean: -39.481754\n",
      "ep 8: ep_len:860 episode reward: total was -52.820000. running mean: -39.615137\n",
      "ep 8: ep_len:525 episode reward: total was -37.400000. running mean: -39.592985\n",
      "ep 8: ep_len:935 episode reward: total was -45.890000. running mean: -39.655956\n",
      "ep 8: ep_len:645 episode reward: total was -35.160000. running mean: -39.610996\n",
      "ep 8: ep_len:500 episode reward: total was -13.320000. running mean: -39.348086\n",
      "ep 8: ep_len:695 episode reward: total was -53.200000. running mean: -39.486605\n",
      "ep 8: ep_len:515 episode reward: total was -39.390000. running mean: -39.485639\n",
      "ep 8: ep_len:2103 episode reward: total was -303.880000. running mean: -42.129583\n",
      "ep 8: ep_len:500 episode reward: total was -17.910000. running mean: -41.887387\n",
      "ep 8: ep_len:500 episode reward: total was 17.000000. running mean: -41.298513\n",
      "ep 8: ep_len:700 episode reward: total was -37.520000. running mean: -41.260728\n",
      "ep 8: ep_len:500 episode reward: total was -50.610000. running mean: -41.354221\n",
      "ep 8: ep_len:505 episode reward: total was -32.880000. running mean: -41.269478\n",
      "ep 8: ep_len:500 episode reward: total was -29.930000. running mean: -41.156084\n",
      "ep 8: ep_len:585 episode reward: total was -57.510000. running mean: -41.319623\n",
      "ep 8: ep_len:211 episode reward: total was 9.000000. running mean: -40.816427\n",
      "ep 8: ep_len:1020 episode reward: total was -59.680000. running mean: -41.005062\n",
      "ep 8: ep_len:760 episode reward: total was -20.000000. running mean: -40.795012\n",
      "ep 8: ep_len:1050 episode reward: total was -32.440000. running mean: -40.711462\n",
      "ep 8: ep_len:505 episode reward: total was -28.570000. running mean: -40.590047\n",
      "ep 8: ep_len:610 episode reward: total was -27.810000. running mean: -40.462247\n",
      "ep 8: ep_len:505 episode reward: total was -23.350000. running mean: -40.291124\n",
      "ep 8: ep_len:500 episode reward: total was -25.300000. running mean: -40.141213\n",
      "ep 8: ep_len:505 episode reward: total was -41.890000. running mean: -40.158701\n",
      "ep 8: ep_len:1305 episode reward: total was -73.450000. running mean: -40.491614\n",
      "ep 8: ep_len:500 episode reward: total was -14.940000. running mean: -40.236098\n",
      "ep 8: ep_len:208 episode reward: total was 10.500000. running mean: -39.728737\n",
      "ep 8: ep_len:500 episode reward: total was 18.110000. running mean: -39.150349\n",
      "ep 8: ep_len:725 episode reward: total was -50.110000. running mean: -39.259946\n",
      "ep 8: ep_len:815 episode reward: total was -23.320000. running mean: -39.100546\n",
      "ep 8: ep_len:565 episode reward: total was -35.280000. running mean: -39.062341\n",
      "ep 8: ep_len:183 episode reward: total was 3.000000. running mean: -38.641717\n",
      "ep 8: ep_len:500 episode reward: total was -22.450000. running mean: -38.479800\n",
      "ep 8: ep_len:1160 episode reward: total was -48.930000. running mean: -38.584302\n",
      "ep 8: ep_len:500 episode reward: total was -26.900000. running mean: -38.467459\n",
      "ep 8: ep_len:167 episode reward: total was 1.500000. running mean: -38.067785\n",
      "ep 8: ep_len:960 episode reward: total was -38.600000. running mean: -38.073107\n",
      "ep 8: ep_len:237 episode reward: total was 1.000000. running mean: -37.682376\n",
      "ep 8: ep_len:595 episode reward: total was -30.660000. running mean: -37.612152\n",
      "ep 8: ep_len:500 episode reward: total was -12.320000. running mean: -37.359230\n",
      "ep 8: ep_len:585 episode reward: total was -45.830000. running mean: -37.443938\n",
      "ep 8: ep_len:930 episode reward: total was -145.290000. running mean: -38.522399\n",
      "ep 8: ep_len:510 episode reward: total was 15.500000. running mean: -37.982175\n",
      "ep 8: ep_len:630 episode reward: total was -25.050000. running mean: -37.852853\n",
      "ep 8: ep_len:215 episode reward: total was 5.500000. running mean: -37.419324\n",
      "ep 8: ep_len:530 episode reward: total was -28.490000. running mean: -37.330031\n",
      "ep 8: ep_len:505 episode reward: total was -18.660000. running mean: -37.143331\n",
      "ep 8: ep_len:500 episode reward: total was -27.810000. running mean: -37.049998\n",
      "ep 8: ep_len:500 episode reward: total was -23.290000. running mean: -36.912398\n",
      "ep 8: ep_len:750 episode reward: total was -34.360000. running mean: -36.886874\n",
      "ep 8: ep_len:1230 episode reward: total was -165.220000. running mean: -38.170205\n",
      "ep 8: ep_len:650 episode reward: total was -30.060000. running mean: -38.089103\n",
      "ep 8: ep_len:540 episode reward: total was -23.210000. running mean: -37.940312\n",
      "ep 8: ep_len:500 episode reward: total was -17.310000. running mean: -37.734009\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 8: ep_len:186 episode reward: total was 5.500000. running mean: -37.301669\n",
      "ep 8: ep_len:645 episode reward: total was -36.130000. running mean: -37.289952\n",
      "ep 8: ep_len:1095 episode reward: total was -101.860000. running mean: -37.935652\n",
      "ep 8: ep_len:500 episode reward: total was -30.490000. running mean: -37.861196\n",
      "ep 8: ep_len:505 episode reward: total was -9.170000. running mean: -37.574284\n",
      "ep 8: ep_len:815 episode reward: total was -37.960000. running mean: -37.578141\n",
      "ep 8: ep_len:750 episode reward: total was -74.300000. running mean: -37.945360\n",
      "ep 8: ep_len:1445 episode reward: total was -188.020000. running mean: -39.446106\n",
      "ep 8: ep_len:735 episode reward: total was -37.970000. running mean: -39.431345\n",
      "ep 8: ep_len:500 episode reward: total was 19.500000. running mean: -38.842032\n",
      "ep 8: ep_len:505 episode reward: total was -14.090000. running mean: -38.594511\n",
      "ep 8: ep_len:735 episode reward: total was -30.940000. running mean: -38.517966\n",
      "ep 8: ep_len:540 episode reward: total was -35.330000. running mean: -38.486086\n",
      "ep 8: ep_len:670 episode reward: total was -33.050000. running mean: -38.431726\n",
      "ep 8: ep_len:240 episode reward: total was 4.000000. running mean: -38.007408\n",
      "ep 8: ep_len:1005 episode reward: total was -82.360000. running mean: -38.450934\n",
      "ep 8: ep_len:500 episode reward: total was -35.930000. running mean: -38.425725\n",
      "ep 8: ep_len:500 episode reward: total was -50.250000. running mean: -38.543968\n",
      "ep 8: ep_len:500 episode reward: total was -27.540000. running mean: -38.433928\n",
      "ep 8: ep_len:214 episode reward: total was 5.000000. running mean: -37.999589\n",
      "ep 8: ep_len:580 episode reward: total was -29.680000. running mean: -37.916393\n",
      "ep 8: ep_len:1115 episode reward: total was -47.630000. running mean: -38.013529\n",
      "ep 8: ep_len:515 episode reward: total was -56.590000. running mean: -38.199294\n",
      "ep 8: ep_len:610 episode reward: total was -22.600000. running mean: -38.043301\n",
      "ep 8: ep_len:745 episode reward: total was -75.810000. running mean: -38.420968\n",
      "ep 8: ep_len:200 episode reward: total was 3.500000. running mean: -38.001758\n",
      "ep 8: ep_len:328 episode reward: total was 10.500000. running mean: -37.516740\n",
      "ep 8: ep_len:273 episode reward: total was -1.000000. running mean: -37.151573\n",
      "ep 8: ep_len:500 episode reward: total was -43.160000. running mean: -37.211657\n",
      "ep 8: ep_len:655 episode reward: total was -39.110000. running mean: -37.230641\n",
      "ep 8: ep_len:130 episode reward: total was 6.000000. running mean: -36.798334\n",
      "ep 8: ep_len:645 episode reward: total was -17.420000. running mean: -36.604551\n",
      "ep 8: ep_len:735 episode reward: total was -25.910000. running mean: -36.497605\n",
      "ep 8: ep_len:104 episode reward: total was 4.000000. running mean: -36.092629\n",
      "ep 8: ep_len:505 episode reward: total was -50.840000. running mean: -36.240103\n",
      "ep 8: ep_len:500 episode reward: total was 0.660000. running mean: -35.871102\n",
      "ep 8: ep_len:206 episode reward: total was 4.000000. running mean: -35.472391\n",
      "ep 8: ep_len:635 episode reward: total was -76.030000. running mean: -35.877967\n",
      "ep 8: ep_len:447 episode reward: total was -10.770000. running mean: -35.626887\n",
      "ep 8: ep_len:800 episode reward: total was -56.510000. running mean: -35.835719\n",
      "ep 8: ep_len:540 episode reward: total was -42.400000. running mean: -35.901361\n",
      "ep 8: ep_len:500 episode reward: total was -33.990000. running mean: -35.882248\n",
      "ep 8: ep_len:1830 episode reward: total was -240.810000. running mean: -37.931525\n",
      "ep 8: ep_len:1020 episode reward: total was -37.330000. running mean: -37.925510\n",
      "ep 8: ep_len:505 episode reward: total was -28.830000. running mean: -37.834555\n",
      "ep 8: ep_len:505 episode reward: total was -1.310000. running mean: -37.469309\n",
      "ep 8: ep_len:615 episode reward: total was -58.410000. running mean: -37.678716\n",
      "ep 8: ep_len:500 episode reward: total was -25.480000. running mean: -37.556729\n",
      "ep 8: ep_len:1505 episode reward: total was -224.800000. running mean: -39.429162\n",
      "ep 8: ep_len:1315 episode reward: total was -71.830000. running mean: -39.753170\n",
      "ep 8: ep_len:500 episode reward: total was -28.360000. running mean: -39.639239\n",
      "ep 8: ep_len:885 episode reward: total was -58.860000. running mean: -39.831446\n",
      "ep 8: ep_len:275 episode reward: total was 8.000000. running mean: -39.353132\n",
      "ep 8: ep_len:740 episode reward: total was -30.400000. running mean: -39.263600\n",
      "ep 8: ep_len:505 episode reward: total was -23.540000. running mean: -39.106364\n",
      "ep 8: ep_len:945 episode reward: total was -20.890000. running mean: -38.924201\n",
      "ep 8: ep_len:500 episode reward: total was 4.250000. running mean: -38.492459\n",
      "ep 8: ep_len:500 episode reward: total was -10.950000. running mean: -38.217034\n",
      "ep 8: ep_len:500 episode reward: total was -5.820000. running mean: -37.893064\n",
      "ep 8: ep_len:505 episode reward: total was -9.900000. running mean: -37.613133\n",
      "ep 8: ep_len:1065 episode reward: total was -67.610000. running mean: -37.913102\n",
      "ep 8: ep_len:540 episode reward: total was -48.460000. running mean: -38.018571\n",
      "ep 8: ep_len:955 episode reward: total was -100.150000. running mean: -38.639885\n",
      "ep 8: ep_len:640 episode reward: total was -15.760000. running mean: -38.411086\n",
      "ep 8: ep_len:915 episode reward: total was -30.170000. running mean: -38.328675\n",
      "ep 8: ep_len:720 episode reward: total was -67.780000. running mean: -38.623189\n",
      "ep 8: ep_len:1035 episode reward: total was -176.280000. running mean: -39.999757\n",
      "ep 8: ep_len:815 episode reward: total was -59.730000. running mean: -40.197059\n",
      "ep 8: ep_len:500 episode reward: total was -7.360000. running mean: -39.868689\n",
      "ep 8: ep_len:605 episode reward: total was -18.620000. running mean: -39.656202\n",
      "ep 8: ep_len:505 episode reward: total was -34.370000. running mean: -39.603340\n",
      "ep 8: ep_len:146 episode reward: total was 10.000000. running mean: -39.107306\n",
      "ep 8: ep_len:231 episode reward: total was 5.000000. running mean: -38.666233\n",
      "ep 8: ep_len:685 episode reward: total was -89.580000. running mean: -39.175371\n",
      "ep 8: ep_len:500 episode reward: total was -4.760000. running mean: -38.831217\n",
      "ep 8: ep_len:1040 episode reward: total was -94.860000. running mean: -39.391505\n",
      "ep 8: ep_len:685 episode reward: total was -21.750000. running mean: -39.215090\n",
      "ep 8: ep_len:500 episode reward: total was -5.280000. running mean: -38.875739\n",
      "ep 8: ep_len:580 episode reward: total was -10.930000. running mean: -38.596282\n",
      "ep 8: ep_len:228 episode reward: total was 8.000000. running mean: -38.130319\n",
      "ep 8: ep_len:500 episode reward: total was -14.640000. running mean: -37.895416\n",
      "ep 8: ep_len:655 episode reward: total was -19.960000. running mean: -37.716062\n",
      "ep 8: ep_len:347 episode reward: total was -2.290000. running mean: -37.361801\n",
      "ep 8: ep_len:500 episode reward: total was -25.980000. running mean: -37.247983\n",
      "ep 8: ep_len:575 episode reward: total was -59.500000. running mean: -37.470503\n",
      "ep 8: ep_len:505 episode reward: total was -25.680000. running mean: -37.352598\n",
      "ep 8: ep_len:640 episode reward: total was -14.460000. running mean: -37.123672\n",
      "ep 8: ep_len:142 episode reward: total was 4.000000. running mean: -36.712435\n",
      "ep 8: ep_len:565 episode reward: total was -27.410000. running mean: -36.619411\n",
      "ep 8: ep_len:1355 episode reward: total was -141.350000. running mean: -37.666717\n",
      "ep 8: ep_len:500 episode reward: total was -4.820000. running mean: -37.338250\n",
      "ep 8: ep_len:500 episode reward: total was -19.490000. running mean: -37.159767\n",
      "ep 8: ep_len:765 episode reward: total was -46.510000. running mean: -37.253270\n",
      "ep 8: ep_len:143 episode reward: total was -19.000000. running mean: -37.070737\n",
      "ep 8: ep_len:1615 episode reward: total was -173.570000. running mean: -38.435729\n",
      "ep 8: ep_len:995 episode reward: total was -82.380000. running mean: -38.875172\n",
      "ep 8: ep_len:245 episode reward: total was 5.500000. running mean: -38.431420\n",
      "ep 8: ep_len:505 episode reward: total was -7.290000. running mean: -38.120006\n",
      "ep 8: ep_len:570 episode reward: total was -30.190000. running mean: -38.040706\n",
      "ep 8: ep_len:266 episode reward: total was 4.500000. running mean: -37.615299\n",
      "ep 8: ep_len:810 episode reward: total was -33.430000. running mean: -37.573446\n",
      "ep 8: ep_len:505 episode reward: total was -42.390000. running mean: -37.621612\n",
      "ep 8: ep_len:680 episode reward: total was -42.320000. running mean: -37.668596\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 8: ep_len:505 episode reward: total was -31.320000. running mean: -37.605110\n",
      "ep 8: ep_len:2155 episode reward: total was -202.350000. running mean: -39.252558\n",
      "ep 8: ep_len:640 episode reward: total was -29.950000. running mean: -39.159533\n",
      "ep 8: ep_len:940 episode reward: total was -46.480000. running mean: -39.232738\n",
      "ep 8: ep_len:1550 episode reward: total was -136.840000. running mean: -40.208810\n",
      "ep 8: ep_len:500 episode reward: total was -50.530000. running mean: -40.312022\n",
      "ep 8: ep_len:705 episode reward: total was -63.770000. running mean: -40.546602\n",
      "ep 8: ep_len:940 episode reward: total was -38.470000. running mean: -40.525836\n",
      "ep 8: ep_len:500 episode reward: total was 15.500000. running mean: -39.965578\n",
      "ep 8: ep_len:1090 episode reward: total was -95.810000. running mean: -40.524022\n",
      "ep 8: ep_len:1095 episode reward: total was -58.100000. running mean: -40.699782\n",
      "ep 8: ep_len:1705 episode reward: total was -123.900000. running mean: -41.531784\n",
      "ep 8: ep_len:157 episode reward: total was 8.500000. running mean: -41.031466\n",
      "ep 8: ep_len:500 episode reward: total was -15.850000. running mean: -40.779651\n",
      "ep 8: ep_len:905 episode reward: total was -89.140000. running mean: -41.263255\n",
      "ep 8: ep_len:525 episode reward: total was -46.470000. running mean: -41.315322\n",
      "ep 8: ep_len:860 episode reward: total was -68.110000. running mean: -41.583269\n",
      "ep 8: ep_len:500 episode reward: total was -18.900000. running mean: -41.356436\n",
      "ep 8: ep_len:860 episode reward: total was -50.070000. running mean: -41.443572\n",
      "ep 8: ep_len:187 episode reward: total was 4.000000. running mean: -40.989136\n",
      "ep 8: ep_len:505 episode reward: total was -9.470000. running mean: -40.673945\n",
      "ep 8: ep_len:765 episode reward: total was -44.980000. running mean: -40.717005\n",
      "ep 8: ep_len:780 episode reward: total was -24.060000. running mean: -40.550435\n",
      "ep 8: ep_len:500 episode reward: total was -37.460000. running mean: -40.519531\n",
      "ep 8: ep_len:915 episode reward: total was -84.620000. running mean: -40.960536\n",
      "ep 8: ep_len:500 episode reward: total was -14.050000. running mean: -40.691430\n",
      "ep 8: ep_len:1845 episode reward: total was -147.400000. running mean: -41.758516\n",
      "ep 8: ep_len:1380 episode reward: total was -80.100000. running mean: -42.141931\n",
      "ep 8: ep_len:663 episode reward: total was -107.270000. running mean: -42.793212\n",
      "ep 8: ep_len:210 episode reward: total was 3.510000. running mean: -42.330179\n",
      "ep 8: ep_len:273 episode reward: total was 16.500000. running mean: -41.741878\n",
      "ep 8: ep_len:500 episode reward: total was -13.630000. running mean: -41.460759\n",
      "ep 8: ep_len:500 episode reward: total was -28.640000. running mean: -41.332551\n",
      "ep 8: ep_len:505 episode reward: total was -26.550000. running mean: -41.184726\n",
      "ep 8: ep_len:196 episode reward: total was 9.000000. running mean: -40.682878\n",
      "ep 8: ep_len:500 episode reward: total was -35.380000. running mean: -40.629850\n",
      "ep 8: ep_len:850 episode reward: total was -39.370000. running mean: -40.617251\n",
      "ep 8: ep_len:770 episode reward: total was -45.980000. running mean: -40.670879\n",
      "ep 8: ep_len:980 episode reward: total was -40.990000. running mean: -40.674070\n",
      "ep 8: ep_len:1090 episode reward: total was -108.970000. running mean: -41.357029\n",
      "ep 8: ep_len:1480 episode reward: total was -202.610000. running mean: -42.969559\n",
      "ep 8: ep_len:510 episode reward: total was -2.320000. running mean: -42.563063\n",
      "ep 8: ep_len:500 episode reward: total was -55.660000. running mean: -42.694033\n",
      "ep 8: ep_len:1075 episode reward: total was -88.890000. running mean: -43.155992\n",
      "ep 8: ep_len:500 episode reward: total was -13.780000. running mean: -42.862232\n",
      "ep 8: ep_len:1075 episode reward: total was -90.300000. running mean: -43.336610\n",
      "ep 8: ep_len:1940 episode reward: total was -195.140000. running mean: -44.854644\n",
      "ep 8: ep_len:500 episode reward: total was -33.880000. running mean: -44.744898\n",
      "ep 8: ep_len:735 episode reward: total was -48.560000. running mean: -44.783049\n",
      "ep 8: ep_len:720 episode reward: total was -35.910000. running mean: -44.694318\n",
      "ep 8: ep_len:835 episode reward: total was -56.960000. running mean: -44.816975\n",
      "ep 8: ep_len:510 episode reward: total was -22.860000. running mean: -44.597405\n",
      "ep 8: ep_len:302 episode reward: total was 6.500000. running mean: -44.086431\n",
      "ep 8: ep_len:500 episode reward: total was -31.890000. running mean: -43.964467\n",
      "ep 8: ep_len:500 episode reward: total was -27.570000. running mean: -43.800522\n",
      "ep 8: ep_len:845 episode reward: total was -61.990000. running mean: -43.982417\n",
      "ep 8: ep_len:755 episode reward: total was -54.060000. running mean: -44.083193\n",
      "ep 8: ep_len:500 episode reward: total was -12.350000. running mean: -43.765861\n",
      "ep 8: ep_len:550 episode reward: total was -25.180000. running mean: -43.580002\n",
      "ep 8: ep_len:810 episode reward: total was -56.490000. running mean: -43.709102\n",
      "ep 8: ep_len:770 episode reward: total was -45.460000. running mean: -43.726611\n",
      "ep 8: ep_len:474 episode reward: total was -1.320000. running mean: -43.302545\n",
      "ep 8: ep_len:540 episode reward: total was -35.820000. running mean: -43.227720\n",
      "ep 8: ep_len:510 episode reward: total was -57.090000. running mean: -43.366342\n",
      "ep 8: ep_len:510 episode reward: total was -15.820000. running mean: -43.090879\n",
      "ep 8: ep_len:540 episode reward: total was -29.200000. running mean: -42.951970\n",
      "ep 8: ep_len:586 episode reward: total was -94.810000. running mean: -43.470550\n",
      "ep 8: ep_len:500 episode reward: total was -8.340000. running mean: -43.119245\n",
      "ep 8: ep_len:500 episode reward: total was 4.740000. running mean: -42.640653\n",
      "ep 8: ep_len:855 episode reward: total was -32.730000. running mean: -42.541546\n",
      "ep 8: ep_len:600 episode reward: total was -45.310000. running mean: -42.569231\n",
      "ep 8: ep_len:500 episode reward: total was -23.810000. running mean: -42.381638\n",
      "ep 8: ep_len:650 episode reward: total was -32.080000. running mean: -42.278622\n",
      "ep 8: ep_len:500 episode reward: total was -5.800000. running mean: -41.913836\n",
      "ep 8: ep_len:765 episode reward: total was -57.100000. running mean: -42.065697\n",
      "ep 8: ep_len:700 episode reward: total was -31.060000. running mean: -41.955640\n",
      "ep 8: ep_len:610 episode reward: total was -36.170000. running mean: -41.897784\n",
      "ep 8: ep_len:505 episode reward: total was -16.330000. running mean: -41.642106\n",
      "ep 8: ep_len:550 episode reward: total was -22.350000. running mean: -41.449185\n",
      "ep 8: ep_len:645 episode reward: total was -44.830000. running mean: -41.482993\n",
      "ep 8: ep_len:510 episode reward: total was -22.740000. running mean: -41.295563\n",
      "ep 8: ep_len:610 episode reward: total was -19.070000. running mean: -41.073308\n",
      "ep 8: ep_len:635 episode reward: total was -35.870000. running mean: -41.021275\n",
      "ep 8: ep_len:500 episode reward: total was -26.960000. running mean: -40.880662\n",
      "ep 8: ep_len:550 episode reward: total was -43.390000. running mean: -40.905755\n",
      "ep 8: ep_len:535 episode reward: total was -31.300000. running mean: -40.809698\n",
      "ep 8: ep_len:590 episode reward: total was -58.500000. running mean: -40.986601\n",
      "ep 8: ep_len:575 episode reward: total was -52.640000. running mean: -41.103135\n",
      "ep 8: ep_len:610 episode reward: total was -44.560000. running mean: -41.137703\n",
      "ep 8: ep_len:965 episode reward: total was -48.270000. running mean: -41.209026\n",
      "ep 8: ep_len:500 episode reward: total was -17.040000. running mean: -40.967336\n",
      "ep 8: ep_len:505 episode reward: total was -25.310000. running mean: -40.810763\n",
      "ep 8: ep_len:237 episode reward: total was -21.500000. running mean: -40.617655\n",
      "ep 8: ep_len:170 episode reward: total was 0.010000. running mean: -40.211378\n",
      "ep 8: ep_len:500 episode reward: total was 17.500000. running mean: -39.634265\n",
      "ep 8: ep_len:760 episode reward: total was -41.960000. running mean: -39.657522\n",
      "ep 8: ep_len:505 episode reward: total was -28.390000. running mean: -39.544847\n",
      "ep 8: ep_len:535 episode reward: total was -27.260000. running mean: -39.421998\n",
      "ep 8: ep_len:500 episode reward: total was 22.000000. running mean: -38.807778\n",
      "ep 8: ep_len:730 episode reward: total was -21.980000. running mean: -38.639501\n",
      "ep 8: ep_len:1015 episode reward: total was -46.610000. running mean: -38.719206\n",
      "ep 8: ep_len:500 episode reward: total was -2.780000. running mean: -38.359813\n",
      "ep 8: ep_len:500 episode reward: total was -32.650000. running mean: -38.302715\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 8: ep_len:725 episode reward: total was -65.260000. running mean: -38.572288\n",
      "ep 8: ep_len:1005 episode reward: total was -54.600000. running mean: -38.732565\n",
      "ep 8: ep_len:650 episode reward: total was -60.360000. running mean: -38.948840\n",
      "ep 8: ep_len:505 episode reward: total was -19.080000. running mean: -38.750151\n",
      "ep 8: ep_len:483 episode reward: total was -22.870000. running mean: -38.591350\n",
      "ep 8: ep_len:500 episode reward: total was -27.740000. running mean: -38.482836\n",
      "ep 8: ep_len:500 episode reward: total was -19.110000. running mean: -38.289108\n",
      "ep 8: ep_len:785 episode reward: total was -78.760000. running mean: -38.693817\n",
      "ep 8: ep_len:1020 episode reward: total was -135.970000. running mean: -39.666579\n",
      "ep 8: ep_len:560 episode reward: total was -34.980000. running mean: -39.619713\n",
      "ep 8: ep_len:500 episode reward: total was -24.310000. running mean: -39.466616\n",
      "ep 8: ep_len:910 episode reward: total was -92.160000. running mean: -39.993550\n",
      "ep 8: ep_len:655 episode reward: total was -32.040000. running mean: -39.914014\n",
      "ep 8: ep_len:500 episode reward: total was -26.590000. running mean: -39.780774\n",
      "ep 8: ep_len:795 episode reward: total was -57.040000. running mean: -39.953366\n",
      "ep 8: ep_len:670 episode reward: total was -33.050000. running mean: -39.884333\n",
      "ep 8: ep_len:500 episode reward: total was -13.830000. running mean: -39.623789\n",
      "ep 8: ep_len:500 episode reward: total was -26.790000. running mean: -39.495451\n",
      "ep 8: ep_len:675 episode reward: total was -41.280000. running mean: -39.513297\n",
      "ep 8: ep_len:500 episode reward: total was -20.960000. running mean: -39.327764\n",
      "ep 8: ep_len:225 episode reward: total was 14.000000. running mean: -38.794486\n",
      "ep 8: ep_len:905 episode reward: total was -38.830000. running mean: -38.794841\n",
      "ep 8: ep_len:500 episode reward: total was -44.060000. running mean: -38.847493\n",
      "ep 8: ep_len:935 episode reward: total was -77.940000. running mean: -39.238418\n",
      "ep 8: ep_len:500 episode reward: total was -19.820000. running mean: -39.044234\n",
      "ep 8: ep_len:500 episode reward: total was -20.340000. running mean: -38.857191\n",
      "ep 8: ep_len:570 episode reward: total was -96.360000. running mean: -39.432220\n",
      "ep 8: ep_len:500 episode reward: total was -30.330000. running mean: -39.341197\n",
      "ep 8: ep_len:1010 episode reward: total was -39.100000. running mean: -39.338785\n",
      "ep 8: ep_len:725 episode reward: total was -36.980000. running mean: -39.315198\n",
      "ep 8: ep_len:510 episode reward: total was -35.880000. running mean: -39.280846\n",
      "ep 8: ep_len:785 episode reward: total was -29.070000. running mean: -39.178737\n",
      "ep 8: ep_len:500 episode reward: total was -45.540000. running mean: -39.242350\n",
      "ep 8: ep_len:635 episode reward: total was -53.320000. running mean: -39.383126\n",
      "ep 8: ep_len:720 episode reward: total was -41.520000. running mean: -39.404495\n",
      "ep 8: ep_len:2130 episode reward: total was -288.230000. running mean: -41.892750\n",
      "ep 8: ep_len:700 episode reward: total was -40.270000. running mean: -41.876523\n",
      "ep 8: ep_len:510 episode reward: total was -26.050000. running mean: -41.718257\n",
      "ep 8: ep_len:500 episode reward: total was 4.630000. running mean: -41.254775\n",
      "ep 8: ep_len:1710 episode reward: total was -182.900000. running mean: -42.671227\n",
      "ep 8: ep_len:530 episode reward: total was -30.070000. running mean: -42.545215\n",
      "ep 8: ep_len:1837 episode reward: total was -247.940000. running mean: -44.599163\n",
      "ep 8: ep_len:1325 episode reward: total was -114.230000. running mean: -45.295471\n",
      "ep 8: ep_len:805 episode reward: total was -55.000000. running mean: -45.392516\n",
      "ep 8: ep_len:500 episode reward: total was -18.410000. running mean: -45.122691\n",
      "ep 8: ep_len:860 episode reward: total was -50.070000. running mean: -45.172164\n",
      "ep 8: ep_len:505 episode reward: total was -50.550000. running mean: -45.225943\n",
      "ep 8: ep_len:456 episode reward: total was -20.820000. running mean: -44.981883\n",
      "ep 8: ep_len:500 episode reward: total was -0.810000. running mean: -44.540164\n",
      "ep 8: ep_len:895 episode reward: total was -52.900000. running mean: -44.623763\n",
      "ep 8: ep_len:500 episode reward: total was -36.450000. running mean: -44.542025\n",
      "ep 8: ep_len:116 episode reward: total was 1.500000. running mean: -44.081605\n",
      "ep 8: ep_len:560 episode reward: total was -29.230000. running mean: -43.933089\n",
      "ep 8: ep_len:545 episode reward: total was -51.480000. running mean: -44.008558\n",
      "ep 8: ep_len:500 episode reward: total was -46.660000. running mean: -44.035072\n",
      "ep 8: ep_len:505 episode reward: total was -2.320000. running mean: -43.617922\n",
      "ep 8: ep_len:835 episode reward: total was -55.710000. running mean: -43.738842\n",
      "ep 8: ep_len:500 episode reward: total was -8.370000. running mean: -43.385154\n",
      "ep 8: ep_len:840 episode reward: total was -61.480000. running mean: -43.566102\n",
      "ep 8: ep_len:615 episode reward: total was -60.540000. running mean: -43.735841\n",
      "ep 8: ep_len:500 episode reward: total was -14.160000. running mean: -43.440083\n",
      "ep 8: ep_len:1000 episode reward: total was -41.540000. running mean: -43.421082\n",
      "ep 8: ep_len:184 episode reward: total was -2.500000. running mean: -43.011871\n",
      "ep 8: ep_len:1115 episode reward: total was -38.390000. running mean: -42.965653\n",
      "ep 8: ep_len:120 episode reward: total was 7.010000. running mean: -42.465896\n",
      "ep 8: ep_len:505 episode reward: total was -11.840000. running mean: -42.159637\n",
      "ep 8: ep_len:1135 episode reward: total was -62.990000. running mean: -42.367941\n",
      "ep 8: ep_len:500 episode reward: total was -33.940000. running mean: -42.283661\n",
      "ep 8: ep_len:505 episode reward: total was -43.970000. running mean: -42.300525\n",
      "ep 8: ep_len:500 episode reward: total was -5.350000. running mean: -41.931019\n",
      "ep 8: ep_len:165 episode reward: total was 6.000000. running mean: -41.451709\n",
      "ep 8: ep_len:500 episode reward: total was -0.280000. running mean: -41.039992\n",
      "ep 8: ep_len:132 episode reward: total was 1.500000. running mean: -40.614592\n",
      "ep 8: ep_len:171 episode reward: total was 8.000000. running mean: -40.128446\n",
      "ep 8: ep_len:500 episode reward: total was -30.120000. running mean: -40.028362\n",
      "ep 8: ep_len:580 episode reward: total was -30.270000. running mean: -39.930778\n",
      "ep 8: ep_len:500 episode reward: total was -4.290000. running mean: -39.574370\n",
      "ep 8: ep_len:505 episode reward: total was -30.310000. running mean: -39.481727\n",
      "ep 8: ep_len:1110 episode reward: total was -58.340000. running mean: -39.670309\n",
      "ep 8: ep_len:84 episode reward: total was 0.500000. running mean: -39.268606\n",
      "ep 8: ep_len:620 episode reward: total was -47.780000. running mean: -39.353720\n",
      "ep 8: ep_len:795 episode reward: total was -49.450000. running mean: -39.454683\n",
      "ep 8: ep_len:500 episode reward: total was 8.260000. running mean: -38.977536\n",
      "ep 8: ep_len:920 episode reward: total was -42.940000. running mean: -39.017161\n",
      "ep 8: ep_len:219 episode reward: total was 6.000000. running mean: -38.566989\n",
      "ep 8: ep_len:267 episode reward: total was 2.500000. running mean: -38.156319\n",
      "ep 8: ep_len:505 episode reward: total was -22.140000. running mean: -37.996156\n",
      "ep 8: ep_len:500 episode reward: total was 3.700000. running mean: -37.579195\n",
      "ep 8: ep_len:885 episode reward: total was -51.810000. running mean: -37.721503\n",
      "ep 8: ep_len:815 episode reward: total was -51.430000. running mean: -37.858588\n",
      "ep 8: ep_len:595 episode reward: total was -52.880000. running mean: -38.008802\n",
      "ep 8: ep_len:650 episode reward: total was -51.970000. running mean: -38.148414\n",
      "ep 8: ep_len:555 episode reward: total was -47.420000. running mean: -38.241130\n",
      "ep 8: ep_len:500 episode reward: total was -4.260000. running mean: -37.901318\n",
      "ep 8: ep_len:327 episode reward: total was -16.410000. running mean: -37.686405\n",
      "ep 8: ep_len:500 episode reward: total was -44.620000. running mean: -37.755741\n",
      "ep 8: ep_len:1025 episode reward: total was -130.310000. running mean: -38.681284\n",
      "ep 8: ep_len:505 episode reward: total was -19.080000. running mean: -38.485271\n",
      "ep 8: ep_len:560 episode reward: total was -43.950000. running mean: -38.539918\n",
      "ep 8: ep_len:500 episode reward: total was -26.700000. running mean: -38.421519\n",
      "ep 8: ep_len:910 episode reward: total was -42.510000. running mean: -38.462404\n",
      "ep 8: ep_len:505 episode reward: total was -35.580000. running mean: -38.433580\n",
      "ep 8: ep_len:705 episode reward: total was -38.170000. running mean: -38.430944\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 8: ep_len:500 episode reward: total was -37.660000. running mean: -38.423234\n",
      "ep 8: ep_len:295 episode reward: total was 0.500000. running mean: -38.034002\n",
      "ep 8: ep_len:500 episode reward: total was -9.970000. running mean: -37.753362\n",
      "ep 8: ep_len:500 episode reward: total was 12.500000. running mean: -37.250829\n",
      "ep 8: ep_len:500 episode reward: total was -26.830000. running mean: -37.146620\n",
      "ep 8: ep_len:500 episode reward: total was -7.460000. running mean: -36.849754\n",
      "ep 8: ep_len:510 episode reward: total was -30.000000. running mean: -36.781256\n",
      "ep 8: ep_len:545 episode reward: total was -43.890000. running mean: -36.852344\n",
      "ep 8: ep_len:625 episode reward: total was -29.100000. running mean: -36.774820\n",
      "ep 8: ep_len:500 episode reward: total was -11.580000. running mean: -36.522872\n",
      "ep 8: ep_len:670 episode reward: total was -50.000000. running mean: -36.657644\n",
      "ep 8: ep_len:500 episode reward: total was -26.130000. running mean: -36.552367\n",
      "ep 8: ep_len:500 episode reward: total was 29.000000. running mean: -35.896843\n",
      "ep 8: ep_len:500 episode reward: total was 2.740000. running mean: -35.510475\n",
      "ep 8: ep_len:126 episode reward: total was 6.500000. running mean: -35.090370\n",
      "ep 8: ep_len:705 episode reward: total was -25.910000. running mean: -34.998567\n",
      "ep 8: ep_len:324 episode reward: total was -11.310000. running mean: -34.761681\n",
      "ep 8: ep_len:725 episode reward: total was -112.730000. running mean: -35.541364\n",
      "ep 8: ep_len:257 episode reward: total was 7.500000. running mean: -35.110950\n",
      "ep 8: ep_len:500 episode reward: total was -32.100000. running mean: -35.080841\n",
      "ep 8: ep_len:895 episode reward: total was -89.160000. running mean: -35.621633\n",
      "ep 8: ep_len:500 episode reward: total was -6.810000. running mean: -35.333516\n",
      "ep 8: ep_len:505 episode reward: total was -4.810000. running mean: -35.028281\n",
      "ep 8: ep_len:500 episode reward: total was 8.000000. running mean: -34.597998\n",
      "ep 8: ep_len:800 episode reward: total was -24.580000. running mean: -34.497818\n",
      "ep 8: ep_len:755 episode reward: total was -38.420000. running mean: -34.537040\n",
      "ep 8: ep_len:208 episode reward: total was 4.000000. running mean: -34.151670\n",
      "ep 8: ep_len:1095 episode reward: total was -85.740000. running mean: -34.667553\n",
      "ep 8: ep_len:710 episode reward: total was -61.250000. running mean: -34.933377\n",
      "ep 8: ep_len:1020 episode reward: total was -62.580000. running mean: -35.209844\n",
      "ep 8: ep_len:865 episode reward: total was -37.240000. running mean: -35.230145\n",
      "ep 8: ep_len:695 episode reward: total was -24.720000. running mean: -35.125044\n",
      "ep 8: ep_len:213 episode reward: total was 3.500000. running mean: -34.738793\n",
      "ep 8: ep_len:500 episode reward: total was -24.970000. running mean: -34.641105\n",
      "ep 8: ep_len:500 episode reward: total was -41.060000. running mean: -34.705294\n",
      "ep 8: ep_len:505 episode reward: total was -16.780000. running mean: -34.526041\n",
      "ep 8: ep_len:825 episode reward: total was -91.970000. running mean: -35.100481\n",
      "ep 8: ep_len:510 episode reward: total was -28.680000. running mean: -35.036276\n",
      "ep 8: ep_len:865 episode reward: total was -56.870000. running mean: -35.254613\n",
      "ep 8: ep_len:545 episode reward: total was -41.380000. running mean: -35.315867\n",
      "ep 8: ep_len:770 episode reward: total was -48.030000. running mean: -35.443009\n",
      "ep 8: ep_len:610 episode reward: total was -28.120000. running mean: -35.369779\n",
      "ep 8: ep_len:500 episode reward: total was -26.440000. running mean: -35.280481\n",
      "ep 8: ep_len:219 episode reward: total was 2.000000. running mean: -34.907676\n",
      "ep 8: ep_len:545 episode reward: total was -4.640000. running mean: -34.604999\n",
      "ep 8: ep_len:500 episode reward: total was 14.000000. running mean: -34.118949\n",
      "ep 8: ep_len:595 episode reward: total was -54.020000. running mean: -34.317960\n",
      "ep 8: ep_len:500 episode reward: total was -19.320000. running mean: -34.167980\n",
      "ep 8: ep_len:545 episode reward: total was -46.430000. running mean: -34.290600\n",
      "ep 8: ep_len:591 episode reward: total was -69.800000. running mean: -34.645694\n",
      "ep 8: ep_len:200 episode reward: total was 9.500000. running mean: -34.204237\n",
      "ep 8: ep_len:720 episode reward: total was -52.270000. running mean: -34.384895\n",
      "ep 8: ep_len:500 episode reward: total was -41.530000. running mean: -34.456346\n",
      "ep 8: ep_len:1505 episode reward: total was -209.340000. running mean: -36.205183\n",
      "ep 8: ep_len:207 episode reward: total was 14.500000. running mean: -35.698131\n",
      "ep 8: ep_len:500 episode reward: total was -6.350000. running mean: -35.404649\n",
      "ep 8: ep_len:570 episode reward: total was -38.300000. running mean: -35.433603\n",
      "ep 8: ep_len:925 episode reward: total was -58.400000. running mean: -35.663267\n",
      "ep 8: ep_len:1120 episode reward: total was -57.510000. running mean: -35.881734\n",
      "ep 8: ep_len:500 episode reward: total was -14.200000. running mean: -35.664917\n",
      "ep 8: ep_len:500 episode reward: total was -20.810000. running mean: -35.516368\n",
      "ep 8: ep_len:500 episode reward: total was -33.930000. running mean: -35.500504\n",
      "ep 8: ep_len:785 episode reward: total was -52.650000. running mean: -35.671999\n",
      "ep 8: ep_len:500 episode reward: total was -49.990000. running mean: -35.815179\n",
      "ep 8: ep_len:130 episode reward: total was 5.500000. running mean: -35.402027\n",
      "ep 8: ep_len:825 episode reward: total was -66.560000. running mean: -35.713607\n",
      "ep 8: ep_len:290 episode reward: total was 15.500000. running mean: -35.201471\n",
      "ep 8: ep_len:1045 episode reward: total was -70.220000. running mean: -35.551656\n",
      "ep 8: ep_len:915 episode reward: total was -40.010000. running mean: -35.596240\n",
      "ep 8: ep_len:740 episode reward: total was -47.540000. running mean: -35.715677\n",
      "ep 8: ep_len:500 episode reward: total was -36.690000. running mean: -35.725420\n",
      "ep 8: ep_len:685 episode reward: total was -35.490000. running mean: -35.723066\n",
      "ep 8: ep_len:500 episode reward: total was -6.320000. running mean: -35.429036\n",
      "ep 8: ep_len:625 episode reward: total was -79.080000. running mean: -35.865545\n",
      "ep 8: ep_len:935 episode reward: total was -73.930000. running mean: -36.246190\n",
      "ep 8: ep_len:505 episode reward: total was 19.500000. running mean: -35.688728\n",
      "ep 8: ep_len:500 episode reward: total was -5.770000. running mean: -35.389541\n",
      "ep 8: ep_len:690 episode reward: total was -35.010000. running mean: -35.385745\n",
      "ep 8: ep_len:126 episode reward: total was 5.000000. running mean: -34.981888\n",
      "ep 8: ep_len:500 episode reward: total was -6.280000. running mean: -34.694869\n",
      "ep 8: ep_len:830 episode reward: total was -30.350000. running mean: -34.651420\n",
      "ep 8: ep_len:500 episode reward: total was -24.820000. running mean: -34.553106\n",
      "ep 8: ep_len:830 episode reward: total was -25.480000. running mean: -34.462375\n",
      "ep 8: ep_len:770 episode reward: total was -95.470000. running mean: -35.072451\n",
      "ep 8: ep_len:535 episode reward: total was -13.690000. running mean: -34.858627\n",
      "ep 8: ep_len:1030 episode reward: total was -53.780000. running mean: -35.047840\n",
      "ep 8: ep_len:505 episode reward: total was -44.260000. running mean: -35.139962\n",
      "ep 8: ep_len:940 episode reward: total was -33.300000. running mean: -35.121562\n",
      "ep 8: ep_len:505 episode reward: total was -30.490000. running mean: -35.075247\n",
      "ep 8: ep_len:500 episode reward: total was -7.810000. running mean: -34.802594\n",
      "ep 8: ep_len:505 episode reward: total was -30.900000. running mean: -34.763568\n",
      "ep 8: ep_len:760 episode reward: total was -50.530000. running mean: -34.921233\n",
      "ep 8: ep_len:321 episode reward: total was 10.000000. running mean: -34.472020\n",
      "ep 8: ep_len:840 episode reward: total was -42.330000. running mean: -34.550600\n",
      "ep 8: ep_len:500 episode reward: total was -35.530000. running mean: -34.560394\n",
      "ep 8: ep_len:880 episode reward: total was -62.370000. running mean: -34.838490\n",
      "ep 8: ep_len:650 episode reward: total was -35.440000. running mean: -34.844505\n",
      "ep 8: ep_len:655 episode reward: total was -6.530000. running mean: -34.561360\n",
      "ep 8: ep_len:500 episode reward: total was -1.720000. running mean: -34.232947\n",
      "ep 8: ep_len:710 episode reward: total was -64.770000. running mean: -34.538317\n",
      "ep 8: ep_len:665 episode reward: total was -24.260000. running mean: -34.435534\n",
      "ep 8: ep_len:620 episode reward: total was -47.290000. running mean: -34.564079\n",
      "ep 8: ep_len:500 episode reward: total was 21.500000. running mean: -34.003438\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 8: ep_len:477 episode reward: total was 8.180000. running mean: -33.581603\n",
      "ep 8: ep_len:725 episode reward: total was -56.170000. running mean: -33.807487\n",
      "ep 8: ep_len:625 episode reward: total was -43.210000. running mean: -33.901513\n",
      "ep 8: ep_len:555 episode reward: total was -84.790000. running mean: -34.410397\n",
      "ep 8: ep_len:695 episode reward: total was -71.270000. running mean: -34.778993\n",
      "ep 8: ep_len:500 episode reward: total was -29.870000. running mean: -34.729904\n",
      "ep 8: ep_len:396 episode reward: total was 6.500000. running mean: -34.317604\n",
      "ep 8: ep_len:500 episode reward: total was -22.330000. running mean: -34.197728\n",
      "ep 8: ep_len:890 episode reward: total was -62.880000. running mean: -34.484551\n",
      "ep 8: ep_len:800 episode reward: total was -68.630000. running mean: -34.826006\n",
      "ep 8: ep_len:555 episode reward: total was -58.500000. running mean: -35.062746\n",
      "ep 8: ep_len:655 episode reward: total was -92.640000. running mean: -35.638518\n",
      "ep 8: ep_len:259 episode reward: total was 8.000000. running mean: -35.202133\n",
      "ep 8: ep_len:590 episode reward: total was -48.360000. running mean: -35.333712\n",
      "ep 8: ep_len:675 episode reward: total was -40.110000. running mean: -35.381475\n",
      "ep 8: ep_len:550 episode reward: total was -32.430000. running mean: -35.351960\n",
      "ep 8: ep_len:500 episode reward: total was -35.260000. running mean: -35.351040\n",
      "ep 8: ep_len:505 episode reward: total was -2.210000. running mean: -35.019630\n",
      "ep 8: ep_len:146 episode reward: total was 2.500000. running mean: -34.644433\n",
      "ep 8: ep_len:575 episode reward: total was -34.870000. running mean: -34.646689\n",
      "ep 8: ep_len:810 episode reward: total was -26.120000. running mean: -34.561422\n",
      "ep 8: ep_len:500 episode reward: total was -76.940000. running mean: -34.985208\n",
      "ep 8: ep_len:560 episode reward: total was -59.530000. running mean: -35.230656\n",
      "ep 8: ep_len:970 episode reward: total was -50.670000. running mean: -35.385049\n",
      "ep 8: ep_len:500 episode reward: total was -12.230000. running mean: -35.153499\n",
      "ep 8: ep_len:595 episode reward: total was -51.350000. running mean: -35.315464\n",
      "ep 8: ep_len:375 episode reward: total was 13.500000. running mean: -34.827309\n",
      "ep 8: ep_len:500 episode reward: total was -8.770000. running mean: -34.566736\n",
      "ep 8: ep_len:760 episode reward: total was -21.430000. running mean: -34.435369\n",
      "ep 8: ep_len:500 episode reward: total was -37.380000. running mean: -34.464815\n",
      "ep 8: ep_len:500 episode reward: total was -16.980000. running mean: -34.289967\n",
      "ep 8: ep_len:500 episode reward: total was -33.020000. running mean: -34.277267\n",
      "ep 8: ep_len:505 episode reward: total was -14.910000. running mean: -34.083595\n",
      "ep 8: ep_len:1930 episode reward: total was -329.460000. running mean: -37.037359\n",
      "ep 8: ep_len:580 episode reward: total was -53.920000. running mean: -37.206185\n",
      "ep 8: ep_len:715 episode reward: total was -57.200000. running mean: -37.406123\n",
      "ep 8: ep_len:500 episode reward: total was -26.560000. running mean: -37.297662\n",
      "ep 8: ep_len:1140 episode reward: total was -147.250000. running mean: -38.397185\n",
      "ep 8: ep_len:510 episode reward: total was -2.200000. running mean: -38.035214\n",
      "ep 8: ep_len:500 episode reward: total was -20.280000. running mean: -37.857661\n",
      "ep 8: ep_len:545 episode reward: total was -41.380000. running mean: -37.892885\n",
      "ep 8: ep_len:393 episode reward: total was -18.360000. running mean: -37.697556\n",
      "ep 8: ep_len:500 episode reward: total was -48.600000. running mean: -37.806580\n",
      "ep 8: ep_len:695 episode reward: total was -38.410000. running mean: -37.812615\n",
      "ep 8: ep_len:515 episode reward: total was -21.540000. running mean: -37.649888\n",
      "ep 8: ep_len:505 episode reward: total was -34.310000. running mean: -37.616490\n",
      "ep 8: ep_len:505 episode reward: total was -2.810000. running mean: -37.268425\n",
      "ep 8: ep_len:500 episode reward: total was -13.250000. running mean: -37.028240\n",
      "ep 8: ep_len:55 episode reward: total was -9.990000. running mean: -36.757858\n",
      "ep 8: ep_len:545 episode reward: total was 2.250000. running mean: -36.367779\n",
      "ep 8: ep_len:500 episode reward: total was -26.330000. running mean: -36.267402\n",
      "ep 8: ep_len:500 episode reward: total was -19.090000. running mean: -36.095628\n",
      "ep 8: ep_len:500 episode reward: total was -37.230000. running mean: -36.106971\n",
      "ep 8: ep_len:164 episode reward: total was 1.500000. running mean: -35.730902\n",
      "ep 8: ep_len:770 episode reward: total was -30.080000. running mean: -35.674393\n",
      "ep 8: ep_len:790 episode reward: total was -25.810000. running mean: -35.575749\n",
      "ep 8: ep_len:640 episode reward: total was -48.260000. running mean: -35.702591\n",
      "ep 8: ep_len:895 episode reward: total was -79.550000. running mean: -36.141065\n",
      "ep 8: ep_len:545 episode reward: total was -36.820000. running mean: -36.147855\n",
      "ep 8: ep_len:565 episode reward: total was -89.840000. running mean: -36.684776\n",
      "ep 8: ep_len:500 episode reward: total was -23.680000. running mean: -36.554728\n",
      "ep 8: ep_len:2540 episode reward: total was -415.100000. running mean: -40.340181\n",
      "ep 8: ep_len:590 episode reward: total was -78.750000. running mean: -40.724279\n",
      "ep 8: ep_len:500 episode reward: total was -24.360000. running mean: -40.560636\n",
      "ep 8: ep_len:720 episode reward: total was -42.560000. running mean: -40.580630\n",
      "ep 8: ep_len:500 episode reward: total was -27.810000. running mean: -40.452924\n",
      "ep 8: ep_len:500 episode reward: total was -19.280000. running mean: -40.241195\n",
      "ep 8: ep_len:213 episode reward: total was 9.000000. running mean: -39.748783\n",
      "ep 8: ep_len:500 episode reward: total was -52.660000. running mean: -39.877895\n",
      "ep 8: ep_len:790 episode reward: total was -49.980000. running mean: -39.978916\n",
      "ep 8: ep_len:1020 episode reward: total was -71.970000. running mean: -40.298827\n",
      "ep 8: ep_len:885 episode reward: total was -64.630000. running mean: -40.542138\n",
      "ep 8: ep_len:590 episode reward: total was -16.630000. running mean: -40.303017\n",
      "ep 8: ep_len:505 episode reward: total was -6.650000. running mean: -39.966487\n",
      "ep 8: ep_len:985 episode reward: total was -35.570000. running mean: -39.922522\n",
      "ep 8: ep_len:181 episode reward: total was -1.500000. running mean: -39.538297\n",
      "ep 8: ep_len:500 episode reward: total was -9.220000. running mean: -39.235114\n",
      "ep 8: ep_len:770 episode reward: total was -39.400000. running mean: -39.236763\n",
      "ep 8: ep_len:500 episode reward: total was -19.550000. running mean: -39.039895\n",
      "ep 8: ep_len:1035 episode reward: total was -34.630000. running mean: -38.995796\n",
      "ep 8: ep_len:500 episode reward: total was -13.660000. running mean: -38.742438\n",
      "ep 8: ep_len:635 episode reward: total was -17.930000. running mean: -38.534314\n",
      "ep 8: ep_len:201 episode reward: total was 8.000000. running mean: -38.068971\n",
      "ep 8: ep_len:745 episode reward: total was -50.430000. running mean: -38.192581\n",
      "ep 8: ep_len:500 episode reward: total was -8.240000. running mean: -37.893055\n",
      "ep 8: ep_len:500 episode reward: total was -32.370000. running mean: -37.837825\n",
      "ep 8: ep_len:500 episode reward: total was 0.730000. running mean: -37.452146\n",
      "ep 8: ep_len:494 episode reward: total was 0.710000. running mean: -37.070525\n",
      "ep 8: ep_len:645 episode reward: total was -83.350000. running mean: -37.533320\n",
      "ep 8: ep_len:158 episode reward: total was 10.000000. running mean: -37.057986\n",
      "ep 8: ep_len:500 episode reward: total was -29.410000. running mean: -36.981507\n",
      "ep 8: ep_len:555 episode reward: total was -0.810000. running mean: -36.619791\n",
      "ep 8: ep_len:650 episode reward: total was -20.840000. running mean: -36.461994\n",
      "ep 8: ep_len:500 episode reward: total was -25.670000. running mean: -36.354074\n",
      "ep 8: ep_len:2790 episode reward: total was -387.370000. running mean: -39.864233\n",
      "ep 8: ep_len:505 episode reward: total was -15.880000. running mean: -39.624391\n",
      "ep 8: ep_len:5668 episode reward: total was -931.840000. running mean: -48.546547\n",
      "ep 8: ep_len:815 episode reward: total was -69.820000. running mean: -48.759281\n",
      "ep 8: ep_len:505 episode reward: total was -39.010000. running mean: -48.661788\n",
      "ep 8: ep_len:1365 episode reward: total was -172.540000. running mean: -49.900570\n",
      "ep 8: ep_len:625 episode reward: total was -72.500000. running mean: -50.126565\n",
      "ep 8: ep_len:454 episode reward: total was -3.910000. running mean: -49.664399\n",
      "ep 8: ep_len:835 episode reward: total was -49.070000. running mean: -49.658455\n",
      "epsilon:0.261647 episode_count: 7095. steps_count: 5074924.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 9: ep_len:1670 episode reward: total was -173.580000. running mean: -50.897671\n",
      "ep 9: ep_len:785 episode reward: total was -57.060000. running mean: -50.959294\n",
      "ep 9: ep_len:690 episode reward: total was -39.040000. running mean: -50.840101\n",
      "ep 9: ep_len:555 episode reward: total was -53.480000. running mean: -50.866500\n",
      "ep 9: ep_len:510 episode reward: total was -33.400000. running mean: -50.691835\n",
      "ep 9: ep_len:505 episode reward: total was -18.900000. running mean: -50.373917\n",
      "ep 9: ep_len:505 episode reward: total was -26.380000. running mean: -50.133977\n",
      "ep 9: ep_len:990 episode reward: total was -59.800000. running mean: -50.230638\n",
      "ep 9: ep_len:940 episode reward: total was -82.210000. running mean: -50.550431\n",
      "ep 9: ep_len:1070 episode reward: total was -40.020000. running mean: -50.445127\n",
      "ep 9: ep_len:500 episode reward: total was -5.310000. running mean: -49.993776\n",
      "ep 9: ep_len:1010 episode reward: total was -20.010000. running mean: -49.693938\n",
      "ep 9: ep_len:500 episode reward: total was -13.800000. running mean: -49.334999\n",
      "ep 9: ep_len:144 episode reward: total was 3.500000. running mean: -48.806649\n",
      "ep 9: ep_len:905 episode reward: total was -60.860000. running mean: -48.927182\n",
      "ep 9: ep_len:1220 episode reward: total was -55.580000. running mean: -48.993710\n",
      "ep 9: ep_len:500 episode reward: total was -7.760000. running mean: -48.581373\n",
      "ep 9: ep_len:500 episode reward: total was -28.850000. running mean: -48.384059\n",
      "ep 9: ep_len:500 episode reward: total was -0.630000. running mean: -47.906519\n",
      "ep 9: ep_len:725 episode reward: total was -13.680000. running mean: -47.564254\n",
      "ep 9: ep_len:730 episode reward: total was -59.160000. running mean: -47.680211\n",
      "ep 9: ep_len:1710 episode reward: total was -220.850000. running mean: -49.411909\n",
      "ep 9: ep_len:985 episode reward: total was -118.240000. running mean: -50.100190\n",
      "ep 9: ep_len:1635 episode reward: total was -212.920000. running mean: -51.728388\n",
      "ep 9: ep_len:650 episode reward: total was -0.960000. running mean: -51.220704\n",
      "ep 9: ep_len:530 episode reward: total was -49.630000. running mean: -51.204797\n",
      "ep 9: ep_len:505 episode reward: total was -15.410000. running mean: -50.846849\n",
      "ep 9: ep_len:530 episode reward: total was -18.570000. running mean: -50.524081\n",
      "ep 9: ep_len:505 episode reward: total was -4.640000. running mean: -50.065240\n",
      "ep 9: ep_len:655 episode reward: total was -34.810000. running mean: -49.912687\n",
      "ep 9: ep_len:665 episode reward: total was -15.800000. running mean: -49.571561\n",
      "ep 9: ep_len:206 episode reward: total was -0.500000. running mean: -49.080845\n",
      "ep 9: ep_len:500 episode reward: total was -25.890000. running mean: -48.848936\n",
      "ep 9: ep_len:630 episode reward: total was -23.000000. running mean: -48.590447\n",
      "ep 9: ep_len:815 episode reward: total was -64.850000. running mean: -48.753043\n",
      "ep 9: ep_len:525 episode reward: total was -43.440000. running mean: -48.699912\n",
      "ep 9: ep_len:895 episode reward: total was -36.740000. running mean: -48.580313\n",
      "ep 9: ep_len:770 episode reward: total was -23.230000. running mean: -48.326810\n",
      "ep 9: ep_len:500 episode reward: total was -11.990000. running mean: -47.963442\n",
      "ep 9: ep_len:770 episode reward: total was -98.470000. running mean: -48.468507\n",
      "ep 9: ep_len:500 episode reward: total was -11.390000. running mean: -48.097722\n",
      "ep 9: ep_len:500 episode reward: total was -23.290000. running mean: -47.849645\n",
      "ep 9: ep_len:610 episode reward: total was -29.770000. running mean: -47.668849\n",
      "ep 9: ep_len:500 episode reward: total was -21.380000. running mean: -47.405960\n",
      "ep 9: ep_len:500 episode reward: total was -38.500000. running mean: -47.316901\n",
      "ep 9: ep_len:272 episode reward: total was 17.000000. running mean: -46.673732\n",
      "ep 9: ep_len:860 episode reward: total was -79.880000. running mean: -47.005794\n",
      "ep 9: ep_len:725 episode reward: total was -49.070000. running mean: -47.026436\n",
      "ep 9: ep_len:1245 episode reward: total was -86.530000. running mean: -47.421472\n",
      "ep 9: ep_len:162 episode reward: total was 10.000000. running mean: -46.847257\n",
      "ep 9: ep_len:500 episode reward: total was -22.740000. running mean: -46.606185\n",
      "ep 9: ep_len:505 episode reward: total was -73.810000. running mean: -46.878223\n",
      "ep 9: ep_len:595 episode reward: total was -25.310000. running mean: -46.662541\n",
      "ep 9: ep_len:540 episode reward: total was -2.740000. running mean: -46.223315\n",
      "ep 9: ep_len:655 episode reward: total was -44.190000. running mean: -46.202982\n",
      "ep 9: ep_len:93 episode reward: total was 6.000000. running mean: -45.680952\n",
      "ep 9: ep_len:505 episode reward: total was -6.220000. running mean: -45.286343\n",
      "ep 9: ep_len:725 episode reward: total was -54.150000. running mean: -45.374979\n",
      "ep 9: ep_len:550 episode reward: total was -22.030000. running mean: -45.141529\n",
      "ep 9: ep_len:434 episode reward: total was 17.500000. running mean: -44.515114\n",
      "ep 9: ep_len:1225 episode reward: total was -88.090000. running mean: -44.950863\n",
      "ep 9: ep_len:675 episode reward: total was -39.330000. running mean: -44.894654\n",
      "ep 9: ep_len:535 episode reward: total was -31.300000. running mean: -44.758708\n",
      "ep 9: ep_len:880 episode reward: total was -57.880000. running mean: -44.889921\n",
      "ep 9: ep_len:515 episode reward: total was -30.330000. running mean: -44.744322\n",
      "ep 9: ep_len:1090 episode reward: total was -108.970000. running mean: -45.386578\n",
      "ep 9: ep_len:835 episode reward: total was -28.700000. running mean: -45.219713\n",
      "ep 9: ep_len:505 episode reward: total was -39.960000. running mean: -45.167115\n",
      "ep 9: ep_len:660 episode reward: total was -36.100000. running mean: -45.076444\n",
      "ep 9: ep_len:755 episode reward: total was -40.440000. running mean: -45.030080\n",
      "ep 9: ep_len:216 episode reward: total was 5.500000. running mean: -44.524779\n",
      "ep 9: ep_len:510 episode reward: total was -12.390000. running mean: -44.203431\n",
      "ep 9: ep_len:820 episode reward: total was -24.300000. running mean: -44.004397\n",
      "ep 9: ep_len:525 episode reward: total was -46.150000. running mean: -44.025853\n",
      "ep 9: ep_len:535 episode reward: total was -41.890000. running mean: -44.004494\n",
      "ep 9: ep_len:505 episode reward: total was -31.850000. running mean: -43.882950\n",
      "ep 9: ep_len:505 episode reward: total was -27.460000. running mean: -43.718720\n",
      "ep 9: ep_len:500 episode reward: total was -20.620000. running mean: -43.487733\n",
      "ep 9: ep_len:890 episode reward: total was -25.960000. running mean: -43.312455\n",
      "ep 9: ep_len:1015 episode reward: total was -115.660000. running mean: -44.035931\n",
      "ep 9: ep_len:565 episode reward: total was -4.290000. running mean: -43.638472\n",
      "ep 9: ep_len:635 episode reward: total was -49.800000. running mean: -43.700087\n",
      "ep 9: ep_len:86 episode reward: total was 4.000000. running mean: -43.223086\n",
      "ep 9: ep_len:500 episode reward: total was -33.510000. running mean: -43.125955\n",
      "ep 9: ep_len:204 episode reward: total was 12.500000. running mean: -42.569696\n",
      "ep 9: ep_len:745 episode reward: total was -37.550000. running mean: -42.519499\n",
      "ep 9: ep_len:550 episode reward: total was -36.810000. running mean: -42.462404\n",
      "ep 9: ep_len:505 episode reward: total was -36.340000. running mean: -42.401180\n",
      "ep 9: ep_len:975 episode reward: total was -90.440000. running mean: -42.881568\n",
      "ep 9: ep_len:505 episode reward: total was -32.400000. running mean: -42.776752\n",
      "ep 9: ep_len:500 episode reward: total was -28.270000. running mean: -42.631685\n",
      "ep 9: ep_len:505 episode reward: total was -8.790000. running mean: -42.293268\n",
      "ep 9: ep_len:1105 episode reward: total was -64.510000. running mean: -42.515435\n",
      "ep 9: ep_len:850 episode reward: total was -29.770000. running mean: -42.387981\n",
      "ep 9: ep_len:505 episode reward: total was 19.000000. running mean: -41.774101\n",
      "ep 9: ep_len:500 episode reward: total was -27.860000. running mean: -41.634960\n",
      "ep 9: ep_len:202 episode reward: total was 15.500000. running mean: -41.063610\n",
      "ep 9: ep_len:905 episode reward: total was -34.170000. running mean: -40.994674\n",
      "ep 9: ep_len:500 episode reward: total was -3.900000. running mean: -40.623728\n",
      "ep 9: ep_len:505 episode reward: total was -4.280000. running mean: -40.260290\n",
      "ep 9: ep_len:690 episode reward: total was -36.040000. running mean: -40.218087\n",
      "ep 9: ep_len:500 episode reward: total was 3.670000. running mean: -39.779206\n",
      "ep 9: ep_len:670 episode reward: total was -87.070000. running mean: -40.252114\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 9: ep_len:505 episode reward: total was -46.600000. running mean: -40.315593\n",
      "ep 9: ep_len:755 episode reward: total was -58.120000. running mean: -40.493637\n",
      "ep 9: ep_len:770 episode reward: total was -90.420000. running mean: -40.992901\n",
      "ep 9: ep_len:625 episode reward: total was -45.230000. running mean: -41.035272\n",
      "ep 9: ep_len:500 episode reward: total was -5.770000. running mean: -40.682619\n",
      "ep 9: ep_len:505 episode reward: total was -9.150000. running mean: -40.367293\n",
      "ep 9: ep_len:740 episode reward: total was -22.360000. running mean: -40.187220\n",
      "ep 9: ep_len:5360 episode reward: total was -1007.070000. running mean: -49.856048\n",
      "ep 9: ep_len:580 episode reward: total was -20.980000. running mean: -49.567287\n",
      "ep 9: ep_len:670 episode reward: total was -44.160000. running mean: -49.513215\n",
      "ep 9: ep_len:445 episode reward: total was 9.000000. running mean: -48.928082\n",
      "ep 9: ep_len:520 episode reward: total was -30.290000. running mean: -48.741702\n",
      "ep 9: ep_len:555 episode reward: total was -32.120000. running mean: -48.575485\n",
      "ep 9: ep_len:775 episode reward: total was -54.050000. running mean: -48.630230\n",
      "ep 9: ep_len:505 episode reward: total was -25.420000. running mean: -48.398127\n",
      "ep 9: ep_len:710 episode reward: total was -15.380000. running mean: -48.067946\n",
      "ep 9: ep_len:640 episode reward: total was -36.250000. running mean: -47.949767\n",
      "ep 9: ep_len:500 episode reward: total was -38.040000. running mean: -47.850669\n",
      "ep 9: ep_len:725 episode reward: total was -35.970000. running mean: -47.731862\n",
      "ep 9: ep_len:500 episode reward: total was 16.000000. running mean: -47.094544\n",
      "ep 9: ep_len:590 episode reward: total was -12.100000. running mean: -46.744598\n",
      "ep 9: ep_len:675 episode reward: total was -45.650000. running mean: -46.733652\n",
      "ep 9: ep_len:870 episode reward: total was -21.710000. running mean: -46.483416\n",
      "ep 9: ep_len:890 episode reward: total was -59.360000. running mean: -46.612182\n",
      "ep 9: ep_len:770 episode reward: total was -68.690000. running mean: -46.832960\n",
      "ep 9: ep_len:715 episode reward: total was -60.170000. running mean: -46.966330\n",
      "ep 9: ep_len:505 episode reward: total was -19.310000. running mean: -46.689767\n",
      "ep 9: ep_len:500 episode reward: total was 2.170000. running mean: -46.201169\n",
      "ep 9: ep_len:1455 episode reward: total was -164.430000. running mean: -47.383458\n",
      "ep 9: ep_len:855 episode reward: total was -85.200000. running mean: -47.761623\n",
      "ep 9: ep_len:500 episode reward: total was -35.120000. running mean: -47.635207\n",
      "ep 9: ep_len:785 episode reward: total was -31.890000. running mean: -47.477755\n",
      "ep 9: ep_len:2320 episode reward: total was -421.630000. running mean: -51.219277\n",
      "ep 9: ep_len:520 episode reward: total was -15.830000. running mean: -50.865384\n",
      "ep 9: ep_len:500 episode reward: total was -11.800000. running mean: -50.474730\n",
      "ep 9: ep_len:1445 episode reward: total was -176.910000. running mean: -51.739083\n",
      "ep 9: ep_len:500 episode reward: total was 1.180000. running mean: -51.209892\n",
      "ep 9: ep_len:500 episode reward: total was 9.210000. running mean: -50.605693\n",
      "ep 9: ep_len:189 episode reward: total was 2.000000. running mean: -50.079636\n",
      "ep 9: ep_len:635 episode reward: total was -50.290000. running mean: -50.081740\n",
      "ep 9: ep_len:198 episode reward: total was -3.000000. running mean: -49.610923\n",
      "ep 9: ep_len:500 episode reward: total was -15.170000. running mean: -49.266514\n",
      "ep 9: ep_len:745 episode reward: total was -29.470000. running mean: -49.068548\n",
      "ep 9: ep_len:500 episode reward: total was -13.840000. running mean: -48.716263\n",
      "ep 9: ep_len:165 episode reward: total was 5.000000. running mean: -48.179100\n",
      "ep 9: ep_len:500 episode reward: total was 0.210000. running mean: -47.695209\n",
      "ep 9: ep_len:640 episode reward: total was -54.290000. running mean: -47.761157\n",
      "ep 9: ep_len:520 episode reward: total was -58.080000. running mean: -47.864346\n",
      "ep 9: ep_len:1000 episode reward: total was -30.070000. running mean: -47.686402\n",
      "ep 9: ep_len:500 episode reward: total was -11.640000. running mean: -47.325938\n",
      "ep 9: ep_len:915 episode reward: total was -46.800000. running mean: -47.320679\n",
      "ep 9: ep_len:500 episode reward: total was -19.090000. running mean: -47.038372\n",
      "ep 9: ep_len:510 episode reward: total was 2.250000. running mean: -46.545488\n",
      "ep 9: ep_len:885 episode reward: total was -139.300000. running mean: -47.473033\n",
      "ep 9: ep_len:730 episode reward: total was -27.480000. running mean: -47.273103\n",
      "ep 9: ep_len:500 episode reward: total was -7.760000. running mean: -46.877972\n",
      "ep 9: ep_len:500 episode reward: total was -29.520000. running mean: -46.704392\n",
      "ep 9: ep_len:500 episode reward: total was -19.200000. running mean: -46.429348\n",
      "ep 9: ep_len:985 episode reward: total was -40.390000. running mean: -46.368955\n",
      "ep 9: ep_len:825 episode reward: total was -25.930000. running mean: -46.164565\n",
      "ep 9: ep_len:800 episode reward: total was -51.970000. running mean: -46.222620\n",
      "ep 9: ep_len:505 episode reward: total was -12.470000. running mean: -45.885093\n",
      "ep 9: ep_len:1005 episode reward: total was -45.030000. running mean: -45.876543\n",
      "ep 9: ep_len:645 episode reward: total was -26.520000. running mean: -45.682977\n",
      "ep 9: ep_len:990 episode reward: total was -34.670000. running mean: -45.572847\n",
      "ep 9: ep_len:575 episode reward: total was -41.810000. running mean: -45.535219\n",
      "ep 9: ep_len:505 episode reward: total was -3.040000. running mean: -45.110267\n",
      "ep 9: ep_len:635 episode reward: total was -68.440000. running mean: -45.343564\n",
      "ep 9: ep_len:930 episode reward: total was -11.450000. running mean: -45.004628\n",
      "ep 9: ep_len:224 episode reward: total was 7.000000. running mean: -44.484582\n",
      "ep 9: ep_len:650 episode reward: total was -65.900000. running mean: -44.698736\n",
      "ep 9: ep_len:755 episode reward: total was -66.700000. running mean: -44.918749\n",
      "ep 9: ep_len:930 episode reward: total was -40.230000. running mean: -44.871861\n",
      "ep 9: ep_len:940 episode reward: total was -49.060000. running mean: -44.913743\n",
      "ep 9: ep_len:505 episode reward: total was 5.500000. running mean: -44.409605\n",
      "ep 9: ep_len:555 episode reward: total was -4.770000. running mean: -44.013209\n",
      "ep 9: ep_len:815 episode reward: total was -27.740000. running mean: -43.850477\n",
      "ep 9: ep_len:500 episode reward: total was -34.820000. running mean: -43.760172\n",
      "ep 9: ep_len:980 episode reward: total was -58.670000. running mean: -43.909271\n",
      "ep 9: ep_len:950 episode reward: total was -70.320000. running mean: -44.173378\n",
      "ep 9: ep_len:975 episode reward: total was -96.150000. running mean: -44.693144\n",
      "ep 9: ep_len:565 episode reward: total was -28.210000. running mean: -44.528313\n",
      "ep 9: ep_len:700 episode reward: total was -35.950000. running mean: -44.442530\n",
      "ep 9: ep_len:500 episode reward: total was -34.890000. running mean: -44.347004\n",
      "ep 9: ep_len:500 episode reward: total was -31.920000. running mean: -44.222734\n",
      "ep 9: ep_len:560 episode reward: total was -47.410000. running mean: -44.254607\n",
      "ep 9: ep_len:955 episode reward: total was -35.580000. running mean: -44.167861\n",
      "ep 9: ep_len:1080 episode reward: total was -46.910000. running mean: -44.195282\n",
      "ep 9: ep_len:1315 episode reward: total was -187.300000. running mean: -45.626329\n",
      "ep 9: ep_len:615 episode reward: total was -33.160000. running mean: -45.501666\n",
      "ep 9: ep_len:387 episode reward: total was 11.500000. running mean: -44.931650\n",
      "ep 9: ep_len:500 episode reward: total was 4.240000. running mean: -44.439933\n",
      "ep 9: ep_len:500 episode reward: total was -17.330000. running mean: -44.168834\n",
      "ep 9: ep_len:705 episode reward: total was -31.970000. running mean: -44.046845\n",
      "ep 9: ep_len:760 episode reward: total was -57.110000. running mean: -44.177477\n",
      "ep 9: ep_len:955 episode reward: total was -71.980000. running mean: -44.455502\n",
      "ep 9: ep_len:965 episode reward: total was -38.290000. running mean: -44.393847\n",
      "ep 9: ep_len:900 episode reward: total was -25.830000. running mean: -44.208209\n",
      "ep 9: ep_len:500 episode reward: total was -12.790000. running mean: -43.894027\n",
      "ep 9: ep_len:515 episode reward: total was -14.040000. running mean: -43.595486\n",
      "ep 9: ep_len:745 episode reward: total was -44.010000. running mean: -43.599631\n",
      "ep 9: ep_len:510 episode reward: total was -37.900000. running mean: -43.542635\n",
      "ep 9: ep_len:500 episode reward: total was 5.190000. running mean: -43.055309\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 9: ep_len:1025 episode reward: total was -38.530000. running mean: -43.010056\n",
      "ep 9: ep_len:675 episode reward: total was -42.620000. running mean: -43.006155\n",
      "ep 9: ep_len:545 episode reward: total was -39.360000. running mean: -42.969694\n",
      "ep 9: ep_len:172 episode reward: total was 6.500000. running mean: -42.474997\n",
      "ep 9: ep_len:515 episode reward: total was -62.270000. running mean: -42.672947\n",
      "ep 9: ep_len:900 episode reward: total was -34.050000. running mean: -42.586717\n",
      "ep 9: ep_len:500 episode reward: total was -10.070000. running mean: -42.261550\n",
      "ep 9: ep_len:760 episode reward: total was -30.580000. running mean: -42.144735\n",
      "ep 9: ep_len:755 episode reward: total was -42.540000. running mean: -42.148687\n",
      "ep 9: ep_len:500 episode reward: total was -29.010000. running mean: -42.017300\n",
      "ep 9: ep_len:500 episode reward: total was -33.970000. running mean: -41.936827\n",
      "ep 9: ep_len:500 episode reward: total was -16.050000. running mean: -41.677959\n",
      "ep 9: ep_len:705 episode reward: total was -33.960000. running mean: -41.600779\n",
      "ep 9: ep_len:715 episode reward: total was -36.480000. running mean: -41.549572\n",
      "ep 9: ep_len:830 episode reward: total was -19.160000. running mean: -41.325676\n",
      "ep 9: ep_len:750 episode reward: total was -27.120000. running mean: -41.183619\n",
      "ep 9: ep_len:402 episode reward: total was -4.780000. running mean: -40.819583\n",
      "ep 9: ep_len:505 episode reward: total was -19.870000. running mean: -40.610087\n",
      "ep 9: ep_len:500 episode reward: total was -26.410000. running mean: -40.468086\n",
      "ep 9: ep_len:473 episode reward: total was 0.720000. running mean: -40.056205\n",
      "ep 9: ep_len:500 episode reward: total was -2.280000. running mean: -39.678443\n",
      "ep 9: ep_len:800 episode reward: total was -42.570000. running mean: -39.707359\n",
      "ep 9: ep_len:500 episode reward: total was -16.800000. running mean: -39.478285\n",
      "ep 9: ep_len:1045 episode reward: total was -38.350000. running mean: -39.467002\n",
      "ep 9: ep_len:500 episode reward: total was 2.720000. running mean: -39.045132\n",
      "ep 9: ep_len:500 episode reward: total was -18.380000. running mean: -38.838481\n",
      "ep 9: ep_len:630 episode reward: total was -23.230000. running mean: -38.682396\n",
      "ep 9: ep_len:865 episode reward: total was -46.550000. running mean: -38.761072\n",
      "ep 9: ep_len:500 episode reward: total was -18.050000. running mean: -38.553962\n",
      "ep 9: ep_len:570 episode reward: total was -41.540000. running mean: -38.583822\n",
      "ep 9: ep_len:790 episode reward: total was -56.010000. running mean: -38.758084\n",
      "ep 9: ep_len:635 episode reward: total was -30.090000. running mean: -38.671403\n",
      "ep 9: ep_len:500 episode reward: total was -12.170000. running mean: -38.406389\n",
      "ep 9: ep_len:500 episode reward: total was -12.780000. running mean: -38.150125\n",
      "ep 9: ep_len:675 episode reward: total was -20.920000. running mean: -37.977824\n",
      "ep 9: ep_len:560 episode reward: total was -21.640000. running mean: -37.814446\n",
      "ep 9: ep_len:150 episode reward: total was 4.500000. running mean: -37.391301\n",
      "ep 9: ep_len:139 episode reward: total was 9.000000. running mean: -36.927388\n",
      "ep 9: ep_len:500 episode reward: total was -33.390000. running mean: -36.892014\n",
      "ep 9: ep_len:525 episode reward: total was -20.200000. running mean: -36.725094\n",
      "ep 9: ep_len:530 episode reward: total was -76.240000. running mean: -37.120243\n",
      "ep 9: ep_len:386 episode reward: total was -23.990000. running mean: -36.988941\n",
      "ep 9: ep_len:500 episode reward: total was -26.840000. running mean: -36.887451\n",
      "ep 9: ep_len:850 episode reward: total was -54.910000. running mean: -37.067677\n",
      "ep 9: ep_len:500 episode reward: total was -24.290000. running mean: -36.939900\n",
      "ep 9: ep_len:500 episode reward: total was -7.260000. running mean: -36.643101\n",
      "ep 9: ep_len:920 episode reward: total was -71.940000. running mean: -36.996070\n",
      "ep 9: ep_len:765 episode reward: total was -43.370000. running mean: -37.059809\n",
      "ep 9: ep_len:184 episode reward: total was -2.000000. running mean: -36.709211\n",
      "ep 9: ep_len:555 episode reward: total was -34.060000. running mean: -36.682719\n",
      "ep 9: ep_len:570 episode reward: total was -7.640000. running mean: -36.392292\n",
      "ep 9: ep_len:280 episode reward: total was 6.000000. running mean: -35.968369\n",
      "ep 9: ep_len:119 episode reward: total was 1.500000. running mean: -35.593685\n",
      "ep 9: ep_len:950 episode reward: total was -47.700000. running mean: -35.714748\n",
      "ep 9: ep_len:865 episode reward: total was -71.530000. running mean: -36.072901\n",
      "ep 9: ep_len:259 episode reward: total was 12.000000. running mean: -35.592172\n",
      "ep 9: ep_len:500 episode reward: total was -17.530000. running mean: -35.411550\n",
      "ep 9: ep_len:725 episode reward: total was -35.970000. running mean: -35.417135\n",
      "ep 9: ep_len:500 episode reward: total was -28.390000. running mean: -35.346863\n",
      "ep 9: ep_len:249 episode reward: total was 10.000000. running mean: -34.893395\n",
      "ep 9: ep_len:175 episode reward: total was -0.500000. running mean: -34.549461\n",
      "ep 9: ep_len:585 episode reward: total was -34.720000. running mean: -34.551166\n",
      "ep 9: ep_len:655 episode reward: total was -28.030000. running mean: -34.485955\n",
      "ep 9: ep_len:660 episode reward: total was -27.500000. running mean: -34.416095\n",
      "ep 9: ep_len:171 episode reward: total was -0.500000. running mean: -34.076934\n",
      "ep 9: ep_len:500 episode reward: total was -30.900000. running mean: -34.045165\n",
      "ep 9: ep_len:500 episode reward: total was 2.190000. running mean: -33.682813\n",
      "ep 9: ep_len:505 episode reward: total was 27.000000. running mean: -33.075985\n",
      "ep 9: ep_len:510 episode reward: total was -13.840000. running mean: -32.883625\n",
      "ep 9: ep_len:288 episode reward: total was 6.500000. running mean: -32.489789\n",
      "ep 9: ep_len:500 episode reward: total was -15.430000. running mean: -32.319191\n",
      "ep 9: ep_len:620 episode reward: total was -39.700000. running mean: -32.392999\n",
      "ep 9: ep_len:500 episode reward: total was -19.290000. running mean: -32.261969\n",
      "ep 9: ep_len:745 episode reward: total was -34.920000. running mean: -32.288549\n",
      "ep 9: ep_len:500 episode reward: total was -35.770000. running mean: -32.323364\n",
      "ep 9: ep_len:1370 episode reward: total was -178.270000. running mean: -33.782830\n",
      "ep 9: ep_len:830 episode reward: total was -32.830000. running mean: -33.773302\n",
      "ep 9: ep_len:500 episode reward: total was -39.660000. running mean: -33.832169\n",
      "ep 9: ep_len:500 episode reward: total was -26.310000. running mean: -33.756947\n",
      "ep 9: ep_len:257 episode reward: total was -10.000000. running mean: -33.519378\n",
      "ep 9: ep_len:206 episode reward: total was 14.500000. running mean: -33.039184\n",
      "ep 9: ep_len:138 episode reward: total was 1.500000. running mean: -32.693792\n",
      "ep 9: ep_len:665 episode reward: total was -43.730000. running mean: -32.804154\n",
      "ep 9: ep_len:1100 episode reward: total was -88.920000. running mean: -33.365313\n",
      "ep 9: ep_len:505 episode reward: total was -23.310000. running mean: -33.264760\n",
      "ep 9: ep_len:400 episode reward: total was -19.690000. running mean: -33.129012\n",
      "ep 9: ep_len:985 episode reward: total was -35.590000. running mean: -33.153622\n",
      "ep 9: ep_len:1095 episode reward: total was -73.680000. running mean: -33.558886\n",
      "ep 9: ep_len:1500 episode reward: total was -179.830000. running mean: -35.021597\n",
      "ep 9: ep_len:750 episode reward: total was -33.380000. running mean: -35.005181\n",
      "ep 9: ep_len:500 episode reward: total was -42.540000. running mean: -35.080529\n",
      "ep 9: ep_len:585 episode reward: total was -38.760000. running mean: -35.117324\n",
      "ep 9: ep_len:820 episode reward: total was -49.380000. running mean: -35.259950\n",
      "ep 9: ep_len:965 episode reward: total was -35.450000. running mean: -35.261851\n",
      "ep 9: ep_len:1270 episode reward: total was -87.850000. running mean: -35.787732\n",
      "ep 9: ep_len:535 episode reward: total was -40.880000. running mean: -35.838655\n",
      "ep 9: ep_len:500 episode reward: total was -44.010000. running mean: -35.920369\n",
      "ep 9: ep_len:500 episode reward: total was -6.310000. running mean: -35.624265\n",
      "ep 9: ep_len:127 episode reward: total was 7.000000. running mean: -35.198022\n",
      "ep 9: ep_len:500 episode reward: total was -2.650000. running mean: -34.872542\n",
      "ep 9: ep_len:735 episode reward: total was -73.320000. running mean: -35.257017\n",
      "ep 9: ep_len:545 episode reward: total was -38.350000. running mean: -35.287946\n",
      "ep 9: ep_len:625 episode reward: total was -21.400000. running mean: -35.149067\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 9: ep_len:615 episode reward: total was -42.220000. running mean: -35.219776\n",
      "ep 9: ep_len:183 episode reward: total was 8.000000. running mean: -34.787578\n",
      "ep 9: ep_len:219 episode reward: total was 11.000000. running mean: -34.329703\n",
      "ep 9: ep_len:279 episode reward: total was 13.000000. running mean: -33.856406\n",
      "ep 9: ep_len:342 episode reward: total was 16.000000. running mean: -33.357842\n",
      "ep 9: ep_len:424 episode reward: total was 1.510000. running mean: -33.009163\n",
      "ep 9: ep_len:815 episode reward: total was -99.390000. running mean: -33.672972\n",
      "ep 9: ep_len:660 episode reward: total was -18.280000. running mean: -33.519042\n",
      "ep 9: ep_len:645 episode reward: total was -9.830000. running mean: -33.282151\n",
      "ep 9: ep_len:500 episode reward: total was -12.780000. running mean: -33.077130\n",
      "ep 9: ep_len:500 episode reward: total was -13.130000. running mean: -32.877659\n",
      "ep 9: ep_len:273 episode reward: total was 4.500000. running mean: -32.503882\n",
      "ep 9: ep_len:500 episode reward: total was 12.500000. running mean: -32.053843\n",
      "ep 9: ep_len:500 episode reward: total was -25.340000. running mean: -31.986705\n",
      "ep 9: ep_len:197 episode reward: total was 9.500000. running mean: -31.571838\n",
      "ep 9: ep_len:500 episode reward: total was -17.280000. running mean: -31.428919\n",
      "ep 9: ep_len:1000 episode reward: total was -64.460000. running mean: -31.759230\n",
      "ep 9: ep_len:800 episode reward: total was -48.950000. running mean: -31.931138\n",
      "ep 9: ep_len:500 episode reward: total was -26.300000. running mean: -31.874826\n",
      "ep 9: ep_len:500 episode reward: total was -10.270000. running mean: -31.658778\n",
      "ep 9: ep_len:1865 episode reward: total was -272.050000. running mean: -34.062690\n",
      "ep 9: ep_len:840 episode reward: total was -47.860000. running mean: -34.200664\n",
      "ep 9: ep_len:500 episode reward: total was -13.300000. running mean: -33.991657\n",
      "ep 9: ep_len:525 episode reward: total was -37.350000. running mean: -34.025240\n",
      "ep 9: ep_len:500 episode reward: total was -1.850000. running mean: -33.703488\n",
      "ep 9: ep_len:635 episode reward: total was -69.600000. running mean: -34.062453\n",
      "ep 9: ep_len:389 episode reward: total was -18.830000. running mean: -33.910129\n",
      "ep 9: ep_len:970 episode reward: total was -69.820000. running mean: -34.269227\n",
      "ep 9: ep_len:500 episode reward: total was -16.790000. running mean: -34.094435\n",
      "ep 9: ep_len:635 episode reward: total was -40.680000. running mean: -34.160291\n",
      "ep 9: ep_len:515 episode reward: total was -61.120000. running mean: -34.429888\n",
      "ep 9: ep_len:725 episode reward: total was -32.940000. running mean: -34.414989\n",
      "ep 9: ep_len:371 episode reward: total was 6.000000. running mean: -34.010839\n",
      "ep 9: ep_len:505 episode reward: total was -11.780000. running mean: -33.788531\n",
      "ep 9: ep_len:134 episode reward: total was -5.000000. running mean: -33.500645\n",
      "ep 9: ep_len:500 episode reward: total was -13.490000. running mean: -33.300539\n",
      "ep 9: ep_len:590 episode reward: total was -19.390000. running mean: -33.161433\n",
      "ep 9: ep_len:266 episode reward: total was 14.500000. running mean: -32.684819\n",
      "ep 9: ep_len:1430 episode reward: total was -159.360000. running mean: -33.951571\n",
      "ep 9: ep_len:1050 episode reward: total was -129.250000. running mean: -34.904555\n",
      "ep 9: ep_len:540 episode reward: total was -29.270000. running mean: -34.848210\n",
      "ep 9: ep_len:570 episode reward: total was -80.690000. running mean: -35.306628\n",
      "ep 9: ep_len:510 episode reward: total was -27.280000. running mean: -35.226361\n",
      "ep 9: ep_len:900 episode reward: total was -44.860000. running mean: -35.322698\n",
      "ep 9: ep_len:595 episode reward: total was -44.810000. running mean: -35.417571\n",
      "ep 9: ep_len:845 episode reward: total was -34.130000. running mean: -35.404695\n",
      "ep 9: ep_len:239 episode reward: total was -35.000000. running mean: -35.400648\n",
      "ep 9: ep_len:560 episode reward: total was -82.760000. running mean: -35.874242\n",
      "ep 9: ep_len:227 episode reward: total was -18.500000. running mean: -35.700499\n",
      "ep 9: ep_len:545 episode reward: total was -44.380000. running mean: -35.787294\n",
      "ep 9: ep_len:720 episode reward: total was -62.350000. running mean: -36.052921\n",
      "ep 9: ep_len:500 episode reward: total was -11.250000. running mean: -35.804892\n",
      "ep 9: ep_len:500 episode reward: total was -9.270000. running mean: -35.539543\n",
      "ep 9: ep_len:505 episode reward: total was -17.520000. running mean: -35.359348\n",
      "ep 9: ep_len:695 episode reward: total was -31.990000. running mean: -35.325654\n",
      "ep 9: ep_len:780 episode reward: total was -14.720000. running mean: -35.119598\n",
      "ep 9: ep_len:535 episode reward: total was -35.340000. running mean: -35.121802\n",
      "ep 9: ep_len:545 episode reward: total was -34.420000. running mean: -35.114784\n",
      "ep 9: ep_len:500 episode reward: total was -34.520000. running mean: -35.108836\n",
      "ep 9: ep_len:385 episode reward: total was -33.220000. running mean: -35.089947\n",
      "ep 9: ep_len:332 episode reward: total was -10.340000. running mean: -34.842448\n",
      "ep 9: ep_len:575 episode reward: total was -18.970000. running mean: -34.683723\n",
      "ep 9: ep_len:560 episode reward: total was -35.290000. running mean: -34.689786\n",
      "ep 9: ep_len:885 episode reward: total was -54.840000. running mean: -34.891288\n",
      "ep 9: ep_len:497 episode reward: total was -59.640000. running mean: -35.138775\n",
      "ep 9: ep_len:505 episode reward: total was 9.500000. running mean: -34.692388\n",
      "ep 9: ep_len:755 episode reward: total was -72.380000. running mean: -35.069264\n",
      "ep 9: ep_len:500 episode reward: total was -40.300000. running mean: -35.121571\n",
      "ep 9: ep_len:515 episode reward: total was 0.720000. running mean: -34.763155\n",
      "ep 9: ep_len:530 episode reward: total was -23.230000. running mean: -34.647824\n",
      "ep 9: ep_len:750 episode reward: total was -29.370000. running mean: -34.595046\n",
      "ep 9: ep_len:232 episode reward: total was 8.500000. running mean: -34.164095\n",
      "ep 9: ep_len:1130 episode reward: total was -89.180000. running mean: -34.714254\n",
      "ep 9: ep_len:500 episode reward: total was -25.600000. running mean: -34.623112\n",
      "ep 9: ep_len:500 episode reward: total was -16.830000. running mean: -34.445181\n",
      "ep 9: ep_len:700 episode reward: total was -16.500000. running mean: -34.265729\n",
      "ep 9: ep_len:500 episode reward: total was -25.400000. running mean: -34.177072\n",
      "ep 9: ep_len:830 episode reward: total was -117.590000. running mean: -35.011201\n",
      "ep 9: ep_len:500 episode reward: total was -20.210000. running mean: -34.863189\n",
      "ep 9: ep_len:590 episode reward: total was -79.690000. running mean: -35.311457\n",
      "ep 9: ep_len:2395 episode reward: total was -245.990000. running mean: -37.418242\n",
      "ep 9: ep_len:500 episode reward: total was -41.850000. running mean: -37.462560\n",
      "ep 9: ep_len:500 episode reward: total was -28.840000. running mean: -37.376334\n",
      "ep 9: ep_len:1795 episode reward: total was -124.950000. running mean: -38.252071\n",
      "ep 9: ep_len:540 episode reward: total was -30.340000. running mean: -38.172950\n",
      "ep 9: ep_len:715 episode reward: total was -47.070000. running mean: -38.261921\n",
      "ep 9: ep_len:710 episode reward: total was -35.970000. running mean: -38.239002\n",
      "ep 9: ep_len:500 episode reward: total was 19.000000. running mean: -37.666612\n",
      "ep 9: ep_len:1020 episode reward: total was -98.000000. running mean: -38.269945\n",
      "ep 9: ep_len:500 episode reward: total was -27.470000. running mean: -38.161946\n",
      "ep 9: ep_len:1655 episode reward: total was -86.600000. running mean: -38.646327\n",
      "ep 9: ep_len:1122 episode reward: total was -76.260000. running mean: -39.022463\n",
      "ep 9: ep_len:500 episode reward: total was -34.350000. running mean: -38.975739\n",
      "ep 9: ep_len:810 episode reward: total was -54.470000. running mean: -39.130681\n",
      "ep 9: ep_len:770 episode reward: total was -47.480000. running mean: -39.214174\n",
      "ep 9: ep_len:540 episode reward: total was -49.440000. running mean: -39.316433\n",
      "ep 9: ep_len:203 episode reward: total was 9.500000. running mean: -38.828268\n",
      "ep 9: ep_len:775 episode reward: total was -49.000000. running mean: -38.929986\n",
      "ep 9: ep_len:510 episode reward: total was -23.660000. running mean: -38.777286\n",
      "ep 9: ep_len:675 episode reward: total was -29.000000. running mean: -38.679513\n",
      "ep 9: ep_len:505 episode reward: total was -36.550000. running mean: -38.658218\n",
      "ep 9: ep_len:500 episode reward: total was 7.190000. running mean: -38.199736\n",
      "ep 9: ep_len:1110 episode reward: total was -43.330000. running mean: -38.251038\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 9: ep_len:505 episode reward: total was -9.820000. running mean: -37.966728\n",
      "ep 9: ep_len:232 episode reward: total was 7.000000. running mean: -37.517061\n",
      "ep 9: ep_len:980 episode reward: total was -62.730000. running mean: -37.769190\n",
      "ep 9: ep_len:1015 episode reward: total was -66.610000. running mean: -38.057598\n",
      "ep 9: ep_len:755 episode reward: total was -53.690000. running mean: -38.213922\n",
      "ep 9: ep_len:795 episode reward: total was -20.430000. running mean: -38.036083\n",
      "ep 9: ep_len:1330 episode reward: total was -79.390000. running mean: -38.449622\n",
      "ep 9: ep_len:133 episode reward: total was 1.500000. running mean: -38.050126\n",
      "ep 9: ep_len:615 episode reward: total was -25.410000. running mean: -37.923725\n",
      "ep 9: ep_len:760 episode reward: total was -82.850000. running mean: -38.372987\n",
      "ep 9: ep_len:388 episode reward: total was -19.770000. running mean: -38.186957\n",
      "ep 9: ep_len:900 episode reward: total was -31.100000. running mean: -38.116088\n",
      "ep 9: ep_len:1305 episode reward: total was -88.050000. running mean: -38.615427\n",
      "ep 9: ep_len:1750 episode reward: total was -216.710000. running mean: -40.396373\n",
      "ep 9: ep_len:500 episode reward: total was -6.350000. running mean: -40.055909\n",
      "ep 9: ep_len:500 episode reward: total was -29.080000. running mean: -39.946150\n",
      "ep 9: ep_len:1005 episode reward: total was -119.240000. running mean: -40.739088\n",
      "ep 9: ep_len:500 episode reward: total was -10.810000. running mean: -40.439798\n",
      "ep 9: ep_len:1095 episode reward: total was -92.800000. running mean: -40.963400\n",
      "ep 9: ep_len:690 episode reward: total was -63.780000. running mean: -41.191566\n",
      "ep 9: ep_len:505 episode reward: total was -24.150000. running mean: -41.021150\n",
      "ep 9: ep_len:500 episode reward: total was -17.710000. running mean: -40.788038\n",
      "ep 9: ep_len:799 episode reward: total was -40.480000. running mean: -40.784958\n",
      "ep 9: ep_len:505 episode reward: total was -41.610000. running mean: -40.793208\n",
      "ep 9: ep_len:715 episode reward: total was -78.410000. running mean: -41.169376\n",
      "ep 9: ep_len:505 episode reward: total was -64.660000. running mean: -41.404283\n",
      "ep 9: ep_len:670 episode reward: total was -126.950000. running mean: -42.259740\n",
      "ep 9: ep_len:1270 episode reward: total was -32.810000. running mean: -42.165242\n",
      "ep 9: ep_len:625 episode reward: total was -16.090000. running mean: -41.904490\n",
      "ep 9: ep_len:500 episode reward: total was -23.380000. running mean: -41.719245\n",
      "ep 9: ep_len:500 episode reward: total was -8.530000. running mean: -41.387353\n",
      "ep 9: ep_len:885 episode reward: total was -62.400000. running mean: -41.597479\n",
      "ep 9: ep_len:800 episode reward: total was -32.790000. running mean: -41.509404\n",
      "ep 9: ep_len:480 episode reward: total was 5.650000. running mean: -41.037810\n",
      "ep 9: ep_len:735 episode reward: total was -46.870000. running mean: -41.096132\n",
      "ep 9: ep_len:10 episode reward: total was -0.500000. running mean: -40.690171\n",
      "ep 9: ep_len:500 episode reward: total was -5.800000. running mean: -40.341269\n",
      "ep 9: ep_len:735 episode reward: total was -5.020000. running mean: -39.988056\n",
      "ep 9: ep_len:500 episode reward: total was -21.320000. running mean: -39.801376\n",
      "ep 9: ep_len:500 episode reward: total was -26.900000. running mean: -39.672362\n",
      "ep 9: ep_len:500 episode reward: total was -0.200000. running mean: -39.277638\n",
      "ep 9: ep_len:510 episode reward: total was -0.820000. running mean: -38.893062\n",
      "ep 9: ep_len:500 episode reward: total was -20.310000. running mean: -38.707231\n",
      "ep 9: ep_len:675 episode reward: total was -59.300000. running mean: -38.913159\n",
      "ep 9: ep_len:695 episode reward: total was -26.940000. running mean: -38.793428\n",
      "ep 9: ep_len:505 episode reward: total was -4.750000. running mean: -38.452993\n",
      "ep 9: ep_len:150 episode reward: total was 5.510000. running mean: -38.013363\n",
      "ep 9: ep_len:800 episode reward: total was -40.870000. running mean: -38.041930\n",
      "ep 9: ep_len:500 episode reward: total was -21.450000. running mean: -37.876010\n",
      "ep 9: ep_len:500 episode reward: total was -6.220000. running mean: -37.559450\n",
      "ep 9: ep_len:500 episode reward: total was -18.340000. running mean: -37.367256\n",
      "ep 9: ep_len:500 episode reward: total was -20.910000. running mean: -37.202683\n",
      "ep 9: ep_len:525 episode reward: total was -34.350000. running mean: -37.174156\n",
      "ep 9: ep_len:565 episode reward: total was -52.940000. running mean: -37.331815\n",
      "ep 9: ep_len:195 episode reward: total was 4.500000. running mean: -36.913497\n",
      "ep 9: ep_len:595 episode reward: total was -10.650000. running mean: -36.650862\n",
      "ep 9: ep_len:505 episode reward: total was -20.780000. running mean: -36.492153\n",
      "ep 9: ep_len:575 episode reward: total was -52.430000. running mean: -36.651532\n",
      "ep 9: ep_len:580 episode reward: total was -26.800000. running mean: -36.553016\n",
      "ep 9: ep_len:535 episode reward: total was -47.460000. running mean: -36.662086\n",
      "ep 9: ep_len:500 episode reward: total was -78.990000. running mean: -37.085365\n",
      "ep 9: ep_len:600 episode reward: total was -55.430000. running mean: -37.268812\n",
      "ep 9: ep_len:392 episode reward: total was 24.500000. running mean: -36.651124\n",
      "ep 9: ep_len:500 episode reward: total was -11.340000. running mean: -36.398012\n",
      "ep 9: ep_len:525 episode reward: total was -20.700000. running mean: -36.241032\n",
      "ep 9: ep_len:530 episode reward: total was -39.020000. running mean: -36.268822\n",
      "ep 9: ep_len:189 episode reward: total was 12.500000. running mean: -35.781134\n",
      "ep 9: ep_len:160 episode reward: total was 3.000000. running mean: -35.393322\n",
      "ep 9: ep_len:515 episode reward: total was -30.820000. running mean: -35.347589\n",
      "ep 9: ep_len:810 episode reward: total was -38.490000. running mean: -35.379013\n",
      "ep 9: ep_len:615 episode reward: total was -31.110000. running mean: -35.336323\n",
      "ep 9: ep_len:760 episode reward: total was -58.500000. running mean: -35.567960\n",
      "ep 9: ep_len:500 episode reward: total was 19.000000. running mean: -35.022280\n",
      "ep 9: ep_len:161 episode reward: total was -3.500000. running mean: -34.707057\n",
      "ep 9: ep_len:510 episode reward: total was -7.340000. running mean: -34.433387\n",
      "ep 9: ep_len:765 episode reward: total was -53.550000. running mean: -34.624553\n",
      "ep 9: ep_len:510 episode reward: total was 0.230000. running mean: -34.276007\n",
      "ep 9: ep_len:204 episode reward: total was 5.000000. running mean: -33.883247\n",
      "ep 9: ep_len:695 episode reward: total was -14.790000. running mean: -33.692315\n",
      "ep 9: ep_len:505 episode reward: total was -25.300000. running mean: -33.608392\n",
      "ep 9: ep_len:1225 episode reward: total was -49.130000. running mean: -33.763608\n",
      "ep 9: ep_len:920 episode reward: total was -117.470000. running mean: -34.600672\n",
      "ep 9: ep_len:510 episode reward: total was -20.830000. running mean: -34.462965\n",
      "ep 9: ep_len:500 episode reward: total was -1.300000. running mean: -34.131335\n",
      "ep 9: ep_len:500 episode reward: total was -34.580000. running mean: -34.135822\n",
      "ep 9: ep_len:985 episode reward: total was -31.560000. running mean: -34.110064\n",
      "ep 9: ep_len:735 episode reward: total was -44.520000. running mean: -34.214163\n",
      "ep 9: ep_len:990 episode reward: total was -129.970000. running mean: -35.171722\n",
      "ep 9: ep_len:505 episode reward: total was -0.360000. running mean: -34.823604\n",
      "ep 9: ep_len:705 episode reward: total was -13.090000. running mean: -34.606268\n",
      "ep 9: ep_len:870 episode reward: total was -60.930000. running mean: -34.869506\n",
      "ep 9: ep_len:675 episode reward: total was -33.040000. running mean: -34.851211\n",
      "ep 9: ep_len:500 episode reward: total was 3.440000. running mean: -34.468298\n",
      "ep 9: ep_len:960 episode reward: total was -36.810000. running mean: -34.491715\n",
      "ep 9: ep_len:815 episode reward: total was -12.080000. running mean: -34.267598\n",
      "ep 9: ep_len:500 episode reward: total was -26.370000. running mean: -34.188622\n",
      "ep 9: ep_len:500 episode reward: total was -12.750000. running mean: -33.974236\n",
      "ep 9: ep_len:580 episode reward: total was -19.230000. running mean: -33.826794\n",
      "ep 9: ep_len:500 episode reward: total was -51.600000. running mean: -34.004526\n",
      "ep 9: ep_len:263 episode reward: total was 13.500000. running mean: -33.529481\n",
      "ep 9: ep_len:500 episode reward: total was -4.780000. running mean: -33.241986\n",
      "ep 9: ep_len:500 episode reward: total was 6.750000. running mean: -32.842066\n",
      "ep 9: ep_len:895 episode reward: total was -48.760000. running mean: -33.001245\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 9: ep_len:1325 episode reward: total was -198.880000. running mean: -34.660033\n",
      "ep 9: ep_len:510 episode reward: total was -33.180000. running mean: -34.645232\n",
      "ep 9: ep_len:500 episode reward: total was -24.260000. running mean: -34.541380\n",
      "ep 9: ep_len:500 episode reward: total was -21.270000. running mean: -34.408666\n",
      "ep 9: ep_len:820 episode reward: total was -20.580000. running mean: -34.270380\n",
      "ep 9: ep_len:500 episode reward: total was -30.480000. running mean: -34.232476\n",
      "ep 9: ep_len:680 episode reward: total was -28.830000. running mean: -34.178451\n",
      "ep 9: ep_len:630 episode reward: total was -54.830000. running mean: -34.384967\n",
      "ep 9: ep_len:1435 episode reward: total was -243.620000. running mean: -36.477317\n",
      "ep 9: ep_len:645 episode reward: total was -52.780000. running mean: -36.640344\n",
      "ep 9: ep_len:705 episode reward: total was -49.140000. running mean: -36.765340\n",
      "ep 9: ep_len:1695 episode reward: total was -240.090000. running mean: -38.798587\n",
      "ep 9: ep_len:640 episode reward: total was -48.260000. running mean: -38.893201\n",
      "ep 9: ep_len:560 episode reward: total was -42.650000. running mean: -38.930769\n",
      "ep 9: ep_len:482 episode reward: total was -46.270000. running mean: -39.004161\n",
      "ep 9: ep_len:1665 episode reward: total was -211.330000. running mean: -40.727420\n",
      "ep 9: ep_len:515 episode reward: total was -20.010000. running mean: -40.520246\n",
      "ep 9: ep_len:1415 episode reward: total was -170.940000. running mean: -41.824443\n",
      "ep 9: ep_len:960 episode reward: total was -82.970000. running mean: -42.235899\n",
      "ep 9: ep_len:545 episode reward: total was -20.670000. running mean: -42.020240\n",
      "ep 9: ep_len:500 episode reward: total was -27.480000. running mean: -41.874837\n",
      "ep 9: ep_len:670 episode reward: total was -45.140000. running mean: -41.907489\n",
      "ep 9: ep_len:505 episode reward: total was -1.810000. running mean: -41.506514\n",
      "ep 9: ep_len:516 episode reward: total was -23.780000. running mean: -41.329249\n",
      "ep 9: ep_len:505 episode reward: total was 3.240000. running mean: -40.883556\n",
      "ep 9: ep_len:645 episode reward: total was -32.090000. running mean: -40.795621\n",
      "ep 9: ep_len:500 episode reward: total was -36.020000. running mean: -40.747865\n",
      "ep 9: ep_len:122 episode reward: total was 6.000000. running mean: -40.280386\n",
      "ep 9: ep_len:500 episode reward: total was -18.660000. running mean: -40.064182\n",
      "ep 9: ep_len:585 episode reward: total was -17.900000. running mean: -39.842540\n",
      "ep 9: ep_len:580 episode reward: total was -16.770000. running mean: -39.611815\n",
      "ep 9: ep_len:505 episode reward: total was -22.960000. running mean: -39.445297\n",
      "ep 9: ep_len:750 episode reward: total was -30.350000. running mean: -39.354344\n",
      "ep 9: ep_len:500 episode reward: total was -32.430000. running mean: -39.285100\n",
      "ep 9: ep_len:720 episode reward: total was -104.140000. running mean: -39.933649\n",
      "ep 9: ep_len:500 episode reward: total was -0.020000. running mean: -39.534513\n",
      "ep 9: ep_len:500 episode reward: total was -16.150000. running mean: -39.300668\n",
      "ep 9: ep_len:740 episode reward: total was -44.020000. running mean: -39.347861\n",
      "ep 9: ep_len:845 episode reward: total was -56.540000. running mean: -39.519782\n",
      "ep 9: ep_len:493 episode reward: total was -5.830000. running mean: -39.182885\n",
      "ep 9: ep_len:905 episode reward: total was -48.970000. running mean: -39.280756\n",
      "ep 9: ep_len:785 episode reward: total was -47.380000. running mean: -39.361748\n",
      "ep 9: ep_len:500 episode reward: total was -2.270000. running mean: -38.990831\n",
      "ep 9: ep_len:500 episode reward: total was -24.880000. running mean: -38.849722\n",
      "ep 9: ep_len:250 episode reward: total was -24.500000. running mean: -38.706225\n",
      "ep 9: ep_len:2275 episode reward: total was -207.710000. running mean: -40.396263\n",
      "ep 9: ep_len:183 episode reward: total was 1.500000. running mean: -39.977300\n",
      "ep 9: ep_len:585 episode reward: total was -11.410000. running mean: -39.691627\n",
      "ep 9: ep_len:500 episode reward: total was -17.270000. running mean: -39.467411\n",
      "ep 9: ep_len:154 episode reward: total was 0.500000. running mean: -39.067737\n",
      "ep 9: ep_len:500 episode reward: total was -18.860000. running mean: -38.865660\n",
      "ep 9: ep_len:500 episode reward: total was -24.220000. running mean: -38.719203\n",
      "ep 9: ep_len:695 episode reward: total was -69.360000. running mean: -39.025611\n",
      "ep 9: ep_len:147 episode reward: total was 6.000000. running mean: -38.575355\n",
      "ep 9: ep_len:500 episode reward: total was -33.110000. running mean: -38.520701\n",
      "ep 9: ep_len:700 episode reward: total was -43.060000. running mean: -38.566094\n",
      "ep 9: ep_len:500 episode reward: total was -33.940000. running mean: -38.519833\n",
      "ep 9: ep_len:344 episode reward: total was 4.000000. running mean: -38.094635\n",
      "ep 9: ep_len:505 episode reward: total was -8.330000. running mean: -37.796989\n",
      "ep 9: ep_len:166 episode reward: total was 3.000000. running mean: -37.389019\n",
      "ep 9: ep_len:585 episode reward: total was -15.060000. running mean: -37.165729\n",
      "ep 9: ep_len:500 episode reward: total was -8.770000. running mean: -36.881771\n",
      "ep 9: ep_len:810 episode reward: total was -56.490000. running mean: -37.077854\n",
      "ep 9: ep_len:1055 episode reward: total was -38.480000. running mean: -37.091875\n",
      "ep 9: ep_len:500 episode reward: total was -37.110000. running mean: -37.092056\n",
      "ep 9: ep_len:505 episode reward: total was -29.340000. running mean: -37.014536\n",
      "ep 9: ep_len:500 episode reward: total was -21.900000. running mean: -36.863390\n",
      "ep 9: ep_len:510 episode reward: total was -31.870000. running mean: -36.813456\n",
      "ep 9: ep_len:353 episode reward: total was -12.900000. running mean: -36.574322\n",
      "ep 9: ep_len:635 episode reward: total was -35.510000. running mean: -36.563679\n",
      "ep 9: ep_len:620 episode reward: total was -109.910000. running mean: -37.297142\n",
      "ep 9: ep_len:505 episode reward: total was -10.040000. running mean: -37.024570\n",
      "ep 9: ep_len:1440 episode reward: total was -251.170000. running mean: -39.166025\n",
      "ep 9: ep_len:540 episode reward: total was -92.870000. running mean: -39.703064\n",
      "ep 9: ep_len:750 episode reward: total was -42.960000. running mean: -39.735634\n",
      "ep 9: ep_len:294 episode reward: total was 12.000000. running mean: -39.218277\n",
      "ep 9: ep_len:645 episode reward: total was -32.070000. running mean: -39.146795\n",
      "ep 9: ep_len:685 episode reward: total was -28.120000. running mean: -39.036527\n",
      "ep 9: ep_len:500 episode reward: total was -33.620000. running mean: -38.982362\n",
      "ep 9: ep_len:505 episode reward: total was -22.940000. running mean: -38.821938\n",
      "ep 9: ep_len:489 episode reward: total was -21.500000. running mean: -38.648719\n",
      "ep 9: ep_len:500 episode reward: total was -16.790000. running mean: -38.430131\n",
      "ep 9: ep_len:660 episode reward: total was -30.450000. running mean: -38.350330\n",
      "ep 9: ep_len:500 episode reward: total was -9.310000. running mean: -38.059927\n",
      "ep 9: ep_len:615 episode reward: total was -15.680000. running mean: -37.836127\n",
      "ep 9: ep_len:392 episode reward: total was 11.000000. running mean: -37.347766\n",
      "ep 9: ep_len:500 episode reward: total was -4.630000. running mean: -37.020589\n",
      "ep 9: ep_len:505 episode reward: total was -4.280000. running mean: -36.693183\n",
      "ep 9: ep_len:570 episode reward: total was -74.710000. running mean: -37.073351\n",
      "ep 9: ep_len:510 episode reward: total was 19.500000. running mean: -36.507617\n",
      "ep 9: ep_len:1000 episode reward: total was -111.870000. running mean: -37.261241\n",
      "ep 9: ep_len:540 episode reward: total was -77.230000. running mean: -37.660929\n",
      "ep 9: ep_len:317 episode reward: total was -7.770000. running mean: -37.362019\n",
      "ep 9: ep_len:775 episode reward: total was -60.030000. running mean: -37.588699\n",
      "ep 9: ep_len:282 episode reward: total was 10.000000. running mean: -37.112812\n",
      "ep 9: ep_len:505 episode reward: total was -27.150000. running mean: -37.013184\n",
      "ep 9: ep_len:505 episode reward: total was -23.980000. running mean: -36.882852\n",
      "ep 9: ep_len:237 episode reward: total was 8.500000. running mean: -36.429024\n",
      "ep 9: ep_len:505 episode reward: total was 5.240000. running mean: -36.012334\n",
      "ep 9: ep_len:2255 episode reward: total was -269.930000. running mean: -38.351510\n",
      "ep 9: ep_len:500 episode reward: total was 5.500000. running mean: -37.912995\n",
      "ep 9: ep_len:810 episode reward: total was -40.920000. running mean: -37.943065\n",
      "ep 9: ep_len:800 episode reward: total was -32.790000. running mean: -37.891534\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 9: ep_len:820 episode reward: total was -42.790000. running mean: -37.940519\n",
      "ep 9: ep_len:680 episode reward: total was -49.190000. running mean: -38.053014\n",
      "ep 9: ep_len:865 episode reward: total was -49.400000. running mean: -38.166484\n",
      "ep 9: ep_len:560 episode reward: total was -32.750000. running mean: -38.112319\n",
      "ep 9: ep_len:500 episode reward: total was -15.250000. running mean: -37.883696\n",
      "ep 9: ep_len:185 episode reward: total was 2.500000. running mean: -37.479859\n",
      "ep 9: ep_len:159 episode reward: total was 1.000000. running mean: -37.095060\n",
      "ep 9: ep_len:505 episode reward: total was -7.810000. running mean: -36.802210\n",
      "ep 9: ep_len:705 episode reward: total was -60.740000. running mean: -37.041588\n",
      "ep 9: ep_len:157 episode reward: total was 3.500000. running mean: -36.636172\n",
      "ep 9: ep_len:560 episode reward: total was -31.250000. running mean: -36.582310\n",
      "ep 9: ep_len:850 episode reward: total was -29.530000. running mean: -36.511787\n",
      "ep 9: ep_len:1290 episode reward: total was -127.240000. running mean: -37.419069\n",
      "ep 9: ep_len:880 episode reward: total was -52.310000. running mean: -37.567978\n",
      "ep 9: ep_len:500 episode reward: total was -19.230000. running mean: -37.384598\n",
      "ep 9: ep_len:715 episode reward: total was -28.890000. running mean: -37.299653\n",
      "ep 9: ep_len:700 episode reward: total was -44.100000. running mean: -37.367656\n",
      "ep 9: ep_len:505 episode reward: total was -11.310000. running mean: -37.107079\n",
      "ep 9: ep_len:303 episode reward: total was 6.000000. running mean: -36.676009\n",
      "ep 9: ep_len:500 episode reward: total was -16.000000. running mean: -36.469249\n",
      "ep 9: ep_len:721 episode reward: total was -38.470000. running mean: -36.489256\n",
      "ep 9: ep_len:520 episode reward: total was -22.240000. running mean: -36.346763\n",
      "ep 9: ep_len:555 episode reward: total was -44.390000. running mean: -36.427196\n",
      "ep 9: ep_len:1050 episode reward: total was -40.240000. running mean: -36.465324\n",
      "ep 9: ep_len:634 episode reward: total was -96.960000. running mean: -37.070271\n",
      "ep 9: ep_len:467 episode reward: total was -7.950000. running mean: -36.779068\n",
      "ep 9: ep_len:665 episode reward: total was -36.580000. running mean: -36.777077\n",
      "ep 9: ep_len:1310 episode reward: total was -203.470000. running mean: -38.444007\n",
      "ep 9: ep_len:292 episode reward: total was 4.000000. running mean: -38.019566\n",
      "ep 9: ep_len:1095 episode reward: total was -60.560000. running mean: -38.244971\n",
      "ep 9: ep_len:550 episode reward: total was -40.360000. running mean: -38.266121\n",
      "ep 9: ep_len:500 episode reward: total was -47.560000. running mean: -38.359060\n",
      "ep 9: ep_len:432 episode reward: total was -18.830000. running mean: -38.163769\n",
      "ep 9: ep_len:500 episode reward: total was -21.750000. running mean: -37.999632\n",
      "ep 9: ep_len:730 episode reward: total was -40.000000. running mean: -38.019635\n",
      "ep 9: ep_len:515 episode reward: total was -35.350000. running mean: -37.992939\n",
      "ep 9: ep_len:795 episode reward: total was -36.870000. running mean: -37.981710\n",
      "ep 9: ep_len:590 episode reward: total was -41.290000. running mean: -38.014792\n",
      "ep 9: ep_len:805 episode reward: total was -36.300000. running mean: -37.997644\n",
      "ep 9: ep_len:275 episode reward: total was -3.500000. running mean: -37.652668\n",
      "ep 9: ep_len:815 episode reward: total was -31.370000. running mean: -37.589841\n",
      "ep 9: ep_len:755 episode reward: total was -42.110000. running mean: -37.635043\n",
      "ep 9: ep_len:715 episode reward: total was -32.440000. running mean: -37.583093\n",
      "ep 9: ep_len:790 episode reward: total was -119.690000. running mean: -38.404162\n",
      "ep 9: ep_len:595 episode reward: total was -57.520000. running mean: -38.595320\n",
      "ep 9: ep_len:500 episode reward: total was -7.800000. running mean: -38.287367\n",
      "ep 9: ep_len:505 episode reward: total was -5.700000. running mean: -37.961493\n",
      "ep 9: ep_len:920 episode reward: total was -71.420000. running mean: -38.296078\n",
      "ep 9: ep_len:700 episode reward: total was -34.800000. running mean: -38.261117\n",
      "ep 9: ep_len:500 episode reward: total was -32.900000. running mean: -38.207506\n",
      "ep 9: ep_len:760 episode reward: total was -36.400000. running mean: -38.189431\n",
      "ep 9: ep_len:500 episode reward: total was -42.500000. running mean: -38.232537\n",
      "ep 9: ep_len:500 episode reward: total was -21.350000. running mean: -38.063711\n",
      "ep 9: ep_len:197 episode reward: total was -5.410000. running mean: -37.737174\n",
      "ep 9: ep_len:500 episode reward: total was -9.320000. running mean: -37.453003\n",
      "ep 9: ep_len:1005 episode reward: total was -110.510000. running mean: -38.183573\n",
      "ep 9: ep_len:795 episode reward: total was -42.380000. running mean: -38.225537\n",
      "ep 9: ep_len:500 episode reward: total was -13.810000. running mean: -37.981382\n",
      "ep 9: ep_len:510 episode reward: total was -26.940000. running mean: -37.870968\n",
      "ep 9: ep_len:500 episode reward: total was -5.890000. running mean: -37.551158\n",
      "ep 9: ep_len:500 episode reward: total was -39.510000. running mean: -37.570746\n",
      "ep 9: ep_len:500 episode reward: total was -36.390000. running mean: -37.558939\n",
      "ep 9: ep_len:520 episode reward: total was -33.930000. running mean: -37.522650\n",
      "ep 9: ep_len:780 episode reward: total was -58.570000. running mean: -37.733123\n",
      "ep 9: ep_len:635 episode reward: total was -40.190000. running mean: -37.757692\n",
      "ep 9: ep_len:725 episode reward: total was -49.100000. running mean: -37.871115\n",
      "ep 9: ep_len:173 episode reward: total was 11.000000. running mean: -37.382404\n",
      "ep 9: ep_len:500 episode reward: total was 6.760000. running mean: -36.940980\n",
      "ep 9: ep_len:630 episode reward: total was -33.950000. running mean: -36.911070\n",
      "ep 9: ep_len:500 episode reward: total was -14.560000. running mean: -36.687559\n",
      "ep 9: ep_len:500 episode reward: total was -13.750000. running mean: -36.458184\n",
      "ep 9: ep_len:500 episode reward: total was -8.280000. running mean: -36.176402\n",
      "ep 9: ep_len:785 episode reward: total was -65.110000. running mean: -36.465738\n",
      "ep 9: ep_len:500 episode reward: total was -17.310000. running mean: -36.274180\n",
      "ep 9: ep_len:630 episode reward: total was -96.760000. running mean: -36.879039\n",
      "ep 9: ep_len:500 episode reward: total was 6.230000. running mean: -36.447948\n",
      "ep 9: ep_len:815 episode reward: total was -37.930000. running mean: -36.462769\n",
      "ep 9: ep_len:286 episode reward: total was 13.500000. running mean: -35.963141\n",
      "ep 9: ep_len:194 episode reward: total was 2.500000. running mean: -35.578510\n",
      "ep 9: ep_len:575 episode reward: total was -33.730000. running mean: -35.560025\n",
      "ep 9: ep_len:505 episode reward: total was -26.850000. running mean: -35.472924\n",
      "ep 9: ep_len:500 episode reward: total was -12.340000. running mean: -35.241595\n",
      "ep 9: ep_len:227 episode reward: total was 11.000000. running mean: -34.779179\n",
      "ep 9: ep_len:510 episode reward: total was -23.290000. running mean: -34.664287\n",
      "ep 9: ep_len:675 episode reward: total was -28.970000. running mean: -34.607344\n",
      "ep 9: ep_len:274 episode reward: total was 7.500000. running mean: -34.186271\n",
      "ep 9: ep_len:525 episode reward: total was -30.460000. running mean: -34.149008\n",
      "ep 9: ep_len:805 episode reward: total was -65.590000. running mean: -34.463418\n",
      "ep 9: ep_len:1535 episode reward: total was -245.440000. running mean: -36.573184\n",
      "ep 9: ep_len:615 episode reward: total was -58.900000. running mean: -36.796452\n",
      "ep 9: ep_len:500 episode reward: total was -45.660000. running mean: -36.885088\n",
      "ep 9: ep_len:500 episode reward: total was -37.980000. running mean: -36.896037\n",
      "ep 9: ep_len:795 episode reward: total was -22.630000. running mean: -36.753376\n",
      "ep 9: ep_len:149 episode reward: total was 2.500000. running mean: -36.360843\n",
      "ep 9: ep_len:500 episode reward: total was -46.520000. running mean: -36.462434\n",
      "ep 9: ep_len:500 episode reward: total was -24.250000. running mean: -36.340310\n",
      "ep 9: ep_len:500 episode reward: total was -1.270000. running mean: -35.989607\n",
      "ep 9: ep_len:165 episode reward: total was 9.000000. running mean: -35.539711\n",
      "ep 9: ep_len:366 episode reward: total was -15.990000. running mean: -35.344214\n",
      "ep 9: ep_len:605 episode reward: total was -27.610000. running mean: -35.266871\n",
      "ep 9: ep_len:500 episode reward: total was -44.120000. running mean: -35.355403\n",
      "ep 9: ep_len:500 episode reward: total was 21.500000. running mean: -34.786849\n",
      "ep 9: ep_len:685 episode reward: total was -32.500000. running mean: -34.763980\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 9: ep_len:500 episode reward: total was -5.190000. running mean: -34.468240\n",
      "ep 9: ep_len:231 episode reward: total was 2.000000. running mean: -34.103558\n",
      "ep 9: ep_len:615 episode reward: total was -64.470000. running mean: -34.407222\n",
      "ep 9: ep_len:446 episode reward: total was -35.500000. running mean: -34.418150\n",
      "ep 9: ep_len:575 episode reward: total was -60.480000. running mean: -34.678769\n",
      "ep 9: ep_len:840 episode reward: total was -17.560000. running mean: -34.507581\n",
      "ep 9: ep_len:710 episode reward: total was -35.320000. running mean: -34.515705\n",
      "ep 9: ep_len:645 episode reward: total was -13.410000. running mean: -34.304648\n",
      "ep 9: ep_len:500 episode reward: total was -34.060000. running mean: -34.302202\n",
      "ep 9: ep_len:615 episode reward: total was -14.900000. running mean: -34.108180\n",
      "ep 9: ep_len:2370 episode reward: total was -199.780000. running mean: -35.764898\n",
      "ep 9: ep_len:755 episode reward: total was -46.430000. running mean: -35.871549\n",
      "ep 9: ep_len:500 episode reward: total was -25.860000. running mean: -35.771433\n",
      "ep 9: ep_len:491 episode reward: total was 2.190000. running mean: -35.391819\n",
      "ep 9: ep_len:1090 episode reward: total was -119.560000. running mean: -36.233501\n",
      "ep 9: ep_len:500 episode reward: total was -11.790000. running mean: -35.989066\n",
      "ep 9: ep_len:500 episode reward: total was -9.750000. running mean: -35.726675\n",
      "ep 9: ep_len:381 episode reward: total was 9.500000. running mean: -35.274408\n",
      "ep 9: ep_len:535 episode reward: total was -15.920000. running mean: -35.080864\n",
      "ep 9: ep_len:500 episode reward: total was -5.770000. running mean: -34.787756\n",
      "ep 9: ep_len:500 episode reward: total was -4.300000. running mean: -34.482878\n",
      "ep 9: ep_len:500 episode reward: total was -15.500000. running mean: -34.293049\n",
      "ep 9: ep_len:640 episode reward: total was -31.580000. running mean: -34.265919\n",
      "ep 9: ep_len:625 episode reward: total was -15.380000. running mean: -34.077060\n",
      "ep 9: ep_len:500 episode reward: total was -32.470000. running mean: -34.060989\n",
      "ep 9: ep_len:505 episode reward: total was -5.790000. running mean: -33.778279\n",
      "ep 9: ep_len:500 episode reward: total was -31.970000. running mean: -33.760196\n",
      "ep 9: ep_len:500 episode reward: total was -18.540000. running mean: -33.607994\n",
      "ep 9: ep_len:500 episode reward: total was -39.220000. running mean: -33.664115\n",
      "ep 9: ep_len:1245 episode reward: total was -177.340000. running mean: -35.100873\n",
      "ep 9: ep_len:815 episode reward: total was -68.280000. running mean: -35.432665\n",
      "ep 9: ep_len:670 episode reward: total was -46.670000. running mean: -35.545038\n",
      "ep 9: ep_len:775 episode reward: total was -35.870000. running mean: -35.548288\n",
      "ep 9: ep_len:760 episode reward: total was -14.710000. running mean: -35.339905\n",
      "ep 9: ep_len:177 episode reward: total was 4.000000. running mean: -34.946506\n",
      "ep 9: ep_len:505 episode reward: total was -4.280000. running mean: -34.639841\n",
      "ep 9: ep_len:579 episode reward: total was -70.070000. running mean: -34.994142\n",
      "ep 9: ep_len:610 episode reward: total was -0.170000. running mean: -34.645901\n",
      "ep 9: ep_len:505 episode reward: total was -30.700000. running mean: -34.606442\n",
      "ep 9: ep_len:426 episode reward: total was -10.790000. running mean: -34.368277\n",
      "ep 9: ep_len:765 episode reward: total was -42.960000. running mean: -34.454195\n",
      "ep 9: ep_len:500 episode reward: total was -15.780000. running mean: -34.267453\n",
      "ep 9: ep_len:520 episode reward: total was -25.760000. running mean: -34.182378\n",
      "ep 9: ep_len:500 episode reward: total was -30.210000. running mean: -34.142654\n",
      "ep 9: ep_len:740 episode reward: total was -31.900000. running mean: -34.120228\n",
      "ep 9: ep_len:1090 episode reward: total was -92.950000. running mean: -34.708526\n",
      "ep 9: ep_len:550 episode reward: total was -24.200000. running mean: -34.603440\n",
      "ep 9: ep_len:500 episode reward: total was -9.630000. running mean: -34.353706\n",
      "ep 9: ep_len:815 episode reward: total was -2.960000. running mean: -34.039769\n",
      "ep 9: ep_len:1020 episode reward: total was -16.390000. running mean: -33.863271\n",
      "ep 9: ep_len:183 episode reward: total was 6.000000. running mean: -33.464638\n",
      "ep 9: ep_len:500 episode reward: total was -1.200000. running mean: -33.141992\n",
      "ep 9: ep_len:770 episode reward: total was -26.790000. running mean: -33.078472\n",
      "ep 9: ep_len:432 episode reward: total was -3.330000. running mean: -32.780987\n",
      "ep 9: ep_len:845 episode reward: total was -68.260000. running mean: -33.135778\n",
      "ep 9: ep_len:520 episode reward: total was -32.810000. running mean: -33.132520\n",
      "ep 9: ep_len:500 episode reward: total was -31.520000. running mean: -33.116395\n",
      "ep 9: ep_len:500 episode reward: total was -38.300000. running mean: -33.168231\n",
      "ep 9: ep_len:700 episode reward: total was -28.800000. running mean: -33.124548\n",
      "ep 9: ep_len:500 episode reward: total was -4.760000. running mean: -32.840903\n",
      "ep 9: ep_len:720 episode reward: total was -15.830000. running mean: -32.670794\n",
      "ep 9: ep_len:500 episode reward: total was -5.770000. running mean: -32.401786\n",
      "ep 9: ep_len:530 episode reward: total was -62.760000. running mean: -32.705368\n",
      "ep 9: ep_len:505 episode reward: total was -51.560000. running mean: -32.893914\n",
      "ep 9: ep_len:655 episode reward: total was -29.340000. running mean: -32.858375\n",
      "ep 9: ep_len:520 episode reward: total was -20.710000. running mean: -32.736891\n",
      "ep 9: ep_len:500 episode reward: total was -10.640000. running mean: -32.515923\n",
      "ep 9: ep_len:2655 episode reward: total was -388.770000. running mean: -36.078463\n",
      "ep 9: ep_len:980 episode reward: total was -45.720000. running mean: -36.174879\n",
      "ep 9: ep_len:500 episode reward: total was 17.500000. running mean: -35.638130\n",
      "ep 9: ep_len:898 episode reward: total was -92.170000. running mean: -36.203449\n",
      "ep 9: ep_len:535 episode reward: total was -27.430000. running mean: -36.115714\n",
      "ep 9: ep_len:500 episode reward: total was -27.620000. running mean: -36.030757\n",
      "ep 9: ep_len:500 episode reward: total was 17.000000. running mean: -35.500449\n",
      "ep 9: ep_len:505 episode reward: total was 14.000000. running mean: -35.005445\n",
      "ep 9: ep_len:565 episode reward: total was -20.620000. running mean: -34.861590\n",
      "ep 9: ep_len:251 episode reward: total was 12.000000. running mean: -34.392975\n",
      "epsilon:0.246086 episode_count: 7893. steps_count: 5583513.000000\n",
      "ep 10: ep_len:1605 episode reward: total was -168.900000. running mean: -35.738045\n",
      "ep 10: ep_len:885 episode reward: total was -42.890000. running mean: -35.809564\n",
      "ep 10: ep_len:505 episode reward: total was -32.700000. running mean: -35.778469\n",
      "ep 10: ep_len:970 episode reward: total was -52.230000. running mean: -35.942984\n",
      "ep 10: ep_len:505 episode reward: total was -14.860000. running mean: -35.732154\n",
      "ep 10: ep_len:505 episode reward: total was -58.230000. running mean: -35.957133\n",
      "ep 10: ep_len:695 episode reward: total was -41.080000. running mean: -36.008361\n",
      "ep 10: ep_len:655 episode reward: total was -45.200000. running mean: -36.100278\n",
      "ep 10: ep_len:875 episode reward: total was -53.510000. running mean: -36.274375\n",
      "ep 10: ep_len:1060 episode reward: total was -45.590000. running mean: -36.367531\n",
      "ep 10: ep_len:500 episode reward: total was -28.920000. running mean: -36.293056\n",
      "ep 10: ep_len:835 episode reward: total was -41.190000. running mean: -36.342025\n",
      "ep 10: ep_len:515 episode reward: total was -31.340000. running mean: -36.292005\n",
      "ep 10: ep_len:177 episode reward: total was 0.000000. running mean: -35.929085\n",
      "ep 10: ep_len:875 episode reward: total was -54.860000. running mean: -36.118394\n",
      "ep 10: ep_len:865 episode reward: total was -61.430000. running mean: -36.371510\n",
      "ep 10: ep_len:500 episode reward: total was -0.800000. running mean: -36.015795\n",
      "ep 10: ep_len:660 episode reward: total was -37.110000. running mean: -36.026737\n",
      "ep 10: ep_len:665 episode reward: total was -59.290000. running mean: -36.259370\n",
      "ep 10: ep_len:710 episode reward: total was -34.280000. running mean: -36.239576\n",
      "ep 10: ep_len:510 episode reward: total was -17.360000. running mean: -36.050780\n",
      "ep 10: ep_len:1480 episode reward: total was -150.610000. running mean: -37.196373\n",
      "ep 10: ep_len:980 episode reward: total was -100.590000. running mean: -37.830309\n",
      "ep 10: ep_len:500 episode reward: total was -25.820000. running mean: -37.710206\n",
      "ep 10: ep_len:500 episode reward: total was -18.940000. running mean: -37.522504\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 10: ep_len:525 episode reward: total was -36.860000. running mean: -37.515879\n",
      "ep 10: ep_len:500 episode reward: total was -14.470000. running mean: -37.285420\n",
      "ep 10: ep_len:14620 episode reward: total was -2779.590000. running mean: -64.708466\n",
      "ep 10: ep_len:500 episode reward: total was -11.800000. running mean: -64.179381\n",
      "ep 10: ep_len:500 episode reward: total was 0.200000. running mean: -63.535587\n",
      "ep 10: ep_len:525 episode reward: total was -73.740000. running mean: -63.637631\n",
      "ep 10: ep_len:204 episode reward: total was 1.000000. running mean: -62.991255\n",
      "ep 10: ep_len:605 episode reward: total was -32.380000. running mean: -62.685142\n",
      "ep 10: ep_len:500 episode reward: total was -27.020000. running mean: -62.328491\n",
      "ep 10: ep_len:505 episode reward: total was -2.890000. running mean: -61.734106\n",
      "ep 10: ep_len:715 episode reward: total was -33.400000. running mean: -61.450765\n",
      "ep 10: ep_len:725 episode reward: total was -44.050000. running mean: -61.276757\n",
      "ep 10: ep_len:605 episode reward: total was -35.200000. running mean: -61.015990\n",
      "ep 10: ep_len:505 episode reward: total was -17.400000. running mean: -60.579830\n",
      "ep 10: ep_len:749 episode reward: total was -75.300000. running mean: -60.727032\n",
      "ep 10: ep_len:500 episode reward: total was -19.310000. running mean: -60.312861\n",
      "ep 10: ep_len:500 episode reward: total was -31.980000. running mean: -60.029533\n",
      "ep 10: ep_len:560 episode reward: total was -53.650000. running mean: -59.965737\n",
      "ep 10: ep_len:555 episode reward: total was -50.450000. running mean: -59.870580\n",
      "ep 10: ep_len:500 episode reward: total was -22.970000. running mean: -59.501574\n",
      "ep 10: ep_len:174 episode reward: total was 0.500000. running mean: -58.901558\n",
      "ep 10: ep_len:19340 episode reward: total was -3711.500000. running mean: -95.427543\n",
      "ep 10: ep_len:710 episode reward: total was -47.080000. running mean: -94.944067\n",
      "ep 10: ep_len:920 episode reward: total was -74.970000. running mean: -94.744327\n",
      "ep 10: ep_len:500 episode reward: total was -59.970000. running mean: -94.396583\n",
      "ep 10: ep_len:735 episode reward: total was -63.220000. running mean: -94.084818\n",
      "ep 10: ep_len:640 episode reward: total was -48.720000. running mean: -93.631169\n",
      "ep 10: ep_len:500 episode reward: total was -17.890000. running mean: -92.873758\n",
      "ep 10: ep_len:665 episode reward: total was -80.530000. running mean: -92.750320\n",
      "ep 10: ep_len:500 episode reward: total was -35.160000. running mean: -92.174417\n",
      "ep 10: ep_len:720 episode reward: total was -58.690000. running mean: -91.839573\n",
      "ep 10: ep_len:635 episode reward: total was -24.720000. running mean: -91.168377\n",
      "ep 10: ep_len:18055 episode reward: total was -3465.110000. running mean: -124.907793\n",
      "ep 10: ep_len:945 episode reward: total was -61.840000. running mean: -124.277115\n",
      "ep 10: ep_len:560 episode reward: total was -38.810000. running mean: -123.422444\n",
      "ep 10: ep_len:550 episode reward: total was -4.810000. running mean: -122.236320\n",
      "ep 10: ep_len:500 episode reward: total was -36.940000. running mean: -121.383357\n",
      "ep 10: ep_len:1350 episode reward: total was -153.850000. running mean: -121.708023\n",
      "ep 10: ep_len:730 episode reward: total was -34.790000. running mean: -120.838843\n",
      "ep 10: ep_len:505 episode reward: total was -11.760000. running mean: -119.748054\n",
      "ep 10: ep_len:595 episode reward: total was -28.640000. running mean: -118.836974\n",
      "ep 10: ep_len:735 episode reward: total was -33.930000. running mean: -117.987904\n",
      "ep 10: ep_len:223 episode reward: total was 2.500000. running mean: -116.783025\n",
      "ep 10: ep_len:500 episode reward: total was -37.430000. running mean: -115.989495\n",
      "ep 10: ep_len:970 episode reward: total was -109.650000. running mean: -115.926100\n",
      "ep 10: ep_len:655 episode reward: total was -57.240000. running mean: -115.339239\n",
      "ep 10: ep_len:560 episode reward: total was -60.540000. running mean: -114.791246\n",
      "ep 10: ep_len:510 episode reward: total was -16.410000. running mean: -113.807434\n",
      "ep 10: ep_len:550 episode reward: total was -18.450000. running mean: -112.853860\n",
      "ep 10: ep_len:2285 episode reward: total was -309.550000. running mean: -114.820821\n",
      "ep 10: ep_len:650 episode reward: total was -32.050000. running mean: -113.993113\n",
      "ep 10: ep_len:865 episode reward: total was -147.280000. running mean: -114.325982\n",
      "ep 10: ep_len:500 episode reward: total was -20.890000. running mean: -113.391622\n",
      "ep 10: ep_len:660 episode reward: total was -33.560000. running mean: -112.593306\n",
      "ep 10: ep_len:595 episode reward: total was -42.040000. running mean: -111.887773\n",
      "ep 10: ep_len:500 episode reward: total was -18.320000. running mean: -110.952095\n",
      "ep 10: ep_len:550 episode reward: total was -44.400000. running mean: -110.286574\n",
      "ep 10: ep_len:500 episode reward: total was -5.210000. running mean: -109.235808\n",
      "ep 10: ep_len:1090 episode reward: total was -72.740000. running mean: -108.870850\n",
      "ep 10: ep_len:840 episode reward: total was -56.260000. running mean: -108.344742\n",
      "ep 10: ep_len:500 episode reward: total was -23.150000. running mean: -107.492794\n",
      "ep 10: ep_len:640 episode reward: total was -18.990000. running mean: -106.607766\n",
      "ep 10: ep_len:810 episode reward: total was -56.490000. running mean: -106.106589\n",
      "ep 10: ep_len:510 episode reward: total was -44.480000. running mean: -105.490323\n",
      "ep 10: ep_len:505 episode reward: total was -29.890000. running mean: -104.734319\n",
      "ep 10: ep_len:1935 episode reward: total was -278.680000. running mean: -106.473776\n",
      "ep 10: ep_len:129 episode reward: total was 3.500000. running mean: -105.374039\n",
      "ep 10: ep_len:500 episode reward: total was -3.290000. running mean: -104.353198\n",
      "ep 10: ep_len:510 episode reward: total was -3.820000. running mean: -103.347866\n",
      "ep 10: ep_len:500 episode reward: total was -30.970000. running mean: -102.624088\n",
      "ep 10: ep_len:685 episode reward: total was -39.080000. running mean: -101.988647\n",
      "ep 10: ep_len:500 episode reward: total was -52.760000. running mean: -101.496360\n",
      "ep 10: ep_len:208 episode reward: total was 13.000000. running mean: -100.351397\n",
      "ep 10: ep_len:615 episode reward: total was -73.530000. running mean: -100.083183\n",
      "ep 10: ep_len:505 episode reward: total was -17.330000. running mean: -99.255651\n",
      "ep 10: ep_len:515 episode reward: total was -48.510000. running mean: -98.748194\n",
      "ep 10: ep_len:463 episode reward: total was -61.500000. running mean: -98.375712\n",
      "ep 10: ep_len:500 episode reward: total was 11.000000. running mean: -97.281955\n",
      "ep 10: ep_len:575 episode reward: total was -34.250000. running mean: -96.651636\n",
      "ep 10: ep_len:595 episode reward: total was -57.440000. running mean: -96.259519\n",
      "ep 10: ep_len:132 episode reward: total was -2.000000. running mean: -95.316924\n",
      "ep 10: ep_len:615 episode reward: total was -33.130000. running mean: -94.695055\n",
      "ep 10: ep_len:550 episode reward: total was -12.770000. running mean: -93.875804\n",
      "ep 10: ep_len:735 episode reward: total was -49.570000. running mean: -93.432746\n",
      "ep 10: ep_len:500 episode reward: total was -36.600000. running mean: -92.864419\n",
      "ep 10: ep_len:500 episode reward: total was -35.900000. running mean: -92.294775\n",
      "ep 10: ep_len:865 episode reward: total was -85.180000. running mean: -92.223627\n",
      "ep 10: ep_len:505 episode reward: total was -8.720000. running mean: -91.388591\n",
      "ep 10: ep_len:750 episode reward: total was -71.920000. running mean: -91.193905\n",
      "ep 10: ep_len:760 episode reward: total was -72.780000. running mean: -91.009766\n",
      "ep 10: ep_len:885 episode reward: total was -50.800000. running mean: -90.607668\n",
      "ep 10: ep_len:655 episode reward: total was -61.350000. running mean: -90.315091\n",
      "ep 10: ep_len:580 episode reward: total was -58.950000. running mean: -90.001440\n",
      "ep 10: ep_len:650 episode reward: total was -35.460000. running mean: -89.456026\n",
      "ep 10: ep_len:685 episode reward: total was -28.980000. running mean: -88.851266\n",
      "ep 10: ep_len:1550 episode reward: total was -160.570000. running mean: -89.568453\n",
      "ep 10: ep_len:760 episode reward: total was -17.230000. running mean: -88.845069\n",
      "ep 10: ep_len:680 episode reward: total was -37.070000. running mean: -88.327318\n",
      "ep 10: ep_len:500 episode reward: total was -13.420000. running mean: -87.578245\n",
      "ep 10: ep_len:890 episode reward: total was -65.510000. running mean: -87.357562\n",
      "ep 10: ep_len:765 episode reward: total was -46.480000. running mean: -86.948787\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 10: ep_len:500 episode reward: total was -27.440000. running mean: -86.353699\n",
      "ep 10: ep_len:500 episode reward: total was -33.390000. running mean: -85.824062\n",
      "ep 10: ep_len:500 episode reward: total was 0.760000. running mean: -84.958221\n",
      "ep 10: ep_len:1340 episode reward: total was -158.970000. running mean: -85.698339\n",
      "ep 10: ep_len:765 episode reward: total was -57.070000. running mean: -85.412056\n",
      "ep 10: ep_len:500 episode reward: total was -34.000000. running mean: -84.897935\n",
      "ep 10: ep_len:500 episode reward: total was -16.290000. running mean: -84.211856\n",
      "ep 10: ep_len:500 episode reward: total was 21.500000. running mean: -83.154737\n",
      "ep 10: ep_len:500 episode reward: total was -4.300000. running mean: -82.366190\n",
      "ep 10: ep_len:895 episode reward: total was -46.350000. running mean: -82.006028\n",
      "ep 10: ep_len:1870 episode reward: total was -194.900000. running mean: -83.134968\n",
      "ep 10: ep_len:500 episode reward: total was -26.410000. running mean: -82.567718\n",
      "ep 10: ep_len:500 episode reward: total was -11.870000. running mean: -81.860741\n",
      "ep 10: ep_len:625 episode reward: total was -43.730000. running mean: -81.479433\n",
      "ep 10: ep_len:500 episode reward: total was -7.050000. running mean: -80.735139\n",
      "ep 10: ep_len:720 episode reward: total was -30.580000. running mean: -80.233588\n",
      "ep 10: ep_len:500 episode reward: total was -9.750000. running mean: -79.528752\n",
      "ep 10: ep_len:695 episode reward: total was -24.360000. running mean: -78.977064\n",
      "ep 10: ep_len:660 episode reward: total was -59.330000. running mean: -78.780594\n",
      "ep 10: ep_len:505 episode reward: total was -55.570000. running mean: -78.548488\n",
      "ep 10: ep_len:500 episode reward: total was 5.800000. running mean: -77.705003\n",
      "ep 10: ep_len:500 episode reward: total was -10.200000. running mean: -77.029953\n",
      "ep 10: ep_len:505 episode reward: total was -26.950000. running mean: -76.529153\n",
      "ep 10: ep_len:695 episode reward: total was -30.950000. running mean: -76.073362\n",
      "ep 10: ep_len:875 episode reward: total was -23.120000. running mean: -75.543828\n",
      "ep 10: ep_len:915 episode reward: total was -56.280000. running mean: -75.351190\n",
      "ep 10: ep_len:605 episode reward: total was -26.110000. running mean: -74.858778\n",
      "ep 10: ep_len:500 episode reward: total was -18.310000. running mean: -74.293290\n",
      "ep 10: ep_len:1010 episode reward: total was -105.870000. running mean: -74.609057\n",
      "ep 10: ep_len:565 episode reward: total was -8.460000. running mean: -73.947567\n",
      "ep 10: ep_len:770 episode reward: total was -50.020000. running mean: -73.708291\n",
      "ep 10: ep_len:273 episode reward: total was 2.000000. running mean: -72.951208\n",
      "ep 10: ep_len:730 episode reward: total was -36.450000. running mean: -72.586196\n",
      "ep 10: ep_len:500 episode reward: total was -1.320000. running mean: -71.873534\n",
      "ep 10: ep_len:500 episode reward: total was -24.510000. running mean: -71.399899\n",
      "ep 10: ep_len:500 episode reward: total was -10.140000. running mean: -70.787300\n",
      "ep 10: ep_len:895 episode reward: total was -21.080000. running mean: -70.290227\n",
      "ep 10: ep_len:759 episode reward: total was -73.280000. running mean: -70.320124\n",
      "ep 10: ep_len:570 episode reward: total was -6.260000. running mean: -69.679523\n",
      "ep 10: ep_len:505 episode reward: total was -14.610000. running mean: -69.128828\n",
      "ep 10: ep_len:635 episode reward: total was -2.220000. running mean: -68.459740\n",
      "ep 10: ep_len:915 episode reward: total was -21.890000. running mean: -67.994042\n",
      "ep 10: ep_len:199 episode reward: total was 6.000000. running mean: -67.254102\n",
      "ep 10: ep_len:600 episode reward: total was -49.350000. running mean: -67.075061\n",
      "ep 10: ep_len:500 episode reward: total was -5.360000. running mean: -66.457910\n",
      "ep 10: ep_len:251 episode reward: total was 8.500000. running mean: -65.708331\n",
      "ep 10: ep_len:500 episode reward: total was -16.370000. running mean: -65.214948\n",
      "ep 10: ep_len:840 episode reward: total was -18.140000. running mean: -64.744198\n",
      "ep 10: ep_len:500 episode reward: total was 17.000000. running mean: -63.926756\n",
      "ep 10: ep_len:500 episode reward: total was -0.810000. running mean: -63.295589\n",
      "ep 10: ep_len:500 episode reward: total was -18.850000. running mean: -62.851133\n",
      "ep 10: ep_len:575 episode reward: total was -48.390000. running mean: -62.706522\n",
      "ep 10: ep_len:750 episode reward: total was -50.660000. running mean: -62.586056\n",
      "ep 10: ep_len:500 episode reward: total was -27.390000. running mean: -62.234096\n",
      "ep 10: ep_len:169 episode reward: total was 9.000000. running mean: -61.521755\n",
      "ep 10: ep_len:505 episode reward: total was -0.790000. running mean: -60.914437\n",
      "ep 10: ep_len:55 episode reward: total was 2.500000. running mean: -60.280293\n",
      "ep 10: ep_len:565 episode reward: total was -28.700000. running mean: -59.964490\n",
      "ep 10: ep_len:510 episode reward: total was -38.910000. running mean: -59.753945\n",
      "ep 10: ep_len:500 episode reward: total was 12.240000. running mean: -59.034006\n",
      "ep 10: ep_len:655 episode reward: total was -30.900000. running mean: -58.752666\n",
      "ep 10: ep_len:500 episode reward: total was -35.730000. running mean: -58.522439\n",
      "ep 10: ep_len:905 episode reward: total was -2.990000. running mean: -57.967114\n",
      "ep 10: ep_len:178 episode reward: total was 4.000000. running mean: -57.347443\n",
      "ep 10: ep_len:187 episode reward: total was -2.500000. running mean: -56.798969\n",
      "ep 10: ep_len:805 episode reward: total was -68.100000. running mean: -56.911979\n",
      "ep 10: ep_len:219 episode reward: total was -3.500000. running mean: -56.377859\n",
      "ep 10: ep_len:965 episode reward: total was -97.100000. running mean: -56.785081\n",
      "ep 10: ep_len:505 episode reward: total was -7.620000. running mean: -56.293430\n",
      "ep 10: ep_len:1605 episode reward: total was -186.010000. running mean: -57.590596\n",
      "ep 10: ep_len:510 episode reward: total was -45.400000. running mean: -57.468690\n",
      "ep 10: ep_len:500 episode reward: total was -8.370000. running mean: -56.977703\n",
      "ep 10: ep_len:720 episode reward: total was -49.110000. running mean: -56.899026\n",
      "ep 10: ep_len:805 episode reward: total was -40.980000. running mean: -56.739836\n",
      "ep 10: ep_len:865 episode reward: total was -39.830000. running mean: -56.570737\n",
      "ep 10: ep_len:274 episode reward: total was 12.500000. running mean: -55.880030\n",
      "ep 10: ep_len:615 episode reward: total was -37.200000. running mean: -55.693230\n",
      "ep 10: ep_len:550 episode reward: total was -28.210000. running mean: -55.418397\n",
      "ep 10: ep_len:500 episode reward: total was -21.850000. running mean: -55.082713\n",
      "ep 10: ep_len:500 episode reward: total was -13.520000. running mean: -54.667086\n",
      "ep 10: ep_len:785 episode reward: total was -44.420000. running mean: -54.564615\n",
      "ep 10: ep_len:1015 episode reward: total was -43.690000. running mean: -54.455869\n",
      "ep 10: ep_len:500 episode reward: total was -5.790000. running mean: -53.969210\n",
      "ep 10: ep_len:715 episode reward: total was -46.580000. running mean: -53.895318\n",
      "ep 10: ep_len:760 episode reward: total was -31.000000. running mean: -53.666365\n",
      "ep 10: ep_len:845 episode reward: total was -61.850000. running mean: -53.748202\n",
      "ep 10: ep_len:184 episode reward: total was 7.500000. running mean: -53.135719\n",
      "ep 10: ep_len:500 episode reward: total was 6.930000. running mean: -52.535062\n",
      "ep 10: ep_len:690 episode reward: total was -30.470000. running mean: -52.314412\n",
      "ep 10: ep_len:695 episode reward: total was -40.560000. running mean: -52.196868\n",
      "ep 10: ep_len:500 episode reward: total was -12.630000. running mean: -51.801199\n",
      "ep 10: ep_len:500 episode reward: total was -5.330000. running mean: -51.336487\n",
      "ep 10: ep_len:612 episode reward: total was -43.220000. running mean: -51.255322\n",
      "ep 10: ep_len:515 episode reward: total was -8.190000. running mean: -50.824669\n",
      "ep 10: ep_len:790 episode reward: total was -51.480000. running mean: -50.831222\n",
      "ep 10: ep_len:735 episode reward: total was -33.930000. running mean: -50.662210\n",
      "ep 10: ep_len:1175 episode reward: total was -103.710000. running mean: -51.192688\n",
      "ep 10: ep_len:755 episode reward: total was -19.100000. running mean: -50.871761\n",
      "ep 10: ep_len:775 episode reward: total was -61.120000. running mean: -50.974243\n",
      "ep 10: ep_len:416 episode reward: total was -6.750000. running mean: -50.532001\n",
      "ep 10: ep_len:500 episode reward: total was -20.840000. running mean: -50.235081\n",
      "ep 10: ep_len:480 episode reward: total was -1.830000. running mean: -49.751030\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 10: ep_len:525 episode reward: total was -26.420000. running mean: -49.517720\n",
      "ep 10: ep_len:497 episode reward: total was -11.270000. running mean: -49.135243\n",
      "ep 10: ep_len:500 episode reward: total was -22.830000. running mean: -48.872190\n",
      "ep 10: ep_len:945 episode reward: total was -49.270000. running mean: -48.876168\n",
      "ep 10: ep_len:890 episode reward: total was -55.320000. running mean: -48.940607\n",
      "ep 10: ep_len:500 episode reward: total was -8.800000. running mean: -48.539200\n",
      "ep 10: ep_len:755 episode reward: total was -56.040000. running mean: -48.614208\n",
      "ep 10: ep_len:500 episode reward: total was -15.480000. running mean: -48.282866\n",
      "ep 10: ep_len:535 episode reward: total was -31.300000. running mean: -48.113038\n",
      "ep 10: ep_len:1310 episode reward: total was -94.390000. running mean: -48.575807\n",
      "ep 10: ep_len:500 episode reward: total was -5.300000. running mean: -48.143049\n",
      "ep 10: ep_len:500 episode reward: total was 24.500000. running mean: -47.416619\n",
      "ep 10: ep_len:715 episode reward: total was -37.000000. running mean: -47.312453\n",
      "ep 10: ep_len:585 episode reward: total was -40.780000. running mean: -47.247128\n",
      "ep 10: ep_len:500 episode reward: total was -13.240000. running mean: -46.907057\n",
      "ep 10: ep_len:720 episode reward: total was -38.490000. running mean: -46.822886\n",
      "ep 10: ep_len:505 episode reward: total was -8.190000. running mean: -46.436557\n",
      "ep 10: ep_len:860 episode reward: total was -47.790000. running mean: -46.450092\n",
      "ep 10: ep_len:600 episode reward: total was -36.220000. running mean: -46.347791\n",
      "ep 10: ep_len:760 episode reward: total was -28.490000. running mean: -46.169213\n",
      "ep 10: ep_len:365 episode reward: total was -13.460000. running mean: -45.842121\n",
      "ep 10: ep_len:500 episode reward: total was -3.780000. running mean: -45.421500\n",
      "ep 10: ep_len:36 episode reward: total was 2.000000. running mean: -44.947285\n",
      "ep 10: ep_len:585 episode reward: total was -11.320000. running mean: -44.611012\n",
      "ep 10: ep_len:825 episode reward: total was -38.660000. running mean: -44.551502\n",
      "ep 10: ep_len:500 episode reward: total was -14.240000. running mean: -44.248387\n",
      "ep 10: ep_len:1005 episode reward: total was -70.530000. running mean: -44.511203\n",
      "ep 10: ep_len:940 episode reward: total was -43.380000. running mean: -44.499891\n",
      "ep 10: ep_len:274 episode reward: total was 16.000000. running mean: -43.894892\n",
      "ep 10: ep_len:500 episode reward: total was -10.610000. running mean: -43.562043\n",
      "ep 10: ep_len:515 episode reward: total was -22.600000. running mean: -43.352423\n",
      "ep 10: ep_len:193 episode reward: total was 14.500000. running mean: -42.773898\n",
      "ep 10: ep_len:184 episode reward: total was 6.000000. running mean: -42.286159\n",
      "ep 10: ep_len:780 episode reward: total was -74.830000. running mean: -42.611598\n",
      "ep 10: ep_len:1020 episode reward: total was -59.160000. running mean: -42.777082\n",
      "ep 10: ep_len:565 episode reward: total was -23.160000. running mean: -42.580911\n",
      "ep 10: ep_len:500 episode reward: total was 1.160000. running mean: -42.143502\n",
      "ep 10: ep_len:500 episode reward: total was -12.340000. running mean: -41.845467\n",
      "ep 10: ep_len:281 episode reward: total was 7.000000. running mean: -41.357012\n",
      "ep 10: ep_len:201 episode reward: total was 8.000000. running mean: -40.863442\n",
      "ep 10: ep_len:615 episode reward: total was -32.150000. running mean: -40.776308\n",
      "ep 10: ep_len:600 episode reward: total was -21.070000. running mean: -40.579244\n",
      "ep 10: ep_len:500 episode reward: total was -14.310000. running mean: -40.316552\n",
      "ep 10: ep_len:500 episode reward: total was 26.500000. running mean: -39.648387\n",
      "ep 10: ep_len:500 episode reward: total was -0.770000. running mean: -39.259603\n",
      "ep 10: ep_len:500 episode reward: total was 11.500000. running mean: -38.752007\n",
      "ep 10: ep_len:500 episode reward: total was -11.310000. running mean: -38.477587\n",
      "ep 10: ep_len:540 episode reward: total was -86.340000. running mean: -38.956211\n",
      "ep 10: ep_len:860 episode reward: total was -45.710000. running mean: -39.023749\n",
      "ep 10: ep_len:525 episode reward: total was -30.310000. running mean: -38.936611\n",
      "ep 10: ep_len:740 episode reward: total was -35.940000. running mean: -38.906645\n",
      "ep 10: ep_len:520 episode reward: total was -29.270000. running mean: -38.810279\n",
      "ep 10: ep_len:1260 episode reward: total was -137.890000. running mean: -39.801076\n",
      "ep 10: ep_len:845 episode reward: total was -20.610000. running mean: -39.609165\n",
      "ep 10: ep_len:500 episode reward: total was -14.870000. running mean: -39.361773\n",
      "ep 10: ep_len:510 episode reward: total was -9.150000. running mean: -39.059656\n",
      "ep 10: ep_len:244 episode reward: total was -3.480000. running mean: -38.703859\n",
      "ep 10: ep_len:635 episode reward: total was -29.570000. running mean: -38.612520\n",
      "ep 10: ep_len:1105 episode reward: total was -95.810000. running mean: -39.184495\n",
      "ep 10: ep_len:500 episode reward: total was -6.750000. running mean: -38.860150\n",
      "ep 10: ep_len:471 episode reward: total was -4.610000. running mean: -38.517649\n",
      "ep 10: ep_len:700 episode reward: total was -30.970000. running mean: -38.442172\n",
      "ep 10: ep_len:1215 episode reward: total was -21.840000. running mean: -38.276151\n",
      "ep 10: ep_len:1740 episode reward: total was -99.550000. running mean: -38.888889\n",
      "ep 10: ep_len:1000 episode reward: total was -36.080000. running mean: -38.860800\n",
      "ep 10: ep_len:500 episode reward: total was 23.000000. running mean: -38.242192\n",
      "ep 10: ep_len:800 episode reward: total was -43.380000. running mean: -38.293570\n",
      "ep 10: ep_len:500 episode reward: total was -8.280000. running mean: -37.993435\n",
      "ep 10: ep_len:805 episode reward: total was -29.650000. running mean: -37.910000\n",
      "ep 10: ep_len:825 episode reward: total was -40.540000. running mean: -37.936300\n",
      "ep 10: ep_len:301 episode reward: total was 13.500000. running mean: -37.421937\n",
      "ep 10: ep_len:930 episode reward: total was -49.700000. running mean: -37.544718\n",
      "ep 10: ep_len:505 episode reward: total was -5.270000. running mean: -37.221971\n",
      "ep 10: ep_len:500 episode reward: total was -32.440000. running mean: -37.174151\n",
      "ep 10: ep_len:500 episode reward: total was 3.790000. running mean: -36.764509\n",
      "ep 10: ep_len:244 episode reward: total was 6.000000. running mean: -36.336864\n",
      "ep 10: ep_len:500 episode reward: total was -9.150000. running mean: -36.064996\n",
      "ep 10: ep_len:765 episode reward: total was -34.880000. running mean: -36.053146\n",
      "ep 10: ep_len:500 episode reward: total was -3.230000. running mean: -35.724914\n",
      "ep 10: ep_len:840 episode reward: total was -38.280000. running mean: -35.750465\n",
      "ep 10: ep_len:595 episode reward: total was -47.340000. running mean: -35.866361\n",
      "ep 10: ep_len:250 episode reward: total was 7.500000. running mean: -35.432697\n",
      "ep 10: ep_len:282 episode reward: total was 9.000000. running mean: -34.988370\n",
      "ep 10: ep_len:785 episode reward: total was -110.650000. running mean: -35.744986\n",
      "ep 10: ep_len:700 episode reward: total was -38.390000. running mean: -35.771436\n",
      "ep 10: ep_len:188 episode reward: total was 5.000000. running mean: -35.363722\n",
      "ep 10: ep_len:530 episode reward: total was -32.290000. running mean: -35.332985\n",
      "ep 10: ep_len:765 episode reward: total was -37.930000. running mean: -35.358955\n",
      "ep 10: ep_len:915 episode reward: total was -133.130000. running mean: -36.336665\n",
      "ep 10: ep_len:334 episode reward: total was 8.500000. running mean: -35.888299\n",
      "ep 10: ep_len:620 episode reward: total was -27.390000. running mean: -35.803316\n",
      "ep 10: ep_len:750 episode reward: total was -53.330000. running mean: -35.978583\n",
      "ep 10: ep_len:424 episode reward: total was -7.310000. running mean: -35.691897\n",
      "ep 10: ep_len:770 episode reward: total was -45.950000. running mean: -35.794478\n",
      "ep 10: ep_len:735 episode reward: total was -48.040000. running mean: -35.916933\n",
      "ep 10: ep_len:595 episode reward: total was -7.900000. running mean: -35.636764\n",
      "ep 10: ep_len:1000 episode reward: total was -40.660000. running mean: -35.686996\n",
      "ep 10: ep_len:790 episode reward: total was -42.910000. running mean: -35.759226\n",
      "ep 10: ep_len:670 episode reward: total was -23.800000. running mean: -35.639634\n",
      "ep 10: ep_len:525 episode reward: total was -10.770000. running mean: -35.390937\n",
      "ep 10: ep_len:780 episode reward: total was -37.960000. running mean: -35.416628\n",
      "ep 10: ep_len:585 episode reward: total was -52.410000. running mean: -35.586562\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 10: ep_len:1610 episode reward: total was -218.140000. running mean: -37.412096\n",
      "ep 10: ep_len:985 episode reward: total was -58.650000. running mean: -37.624475\n",
      "ep 10: ep_len:505 episode reward: total was -14.230000. running mean: -37.390531\n",
      "ep 10: ep_len:650 episode reward: total was -44.200000. running mean: -37.458625\n",
      "ep 10: ep_len:204 episode reward: total was 5.000000. running mean: -37.034039\n",
      "ep 10: ep_len:326 episode reward: total was 8.500000. running mean: -36.578699\n",
      "ep 10: ep_len:500 episode reward: total was -44.040000. running mean: -36.653312\n",
      "ep 10: ep_len:855 episode reward: total was -65.610000. running mean: -36.942878\n",
      "ep 10: ep_len:945 episode reward: total was -19.330000. running mean: -36.766750\n",
      "ep 10: ep_len:510 episode reward: total was 0.710000. running mean: -36.391982\n",
      "ep 10: ep_len:545 episode reward: total was -32.780000. running mean: -36.355862\n",
      "ep 10: ep_len:500 episode reward: total was -22.370000. running mean: -36.216004\n",
      "ep 10: ep_len:1415 episode reward: total was -119.920000. running mean: -37.053044\n",
      "ep 10: ep_len:1080 episode reward: total was -94.850000. running mean: -37.631013\n",
      "ep 10: ep_len:515 episode reward: total was -41.410000. running mean: -37.668803\n",
      "ep 10: ep_len:805 episode reward: total was -98.430000. running mean: -38.276415\n",
      "ep 10: ep_len:152 episode reward: total was 1.500000. running mean: -37.878651\n",
      "ep 10: ep_len:560 episode reward: total was -26.200000. running mean: -37.761864\n",
      "ep 10: ep_len:960 episode reward: total was -31.480000. running mean: -37.699046\n",
      "ep 10: ep_len:1010 episode reward: total was -69.940000. running mean: -38.021455\n",
      "ep 10: ep_len:1050 episode reward: total was -31.100000. running mean: -37.952241\n",
      "ep 10: ep_len:139 episode reward: total was 4.500000. running mean: -37.527718\n",
      "ep 10: ep_len:692 episode reward: total was -43.090000. running mean: -37.583341\n",
      "ep 10: ep_len:600 episode reward: total was -39.250000. running mean: -37.600008\n",
      "ep 10: ep_len:500 episode reward: total was -30.680000. running mean: -37.530808\n",
      "ep 10: ep_len:575 episode reward: total was -47.870000. running mean: -37.634200\n",
      "ep 10: ep_len:500 episode reward: total was 3.810000. running mean: -37.219758\n",
      "ep 10: ep_len:500 episode reward: total was -6.810000. running mean: -36.915660\n",
      "ep 10: ep_len:750 episode reward: total was -41.460000. running mean: -36.961103\n",
      "ep 10: ep_len:590 episode reward: total was -34.220000. running mean: -36.933692\n",
      "ep 10: ep_len:500 episode reward: total was -4.320000. running mean: -36.607555\n",
      "ep 10: ep_len:535 episode reward: total was -43.390000. running mean: -36.675380\n",
      "ep 10: ep_len:193 episode reward: total was 7.000000. running mean: -36.238626\n",
      "ep 10: ep_len:815 episode reward: total was -49.930000. running mean: -36.375540\n",
      "ep 10: ep_len:565 episode reward: total was -26.910000. running mean: -36.280884\n",
      "ep 10: ep_len:695 episode reward: total was -34.500000. running mean: -36.263076\n",
      "ep 10: ep_len:500 episode reward: total was 0.730000. running mean: -35.893145\n",
      "ep 10: ep_len:500 episode reward: total was -15.230000. running mean: -35.686513\n",
      "ep 10: ep_len:1130 episode reward: total was -44.330000. running mean: -35.772948\n",
      "ep 10: ep_len:500 episode reward: total was -21.450000. running mean: -35.629719\n",
      "ep 10: ep_len:500 episode reward: total was 14.500000. running mean: -35.128422\n",
      "ep 10: ep_len:180 episode reward: total was 1.500000. running mean: -34.762137\n",
      "ep 10: ep_len:505 episode reward: total was -29.430000. running mean: -34.708816\n",
      "ep 10: ep_len:615 episode reward: total was -48.280000. running mean: -34.844528\n",
      "ep 10: ep_len:500 episode reward: total was 2.210000. running mean: -34.473983\n",
      "ep 10: ep_len:520 episode reward: total was -26.280000. running mean: -34.392043\n",
      "ep 10: ep_len:680 episode reward: total was -27.980000. running mean: -34.327922\n",
      "ep 10: ep_len:160 episode reward: total was 4.000000. running mean: -33.944643\n",
      "ep 10: ep_len:530 episode reward: total was -19.260000. running mean: -33.797797\n",
      "ep 10: ep_len:595 episode reward: total was -67.020000. running mean: -34.130019\n",
      "ep 10: ep_len:605 episode reward: total was -31.160000. running mean: -34.100319\n",
      "ep 10: ep_len:515 episode reward: total was -34.000000. running mean: -34.099315\n",
      "ep 10: ep_len:610 episode reward: total was -30.140000. running mean: -34.059722\n",
      "ep 10: ep_len:745 episode reward: total was -99.550000. running mean: -34.714625\n",
      "ep 10: ep_len:500 episode reward: total was -9.570000. running mean: -34.463179\n",
      "ep 10: ep_len:500 episode reward: total was -47.800000. running mean: -34.596547\n",
      "ep 10: ep_len:500 episode reward: total was -20.990000. running mean: -34.460481\n",
      "ep 10: ep_len:500 episode reward: total was -12.750000. running mean: -34.243377\n",
      "ep 10: ep_len:740 episode reward: total was -43.010000. running mean: -34.331043\n",
      "ep 10: ep_len:1440 episode reward: total was -96.700000. running mean: -34.954732\n",
      "ep 10: ep_len:525 episode reward: total was -96.970000. running mean: -35.574885\n",
      "ep 10: ep_len:685 episode reward: total was -41.100000. running mean: -35.630136\n",
      "ep 10: ep_len:685 episode reward: total was -32.500000. running mean: -35.598835\n",
      "ep 10: ep_len:505 episode reward: total was 17.500000. running mean: -35.067847\n",
      "ep 10: ep_len:1115 episode reward: total was -105.890000. running mean: -35.776068\n",
      "ep 10: ep_len:505 episode reward: total was 1.210000. running mean: -35.406207\n",
      "ep 10: ep_len:1705 episode reward: total was -86.290000. running mean: -35.915045\n",
      "ep 10: ep_len:875 episode reward: total was -157.900000. running mean: -37.134895\n",
      "ep 10: ep_len:9130 episode reward: total was -1700.050000. running mean: -53.764046\n",
      "ep 10: ep_len:880 episode reward: total was -49.430000. running mean: -53.720705\n",
      "ep 10: ep_len:945 episode reward: total was -42.860000. running mean: -53.612098\n",
      "ep 10: ep_len:505 episode reward: total was -44.720000. running mean: -53.523177\n",
      "ep 10: ep_len:98 episode reward: total was 5.000000. running mean: -52.937946\n",
      "ep 10: ep_len:730 episode reward: total was -44.530000. running mean: -52.853866\n",
      "ep 10: ep_len:530 episode reward: total was -39.780000. running mean: -52.723128\n",
      "ep 10: ep_len:700 episode reward: total was -42.080000. running mean: -52.616696\n",
      "ep 10: ep_len:765 episode reward: total was -22.040000. running mean: -52.310929\n",
      "ep 10: ep_len:214 episode reward: total was 7.500000. running mean: -51.712820\n",
      "ep 10: ep_len:510 episode reward: total was -9.390000. running mean: -51.289592\n",
      "ep 10: ep_len:860 episode reward: total was -59.940000. running mean: -51.376096\n",
      "ep 10: ep_len:500 episode reward: total was -33.020000. running mean: -51.192535\n",
      "ep 10: ep_len:152 episode reward: total was 8.000000. running mean: -50.600610\n",
      "ep 10: ep_len:1330 episode reward: total was -94.740000. running mean: -51.042003\n",
      "ep 10: ep_len:520 episode reward: total was -42.440000. running mean: -50.955983\n",
      "ep 10: ep_len:192 episode reward: total was 8.500000. running mean: -50.361424\n",
      "ep 10: ep_len:500 episode reward: total was -34.730000. running mean: -50.205109\n",
      "ep 10: ep_len:695 episode reward: total was -24.920000. running mean: -49.952258\n",
      "ep 10: ep_len:960 episode reward: total was -76.910000. running mean: -50.221836\n",
      "ep 10: ep_len:160 episode reward: total was 6.510000. running mean: -49.654517\n",
      "ep 10: ep_len:525 episode reward: total was -25.750000. running mean: -49.415472\n",
      "ep 10: ep_len:760 episode reward: total was -26.880000. running mean: -49.190117\n",
      "ep 10: ep_len:780 episode reward: total was -27.260000. running mean: -48.970816\n",
      "ep 10: ep_len:310 episode reward: total was 11.500000. running mean: -48.366108\n",
      "ep 10: ep_len:950 episode reward: total was -47.700000. running mean: -48.359447\n",
      "ep 10: ep_len:1515 episode reward: total was -89.030000. running mean: -48.766153\n",
      "ep 10: ep_len:1904 episode reward: total was -274.990000. running mean: -51.028391\n",
      "ep 10: ep_len:500 episode reward: total was -22.390000. running mean: -50.742007\n",
      "ep 10: ep_len:500 episode reward: total was -29.240000. running mean: -50.526987\n",
      "ep 10: ep_len:580 episode reward: total was -57.470000. running mean: -50.596417\n",
      "ep 10: ep_len:555 episode reward: total was -18.200000. running mean: -50.272453\n",
      "ep 10: ep_len:950 episode reward: total was -33.500000. running mean: -50.104728\n",
      "ep 10: ep_len:810 episode reward: total was -90.340000. running mean: -50.507081\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 10: ep_len:500 episode reward: total was -49.090000. running mean: -50.492910\n",
      "ep 10: ep_len:500 episode reward: total was -21.740000. running mean: -50.205381\n",
      "ep 10: ep_len:630 episode reward: total was -14.890000. running mean: -49.852227\n",
      "ep 10: ep_len:273 episode reward: total was 16.500000. running mean: -49.188705\n",
      "ep 10: ep_len:935 episode reward: total was -29.460000. running mean: -48.991418\n",
      "ep 10: ep_len:500 episode reward: total was -22.790000. running mean: -48.729404\n",
      "ep 10: ep_len:875 episode reward: total was -104.320000. running mean: -49.285310\n",
      "ep 10: ep_len:500 episode reward: total was -13.510000. running mean: -48.927557\n",
      "ep 10: ep_len:875 episode reward: total was -58.870000. running mean: -49.026981\n",
      "ep 10: ep_len:730 episode reward: total was -52.120000. running mean: -49.057911\n",
      "ep 10: ep_len:505 episode reward: total was 3.760000. running mean: -48.529732\n",
      "ep 10: ep_len:505 episode reward: total was -14.060000. running mean: -48.185035\n",
      "ep 10: ep_len:995 episode reward: total was -76.840000. running mean: -48.471585\n",
      "ep 10: ep_len:925 episode reward: total was -37.060000. running mean: -48.357469\n",
      "ep 10: ep_len:500 episode reward: total was -22.580000. running mean: -48.099694\n",
      "ep 10: ep_len:570 episode reward: total was -49.410000. running mean: -48.112797\n",
      "ep 10: ep_len:510 episode reward: total was -69.730000. running mean: -48.328969\n",
      "ep 10: ep_len:505 episode reward: total was -11.910000. running mean: -47.964780\n",
      "ep 10: ep_len:500 episode reward: total was -13.670000. running mean: -47.621832\n",
      "ep 10: ep_len:860 episode reward: total was -30.120000. running mean: -47.446813\n",
      "ep 10: ep_len:680 episode reward: total was -14.810000. running mean: -47.120445\n",
      "ep 10: ep_len:595 episode reward: total was -27.140000. running mean: -46.920641\n",
      "ep 10: ep_len:500 episode reward: total was 9.290000. running mean: -46.358534\n",
      "ep 10: ep_len:860 episode reward: total was -22.830000. running mean: -46.123249\n",
      "ep 10: ep_len:500 episode reward: total was -13.850000. running mean: -45.800517\n",
      "ep 10: ep_len:750 episode reward: total was -38.950000. running mean: -45.732011\n",
      "ep 10: ep_len:505 episode reward: total was -15.330000. running mean: -45.427991\n",
      "ep 10: ep_len:500 episode reward: total was -18.810000. running mean: -45.161811\n",
      "ep 10: ep_len:500 episode reward: total was 3.660000. running mean: -44.673593\n",
      "ep 10: ep_len:500 episode reward: total was -12.560000. running mean: -44.352457\n",
      "ep 10: ep_len:645 episode reward: total was -55.290000. running mean: -44.461833\n",
      "ep 10: ep_len:995 episode reward: total was -75.340000. running mean: -44.770614\n",
      "ep 10: ep_len:505 episode reward: total was -8.240000. running mean: -44.405308\n",
      "ep 10: ep_len:585 episode reward: total was -62.220000. running mean: -44.583455\n",
      "ep 10: ep_len:334 episode reward: total was -10.000000. running mean: -44.237621\n",
      "ep 10: ep_len:930 episode reward: total was -91.110000. running mean: -44.706344\n",
      "ep 10: ep_len:900 episode reward: total was -27.890000. running mean: -44.538181\n",
      "ep 10: ep_len:665 episode reward: total was -31.850000. running mean: -44.411299\n",
      "ep 10: ep_len:500 episode reward: total was -19.850000. running mean: -44.165686\n",
      "ep 10: ep_len:500 episode reward: total was -35.000000. running mean: -44.074029\n",
      "ep 10: ep_len:500 episode reward: total was -34.460000. running mean: -43.977889\n",
      "ep 10: ep_len:505 episode reward: total was -43.540000. running mean: -43.973510\n",
      "ep 10: ep_len:500 episode reward: total was -13.290000. running mean: -43.666675\n",
      "ep 10: ep_len:500 episode reward: total was -9.530000. running mean: -43.325308\n",
      "ep 10: ep_len:560 episode reward: total was -43.580000. running mean: -43.327855\n",
      "ep 10: ep_len:218 episode reward: total was 3.500000. running mean: -42.859577\n",
      "ep 10: ep_len:143 episode reward: total was 2.000000. running mean: -42.410981\n",
      "ep 10: ep_len:139 episode reward: total was 3.000000. running mean: -41.956871\n",
      "ep 10: ep_len:640 episode reward: total was -14.780000. running mean: -41.685102\n",
      "ep 10: ep_len:500 episode reward: total was -29.580000. running mean: -41.564051\n",
      "ep 10: ep_len:690 episode reward: total was -34.020000. running mean: -41.488611\n",
      "ep 10: ep_len:585 episode reward: total was -56.450000. running mean: -41.638225\n",
      "ep 10: ep_len:500 episode reward: total was -45.050000. running mean: -41.672342\n",
      "ep 10: ep_len:500 episode reward: total was -13.790000. running mean: -41.393519\n",
      "ep 10: ep_len:695 episode reward: total was -37.010000. running mean: -41.349684\n",
      "ep 10: ep_len:500 episode reward: total was -16.450000. running mean: -41.100687\n",
      "ep 10: ep_len:500 episode reward: total was -45.840000. running mean: -41.148080\n",
      "ep 10: ep_len:500 episode reward: total was -12.680000. running mean: -40.863399\n",
      "ep 10: ep_len:1285 episode reward: total was -23.050000. running mean: -40.685265\n",
      "ep 10: ep_len:750 episode reward: total was -61.310000. running mean: -40.891513\n",
      "ep 10: ep_len:510 episode reward: total was -49.180000. running mean: -40.974398\n",
      "ep 10: ep_len:487 episode reward: total was -5.830000. running mean: -40.622954\n",
      "ep 10: ep_len:500 episode reward: total was -20.220000. running mean: -40.418924\n",
      "ep 10: ep_len:560 episode reward: total was -29.520000. running mean: -40.309935\n",
      "ep 10: ep_len:685 episode reward: total was -76.500000. running mean: -40.671835\n",
      "ep 10: ep_len:945 episode reward: total was -151.460000. running mean: -41.779717\n",
      "ep 10: ep_len:585 episode reward: total was -29.850000. running mean: -41.660420\n",
      "ep 10: ep_len:750 episode reward: total was -55.850000. running mean: -41.802316\n",
      "ep 10: ep_len:535 episode reward: total was -9.300000. running mean: -41.477293\n",
      "ep 10: ep_len:720 episode reward: total was -41.080000. running mean: -41.473320\n",
      "ep 10: ep_len:545 episode reward: total was -49.460000. running mean: -41.553186\n",
      "ep 10: ep_len:765 episode reward: total was -49.020000. running mean: -41.627855\n",
      "ep 10: ep_len:860 episode reward: total was -37.710000. running mean: -41.588676\n",
      "ep 10: ep_len:555 episode reward: total was -25.720000. running mean: -41.429989\n",
      "ep 10: ep_len:740 episode reward: total was -28.770000. running mean: -41.303389\n",
      "ep 10: ep_len:500 episode reward: total was -31.150000. running mean: -41.201856\n",
      "ep 10: ep_len:505 episode reward: total was -49.050000. running mean: -41.280337\n",
      "ep 10: ep_len:950 episode reward: total was -27.690000. running mean: -41.144434\n",
      "ep 10: ep_len:505 episode reward: total was 5.700000. running mean: -40.675989\n",
      "ep 10: ep_len:1005 episode reward: total was -46.790000. running mean: -40.737129\n",
      "ep 10: ep_len:1265 episode reward: total was -188.900000. running mean: -42.218758\n",
      "ep 10: ep_len:515 episode reward: total was -16.030000. running mean: -41.956870\n",
      "ep 10: ep_len:560 episode reward: total was -48.320000. running mean: -42.020502\n",
      "ep 10: ep_len:500 episode reward: total was -26.380000. running mean: -41.864097\n",
      "ep 10: ep_len:500 episode reward: total was -23.960000. running mean: -41.685056\n",
      "ep 10: ep_len:835 episode reward: total was -19.690000. running mean: -41.465105\n",
      "ep 10: ep_len:505 episode reward: total was -39.440000. running mean: -41.444854\n",
      "ep 10: ep_len:755 episode reward: total was -28.000000. running mean: -41.310406\n",
      "ep 10: ep_len:1665 episode reward: total was -197.150000. running mean: -42.868802\n",
      "ep 10: ep_len:635 episode reward: total was -40.160000. running mean: -42.841714\n",
      "ep 10: ep_len:725 episode reward: total was -30.400000. running mean: -42.717296\n",
      "ep 10: ep_len:1790 episode reward: total was -182.410000. running mean: -44.114223\n",
      "ep 10: ep_len:650 episode reward: total was -38.140000. running mean: -44.054481\n",
      "ep 10: ep_len:500 episode reward: total was -11.530000. running mean: -43.729236\n",
      "ep 10: ep_len:725 episode reward: total was -27.910000. running mean: -43.571044\n",
      "ep 10: ep_len:565 episode reward: total was -28.510000. running mean: -43.420434\n",
      "ep 10: ep_len:850 episode reward: total was -16.590000. running mean: -43.152129\n",
      "ep 10: ep_len:177 episode reward: total was 7.000000. running mean: -42.650608\n",
      "ep 10: ep_len:1450 episode reward: total was -193.580000. running mean: -44.159902\n",
      "ep 10: ep_len:990 episode reward: total was -105.130000. running mean: -44.769603\n",
      "ep 10: ep_len:775 episode reward: total was -38.900000. running mean: -44.710907\n",
      "ep 10: ep_len:500 episode reward: total was -20.990000. running mean: -44.473698\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 10: ep_len:685 episode reward: total was -32.010000. running mean: -44.349061\n",
      "ep 10: ep_len:615 episode reward: total was -46.960000. running mean: -44.375170\n",
      "ep 10: ep_len:379 episode reward: total was -23.320000. running mean: -44.164619\n",
      "ep 10: ep_len:650 episode reward: total was -42.570000. running mean: -44.148672\n",
      "ep 10: ep_len:500 episode reward: total was -28.460000. running mean: -43.991786\n",
      "ep 10: ep_len:500 episode reward: total was -29.010000. running mean: -43.841968\n",
      "ep 10: ep_len:575 episode reward: total was -33.240000. running mean: -43.735948\n",
      "ep 10: ep_len:500 episode reward: total was -12.810000. running mean: -43.426689\n",
      "ep 10: ep_len:565 episode reward: total was -37.790000. running mean: -43.370322\n",
      "ep 10: ep_len:500 episode reward: total was -10.960000. running mean: -43.046218\n",
      "ep 10: ep_len:500 episode reward: total was -8.810000. running mean: -42.703856\n",
      "ep 10: ep_len:595 episode reward: total was -43.300000. running mean: -42.709818\n",
      "ep 10: ep_len:2040 episode reward: total was -291.900000. running mean: -45.201720\n",
      "ep 10: ep_len:405 episode reward: total was -50.730000. running mean: -45.257002\n",
      "ep 10: ep_len:500 episode reward: total was -23.990000. running mean: -45.044332\n",
      "ep 10: ep_len:505 episode reward: total was -5.660000. running mean: -44.650489\n",
      "ep 10: ep_len:192 episode reward: total was 8.500000. running mean: -44.118984\n",
      "ep 10: ep_len:865 episode reward: total was -37.950000. running mean: -44.057294\n",
      "ep 10: ep_len:152 episode reward: total was 10.500000. running mean: -43.511721\n",
      "ep 10: ep_len:500 episode reward: total was -4.360000. running mean: -43.120204\n",
      "ep 10: ep_len:985 episode reward: total was -43.430000. running mean: -43.123302\n",
      "ep 10: ep_len:830 episode reward: total was -22.760000. running mean: -42.919669\n",
      "ep 10: ep_len:505 episode reward: total was -18.390000. running mean: -42.674372\n",
      "ep 10: ep_len:500 episode reward: total was -64.240000. running mean: -42.890029\n",
      "ep 10: ep_len:510 episode reward: total was -13.860000. running mean: -42.599728\n",
      "ep 10: ep_len:178 episode reward: total was 4.000000. running mean: -42.133731\n",
      "ep 10: ep_len:500 episode reward: total was -13.060000. running mean: -41.842994\n",
      "ep 10: ep_len:720 episode reward: total was -14.050000. running mean: -41.565064\n",
      "ep 10: ep_len:500 episode reward: total was -35.530000. running mean: -41.504713\n",
      "ep 10: ep_len:515 episode reward: total was -7.350000. running mean: -41.163166\n",
      "ep 10: ep_len:500 episode reward: total was -28.870000. running mean: -41.040234\n",
      "ep 10: ep_len:55 episode reward: total was 2.500000. running mean: -40.604832\n",
      "ep 10: ep_len:590 episode reward: total was -11.410000. running mean: -40.312884\n",
      "ep 10: ep_len:765 episode reward: total was -38.920000. running mean: -40.298955\n",
      "ep 10: ep_len:500 episode reward: total was -6.350000. running mean: -39.959465\n",
      "ep 10: ep_len:500 episode reward: total was -40.350000. running mean: -39.963371\n",
      "ep 10: ep_len:500 episode reward: total was -14.550000. running mean: -39.709237\n",
      "ep 10: ep_len:500 episode reward: total was -16.310000. running mean: -39.475245\n",
      "ep 10: ep_len:855 episode reward: total was -33.690000. running mean: -39.417392\n",
      "ep 10: ep_len:765 episode reward: total was -27.810000. running mean: -39.301318\n",
      "ep 10: ep_len:500 episode reward: total was -0.140000. running mean: -38.909705\n",
      "ep 10: ep_len:500 episode reward: total was -1.290000. running mean: -38.533508\n",
      "ep 10: ep_len:585 episode reward: total was -29.180000. running mean: -38.439973\n",
      "ep 10: ep_len:500 episode reward: total was -25.340000. running mean: -38.308973\n",
      "ep 10: ep_len:650 episode reward: total was -68.470000. running mean: -38.610583\n",
      "ep 10: ep_len:510 episode reward: total was -40.560000. running mean: -38.630078\n",
      "ep 10: ep_len:980 episode reward: total was -113.230000. running mean: -39.376077\n",
      "ep 10: ep_len:670 episode reward: total was -7.510000. running mean: -39.057416\n",
      "ep 10: ep_len:1590 episode reward: total was -247.680000. running mean: -41.143642\n",
      "ep 10: ep_len:590 episode reward: total was -65.060000. running mean: -41.382806\n",
      "ep 10: ep_len:500 episode reward: total was -14.710000. running mean: -41.116077\n",
      "ep 10: ep_len:158 episode reward: total was 5.000000. running mean: -40.654917\n",
      "ep 10: ep_len:520 episode reward: total was -43.040000. running mean: -40.678768\n",
      "ep 10: ep_len:500 episode reward: total was 0.180000. running mean: -40.270180\n",
      "ep 10: ep_len:500 episode reward: total was -10.510000. running mean: -39.972578\n",
      "ep 10: ep_len:620 episode reward: total was -37.850000. running mean: -39.951352\n",
      "ep 10: ep_len:595 episode reward: total was -15.720000. running mean: -39.709039\n",
      "ep 10: ep_len:500 episode reward: total was -9.880000. running mean: -39.410748\n",
      "ep 10: ep_len:500 episode reward: total was -20.440000. running mean: -39.221041\n",
      "ep 10: ep_len:505 episode reward: total was -3.300000. running mean: -38.861830\n",
      "ep 10: ep_len:369 episode reward: total was 6.500000. running mean: -38.408212\n",
      "ep 10: ep_len:570 episode reward: total was -6.070000. running mean: -38.084830\n",
      "ep 10: ep_len:700 episode reward: total was -18.280000. running mean: -37.886782\n",
      "ep 10: ep_len:500 episode reward: total was -55.630000. running mean: -38.064214\n",
      "ep 10: ep_len:875 episode reward: total was -80.600000. running mean: -38.489572\n",
      "ep 10: ep_len:1145 episode reward: total was -66.240000. running mean: -38.767076\n",
      "ep 10: ep_len:500 episode reward: total was -19.140000. running mean: -38.570805\n",
      "ep 10: ep_len:505 episode reward: total was 2.210000. running mean: -38.162997\n",
      "ep 10: ep_len:685 episode reward: total was -52.210000. running mean: -38.303467\n",
      "ep 10: ep_len:302 episode reward: total was 13.500000. running mean: -37.785433\n",
      "ep 10: ep_len:505 episode reward: total was -3.560000. running mean: -37.443178\n",
      "ep 10: ep_len:1360 episode reward: total was -159.410000. running mean: -38.662846\n",
      "ep 10: ep_len:755 episode reward: total was -26.840000. running mean: -38.544618\n",
      "ep 10: ep_len:615 episode reward: total was -0.300000. running mean: -38.162172\n",
      "ep 10: ep_len:500 episode reward: total was 14.500000. running mean: -37.635550\n",
      "ep 10: ep_len:775 episode reward: total was -27.540000. running mean: -37.534595\n",
      "ep 10: ep_len:795 episode reward: total was -48.960000. running mean: -37.648849\n",
      "ep 10: ep_len:185 episode reward: total was -2.500000. running mean: -37.297360\n",
      "ep 10: ep_len:500 episode reward: total was -28.490000. running mean: -37.209287\n",
      "ep 10: ep_len:705 episode reward: total was -66.800000. running mean: -37.505194\n",
      "ep 10: ep_len:1070 episode reward: total was -38.270000. running mean: -37.512842\n",
      "ep 10: ep_len:820 episode reward: total was -28.320000. running mean: -37.420913\n",
      "ep 10: ep_len:505 episode reward: total was -21.250000. running mean: -37.259204\n",
      "ep 10: ep_len:500 episode reward: total was -30.390000. running mean: -37.190512\n",
      "ep 10: ep_len:500 episode reward: total was -8.400000. running mean: -36.902607\n",
      "ep 10: ep_len:550 episode reward: total was -34.300000. running mean: -36.876581\n",
      "ep 10: ep_len:500 episode reward: total was -26.010000. running mean: -36.767915\n",
      "ep 10: ep_len:1195 episode reward: total was -122.380000. running mean: -37.624036\n",
      "ep 10: ep_len:840 episode reward: total was -32.710000. running mean: -37.574896\n",
      "ep 10: ep_len:565 episode reward: total was -28.180000. running mean: -37.480947\n",
      "ep 10: ep_len:755 episode reward: total was -40.500000. running mean: -37.511137\n",
      "ep 10: ep_len:795 episode reward: total was -66.860000. running mean: -37.804626\n",
      "ep 10: ep_len:510 episode reward: total was -28.860000. running mean: -37.715180\n",
      "ep 10: ep_len:550 episode reward: total was -5.110000. running mean: -37.389128\n",
      "ep 10: ep_len:684 episode reward: total was -30.470000. running mean: -37.319937\n",
      "ep 10: ep_len:500 episode reward: total was -10.060000. running mean: -37.047337\n",
      "ep 10: ep_len:580 episode reward: total was -29.570000. running mean: -36.972564\n",
      "ep 10: ep_len:515 episode reward: total was -37.400000. running mean: -36.976838\n",
      "ep 10: ep_len:500 episode reward: total was -38.220000. running mean: -36.989270\n",
      "ep 10: ep_len:284 episode reward: total was -5.420000. running mean: -36.673577\n",
      "ep 10: ep_len:925 episode reward: total was -44.240000. running mean: -36.749241\n",
      "ep 10: ep_len:1615 episode reward: total was -224.370000. running mean: -38.625449\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 10: ep_len:815 episode reward: total was -46.870000. running mean: -38.707894\n",
      "ep 10: ep_len:500 episode reward: total was -3.320000. running mean: -38.354015\n",
      "ep 10: ep_len:500 episode reward: total was -31.430000. running mean: -38.284775\n",
      "ep 10: ep_len:865 episode reward: total was -63.970000. running mean: -38.541628\n",
      "ep 10: ep_len:500 episode reward: total was -19.850000. running mean: -38.354711\n",
      "ep 10: ep_len:745 episode reward: total was -45.510000. running mean: -38.426264\n",
      "ep 10: ep_len:500 episode reward: total was -5.900000. running mean: -38.101002\n",
      "ep 10: ep_len:500 episode reward: total was -8.550000. running mean: -37.805492\n",
      "ep 10: ep_len:620 episode reward: total was -51.820000. running mean: -37.945637\n",
      "ep 10: ep_len:885 episode reward: total was -49.360000. running mean: -38.059780\n",
      "ep 10: ep_len:705 episode reward: total was -29.950000. running mean: -37.978682\n",
      "ep 10: ep_len:500 episode reward: total was -10.670000. running mean: -37.705596\n",
      "ep 10: ep_len:760 episode reward: total was -40.430000. running mean: -37.732840\n",
      "ep 10: ep_len:500 episode reward: total was -21.930000. running mean: -37.574811\n",
      "ep 10: ep_len:605 episode reward: total was -59.620000. running mean: -37.795263\n",
      "ep 10: ep_len:500 episode reward: total was -12.880000. running mean: -37.546111\n",
      "ep 10: ep_len:715 episode reward: total was -25.040000. running mean: -37.421049\n",
      "ep 10: ep_len:855 episode reward: total was -55.910000. running mean: -37.605939\n",
      "ep 10: ep_len:510 episode reward: total was -18.270000. running mean: -37.412580\n",
      "ep 10: ep_len:680 episode reward: total was -14.740000. running mean: -37.185854\n",
      "ep 10: ep_len:550 episode reward: total was -39.150000. running mean: -37.205495\n",
      "ep 10: ep_len:346 episode reward: total was 15.500000. running mean: -36.678440\n",
      "ep 10: ep_len:500 episode reward: total was -10.720000. running mean: -36.418856\n",
      "ep 10: ep_len:570 episode reward: total was -27.190000. running mean: -36.326567\n",
      "ep 10: ep_len:500 episode reward: total was -20.380000. running mean: -36.167102\n",
      "ep 10: ep_len:570 episode reward: total was -16.840000. running mean: -35.973831\n",
      "ep 10: ep_len:500 episode reward: total was -48.290000. running mean: -36.096992\n",
      "ep 10: ep_len:910 episode reward: total was -56.530000. running mean: -36.301322\n",
      "ep 10: ep_len:505 episode reward: total was -9.290000. running mean: -36.031209\n",
      "ep 10: ep_len:645 episode reward: total was -21.640000. running mean: -35.887297\n",
      "ep 10: ep_len:700 episode reward: total was -23.430000. running mean: -35.762724\n",
      "ep 10: ep_len:505 episode reward: total was -9.250000. running mean: -35.497597\n",
      "ep 10: ep_len:505 episode reward: total was 2.730000. running mean: -35.115321\n",
      "ep 10: ep_len:505 episode reward: total was -29.340000. running mean: -35.057568\n",
      "ep 10: ep_len:740 episode reward: total was -29.850000. running mean: -35.005492\n",
      "ep 10: ep_len:234 episode reward: total was 8.000000. running mean: -34.575437\n",
      "ep 10: ep_len:585 episode reward: total was -42.280000. running mean: -34.652483\n",
      "ep 10: ep_len:168 episode reward: total was -1.500000. running mean: -34.320958\n",
      "ep 10: ep_len:550 episode reward: total was -51.470000. running mean: -34.492448\n",
      "ep 10: ep_len:500 episode reward: total was -4.680000. running mean: -34.194324\n",
      "ep 10: ep_len:500 episode reward: total was -4.790000. running mean: -33.900281\n",
      "ep 10: ep_len:246 episode reward: total was 5.000000. running mean: -33.511278\n",
      "ep 10: ep_len:500 episode reward: total was -15.530000. running mean: -33.331465\n",
      "ep 10: ep_len:680 episode reward: total was -30.150000. running mean: -33.299650\n",
      "ep 10: ep_len:765 episode reward: total was -34.940000. running mean: -33.316054\n",
      "ep 10: ep_len:765 episode reward: total was -28.500000. running mean: -33.267893\n",
      "ep 10: ep_len:625 episode reward: total was -37.670000. running mean: -33.311914\n",
      "ep 10: ep_len:700 episode reward: total was -97.500000. running mean: -33.953795\n",
      "ep 10: ep_len:495 episode reward: total was 3.670000. running mean: -33.577557\n",
      "ep 10: ep_len:750 episode reward: total was -32.370000. running mean: -33.565482\n",
      "ep 10: ep_len:635 episode reward: total was -48.240000. running mean: -33.712227\n",
      "ep 10: ep_len:625 episode reward: total was -19.340000. running mean: -33.568505\n",
      "ep 10: ep_len:500 episode reward: total was -7.920000. running mean: -33.312020\n",
      "ep 10: ep_len:1010 episode reward: total was -127.330000. running mean: -34.252199\n",
      "ep 10: ep_len:121 episode reward: total was -13.500000. running mean: -34.044677\n",
      "ep 10: ep_len:710 episode reward: total was -30.950000. running mean: -34.013731\n",
      "ep 10: ep_len:399 episode reward: total was 22.000000. running mean: -33.453593\n",
      "ep 10: ep_len:505 episode reward: total was -22.330000. running mean: -33.342357\n",
      "ep 10: ep_len:500 episode reward: total was -17.460000. running mean: -33.183534\n",
      "ep 10: ep_len:735 episode reward: total was -66.250000. running mean: -33.514198\n",
      "ep 10: ep_len:555 episode reward: total was -89.320000. running mean: -34.072256\n",
      "ep 10: ep_len:500 episode reward: total was 30.500000. running mean: -33.426534\n",
      "ep 10: ep_len:500 episode reward: total was -34.460000. running mean: -33.436869\n",
      "ep 10: ep_len:835 episode reward: total was -29.500000. running mean: -33.397500\n",
      "ep 10: ep_len:178 episode reward: total was 5.500000. running mean: -33.008525\n",
      "ep 10: ep_len:690 episode reward: total was -16.290000. running mean: -32.841340\n",
      "ep 10: ep_len:4375 episode reward: total was -750.300000. running mean: -40.015926\n",
      "ep 10: ep_len:505 episode reward: total was 0.210000. running mean: -39.613667\n",
      "ep 10: ep_len:345 episode reward: total was -13.480000. running mean: -39.352330\n",
      "ep 10: ep_len:840 episode reward: total was -36.100000. running mean: -39.319807\n",
      "ep 10: ep_len:940 episode reward: total was -43.250000. running mean: -39.359109\n",
      "ep 10: ep_len:660 episode reward: total was -18.420000. running mean: -39.149718\n",
      "ep 10: ep_len:220 episode reward: total was 10.000000. running mean: -38.658221\n",
      "ep 10: ep_len:940 episode reward: total was -14.420000. running mean: -38.415838\n",
      "ep 10: ep_len:500 episode reward: total was -26.750000. running mean: -38.299180\n",
      "ep 10: ep_len:580 episode reward: total was -49.360000. running mean: -38.409788\n",
      "ep 10: ep_len:337 episode reward: total was 10.000000. running mean: -37.925690\n",
      "ep 10: ep_len:550 episode reward: total was -32.770000. running mean: -37.874133\n",
      "ep 10: ep_len:500 episode reward: total was -11.410000. running mean: -37.609492\n",
      "ep 10: ep_len:700 episode reward: total was -25.950000. running mean: -37.492897\n",
      "ep 10: ep_len:565 episode reward: total was -71.640000. running mean: -37.834368\n",
      "ep 10: ep_len:500 episode reward: total was -13.340000. running mean: -37.589425\n",
      "ep 10: ep_len:560 episode reward: total was -50.410000. running mean: -37.717630\n",
      "ep 10: ep_len:1420 episode reward: total was -89.110000. running mean: -38.231554\n",
      "ep 10: ep_len:595 episode reward: total was -37.240000. running mean: -38.221638\n",
      "ep 10: ep_len:840 episode reward: total was -28.450000. running mean: -38.123922\n",
      "ep 10: ep_len:459 episode reward: total was 2.680000. running mean: -37.715883\n",
      "ep 10: ep_len:500 episode reward: total was 21.500000. running mean: -37.123724\n",
      "ep 10: ep_len:500 episode reward: total was 7.800000. running mean: -36.674487\n",
      "ep 10: ep_len:505 episode reward: total was -10.290000. running mean: -36.410642\n",
      "ep 10: ep_len:645 episode reward: total was -51.280000. running mean: -36.559336\n",
      "ep 10: ep_len:1125 episode reward: total was -31.450000. running mean: -36.508242\n",
      "ep 10: ep_len:970 episode reward: total was -27.130000. running mean: -36.414460\n",
      "ep 10: ep_len:500 episode reward: total was 2.730000. running mean: -36.023015\n",
      "ep 10: ep_len:540 episode reward: total was -41.390000. running mean: -36.076685\n",
      "ep 10: ep_len:500 episode reward: total was -46.880000. running mean: -36.184718\n",
      "ep 10: ep_len:590 episode reward: total was -17.470000. running mean: -35.997571\n",
      "ep 10: ep_len:500 episode reward: total was -28.430000. running mean: -35.921895\n",
      "ep 10: ep_len:500 episode reward: total was -11.270000. running mean: -35.675376\n",
      "ep 10: ep_len:505 episode reward: total was -6.790000. running mean: -35.386523\n",
      "ep 10: ep_len:575 episode reward: total was -44.350000. running mean: -35.476157\n",
      "ep 10: ep_len:1020 episode reward: total was -50.250000. running mean: -35.623896\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 10: ep_len:1235 episode reward: total was -184.430000. running mean: -37.111957\n",
      "ep 10: ep_len:500 episode reward: total was -23.410000. running mean: -36.974937\n",
      "ep 10: ep_len:930 episode reward: total was -45.790000. running mean: -37.063088\n",
      "ep 10: ep_len:790 episode reward: total was -53.010000. running mean: -37.222557\n",
      "ep 10: ep_len:755 episode reward: total was -26.290000. running mean: -37.113231\n",
      "ep 10: ep_len:565 episode reward: total was -33.960000. running mean: -37.081699\n",
      "ep 10: ep_len:565 episode reward: total was -61.540000. running mean: -37.326282\n",
      "ep 10: ep_len:1805 episode reward: total was -167.130000. running mean: -38.624319\n",
      "ep 10: ep_len:555 episode reward: total was -42.720000. running mean: -38.665276\n",
      "ep 10: ep_len:595 episode reward: total was -21.320000. running mean: -38.491823\n",
      "ep 10: ep_len:740 episode reward: total was -33.920000. running mean: -38.446105\n",
      "ep 10: ep_len:500 episode reward: total was -17.740000. running mean: -38.239044\n",
      "ep 10: ep_len:500 episode reward: total was -27.820000. running mean: -38.134854\n",
      "ep 10: ep_len:287 episode reward: total was 12.000000. running mean: -37.633505\n",
      "ep 10: ep_len:500 episode reward: total was -13.270000. running mean: -37.389870\n",
      "ep 10: ep_len:875 episode reward: total was -48.610000. running mean: -37.502071\n",
      "ep 10: ep_len:850 episode reward: total was -107.400000. running mean: -38.201051\n",
      "ep 10: ep_len:605 episode reward: total was -28.130000. running mean: -38.100340\n",
      "ep 10: ep_len:500 episode reward: total was -10.150000. running mean: -37.820837\n",
      "ep 10: ep_len:505 episode reward: total was -15.650000. running mean: -37.599128\n",
      "ep 10: ep_len:730 episode reward: total was -43.030000. running mean: -37.653437\n",
      "ep 10: ep_len:152 episode reward: total was -9.000000. running mean: -37.366903\n",
      "ep 10: ep_len:510 episode reward: total was -35.390000. running mean: -37.347134\n",
      "ep 10: ep_len:950 episode reward: total was -28.930000. running mean: -37.262962\n",
      "ep 10: ep_len:505 episode reward: total was -17.950000. running mean: -37.069833\n",
      "ep 10: ep_len:735 episode reward: total was -40.480000. running mean: -37.103934\n",
      "ep 10: ep_len:600 episode reward: total was -14.480000. running mean: -36.877695\n",
      "ep 10: ep_len:500 episode reward: total was -26.470000. running mean: -36.773618\n",
      "ep 10: ep_len:256 episode reward: total was -19.000000. running mean: -36.595882\n",
      "ep 10: ep_len:580 episode reward: total was -9.270000. running mean: -36.322623\n",
      "ep 10: ep_len:500 episode reward: total was 3.240000. running mean: -35.926997\n",
      "ep 10: ep_len:665 episode reward: total was -15.270000. running mean: -35.720427\n",
      "ep 10: ep_len:500 episode reward: total was 8.250000. running mean: -35.280723\n",
      "ep 10: ep_len:435 episode reward: total was -10.290000. running mean: -35.030815\n",
      "ep 10: ep_len:565 episode reward: total was -79.220000. running mean: -35.472707\n",
      "ep 10: ep_len:242 episode reward: total was 15.000000. running mean: -34.967980\n",
      "ep 10: ep_len:580 episode reward: total was -27.720000. running mean: -34.895500\n",
      "ep 10: ep_len:970 episode reward: total was -126.380000. running mean: -35.810345\n",
      "ep 10: ep_len:1600 episode reward: total was -267.550000. running mean: -38.127742\n",
      "ep 10: ep_len:2867 episode reward: total was -312.890000. running mean: -40.875364\n",
      "ep 10: ep_len:945 episode reward: total was -63.470000. running mean: -41.101311\n",
      "ep 10: ep_len:500 episode reward: total was 26.000000. running mean: -40.430298\n",
      "ep 10: ep_len:780 episode reward: total was -73.230000. running mean: -40.758295\n",
      "ep 10: ep_len:580 episode reward: total was -12.720000. running mean: -40.477912\n",
      "ep 10: ep_len:1330 episode reward: total was -78.370000. running mean: -40.856833\n",
      "ep 10: ep_len:710 episode reward: total was -82.950000. running mean: -41.277764\n",
      "ep 10: ep_len:500 episode reward: total was 19.000000. running mean: -40.674987\n",
      "ep 10: ep_len:500 episode reward: total was -27.900000. running mean: -40.547237\n",
      "epsilon:0.230759 episode_count: 8679. steps_count: 6148344.000000\n",
      "ep 11: ep_len:1475 episode reward: total was -83.930000. running mean: -40.981064\n",
      "ep 11: ep_len:790 episode reward: total was -61.580000. running mean: -41.187054\n",
      "ep 11: ep_len:500 episode reward: total was -19.660000. running mean: -40.971783\n",
      "ep 11: ep_len:1020 episode reward: total was -170.800000. running mean: -42.270065\n",
      "ep 11: ep_len:540 episode reward: total was -10.350000. running mean: -41.950865\n",
      "ep 11: ep_len:500 episode reward: total was -34.000000. running mean: -41.871356\n",
      "ep 11: ep_len:500 episode reward: total was -46.960000. running mean: -41.922243\n",
      "ep 11: ep_len:500 episode reward: total was -8.760000. running mean: -41.590620\n",
      "ep 11: ep_len:845 episode reward: total was -63.000000. running mean: -41.804714\n",
      "ep 11: ep_len:1020 episode reward: total was -22.960000. running mean: -41.616267\n",
      "ep 11: ep_len:500 episode reward: total was -20.900000. running mean: -41.409104\n",
      "ep 11: ep_len:660 episode reward: total was -44.150000. running mean: -41.436513\n",
      "ep 11: ep_len:560 episode reward: total was -44.350000. running mean: -41.465648\n",
      "ep 11: ep_len:1090 episode reward: total was -89.780000. running mean: -41.948791\n",
      "ep 11: ep_len:1030 episode reward: total was -45.450000. running mean: -41.983804\n",
      "ep 11: ep_len:500 episode reward: total was 7.740000. running mean: -41.486566\n",
      "ep 11: ep_len:505 episode reward: total was -50.960000. running mean: -41.581300\n",
      "ep 11: ep_len:500 episode reward: total was -20.040000. running mean: -41.365887\n",
      "ep 11: ep_len:615 episode reward: total was -42.220000. running mean: -41.374428\n",
      "ep 11: ep_len:500 episode reward: total was -28.170000. running mean: -41.242384\n",
      "ep 11: ep_len:1615 episode reward: total was -201.850000. running mean: -42.848460\n",
      "ep 11: ep_len:237 episode reward: total was 13.000000. running mean: -42.289975\n",
      "ep 11: ep_len:1010 episode reward: total was -72.770000. running mean: -42.594776\n",
      "ep 11: ep_len:1420 episode reward: total was -165.880000. running mean: -43.827628\n",
      "ep 11: ep_len:500 episode reward: total was -7.370000. running mean: -43.463052\n",
      "ep 11: ep_len:940 episode reward: total was -55.780000. running mean: -43.586221\n",
      "ep 11: ep_len:940 episode reward: total was -20.010000. running mean: -43.350459\n",
      "ep 11: ep_len:885 episode reward: total was -66.450000. running mean: -43.581454\n",
      "ep 11: ep_len:920 episode reward: total was -143.300000. running mean: -44.578640\n",
      "ep 11: ep_len:565 episode reward: total was -25.180000. running mean: -44.384653\n",
      "ep 11: ep_len:484 episode reward: total was -13.470000. running mean: -44.075507\n",
      "ep 11: ep_len:505 episode reward: total was -16.210000. running mean: -43.796852\n",
      "ep 11: ep_len:810 episode reward: total was -44.980000. running mean: -43.808683\n",
      "ep 11: ep_len:670 episode reward: total was -31.930000. running mean: -43.689896\n",
      "ep 11: ep_len:500 episode reward: total was -17.840000. running mean: -43.431397\n",
      "ep 11: ep_len:685 episode reward: total was -34.030000. running mean: -43.337383\n",
      "ep 11: ep_len:725 episode reward: total was -26.110000. running mean: -43.165110\n",
      "ep 11: ep_len:500 episode reward: total was -18.880000. running mean: -42.922258\n",
      "ep 11: ep_len:791 episode reward: total was -34.810000. running mean: -42.841136\n",
      "ep 11: ep_len:945 episode reward: total was -36.720000. running mean: -42.779925\n",
      "ep 11: ep_len:820 episode reward: total was -16.260000. running mean: -42.514725\n",
      "ep 11: ep_len:520 episode reward: total was -27.780000. running mean: -42.367378\n",
      "ep 11: ep_len:500 episode reward: total was -11.800000. running mean: -42.061704\n",
      "ep 11: ep_len:530 episode reward: total was -19.970000. running mean: -41.840787\n",
      "ep 11: ep_len:162 episode reward: total was 1.000000. running mean: -41.412379\n",
      "ep 11: ep_len:500 episode reward: total was -37.480000. running mean: -41.373056\n",
      "ep 11: ep_len:745 episode reward: total was -32.900000. running mean: -41.288325\n",
      "ep 11: ep_len:950 episode reward: total was -66.800000. running mean: -41.543442\n",
      "ep 11: ep_len:204 episode reward: total was 9.500000. running mean: -41.033007\n",
      "ep 11: ep_len:905 episode reward: total was -37.010000. running mean: -40.992777\n",
      "ep 11: ep_len:185 episode reward: total was 4.000000. running mean: -40.542849\n",
      "ep 11: ep_len:860 episode reward: total was -164.950000. running mean: -41.786921\n",
      "ep 11: ep_len:500 episode reward: total was -7.120000. running mean: -41.440252\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 11: ep_len:500 episode reward: total was -9.160000. running mean: -41.117449\n",
      "ep 11: ep_len:670 episode reward: total was -20.900000. running mean: -40.915275\n",
      "ep 11: ep_len:615 episode reward: total was 6.190000. running mean: -40.444222\n",
      "ep 11: ep_len:535 episode reward: total was -37.360000. running mean: -40.413380\n",
      "ep 11: ep_len:562 episode reward: total was -82.740000. running mean: -40.836646\n",
      "ep 11: ep_len:1225 episode reward: total was -217.260000. running mean: -42.600880\n",
      "ep 11: ep_len:500 episode reward: total was -29.350000. running mean: -42.468371\n",
      "ep 11: ep_len:830 episode reward: total was -31.330000. running mean: -42.356987\n",
      "ep 11: ep_len:149 episode reward: total was 1.000000. running mean: -41.923417\n",
      "ep 11: ep_len:500 episode reward: total was -27.420000. running mean: -41.778383\n",
      "ep 11: ep_len:484 episode reward: total was 16.170000. running mean: -41.198899\n",
      "ep 11: ep_len:1150 episode reward: total was -85.620000. running mean: -41.643110\n",
      "ep 11: ep_len:625 episode reward: total was -47.280000. running mean: -41.699479\n",
      "ep 11: ep_len:505 episode reward: total was -32.860000. running mean: -41.611084\n",
      "ep 11: ep_len:640 episode reward: total was -42.200000. running mean: -41.616973\n",
      "ep 11: ep_len:760 episode reward: total was -33.360000. running mean: -41.534404\n",
      "ep 11: ep_len:152 episode reward: total was 9.000000. running mean: -41.029060\n",
      "ep 11: ep_len:865 episode reward: total was -37.860000. running mean: -40.997369\n",
      "ep 11: ep_len:705 episode reward: total was -32.550000. running mean: -40.912895\n",
      "ep 11: ep_len:367 episode reward: total was -42.730000. running mean: -40.931066\n",
      "ep 11: ep_len:500 episode reward: total was -5.180000. running mean: -40.573556\n",
      "ep 11: ep_len:500 episode reward: total was -2.820000. running mean: -40.196020\n",
      "ep 11: ep_len:500 episode reward: total was -5.860000. running mean: -39.852660\n",
      "ep 11: ep_len:2110 episode reward: total was -193.790000. running mean: -41.392033\n",
      "ep 11: ep_len:660 episode reward: total was -21.960000. running mean: -41.197713\n",
      "ep 11: ep_len:1420 episode reward: total was -231.740000. running mean: -43.103136\n",
      "ep 11: ep_len:500 episode reward: total was -7.300000. running mean: -42.745105\n",
      "ep 11: ep_len:695 episode reward: total was -35.020000. running mean: -42.667854\n",
      "ep 11: ep_len:500 episode reward: total was -17.720000. running mean: -42.418375\n",
      "ep 11: ep_len:271 episode reward: total was 4.500000. running mean: -41.949191\n",
      "ep 11: ep_len:500 episode reward: total was -12.840000. running mean: -41.658099\n",
      "ep 11: ep_len:560 episode reward: total was -27.210000. running mean: -41.513618\n",
      "ep 11: ep_len:510 episode reward: total was -8.110000. running mean: -41.179582\n",
      "ep 11: ep_len:815 episode reward: total was -38.560000. running mean: -41.153386\n",
      "ep 11: ep_len:520 episode reward: total was -25.870000. running mean: -41.000552\n",
      "ep 11: ep_len:510 episode reward: total was -20.990000. running mean: -40.800447\n",
      "ep 11: ep_len:505 episode reward: total was -47.980000. running mean: -40.872242\n",
      "ep 11: ep_len:515 episode reward: total was -29.290000. running mean: -40.756420\n",
      "ep 11: ep_len:565 episode reward: total was -14.270000. running mean: -40.491556\n",
      "ep 11: ep_len:510 episode reward: total was -23.410000. running mean: -40.320740\n",
      "ep 11: ep_len:500 episode reward: total was -37.990000. running mean: -40.297433\n",
      "ep 11: ep_len:500 episode reward: total was 1.730000. running mean: -39.877159\n",
      "ep 11: ep_len:910 episode reward: total was -5.300000. running mean: -39.531387\n",
      "ep 11: ep_len:900 episode reward: total was -48.810000. running mean: -39.624173\n",
      "ep 11: ep_len:700 episode reward: total was -28.950000. running mean: -39.517431\n",
      "ep 11: ep_len:500 episode reward: total was -25.420000. running mean: -39.376457\n",
      "ep 11: ep_len:665 episode reward: total was -63.850000. running mean: -39.621192\n",
      "ep 11: ep_len:860 episode reward: total was -133.880000. running mean: -40.563781\n",
      "ep 11: ep_len:695 episode reward: total was -38.000000. running mean: -40.538143\n",
      "ep 11: ep_len:500 episode reward: total was -22.890000. running mean: -40.361661\n",
      "ep 11: ep_len:570 episode reward: total was -41.820000. running mean: -40.376245\n",
      "ep 11: ep_len:500 episode reward: total was 4.150000. running mean: -39.930982\n",
      "ep 11: ep_len:135 episode reward: total was 9.000000. running mean: -39.441672\n",
      "ep 11: ep_len:500 episode reward: total was -36.770000. running mean: -39.414956\n",
      "ep 11: ep_len:500 episode reward: total was -0.780000. running mean: -39.028606\n",
      "ep 11: ep_len:6500 episode reward: total was -1190.130000. running mean: -50.539620\n",
      "ep 11: ep_len:885 episode reward: total was -109.430000. running mean: -51.128524\n",
      "ep 11: ep_len:500 episode reward: total was -23.350000. running mean: -50.850739\n",
      "ep 11: ep_len:890 episode reward: total was -53.300000. running mean: -50.875231\n",
      "ep 11: ep_len:565 episode reward: total was -53.870000. running mean: -50.905179\n",
      "ep 11: ep_len:770 episode reward: total was -41.770000. running mean: -50.813827\n",
      "ep 11: ep_len:835 episode reward: total was -46.830000. running mean: -50.773989\n",
      "ep 11: ep_len:930 episode reward: total was -52.790000. running mean: -50.794149\n",
      "ep 11: ep_len:505 episode reward: total was -35.460000. running mean: -50.640808\n",
      "ep 11: ep_len:1415 episode reward: total was -226.980000. running mean: -52.404199\n",
      "ep 11: ep_len:860 episode reward: total was -56.450000. running mean: -52.444657\n",
      "ep 11: ep_len:700 episode reward: total was -24.390000. running mean: -52.164111\n",
      "ep 11: ep_len:500 episode reward: total was 32.000000. running mean: -51.322470\n",
      "ep 11: ep_len:730 episode reward: total was -68.770000. running mean: -51.496945\n",
      "ep 11: ep_len:1020 episode reward: total was -20.370000. running mean: -51.185676\n",
      "ep 11: ep_len:146 episode reward: total was 3.000000. running mean: -50.643819\n",
      "ep 11: ep_len:780 episode reward: total was -36.830000. running mean: -50.505681\n",
      "ep 11: ep_len:850 episode reward: total was -59.960000. running mean: -50.600224\n",
      "ep 11: ep_len:500 episode reward: total was -17.700000. running mean: -50.271222\n",
      "ep 11: ep_len:235 episode reward: total was 5.500000. running mean: -49.713509\n",
      "ep 11: ep_len:770 episode reward: total was -79.200000. running mean: -50.008374\n",
      "ep 11: ep_len:500 episode reward: total was -10.330000. running mean: -49.611591\n",
      "ep 11: ep_len:505 episode reward: total was -5.330000. running mean: -49.168775\n",
      "ep 11: ep_len:1390 episode reward: total was -129.580000. running mean: -49.972887\n",
      "ep 11: ep_len:915 episode reward: total was -54.380000. running mean: -50.016958\n",
      "ep 11: ep_len:500 episode reward: total was -37.670000. running mean: -49.893488\n",
      "ep 11: ep_len:500 episode reward: total was -6.290000. running mean: -49.457454\n",
      "ep 11: ep_len:500 episode reward: total was 23.500000. running mean: -48.727879\n",
      "ep 11: ep_len:500 episode reward: total was -5.790000. running mean: -48.298500\n",
      "ep 11: ep_len:510 episode reward: total was -23.420000. running mean: -48.049715\n",
      "ep 11: ep_len:1425 episode reward: total was -97.160000. running mean: -48.540818\n",
      "ep 11: ep_len:540 episode reward: total was -50.570000. running mean: -48.561110\n",
      "ep 11: ep_len:635 episode reward: total was -47.130000. running mean: -48.546799\n",
      "ep 11: ep_len:208 episode reward: total was 10.500000. running mean: -47.956331\n",
      "ep 11: ep_len:585 episode reward: total was -41.790000. running mean: -47.894668\n",
      "ep 11: ep_len:160 episode reward: total was 8.500000. running mean: -47.330721\n",
      "ep 11: ep_len:500 episode reward: total was -7.490000. running mean: -46.932314\n",
      "ep 11: ep_len:965 episode reward: total was -21.460000. running mean: -46.677591\n",
      "ep 11: ep_len:510 episode reward: total was -69.210000. running mean: -46.902915\n",
      "ep 11: ep_len:268 episode reward: total was 8.500000. running mean: -46.348885\n",
      "ep 11: ep_len:500 episode reward: total was 6.630000. running mean: -45.819097\n",
      "ep 11: ep_len:765 episode reward: total was -42.820000. running mean: -45.789106\n",
      "ep 11: ep_len:595 episode reward: total was -50.060000. running mean: -45.831815\n",
      "ep 11: ep_len:615 episode reward: total was -10.550000. running mean: -45.478996\n",
      "ep 11: ep_len:184 episode reward: total was 6.000000. running mean: -44.964206\n",
      "ep 11: ep_len:500 episode reward: total was -22.970000. running mean: -44.744264\n",
      "ep 11: ep_len:880 episode reward: total was -26.150000. running mean: -44.558322\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 11: ep_len:690 episode reward: total was -30.990000. running mean: -44.422639\n",
      "ep 11: ep_len:815 episode reward: total was -41.320000. running mean: -44.391612\n",
      "ep 11: ep_len:790 episode reward: total was -42.540000. running mean: -44.373096\n",
      "ep 11: ep_len:305 episode reward: total was -11.920000. running mean: -44.048565\n",
      "ep 11: ep_len:500 episode reward: total was -22.000000. running mean: -43.828079\n",
      "ep 11: ep_len:500 episode reward: total was -12.880000. running mean: -43.518599\n",
      "ep 11: ep_len:500 episode reward: total was -7.570000. running mean: -43.159113\n",
      "ep 11: ep_len:810 episode reward: total was -33.780000. running mean: -43.065322\n",
      "ep 11: ep_len:695 episode reward: total was -29.450000. running mean: -42.929168\n",
      "ep 11: ep_len:610 episode reward: total was -50.460000. running mean: -43.004477\n",
      "ep 11: ep_len:500 episode reward: total was -21.570000. running mean: -42.790132\n",
      "ep 11: ep_len:510 episode reward: total was -26.790000. running mean: -42.630131\n",
      "ep 11: ep_len:610 episode reward: total was -27.110000. running mean: -42.474929\n",
      "ep 11: ep_len:505 episode reward: total was -10.350000. running mean: -42.153680\n",
      "ep 11: ep_len:950 episode reward: total was -40.920000. running mean: -42.141343\n",
      "ep 11: ep_len:500 episode reward: total was -20.500000. running mean: -41.924930\n",
      "ep 11: ep_len:510 episode reward: total was -30.780000. running mean: -41.813480\n",
      "ep 11: ep_len:785 episode reward: total was -34.350000. running mean: -41.738846\n",
      "ep 11: ep_len:172 episode reward: total was 9.500000. running mean: -41.226457\n",
      "ep 11: ep_len:915 episode reward: total was -61.850000. running mean: -41.432693\n",
      "ep 11: ep_len:1020 episode reward: total was -41.150000. running mean: -41.429866\n",
      "ep 11: ep_len:196 episode reward: total was 13.500000. running mean: -40.880567\n",
      "ep 11: ep_len:640 episode reward: total was -18.990000. running mean: -40.661661\n",
      "ep 11: ep_len:209 episode reward: total was 10.000000. running mean: -40.155045\n",
      "ep 11: ep_len:815 episode reward: total was -41.370000. running mean: -40.167194\n",
      "ep 11: ep_len:520 episode reward: total was -41.430000. running mean: -40.179822\n",
      "ep 11: ep_len:500 episode reward: total was -39.710000. running mean: -40.175124\n",
      "ep 11: ep_len:505 episode reward: total was -23.760000. running mean: -40.010973\n",
      "ep 11: ep_len:505 episode reward: total was -54.190000. running mean: -40.152763\n",
      "ep 11: ep_len:500 episode reward: total was -55.480000. running mean: -40.306035\n",
      "ep 11: ep_len:500 episode reward: total was -20.000000. running mean: -40.102975\n",
      "ep 11: ep_len:75 episode reward: total was 3.000000. running mean: -39.671945\n",
      "ep 11: ep_len:540 episode reward: total was -42.370000. running mean: -39.698926\n",
      "ep 11: ep_len:505 episode reward: total was 2.210000. running mean: -39.279837\n",
      "ep 11: ep_len:756 episode reward: total was -79.300000. running mean: -39.680038\n",
      "ep 11: ep_len:505 episode reward: total was -27.990000. running mean: -39.563138\n",
      "ep 11: ep_len:510 episode reward: total was -31.280000. running mean: -39.480307\n",
      "ep 11: ep_len:710 episode reward: total was -30.950000. running mean: -39.395003\n",
      "ep 11: ep_len:785 episode reward: total was -30.770000. running mean: -39.308753\n",
      "ep 11: ep_len:895 episode reward: total was -136.110000. running mean: -40.276766\n",
      "ep 11: ep_len:500 episode reward: total was -4.550000. running mean: -39.919498\n",
      "ep 11: ep_len:1600 episode reward: total was -236.310000. running mean: -41.883403\n",
      "ep 11: ep_len:500 episode reward: total was 4.270000. running mean: -41.421869\n",
      "ep 11: ep_len:500 episode reward: total was 2.740000. running mean: -40.980251\n",
      "ep 11: ep_len:995 episode reward: total was -28.500000. running mean: -40.855448\n",
      "ep 11: ep_len:1005 episode reward: total was -38.120000. running mean: -40.828094\n",
      "ep 11: ep_len:1000 episode reward: total was -23.440000. running mean: -40.654213\n",
      "ep 11: ep_len:630 episode reward: total was -55.320000. running mean: -40.800870\n",
      "ep 11: ep_len:965 episode reward: total was -31.310000. running mean: -40.705962\n",
      "ep 11: ep_len:500 episode reward: total was -14.810000. running mean: -40.447002\n",
      "ep 11: ep_len:565 episode reward: total was -8.460000. running mean: -40.127132\n",
      "ep 11: ep_len:880 episode reward: total was -52.490000. running mean: -40.250761\n",
      "ep 11: ep_len:4215 episode reward: total was -723.870000. running mean: -47.086953\n",
      "ep 11: ep_len:500 episode reward: total was 1.760000. running mean: -46.598484\n",
      "ep 11: ep_len:520 episode reward: total was -17.730000. running mean: -46.309799\n",
      "ep 11: ep_len:720 episode reward: total was -35.950000. running mean: -46.206201\n",
      "ep 11: ep_len:610 episode reward: total was -42.380000. running mean: -46.167939\n",
      "ep 11: ep_len:650 episode reward: total was -11.000000. running mean: -45.816259\n",
      "ep 11: ep_len:218 episode reward: total was 8.500000. running mean: -45.273097\n",
      "ep 11: ep_len:865 episode reward: total was -30.650000. running mean: -45.126866\n",
      "ep 11: ep_len:745 episode reward: total was -33.390000. running mean: -45.009497\n",
      "ep 11: ep_len:685 episode reward: total was -19.560000. running mean: -44.755002\n",
      "ep 11: ep_len:635 episode reward: total was -42.050000. running mean: -44.727952\n",
      "ep 11: ep_len:505 episode reward: total was -30.440000. running mean: -44.585073\n",
      "ep 11: ep_len:515 episode reward: total was -0.800000. running mean: -44.147222\n",
      "ep 11: ep_len:780 episode reward: total was -18.290000. running mean: -43.888650\n",
      "ep 11: ep_len:930 episode reward: total was -32.980000. running mean: -43.779563\n",
      "ep 11: ep_len:500 episode reward: total was -11.140000. running mean: -43.453168\n",
      "ep 11: ep_len:575 episode reward: total was -33.240000. running mean: -43.351036\n",
      "ep 11: ep_len:500 episode reward: total was -40.640000. running mean: -43.323926\n",
      "ep 11: ep_len:416 episode reward: total was -0.280000. running mean: -42.893486\n",
      "ep 11: ep_len:505 episode reward: total was -9.910000. running mean: -42.563651\n",
      "ep 11: ep_len:450 episode reward: total was 4.700000. running mean: -42.091015\n",
      "ep 11: ep_len:500 episode reward: total was -5.350000. running mean: -41.723605\n",
      "ep 11: ep_len:505 episode reward: total was -35.430000. running mean: -41.660669\n",
      "ep 11: ep_len:705 episode reward: total was -35.000000. running mean: -41.594062\n",
      "ep 11: ep_len:500 episode reward: total was -37.060000. running mean: -41.548721\n",
      "ep 11: ep_len:1020 episode reward: total was -60.550000. running mean: -41.738734\n",
      "ep 11: ep_len:500 episode reward: total was 0.760000. running mean: -41.313747\n",
      "ep 11: ep_len:505 episode reward: total was -10.400000. running mean: -41.004609\n",
      "ep 11: ep_len:730 episode reward: total was -11.580000. running mean: -40.710363\n",
      "ep 11: ep_len:1035 episode reward: total was -37.940000. running mean: -40.682660\n",
      "ep 11: ep_len:1440 episode reward: total was -89.870000. running mean: -41.174533\n",
      "ep 11: ep_len:500 episode reward: total was -51.570000. running mean: -41.278488\n",
      "ep 11: ep_len:500 episode reward: total was 23.000000. running mean: -40.635703\n",
      "ep 11: ep_len:985 episode reward: total was -44.530000. running mean: -40.674646\n",
      "ep 11: ep_len:510 episode reward: total was -16.770000. running mean: -40.435599\n",
      "ep 11: ep_len:500 episode reward: total was -14.740000. running mean: -40.178643\n",
      "ep 11: ep_len:895 episode reward: total was -32.240000. running mean: -40.099257\n",
      "ep 11: ep_len:500 episode reward: total was -18.110000. running mean: -39.879364\n",
      "ep 11: ep_len:188 episode reward: total was 6.500000. running mean: -39.415571\n",
      "ep 11: ep_len:1165 episode reward: total was -47.470000. running mean: -39.496115\n",
      "ep 11: ep_len:500 episode reward: total was -24.570000. running mean: -39.346854\n",
      "ep 11: ep_len:880 episode reward: total was -26.310000. running mean: -39.216485\n",
      "ep 11: ep_len:500 episode reward: total was -23.590000. running mean: -39.060221\n",
      "ep 11: ep_len:500 episode reward: total was 7.710000. running mean: -38.592518\n",
      "ep 11: ep_len:855 episode reward: total was -61.970000. running mean: -38.826293\n",
      "ep 11: ep_len:500 episode reward: total was -13.950000. running mean: -38.577530\n",
      "ep 11: ep_len:500 episode reward: total was -13.910000. running mean: -38.330855\n",
      "ep 11: ep_len:1130 episode reward: total was -56.960000. running mean: -38.517146\n",
      "ep 11: ep_len:500 episode reward: total was -18.960000. running mean: -38.321575\n",
      "ep 11: ep_len:214 episode reward: total was 8.000000. running mean: -37.858359\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 11: ep_len:935 episode reward: total was -46.480000. running mean: -37.944576\n",
      "ep 11: ep_len:500 episode reward: total was -38.560000. running mean: -37.950730\n",
      "ep 11: ep_len:218 episode reward: total was 7.000000. running mean: -37.501223\n",
      "ep 11: ep_len:590 episode reward: total was -23.870000. running mean: -37.364910\n",
      "ep 11: ep_len:1150 episode reward: total was -48.910000. running mean: -37.480361\n",
      "ep 11: ep_len:580 episode reward: total was -23.130000. running mean: -37.336858\n",
      "ep 11: ep_len:500 episode reward: total was -0.380000. running mean: -36.967289\n",
      "ep 11: ep_len:500 episode reward: total was -18.310000. running mean: -36.780716\n",
      "ep 11: ep_len:510 episode reward: total was -13.220000. running mean: -36.545109\n",
      "ep 11: ep_len:720 episode reward: total was -32.920000. running mean: -36.508858\n",
      "ep 11: ep_len:500 episode reward: total was 1.130000. running mean: -36.132469\n",
      "ep 11: ep_len:167 episode reward: total was 7.500000. running mean: -35.696145\n",
      "ep 11: ep_len:500 episode reward: total was -27.390000. running mean: -35.613083\n",
      "ep 11: ep_len:795 episode reward: total was -32.480000. running mean: -35.581752\n",
      "ep 11: ep_len:505 episode reward: total was -17.420000. running mean: -35.400135\n",
      "ep 11: ep_len:200 episode reward: total was 8.000000. running mean: -34.966133\n",
      "ep 11: ep_len:620 episode reward: total was -41.230000. running mean: -35.028772\n",
      "ep 11: ep_len:590 episode reward: total was -22.070000. running mean: -34.899184\n",
      "ep 11: ep_len:515 episode reward: total was -34.860000. running mean: -34.898793\n",
      "ep 11: ep_len:500 episode reward: total was 1.170000. running mean: -34.538105\n",
      "ep 11: ep_len:530 episode reward: total was -30.860000. running mean: -34.501324\n",
      "ep 11: ep_len:505 episode reward: total was 15.000000. running mean: -34.006310\n",
      "ep 11: ep_len:500 episode reward: total was -17.440000. running mean: -33.840647\n",
      "ep 11: ep_len:500 episode reward: total was -20.380000. running mean: -33.706041\n",
      "ep 11: ep_len:500 episode reward: total was -21.840000. running mean: -33.587380\n",
      "ep 11: ep_len:270 episode reward: total was -0.480000. running mean: -33.256307\n",
      "ep 11: ep_len:240 episode reward: total was 8.000000. running mean: -32.843743\n",
      "ep 11: ep_len:590 episode reward: total was -33.180000. running mean: -32.847106\n",
      "ep 11: ep_len:361 episode reward: total was 8.000000. running mean: -32.438635\n",
      "ep 11: ep_len:505 episode reward: total was -21.950000. running mean: -32.333749\n",
      "ep 11: ep_len:520 episode reward: total was -10.650000. running mean: -32.116911\n",
      "ep 11: ep_len:540 episode reward: total was -45.910000. running mean: -32.254842\n",
      "ep 11: ep_len:1120 episode reward: total was -79.420000. running mean: -32.726494\n",
      "ep 11: ep_len:1460 episode reward: total was -121.360000. running mean: -33.612829\n",
      "ep 11: ep_len:1020 episode reward: total was -19.880000. running mean: -33.475500\n",
      "ep 11: ep_len:500 episode reward: total was -36.600000. running mean: -33.506745\n",
      "ep 11: ep_len:500 episode reward: total was -4.310000. running mean: -33.214778\n",
      "ep 11: ep_len:715 episode reward: total was -13.150000. running mean: -33.014130\n",
      "ep 11: ep_len:735 episode reward: total was -36.960000. running mean: -33.053589\n",
      "ep 11: ep_len:1020 episode reward: total was -53.560000. running mean: -33.258653\n",
      "ep 11: ep_len:980 episode reward: total was -49.740000. running mean: -33.423466\n",
      "ep 11: ep_len:500 episode reward: total was -43.030000. running mean: -33.519532\n",
      "ep 11: ep_len:610 episode reward: total was -34.180000. running mean: -33.526136\n",
      "ep 11: ep_len:211 episode reward: total was 6.000000. running mean: -33.130875\n",
      "ep 11: ep_len:500 episode reward: total was -10.510000. running mean: -32.904666\n",
      "ep 11: ep_len:875 episode reward: total was -48.090000. running mean: -33.056520\n",
      "ep 11: ep_len:500 episode reward: total was 14.200000. running mean: -32.583954\n",
      "ep 11: ep_len:500 episode reward: total was -11.070000. running mean: -32.368815\n",
      "ep 11: ep_len:540 episode reward: total was -32.300000. running mean: -32.368127\n",
      "ep 11: ep_len:102 episode reward: total was 1.500000. running mean: -32.029446\n",
      "ep 11: ep_len:331 episode reward: total was 7.000000. running mean: -31.639151\n",
      "ep 11: ep_len:500 episode reward: total was -30.050000. running mean: -31.623260\n",
      "ep 11: ep_len:720 episode reward: total was -36.410000. running mean: -31.671127\n",
      "ep 11: ep_len:645 episode reward: total was -21.490000. running mean: -31.569316\n",
      "ep 11: ep_len:870 episode reward: total was -112.930000. running mean: -32.382923\n",
      "ep 11: ep_len:111 episode reward: total was 8.000000. running mean: -31.979093\n",
      "ep 11: ep_len:830 episode reward: total was -51.350000. running mean: -32.172802\n",
      "ep 11: ep_len:530 episode reward: total was -22.340000. running mean: -32.074474\n",
      "ep 11: ep_len:510 episode reward: total was -7.180000. running mean: -31.825530\n",
      "ep 11: ep_len:505 episode reward: total was -9.880000. running mean: -31.606074\n",
      "ep 11: ep_len:1035 episode reward: total was -32.710000. running mean: -31.617114\n",
      "ep 11: ep_len:500 episode reward: total was -9.290000. running mean: -31.393842\n",
      "ep 11: ep_len:500 episode reward: total was -26.460000. running mean: -31.344504\n",
      "ep 11: ep_len:2135 episode reward: total was -180.110000. running mean: -32.832159\n",
      "ep 11: ep_len:805 episode reward: total was -34.800000. running mean: -32.851837\n",
      "ep 11: ep_len:500 episode reward: total was -12.800000. running mean: -32.651319\n",
      "ep 11: ep_len:550 episode reward: total was -39.350000. running mean: -32.718306\n",
      "ep 11: ep_len:730 episode reward: total was -50.920000. running mean: -32.900323\n",
      "ep 11: ep_len:1100 episode reward: total was -147.330000. running mean: -34.044620\n",
      "ep 11: ep_len:625 episode reward: total was -63.760000. running mean: -34.341773\n",
      "ep 11: ep_len:1020 episode reward: total was -56.070000. running mean: -34.559056\n",
      "ep 11: ep_len:505 episode reward: total was 1.780000. running mean: -34.195665\n",
      "ep 11: ep_len:680 episode reward: total was -22.560000. running mean: -34.079308\n",
      "ep 11: ep_len:339 episode reward: total was -4.000000. running mean: -33.778515\n",
      "ep 11: ep_len:500 episode reward: total was -22.560000. running mean: -33.666330\n",
      "ep 11: ep_len:1370 episode reward: total was -87.810000. running mean: -34.207767\n",
      "ep 11: ep_len:690 episode reward: total was -35.000000. running mean: -34.215689\n",
      "ep 11: ep_len:500 episode reward: total was -21.360000. running mean: -34.087132\n",
      "ep 11: ep_len:266 episode reward: total was 13.000000. running mean: -33.616261\n",
      "ep 11: ep_len:500 episode reward: total was -22.280000. running mean: -33.502898\n",
      "ep 11: ep_len:500 episode reward: total was -10.310000. running mean: -33.270969\n",
      "ep 11: ep_len:252 episode reward: total was 14.500000. running mean: -32.793260\n",
      "ep 11: ep_len:319 episode reward: total was -9.870000. running mean: -32.564027\n",
      "ep 11: ep_len:268 episode reward: total was 7.500000. running mean: -32.163387\n",
      "ep 11: ep_len:1030 episode reward: total was -114.110000. running mean: -32.982853\n",
      "ep 11: ep_len:625 episode reward: total was -33.110000. running mean: -32.984124\n",
      "ep 11: ep_len:1350 episode reward: total was -131.680000. running mean: -33.971083\n",
      "ep 11: ep_len:500 episode reward: total was -6.780000. running mean: -33.699172\n",
      "ep 11: ep_len:920 episode reward: total was -52.310000. running mean: -33.885281\n",
      "ep 11: ep_len:500 episode reward: total was -32.370000. running mean: -33.870128\n",
      "ep 11: ep_len:565 episode reward: total was -21.630000. running mean: -33.747727\n",
      "ep 11: ep_len:705 episode reward: total was -89.860000. running mean: -34.308849\n",
      "ep 11: ep_len:735 episode reward: total was -33.270000. running mean: -34.298461\n",
      "ep 11: ep_len:510 episode reward: total was -1.680000. running mean: -33.972276\n",
      "ep 11: ep_len:500 episode reward: total was -43.960000. running mean: -34.072153\n",
      "ep 11: ep_len:198 episode reward: total was 13.500000. running mean: -33.596432\n",
      "ep 11: ep_len:960 episode reward: total was -99.130000. running mean: -34.251768\n",
      "ep 11: ep_len:670 episode reward: total was -33.050000. running mean: -34.239750\n",
      "ep 11: ep_len:845 episode reward: total was -19.460000. running mean: -34.091952\n",
      "ep 11: ep_len:590 episode reward: total was -20.600000. running mean: -33.957033\n",
      "ep 11: ep_len:500 episode reward: total was 2.710000. running mean: -33.590363\n",
      "ep 11: ep_len:810 episode reward: total was -11.910000. running mean: -33.373559\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 11: ep_len:1430 episode reward: total was -225.650000. running mean: -35.296323\n",
      "ep 11: ep_len:540 episode reward: total was -76.740000. running mean: -35.710760\n",
      "ep 11: ep_len:520 episode reward: total was -9.860000. running mean: -35.452252\n",
      "ep 11: ep_len:530 episode reward: total was -26.260000. running mean: -35.360330\n",
      "ep 11: ep_len:500 episode reward: total was -28.360000. running mean: -35.290327\n",
      "ep 11: ep_len:680 episode reward: total was 1.820000. running mean: -34.919223\n",
      "ep 11: ep_len:505 episode reward: total was -12.380000. running mean: -34.693831\n",
      "ep 11: ep_len:215 episode reward: total was 7.000000. running mean: -34.276893\n",
      "ep 11: ep_len:505 episode reward: total was -34.550000. running mean: -34.279624\n",
      "ep 11: ep_len:695 episode reward: total was -72.970000. running mean: -34.666528\n",
      "ep 11: ep_len:510 episode reward: total was -26.300000. running mean: -34.582862\n",
      "ep 11: ep_len:655 episode reward: total was -23.950000. running mean: -34.476534\n",
      "ep 11: ep_len:650 episode reward: total was -30.550000. running mean: -34.437268\n",
      "ep 11: ep_len:180 episode reward: total was 3.000000. running mean: -34.062896\n",
      "ep 11: ep_len:1260 episode reward: total was -143.980000. running mean: -35.162067\n",
      "ep 11: ep_len:555 episode reward: total was -57.520000. running mean: -35.385646\n",
      "ep 11: ep_len:255 episode reward: total was 3.000000. running mean: -35.001790\n",
      "ep 11: ep_len:505 episode reward: total was -3.280000. running mean: -34.684572\n",
      "ep 11: ep_len:500 episode reward: total was -23.410000. running mean: -34.571826\n",
      "ep 11: ep_len:500 episode reward: total was -32.900000. running mean: -34.555108\n",
      "ep 11: ep_len:500 episode reward: total was -29.560000. running mean: -34.505157\n",
      "ep 11: ep_len:505 episode reward: total was -20.670000. running mean: -34.366805\n",
      "ep 11: ep_len:525 episode reward: total was -22.130000. running mean: -34.244437\n",
      "ep 11: ep_len:2360 episode reward: total was -224.180000. running mean: -36.143793\n",
      "ep 11: ep_len:505 episode reward: total was -34.470000. running mean: -36.127055\n",
      "ep 11: ep_len:725 episode reward: total was -42.520000. running mean: -36.190984\n",
      "ep 11: ep_len:1645 episode reward: total was -103.820000. running mean: -36.867274\n",
      "ep 11: ep_len:1000 episode reward: total was -121.290000. running mean: -37.711502\n",
      "ep 11: ep_len:895 episode reward: total was -31.480000. running mean: -37.649187\n",
      "ep 11: ep_len:735 episode reward: total was -39.500000. running mean: -37.667695\n",
      "ep 11: ep_len:505 episode reward: total was 22.000000. running mean: -37.071018\n",
      "ep 11: ep_len:1160 episode reward: total was -122.140000. running mean: -37.921708\n",
      "ep 11: ep_len:1000 episode reward: total was -25.080000. running mean: -37.793291\n",
      "ep 11: ep_len:1445 episode reward: total was -56.230000. running mean: -37.977658\n",
      "ep 11: ep_len:500 episode reward: total was -11.860000. running mean: -37.716481\n",
      "ep 11: ep_len:500 episode reward: total was -9.310000. running mean: -37.432416\n",
      "ep 11: ep_len:1030 episode reward: total was -74.350000. running mean: -37.801592\n",
      "ep 11: ep_len:1575 episode reward: total was -141.330000. running mean: -38.836876\n",
      "ep 11: ep_len:500 episode reward: total was -12.730000. running mean: -38.575807\n",
      "ep 11: ep_len:292 episode reward: total was 5.000000. running mean: -38.140049\n",
      "ep 11: ep_len:785 episode reward: total was -21.710000. running mean: -37.975749\n",
      "ep 11: ep_len:500 episode reward: total was -9.600000. running mean: -37.691991\n",
      "ep 11: ep_len:665 episode reward: total was -25.990000. running mean: -37.574971\n",
      "ep 11: ep_len:1265 episode reward: total was -117.710000. running mean: -38.376322\n",
      "ep 11: ep_len:293 episode reward: total was 9.500000. running mean: -37.897559\n",
      "ep 11: ep_len:500 episode reward: total was 4.150000. running mean: -37.477083\n",
      "ep 11: ep_len:975 episode reward: total was -54.660000. running mean: -37.648912\n",
      "ep 11: ep_len:505 episode reward: total was -31.850000. running mean: -37.590923\n",
      "ep 11: ep_len:160 episode reward: total was 4.500000. running mean: -37.170014\n",
      "ep 11: ep_len:1175 episode reward: total was -48.100000. running mean: -37.279314\n",
      "ep 11: ep_len:500 episode reward: total was -7.970000. running mean: -36.986220\n",
      "ep 11: ep_len:241 episode reward: total was 15.000000. running mean: -36.466358\n",
      "ep 11: ep_len:500 episode reward: total was -2.680000. running mean: -36.128495\n",
      "ep 11: ep_len:505 episode reward: total was -29.660000. running mean: -36.063810\n",
      "ep 11: ep_len:1400 episode reward: total was -229.550000. running mean: -37.998672\n",
      "ep 11: ep_len:505 episode reward: total was -35.920000. running mean: -37.977885\n",
      "ep 11: ep_len:845 episode reward: total was -8.770000. running mean: -37.685806\n",
      "ep 11: ep_len:880 episode reward: total was -34.340000. running mean: -37.652348\n",
      "ep 11: ep_len:476 episode reward: total was 23.500000. running mean: -37.040825\n",
      "ep 11: ep_len:500 episode reward: total was -11.960000. running mean: -36.790016\n",
      "ep 11: ep_len:1380 episode reward: total was -75.870000. running mean: -37.180816\n",
      "ep 11: ep_len:1360 episode reward: total was -129.640000. running mean: -38.105408\n",
      "ep 11: ep_len:505 episode reward: total was -4.320000. running mean: -37.767554\n",
      "ep 11: ep_len:895 episode reward: total was -92.190000. running mean: -38.311778\n",
      "ep 11: ep_len:1030 episode reward: total was -106.060000. running mean: -38.989261\n",
      "ep 11: ep_len:500 episode reward: total was -21.960000. running mean: -38.818968\n",
      "ep 11: ep_len:960 episode reward: total was -50.650000. running mean: -38.937278\n",
      "ep 11: ep_len:500 episode reward: total was -35.960000. running mean: -38.907506\n",
      "ep 11: ep_len:505 episode reward: total was -38.140000. running mean: -38.899830\n",
      "ep 11: ep_len:738 episode reward: total was -91.500000. running mean: -39.425832\n",
      "ep 11: ep_len:625 episode reward: total was -3.930000. running mean: -39.070874\n",
      "ep 11: ep_len:500 episode reward: total was -1.770000. running mean: -38.697865\n",
      "ep 11: ep_len:675 episode reward: total was -56.270000. running mean: -38.873586\n",
      "ep 11: ep_len:347 episode reward: total was 16.500000. running mean: -38.319851\n",
      "ep 11: ep_len:510 episode reward: total was -12.990000. running mean: -38.066552\n",
      "ep 11: ep_len:585 episode reward: total was -9.580000. running mean: -37.781687\n",
      "ep 11: ep_len:1175 episode reward: total was -46.980000. running mean: -37.873670\n",
      "ep 11: ep_len:635 episode reward: total was -5.070000. running mean: -37.545633\n",
      "ep 11: ep_len:515 episode reward: total was -37.400000. running mean: -37.544177\n",
      "ep 11: ep_len:605 episode reward: total was -27.110000. running mean: -37.439835\n",
      "ep 11: ep_len:950 episode reward: total was -47.260000. running mean: -37.538037\n",
      "ep 11: ep_len:785 episode reward: total was -34.320000. running mean: -37.505856\n",
      "ep 11: ep_len:500 episode reward: total was 4.710000. running mean: -37.083698\n",
      "ep 11: ep_len:565 episode reward: total was -30.720000. running mean: -37.020061\n",
      "ep 11: ep_len:525 episode reward: total was -46.470000. running mean: -37.114560\n",
      "ep 11: ep_len:650 episode reward: total was -21.360000. running mean: -36.957014\n",
      "ep 11: ep_len:1075 episode reward: total was -150.410000. running mean: -38.091544\n",
      "ep 11: ep_len:765 episode reward: total was -23.460000. running mean: -37.945229\n",
      "ep 11: ep_len:500 episode reward: total was -23.350000. running mean: -37.799277\n",
      "ep 11: ep_len:500 episode reward: total was -15.280000. running mean: -37.574084\n",
      "ep 11: ep_len:500 episode reward: total was -10.850000. running mean: -37.306843\n",
      "ep 11: ep_len:500 episode reward: total was -39.880000. running mean: -37.332575\n",
      "ep 11: ep_len:700 episode reward: total was -61.870000. running mean: -37.577949\n",
      "ep 11: ep_len:715 episode reward: total was -40.060000. running mean: -37.602769\n",
      "ep 11: ep_len:500 episode reward: total was -1.790000. running mean: -37.244642\n",
      "ep 11: ep_len:186 episode reward: total was 11.000000. running mean: -36.762195\n",
      "ep 11: ep_len:500 episode reward: total was -10.120000. running mean: -36.495773\n",
      "ep 11: ep_len:510 episode reward: total was -40.460000. running mean: -36.535415\n",
      "ep 11: ep_len:500 episode reward: total was -2.100000. running mean: -36.191061\n",
      "ep 11: ep_len:1235 episode reward: total was -88.480000. running mean: -36.713951\n",
      "ep 11: ep_len:560 episode reward: total was -49.430000. running mean: -36.841111\n",
      "ep 11: ep_len:500 episode reward: total was -38.990000. running mean: -36.862600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 11: ep_len:660 episode reward: total was -66.730000. running mean: -37.161274\n",
      "ep 11: ep_len:500 episode reward: total was -18.010000. running mean: -36.969761\n",
      "ep 11: ep_len:500 episode reward: total was -22.300000. running mean: -36.823064\n",
      "ep 11: ep_len:830 episode reward: total was 7.090000. running mean: -36.383933\n",
      "ep 11: ep_len:670 episode reward: total was -18.780000. running mean: -36.207894\n",
      "ep 11: ep_len:500 episode reward: total was -11.300000. running mean: -35.958815\n",
      "ep 11: ep_len:960 episode reward: total was -32.650000. running mean: -35.925727\n",
      "ep 11: ep_len:520 episode reward: total was -26.890000. running mean: -35.835369\n",
      "ep 11: ep_len:505 episode reward: total was -25.360000. running mean: -35.730616\n",
      "ep 11: ep_len:550 episode reward: total was -20.880000. running mean: -35.582110\n",
      "ep 11: ep_len:515 episode reward: total was -24.270000. running mean: -35.468988\n",
      "ep 11: ep_len:770 episode reward: total was -24.480000. running mean: -35.359099\n",
      "ep 11: ep_len:154 episode reward: total was 9.000000. running mean: -34.915508\n",
      "ep 11: ep_len:500 episode reward: total was -22.420000. running mean: -34.790553\n",
      "ep 11: ep_len:520 episode reward: total was -46.970000. running mean: -34.912347\n",
      "ep 11: ep_len:945 episode reward: total was -31.760000. running mean: -34.880824\n",
      "ep 11: ep_len:540 episode reward: total was -18.650000. running mean: -34.718515\n",
      "ep 11: ep_len:500 episode reward: total was -40.550000. running mean: -34.776830\n",
      "ep 11: ep_len:500 episode reward: total was 3.200000. running mean: -34.397062\n",
      "ep 11: ep_len:780 episode reward: total was -43.910000. running mean: -34.492191\n",
      "ep 11: ep_len:500 episode reward: total was -17.350000. running mean: -34.320769\n",
      "ep 11: ep_len:1045 episode reward: total was -97.950000. running mean: -34.957062\n",
      "ep 11: ep_len:735 episode reward: total was -47.060000. running mean: -35.078091\n",
      "ep 11: ep_len:990 episode reward: total was -55.230000. running mean: -35.279610\n",
      "ep 11: ep_len:635 episode reward: total was -37.130000. running mean: -35.298114\n",
      "ep 11: ep_len:500 episode reward: total was -9.630000. running mean: -35.041433\n",
      "ep 11: ep_len:447 episode reward: total was 2.710000. running mean: -34.663919\n",
      "ep 11: ep_len:505 episode reward: total was -10.080000. running mean: -34.418079\n",
      "ep 11: ep_len:910 episode reward: total was -21.560000. running mean: -34.289499\n",
      "ep 11: ep_len:515 episode reward: total was -28.310000. running mean: -34.229704\n",
      "ep 11: ep_len:830 episode reward: total was -145.330000. running mean: -35.340707\n",
      "ep 11: ep_len:585 episode reward: total was -53.390000. running mean: -35.521199\n",
      "ep 11: ep_len:505 episode reward: total was -32.240000. running mean: -35.488387\n",
      "ep 11: ep_len:1150 episode reward: total was -155.310000. running mean: -36.686604\n",
      "ep 11: ep_len:615 episode reward: total was -21.040000. running mean: -36.530138\n",
      "ep 11: ep_len:560 episode reward: total was -23.660000. running mean: -36.401436\n",
      "ep 11: ep_len:775 episode reward: total was -56.070000. running mean: -36.598122\n",
      "ep 11: ep_len:635 episode reward: total was -30.580000. running mean: -36.537941\n",
      "ep 11: ep_len:940 episode reward: total was -79.130000. running mean: -36.963861\n",
      "ep 11: ep_len:785 episode reward: total was -23.260000. running mean: -36.826823\n",
      "ep 11: ep_len:730 episode reward: total was -59.680000. running mean: -37.055354\n",
      "ep 11: ep_len:1040 episode reward: total was -65.020000. running mean: -37.335001\n",
      "ep 11: ep_len:500 episode reward: total was -34.060000. running mean: -37.302251\n",
      "ep 11: ep_len:500 episode reward: total was 5.280000. running mean: -36.876428\n",
      "ep 11: ep_len:825 episode reward: total was -64.540000. running mean: -37.153064\n",
      "ep 11: ep_len:1540 episode reward: total was -154.150000. running mean: -38.323033\n",
      "ep 11: ep_len:500 episode reward: total was -7.490000. running mean: -38.014703\n",
      "ep 11: ep_len:500 episode reward: total was -46.790000. running mean: -38.102456\n",
      "ep 11: ep_len:730 episode reward: total was -37.940000. running mean: -38.100831\n",
      "ep 11: ep_len:500 episode reward: total was -24.410000. running mean: -37.963923\n",
      "ep 11: ep_len:505 episode reward: total was -28.850000. running mean: -37.872784\n",
      "ep 11: ep_len:515 episode reward: total was -20.260000. running mean: -37.696656\n",
      "ep 11: ep_len:630 episode reward: total was -55.350000. running mean: -37.873190\n",
      "ep 11: ep_len:1515 episode reward: total was -149.010000. running mean: -38.984558\n",
      "ep 11: ep_len:585 episode reward: total was -51.890000. running mean: -39.113612\n",
      "ep 11: ep_len:995 episode reward: total was -29.990000. running mean: -39.022376\n",
      "ep 11: ep_len:1465 episode reward: total was -139.010000. running mean: -40.022252\n",
      "ep 11: ep_len:615 episode reward: total was -47.300000. running mean: -40.095030\n",
      "ep 11: ep_len:500 episode reward: total was -10.950000. running mean: -39.803579\n",
      "ep 11: ep_len:525 episode reward: total was -33.310000. running mean: -39.738644\n",
      "ep 11: ep_len:1775 episode reward: total was -182.880000. running mean: -41.170057\n",
      "ep 11: ep_len:500 episode reward: total was -26.730000. running mean: -41.025657\n",
      "ep 11: ep_len:193 episode reward: total was 3.000000. running mean: -40.585400\n",
      "ep 11: ep_len:1490 episode reward: total was -166.750000. running mean: -41.847046\n",
      "ep 11: ep_len:1015 episode reward: total was -60.640000. running mean: -42.034976\n",
      "ep 11: ep_len:1045 episode reward: total was -29.350000. running mean: -41.908126\n",
      "ep 11: ep_len:640 episode reward: total was -17.510000. running mean: -41.664145\n",
      "ep 11: ep_len:1000 episode reward: total was -45.500000. running mean: -41.702503\n",
      "ep 11: ep_len:500 episode reward: total was 5.620000. running mean: -41.229278\n",
      "ep 11: ep_len:361 episode reward: total was -23.870000. running mean: -41.055685\n",
      "ep 11: ep_len:555 episode reward: total was -15.490000. running mean: -40.800028\n",
      "ep 11: ep_len:685 episode reward: total was -37.030000. running mean: -40.762328\n",
      "ep 11: ep_len:685 episode reward: total was -56.880000. running mean: -40.923505\n",
      "ep 11: ep_len:500 episode reward: total was 1.240000. running mean: -40.501870\n",
      "ep 11: ep_len:500 episode reward: total was -17.740000. running mean: -40.274251\n",
      "ep 11: ep_len:500 episode reward: total was -34.670000. running mean: -40.218209\n",
      "ep 11: ep_len:585 episode reward: total was -37.370000. running mean: -40.189726\n",
      "ep 11: ep_len:715 episode reward: total was -23.870000. running mean: -40.026529\n",
      "ep 11: ep_len:635 episode reward: total was -55.340000. running mean: -40.179664\n",
      "ep 11: ep_len:720 episode reward: total was -78.890000. running mean: -40.566767\n",
      "ep 11: ep_len:241 episode reward: total was 12.000000. running mean: -40.041100\n",
      "ep 11: ep_len:605 episode reward: total was -57.540000. running mean: -40.216089\n",
      "ep 11: ep_len:1000 episode reward: total was -58.450000. running mean: -40.398428\n",
      "ep 11: ep_len:500 episode reward: total was -2.220000. running mean: -40.016643\n",
      "ep 11: ep_len:860 episode reward: total was -40.290000. running mean: -40.019377\n",
      "ep 11: ep_len:67 episode reward: total was -3.500000. running mean: -39.654183\n",
      "ep 11: ep_len:505 episode reward: total was 1.590000. running mean: -39.241741\n",
      "ep 11: ep_len:1040 episode reward: total was -49.410000. running mean: -39.343424\n",
      "ep 11: ep_len:770 episode reward: total was -27.340000. running mean: -39.223390\n",
      "ep 11: ep_len:500 episode reward: total was -0.290000. running mean: -38.834056\n",
      "ep 11: ep_len:500 episode reward: total was -2.770000. running mean: -38.473415\n",
      "ep 11: ep_len:505 episode reward: total was -5.850000. running mean: -38.147181\n",
      "ep 11: ep_len:256 episode reward: total was 10.500000. running mean: -37.660709\n",
      "ep 11: ep_len:740 episode reward: total was -109.470000. running mean: -38.378802\n",
      "ep 11: ep_len:327 episode reward: total was 10.000000. running mean: -37.895014\n",
      "ep 11: ep_len:675 episode reward: total was -21.130000. running mean: -37.727364\n",
      "ep 11: ep_len:500 episode reward: total was -27.930000. running mean: -37.629390\n",
      "ep 11: ep_len:510 episode reward: total was -26.240000. running mean: -37.515497\n",
      "ep 11: ep_len:505 episode reward: total was -16.220000. running mean: -37.302542\n",
      "ep 11: ep_len:500 episode reward: total was 4.730000. running mean: -36.882216\n",
      "ep 11: ep_len:750 episode reward: total was -35.920000. running mean: -36.872594\n",
      "ep 11: ep_len:505 episode reward: total was -23.920000. running mean: -36.743068\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 11: ep_len:1434 episode reward: total was -250.700000. running mean: -38.882637\n",
      "ep 11: ep_len:500 episode reward: total was 9.200000. running mean: -38.401811\n",
      "ep 11: ep_len:500 episode reward: total was -14.870000. running mean: -38.166493\n",
      "ep 11: ep_len:825 episode reward: total was -60.990000. running mean: -38.394728\n",
      "ep 11: ep_len:1010 episode reward: total was -30.360000. running mean: -38.314381\n",
      "ep 11: ep_len:520 episode reward: total was -98.970000. running mean: -38.920937\n",
      "ep 11: ep_len:505 episode reward: total was 6.250000. running mean: -38.469228\n",
      "ep 11: ep_len:500 episode reward: total was -15.780000. running mean: -38.242335\n",
      "ep 11: ep_len:975 episode reward: total was -52.830000. running mean: -38.388212\n",
      "ep 11: ep_len:505 episode reward: total was -21.460000. running mean: -38.218930\n",
      "ep 11: ep_len:500 episode reward: total was -10.170000. running mean: -37.938440\n",
      "ep 11: ep_len:1625 episode reward: total was -305.380000. running mean: -40.612856\n",
      "ep 11: ep_len:500 episode reward: total was 5.750000. running mean: -40.149228\n",
      "ep 11: ep_len:1745 episode reward: total was -254.600000. running mean: -42.293735\n",
      "ep 11: ep_len:850 episode reward: total was -61.310000. running mean: -42.483898\n",
      "ep 11: ep_len:785 episode reward: total was -36.860000. running mean: -42.427659\n",
      "ep 11: ep_len:500 episode reward: total was -59.670000. running mean: -42.600082\n",
      "ep 11: ep_len:1075 episode reward: total was -163.950000. running mean: -43.813581\n",
      "ep 11: ep_len:500 episode reward: total was -16.060000. running mean: -43.536046\n",
      "ep 11: ep_len:500 episode reward: total was -14.340000. running mean: -43.244085\n",
      "ep 11: ep_len:515 episode reward: total was -33.360000. running mean: -43.145244\n",
      "ep 11: ep_len:500 episode reward: total was -8.380000. running mean: -42.797592\n",
      "ep 11: ep_len:500 episode reward: total was -21.480000. running mean: -42.584416\n",
      "ep 11: ep_len:500 episode reward: total was 4.730000. running mean: -42.111272\n",
      "ep 11: ep_len:660 episode reward: total was -28.510000. running mean: -41.975259\n",
      "ep 11: ep_len:560 episode reward: total was -21.640000. running mean: -41.771907\n",
      "ep 11: ep_len:500 episode reward: total was -6.840000. running mean: -41.422587\n",
      "ep 11: ep_len:805 episode reward: total was -60.050000. running mean: -41.608862\n",
      "ep 11: ep_len:500 episode reward: total was 32.000000. running mean: -40.872773\n",
      "ep 11: ep_len:770 episode reward: total was -43.930000. running mean: -40.903345\n",
      "ep 11: ep_len:930 episode reward: total was -3.900000. running mean: -40.533312\n",
      "ep 11: ep_len:320 episode reward: total was -15.900000. running mean: -40.286979\n",
      "ep 11: ep_len:675 episode reward: total was -58.260000. running mean: -40.466709\n",
      "ep 11: ep_len:650 episode reward: total was -42.720000. running mean: -40.489242\n",
      "ep 11: ep_len:520 episode reward: total was -24.980000. running mean: -40.334149\n",
      "ep 11: ep_len:895 episode reward: total was -20.530000. running mean: -40.136108\n",
      "ep 11: ep_len:500 episode reward: total was -5.280000. running mean: -39.787547\n",
      "ep 11: ep_len:500 episode reward: total was 15.500000. running mean: -39.234671\n",
      "ep 11: ep_len:500 episode reward: total was -34.640000. running mean: -39.188725\n",
      "ep 11: ep_len:715 episode reward: total was -29.930000. running mean: -39.096137\n",
      "ep 11: ep_len:500 episode reward: total was -17.410000. running mean: -38.879276\n",
      "ep 11: ep_len:530 episode reward: total was -32.890000. running mean: -38.819383\n",
      "ep 11: ep_len:810 episode reward: total was -34.270000. running mean: -38.773889\n",
      "ep 11: ep_len:560 episode reward: total was -96.470000. running mean: -39.350851\n",
      "ep 11: ep_len:500 episode reward: total was -15.470000. running mean: -39.112042\n",
      "ep 11: ep_len:163 episode reward: total was 7.500000. running mean: -38.645922\n",
      "ep 11: ep_len:500 episode reward: total was -13.890000. running mean: -38.398362\n",
      "ep 11: ep_len:550 episode reward: total was -20.860000. running mean: -38.222979\n",
      "ep 11: ep_len:605 episode reward: total was -31.160000. running mean: -38.152349\n",
      "ep 11: ep_len:875 episode reward: total was -31.010000. running mean: -38.080925\n",
      "ep 11: ep_len:505 episode reward: total was -6.440000. running mean: -37.764516\n",
      "ep 11: ep_len:805 episode reward: total was -39.820000. running mean: -37.785071\n",
      "ep 11: ep_len:600 episode reward: total was -84.180000. running mean: -38.249020\n",
      "ep 11: ep_len:406 episode reward: total was -19.000000. running mean: -38.056530\n",
      "ep 11: ep_len:915 episode reward: total was -54.250000. running mean: -38.218465\n",
      "ep 11: ep_len:500 episode reward: total was -39.630000. running mean: -38.232580\n",
      "ep 11: ep_len:500 episode reward: total was -14.100000. running mean: -37.991254\n",
      "ep 11: ep_len:740 episode reward: total was -38.920000. running mean: -38.000542\n",
      "ep 11: ep_len:500 episode reward: total was -12.690000. running mean: -37.747436\n",
      "ep 11: ep_len:570 episode reward: total was -38.270000. running mean: -37.752662\n",
      "ep 11: ep_len:1060 episode reward: total was -59.470000. running mean: -37.969835\n",
      "ep 11: ep_len:489 episode reward: total was -42.340000. running mean: -38.013537\n",
      "ep 11: ep_len:515 episode reward: total was -23.880000. running mean: -37.872202\n",
      "ep 11: ep_len:870 episode reward: total was -53.870000. running mean: -38.032180\n",
      "ep 11: ep_len:1360 episode reward: total was -158.070000. running mean: -39.232558\n",
      "ep 11: ep_len:305 episode reward: total was 12.500000. running mean: -38.715232\n",
      "ep 11: ep_len:790 episode reward: total was -44.930000. running mean: -38.777380\n",
      "ep 11: ep_len:500 episode reward: total was -3.260000. running mean: -38.422206\n",
      "ep 11: ep_len:505 episode reward: total was -39.560000. running mean: -38.433584\n",
      "ep 11: ep_len:433 episode reward: total was -18.800000. running mean: -38.237248\n",
      "ep 11: ep_len:500 episode reward: total was -8.280000. running mean: -37.937676\n",
      "ep 11: ep_len:510 episode reward: total was -41.050000. running mean: -37.968799\n",
      "ep 11: ep_len:640 episode reward: total was -26.040000. running mean: -37.849511\n",
      "ep 11: ep_len:500 episode reward: total was -2.160000. running mean: -37.492616\n",
      "ep 11: ep_len:500 episode reward: total was -18.480000. running mean: -37.302490\n",
      "ep 11: ep_len:900 episode reward: total was -47.340000. running mean: -37.402865\n",
      "ep 11: ep_len:900 episode reward: total was -45.360000. running mean: -37.482436\n",
      "ep 11: ep_len:500 episode reward: total was -8.090000. running mean: -37.188512\n",
      "ep 11: ep_len:750 episode reward: total was -31.360000. running mean: -37.130227\n",
      "ep 11: ep_len:515 episode reward: total was -35.120000. running mean: -37.110125\n",
      "ep 11: ep_len:505 episode reward: total was -1.780000. running mean: -36.756823\n",
      "ep 11: ep_len:500 episode reward: total was -11.790000. running mean: -36.507155\n",
      "ep 11: ep_len:585 episode reward: total was -1.640000. running mean: -36.158483\n",
      "ep 11: ep_len:930 episode reward: total was -56.770000. running mean: -36.364599\n",
      "ep 11: ep_len:500 episode reward: total was -20.250000. running mean: -36.203453\n",
      "ep 11: ep_len:575 episode reward: total was -36.910000. running mean: -36.210518\n",
      "ep 11: ep_len:860 episode reward: total was -50.360000. running mean: -36.352013\n",
      "ep 11: ep_len:850 episode reward: total was -11.950000. running mean: -36.107993\n",
      "ep 11: ep_len:580 episode reward: total was -80.700000. running mean: -36.553913\n",
      "ep 11: ep_len:500 episode reward: total was -19.430000. running mean: -36.382674\n",
      "ep 11: ep_len:520 episode reward: total was -26.250000. running mean: -36.281347\n",
      "ep 11: ep_len:765 episode reward: total was -93.460000. running mean: -36.853134\n",
      "ep 11: ep_len:505 episode reward: total was -17.210000. running mean: -36.656702\n",
      "ep 11: ep_len:500 episode reward: total was -8.250000. running mean: -36.372635\n",
      "ep 11: ep_len:560 episode reward: total was -23.980000. running mean: -36.248709\n",
      "ep 11: ep_len:815 episode reward: total was -26.510000. running mean: -36.151322\n",
      "ep 11: ep_len:500 episode reward: total was -28.890000. running mean: -36.078709\n",
      "ep 11: ep_len:615 episode reward: total was -19.230000. running mean: -35.910221\n",
      "ep 11: ep_len:500 episode reward: total was -14.350000. running mean: -35.694619\n",
      "ep 11: ep_len:1045 episode reward: total was -28.460000. running mean: -35.622273\n",
      "ep 11: ep_len:635 episode reward: total was -35.110000. running mean: -35.617150\n",
      "ep 11: ep_len:950 episode reward: total was -12.340000. running mean: -35.384379\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 11: ep_len:160 episode reward: total was 1.500000. running mean: -35.015535\n",
      "ep 11: ep_len:500 episode reward: total was -7.300000. running mean: -34.738380\n",
      "ep 11: ep_len:550 episode reward: total was -55.510000. running mean: -34.946096\n",
      "ep 11: ep_len:1475 episode reward: total was -148.440000. running mean: -36.081035\n",
      "ep 11: ep_len:580 episode reward: total was -41.310000. running mean: -36.133325\n",
      "ep 11: ep_len:735 episode reward: total was -44.000000. running mean: -36.211991\n",
      "ep 11: ep_len:740 episode reward: total was -58.130000. running mean: -36.431171\n",
      "ep 11: ep_len:505 episode reward: total was -12.330000. running mean: -36.190160\n",
      "ep 11: ep_len:860 episode reward: total was -49.810000. running mean: -36.326358\n",
      "ep 11: ep_len:500 episode reward: total was 13.730000. running mean: -35.825795\n",
      "ep 11: ep_len:755 episode reward: total was -26.820000. running mean: -35.735737\n",
      "ep 11: ep_len:625 episode reward: total was -39.690000. running mean: -35.775279\n",
      "ep 11: ep_len:505 episode reward: total was -51.040000. running mean: -35.927926\n",
      "ep 11: ep_len:875 episode reward: total was -71.150000. running mean: -36.280147\n",
      "ep 11: ep_len:206 episode reward: total was 16.000000. running mean: -35.757346\n",
      "ep 11: ep_len:550 episode reward: total was -20.370000. running mean: -35.603472\n",
      "ep 11: ep_len:730 episode reward: total was -26.870000. running mean: -35.516137\n",
      "ep 11: ep_len:241 episode reward: total was 13.500000. running mean: -35.025976\n",
      "ep 11: ep_len:500 episode reward: total was -12.880000. running mean: -34.804516\n",
      "ep 11: ep_len:500 episode reward: total was -43.060000. running mean: -34.887071\n",
      "ep 11: ep_len:1650 episode reward: total was -251.620000. running mean: -37.054400\n",
      "ep 11: ep_len:945 episode reward: total was -24.290000. running mean: -36.926756\n",
      "ep 11: ep_len:17225 episode reward: total was -1422.290000. running mean: -50.780389\n",
      "ep 11: ep_len:500 episode reward: total was -17.820000. running mean: -50.450785\n",
      "ep 11: ep_len:755 episode reward: total was -41.970000. running mean: -50.365977\n",
      "ep 11: ep_len:735 episode reward: total was -17.760000. running mean: -50.039917\n",
      "ep 11: ep_len:505 episode reward: total was -14.120000. running mean: -49.680718\n",
      "ep 11: ep_len:500 episode reward: total was 2.220000. running mean: -49.161711\n",
      "ep 11: ep_len:97 episode reward: total was 4.000000. running mean: -48.630094\n",
      "ep 11: ep_len:500 episode reward: total was 6.600000. running mean: -48.077793\n",
      "ep 11: ep_len:705 episode reward: total was -63.490000. running mean: -48.231915\n",
      "ep 11: ep_len:1310 episode reward: total was -200.120000. running mean: -49.750796\n",
      "ep 11: ep_len:500 episode reward: total was 21.000000. running mean: -49.043288\n",
      "ep 11: ep_len:259 episode reward: total was 12.500000. running mean: -48.427855\n",
      "ep 11: ep_len:715 episode reward: total was -28.920000. running mean: -48.232777\n",
      "ep 11: ep_len:505 episode reward: total was -11.260000. running mean: -47.863049\n",
      "ep 11: ep_len:310 episode reward: total was 13.000000. running mean: -47.254418\n",
      "ep 11: ep_len:600 episode reward: total was -53.360000. running mean: -47.315474\n",
      "ep 11: ep_len:319 episode reward: total was 15.500000. running mean: -46.687319\n",
      "ep 11: ep_len:500 episode reward: total was -4.700000. running mean: -46.267446\n",
      "ep 11: ep_len:500 episode reward: total was -9.390000. running mean: -45.898672\n",
      "ep 11: ep_len:675 episode reward: total was -81.180000. running mean: -46.251485\n",
      "ep 11: ep_len:535 episode reward: total was -9.930000. running mean: -45.888270\n",
      "ep 11: ep_len:500 episode reward: total was -33.050000. running mean: -45.759887\n",
      "ep 11: ep_len:625 episode reward: total was -8.330000. running mean: -45.385589\n",
      "ep 11: ep_len:2245 episode reward: total was -320.860000. running mean: -48.140333\n",
      "ep 11: ep_len:545 episode reward: total was -40.860000. running mean: -48.067529\n",
      "ep 11: ep_len:500 episode reward: total was -29.900000. running mean: -47.885854\n",
      "ep 11: ep_len:486 episode reward: total was -7.790000. running mean: -47.484896\n",
      "ep 11: ep_len:1120 episode reward: total was -127.090000. running mean: -48.280947\n",
      "ep 11: ep_len:500 episode reward: total was -6.320000. running mean: -47.861337\n",
      "ep 11: ep_len:500 episode reward: total was -26.850000. running mean: -47.651224\n",
      "ep 11: ep_len:815 episode reward: total was -94.860000. running mean: -48.123311\n",
      "ep 11: ep_len:810 episode reward: total was -14.770000. running mean: -47.789778\n",
      "ep 11: ep_len:500 episode reward: total was -7.280000. running mean: -47.384681\n",
      "ep 11: ep_len:500 episode reward: total was -12.740000. running mean: -47.038234\n",
      "ep 11: ep_len:880 episode reward: total was -44.970000. running mean: -47.017551\n",
      "ep 11: ep_len:675 episode reward: total was -32.030000. running mean: -46.867676\n",
      "ep 11: ep_len:500 episode reward: total was -26.530000. running mean: -46.664299\n",
      "ep 11: ep_len:500 episode reward: total was -23.960000. running mean: -46.437256\n",
      "ep 11: ep_len:39 episode reward: total was 3.500000. running mean: -45.937884\n",
      "ep 11: ep_len:915 episode reward: total was -44.300000. running mean: -45.921505\n",
      "ep 11: ep_len:540 episode reward: total was -27.740000. running mean: -45.739690\n",
      "ep 11: ep_len:595 episode reward: total was -53.400000. running mean: -45.816293\n",
      "ep 11: ep_len:500 episode reward: total was -35.650000. running mean: -45.714630\n",
      "ep 11: ep_len:177 episode reward: total was 7.000000. running mean: -45.187484\n",
      "ep 11: ep_len:500 episode reward: total was -21.200000. running mean: -44.947609\n",
      "ep 11: ep_len:500 episode reward: total was -16.430000. running mean: -44.662433\n",
      "ep 11: ep_len:645 episode reward: total was -82.590000. running mean: -45.041708\n",
      "ep 11: ep_len:805 episode reward: total was -75.200000. running mean: -45.343291\n",
      "ep 11: ep_len:545 episode reward: total was -59.040000. running mean: -45.480258\n",
      "ep 11: ep_len:170 episode reward: total was 9.500000. running mean: -44.930456\n",
      "ep 11: ep_len:525 episode reward: total was -34.320000. running mean: -44.824351\n",
      "ep 11: ep_len:500 episode reward: total was -47.700000. running mean: -44.853108\n",
      "ep 11: ep_len:195 episode reward: total was -4.500000. running mean: -44.449577\n",
      "ep 11: ep_len:1560 episode reward: total was -191.340000. running mean: -45.918481\n",
      "ep 11: ep_len:970 episode reward: total was -103.000000. running mean: -46.489296\n",
      "ep 11: ep_len:477 episode reward: total was -6.240000. running mean: -46.086803\n",
      "ep 11: ep_len:740 episode reward: total was -45.520000. running mean: -46.081135\n",
      "ep 11: ep_len:735 episode reward: total was -9.310000. running mean: -45.713424\n",
      "ep 11: ep_len:530 episode reward: total was -22.220000. running mean: -45.478489\n",
      "ep 11: ep_len:212 episode reward: total was 9.000000. running mean: -44.933705\n",
      "ep 11: ep_len:505 episode reward: total was -23.910000. running mean: -44.723468\n",
      "ep 11: ep_len:745 episode reward: total was -35.410000. running mean: -44.630333\n",
      "ep 11: ep_len:835 episode reward: total was -81.810000. running mean: -45.002130\n",
      "ep 11: ep_len:550 episode reward: total was -23.160000. running mean: -44.783708\n",
      "ep 11: ep_len:620 episode reward: total was -16.060000. running mean: -44.496471\n",
      "ep 11: ep_len:500 episode reward: total was -36.070000. running mean: -44.412206\n",
      "ep 11: ep_len:765 episode reward: total was -35.890000. running mean: -44.326984\n",
      "ep 11: ep_len:142 episode reward: total was 9.500000. running mean: -43.788715\n",
      "ep 11: ep_len:246 episode reward: total was 4.000000. running mean: -43.310827\n",
      "ep 11: ep_len:500 episode reward: total was -4.270000. running mean: -42.920419\n",
      "ep 11: ep_len:755 episode reward: total was -57.090000. running mean: -43.062115\n",
      "ep 11: ep_len:500 episode reward: total was 1.670000. running mean: -42.614794\n",
      "ep 11: ep_len:720 episode reward: total was -45.040000. running mean: -42.639046\n",
      "ep 11: ep_len:500 episode reward: total was -11.470000. running mean: -42.327355\n",
      "ep 11: ep_len:500 episode reward: total was -5.790000. running mean: -41.961982\n",
      "ep 11: ep_len:505 episode reward: total was 1.710000. running mean: -41.525262\n",
      "ep 11: ep_len:500 episode reward: total was -12.840000. running mean: -41.238409\n",
      "ep 11: ep_len:500 episode reward: total was -3.780000. running mean: -40.863825\n",
      "ep 11: ep_len:585 episode reward: total was -37.360000. running mean: -40.828787\n",
      "ep 11: ep_len:460 episode reward: total was -7.780000. running mean: -40.498299\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 11: ep_len:646 episode reward: total was -94.690000. running mean: -41.040216\n",
      "ep 11: ep_len:500 episode reward: total was -35.900000. running mean: -40.988814\n",
      "ep 11: ep_len:500 episode reward: total was -6.260000. running mean: -40.641526\n",
      "ep 11: ep_len:500 episode reward: total was -25.390000. running mean: -40.489011\n",
      "ep 11: ep_len:670 episode reward: total was -12.010000. running mean: -40.204221\n",
      "ep 11: ep_len:2635 episode reward: total was -369.570000. running mean: -43.497878\n",
      "ep 11: ep_len:955 episode reward: total was -33.100000. running mean: -43.393900\n",
      "ep 11: ep_len:5450 episode reward: total was -903.090000. running mean: -51.990861\n",
      "ep 11: ep_len:900 episode reward: total was -52.590000. running mean: -51.996852\n",
      "ep 11: ep_len:500 episode reward: total was -53.560000. running mean: -52.012483\n",
      "ep 11: ep_len:1235 episode reward: total was -128.850000. running mean: -52.780859\n",
      "ep 11: ep_len:885 episode reward: total was -59.820000. running mean: -52.851250\n",
      "ep 11: ep_len:500 episode reward: total was 24.500000. running mean: -52.077737\n",
      "ep 11: ep_len:500 episode reward: total was -25.640000. running mean: -51.813360\n",
      "ep 11: ep_len:206 episode reward: total was 7.000000. running mean: -51.225227\n",
      "epsilon:0.215510 episode_count: 9461. steps_count: 6689262.000000\n",
      "ep 12: ep_len:1645 episode reward: total was -288.650000. running mean: -53.599474\n",
      "ep 12: ep_len:785 episode reward: total was -64.650000. running mean: -53.709979\n",
      "ep 12: ep_len:725 episode reward: total was -67.390000. running mean: -53.846780\n",
      "ep 12: ep_len:1075 episode reward: total was -90.820000. running mean: -54.216512\n",
      "ep 12: ep_len:510 episode reward: total was -17.290000. running mean: -53.847247\n",
      "ep 12: ep_len:1180 episode reward: total was -186.460000. running mean: -55.173374\n",
      "ep 12: ep_len:765 episode reward: total was -28.820000. running mean: -54.909841\n",
      "ep 12: ep_len:500 episode reward: total was -51.140000. running mean: -54.872142\n",
      "ep 12: ep_len:845 episode reward: total was -64.500000. running mean: -54.968421\n",
      "ep 12: ep_len:500 episode reward: total was -7.920000. running mean: -54.497937\n",
      "ep 12: ep_len:555 episode reward: total was -35.790000. running mean: -54.310857\n",
      "ep 12: ep_len:505 episode reward: total was -0.250000. running mean: -53.770249\n",
      "ep 12: ep_len:790 episode reward: total was -7.370000. running mean: -53.306246\n",
      "ep 12: ep_len:1335 episode reward: total was -92.420000. running mean: -53.697384\n",
      "ep 12: ep_len:1150 episode reward: total was -45.420000. running mean: -53.614610\n",
      "ep 12: ep_len:500 episode reward: total was 3.230000. running mean: -53.046164\n",
      "ep 12: ep_len:660 episode reward: total was -19.940000. running mean: -52.715102\n",
      "ep 12: ep_len:685 episode reward: total was -87.560000. running mean: -53.063551\n",
      "ep 12: ep_len:615 episode reward: total was -36.280000. running mean: -52.895716\n",
      "ep 12: ep_len:500 episode reward: total was -25.810000. running mean: -52.624858\n",
      "ep 12: ep_len:1605 episode reward: total was -105.300000. running mean: -53.151610\n",
      "ep 12: ep_len:191 episode reward: total was 11.500000. running mean: -52.505094\n",
      "ep 12: ep_len:1100 episode reward: total was -81.400000. running mean: -52.794043\n",
      "ep 12: ep_len:500 episode reward: total was -17.370000. running mean: -52.439802\n",
      "ep 12: ep_len:500 episode reward: total was -22.980000. running mean: -52.145204\n",
      "ep 12: ep_len:510 episode reward: total was -39.430000. running mean: -52.018052\n",
      "ep 12: ep_len:500 episode reward: total was 2.250000. running mean: -51.475372\n",
      "ep 12: ep_len:14725 episode reward: total was -1826.980000. running mean: -69.230418\n",
      "ep 12: ep_len:655 episode reward: total was -33.080000. running mean: -68.868914\n",
      "ep 12: ep_len:500 episode reward: total was -23.320000. running mean: -68.413425\n",
      "ep 12: ep_len:500 episode reward: total was -23.480000. running mean: -67.964090\n",
      "ep 12: ep_len:500 episode reward: total was -23.810000. running mean: -67.522550\n",
      "ep 12: ep_len:505 episode reward: total was -21.870000. running mean: -67.066024\n",
      "ep 12: ep_len:565 episode reward: total was -12.300000. running mean: -66.518364\n",
      "ep 12: ep_len:600 episode reward: total was -19.290000. running mean: -66.046080\n",
      "ep 12: ep_len:775 episode reward: total was -39.390000. running mean: -65.779519\n",
      "ep 12: ep_len:595 episode reward: total was -25.670000. running mean: -65.378424\n",
      "ep 12: ep_len:500 episode reward: total was -25.890000. running mean: -64.983540\n",
      "ep 12: ep_len:680 episode reward: total was -27.290000. running mean: -64.606605\n",
      "ep 12: ep_len:500 episode reward: total was -56.100000. running mean: -64.521539\n",
      "ep 12: ep_len:204 episode reward: total was 8.000000. running mean: -63.796323\n",
      "ep 12: ep_len:515 episode reward: total was -31.310000. running mean: -63.471460\n",
      "ep 12: ep_len:970 episode reward: total was -35.150000. running mean: -63.188245\n",
      "ep 12: ep_len:505 episode reward: total was -13.810000. running mean: -62.694463\n",
      "ep 12: ep_len:900 episode reward: total was -84.640000. running mean: -62.913918\n",
      "ep 12: ep_len:247 episode reward: total was 13.000000. running mean: -62.154779\n",
      "ep 12: ep_len:500 episode reward: total was -0.710000. running mean: -61.540331\n",
      "ep 12: ep_len:725 episode reward: total was -19.290000. running mean: -61.117828\n",
      "ep 12: ep_len:1130 episode reward: total was -55.920000. running mean: -61.065850\n",
      "ep 12: ep_len:740 episode reward: total was -20.560000. running mean: -60.660791\n",
      "ep 12: ep_len:293 episode reward: total was 14.000000. running mean: -59.914183\n",
      "ep 12: ep_len:915 episode reward: total was -36.070000. running mean: -59.675741\n",
      "ep 12: ep_len:500 episode reward: total was -12.320000. running mean: -59.202184\n",
      "ep 12: ep_len:505 episode reward: total was -15.890000. running mean: -58.769062\n",
      "ep 12: ep_len:650 episode reward: total was -30.060000. running mean: -58.481972\n",
      "ep 12: ep_len:131 episode reward: total was 7.000000. running mean: -57.827152\n",
      "ep 12: ep_len:820 episode reward: total was -41.900000. running mean: -57.667880\n",
      "ep 12: ep_len:700 episode reward: total was -38.130000. running mean: -57.472501\n",
      "ep 12: ep_len:680 episode reward: total was -62.980000. running mean: -57.527576\n",
      "ep 12: ep_len:267 episode reward: total was 7.000000. running mean: -56.882301\n",
      "ep 12: ep_len:505 episode reward: total was -25.720000. running mean: -56.570678\n",
      "ep 12: ep_len:880 episode reward: total was -42.830000. running mean: -56.433271\n",
      "ep 12: ep_len:570 episode reward: total was -44.850000. running mean: -56.317438\n",
      "ep 12: ep_len:151 episode reward: total was -4.000000. running mean: -55.794264\n",
      "ep 12: ep_len:123 episode reward: total was -2.500000. running mean: -55.261321\n",
      "ep 12: ep_len:505 episode reward: total was -25.390000. running mean: -54.962608\n",
      "ep 12: ep_len:675 episode reward: total was -24.830000. running mean: -54.661282\n",
      "ep 12: ep_len:263 episode reward: total was 4.500000. running mean: -54.069669\n",
      "ep 12: ep_len:615 episode reward: total was -43.230000. running mean: -53.961272\n",
      "ep 12: ep_len:950 episode reward: total was -85.120000. running mean: -54.272860\n",
      "ep 12: ep_len:740 episode reward: total was -21.060000. running mean: -53.940731\n",
      "ep 12: ep_len:750 episode reward: total was -36.990000. running mean: -53.771224\n",
      "ep 12: ep_len:940 episode reward: total was -69.030000. running mean: -53.923812\n",
      "ep 12: ep_len:510 episode reward: total was -7.340000. running mean: -53.457973\n",
      "ep 12: ep_len:389 episode reward: total was -5.120000. running mean: -52.974594\n",
      "ep 12: ep_len:500 episode reward: total was -19.880000. running mean: -52.643648\n",
      "ep 12: ep_len:500 episode reward: total was -1.840000. running mean: -52.135611\n",
      "ep 12: ep_len:500 episode reward: total was -0.260000. running mean: -51.616855\n",
      "ep 12: ep_len:1970 episode reward: total was -254.670000. running mean: -53.647387\n",
      "ep 12: ep_len:770 episode reward: total was -28.990000. running mean: -53.400813\n",
      "ep 12: ep_len:650 episode reward: total was -20.970000. running mean: -53.076505\n",
      "ep 12: ep_len:396 episode reward: total was 12.500000. running mean: -52.420740\n",
      "ep 12: ep_len:655 episode reward: total was -29.040000. running mean: -52.186932\n",
      "ep 12: ep_len:60 episode reward: total was -1.000000. running mean: -51.675063\n",
      "ep 12: ep_len:690 episode reward: total was -8.330000. running mean: -51.241612\n",
      "ep 12: ep_len:500 episode reward: total was -29.470000. running mean: -51.023896\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 12: ep_len:595 episode reward: total was -39.260000. running mean: -50.906257\n",
      "ep 12: ep_len:500 episode reward: total was -27.660000. running mean: -50.673795\n",
      "ep 12: ep_len:535 episode reward: total was -10.900000. running mean: -50.276057\n",
      "ep 12: ep_len:510 episode reward: total was -19.470000. running mean: -49.967996\n",
      "ep 12: ep_len:770 episode reward: total was -83.350000. running mean: -50.301816\n",
      "ep 12: ep_len:630 episode reward: total was -8.080000. running mean: -49.879598\n",
      "ep 12: ep_len:500 episode reward: total was -12.280000. running mean: -49.503602\n",
      "ep 12: ep_len:570 episode reward: total was -56.480000. running mean: -49.573366\n",
      "ep 12: ep_len:500 episode reward: total was 17.000000. running mean: -48.907632\n",
      "ep 12: ep_len:695 episode reward: total was -67.830000. running mean: -49.096856\n",
      "ep 12: ep_len:160 episode reward: total was 4.000000. running mean: -48.565887\n",
      "ep 12: ep_len:500 episode reward: total was -17.410000. running mean: -48.254329\n",
      "ep 12: ep_len:525 episode reward: total was -38.390000. running mean: -48.155685\n",
      "ep 12: ep_len:895 episode reward: total was -50.850000. running mean: -48.182628\n",
      "ep 12: ep_len:710 episode reward: total was -31.440000. running mean: -48.015202\n",
      "ep 12: ep_len:500 episode reward: total was -37.920000. running mean: -47.914250\n",
      "ep 12: ep_len:210 episode reward: total was 7.500000. running mean: -47.360108\n",
      "ep 12: ep_len:700 episode reward: total was -64.820000. running mean: -47.534706\n",
      "ep 12: ep_len:500 episode reward: total was -21.470000. running mean: -47.274059\n",
      "ep 12: ep_len:500 episode reward: total was -53.160000. running mean: -47.332919\n",
      "ep 12: ep_len:770 episode reward: total was -70.220000. running mean: -47.561790\n",
      "ep 12: ep_len:810 episode reward: total was -35.150000. running mean: -47.437672\n",
      "ep 12: ep_len:500 episode reward: total was -27.470000. running mean: -47.237995\n",
      "ep 12: ep_len:500 episode reward: total was 2.830000. running mean: -46.737315\n",
      "ep 12: ep_len:500 episode reward: total was -8.800000. running mean: -46.357942\n",
      "ep 12: ep_len:1070 episode reward: total was -24.430000. running mean: -46.138663\n",
      "ep 12: ep_len:500 episode reward: total was -11.430000. running mean: -45.791576\n",
      "ep 12: ep_len:925 episode reward: total was -30.610000. running mean: -45.639760\n",
      "ep 12: ep_len:308 episode reward: total was 8.000000. running mean: -45.103363\n",
      "ep 12: ep_len:1100 episode reward: total was -36.890000. running mean: -45.021229\n",
      "ep 12: ep_len:685 episode reward: total was -27.970000. running mean: -44.850717\n",
      "ep 12: ep_len:735 episode reward: total was -43.390000. running mean: -44.836109\n",
      "ep 12: ep_len:880 episode reward: total was -65.440000. running mean: -45.042148\n",
      "ep 12: ep_len:505 episode reward: total was -27.960000. running mean: -44.871327\n",
      "ep 12: ep_len:505 episode reward: total was -34.480000. running mean: -44.767414\n",
      "ep 12: ep_len:500 episode reward: total was -32.320000. running mean: -44.642939\n",
      "ep 12: ep_len:500 episode reward: total was -46.090000. running mean: -44.657410\n",
      "ep 12: ep_len:705 episode reward: total was -26.920000. running mean: -44.480036\n",
      "ep 12: ep_len:1415 episode reward: total was -167.880000. running mean: -45.714036\n",
      "ep 12: ep_len:810 episode reward: total was -35.000000. running mean: -45.606895\n",
      "ep 12: ep_len:760 episode reward: total was -28.830000. running mean: -45.439126\n",
      "ep 12: ep_len:735 episode reward: total was -26.150000. running mean: -45.246235\n",
      "ep 12: ep_len:1015 episode reward: total was -69.020000. running mean: -45.483973\n",
      "ep 12: ep_len:980 episode reward: total was -37.960000. running mean: -45.408733\n",
      "ep 12: ep_len:208 episode reward: total was 13.000000. running mean: -44.824646\n",
      "ep 12: ep_len:500 episode reward: total was -34.850000. running mean: -44.724899\n",
      "ep 12: ep_len:815 episode reward: total was -25.390000. running mean: -44.531550\n",
      "ep 12: ep_len:500 episode reward: total was -1.330000. running mean: -44.099535\n",
      "ep 12: ep_len:1580 episode reward: total was -120.550000. running mean: -44.864039\n",
      "ep 12: ep_len:865 episode reward: total was -56.900000. running mean: -44.984399\n",
      "ep 12: ep_len:500 episode reward: total was -19.640000. running mean: -44.730955\n",
      "ep 12: ep_len:515 episode reward: total was -29.810000. running mean: -44.581745\n",
      "ep 12: ep_len:500 episode reward: total was 27.500000. running mean: -43.860928\n",
      "ep 12: ep_len:500 episode reward: total was -0.290000. running mean: -43.425219\n",
      "ep 12: ep_len:500 episode reward: total was -25.920000. running mean: -43.250166\n",
      "ep 12: ep_len:1520 episode reward: total was -126.780000. running mean: -44.085465\n",
      "ep 12: ep_len:500 episode reward: total was -0.320000. running mean: -43.647810\n",
      "ep 12: ep_len:510 episode reward: total was -11.880000. running mean: -43.330132\n",
      "ep 12: ep_len:72 episode reward: total was 5.000000. running mean: -42.846831\n",
      "ep 12: ep_len:500 episode reward: total was 18.500000. running mean: -42.233362\n",
      "ep 12: ep_len:244 episode reward: total was 9.000000. running mean: -41.721029\n",
      "ep 12: ep_len:680 episode reward: total was -55.220000. running mean: -41.856019\n",
      "ep 12: ep_len:990 episode reward: total was -18.870000. running mean: -41.626158\n",
      "ep 12: ep_len:505 episode reward: total was -7.780000. running mean: -41.287697\n",
      "ep 12: ep_len:261 episode reward: total was 9.500000. running mean: -40.779820\n",
      "ep 12: ep_len:520 episode reward: total was -24.320000. running mean: -40.615222\n",
      "ep 12: ep_len:645 episode reward: total was -29.060000. running mean: -40.499669\n",
      "ep 12: ep_len:555 episode reward: total was -49.440000. running mean: -40.589073\n",
      "ep 12: ep_len:630 episode reward: total was -16.440000. running mean: -40.347582\n",
      "ep 12: ep_len:100 episode reward: total was 4.500000. running mean: -39.899106\n",
      "ep 12: ep_len:500 episode reward: total was -19.550000. running mean: -39.695615\n",
      "ep 12: ep_len:1050 episode reward: total was -151.300000. running mean: -40.811659\n",
      "ep 12: ep_len:955 episode reward: total was -12.490000. running mean: -40.528442\n",
      "ep 12: ep_len:510 episode reward: total was -43.010000. running mean: -40.553258\n",
      "ep 12: ep_len:500 episode reward: total was -9.850000. running mean: -40.246225\n",
      "ep 12: ep_len:675 episode reward: total was -36.560000. running mean: -40.209363\n",
      "ep 12: ep_len:500 episode reward: total was -11.490000. running mean: -39.922169\n",
      "ep 12: ep_len:500 episode reward: total was -8.350000. running mean: -39.606448\n",
      "ep 12: ep_len:695 episode reward: total was -35.020000. running mean: -39.560583\n",
      "ep 12: ep_len:625 episode reward: total was -33.140000. running mean: -39.496377\n",
      "ep 12: ep_len:660 episode reward: total was -33.590000. running mean: -39.437314\n",
      "ep 12: ep_len:515 episode reward: total was -14.830000. running mean: -39.191241\n",
      "ep 12: ep_len:505 episode reward: total was -15.870000. running mean: -38.958028\n",
      "ep 12: ep_len:555 episode reward: total was -1.620000. running mean: -38.584648\n",
      "ep 12: ep_len:655 episode reward: total was -21.970000. running mean: -38.418501\n",
      "ep 12: ep_len:500 episode reward: total was -4.980000. running mean: -38.084116\n",
      "ep 12: ep_len:985 episode reward: total was -40.050000. running mean: -38.103775\n",
      "ep 12: ep_len:500 episode reward: total was -6.510000. running mean: -37.787837\n",
      "ep 12: ep_len:660 episode reward: total was -54.770000. running mean: -37.957659\n",
      "ep 12: ep_len:1050 episode reward: total was -25.330000. running mean: -37.831382\n",
      "ep 12: ep_len:600 episode reward: total was -22.010000. running mean: -37.673169\n",
      "ep 12: ep_len:1060 episode reward: total was -23.440000. running mean: -37.530837\n",
      "ep 12: ep_len:505 episode reward: total was -18.310000. running mean: -37.338629\n",
      "ep 12: ep_len:800 episode reward: total was -35.360000. running mean: -37.318842\n",
      "ep 12: ep_len:500 episode reward: total was 20.000000. running mean: -36.745654\n",
      "ep 12: ep_len:995 episode reward: total was -34.660000. running mean: -36.724797\n",
      "ep 12: ep_len:740 episode reward: total was -78.570000. running mean: -37.143249\n",
      "ep 12: ep_len:500 episode reward: total was -32.800000. running mean: -37.099817\n",
      "ep 12: ep_len:515 episode reward: total was -61.120000. running mean: -37.340019\n",
      "ep 12: ep_len:895 episode reward: total was -19.680000. running mean: -37.163419\n",
      "ep 12: ep_len:247 episode reward: total was 13.000000. running mean: -36.661784\n",
      "ep 12: ep_len:505 episode reward: total was -6.410000. running mean: -36.359266\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 12: ep_len:550 episode reward: total was -22.150000. running mean: -36.217174\n",
      "ep 12: ep_len:505 episode reward: total was -26.800000. running mean: -36.123002\n",
      "ep 12: ep_len:500 episode reward: total was -28.430000. running mean: -36.046072\n",
      "ep 12: ep_len:500 episode reward: total was -12.820000. running mean: -35.813811\n",
      "ep 12: ep_len:500 episode reward: total was -25.270000. running mean: -35.708373\n",
      "ep 12: ep_len:685 episode reward: total was -31.980000. running mean: -35.671090\n",
      "ep 12: ep_len:230 episode reward: total was 8.000000. running mean: -35.234379\n",
      "ep 12: ep_len:775 episode reward: total was -36.880000. running mean: -35.250835\n",
      "ep 12: ep_len:505 episode reward: total was -1.750000. running mean: -34.915826\n",
      "ep 12: ep_len:1608 episode reward: total was -219.610000. running mean: -36.762768\n",
      "ep 12: ep_len:1880 episode reward: total was -296.750000. running mean: -39.362641\n",
      "ep 12: ep_len:500 episode reward: total was -5.740000. running mean: -39.026414\n",
      "ep 12: ep_len:760 episode reward: total was -35.820000. running mean: -38.994350\n",
      "ep 12: ep_len:755 episode reward: total was -25.900000. running mean: -38.863406\n",
      "ep 12: ep_len:1110 episode reward: total was -35.930000. running mean: -38.834072\n",
      "ep 12: ep_len:515 episode reward: total was -40.020000. running mean: -38.845932\n",
      "ep 12: ep_len:349 episode reward: total was 15.000000. running mean: -38.307472\n",
      "ep 12: ep_len:620 episode reward: total was -37.680000. running mean: -38.301198\n",
      "ep 12: ep_len:845 episode reward: total was -13.630000. running mean: -38.054486\n",
      "ep 12: ep_len:730 episode reward: total was -4.810000. running mean: -37.722041\n",
      "ep 12: ep_len:500 episode reward: total was -18.000000. running mean: -37.524820\n",
      "ep 12: ep_len:575 episode reward: total was -4.090000. running mean: -37.190472\n",
      "ep 12: ep_len:530 episode reward: total was -43.430000. running mean: -37.252867\n",
      "ep 12: ep_len:536 episode reward: total was -58.230000. running mean: -37.462639\n",
      "ep 12: ep_len:925 episode reward: total was -40.890000. running mean: -37.496912\n",
      "ep 12: ep_len:500 episode reward: total was -16.120000. running mean: -37.283143\n",
      "ep 12: ep_len:955 episode reward: total was -98.830000. running mean: -37.898612\n",
      "ep 12: ep_len:500 episode reward: total was -20.280000. running mean: -37.722426\n",
      "ep 12: ep_len:216 episode reward: total was 6.500000. running mean: -37.280201\n",
      "ep 12: ep_len:855 episode reward: total was -12.000000. running mean: -37.027399\n",
      "ep 12: ep_len:500 episode reward: total was -13.070000. running mean: -36.787825\n",
      "ep 12: ep_len:500 episode reward: total was -25.490000. running mean: -36.674847\n",
      "ep 12: ep_len:835 episode reward: total was -31.970000. running mean: -36.627799\n",
      "ep 12: ep_len:500 episode reward: total was -75.840000. running mean: -37.019921\n",
      "ep 12: ep_len:700 episode reward: total was -12.230000. running mean: -36.772022\n",
      "ep 12: ep_len:150 episode reward: total was 6.000000. running mean: -36.344301\n",
      "ep 12: ep_len:500 episode reward: total was -11.590000. running mean: -36.096758\n",
      "ep 12: ep_len:720 episode reward: total was -23.340000. running mean: -35.969191\n",
      "ep 12: ep_len:500 episode reward: total was 2.890000. running mean: -35.580599\n",
      "ep 12: ep_len:820 episode reward: total was -20.560000. running mean: -35.430393\n",
      "ep 12: ep_len:610 episode reward: total was -90.740000. running mean: -35.983489\n",
      "ep 12: ep_len:500 episode reward: total was -0.230000. running mean: -35.625954\n",
      "ep 12: ep_len:505 episode reward: total was -31.410000. running mean: -35.583794\n",
      "ep 12: ep_len:500 episode reward: total was 4.700000. running mean: -35.180957\n",
      "ep 12: ep_len:640 episode reward: total was -38.360000. running mean: -35.212747\n",
      "ep 12: ep_len:560 episode reward: total was -21.880000. running mean: -35.079420\n",
      "ep 12: ep_len:625 episode reward: total was -59.390000. running mean: -35.322525\n",
      "ep 12: ep_len:565 episode reward: total was -34.810000. running mean: -35.317400\n",
      "ep 12: ep_len:785 episode reward: total was -41.990000. running mean: -35.384126\n",
      "ep 12: ep_len:580 episode reward: total was -28.680000. running mean: -35.317085\n",
      "ep 12: ep_len:500 episode reward: total was -9.410000. running mean: -35.058014\n",
      "ep 12: ep_len:765 episode reward: total was -59.700000. running mean: -35.304434\n",
      "ep 12: ep_len:500 episode reward: total was 1.690000. running mean: -34.934489\n",
      "ep 12: ep_len:1575 episode reward: total was -80.530000. running mean: -35.390445\n",
      "ep 12: ep_len:555 episode reward: total was -35.300000. running mean: -35.389540\n",
      "ep 12: ep_len:725 episode reward: total was -19.810000. running mean: -35.233745\n",
      "ep 12: ep_len:910 episode reward: total was -26.380000. running mean: -35.145207\n",
      "ep 12: ep_len:500 episode reward: total was 0.530000. running mean: -34.788455\n",
      "ep 12: ep_len:500 episode reward: total was -18.780000. running mean: -34.628371\n",
      "ep 12: ep_len:500 episode reward: total was -21.330000. running mean: -34.495387\n",
      "ep 12: ep_len:500 episode reward: total was -20.590000. running mean: -34.356333\n",
      "ep 12: ep_len:234 episode reward: total was 6.500000. running mean: -33.947770\n",
      "ep 12: ep_len:500 episode reward: total was -6.260000. running mean: -33.670892\n",
      "ep 12: ep_len:545 episode reward: total was -73.720000. running mean: -34.071383\n",
      "ep 12: ep_len:720 episode reward: total was -35.460000. running mean: -34.085269\n",
      "ep 12: ep_len:500 episode reward: total was 2.020000. running mean: -33.724217\n",
      "ep 12: ep_len:645 episode reward: total was -21.310000. running mean: -33.600074\n",
      "ep 12: ep_len:630 episode reward: total was -55.350000. running mean: -33.817574\n",
      "ep 12: ep_len:500 episode reward: total was -4.370000. running mean: -33.523098\n",
      "ep 12: ep_len:505 episode reward: total was -11.760000. running mean: -33.305467\n",
      "ep 12: ep_len:1025 episode reward: total was -63.460000. running mean: -33.607012\n",
      "ep 12: ep_len:755 episode reward: total was -25.210000. running mean: -33.523042\n",
      "ep 12: ep_len:715 episode reward: total was -23.940000. running mean: -33.427212\n",
      "ep 12: ep_len:500 episode reward: total was -28.060000. running mean: -33.373540\n",
      "ep 12: ep_len:282 episode reward: total was -48.500000. running mean: -33.524804\n",
      "ep 12: ep_len:1000 episode reward: total was -32.150000. running mean: -33.511056\n",
      "ep 12: ep_len:540 episode reward: total was -8.780000. running mean: -33.263746\n",
      "ep 12: ep_len:500 episode reward: total was -33.710000. running mean: -33.268208\n",
      "ep 12: ep_len:500 episode reward: total was -1.760000. running mean: -32.953126\n",
      "ep 12: ep_len:672 episode reward: total was -62.370000. running mean: -33.247295\n",
      "ep 12: ep_len:186 episode reward: total was 3.000000. running mean: -32.884822\n",
      "ep 12: ep_len:199 episode reward: total was 3.000000. running mean: -32.525974\n",
      "ep 12: ep_len:520 episode reward: total was -2.240000. running mean: -32.223114\n",
      "ep 12: ep_len:640 episode reward: total was -29.070000. running mean: -32.191583\n",
      "ep 12: ep_len:580 episode reward: total was -34.090000. running mean: -32.210567\n",
      "ep 12: ep_len:500 episode reward: total was -17.280000. running mean: -32.061261\n",
      "ep 12: ep_len:500 episode reward: total was -12.820000. running mean: -31.868849\n",
      "ep 12: ep_len:500 episode reward: total was 20.000000. running mean: -31.350160\n",
      "ep 12: ep_len:795 episode reward: total was -16.490000. running mean: -31.201559\n",
      "ep 12: ep_len:500 episode reward: total was -39.020000. running mean: -31.279743\n",
      "ep 12: ep_len:585 episode reward: total was -27.130000. running mean: -31.238246\n",
      "ep 12: ep_len:525 episode reward: total was -27.280000. running mean: -31.198663\n",
      "ep 12: ep_len:975 episode reward: total was -34.090000. running mean: -31.227577\n",
      "ep 12: ep_len:570 episode reward: total was -58.330000. running mean: -31.498601\n",
      "ep 12: ep_len:1220 episode reward: total was -166.280000. running mean: -32.846415\n",
      "ep 12: ep_len:500 episode reward: total was -21.910000. running mean: -32.737051\n",
      "ep 12: ep_len:500 episode reward: total was -23.520000. running mean: -32.644880\n",
      "ep 12: ep_len:580 episode reward: total was -30.200000. running mean: -32.620431\n",
      "ep 12: ep_len:310 episode reward: total was 0.500000. running mean: -32.289227\n",
      "ep 12: ep_len:139 episode reward: total was 6.500000. running mean: -31.901335\n",
      "ep 12: ep_len:625 episode reward: total was -31.610000. running mean: -31.898421\n",
      "ep 12: ep_len:995 episode reward: total was -91.960000. running mean: -32.499037\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 12: ep_len:510 episode reward: total was -10.830000. running mean: -32.282347\n",
      "ep 12: ep_len:457 episode reward: total was -8.580000. running mean: -32.045323\n",
      "ep 12: ep_len:515 episode reward: total was -36.880000. running mean: -32.093670\n",
      "ep 12: ep_len:890 episode reward: total was -61.100000. running mean: -32.383733\n",
      "ep 12: ep_len:1808 episode reward: total was -203.470000. running mean: -34.094596\n",
      "ep 12: ep_len:790 episode reward: total was -38.470000. running mean: -34.138350\n",
      "ep 12: ep_len:500 episode reward: total was 18.500000. running mean: -33.611967\n",
      "ep 12: ep_len:1005 episode reward: total was -39.010000. running mean: -33.665947\n",
      "ep 12: ep_len:500 episode reward: total was -10.300000. running mean: -33.432287\n",
      "ep 12: ep_len:855 episode reward: total was -38.230000. running mean: -33.480265\n",
      "ep 12: ep_len:805 episode reward: total was -28.490000. running mean: -33.430362\n",
      "ep 12: ep_len:263 episode reward: total was 9.500000. running mean: -33.001058\n",
      "ep 12: ep_len:1105 episode reward: total was -65.510000. running mean: -33.326148\n",
      "ep 12: ep_len:575 episode reward: total was -10.320000. running mean: -33.096086\n",
      "ep 12: ep_len:505 episode reward: total was -37.050000. running mean: -33.135625\n",
      "ep 12: ep_len:500 episode reward: total was -12.410000. running mean: -32.928369\n",
      "ep 12: ep_len:144 episode reward: total was 6.500000. running mean: -32.534085\n",
      "ep 12: ep_len:500 episode reward: total was -9.940000. running mean: -32.308145\n",
      "ep 12: ep_len:665 episode reward: total was -66.390000. running mean: -32.648963\n",
      "ep 12: ep_len:500 episode reward: total was -36.940000. running mean: -32.691873\n",
      "ep 12: ep_len:500 episode reward: total was -10.600000. running mean: -32.470955\n",
      "ep 12: ep_len:530 episode reward: total was -20.200000. running mean: -32.348245\n",
      "ep 12: ep_len:139 episode reward: total was 4.500000. running mean: -31.979763\n",
      "ep 12: ep_len:190 episode reward: total was 11.000000. running mean: -31.549965\n",
      "ep 12: ep_len:240 episode reward: total was 3.500000. running mean: -31.199465\n",
      "ep 12: ep_len:343 episode reward: total was 13.500000. running mean: -30.752471\n",
      "ep 12: ep_len:275 episode reward: total was -3.000000. running mean: -30.474946\n",
      "ep 12: ep_len:840 episode reward: total was -41.580000. running mean: -30.585997\n",
      "ep 12: ep_len:500 episode reward: total was 20.160000. running mean: -30.078537\n",
      "ep 12: ep_len:188 episode reward: total was 8.000000. running mean: -29.697751\n",
      "ep 12: ep_len:605 episode reward: total was -16.460000. running mean: -29.565374\n",
      "ep 12: ep_len:500 episode reward: total was -9.290000. running mean: -29.362620\n",
      "ep 12: ep_len:545 episode reward: total was -5.620000. running mean: -29.125194\n",
      "ep 12: ep_len:500 episode reward: total was 23.000000. running mean: -28.603942\n",
      "ep 12: ep_len:500 episode reward: total was -32.380000. running mean: -28.641703\n",
      "ep 12: ep_len:500 episode reward: total was -13.790000. running mean: -28.493185\n",
      "ep 12: ep_len:414 episode reward: total was -14.830000. running mean: -28.356554\n",
      "ep 12: ep_len:1085 episode reward: total was -23.420000. running mean: -28.307188\n",
      "ep 12: ep_len:765 episode reward: total was -19.410000. running mean: -28.218216\n",
      "ep 12: ep_len:500 episode reward: total was -7.320000. running mean: -28.009234\n",
      "ep 12: ep_len:530 episode reward: total was -22.880000. running mean: -27.957942\n",
      "ep 12: ep_len:795 episode reward: total was -41.860000. running mean: -28.096962\n",
      "ep 12: ep_len:700 episode reward: total was -39.990000. running mean: -28.215893\n",
      "ep 12: ep_len:500 episode reward: total was 5.240000. running mean: -27.881334\n",
      "ep 12: ep_len:500 episode reward: total was -21.290000. running mean: -27.815420\n",
      "ep 12: ep_len:500 episode reward: total was -13.840000. running mean: -27.675666\n",
      "ep 12: ep_len:650 episode reward: total was -54.230000. running mean: -27.941210\n",
      "ep 12: ep_len:965 episode reward: total was -59.300000. running mean: -28.254797\n",
      "ep 12: ep_len:500 episode reward: total was -6.230000. running mean: -28.034549\n",
      "ep 12: ep_len:1025 episode reward: total was -15.820000. running mean: -27.912404\n",
      "ep 12: ep_len:361 episode reward: total was 17.000000. running mean: -27.463280\n",
      "ep 12: ep_len:505 episode reward: total was -37.910000. running mean: -27.567747\n",
      "ep 12: ep_len:500 episode reward: total was -1.520000. running mean: -27.307270\n",
      "ep 12: ep_len:825 episode reward: total was -31.420000. running mean: -27.348397\n",
      "ep 12: ep_len:500 episode reward: total was 6.260000. running mean: -27.012313\n",
      "ep 12: ep_len:222 episode reward: total was 14.500000. running mean: -26.597190\n",
      "ep 12: ep_len:595 episode reward: total was -19.480000. running mean: -26.526018\n",
      "ep 12: ep_len:500 episode reward: total was 6.720000. running mean: -26.193558\n",
      "ep 12: ep_len:352 episode reward: total was 6.500000. running mean: -25.866622\n",
      "ep 12: ep_len:1420 episode reward: total was -101.210000. running mean: -26.620056\n",
      "ep 12: ep_len:1095 episode reward: total was -129.130000. running mean: -27.645155\n",
      "ep 12: ep_len:670 episode reward: total was -24.250000. running mean: -27.611204\n",
      "ep 12: ep_len:510 episode reward: total was -22.300000. running mean: -27.558092\n",
      "ep 12: ep_len:500 episode reward: total was -16.290000. running mean: -27.445411\n",
      "ep 12: ep_len:755 episode reward: total was -34.380000. running mean: -27.514757\n",
      "ep 12: ep_len:505 episode reward: total was -14.730000. running mean: -27.386909\n",
      "ep 12: ep_len:900 episode reward: total was -16.620000. running mean: -27.279240\n",
      "ep 12: ep_len:202 episode reward: total was 5.000000. running mean: -26.956448\n",
      "ep 12: ep_len:620 episode reward: total was -71.860000. running mean: -27.405483\n",
      "ep 12: ep_len:540 episode reward: total was -37.350000. running mean: -27.504928\n",
      "ep 12: ep_len:500 episode reward: total was -7.330000. running mean: -27.303179\n",
      "ep 12: ep_len:505 episode reward: total was -59.640000. running mean: -27.626547\n",
      "ep 12: ep_len:1195 episode reward: total was -84.520000. running mean: -28.195482\n",
      "ep 12: ep_len:645 episode reward: total was -29.550000. running mean: -28.209027\n",
      "ep 12: ep_len:695 episode reward: total was -34.530000. running mean: -28.272237\n",
      "ep 12: ep_len:575 episode reward: total was -23.630000. running mean: -28.225814\n",
      "ep 12: ep_len:560 episode reward: total was -30.820000. running mean: -28.251756\n",
      "ep 12: ep_len:500 episode reward: total was -38.650000. running mean: -28.355739\n",
      "ep 12: ep_len:800 episode reward: total was -55.010000. running mean: -28.622281\n",
      "ep 12: ep_len:770 episode reward: total was -3.480000. running mean: -28.370859\n",
      "ep 12: ep_len:297 episode reward: total was -48.430000. running mean: -28.571450\n",
      "ep 12: ep_len:505 episode reward: total was -17.970000. running mean: -28.465435\n",
      "ep 12: ep_len:505 episode reward: total was -25.690000. running mean: -28.437681\n",
      "ep 12: ep_len:500 episode reward: total was -25.000000. running mean: -28.403304\n",
      "ep 12: ep_len:500 episode reward: total was -4.940000. running mean: -28.168671\n",
      "ep 12: ep_len:530 episode reward: total was -11.840000. running mean: -28.005385\n",
      "ep 12: ep_len:500 episode reward: total was -30.740000. running mean: -28.032731\n",
      "ep 12: ep_len:500 episode reward: total was 8.220000. running mean: -27.670203\n",
      "ep 12: ep_len:500 episode reward: total was -2.800000. running mean: -27.421501\n",
      "ep 12: ep_len:695 episode reward: total was -34.010000. running mean: -27.487386\n",
      "ep 12: ep_len:1755 episode reward: total was -153.420000. running mean: -28.746712\n",
      "ep 12: ep_len:815 episode reward: total was -19.610000. running mean: -28.655345\n",
      "ep 12: ep_len:635 episode reward: total was -22.500000. running mean: -28.593792\n",
      "ep 12: ep_len:500 episode reward: total was 4.780000. running mean: -28.260054\n",
      "ep 12: ep_len:500 episode reward: total was -23.890000. running mean: -28.216353\n",
      "ep 12: ep_len:660 episode reward: total was -36.790000. running mean: -28.302090\n",
      "ep 12: ep_len:500 episode reward: total was 18.000000. running mean: -27.839069\n",
      "ep 12: ep_len:585 episode reward: total was -63.970000. running mean: -28.200378\n",
      "ep 12: ep_len:2185 episode reward: total was -256.040000. running mean: -30.478775\n",
      "ep 12: ep_len:685 episode reward: total was -32.010000. running mean: -30.494087\n",
      "ep 12: ep_len:510 episode reward: total was -30.340000. running mean: -30.492546\n",
      "ep 12: ep_len:1510 episode reward: total was -92.980000. running mean: -31.117420\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 12: ep_len:505 episode reward: total was -24.490000. running mean: -31.051146\n",
      "ep 12: ep_len:645 episode reward: total was -44.180000. running mean: -31.182435\n",
      "ep 12: ep_len:890 episode reward: total was -30.050000. running mean: -31.171110\n",
      "ep 12: ep_len:1150 episode reward: total was -89.660000. running mean: -31.755999\n",
      "ep 12: ep_len:505 episode reward: total was -14.400000. running mean: -31.582439\n",
      "ep 12: ep_len:1400 episode reward: total was -78.050000. running mean: -32.047115\n",
      "ep 12: ep_len:197 episode reward: total was 6.000000. running mean: -31.666644\n",
      "ep 12: ep_len:500 episode reward: total was -5.850000. running mean: -31.408477\n",
      "ep 12: ep_len:500 episode reward: total was 16.000000. running mean: -30.934393\n",
      "ep 12: ep_len:550 episode reward: total was -50.430000. running mean: -31.129349\n",
      "ep 12: ep_len:785 episode reward: total was -37.840000. running mean: -31.196455\n",
      "ep 12: ep_len:500 episode reward: total was -14.690000. running mean: -31.031391\n",
      "ep 12: ep_len:236 episode reward: total was 19.000000. running mean: -30.531077\n",
      "ep 12: ep_len:760 episode reward: total was -36.390000. running mean: -30.589666\n",
      "ep 12: ep_len:161 episode reward: total was -7.000000. running mean: -30.353769\n",
      "ep 12: ep_len:1010 episode reward: total was -35.370000. running mean: -30.403932\n",
      "ep 12: ep_len:670 episode reward: total was -34.030000. running mean: -30.440192\n",
      "ep 12: ep_len:650 episode reward: total was -16.550000. running mean: -30.301290\n",
      "ep 12: ep_len:250 episode reward: total was 7.500000. running mean: -29.923277\n",
      "ep 12: ep_len:500 episode reward: total was -17.840000. running mean: -29.802445\n",
      "ep 12: ep_len:890 episode reward: total was -41.700000. running mean: -29.921420\n",
      "ep 12: ep_len:500 episode reward: total was -14.030000. running mean: -29.762506\n",
      "ep 12: ep_len:1835 episode reward: total was -146.960000. running mean: -30.934481\n",
      "ep 12: ep_len:1255 episode reward: total was -24.000000. running mean: -30.865136\n",
      "ep 12: ep_len:505 episode reward: total was -36.900000. running mean: -30.925485\n",
      "ep 12: ep_len:500 episode reward: total was -9.970000. running mean: -30.715930\n",
      "ep 12: ep_len:1035 episode reward: total was -66.060000. running mean: -31.069371\n",
      "ep 12: ep_len:555 episode reward: total was -43.380000. running mean: -31.192477\n",
      "ep 12: ep_len:241 episode reward: total was 5.500000. running mean: -30.825552\n",
      "ep 12: ep_len:510 episode reward: total was -15.160000. running mean: -30.668897\n",
      "ep 12: ep_len:520 episode reward: total was -36.380000. running mean: -30.726008\n",
      "ep 12: ep_len:980 episode reward: total was -49.000000. running mean: -30.908748\n",
      "ep 12: ep_len:500 episode reward: total was -9.450000. running mean: -30.694160\n",
      "ep 12: ep_len:1045 episode reward: total was -115.610000. running mean: -31.543319\n",
      "ep 12: ep_len:1720 episode reward: total was -188.090000. running mean: -33.108785\n",
      "ep 12: ep_len:500 episode reward: total was 1.740000. running mean: -32.760297\n",
      "ep 12: ep_len:625 episode reward: total was -65.460000. running mean: -33.087295\n",
      "ep 12: ep_len:965 episode reward: total was -130.920000. running mean: -34.065622\n",
      "ep 12: ep_len:500 episode reward: total was -22.370000. running mean: -33.948665\n",
      "ep 12: ep_len:895 episode reward: total was -60.880000. running mean: -34.217979\n",
      "ep 12: ep_len:625 episode reward: total was -61.910000. running mean: -34.494899\n",
      "ep 12: ep_len:595 episode reward: total was -40.680000. running mean: -34.556750\n",
      "ep 12: ep_len:710 episode reward: total was -22.350000. running mean: -34.434682\n",
      "ep 12: ep_len:678 episode reward: total was -50.460000. running mean: -34.594936\n",
      "ep 12: ep_len:128 episode reward: total was 5.000000. running mean: -34.198986\n",
      "ep 12: ep_len:500 episode reward: total was -23.480000. running mean: -34.091796\n",
      "ep 12: ep_len:875 episode reward: total was -55.770000. running mean: -34.308578\n",
      "ep 12: ep_len:349 episode reward: total was 13.500000. running mean: -33.830493\n",
      "ep 12: ep_len:500 episode reward: total was -11.460000. running mean: -33.606788\n",
      "ep 12: ep_len:500 episode reward: total was -11.500000. running mean: -33.385720\n",
      "ep 12: ep_len:835 episode reward: total was -48.850000. running mean: -33.540363\n",
      "ep 12: ep_len:720 episode reward: total was -33.960000. running mean: -33.544559\n",
      "ep 12: ep_len:500 episode reward: total was -31.860000. running mean: -33.527713\n",
      "ep 12: ep_len:515 episode reward: total was -12.150000. running mean: -33.313936\n",
      "ep 12: ep_len:1125 episode reward: total was -86.750000. running mean: -33.848297\n",
      "ep 12: ep_len:760 episode reward: total was -39.940000. running mean: -33.909214\n",
      "ep 12: ep_len:505 episode reward: total was -21.270000. running mean: -33.782822\n",
      "ep 12: ep_len:565 episode reward: total was -41.340000. running mean: -33.858394\n",
      "ep 12: ep_len:500 episode reward: total was -39.510000. running mean: -33.914910\n",
      "ep 12: ep_len:730 episode reward: total was -25.270000. running mean: -33.828461\n",
      "ep 12: ep_len:1237 episode reward: total was -162.190000. running mean: -35.112076\n",
      "ep 12: ep_len:775 episode reward: total was -64.230000. running mean: -35.403255\n",
      "ep 12: ep_len:500 episode reward: total was -33.450000. running mean: -35.383723\n",
      "ep 12: ep_len:500 episode reward: total was 18.720000. running mean: -34.842685\n",
      "ep 12: ep_len:505 episode reward: total was -20.860000. running mean: -34.702859\n",
      "ep 12: ep_len:605 episode reward: total was -17.890000. running mean: -34.534730\n",
      "ep 12: ep_len:630 episode reward: total was -58.380000. running mean: -34.773183\n",
      "ep 12: ep_len:660 episode reward: total was -24.960000. running mean: -34.675051\n",
      "ep 12: ep_len:515 episode reward: total was -23.880000. running mean: -34.567100\n",
      "ep 12: ep_len:770 episode reward: total was -47.480000. running mean: -34.696229\n",
      "ep 12: ep_len:830 episode reward: total was -30.490000. running mean: -34.654167\n",
      "ep 12: ep_len:510 episode reward: total was -7.080000. running mean: -34.378425\n",
      "ep 12: ep_len:505 episode reward: total was -18.400000. running mean: -34.218641\n",
      "ep 12: ep_len:905 episode reward: total was -36.350000. running mean: -34.239955\n",
      "ep 12: ep_len:505 episode reward: total was -36.900000. running mean: -34.266555\n",
      "ep 12: ep_len:500 episode reward: total was -12.630000. running mean: -34.050190\n",
      "ep 12: ep_len:500 episode reward: total was -15.010000. running mean: -33.859788\n",
      "ep 12: ep_len:570 episode reward: total was -18.740000. running mean: -33.708590\n",
      "ep 12: ep_len:755 episode reward: total was -60.400000. running mean: -33.975504\n",
      "ep 12: ep_len:555 episode reward: total was -27.220000. running mean: -33.907949\n",
      "ep 12: ep_len:950 episode reward: total was -94.100000. running mean: -34.509869\n",
      "ep 12: ep_len:665 episode reward: total was -30.480000. running mean: -34.469571\n",
      "ep 12: ep_len:500 episode reward: total was -19.800000. running mean: -34.322875\n",
      "ep 12: ep_len:500 episode reward: total was -13.740000. running mean: -34.117046\n",
      "ep 12: ep_len:500 episode reward: total was -11.200000. running mean: -33.887876\n",
      "ep 12: ep_len:500 episode reward: total was -7.490000. running mean: -33.623897\n",
      "ep 12: ep_len:690 episode reward: total was -12.940000. running mean: -33.417058\n",
      "ep 12: ep_len:176 episode reward: total was -10.500000. running mean: -33.187887\n",
      "ep 12: ep_len:500 episode reward: total was -17.770000. running mean: -33.033709\n",
      "ep 12: ep_len:781 episode reward: total was -76.440000. running mean: -33.467772\n",
      "ep 12: ep_len:505 episode reward: total was -13.330000. running mean: -33.266394\n",
      "ep 12: ep_len:570 episode reward: total was -25.660000. running mean: -33.190330\n",
      "ep 12: ep_len:500 episode reward: total was -36.510000. running mean: -33.223527\n",
      "ep 12: ep_len:163 episode reward: total was 4.000000. running mean: -32.851291\n",
      "ep 12: ep_len:505 episode reward: total was -9.770000. running mean: -32.620478\n",
      "ep 12: ep_len:369 episode reward: total was -70.000000. running mean: -32.994274\n",
      "ep 12: ep_len:500 episode reward: total was 3.630000. running mean: -32.628031\n",
      "ep 12: ep_len:174 episode reward: total was 8.000000. running mean: -32.221751\n",
      "ep 12: ep_len:500 episode reward: total was -1.540000. running mean: -31.914933\n",
      "ep 12: ep_len:700 episode reward: total was -43.090000. running mean: -32.026684\n",
      "ep 12: ep_len:945 episode reward: total was -35.530000. running mean: -32.061717\n",
      "ep 12: ep_len:605 episode reward: total was -22.070000. running mean: -31.961800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 12: ep_len:705 episode reward: total was -42.560000. running mean: -32.067782\n",
      "ep 12: ep_len:484 episode reward: total was 3.160000. running mean: -31.715504\n",
      "ep 12: ep_len:925 episode reward: total was -52.710000. running mean: -31.925449\n",
      "ep 12: ep_len:575 episode reward: total was -35.260000. running mean: -31.958794\n",
      "ep 12: ep_len:735 episode reward: total was -26.860000. running mean: -31.907806\n",
      "ep 12: ep_len:790 episode reward: total was -120.160000. running mean: -32.790328\n",
      "ep 12: ep_len:850 episode reward: total was -33.740000. running mean: -32.799825\n",
      "ep 12: ep_len:500 episode reward: total was 1.390000. running mean: -32.457927\n",
      "ep 12: ep_len:1150 episode reward: total was -98.280000. running mean: -33.116148\n",
      "ep 12: ep_len:605 episode reward: total was -36.210000. running mean: -33.147086\n",
      "ep 12: ep_len:500 episode reward: total was -14.190000. running mean: -32.957515\n",
      "ep 12: ep_len:830 episode reward: total was -38.790000. running mean: -33.015840\n",
      "ep 12: ep_len:785 episode reward: total was -67.160000. running mean: -33.357282\n",
      "ep 12: ep_len:620 episode reward: total was -27.680000. running mean: -33.300509\n",
      "ep 12: ep_len:500 episode reward: total was -11.820000. running mean: -33.085704\n",
      "ep 12: ep_len:500 episode reward: total was -27.110000. running mean: -33.025947\n",
      "ep 12: ep_len:640 episode reward: total was 3.490000. running mean: -32.660787\n",
      "ep 12: ep_len:500 episode reward: total was -14.780000. running mean: -32.481979\n",
      "ep 12: ep_len:500 episode reward: total was 11.680000. running mean: -32.040360\n",
      "ep 12: ep_len:925 episode reward: total was -56.260000. running mean: -32.282556\n",
      "ep 12: ep_len:535 episode reward: total was 1.760000. running mean: -31.942130\n",
      "ep 12: ep_len:505 episode reward: total was -32.120000. running mean: -31.943909\n",
      "ep 12: ep_len:500 episode reward: total was -12.890000. running mean: -31.753370\n",
      "ep 12: ep_len:530 episode reward: total was -28.280000. running mean: -31.718636\n",
      "ep 12: ep_len:505 episode reward: total was -16.970000. running mean: -31.571150\n",
      "ep 12: ep_len:930 episode reward: total was -21.380000. running mean: -31.469238\n",
      "ep 12: ep_len:510 episode reward: total was -35.880000. running mean: -31.513346\n",
      "ep 12: ep_len:500 episode reward: total was -32.010000. running mean: -31.518313\n",
      "ep 12: ep_len:510 episode reward: total was -54.120000. running mean: -31.744330\n",
      "ep 12: ep_len:790 episode reward: total was -11.430000. running mean: -31.541186\n",
      "ep 12: ep_len:700 episode reward: total was -25.920000. running mean: -31.484974\n",
      "ep 12: ep_len:500 episode reward: total was -0.810000. running mean: -31.178225\n",
      "ep 12: ep_len:785 episode reward: total was -25.620000. running mean: -31.122642\n",
      "ep 12: ep_len:500 episode reward: total was -18.360000. running mean: -30.995016\n",
      "ep 12: ep_len:710 episode reward: total was -17.230000. running mean: -30.857366\n",
      "ep 12: ep_len:500 episode reward: total was -29.900000. running mean: -30.847792\n",
      "ep 12: ep_len:500 episode reward: total was -29.550000. running mean: -30.834814\n",
      "ep 12: ep_len:1849 episode reward: total was -232.830000. running mean: -32.854766\n",
      "ep 12: ep_len:1230 episode reward: total was -69.780000. running mean: -33.224018\n",
      "ep 12: ep_len:500 episode reward: total was -29.130000. running mean: -33.183078\n",
      "ep 12: ep_len:500 episode reward: total was -25.480000. running mean: -33.106047\n",
      "ep 12: ep_len:760 episode reward: total was -31.860000. running mean: -33.093587\n",
      "ep 12: ep_len:500 episode reward: total was -2.820000. running mean: -32.790851\n",
      "ep 12: ep_len:475 episode reward: total was -41.810000. running mean: -32.881043\n",
      "ep 12: ep_len:500 episode reward: total was -27.930000. running mean: -32.831532\n",
      "ep 12: ep_len:680 episode reward: total was -43.620000. running mean: -32.939417\n",
      "ep 12: ep_len:481 episode reward: total was 9.500000. running mean: -32.515023\n",
      "ep 12: ep_len:560 episode reward: total was -26.200000. running mean: -32.451872\n",
      "ep 12: ep_len:500 episode reward: total was -9.830000. running mean: -32.225654\n",
      "ep 12: ep_len:500 episode reward: total was 1.300000. running mean: -31.890397\n",
      "ep 12: ep_len:505 episode reward: total was -22.270000. running mean: -31.794193\n",
      "ep 12: ep_len:695 episode reward: total was -21.860000. running mean: -31.694851\n",
      "ep 12: ep_len:500 episode reward: total was -0.290000. running mean: -31.380803\n",
      "ep 12: ep_len:725 episode reward: total was -99.660000. running mean: -32.063595\n",
      "ep 12: ep_len:500 episode reward: total was -27.600000. running mean: -32.018959\n",
      "ep 12: ep_len:500 episode reward: total was -2.620000. running mean: -31.724969\n",
      "ep 12: ep_len:500 episode reward: total was -9.610000. running mean: -31.503820\n",
      "ep 12: ep_len:1045 episode reward: total was -28.000000. running mean: -31.468781\n",
      "ep 12: ep_len:500 episode reward: total was 0.720000. running mean: -31.146893\n",
      "ep 12: ep_len:815 episode reward: total was -48.920000. running mean: -31.324625\n",
      "ep 12: ep_len:505 episode reward: total was -19.450000. running mean: -31.205878\n",
      "ep 12: ep_len:179 episode reward: total was -2.500000. running mean: -30.918820\n",
      "ep 12: ep_len:530 episode reward: total was -22.220000. running mean: -30.831831\n",
      "ep 12: ep_len:520 episode reward: total was -25.870000. running mean: -30.782213\n",
      "ep 12: ep_len:162 episode reward: total was 10.000000. running mean: -30.374391\n",
      "ep 12: ep_len:500 episode reward: total was -38.030000. running mean: -30.450947\n",
      "ep 12: ep_len:187 episode reward: total was 14.000000. running mean: -30.006438\n",
      "ep 12: ep_len:530 episode reward: total was -28.970000. running mean: -29.996073\n",
      "ep 12: ep_len:500 episode reward: total was -8.610000. running mean: -29.782212\n",
      "ep 12: ep_len:236 episode reward: total was 13.500000. running mean: -29.349390\n",
      "ep 12: ep_len:505 episode reward: total was -19.020000. running mean: -29.246096\n",
      "ep 12: ep_len:555 episode reward: total was -14.570000. running mean: -29.099335\n",
      "ep 12: ep_len:500 episode reward: total was -23.300000. running mean: -29.041342\n",
      "ep 12: ep_len:675 episode reward: total was 4.560000. running mean: -28.705329\n",
      "ep 12: ep_len:785 episode reward: total was -38.880000. running mean: -28.807075\n",
      "ep 12: ep_len:630 episode reward: total was -8.300000. running mean: -28.602005\n",
      "ep 12: ep_len:500 episode reward: total was -5.240000. running mean: -28.368385\n",
      "ep 12: ep_len:500 episode reward: total was -4.460000. running mean: -28.129301\n",
      "ep 12: ep_len:655 episode reward: total was -20.960000. running mean: -28.057608\n",
      "ep 12: ep_len:900 episode reward: total was -45.200000. running mean: -28.229032\n",
      "ep 12: ep_len:795 episode reward: total was -30.780000. running mean: -28.254541\n",
      "ep 12: ep_len:500 episode reward: total was -10.640000. running mean: -28.078396\n",
      "ep 12: ep_len:500 episode reward: total was 10.670000. running mean: -27.690912\n",
      "ep 12: ep_len:500 episode reward: total was -20.280000. running mean: -27.616803\n",
      "ep 12: ep_len:985 episode reward: total was -40.690000. running mean: -27.747535\n",
      "ep 12: ep_len:570 episode reward: total was -19.000000. running mean: -27.660059\n",
      "ep 12: ep_len:248 episode reward: total was 4.000000. running mean: -27.343459\n",
      "ep 12: ep_len:725 episode reward: total was -28.510000. running mean: -27.355124\n",
      "ep 12: ep_len:505 episode reward: total was -11.290000. running mean: -27.194473\n",
      "ep 12: ep_len:239 episode reward: total was 8.500000. running mean: -26.837528\n",
      "ep 12: ep_len:565 episode reward: total was -57.000000. running mean: -27.139153\n",
      "ep 12: ep_len:1580 episode reward: total was -220.740000. running mean: -29.075161\n",
      "ep 12: ep_len:570 episode reward: total was -77.690000. running mean: -29.561310\n",
      "ep 12: ep_len:500 episode reward: total was -5.190000. running mean: -29.317597\n",
      "ep 12: ep_len:500 episode reward: total was -34.460000. running mean: -29.369021\n",
      "ep 12: ep_len:680 episode reward: total was -32.460000. running mean: -29.399931\n",
      "ep 12: ep_len:920 episode reward: total was -56.060000. running mean: -29.666531\n",
      "ep 12: ep_len:510 episode reward: total was 1.780000. running mean: -29.352066\n",
      "ep 12: ep_len:368 episode reward: total was 16.000000. running mean: -28.898545\n",
      "ep 12: ep_len:515 episode reward: total was -11.280000. running mean: -28.722360\n",
      "ep 12: ep_len:500 episode reward: total was -18.910000. running mean: -28.624236\n",
      "ep 12: ep_len:650 episode reward: total was -46.170000. running mean: -28.799694\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 12: ep_len:570 episode reward: total was -36.280000. running mean: -28.874497\n",
      "ep 12: ep_len:835 episode reward: total was -33.020000. running mean: -28.915952\n",
      "ep 12: ep_len:505 episode reward: total was -6.950000. running mean: -28.696292\n",
      "ep 12: ep_len:695 episode reward: total was -32.750000. running mean: -28.736830\n",
      "ep 12: ep_len:755 episode reward: total was -73.280000. running mean: -29.182261\n",
      "ep 12: ep_len:925 episode reward: total was -80.010000. running mean: -29.690539\n",
      "ep 12: ep_len:960 episode reward: total was -51.290000. running mean: -29.906533\n",
      "ep 12: ep_len:985 episode reward: total was -4.430000. running mean: -29.651768\n",
      "ep 12: ep_len:500 episode reward: total was 7.210000. running mean: -29.283150\n",
      "ep 12: ep_len:690 episode reward: total was -74.420000. running mean: -29.734519\n",
      "ep 12: ep_len:625 episode reward: total was -19.020000. running mean: -29.627374\n",
      "ep 12: ep_len:510 episode reward: total was -13.770000. running mean: -29.468800\n",
      "ep 12: ep_len:825 episode reward: total was -23.980000. running mean: -29.413912\n",
      "ep 12: ep_len:500 episode reward: total was 6.750000. running mean: -29.052273\n",
      "ep 12: ep_len:500 episode reward: total was 27.500000. running mean: -28.486750\n",
      "ep 12: ep_len:955 episode reward: total was -13.980000. running mean: -28.341682\n",
      "ep 12: ep_len:695 episode reward: total was -29.970000. running mean: -28.357966\n",
      "ep 12: ep_len:910 episode reward: total was -31.410000. running mean: -28.388486\n",
      "ep 12: ep_len:510 episode reward: total was -9.770000. running mean: -28.202301\n",
      "ep 12: ep_len:1140 episode reward: total was -32.240000. running mean: -28.242678\n",
      "ep 12: ep_len:680 episode reward: total was -54.760000. running mean: -28.507851\n",
      "ep 12: ep_len:690 episode reward: total was -6.980000. running mean: -28.292573\n",
      "ep 12: ep_len:500 episode reward: total was 5.740000. running mean: -27.952247\n",
      "ep 12: ep_len:500 episode reward: total was 12.690000. running mean: -27.545825\n",
      "ep 12: ep_len:500 episode reward: total was -0.200000. running mean: -27.272366\n",
      "ep 12: ep_len:500 episode reward: total was -34.400000. running mean: -27.343643\n",
      "ep 12: ep_len:500 episode reward: total was -4.980000. running mean: -27.120006\n",
      "ep 12: ep_len:840 episode reward: total was -45.320000. running mean: -27.302006\n",
      "ep 12: ep_len:500 episode reward: total was -16.700000. running mean: -27.195986\n",
      "ep 12: ep_len:725 episode reward: total was -31.930000. running mean: -27.243326\n",
      "ep 12: ep_len:500 episode reward: total was -26.960000. running mean: -27.240493\n",
      "ep 12: ep_len:580 episode reward: total was -10.300000. running mean: -27.071088\n",
      "ep 12: ep_len:505 episode reward: total was 1.860000. running mean: -26.781777\n",
      "ep 12: ep_len:500 episode reward: total was 23.500000. running mean: -26.278959\n",
      "ep 12: ep_len:500 episode reward: total was -1.610000. running mean: -26.032270\n",
      "ep 12: ep_len:590 episode reward: total was -25.000000. running mean: -26.021947\n",
      "ep 12: ep_len:880 episode reward: total was -74.040000. running mean: -26.502128\n",
      "ep 12: ep_len:467 episode reward: total was -26.290000. running mean: -26.500006\n",
      "ep 12: ep_len:255 episode reward: total was 13.500000. running mean: -26.100006\n",
      "ep 12: ep_len:287 episode reward: total was 2.120000. running mean: -25.817806\n",
      "ep 12: ep_len:870 episode reward: total was -41.260000. running mean: -25.972228\n",
      "ep 12: ep_len:1405 episode reward: total was -125.410000. running mean: -26.966606\n",
      "ep 12: ep_len:820 episode reward: total was -45.880000. running mean: -27.155740\n",
      "ep 12: ep_len:705 episode reward: total was -23.260000. running mean: -27.116782\n",
      "ep 12: ep_len:500 episode reward: total was -26.380000. running mean: -27.109415\n",
      "ep 12: ep_len:388 episode reward: total was -15.840000. running mean: -26.996721\n",
      "ep 12: ep_len:500 episode reward: total was -8.740000. running mean: -26.814153\n",
      "ep 12: ep_len:885 episode reward: total was -38.670000. running mean: -26.932712\n",
      "ep 12: ep_len:575 episode reward: total was -31.440000. running mean: -26.977785\n",
      "ep 12: ep_len:500 episode reward: total was -15.250000. running mean: -26.860507\n",
      "ep 12: ep_len:500 episode reward: total was -20.960000. running mean: -26.801502\n",
      "ep 12: ep_len:830 episode reward: total was -44.330000. running mean: -26.976787\n",
      "ep 12: ep_len:209 episode reward: total was 7.500000. running mean: -26.632019\n",
      "ep 12: ep_len:695 episode reward: total was -60.760000. running mean: -26.973299\n",
      "ep 12: ep_len:680 episode reward: total was -78.450000. running mean: -27.488066\n",
      "ep 12: ep_len:730 episode reward: total was -26.870000. running mean: -27.481885\n",
      "ep 12: ep_len:510 episode reward: total was -25.030000. running mean: -27.457366\n",
      "ep 12: ep_len:610 episode reward: total was -21.270000. running mean: -27.395493\n",
      "ep 12: ep_len:1020 episode reward: total was -32.100000. running mean: -27.442538\n",
      "ep 12: ep_len:500 episode reward: total was 5.920000. running mean: -27.108912\n",
      "ep 12: ep_len:940 episode reward: total was -66.850000. running mean: -27.506323\n",
      "ep 12: ep_len:730 episode reward: total was -40.120000. running mean: -27.632460\n",
      "ep 12: ep_len:690 episode reward: total was -7.230000. running mean: -27.428435\n",
      "ep 12: ep_len:860 episode reward: total was -34.240000. running mean: -27.496551\n",
      "ep 12: ep_len:381 episode reward: total was 21.000000. running mean: -27.011585\n",
      "ep 12: ep_len:244 episode reward: total was 6.000000. running mean: -26.681470\n",
      "ep 12: ep_len:500 episode reward: total was -12.840000. running mean: -26.543055\n",
      "ep 12: ep_len:505 episode reward: total was -13.310000. running mean: -26.410724\n",
      "ep 12: ep_len:600 episode reward: total was -59.940000. running mean: -26.746017\n",
      "ep 12: ep_len:500 episode reward: total was -19.950000. running mean: -26.678057\n",
      "ep 12: ep_len:770 episode reward: total was -87.390000. running mean: -27.285176\n",
      "ep 12: ep_len:500 episode reward: total was -22.700000. running mean: -27.239325\n",
      "ep 12: ep_len:695 episode reward: total was -58.250000. running mean: -27.549431\n",
      "ep 12: ep_len:640 episode reward: total was -27.020000. running mean: -27.544137\n",
      "ep 12: ep_len:680 episode reward: total was -39.090000. running mean: -27.659596\n",
      "ep 12: ep_len:500 episode reward: total was -12.250000. running mean: -27.505500\n",
      "ep 12: ep_len:510 episode reward: total was -41.450000. running mean: -27.644945\n",
      "ep 12: ep_len:625 episode reward: total was -56.910000. running mean: -27.937595\n",
      "ep 12: ep_len:760 episode reward: total was -31.860000. running mean: -27.976819\n",
      "ep 12: ep_len:940 episode reward: total was -12.130000. running mean: -27.818351\n",
      "ep 12: ep_len:935 episode reward: total was -29.500000. running mean: -27.835168\n",
      "ep 12: ep_len:500 episode reward: total was 20.500000. running mean: -27.351816\n",
      "ep 12: ep_len:535 episode reward: total was -32.310000. running mean: -27.401398\n",
      "ep 12: ep_len:500 episode reward: total was -6.020000. running mean: -27.187584\n",
      "ep 12: ep_len:500 episode reward: total was -6.260000. running mean: -26.978308\n",
      "ep 12: ep_len:840 episode reward: total was -27.470000. running mean: -26.983225\n",
      "ep 12: ep_len:500 episode reward: total was -26.590000. running mean: -26.979293\n",
      "ep 12: ep_len:585 episode reward: total was -42.310000. running mean: -27.132600\n",
      "ep 12: ep_len:605 episode reward: total was -47.320000. running mean: -27.334474\n",
      "ep 12: ep_len:485 episode reward: total was 8.190000. running mean: -26.979229\n",
      "ep 12: ep_len:710 episode reward: total was -61.220000. running mean: -27.321637\n",
      "ep 12: ep_len:166 episode reward: total was 6.500000. running mean: -26.983420\n",
      "ep 12: ep_len:650 episode reward: total was -35.080000. running mean: -27.064386\n",
      "ep 12: ep_len:500 episode reward: total was -4.730000. running mean: -26.841042\n",
      "ep 12: ep_len:840 episode reward: total was -39.940000. running mean: -26.972032\n",
      "ep 12: ep_len:204 episode reward: total was 8.000000. running mean: -26.622311\n",
      "ep 12: ep_len:500 episode reward: total was -25.360000. running mean: -26.609688\n",
      "ep 12: ep_len:168 episode reward: total was 8.000000. running mean: -26.263591\n",
      "ep 12: ep_len:700 episode reward: total was -35.500000. running mean: -26.355956\n",
      "ep 12: ep_len:500 episode reward: total was 2.680000. running mean: -26.065596\n",
      "ep 12: ep_len:500 episode reward: total was -6.250000. running mean: -25.867440\n",
      "ep 12: ep_len:740 episode reward: total was -48.060000. running mean: -26.089366\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 12: ep_len:1020 episode reward: total was -26.920000. running mean: -26.097672\n",
      "ep 12: ep_len:790 episode reward: total was -37.790000. running mean: -26.214595\n",
      "ep 12: ep_len:640 episode reward: total was -16.390000. running mean: -26.116349\n",
      "ep 12: ep_len:690 episode reward: total was -25.420000. running mean: -26.109386\n",
      "ep 12: ep_len:215 episode reward: total was 11.000000. running mean: -25.738292\n",
      "ep 12: ep_len:505 episode reward: total was -1.350000. running mean: -25.494409\n",
      "ep 12: ep_len:500 episode reward: total was -47.730000. running mean: -25.716765\n",
      "ep 12: ep_len:500 episode reward: total was -8.250000. running mean: -25.542097\n",
      "ep 12: ep_len:114 episode reward: total was 5.000000. running mean: -25.236676\n",
      "ep 12: ep_len:500 episode reward: total was -5.450000. running mean: -25.038810\n",
      "ep 12: ep_len:635 episode reward: total was -37.130000. running mean: -25.159721\n",
      "ep 12: ep_len:505 episode reward: total was -27.530000. running mean: -25.183424\n",
      "ep 12: ep_len:8760 episode reward: total was -1693.130000. running mean: -41.862890\n",
      "ep 12: ep_len:186 episode reward: total was 9.500000. running mean: -41.349261\n",
      "ep 12: ep_len:820 episode reward: total was -20.830000. running mean: -41.144069\n",
      "ep 12: ep_len:500 episode reward: total was -8.700000. running mean: -40.819628\n",
      "ep 12: ep_len:392 episode reward: total was 17.500000. running mean: -40.236432\n",
      "ep 12: ep_len:715 episode reward: total was -30.310000. running mean: -40.137167\n",
      "ep 12: ep_len:500 episode reward: total was -9.340000. running mean: -39.829196\n",
      "ep 12: ep_len:565 episode reward: total was -17.860000. running mean: -39.609504\n",
      "ep 12: ep_len:1015 episode reward: total was -26.980000. running mean: -39.483209\n",
      "ep 12: ep_len:575 episode reward: total was -56.450000. running mean: -39.652876\n",
      "ep 12: ep_len:500 episode reward: total was -46.730000. running mean: -39.723648\n",
      "ep 12: ep_len:500 episode reward: total was 1.270000. running mean: -39.313711\n",
      "ep 12: ep_len:1105 episode reward: total was -80.290000. running mean: -39.723474\n",
      "ep 12: ep_len:500 episode reward: total was -12.290000. running mean: -39.449139\n",
      "ep 12: ep_len:930 episode reward: total was -24.150000. running mean: -39.296148\n",
      "ep 12: ep_len:500 episode reward: total was 12.700000. running mean: -38.776187\n",
      "ep 12: ep_len:1190 episode reward: total was -116.850000. running mean: -39.556925\n",
      "ep 12: ep_len:500 episode reward: total was 4.760000. running mean: -39.113755\n",
      "ep 12: ep_len:500 episode reward: total was -9.690000. running mean: -38.819518\n",
      "ep 12: ep_len:530 episode reward: total was -24.880000. running mean: -38.680123\n",
      "ep 12: ep_len:406 episode reward: total was -26.890000. running mean: -38.562221\n",
      "ep 12: ep_len:500 episode reward: total was -9.220000. running mean: -38.268799\n",
      "ep 12: ep_len:525 episode reward: total was -43.440000. running mean: -38.320511\n",
      "ep 12: ep_len:635 episode reward: total was -75.540000. running mean: -38.692706\n",
      "ep 12: ep_len:500 episode reward: total was -8.950000. running mean: -38.395279\n",
      "ep 12: ep_len:535 episode reward: total was -9.870000. running mean: -38.110026\n",
      "ep 12: ep_len:540 episode reward: total was -30.980000. running mean: -38.038726\n",
      "ep 12: ep_len:36 episode reward: total was -2.500000. running mean: -37.683339\n",
      "ep 12: ep_len:500 episode reward: total was 0.260000. running mean: -37.303905\n",
      "ep 12: ep_len:505 episode reward: total was 4.680000. running mean: -36.884066\n",
      "ep 12: ep_len:615 episode reward: total was -25.570000. running mean: -36.770926\n",
      "ep 12: ep_len:500 episode reward: total was -21.190000. running mean: -36.615116\n",
      "ep 12: ep_len:500 episode reward: total was -5.500000. running mean: -36.303965\n",
      "ep 12: ep_len:500 episode reward: total was -28.980000. running mean: -36.230726\n",
      "ep 12: ep_len:950 episode reward: total was -22.040000. running mean: -36.088818\n",
      "ep 12: ep_len:780 episode reward: total was -56.030000. running mean: -36.288230\n",
      "ep 12: ep_len:785 episode reward: total was -10.710000. running mean: -36.032448\n",
      "ep 12: ep_len:500 episode reward: total was 1.680000. running mean: -35.655323\n",
      "ep 12: ep_len:665 episode reward: total was -79.650000. running mean: -36.095270\n",
      "ep 12: ep_len:590 episode reward: total was 4.270000. running mean: -35.691617\n",
      "ep 12: ep_len:660 episode reward: total was -25.110000. running mean: -35.585801\n",
      "ep 12: ep_len:483 episode reward: total was 4.750000. running mean: -35.182443\n",
      "ep 12: ep_len:458 episode reward: total was 18.000000. running mean: -34.650619\n",
      "ep 12: ep_len:625 episode reward: total was -17.920000. running mean: -34.483313\n",
      "ep 12: ep_len:515 episode reward: total was -31.310000. running mean: -34.451579\n",
      "ep 12: ep_len:500 episode reward: total was -33.910000. running mean: -34.446164\n",
      "ep 12: ep_len:780 episode reward: total was -42.900000. running mean: -34.530702\n",
      "ep 12: ep_len:780 episode reward: total was -95.450000. running mean: -35.139895\n",
      "ep 12: ep_len:635 episode reward: total was -32.110000. running mean: -35.109596\n",
      "ep 12: ep_len:500 episode reward: total was -9.020000. running mean: -34.848700\n",
      "ep 12: ep_len:595 episode reward: total was -25.470000. running mean: -34.754913\n",
      "ep 12: ep_len:735 episode reward: total was -33.930000. running mean: -34.746664\n",
      "ep 12: ep_len:500 episode reward: total was 0.780000. running mean: -34.391397\n",
      "ep 12: ep_len:740 episode reward: total was -30.460000. running mean: -34.352083\n",
      "ep 12: ep_len:620 episode reward: total was -34.430000. running mean: -34.352863\n",
      "ep 12: ep_len:188 episode reward: total was 8.000000. running mean: -33.929334\n",
      "ep 12: ep_len:680 episode reward: total was -32.020000. running mean: -33.910241\n",
      "ep 12: ep_len:685 episode reward: total was -35.040000. running mean: -33.921538\n",
      "ep 12: ep_len:875 episode reward: total was -35.770000. running mean: -33.940023\n",
      "ep 12: ep_len:1265 episode reward: total was -147.700000. running mean: -35.077623\n",
      "ep 12: ep_len:695 episode reward: total was -12.270000. running mean: -34.849546\n",
      "ep 12: ep_len:615 episode reward: total was -16.750000. running mean: -34.668551\n",
      "ep 12: ep_len:500 episode reward: total was 6.790000. running mean: -34.253965\n",
      "ep 12: ep_len:479 episode reward: total was -5.230000. running mean: -33.963726\n",
      "ep 12: ep_len:560 episode reward: total was -76.730000. running mean: -34.391388\n",
      "ep 12: ep_len:505 episode reward: total was -39.930000. running mean: -34.446775\n",
      "ep 12: ep_len:115 episode reward: total was 5.500000. running mean: -34.047307\n",
      "ep 12: ep_len:525 episode reward: total was -24.740000. running mean: -33.954234\n",
      "ep 12: ep_len:500 episode reward: total was -38.960000. running mean: -34.004291\n",
      "ep 12: ep_len:505 episode reward: total was -23.660000. running mean: -33.900848\n",
      "ep 12: ep_len:2505 episode reward: total was -376.660000. running mean: -37.328440\n",
      "ep 12: ep_len:500 episode reward: total was 5.740000. running mean: -36.897756\n",
      "ep 12: ep_len:5460 episode reward: total was -834.080000. running mean: -44.869578\n",
      "ep 12: ep_len:922 episode reward: total was -103.720000. running mean: -45.458082\n",
      "ep 12: ep_len:500 episode reward: total was -27.850000. running mean: -45.282001\n",
      "ep 12: ep_len:500 episode reward: total was -17.060000. running mean: -44.999781\n",
      "ep 12: ep_len:500 episode reward: total was 20.500000. running mean: -44.344784\n",
      "ep 12: ep_len:431 episode reward: total was -12.980000. running mean: -44.031136\n",
      "ep 12: ep_len:635 episode reward: total was -33.610000. running mean: -43.926924\n",
      "epsilon:0.200125 episode_count: 10250. steps_count: 7211600.000000\n",
      "ep 13: ep_len:500 episode reward: total was 7.270000. running mean: -43.414955\n",
      "ep 13: ep_len:815 episode reward: total was -58.010000. running mean: -43.560906\n",
      "ep 13: ep_len:500 episode reward: total was -35.680000. running mean: -43.482097\n",
      "ep 13: ep_len:970 episode reward: total was -112.240000. running mean: -44.169676\n",
      "ep 13: ep_len:845 episode reward: total was -12.390000. running mean: -43.851879\n",
      "ep 13: ep_len:655 episode reward: total was -41.150000. running mean: -43.824860\n",
      "ep 13: ep_len:755 episode reward: total was -56.080000. running mean: -43.947411\n",
      "ep 13: ep_len:500 episode reward: total was -12.290000. running mean: -43.630837\n",
      "ep 13: ep_len:805 episode reward: total was -70.640000. running mean: -43.900929\n",
      "ep 13: ep_len:500 episode reward: total was 0.200000. running mean: -43.459920\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 13: ep_len:655 episode reward: total was -9.960000. running mean: -43.124920\n",
      "ep 13: ep_len:500 episode reward: total was 9.780000. running mean: -42.595871\n",
      "ep 13: ep_len:505 episode reward: total was -19.910000. running mean: -42.369013\n",
      "ep 13: ep_len:216 episode reward: total was 14.000000. running mean: -41.805322\n",
      "ep 13: ep_len:860 episode reward: total was -64.990000. running mean: -42.037169\n",
      "ep 13: ep_len:815 episode reward: total was -69.120000. running mean: -42.307998\n",
      "ep 13: ep_len:500 episode reward: total was 3.230000. running mean: -41.852618\n",
      "ep 13: ep_len:670 episode reward: total was -31.030000. running mean: -41.744391\n",
      "ep 13: ep_len:640 episode reward: total was -61.340000. running mean: -41.940347\n",
      "ep 13: ep_len:500 episode reward: total was -22.770000. running mean: -41.748644\n",
      "ep 13: ep_len:500 episode reward: total was -18.750000. running mean: -41.518658\n",
      "ep 13: ep_len:1390 episode reward: total was -164.410000. running mean: -42.747571\n",
      "ep 13: ep_len:1055 episode reward: total was -91.530000. running mean: -43.235395\n",
      "ep 13: ep_len:1675 episode reward: total was -159.280000. running mean: -44.395841\n",
      "ep 13: ep_len:479 episode reward: total was 3.270000. running mean: -43.919183\n",
      "ep 13: ep_len:112 episode reward: total was 9.500000. running mean: -43.384991\n",
      "ep 13: ep_len:570 episode reward: total was -57.270000. running mean: -43.523841\n",
      "ep 13: ep_len:500 episode reward: total was 9.260000. running mean: -42.996003\n",
      "ep 13: ep_len:14170 episode reward: total was -2453.770000. running mean: -67.103743\n",
      "ep 13: ep_len:830 episode reward: total was -34.440000. running mean: -66.777105\n",
      "ep 13: ep_len:500 episode reward: total was 13.240000. running mean: -65.976934\n",
      "ep 13: ep_len:820 episode reward: total was -38.880000. running mean: -65.705965\n",
      "ep 13: ep_len:305 episode reward: total was 15.500000. running mean: -64.893905\n",
      "ep 13: ep_len:595 episode reward: total was -8.370000. running mean: -64.328666\n",
      "ep 13: ep_len:815 episode reward: total was -25.730000. running mean: -63.942680\n",
      "ep 13: ep_len:575 episode reward: total was -69.490000. running mean: -63.998153\n",
      "ep 13: ep_len:645 episode reward: total was -27.430000. running mean: -63.632471\n",
      "ep 13: ep_len:980 episode reward: total was -44.200000. running mean: -63.438147\n",
      "ep 13: ep_len:570 episode reward: total was -50.420000. running mean: -63.307965\n",
      "ep 13: ep_len:487 episode reward: total was 2.110000. running mean: -62.653785\n",
      "ep 13: ep_len:500 episode reward: total was -23.130000. running mean: -62.258548\n",
      "ep 13: ep_len:720 episode reward: total was -46.650000. running mean: -62.102462\n",
      "ep 13: ep_len:500 episode reward: total was -45.510000. running mean: -61.936537\n",
      "ep 13: ep_len:520 episode reward: total was -50.520000. running mean: -61.822372\n",
      "ep 13: ep_len:500 episode reward: total was -7.330000. running mean: -61.277448\n",
      "ep 13: ep_len:500 episode reward: total was -22.280000. running mean: -60.887474\n",
      "ep 13: ep_len:158 episode reward: total was 13.000000. running mean: -60.148599\n",
      "ep 13: ep_len:500 episode reward: total was -10.820000. running mean: -59.655313\n",
      "ep 13: ep_len:700 episode reward: total was -30.450000. running mean: -59.363260\n",
      "ep 13: ep_len:1100 episode reward: total was -37.690000. running mean: -59.146527\n",
      "ep 13: ep_len:670 episode reward: total was -45.170000. running mean: -59.006762\n",
      "ep 13: ep_len:217 episode reward: total was 6.500000. running mean: -58.351695\n",
      "ep 13: ep_len:780 episode reward: total was -64.140000. running mean: -58.409578\n",
      "ep 13: ep_len:595 episode reward: total was 4.770000. running mean: -57.777782\n",
      "ep 13: ep_len:500 episode reward: total was -48.600000. running mean: -57.686004\n",
      "ep 13: ep_len:645 episode reward: total was -44.210000. running mean: -57.551244\n",
      "ep 13: ep_len:158 episode reward: total was 12.500000. running mean: -56.850731\n",
      "ep 13: ep_len:805 episode reward: total was -31.870000. running mean: -56.600924\n",
      "ep 13: ep_len:1005 episode reward: total was -36.550000. running mean: -56.400415\n",
      "ep 13: ep_len:700 episode reward: total was -10.570000. running mean: -55.942111\n",
      "ep 13: ep_len:267 episode reward: total was 19.500000. running mean: -55.187690\n",
      "ep 13: ep_len:900 episode reward: total was -82.630000. running mean: -55.462113\n",
      "ep 13: ep_len:600 episode reward: total was -21.070000. running mean: -55.118192\n",
      "ep 13: ep_len:540 episode reward: total was -27.250000. running mean: -54.839510\n",
      "ep 13: ep_len:130 episode reward: total was 0.000000. running mean: -54.291115\n",
      "ep 13: ep_len:660 episode reward: total was -28.000000. running mean: -54.028203\n",
      "ep 13: ep_len:500 episode reward: total was 7.700000. running mean: -53.410921\n",
      "ep 13: ep_len:1210 episode reward: total was -78.730000. running mean: -53.664112\n",
      "ep 13: ep_len:595 episode reward: total was -76.110000. running mean: -53.888571\n",
      "ep 13: ep_len:525 episode reward: total was -47.970000. running mean: -53.829385\n",
      "ep 13: ep_len:285 episode reward: total was -16.000000. running mean: -53.451092\n",
      "ep 13: ep_len:436 episode reward: total was -32.500000. running mean: -53.241581\n",
      "ep 13: ep_len:575 episode reward: total was 13.760000. running mean: -52.571565\n",
      "ep 13: ep_len:500 episode reward: total was -14.990000. running mean: -52.195749\n",
      "ep 13: ep_len:530 episode reward: total was -30.010000. running mean: -51.973892\n",
      "ep 13: ep_len:510 episode reward: total was -63.670000. running mean: -52.090853\n",
      "ep 13: ep_len:510 episode reward: total was -0.380000. running mean: -51.573744\n",
      "ep 13: ep_len:665 episode reward: total was -0.780000. running mean: -51.065807\n",
      "ep 13: ep_len:1845 episode reward: total was -256.940000. running mean: -53.124549\n",
      "ep 13: ep_len:555 episode reward: total was -70.800000. running mean: -53.301303\n",
      "ep 13: ep_len:500 episode reward: total was 11.220000. running mean: -52.656090\n",
      "ep 13: ep_len:500 episode reward: total was -9.770000. running mean: -52.227229\n",
      "ep 13: ep_len:650 episode reward: total was -41.170000. running mean: -52.116657\n",
      "ep 13: ep_len:720 episode reward: total was -42.430000. running mean: -52.019790\n",
      "ep 13: ep_len:252 episode reward: total was 12.500000. running mean: -51.374593\n",
      "ep 13: ep_len:500 episode reward: total was -50.670000. running mean: -51.367547\n",
      "ep 13: ep_len:650 episode reward: total was -44.380000. running mean: -51.297671\n",
      "ep 13: ep_len:500 episode reward: total was -21.220000. running mean: -50.996894\n",
      "ep 13: ep_len:510 episode reward: total was -1.250000. running mean: -50.499425\n",
      "ep 13: ep_len:670 episode reward: total was -29.010000. running mean: -50.284531\n",
      "ep 13: ep_len:500 episode reward: total was -20.040000. running mean: -49.982086\n",
      "ep 13: ep_len:2067 episode reward: total was -216.050000. running mean: -51.642765\n",
      "ep 13: ep_len:1020 episode reward: total was -37.130000. running mean: -51.497637\n",
      "ep 13: ep_len:615 episode reward: total was -58.410000. running mean: -51.566761\n",
      "ep 13: ep_len:500 episode reward: total was -4.240000. running mean: -51.093493\n",
      "ep 13: ep_len:680 episode reward: total was -51.210000. running mean: -51.094658\n",
      "ep 13: ep_len:136 episode reward: total was 10.500000. running mean: -50.478712\n",
      "ep 13: ep_len:500 episode reward: total was -20.900000. running mean: -50.182925\n",
      "ep 13: ep_len:500 episode reward: total was 2.720000. running mean: -49.653896\n",
      "ep 13: ep_len:500 episode reward: total was -27.910000. running mean: -49.436457\n",
      "ep 13: ep_len:700 episode reward: total was -40.060000. running mean: -49.342692\n",
      "ep 13: ep_len:510 episode reward: total was 2.250000. running mean: -48.826765\n",
      "ep 13: ep_len:151 episode reward: total was 9.000000. running mean: -48.248497\n",
      "ep 13: ep_len:660 episode reward: total was -68.420000. running mean: -48.450212\n",
      "ep 13: ep_len:505 episode reward: total was -36.410000. running mean: -48.329810\n",
      "ep 13: ep_len:530 episode reward: total was -64.120000. running mean: -48.487712\n",
      "ep 13: ep_len:307 episode reward: total was -15.500000. running mean: -48.157835\n",
      "ep 13: ep_len:555 episode reward: total was -25.200000. running mean: -47.928257\n",
      "ep 13: ep_len:570 episode reward: total was -32.730000. running mean: -47.776274\n",
      "ep 13: ep_len:630 episode reward: total was -51.860000. running mean: -47.817111\n",
      "ep 13: ep_len:125 episode reward: total was 4.000000. running mean: -47.298940\n",
      "ep 13: ep_len:750 episode reward: total was -42.400000. running mean: -47.249951\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 13: ep_len:915 episode reward: total was -54.390000. running mean: -47.321351\n",
      "ep 13: ep_len:515 episode reward: total was 8.000000. running mean: -46.768138\n",
      "ep 13: ep_len:500 episode reward: total was 17.130000. running mean: -46.129157\n",
      "ep 13: ep_len:740 episode reward: total was -36.430000. running mean: -46.032165\n",
      "ep 13: ep_len:209 episode reward: total was 13.500000. running mean: -45.436843\n",
      "ep 13: ep_len:910 episode reward: total was -58.830000. running mean: -45.570775\n",
      "ep 13: ep_len:665 episode reward: total was -37.590000. running mean: -45.490967\n",
      "ep 13: ep_len:755 episode reward: total was -35.770000. running mean: -45.393757\n",
      "ep 13: ep_len:725 episode reward: total was -110.710000. running mean: -46.046920\n",
      "ep 13: ep_len:895 episode reward: total was -23.640000. running mean: -45.822851\n",
      "ep 13: ep_len:740 episode reward: total was -67.610000. running mean: -46.040722\n",
      "ep 13: ep_len:515 episode reward: total was 30.500000. running mean: -45.275315\n",
      "ep 13: ep_len:500 episode reward: total was -25.030000. running mean: -45.072862\n",
      "ep 13: ep_len:770 episode reward: total was -28.810000. running mean: -44.910233\n",
      "ep 13: ep_len:885 episode reward: total was -64.940000. running mean: -45.110531\n",
      "ep 13: ep_len:500 episode reward: total was -25.760000. running mean: -44.917026\n",
      "ep 13: ep_len:700 episode reward: total was -41.070000. running mean: -44.878555\n",
      "ep 13: ep_len:740 episode reward: total was -28.710000. running mean: -44.716870\n",
      "ep 13: ep_len:900 episode reward: total was -57.340000. running mean: -44.843101\n",
      "ep 13: ep_len:955 episode reward: total was -46.510000. running mean: -44.859770\n",
      "ep 13: ep_len:233 episode reward: total was 13.000000. running mean: -44.281172\n",
      "ep 13: ep_len:740 episode reward: total was -42.080000. running mean: -44.259161\n",
      "ep 13: ep_len:955 episode reward: total was -31.180000. running mean: -44.128369\n",
      "ep 13: ep_len:500 episode reward: total was 7.760000. running mean: -43.609485\n",
      "ep 13: ep_len:500 episode reward: total was 3.070000. running mean: -43.142690\n",
      "ep 13: ep_len:500 episode reward: total was -19.730000. running mean: -42.908564\n",
      "ep 13: ep_len:490 episode reward: total was 20.010000. running mean: -42.279378\n",
      "ep 13: ep_len:500 episode reward: total was -12.220000. running mean: -41.978784\n",
      "ep 13: ep_len:500 episode reward: total was 24.500000. running mean: -41.313996\n",
      "ep 13: ep_len:388 episode reward: total was 20.500000. running mean: -40.695856\n",
      "ep 13: ep_len:895 episode reward: total was -24.220000. running mean: -40.531098\n",
      "ep 13: ep_len:1425 episode reward: total was -113.350000. running mean: -41.259287\n",
      "ep 13: ep_len:500 episode reward: total was 6.690000. running mean: -40.779794\n",
      "ep 13: ep_len:500 episode reward: total was -28.400000. running mean: -40.655996\n",
      "ep 13: ep_len:147 episode reward: total was 1.000000. running mean: -40.239436\n",
      "ep 13: ep_len:500 episode reward: total was 24.500000. running mean: -39.592042\n",
      "ep 13: ep_len:505 episode reward: total was -18.210000. running mean: -39.378221\n",
      "ep 13: ep_len:705 episode reward: total was -25.910000. running mean: -39.243539\n",
      "ep 13: ep_len:510 episode reward: total was -26.730000. running mean: -39.118404\n",
      "ep 13: ep_len:250 episode reward: total was 14.500000. running mean: -38.582220\n",
      "ep 13: ep_len:515 episode reward: total was -43.950000. running mean: -38.635897\n",
      "ep 13: ep_len:625 episode reward: total was -45.260000. running mean: -38.702138\n",
      "ep 13: ep_len:540 episode reward: total was -52.180000. running mean: -38.836917\n",
      "ep 13: ep_len:505 episode reward: total was -14.850000. running mean: -38.597048\n",
      "ep 13: ep_len:505 episode reward: total was -10.200000. running mean: -38.313077\n",
      "ep 13: ep_len:500 episode reward: total was -32.440000. running mean: -38.254347\n",
      "ep 13: ep_len:590 episode reward: total was -1.220000. running mean: -37.884003\n",
      "ep 13: ep_len:840 episode reward: total was -35.860000. running mean: -37.863763\n",
      "ep 13: ep_len:500 episode reward: total was 4.700000. running mean: -37.438126\n",
      "ep 13: ep_len:300 episode reward: total was -3.330000. running mean: -37.097044\n",
      "ep 13: ep_len:505 episode reward: total was -11.450000. running mean: -36.840574\n",
      "ep 13: ep_len:500 episode reward: total was 1.240000. running mean: -36.459768\n",
      "ep 13: ep_len:500 episode reward: total was -9.620000. running mean: -36.191370\n",
      "ep 13: ep_len:660 episode reward: total was -35.070000. running mean: -36.180157\n",
      "ep 13: ep_len:227 episode reward: total was 9.000000. running mean: -35.728355\n",
      "ep 13: ep_len:715 episode reward: total was -42.020000. running mean: -35.791272\n",
      "ep 13: ep_len:610 episode reward: total was -40.730000. running mean: -35.840659\n",
      "ep 13: ep_len:500 episode reward: total was 12.720000. running mean: -35.355052\n",
      "ep 13: ep_len:500 episode reward: total was 0.840000. running mean: -34.993102\n",
      "ep 13: ep_len:675 episode reward: total was -28.050000. running mean: -34.923671\n",
      "ep 13: ep_len:500 episode reward: total was -26.350000. running mean: -34.837934\n",
      "ep 13: ep_len:965 episode reward: total was -28.900000. running mean: -34.778555\n",
      "ep 13: ep_len:500 episode reward: total was -2.950000. running mean: -34.460269\n",
      "ep 13: ep_len:500 episode reward: total was -20.300000. running mean: -34.318666\n",
      "ep 13: ep_len:965 episode reward: total was -15.860000. running mean: -34.134080\n",
      "ep 13: ep_len:500 episode reward: total was -36.540000. running mean: -34.158139\n",
      "ep 13: ep_len:725 episode reward: total was -34.960000. running mean: -34.166158\n",
      "ep 13: ep_len:146 episode reward: total was 7.000000. running mean: -33.754496\n",
      "ep 13: ep_len:500 episode reward: total was -15.740000. running mean: -33.574351\n",
      "ep 13: ep_len:230 episode reward: total was 6.500000. running mean: -33.173608\n",
      "ep 13: ep_len:805 episode reward: total was -48.630000. running mean: -33.328171\n",
      "ep 13: ep_len:500 episode reward: total was 26.000000. running mean: -32.734890\n",
      "ep 13: ep_len:805 episode reward: total was -18.810000. running mean: -32.595641\n",
      "ep 13: ep_len:500 episode reward: total was -38.990000. running mean: -32.659584\n",
      "ep 13: ep_len:720 episode reward: total was -10.220000. running mean: -32.435189\n",
      "ep 13: ep_len:500 episode reward: total was -2.250000. running mean: -32.133337\n",
      "ep 13: ep_len:500 episode reward: total was -58.700000. running mean: -32.399003\n",
      "ep 13: ep_len:249 episode reward: total was 12.500000. running mean: -31.950013\n",
      "ep 13: ep_len:500 episode reward: total was -15.410000. running mean: -31.784613\n",
      "ep 13: ep_len:555 episode reward: total was -30.250000. running mean: -31.769267\n",
      "ep 13: ep_len:500 episode reward: total was 4.770000. running mean: -31.403874\n",
      "ep 13: ep_len:500 episode reward: total was 1.220000. running mean: -31.077636\n",
      "ep 13: ep_len:510 episode reward: total was -12.770000. running mean: -30.894559\n",
      "ep 13: ep_len:535 episode reward: total was -8.300000. running mean: -30.668614\n",
      "ep 13: ep_len:685 episode reward: total was -29.990000. running mean: -30.661828\n",
      "ep 13: ep_len:161 episode reward: total was 13.000000. running mean: -30.225209\n",
      "ep 13: ep_len:955 episode reward: total was -28.860000. running mean: -30.211557\n",
      "ep 13: ep_len:188 episode reward: total was 6.500000. running mean: -29.844442\n",
      "ep 13: ep_len:500 episode reward: total was 2.260000. running mean: -29.523397\n",
      "ep 13: ep_len:545 episode reward: total was -21.560000. running mean: -29.443763\n",
      "ep 13: ep_len:1680 episode reward: total was -261.310000. running mean: -31.762426\n",
      "ep 13: ep_len:500 episode reward: total was 1.240000. running mean: -31.432401\n",
      "ep 13: ep_len:500 episode reward: total was 2.800000. running mean: -31.090077\n",
      "ep 13: ep_len:805 episode reward: total was -28.060000. running mean: -31.059777\n",
      "ep 13: ep_len:1075 episode reward: total was -31.000000. running mean: -31.059179\n",
      "ep 13: ep_len:505 episode reward: total was 4.710000. running mean: -30.701487\n",
      "ep 13: ep_len:620 episode reward: total was -40.710000. running mean: -30.801572\n",
      "ep 13: ep_len:570 episode reward: total was -22.140000. running mean: -30.714956\n",
      "ep 13: ep_len:500 episode reward: total was -11.780000. running mean: -30.525607\n",
      "ep 13: ep_len:565 episode reward: total was -2.000000. running mean: -30.240351\n",
      "ep 13: ep_len:820 episode reward: total was -47.500000. running mean: -30.412947\n",
      "ep 13: ep_len:4460 episode reward: total was -694.900000. running mean: -37.057818\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 13: ep_len:505 episode reward: total was 6.250000. running mean: -36.624740\n",
      "ep 13: ep_len:500 episode reward: total was -13.530000. running mean: -36.393792\n",
      "ep 13: ep_len:905 episode reward: total was -73.210000. running mean: -36.761954\n",
      "ep 13: ep_len:1225 episode reward: total was -142.820000. running mean: -37.822535\n",
      "ep 13: ep_len:137 episode reward: total was 7.500000. running mean: -37.369309\n",
      "ep 13: ep_len:500 episode reward: total was -6.510000. running mean: -37.060716\n",
      "ep 13: ep_len:810 episode reward: total was -44.410000. running mean: -37.134209\n",
      "ep 13: ep_len:505 episode reward: total was -11.460000. running mean: -36.877467\n",
      "ep 13: ep_len:510 episode reward: total was -19.470000. running mean: -36.703392\n",
      "ep 13: ep_len:1080 episode reward: total was -50.850000. running mean: -36.844858\n",
      "ep 13: ep_len:585 episode reward: total was -66.520000. running mean: -37.141610\n",
      "ep 13: ep_len:500 episode reward: total was 3.230000. running mean: -36.737894\n",
      "ep 13: ep_len:220 episode reward: total was 5.500000. running mean: -36.315515\n",
      "ep 13: ep_len:710 episode reward: total was -11.190000. running mean: -36.064260\n",
      "ep 13: ep_len:745 episode reward: total was -36.420000. running mean: -36.067817\n",
      "ep 13: ep_len:715 episode reward: total was -31.950000. running mean: -36.026639\n",
      "ep 13: ep_len:755 episode reward: total was -43.070000. running mean: -36.097073\n",
      "ep 13: ep_len:500 episode reward: total was -22.980000. running mean: -35.965902\n",
      "ep 13: ep_len:500 episode reward: total was -5.770000. running mean: -35.663943\n",
      "ep 13: ep_len:825 episode reward: total was -2.880000. running mean: -35.336103\n",
      "ep 13: ep_len:478 episode reward: total was 7.220000. running mean: -34.910542\n",
      "ep 13: ep_len:605 episode reward: total was -16.800000. running mean: -34.729437\n",
      "ep 13: ep_len:500 episode reward: total was -13.310000. running mean: -34.515243\n",
      "ep 13: ep_len:1015 episode reward: total was -4.830000. running mean: -34.218390\n",
      "ep 13: ep_len:520 episode reward: total was -2.270000. running mean: -33.898906\n",
      "ep 13: ep_len:505 episode reward: total was -45.500000. running mean: -34.014917\n",
      "ep 13: ep_len:500 episode reward: total was 1.760000. running mean: -33.657168\n",
      "ep 13: ep_len:900 episode reward: total was -46.410000. running mean: -33.784696\n",
      "ep 13: ep_len:740 episode reward: total was 2.090000. running mean: -33.425949\n",
      "ep 13: ep_len:775 episode reward: total was -45.450000. running mean: -33.546190\n",
      "ep 13: ep_len:500 episode reward: total was -18.550000. running mean: -33.396228\n",
      "ep 13: ep_len:500 episode reward: total was 10.640000. running mean: -32.955866\n",
      "ep 13: ep_len:710 episode reward: total was -20.330000. running mean: -32.829607\n",
      "ep 13: ep_len:725 episode reward: total was -33.950000. running mean: -32.840811\n",
      "ep 13: ep_len:615 episode reward: total was -18.990000. running mean: -32.702303\n",
      "ep 13: ep_len:535 episode reward: total was -5.240000. running mean: -32.427680\n",
      "ep 13: ep_len:645 episode reward: total was -24.010000. running mean: -32.343503\n",
      "ep 13: ep_len:500 episode reward: total was -0.660000. running mean: -32.026668\n",
      "ep 13: ep_len:216 episode reward: total was 11.000000. running mean: -31.596401\n",
      "ep 13: ep_len:795 episode reward: total was -42.870000. running mean: -31.709137\n",
      "ep 13: ep_len:500 episode reward: total was -3.110000. running mean: -31.423146\n",
      "ep 13: ep_len:745 episode reward: total was -18.760000. running mean: -31.296514\n",
      "ep 13: ep_len:715 episode reward: total was 2.020000. running mean: -30.963349\n",
      "ep 13: ep_len:660 episode reward: total was -12.250000. running mean: -30.776216\n",
      "ep 13: ep_len:1055 episode reward: total was -42.340000. running mean: -30.891854\n",
      "ep 13: ep_len:800 episode reward: total was -29.220000. running mean: -30.875135\n",
      "ep 13: ep_len:550 episode reward: total was -28.860000. running mean: -30.854984\n",
      "ep 13: ep_len:1095 episode reward: total was -84.700000. running mean: -31.393434\n",
      "ep 13: ep_len:655 episode reward: total was -30.400000. running mean: -31.383500\n",
      "ep 13: ep_len:505 episode reward: total was -19.660000. running mean: -31.266265\n",
      "ep 13: ep_len:500 episode reward: total was -24.480000. running mean: -31.198402\n",
      "ep 13: ep_len:266 episode reward: total was 17.500000. running mean: -30.711418\n",
      "ep 13: ep_len:500 episode reward: total was -11.920000. running mean: -30.523504\n",
      "ep 13: ep_len:500 episode reward: total was -6.770000. running mean: -30.285969\n",
      "ep 13: ep_len:670 episode reward: total was -7.880000. running mean: -30.061909\n",
      "ep 13: ep_len:500 episode reward: total was -20.350000. running mean: -29.964790\n",
      "ep 13: ep_len:975 episode reward: total was -44.810000. running mean: -30.113242\n",
      "ep 13: ep_len:565 episode reward: total was -21.630000. running mean: -30.028410\n",
      "ep 13: ep_len:705 episode reward: total was -24.900000. running mean: -29.977126\n",
      "ep 13: ep_len:695 episode reward: total was -51.250000. running mean: -30.189854\n",
      "ep 13: ep_len:925 episode reward: total was -19.360000. running mean: -30.081556\n",
      "ep 13: ep_len:500 episode reward: total was -30.080000. running mean: -30.081540\n",
      "ep 13: ep_len:500 episode reward: total was -21.970000. running mean: -30.000425\n",
      "ep 13: ep_len:820 episode reward: total was -5.420000. running mean: -29.754621\n",
      "ep 13: ep_len:500 episode reward: total was -3.570000. running mean: -29.492774\n",
      "ep 13: ep_len:605 episode reward: total was -6.750000. running mean: -29.265347\n",
      "ep 13: ep_len:500 episode reward: total was 16.750000. running mean: -28.805193\n",
      "ep 13: ep_len:505 episode reward: total was -25.420000. running mean: -28.771341\n",
      "ep 13: ep_len:1225 episode reward: total was -150.600000. running mean: -29.989628\n",
      "ep 13: ep_len:500 episode reward: total was -0.350000. running mean: -29.693231\n",
      "ep 13: ep_len:500 episode reward: total was -0.290000. running mean: -29.399199\n",
      "ep 13: ep_len:570 episode reward: total was -13.050000. running mean: -29.235707\n",
      "ep 13: ep_len:315 episode reward: total was 3.500000. running mean: -28.908350\n",
      "ep 13: ep_len:189 episode reward: total was -1.000000. running mean: -28.629267\n",
      "ep 13: ep_len:625 episode reward: total was -37.150000. running mean: -28.714474\n",
      "ep 13: ep_len:1095 episode reward: total was -83.190000. running mean: -29.259229\n",
      "ep 13: ep_len:545 episode reward: total was -48.450000. running mean: -29.451137\n",
      "ep 13: ep_len:477 episode reward: total was -14.090000. running mean: -29.297526\n",
      "ep 13: ep_len:970 episode reward: total was -80.190000. running mean: -29.806450\n",
      "ep 13: ep_len:785 episode reward: total was -59.050000. running mean: -30.098886\n",
      "ep 13: ep_len:1725 episode reward: total was -91.220000. running mean: -30.710097\n",
      "ep 13: ep_len:730 episode reward: total was -27.360000. running mean: -30.676596\n",
      "ep 13: ep_len:825 episode reward: total was -38.800000. running mean: -30.757830\n",
      "ep 13: ep_len:540 episode reward: total was -23.180000. running mean: -30.682052\n",
      "ep 13: ep_len:565 episode reward: total was -19.090000. running mean: -30.566131\n",
      "ep 13: ep_len:750 episode reward: total was -21.780000. running mean: -30.478270\n",
      "ep 13: ep_len:1300 episode reward: total was -35.590000. running mean: -30.529387\n",
      "ep 13: ep_len:505 episode reward: total was -28.820000. running mean: -30.512293\n",
      "ep 13: ep_len:685 episode reward: total was -12.860000. running mean: -30.335770\n",
      "ep 13: ep_len:670 episode reward: total was 1.520000. running mean: -30.017213\n",
      "ep 13: ep_len:174 episode reward: total was 6.500000. running mean: -29.652041\n",
      "ep 13: ep_len:203 episode reward: total was 10.000000. running mean: -29.255520\n",
      "ep 13: ep_len:500 episode reward: total was 5.380000. running mean: -28.909165\n",
      "ep 13: ep_len:695 episode reward: total was -60.240000. running mean: -29.222473\n",
      "ep 13: ep_len:500 episode reward: total was 6.750000. running mean: -28.862749\n",
      "ep 13: ep_len:735 episode reward: total was -12.730000. running mean: -28.701421\n",
      "ep 13: ep_len:625 episode reward: total was -33.200000. running mean: -28.746407\n",
      "ep 13: ep_len:333 episode reward: total was 15.500000. running mean: -28.303943\n",
      "ep 13: ep_len:204 episode reward: total was 4.500000. running mean: -27.975903\n",
      "ep 13: ep_len:565 episode reward: total was -18.010000. running mean: -27.876244\n",
      "ep 13: ep_len:500 episode reward: total was -10.090000. running mean: -27.698382\n",
      "ep 13: ep_len:182 episode reward: total was 2.000000. running mean: -27.401398\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 13: ep_len:500 episode reward: total was 12.300000. running mean: -27.004384\n",
      "ep 13: ep_len:995 episode reward: total was -51.220000. running mean: -27.246540\n",
      "ep 13: ep_len:500 episode reward: total was -28.080000. running mean: -27.254875\n",
      "ep 13: ep_len:500 episode reward: total was 15.720000. running mean: -26.825126\n",
      "ep 13: ep_len:311 episode reward: total was 16.000000. running mean: -26.396875\n",
      "ep 13: ep_len:500 episode reward: total was -8.790000. running mean: -26.220806\n",
      "ep 13: ep_len:500 episode reward: total was -7.330000. running mean: -26.031898\n",
      "ep 13: ep_len:1110 episode reward: total was -30.810000. running mean: -26.079679\n",
      "ep 13: ep_len:545 episode reward: total was -31.280000. running mean: -26.131682\n",
      "ep 13: ep_len:500 episode reward: total was -11.260000. running mean: -25.982965\n",
      "ep 13: ep_len:2055 episode reward: total was -147.810000. running mean: -27.201236\n",
      "ep 13: ep_len:780 episode reward: total was -25.760000. running mean: -27.186823\n",
      "ep 13: ep_len:510 episode reward: total was -7.800000. running mean: -26.992955\n",
      "ep 13: ep_len:510 episode reward: total was -28.340000. running mean: -27.006426\n",
      "ep 13: ep_len:505 episode reward: total was -1.380000. running mean: -26.750161\n",
      "ep 13: ep_len:1065 episode reward: total was -76.390000. running mean: -27.246560\n",
      "ep 13: ep_len:2030 episode reward: total was -240.520000. running mean: -29.379294\n",
      "ep 13: ep_len:1015 episode reward: total was -60.640000. running mean: -29.691901\n",
      "ep 13: ep_len:500 episode reward: total was -3.230000. running mean: -29.427282\n",
      "ep 13: ep_len:605 episode reward: total was -31.160000. running mean: -29.444609\n",
      "ep 13: ep_len:750 episode reward: total was -49.070000. running mean: -29.640863\n",
      "ep 13: ep_len:570 episode reward: total was -47.360000. running mean: -29.818055\n",
      "ep 13: ep_len:715 episode reward: total was -27.910000. running mean: -29.798974\n",
      "ep 13: ep_len:500 episode reward: total was 16.300000. running mean: -29.337984\n",
      "ep 13: ep_len:162 episode reward: total was 5.500000. running mean: -28.989605\n",
      "ep 13: ep_len:500 episode reward: total was -4.920000. running mean: -28.748908\n",
      "ep 13: ep_len:670 episode reward: total was -46.230000. running mean: -28.923719\n",
      "ep 13: ep_len:291 episode reward: total was 12.000000. running mean: -28.514482\n",
      "ep 13: ep_len:317 episode reward: total was 10.260000. running mean: -28.126737\n",
      "ep 13: ep_len:227 episode reward: total was 6.000000. running mean: -27.785470\n",
      "ep 13: ep_len:500 episode reward: total was 17.000000. running mean: -27.337615\n",
      "ep 13: ep_len:1175 episode reward: total was -67.490000. running mean: -27.739139\n",
      "ep 13: ep_len:1010 episode reward: total was -143.470000. running mean: -28.896448\n",
      "ep 13: ep_len:243 episode reward: total was 9.000000. running mean: -28.517483\n",
      "ep 13: ep_len:505 episode reward: total was -9.280000. running mean: -28.325108\n",
      "ep 13: ep_len:980 episode reward: total was -23.440000. running mean: -28.276257\n",
      "ep 13: ep_len:1540 episode reward: total was -219.660000. running mean: -30.190095\n",
      "ep 13: ep_len:500 episode reward: total was 1.180000. running mean: -29.876394\n",
      "ep 13: ep_len:264 episode reward: total was 2.000000. running mean: -29.557630\n",
      "ep 13: ep_len:698 episode reward: total was -22.360000. running mean: -29.485654\n",
      "ep 13: ep_len:520 episode reward: total was -7.710000. running mean: -29.267897\n",
      "ep 13: ep_len:580 episode reward: total was -24.110000. running mean: -29.216318\n",
      "ep 13: ep_len:595 episode reward: total was -104.910000. running mean: -29.973255\n",
      "ep 13: ep_len:950 episode reward: total was -45.590000. running mean: -30.129422\n",
      "ep 13: ep_len:500 episode reward: total was -5.300000. running mean: -29.881128\n",
      "ep 13: ep_len:710 episode reward: total was -23.360000. running mean: -29.815917\n",
      "ep 13: ep_len:550 episode reward: total was -33.290000. running mean: -29.850658\n",
      "ep 13: ep_len:555 episode reward: total was -18.740000. running mean: -29.739551\n",
      "ep 13: ep_len:605 episode reward: total was -14.840000. running mean: -29.590556\n",
      "ep 13: ep_len:580 episode reward: total was -68.110000. running mean: -29.975750\n",
      "ep 13: ep_len:535 episode reward: total was -33.370000. running mean: -30.009693\n",
      "ep 13: ep_len:915 episode reward: total was -19.820000. running mean: -29.907796\n",
      "ep 13: ep_len:500 episode reward: total was 4.670000. running mean: -29.562018\n",
      "ep 13: ep_len:675 episode reward: total was -8.760000. running mean: -29.353997\n",
      "ep 13: ep_len:820 episode reward: total was -8.170000. running mean: -29.142158\n",
      "ep 13: ep_len:575 episode reward: total was -6.880000. running mean: -28.919536\n",
      "ep 13: ep_len:500 episode reward: total was -23.500000. running mean: -28.865341\n",
      "ep 13: ep_len:500 episode reward: total was -44.070000. running mean: -29.017387\n",
      "ep 13: ep_len:500 episode reward: total was 3.610000. running mean: -28.691113\n",
      "ep 13: ep_len:530 episode reward: total was -44.410000. running mean: -28.848302\n",
      "ep 13: ep_len:705 episode reward: total was -20.920000. running mean: -28.769019\n",
      "ep 13: ep_len:905 episode reward: total was -48.890000. running mean: -28.970229\n",
      "ep 13: ep_len:1300 episode reward: total was -125.720000. running mean: -29.937727\n",
      "ep 13: ep_len:307 episode reward: total was 7.500000. running mean: -29.563349\n",
      "ep 13: ep_len:237 episode reward: total was 10.000000. running mean: -29.167716\n",
      "ep 13: ep_len:500 episode reward: total was -0.770000. running mean: -28.883739\n",
      "ep 13: ep_len:1045 episode reward: total was -13.410000. running mean: -28.729001\n",
      "ep 13: ep_len:326 episode reward: total was 7.000000. running mean: -28.371711\n",
      "ep 13: ep_len:500 episode reward: total was 9.170000. running mean: -27.996294\n",
      "ep 13: ep_len:500 episode reward: total was -27.080000. running mean: -27.987131\n",
      "ep 13: ep_len:620 episode reward: total was -17.280000. running mean: -27.880060\n",
      "ep 13: ep_len:500 episode reward: total was -11.090000. running mean: -27.712159\n",
      "ep 13: ep_len:2460 episode reward: total was -220.850000. running mean: -29.643538\n",
      "ep 13: ep_len:720 episode reward: total was -0.340000. running mean: -29.350502\n",
      "ep 13: ep_len:985 episode reward: total was -39.280000. running mean: -29.449797\n",
      "ep 13: ep_len:1495 episode reward: total was -109.170000. running mean: -30.246999\n",
      "ep 13: ep_len:505 episode reward: total was -20.370000. running mean: -30.148229\n",
      "ep 13: ep_len:675 episode reward: total was -61.290000. running mean: -30.459647\n",
      "ep 13: ep_len:675 episode reward: total was -34.020000. running mean: -30.495251\n",
      "ep 13: ep_len:500 episode reward: total was 27.500000. running mean: -29.915298\n",
      "ep 13: ep_len:1035 episode reward: total was -93.930000. running mean: -30.555445\n",
      "ep 13: ep_len:600 episode reward: total was -9.430000. running mean: -30.344191\n",
      "ep 13: ep_len:1460 episode reward: total was -99.140000. running mean: -31.032149\n",
      "ep 13: ep_len:141 episode reward: total was 11.500000. running mean: -30.606827\n",
      "ep 13: ep_len:500 episode reward: total was -6.340000. running mean: -30.364159\n",
      "ep 13: ep_len:1050 episode reward: total was -97.030000. running mean: -31.030817\n",
      "ep 13: ep_len:500 episode reward: total was 7.340000. running mean: -30.647109\n",
      "ep 13: ep_len:500 episode reward: total was 2.220000. running mean: -30.318438\n",
      "ep 13: ep_len:505 episode reward: total was -21.840000. running mean: -30.233654\n",
      "ep 13: ep_len:178 episode reward: total was 10.000000. running mean: -29.831317\n",
      "ep 13: ep_len:800 episode reward: total was -37.320000. running mean: -29.906204\n",
      "ep 13: ep_len:905 episode reward: total was -31.380000. running mean: -29.920942\n",
      "ep 13: ep_len:685 episode reward: total was -16.830000. running mean: -29.790033\n",
      "ep 13: ep_len:635 episode reward: total was -84.650000. running mean: -30.338632\n",
      "ep 13: ep_len:500 episode reward: total was -1.250000. running mean: -30.047746\n",
      "ep 13: ep_len:1095 episode reward: total was -54.920000. running mean: -30.296469\n",
      "ep 13: ep_len:560 episode reward: total was -0.420000. running mean: -29.997704\n",
      "ep 13: ep_len:1915 episode reward: total was -177.590000. running mean: -31.473627\n",
      "ep 13: ep_len:980 episode reward: total was -46.050000. running mean: -31.619391\n",
      "ep 13: ep_len:500 episode reward: total was -9.540000. running mean: -31.398597\n",
      "ep 13: ep_len:180 episode reward: total was 3.500000. running mean: -31.049611\n",
      "ep 13: ep_len:735 episode reward: total was -28.360000. running mean: -31.022715\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 13: ep_len:500 episode reward: total was -24.110000. running mean: -30.953587\n",
      "ep 13: ep_len:920 episode reward: total was -45.680000. running mean: -31.100852\n",
      "ep 13: ep_len:223 episode reward: total was -1.500000. running mean: -30.804843\n",
      "ep 13: ep_len:685 episode reward: total was -36.410000. running mean: -30.860895\n",
      "ep 13: ep_len:500 episode reward: total was -18.810000. running mean: -30.740386\n",
      "ep 13: ep_len:780 episode reward: total was -37.850000. running mean: -30.811482\n",
      "ep 13: ep_len:625 episode reward: total was 3.540000. running mean: -30.467967\n",
      "ep 13: ep_len:505 episode reward: total was 14.500000. running mean: -30.018287\n",
      "ep 13: ep_len:1924 episode reward: total was -353.700000. running mean: -33.255104\n",
      "ep 13: ep_len:500 episode reward: total was -2.250000. running mean: -32.945053\n",
      "ep 13: ep_len:1004 episode reward: total was -120.730000. running mean: -33.822903\n",
      "ep 13: ep_len:1295 episode reward: total was -150.520000. running mean: -34.989874\n",
      "ep 13: ep_len:565 episode reward: total was 15.250000. running mean: -34.487475\n",
      "ep 13: ep_len:910 episode reward: total was -35.080000. running mean: -34.493400\n",
      "ep 13: ep_len:790 episode reward: total was -70.040000. running mean: -34.848866\n",
      "ep 13: ep_len:725 episode reward: total was -62.540000. running mean: -35.125778\n",
      "ep 13: ep_len:805 episode reward: total was -37.830000. running mean: -35.152820\n",
      "ep 13: ep_len:690 episode reward: total was -32.380000. running mean: -35.125092\n",
      "ep 13: ep_len:244 episode reward: total was 12.000000. running mean: -34.653841\n",
      "ep 13: ep_len:500 episode reward: total was 6.730000. running mean: -34.240002\n",
      "ep 13: ep_len:980 episode reward: total was -32.160000. running mean: -34.219202\n",
      "ep 13: ep_len:500 episode reward: total was -53.590000. running mean: -34.412910\n",
      "ep 13: ep_len:910 episode reward: total was -173.940000. running mean: -35.808181\n",
      "ep 13: ep_len:840 episode reward: total was -44.310000. running mean: -35.893199\n",
      "ep 13: ep_len:500 episode reward: total was -28.050000. running mean: -35.814767\n",
      "ep 13: ep_len:500 episode reward: total was -3.730000. running mean: -35.493920\n",
      "ep 13: ep_len:500 episode reward: total was -17.820000. running mean: -35.317181\n",
      "ep 13: ep_len:860 episode reward: total was -40.750000. running mean: -35.371509\n",
      "ep 13: ep_len:740 episode reward: total was -33.400000. running mean: -35.351794\n",
      "ep 13: ep_len:482 episode reward: total was 7.760000. running mean: -34.920676\n",
      "ep 13: ep_len:535 episode reward: total was -42.900000. running mean: -35.000469\n",
      "ep 13: ep_len:10 episode reward: total was -2.000000. running mean: -34.670464\n",
      "ep 13: ep_len:660 episode reward: total was -17.730000. running mean: -34.501060\n",
      "ep 13: ep_len:1120 episode reward: total was -69.490000. running mean: -34.850949\n",
      "ep 13: ep_len:500 episode reward: total was -20.180000. running mean: -34.704240\n",
      "ep 13: ep_len:505 episode reward: total was 7.280000. running mean: -34.284397\n",
      "ep 13: ep_len:600 episode reward: total was -37.230000. running mean: -34.313853\n",
      "ep 13: ep_len:500 episode reward: total was -8.900000. running mean: -34.059715\n",
      "ep 13: ep_len:510 episode reward: total was -3.270000. running mean: -33.751817\n",
      "ep 13: ep_len:940 episode reward: total was -30.130000. running mean: -33.715599\n",
      "ep 13: ep_len:830 episode reward: total was -12.820000. running mean: -33.506643\n",
      "ep 13: ep_len:1227 episode reward: total was -211.290000. running mean: -35.284477\n",
      "ep 13: ep_len:210 episode reward: total was 6.000000. running mean: -34.871632\n",
      "ep 13: ep_len:500 episode reward: total was -50.650000. running mean: -35.029416\n",
      "ep 13: ep_len:800 episode reward: total was -127.780000. running mean: -35.956922\n",
      "ep 13: ep_len:520 episode reward: total was -5.780000. running mean: -35.655152\n",
      "ep 13: ep_len:665 episode reward: total was -48.180000. running mean: -35.780401\n",
      "ep 13: ep_len:1045 episode reward: total was -45.100000. running mean: -35.873597\n",
      "ep 13: ep_len:535 episode reward: total was -44.920000. running mean: -35.964061\n",
      "ep 13: ep_len:580 episode reward: total was -53.430000. running mean: -36.138720\n",
      "ep 13: ep_len:630 episode reward: total was -9.550000. running mean: -35.872833\n",
      "ep 13: ep_len:910 episode reward: total was -52.740000. running mean: -36.041505\n",
      "ep 13: ep_len:505 episode reward: total was -17.980000. running mean: -35.860890\n",
      "ep 13: ep_len:650 episode reward: total was -29.740000. running mean: -35.799681\n",
      "ep 13: ep_len:885 episode reward: total was -77.550000. running mean: -36.217184\n",
      "ep 13: ep_len:500 episode reward: total was -46.750000. running mean: -36.322512\n",
      "ep 13: ep_len:500 episode reward: total was -24.510000. running mean: -36.204387\n",
      "ep 13: ep_len:570 episode reward: total was -23.480000. running mean: -36.077143\n",
      "ep 13: ep_len:500 episode reward: total was -27.850000. running mean: -35.994872\n",
      "ep 13: ep_len:500 episode reward: total was -17.370000. running mean: -35.808623\n",
      "ep 13: ep_len:500 episode reward: total was 6.720000. running mean: -35.383337\n",
      "ep 13: ep_len:241 episode reward: total was 3.000000. running mean: -34.999503\n",
      "ep 13: ep_len:261 episode reward: total was 1.500000. running mean: -34.634508\n",
      "ep 13: ep_len:500 episode reward: total was -19.770000. running mean: -34.485863\n",
      "ep 13: ep_len:500 episode reward: total was -42.680000. running mean: -34.567805\n",
      "ep 13: ep_len:500 episode reward: total was -22.860000. running mean: -34.450727\n",
      "ep 13: ep_len:570 episode reward: total was -39.310000. running mean: -34.499319\n",
      "ep 13: ep_len:500 episode reward: total was -36.810000. running mean: -34.522426\n",
      "ep 13: ep_len:670 episode reward: total was -12.440000. running mean: -34.301602\n",
      "ep 13: ep_len:1040 episode reward: total was -23.390000. running mean: -34.192486\n",
      "ep 13: ep_len:500 episode reward: total was -16.250000. running mean: -34.013061\n",
      "ep 13: ep_len:10270 episode reward: total was -1934.580000. running mean: -53.018730\n",
      "ep 13: ep_len:500 episode reward: total was -19.180000. running mean: -52.680343\n",
      "ep 13: ep_len:965 episode reward: total was -67.810000. running mean: -52.831640\n",
      "ep 13: ep_len:675 episode reward: total was -70.410000. running mean: -53.007423\n",
      "ep 13: ep_len:500 episode reward: total was -29.190000. running mean: -52.769249\n",
      "ep 13: ep_len:500 episode reward: total was -4.300000. running mean: -52.284557\n",
      "ep 13: ep_len:515 episode reward: total was -58.750000. running mean: -52.349211\n",
      "ep 13: ep_len:720 episode reward: total was -6.510000. running mean: -51.890819\n",
      "ep 13: ep_len:730 episode reward: total was -27.880000. running mean: -51.650711\n",
      "ep 13: ep_len:810 episode reward: total was -152.960000. running mean: -52.663804\n",
      "ep 13: ep_len:905 episode reward: total was -31.880000. running mean: -52.455966\n",
      "ep 13: ep_len:605 episode reward: total was -38.720000. running mean: -52.318606\n",
      "ep 13: ep_len:1070 episode reward: total was -150.960000. running mean: -53.305020\n",
      "ep 13: ep_len:620 episode reward: total was -31.620000. running mean: -53.088170\n",
      "ep 13: ep_len:500 episode reward: total was -7.150000. running mean: -52.628788\n",
      "ep 13: ep_len:1035 episode reward: total was -62.540000. running mean: -52.727900\n",
      "ep 13: ep_len:700 episode reward: total was -38.040000. running mean: -52.581021\n",
      "ep 13: ep_len:565 episode reward: total was -62.330000. running mean: -52.678511\n",
      "ep 13: ep_len:500 episode reward: total was -1.260000. running mean: -52.164326\n",
      "ep 13: ep_len:500 episode reward: total was -27.140000. running mean: -51.914082\n",
      "ep 13: ep_len:500 episode reward: total was -13.170000. running mean: -51.526642\n",
      "ep 13: ep_len:500 episode reward: total was -55.270000. running mean: -51.564075\n",
      "ep 13: ep_len:515 episode reward: total was -19.480000. running mean: -51.243235\n",
      "ep 13: ep_len:1065 episode reward: total was -66.500000. running mean: -51.395802\n",
      "ep 13: ep_len:1110 episode reward: total was -107.920000. running mean: -51.961044\n",
      "ep 13: ep_len:510 episode reward: total was -16.270000. running mean: -51.604134\n",
      "ep 13: ep_len:352 episode reward: total was 19.000000. running mean: -50.898092\n",
      "ep 13: ep_len:505 episode reward: total was -27.350000. running mean: -50.662611\n",
      "ep 13: ep_len:575 episode reward: total was -28.610000. running mean: -50.442085\n",
      "ep 13: ep_len:970 episode reward: total was -58.410000. running mean: -50.521764\n",
      "ep 13: ep_len:515 episode reward: total was -39.420000. running mean: -50.410747\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 13: ep_len:500 episode reward: total was -45.080000. running mean: -50.357439\n",
      "ep 13: ep_len:500 episode reward: total was -37.550000. running mean: -50.229365\n",
      "ep 13: ep_len:630 episode reward: total was -72.520000. running mean: -50.452271\n",
      "ep 13: ep_len:725 episode reward: total was -46.560000. running mean: -50.413349\n",
      "ep 13: ep_len:500 episode reward: total was 3.240000. running mean: -49.876815\n",
      "ep 13: ep_len:695 episode reward: total was -81.480000. running mean: -50.192847\n",
      "ep 13: ep_len:500 episode reward: total was -7.850000. running mean: -49.769418\n",
      "ep 13: ep_len:500 episode reward: total was 0.190000. running mean: -49.269824\n",
      "ep 13: ep_len:1590 episode reward: total was -248.330000. running mean: -51.260426\n",
      "ep 13: ep_len:735 episode reward: total was -14.100000. running mean: -50.888822\n",
      "ep 13: ep_len:1800 episode reward: total was -182.050000. running mean: -52.200434\n",
      "ep 13: ep_len:965 episode reward: total was -92.540000. running mean: -52.603829\n",
      "ep 13: ep_len:505 episode reward: total was -12.920000. running mean: -52.206991\n",
      "ep 13: ep_len:500 episode reward: total was -25.910000. running mean: -51.944021\n",
      "ep 13: ep_len:890 episode reward: total was -13.380000. running mean: -51.558381\n",
      "ep 13: ep_len:500 episode reward: total was -2.860000. running mean: -51.071397\n",
      "ep 13: ep_len:432 episode reward: total was -15.280000. running mean: -50.713483\n",
      "ep 13: ep_len:500 episode reward: total was 4.710000. running mean: -50.159248\n",
      "ep 13: ep_len:610 episode reward: total was -24.080000. running mean: -49.898456\n",
      "ep 13: ep_len:640 episode reward: total was -10.910000. running mean: -49.508571\n",
      "ep 13: ep_len:505 episode reward: total was -4.080000. running mean: -49.054285\n",
      "ep 13: ep_len:545 episode reward: total was -68.130000. running mean: -49.245043\n",
      "ep 13: ep_len:500 episode reward: total was -5.560000. running mean: -48.808192\n",
      "ep 13: ep_len:500 episode reward: total was -8.830000. running mean: -48.408410\n",
      "ep 13: ep_len:880 episode reward: total was -25.200000. running mean: -48.176326\n",
      "ep 13: ep_len:635 episode reward: total was -50.780000. running mean: -48.202363\n",
      "ep 13: ep_len:765 episode reward: total was -120.730000. running mean: -48.927639\n",
      "ep 13: ep_len:241 episode reward: total was 20.000000. running mean: -48.238363\n",
      "ep 13: ep_len:505 episode reward: total was -13.420000. running mean: -47.890179\n",
      "ep 13: ep_len:545 episode reward: total was -3.630000. running mean: -47.447577\n",
      "ep 13: ep_len:715 episode reward: total was -25.890000. running mean: -47.232002\n",
      "ep 13: ep_len:825 episode reward: total was -39.810000. running mean: -47.157782\n",
      "ep 13: ep_len:63 episode reward: total was 3.000000. running mean: -46.656204\n",
      "ep 13: ep_len:199 episode reward: total was 13.500000. running mean: -46.054642\n",
      "ep 13: ep_len:500 episode reward: total was -0.840000. running mean: -45.602495\n",
      "ep 13: ep_len:810 episode reward: total was -48.410000. running mean: -45.630570\n",
      "ep 13: ep_len:790 episode reward: total was -16.140000. running mean: -45.335665\n",
      "ep 13: ep_len:207 episode reward: total was 9.000000. running mean: -44.792308\n",
      "ep 13: ep_len:500 episode reward: total was 4.650000. running mean: -44.297885\n",
      "ep 13: ep_len:500 episode reward: total was -4.300000. running mean: -43.897906\n",
      "ep 13: ep_len:520 episode reward: total was -45.030000. running mean: -43.909227\n",
      "ep 13: ep_len:161 episode reward: total was 11.500000. running mean: -43.355135\n",
      "ep 13: ep_len:181 episode reward: total was 12.000000. running mean: -42.801583\n",
      "ep 13: ep_len:625 episode reward: total was -26.040000. running mean: -42.633968\n",
      "ep 13: ep_len:730 episode reward: total was -67.270000. running mean: -42.880328\n",
      "ep 13: ep_len:505 episode reward: total was -8.890000. running mean: -42.540425\n",
      "ep 13: ep_len:500 episode reward: total was -13.150000. running mean: -42.246520\n",
      "ep 13: ep_len:710 episode reward: total was -49.130000. running mean: -42.315355\n",
      "ep 13: ep_len:156 episode reward: total was 5.000000. running mean: -41.842202\n",
      "ep 13: ep_len:54 episode reward: total was 0.500000. running mean: -41.418780\n",
      "ep 13: ep_len:500 episode reward: total was -17.490000. running mean: -41.179492\n",
      "ep 13: ep_len:785 episode reward: total was -39.890000. running mean: -41.166597\n",
      "ep 13: ep_len:500 episode reward: total was -7.360000. running mean: -40.828531\n",
      "ep 13: ep_len:262 episode reward: total was 14.000000. running mean: -40.280246\n",
      "ep 13: ep_len:630 episode reward: total was -102.300000. running mean: -40.900443\n",
      "ep 13: ep_len:167 episode reward: total was 7.500000. running mean: -40.416439\n",
      "ep 13: ep_len:500 episode reward: total was -8.010000. running mean: -40.092374\n",
      "ep 13: ep_len:660 episode reward: total was -30.530000. running mean: -39.996751\n",
      "ep 13: ep_len:477 episode reward: total was 30.000000. running mean: -39.296783\n",
      "ep 13: ep_len:790 episode reward: total was -55.030000. running mean: -39.454115\n",
      "ep 13: ep_len:565 episode reward: total was -40.330000. running mean: -39.462874\n",
      "ep 13: ep_len:525 episode reward: total was -25.260000. running mean: -39.320845\n",
      "ep 13: ep_len:545 episode reward: total was -43.400000. running mean: -39.361637\n",
      "ep 13: ep_len:935 episode reward: total was -153.740000. running mean: -40.505421\n",
      "ep 13: ep_len:500 episode reward: total was -15.060000. running mean: -40.250966\n",
      "ep 13: ep_len:500 episode reward: total was -23.130000. running mean: -40.079757\n",
      "ep 13: ep_len:510 episode reward: total was 4.500000. running mean: -39.633959\n",
      "ep 13: ep_len:505 episode reward: total was -12.860000. running mean: -39.366220\n",
      "ep 13: ep_len:500 episode reward: total was -27.330000. running mean: -39.245857\n",
      "ep 13: ep_len:525 episode reward: total was -74.750000. running mean: -39.600899\n",
      "ep 13: ep_len:795 episode reward: total was -39.010000. running mean: -39.594990\n",
      "ep 13: ep_len:885 episode reward: total was -11.450000. running mean: -39.313540\n",
      "ep 13: ep_len:575 episode reward: total was -16.070000. running mean: -39.081105\n",
      "ep 13: ep_len:500 episode reward: total was -12.530000. running mean: -38.815593\n",
      "ep 13: ep_len:392 episode reward: total was 18.000000. running mean: -38.247438\n",
      "ep 13: ep_len:500 episode reward: total was -1.760000. running mean: -37.882563\n",
      "ep 13: ep_len:342 episode reward: total was 16.500000. running mean: -37.338738\n",
      "ep 13: ep_len:500 episode reward: total was -4.260000. running mean: -37.007950\n",
      "ep 13: ep_len:500 episode reward: total was 3.630000. running mean: -36.601571\n",
      "ep 13: ep_len:500 episode reward: total was 7.700000. running mean: -36.158555\n",
      "ep 13: ep_len:585 episode reward: total was -33.220000. running mean: -36.129169\n",
      "ep 13: ep_len:835 episode reward: total was -22.640000. running mean: -35.994278\n",
      "ep 13: ep_len:500 episode reward: total was -8.990000. running mean: -35.724235\n",
      "ep 13: ep_len:500 episode reward: total was -8.390000. running mean: -35.450893\n",
      "ep 13: ep_len:500 episode reward: total was -24.080000. running mean: -35.337184\n",
      "ep 13: ep_len:500 episode reward: total was 19.000000. running mean: -34.793812\n",
      "ep 13: ep_len:800 episode reward: total was -45.400000. running mean: -34.899874\n",
      "ep 13: ep_len:930 episode reward: total was -10.870000. running mean: -34.659575\n",
      "ep 13: ep_len:295 episode reward: total was 2.720000. running mean: -34.285779\n",
      "ep 13: ep_len:870 episode reward: total was -77.510000. running mean: -34.718021\n",
      "ep 13: ep_len:196 episode reward: total was 13.000000. running mean: -34.240841\n",
      "ep 13: ep_len:500 episode reward: total was -15.660000. running mean: -34.055033\n",
      "ep 13: ep_len:650 episode reward: total was -43.190000. running mean: -34.146382\n",
      "ep 13: ep_len:795 episode reward: total was -16.770000. running mean: -33.972619\n",
      "ep 13: ep_len:500 episode reward: total was 8.310000. running mean: -33.549792\n",
      "ep 13: ep_len:500 episode reward: total was 33.500000. running mean: -32.879295\n",
      "ep 13: ep_len:780 episode reward: total was -6.470000. running mean: -32.615202\n",
      "ep 13: ep_len:775 episode reward: total was -40.890000. running mean: -32.697950\n",
      "ep 13: ep_len:133 episode reward: total was 8.500000. running mean: -32.285970\n",
      "ep 13: ep_len:500 episode reward: total was 3.200000. running mean: -31.931110\n",
      "ep 13: ep_len:500 episode reward: total was -10.790000. running mean: -31.719699\n",
      "ep 13: ep_len:785 episode reward: total was -37.870000. running mean: -31.781202\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 13: ep_len:625 episode reward: total was -39.200000. running mean: -31.855390\n",
      "ep 13: ep_len:500 episode reward: total was -24.200000. running mean: -31.778836\n",
      "ep 13: ep_len:505 episode reward: total was 9.130000. running mean: -31.369748\n",
      "ep 13: ep_len:500 episode reward: total was -16.860000. running mean: -31.224651\n",
      "ep 13: ep_len:500 episode reward: total was -22.390000. running mean: -31.136304\n",
      "ep 13: ep_len:670 episode reward: total was -28.000000. running mean: -31.104941\n",
      "ep 13: ep_len:1245 episode reward: total was -113.190000. running mean: -31.925792\n",
      "ep 13: ep_len:805 episode reward: total was -38.840000. running mean: -31.994934\n",
      "ep 13: ep_len:500 episode reward: total was -22.280000. running mean: -31.897784\n",
      "ep 13: ep_len:700 episode reward: total was -28.950000. running mean: -31.868306\n",
      "ep 13: ep_len:645 episode reward: total was -15.930000. running mean: -31.708923\n",
      "ep 13: ep_len:238 episode reward: total was 7.500000. running mean: -31.316834\n",
      "ep 13: ep_len:590 episode reward: total was -32.520000. running mean: -31.328866\n",
      "ep 13: ep_len:673 episode reward: total was -27.460000. running mean: -31.290177\n",
      "ep 13: ep_len:550 episode reward: total was -21.170000. running mean: -31.188975\n",
      "ep 13: ep_len:500 episode reward: total was -6.200000. running mean: -30.939086\n",
      "ep 13: ep_len:900 episode reward: total was -72.990000. running mean: -31.359595\n",
      "ep 13: ep_len:156 episode reward: total was 6.500000. running mean: -30.980999\n",
      "ep 13: ep_len:285 episode reward: total was -18.480000. running mean: -30.855989\n",
      "ep 13: ep_len:655 episode reward: total was -29.010000. running mean: -30.837529\n",
      "ep 13: ep_len:1310 episode reward: total was -164.570000. running mean: -32.174854\n",
      "ep 13: ep_len:995 episode reward: total was -59.540000. running mean: -32.448505\n",
      "ep 13: ep_len:500 episode reward: total was -4.790000. running mean: -32.171920\n",
      "ep 13: ep_len:760 episode reward: total was -37.920000. running mean: -32.229401\n",
      "ep 13: ep_len:1030 episode reward: total was -53.960000. running mean: -32.446707\n",
      "ep 13: ep_len:505 episode reward: total was -14.820000. running mean: -32.270440\n",
      "ep 13: ep_len:650 episode reward: total was -49.740000. running mean: -32.445135\n",
      "ep 13: ep_len:1030 episode reward: total was -32.430000. running mean: -32.444984\n",
      "ep 13: ep_len:695 episode reward: total was -33.000000. running mean: -32.450534\n",
      "ep 13: ep_len:695 episode reward: total was -17.500000. running mean: -32.301029\n",
      "ep 13: ep_len:805 episode reward: total was -36.790000. running mean: -32.345919\n",
      "ep 13: ep_len:770 episode reward: total was -46.960000. running mean: -32.492059\n",
      "ep 13: ep_len:500 episode reward: total was -5.650000. running mean: -32.223639\n",
      "ep 13: ep_len:705 episode reward: total was -19.850000. running mean: -32.099902\n",
      "ep 13: ep_len:500 episode reward: total was -51.650000. running mean: -32.295403\n",
      "ep 13: ep_len:505 episode reward: total was -5.270000. running mean: -32.025149\n",
      "ep 13: ep_len:535 episode reward: total was -18.410000. running mean: -31.888998\n",
      "ep 13: ep_len:685 episode reward: total was -54.200000. running mean: -32.112108\n",
      "ep 13: ep_len:925 episode reward: total was -52.710000. running mean: -32.318087\n",
      "ep 13: ep_len:10185 episode reward: total was -1294.050000. running mean: -44.935406\n",
      "ep 13: ep_len:500 episode reward: total was -18.760000. running mean: -44.673652\n",
      "ep 13: ep_len:885 episode reward: total was -40.280000. running mean: -44.629715\n",
      "ep 13: ep_len:690 episode reward: total was -40.070000. running mean: -44.584118\n",
      "ep 13: ep_len:565 episode reward: total was -87.280000. running mean: -45.011077\n",
      "ep 13: ep_len:665 episode reward: total was -59.810000. running mean: -45.159066\n",
      "ep 13: ep_len:845 episode reward: total was 6.040000. running mean: -44.647076\n",
      "ep 13: ep_len:505 episode reward: total was 19.000000. running mean: -44.010605\n",
      "ep 13: ep_len:580 episode reward: total was -16.170000. running mean: -43.732199\n",
      "ep 13: ep_len:500 episode reward: total was -4.760000. running mean: -43.342477\n",
      "ep 13: ep_len:805 episode reward: total was -26.550000. running mean: -43.174552\n",
      "ep 13: ep_len:500 episode reward: total was 4.140000. running mean: -42.701407\n",
      "ep 13: ep_len:505 episode reward: total was -9.210000. running mean: -42.366492\n",
      "ep 13: ep_len:500 episode reward: total was -16.860000. running mean: -42.111428\n",
      "ep 13: ep_len:500 episode reward: total was 15.170000. running mean: -41.538613\n",
      "ep 13: ep_len:1075 episode reward: total was -27.330000. running mean: -41.396527\n",
      "ep 13: ep_len:710 episode reward: total was -31.190000. running mean: -41.294462\n",
      "ep 13: ep_len:148 episode reward: total was 10.000000. running mean: -40.781517\n",
      "ep 13: ep_len:505 episode reward: total was -35.460000. running mean: -40.728302\n",
      "ep 13: ep_len:665 episode reward: total was -49.710000. running mean: -40.818119\n",
      "ep 13: ep_len:505 episode reward: total was 7.250000. running mean: -40.337438\n",
      "ep 13: ep_len:505 episode reward: total was -15.050000. running mean: -40.084563\n",
      "ep 13: ep_len:580 episode reward: total was -20.100000. running mean: -39.884718\n",
      "ep 13: ep_len:510 episode reward: total was -64.190000. running mean: -40.127771\n",
      "ep 13: ep_len:525 episode reward: total was -31.890000. running mean: -40.045393\n",
      "ep 13: ep_len:500 episode reward: total was -3.780000. running mean: -39.682739\n",
      "ep 13: ep_len:850 episode reward: total was -50.870000. running mean: -39.794612\n",
      "ep 13: ep_len:650 episode reward: total was -15.760000. running mean: -39.554265\n",
      "ep 13: ep_len:830 episode reward: total was -22.990000. running mean: -39.388623\n",
      "ep 13: ep_len:433 episode reward: total was 29.500000. running mean: -38.699737\n",
      "ep 13: ep_len:605 episode reward: total was -36.210000. running mean: -38.674839\n",
      "ep 13: ep_len:500 episode reward: total was 0.320000. running mean: -38.284891\n",
      "ep 13: ep_len:500 episode reward: total was 4.270000. running mean: -37.859342\n",
      "ep 13: ep_len:168 episode reward: total was 6.000000. running mean: -37.420749\n",
      "ep 13: ep_len:500 episode reward: total was -11.820000. running mean: -37.164741\n",
      "ep 13: ep_len:251 episode reward: total was 11.500000. running mean: -36.678094\n",
      "ep 13: ep_len:745 episode reward: total was -22.370000. running mean: -36.535013\n",
      "ep 13: ep_len:500 episode reward: total was 9.230000. running mean: -36.077363\n",
      "ep 13: ep_len:705 episode reward: total was -34.490000. running mean: -36.061489\n",
      "ep 13: ep_len:745 episode reward: total was -49.550000. running mean: -36.196374\n",
      "ep 13: ep_len:775 episode reward: total was -29.780000. running mean: -36.132210\n",
      "ep 13: ep_len:500 episode reward: total was -13.000000. running mean: -35.900888\n",
      "ep 13: ep_len:605 episode reward: total was -18.880000. running mean: -35.730679\n",
      "ep 13: ep_len:640 episode reward: total was -19.460000. running mean: -35.567973\n",
      "ep 13: ep_len:131 episode reward: total was 5.500000. running mean: -35.157293\n",
      "ep 13: ep_len:500 episode reward: total was 0.750000. running mean: -34.798220\n",
      "ep 13: ep_len:500 episode reward: total was 27.500000. running mean: -34.175238\n",
      "ep 13: ep_len:505 episode reward: total was -29.340000. running mean: -34.126885\n",
      "ep 13: ep_len:152 episode reward: total was 5.000000. running mean: -33.735616\n",
      "ep 13: ep_len:500 episode reward: total was -5.980000. running mean: -33.458060\n",
      "ep 13: ep_len:755 episode reward: total was -39.150000. running mean: -33.514980\n",
      "ep 13: ep_len:295 episode reward: total was 5.500000. running mean: -33.124830\n",
      "ep 13: ep_len:1010 episode reward: total was -60.980000. running mean: -33.403382\n",
      "ep 13: ep_len:570 episode reward: total was -51.230000. running mean: -33.581648\n",
      "ep 13: ep_len:810 episode reward: total was -46.910000. running mean: -33.714931\n",
      "ep 13: ep_len:500 episode reward: total was -13.780000. running mean: -33.515582\n",
      "ep 13: ep_len:640 episode reward: total was -30.570000. running mean: -33.486126\n",
      "ep 13: ep_len:675 episode reward: total was -24.640000. running mean: -33.397665\n",
      "ep 13: ep_len:500 episode reward: total was -8.380000. running mean: -33.147488\n",
      "ep 13: ep_len:740 episode reward: total was -28.870000. running mean: -33.104713\n",
      "ep 13: ep_len:500 episode reward: total was -14.380000. running mean: -32.917466\n",
      "ep 13: ep_len:500 episode reward: total was -13.800000. running mean: -32.726292\n",
      "ep 13: ep_len:500 episode reward: total was 4.270000. running mean: -32.356329\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 13: ep_len:930 episode reward: total was -82.020000. running mean: -32.852965\n",
      "ep 13: ep_len:505 episode reward: total was -7.740000. running mean: -32.601836\n",
      "ep 13: ep_len:840 episode reward: total was -28.570000. running mean: -32.561517\n",
      "ep 13: ep_len:520 episode reward: total was -36.380000. running mean: -32.599702\n",
      "ep 13: ep_len:1390 episode reward: total was -159.880000. running mean: -33.872505\n",
      "ep 13: ep_len:500 episode reward: total was -7.310000. running mean: -33.606880\n",
      "ep 13: ep_len:465 episode reward: total was 20.000000. running mean: -33.070811\n",
      "ep 13: ep_len:500 episode reward: total was -21.270000. running mean: -32.952803\n",
      "ep 13: ep_len:720 episode reward: total was -34.480000. running mean: -32.968075\n",
      "ep 13: ep_len:500 episode reward: total was 0.720000. running mean: -32.631194\n",
      "ep 13: ep_len:500 episode reward: total was 11.780000. running mean: -32.187082\n",
      "ep 13: ep_len:680 episode reward: total was -80.500000. running mean: -32.670212\n",
      "ep 13: ep_len:500 episode reward: total was -14.740000. running mean: -32.490910\n",
      "ep 13: ep_len:535 episode reward: total was -17.330000. running mean: -32.339300\n",
      "ep 13: ep_len:500 episode reward: total was -22.280000. running mean: -32.238707\n",
      "ep 13: ep_len:500 episode reward: total was -3.750000. running mean: -31.953820\n",
      "ep 13: ep_len:575 episode reward: total was -24.790000. running mean: -31.882182\n",
      "ep 13: ep_len:500 episode reward: total was 6.900000. running mean: -31.494360\n",
      "ep 13: ep_len:900 episode reward: total was -63.900000. running mean: -31.818417\n",
      "ep 13: ep_len:2214 episode reward: total was -301.260000. running mean: -34.512833\n",
      "ep 13: ep_len:830 episode reward: total was -149.420000. running mean: -35.661904\n",
      "ep 13: ep_len:770 episode reward: total was -29.100000. running mean: -35.596285\n",
      "ep 13: ep_len:770 episode reward: total was -36.890000. running mean: -35.609222\n",
      "ep 13: ep_len:665 episode reward: total was -8.630000. running mean: -35.339430\n",
      "ep 13: ep_len:860 episode reward: total was -10.430000. running mean: -35.090336\n",
      "ep 13: ep_len:595 episode reward: total was -112.990000. running mean: -35.869332\n",
      "ep 13: ep_len:2195 episode reward: total was -333.760000. running mean: -38.848239\n",
      "ep 13: ep_len:690 episode reward: total was -27.720000. running mean: -38.736957\n",
      "ep 13: ep_len:457 episode reward: total was 3.660000. running mean: -38.312987\n",
      "ep 13: ep_len:725 episode reward: total was -35.970000. running mean: -38.289557\n",
      "ep 13: ep_len:670 episode reward: total was -35.070000. running mean: -38.257362\n",
      "ep 13: ep_len:500 episode reward: total was -18.790000. running mean: -38.062688\n",
      "ep 13: ep_len:500 episode reward: total was 0.230000. running mean: -37.679761\n",
      "ep 13: ep_len:870 episode reward: total was -46.080000. running mean: -37.763764\n",
      "ep 13: ep_len:920 episode reward: total was -69.940000. running mean: -38.085526\n",
      "ep 13: ep_len:780 episode reward: total was -32.560000. running mean: -38.030271\n",
      "ep 13: ep_len:550 episode reward: total was -16.120000. running mean: -37.811168\n",
      "ep 13: ep_len:705 episode reward: total was -4.980000. running mean: -37.482856\n",
      "ep 13: ep_len:940 episode reward: total was -20.930000. running mean: -37.317328\n",
      "ep 13: ep_len:98 episode reward: total was 6.500000. running mean: -36.879154\n",
      "ep 13: ep_len:171 episode reward: total was 11.000000. running mean: -36.400363\n",
      "ep 13: ep_len:500 episode reward: total was 0.810000. running mean: -36.028259\n",
      "ep 13: ep_len:1030 episode reward: total was -9.850000. running mean: -35.766477\n",
      "ep 13: ep_len:505 episode reward: total was 14.790000. running mean: -35.260912\n",
      "ep 13: ep_len:371 episode reward: total was 18.000000. running mean: -34.728303\n",
      "ep 13: ep_len:735 episode reward: total was -26.860000. running mean: -34.649620\n",
      "ep 13: ep_len:605 episode reward: total was 2.400000. running mean: -34.279124\n",
      "ep 13: ep_len:505 episode reward: total was -33.040000. running mean: -34.266732\n",
      "ep 13: ep_len:212 episode reward: total was 7.500000. running mean: -33.849065\n",
      "ep 13: ep_len:565 episode reward: total was -0.270000. running mean: -33.513274\n",
      "ep 13: ep_len:525 episode reward: total was -27.280000. running mean: -33.450942\n",
      "ep 13: ep_len:500 episode reward: total was -0.780000. running mean: -33.124232\n",
      "ep 13: ep_len:187 episode reward: total was 11.000000. running mean: -32.682990\n",
      "ep 13: ep_len:700 episode reward: total was -17.890000. running mean: -32.535060\n",
      "ep 13: ep_len:505 episode reward: total was -8.820000. running mean: -32.297909\n",
      "ep 13: ep_len:530 episode reward: total was -72.720000. running mean: -32.702130\n",
      "ep 13: ep_len:169 episode reward: total was 3.000000. running mean: -32.345109\n",
      "ep 13: ep_len:615 episode reward: total was -22.260000. running mean: -32.244258\n",
      "ep 13: ep_len:570 episode reward: total was -29.700000. running mean: -32.218815\n",
      "ep 13: ep_len:505 episode reward: total was -14.250000. running mean: -32.039127\n",
      "ep 13: ep_len:500 episode reward: total was -11.650000. running mean: -31.835236\n",
      "ep 13: ep_len:2555 episode reward: total was -366.260000. running mean: -35.179484\n",
      "ep 13: ep_len:530 episode reward: total was -1.960000. running mean: -34.847289\n",
      "ep 13: ep_len:5275 episode reward: total was -870.910000. running mean: -43.207916\n",
      "ep 13: ep_len:929 episode reward: total was -110.290000. running mean: -43.878737\n",
      "ep 13: ep_len:615 episode reward: total was -14.330000. running mean: -43.583249\n",
      "ep 13: ep_len:500 episode reward: total was -10.040000. running mean: -43.247817\n",
      "ep 13: ep_len:505 episode reward: total was 18.000000. running mean: -42.635339\n",
      "ep 13: ep_len:467 episode reward: total was -20.500000. running mean: -42.413985\n",
      "ep 13: ep_len:635 episode reward: total was -54.820000. running mean: -42.538045\n",
      "epsilon:0.184642 episode_count: 11044. steps_count: 7753363.000000\n",
      "ep 14: ep_len:510 episode reward: total was 7.230000. running mean: -42.040365\n",
      "ep 14: ep_len:1060 episode reward: total was -75.650000. running mean: -42.376461\n",
      "ep 14: ep_len:510 episode reward: total was -13.670000. running mean: -42.089397\n",
      "ep 14: ep_len:960 episode reward: total was -49.890000. running mean: -42.167403\n",
      "ep 14: ep_len:965 episode reward: total was -17.370000. running mean: -41.919429\n",
      "ep 14: ep_len:600 episode reward: total was -24.200000. running mean: -41.742234\n",
      "ep 14: ep_len:605 episode reward: total was -8.140000. running mean: -41.406212\n",
      "ep 14: ep_len:515 episode reward: total was -16.190000. running mean: -41.154050\n",
      "ep 14: ep_len:790 episode reward: total was -58.550000. running mean: -41.328009\n",
      "ep 14: ep_len:500 episode reward: total was 1.140000. running mean: -40.903329\n",
      "ep 14: ep_len:500 episode reward: total was 11.800000. running mean: -40.376296\n",
      "ep 14: ep_len:500 episode reward: total was 3.350000. running mean: -39.939033\n",
      "ep 14: ep_len:655 episode reward: total was -9.470000. running mean: -39.634343\n",
      "ep 14: ep_len:1005 episode reward: total was -72.260000. running mean: -39.960599\n",
      "ep 14: ep_len:835 episode reward: total was -47.870000. running mean: -40.039693\n",
      "ep 14: ep_len:500 episode reward: total was 9.170000. running mean: -39.547596\n",
      "ep 14: ep_len:500 episode reward: total was -18.740000. running mean: -39.339520\n",
      "ep 14: ep_len:615 episode reward: total was -5.570000. running mean: -39.001825\n",
      "ep 14: ep_len:209 episode reward: total was 11.500000. running mean: -38.496807\n",
      "ep 14: ep_len:600 episode reward: total was -23.090000. running mean: -38.342739\n",
      "ep 14: ep_len:500 episode reward: total was -19.300000. running mean: -38.152312\n",
      "ep 14: ep_len:1495 episode reward: total was -109.660000. running mean: -38.867388\n",
      "ep 14: ep_len:995 episode reward: total was -85.930000. running mean: -39.338015\n",
      "ep 14: ep_len:1695 episode reward: total was -87.210000. running mean: -39.816734\n",
      "ep 14: ep_len:465 episode reward: total was 14.270000. running mean: -39.275867\n",
      "ep 14: ep_len:185 episode reward: total was 10.000000. running mean: -38.783108\n",
      "ep 14: ep_len:535 episode reward: total was -33.290000. running mean: -38.728177\n",
      "ep 14: ep_len:500 episode reward: total was -5.470000. running mean: -38.395596\n",
      "ep 14: ep_len:14105 episode reward: total was -2616.020000. running mean: -64.171840\n",
      "ep 14: ep_len:500 episode reward: total was -23.550000. running mean: -63.765621\n",
      "ep 14: ep_len:500 episode reward: total was 2.220000. running mean: -63.105765\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 14: ep_len:605 episode reward: total was -7.330000. running mean: -62.548007\n",
      "ep 14: ep_len:500 episode reward: total was 5.680000. running mean: -61.865727\n",
      "ep 14: ep_len:660 episode reward: total was -33.070000. running mean: -61.577770\n",
      "ep 14: ep_len:505 episode reward: total was -15.840000. running mean: -61.120392\n",
      "ep 14: ep_len:500 episode reward: total was -6.870000. running mean: -60.577888\n",
      "ep 14: ep_len:505 episode reward: total was 3.270000. running mean: -59.939409\n",
      "ep 14: ep_len:630 episode reward: total was -30.100000. running mean: -59.641015\n",
      "ep 14: ep_len:500 episode reward: total was 12.140000. running mean: -58.923205\n",
      "ep 14: ep_len:540 episode reward: total was -9.000000. running mean: -58.423973\n",
      "ep 14: ep_len:500 episode reward: total was -43.520000. running mean: -58.274933\n",
      "ep 14: ep_len:182 episode reward: total was 9.000000. running mean: -57.602184\n",
      "ep 14: ep_len:535 episode reward: total was -17.680000. running mean: -57.202962\n",
      "ep 14: ep_len:525 episode reward: total was -21.220000. running mean: -56.843133\n",
      "ep 14: ep_len:500 episode reward: total was -13.320000. running mean: -56.407901\n",
      "ep 14: ep_len:960 episode reward: total was -23.990000. running mean: -56.083722\n",
      "ep 14: ep_len:179 episode reward: total was 2.500000. running mean: -55.497885\n",
      "ep 14: ep_len:500 episode reward: total was -8.850000. running mean: -55.031406\n",
      "ep 14: ep_len:760 episode reward: total was -35.870000. running mean: -54.839792\n",
      "ep 14: ep_len:910 episode reward: total was -62.840000. running mean: -54.919794\n",
      "ep 14: ep_len:685 episode reward: total was -35.010000. running mean: -54.720696\n",
      "ep 14: ep_len:321 episode reward: total was 3.000000. running mean: -54.143489\n",
      "ep 14: ep_len:106 episode reward: total was 6.000000. running mean: -53.542054\n",
      "ep 14: ep_len:500 episode reward: total was -53.280000. running mean: -53.539434\n",
      "ep 14: ep_len:765 episode reward: total was -6.970000. running mean: -53.073740\n",
      "ep 14: ep_len:540 episode reward: total was -28.240000. running mean: -52.825402\n",
      "ep 14: ep_len:640 episode reward: total was -16.950000. running mean: -52.466648\n",
      "ep 14: ep_len:815 episode reward: total was -23.720000. running mean: -52.179182\n",
      "ep 14: ep_len:705 episode reward: total was -27.930000. running mean: -51.936690\n",
      "ep 14: ep_len:500 episode reward: total was -13.490000. running mean: -51.552223\n",
      "ep 14: ep_len:313 episode reward: total was 14.500000. running mean: -50.891701\n",
      "ep 14: ep_len:1245 episode reward: total was -197.540000. running mean: -52.358184\n",
      "ep 14: ep_len:500 episode reward: total was 5.720000. running mean: -51.777402\n",
      "ep 14: ep_len:550 episode reward: total was -40.360000. running mean: -51.663228\n",
      "ep 14: ep_len:217 episode reward: total was 15.500000. running mean: -50.991596\n",
      "ep 14: ep_len:500 episode reward: total was -11.250000. running mean: -50.594180\n",
      "ep 14: ep_len:595 episode reward: total was -18.320000. running mean: -50.271438\n",
      "ep 14: ep_len:1065 episode reward: total was -78.720000. running mean: -50.555923\n",
      "ep 14: ep_len:600 episode reward: total was -44.300000. running mean: -50.493364\n",
      "ep 14: ep_len:500 episode reward: total was 1.760000. running mean: -49.970831\n",
      "ep 14: ep_len:675 episode reward: total was -43.630000. running mean: -49.907422\n",
      "ep 14: ep_len:720 episode reward: total was -39.500000. running mean: -49.803348\n",
      "ep 14: ep_len:920 episode reward: total was -44.850000. running mean: -49.753815\n",
      "ep 14: ep_len:500 episode reward: total was 13.730000. running mean: -49.118976\n",
      "ep 14: ep_len:403 episode reward: total was -6.650000. running mean: -48.694287\n",
      "ep 14: ep_len:540 episode reward: total was -61.590000. running mean: -48.823244\n",
      "ep 14: ep_len:500 episode reward: total was -10.940000. running mean: -48.444411\n",
      "ep 14: ep_len:625 episode reward: total was 3.670000. running mean: -47.923267\n",
      "ep 14: ep_len:1870 episode reward: total was -269.990000. running mean: -50.143935\n",
      "ep 14: ep_len:1350 episode reward: total was -194.380000. running mean: -51.586295\n",
      "ep 14: ep_len:810 episode reward: total was -26.980000. running mean: -51.340232\n",
      "ep 14: ep_len:500 episode reward: total was -21.840000. running mean: -51.045230\n",
      "ep 14: ep_len:885 episode reward: total was -3.310000. running mean: -50.567878\n",
      "ep 14: ep_len:77 episode reward: total was 2.000000. running mean: -50.042199\n",
      "ep 14: ep_len:500 episode reward: total was -17.780000. running mean: -49.719577\n",
      "ep 14: ep_len:177 episode reward: total was 10.500000. running mean: -49.117381\n",
      "ep 14: ep_len:500 episode reward: total was -29.900000. running mean: -48.925207\n",
      "ep 14: ep_len:810 episode reward: total was -21.250000. running mean: -48.648455\n",
      "ep 14: ep_len:580 episode reward: total was -32.510000. running mean: -48.487071\n",
      "ep 14: ep_len:765 episode reward: total was -117.180000. running mean: -49.174000\n",
      "ep 14: ep_len:825 episode reward: total was -13.160000. running mean: -48.813860\n",
      "ep 14: ep_len:505 episode reward: total was -18.990000. running mean: -48.515621\n",
      "ep 14: ep_len:1690 episode reward: total was -181.990000. running mean: -49.850365\n",
      "ep 14: ep_len:570 episode reward: total was -18.100000. running mean: -49.532861\n",
      "ep 14: ep_len:500 episode reward: total was -13.710000. running mean: -49.174633\n",
      "ep 14: ep_len:500 episode reward: total was 26.000000. running mean: -48.422887\n",
      "ep 14: ep_len:985 episode reward: total was -32.040000. running mean: -48.259058\n",
      "ep 14: ep_len:570 episode reward: total was 9.740000. running mean: -47.679067\n",
      "ep 14: ep_len:690 episode reward: total was -30.400000. running mean: -47.506276\n",
      "ep 14: ep_len:915 episode reward: total was -51.330000. running mean: -47.544514\n",
      "ep 14: ep_len:690 episode reward: total was -32.000000. running mean: -47.389069\n",
      "ep 14: ep_len:500 episode reward: total was -36.910000. running mean: -47.284278\n",
      "ep 14: ep_len:645 episode reward: total was -69.460000. running mean: -47.506035\n",
      "ep 14: ep_len:500 episode reward: total was -8.310000. running mean: -47.114075\n",
      "ep 14: ep_len:530 episode reward: total was -44.930000. running mean: -47.092234\n",
      "ep 14: ep_len:1035 episode reward: total was -60.660000. running mean: -47.227912\n",
      "ep 14: ep_len:865 episode reward: total was -18.160000. running mean: -46.937233\n",
      "ep 14: ep_len:208 episode reward: total was 10.000000. running mean: -46.367860\n",
      "ep 14: ep_len:505 episode reward: total was 6.240000. running mean: -45.841782\n",
      "ep 14: ep_len:137 episode reward: total was 6.000000. running mean: -45.323364\n",
      "ep 14: ep_len:505 episode reward: total was -6.650000. running mean: -44.936630\n",
      "ep 14: ep_len:910 episode reward: total was -46.200000. running mean: -44.949264\n",
      "ep 14: ep_len:805 episode reward: total was -37.800000. running mean: -44.877771\n",
      "ep 14: ep_len:500 episode reward: total was 1.710000. running mean: -44.411893\n",
      "ep 14: ep_len:700 episode reward: total was -38.530000. running mean: -44.353075\n",
      "ep 14: ep_len:1160 episode reward: total was -33.340000. running mean: -44.242944\n",
      "ep 14: ep_len:550 episode reward: total was -9.100000. running mean: -43.891514\n",
      "ep 14: ep_len:755 episode reward: total was -44.800000. running mean: -43.900599\n",
      "ep 14: ep_len:1009 episode reward: total was -80.320000. running mean: -44.264793\n",
      "ep 14: ep_len:885 episode reward: total was -40.800000. running mean: -44.230145\n",
      "ep 14: ep_len:500 episode reward: total was -18.330000. running mean: -43.971144\n",
      "ep 14: ep_len:770 episode reward: total was -32.870000. running mean: -43.860132\n",
      "ep 14: ep_len:850 episode reward: total was -18.100000. running mean: -43.602531\n",
      "ep 14: ep_len:850 episode reward: total was -25.820000. running mean: -43.424706\n",
      "ep 14: ep_len:880 episode reward: total was -59.900000. running mean: -43.589459\n",
      "ep 14: ep_len:805 episode reward: total was -94.880000. running mean: -44.102364\n",
      "ep 14: ep_len:915 episode reward: total was -23.740000. running mean: -43.898740\n",
      "ep 14: ep_len:1125 episode reward: total was -23.870000. running mean: -43.698453\n",
      "ep 14: ep_len:1185 episode reward: total was -35.370000. running mean: -43.615169\n",
      "ep 14: ep_len:780 episode reward: total was -58.080000. running mean: -43.759817\n",
      "ep 14: ep_len:500 episode reward: total was -26.280000. running mean: -43.585019\n",
      "ep 14: ep_len:500 episode reward: total was -0.260000. running mean: -43.151769\n",
      "ep 14: ep_len:1650 episode reward: total was -66.890000. running mean: -43.389151\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 14: ep_len:1700 episode reward: total was -125.800000. running mean: -44.213259\n",
      "ep 14: ep_len:590 episode reward: total was -18.690000. running mean: -43.958027\n",
      "ep 14: ep_len:500 episode reward: total was -40.210000. running mean: -43.920546\n",
      "ep 14: ep_len:500 episode reward: total was -7.780000. running mean: -43.559141\n",
      "ep 14: ep_len:3033 episode reward: total was -366.140000. running mean: -46.784950\n",
      "ep 14: ep_len:391 episode reward: total was 18.000000. running mean: -46.137100\n",
      "ep 14: ep_len:845 episode reward: total was -24.700000. running mean: -45.922729\n",
      "ep 14: ep_len:1525 episode reward: total was -57.600000. running mean: -46.039502\n",
      "ep 14: ep_len:575 episode reward: total was -28.220000. running mean: -45.861307\n",
      "ep 14: ep_len:500 episode reward: total was -7.770000. running mean: -45.480394\n",
      "ep 14: ep_len:107 episode reward: total was 4.500000. running mean: -44.980590\n",
      "ep 14: ep_len:205 episode reward: total was 8.500000. running mean: -44.445784\n",
      "ep 14: ep_len:500 episode reward: total was 27.500000. running mean: -43.726326\n",
      "ep 14: ep_len:218 episode reward: total was 11.000000. running mean: -43.179063\n",
      "ep 14: ep_len:515 episode reward: total was -12.290000. running mean: -42.870172\n",
      "ep 14: ep_len:950 episode reward: total was -10.990000. running mean: -42.551370\n",
      "ep 14: ep_len:500 episode reward: total was -13.330000. running mean: -42.259157\n",
      "ep 14: ep_len:525 episode reward: total was -67.330000. running mean: -42.509865\n",
      "ep 14: ep_len:625 episode reward: total was -33.140000. running mean: -42.416167\n",
      "ep 14: ep_len:535 episode reward: total was -43.420000. running mean: -42.426205\n",
      "ep 14: ep_len:500 episode reward: total was -12.880000. running mean: -42.130743\n",
      "ep 14: ep_len:165 episode reward: total was 6.000000. running mean: -41.649435\n",
      "ep 14: ep_len:500 episode reward: total was -21.830000. running mean: -41.451241\n",
      "ep 14: ep_len:500 episode reward: total was 9.780000. running mean: -40.938929\n",
      "ep 14: ep_len:500 episode reward: total was -6.660000. running mean: -40.596139\n",
      "ep 14: ep_len:500 episode reward: total was -26.930000. running mean: -40.459478\n",
      "ep 14: ep_len:720 episode reward: total was -36.990000. running mean: -40.424783\n",
      "ep 14: ep_len:595 episode reward: total was -24.600000. running mean: -40.266535\n",
      "ep 14: ep_len:500 episode reward: total was 9.230000. running mean: -39.771570\n",
      "ep 14: ep_len:500 episode reward: total was -22.400000. running mean: -39.597854\n",
      "ep 14: ep_len:675 episode reward: total was -25.970000. running mean: -39.461576\n",
      "ep 14: ep_len:640 episode reward: total was -27.700000. running mean: -39.343960\n",
      "ep 14: ep_len:685 episode reward: total was -35.010000. running mean: -39.300620\n",
      "ep 14: ep_len:500 episode reward: total was -4.330000. running mean: -38.950914\n",
      "ep 14: ep_len:500 episode reward: total was -20.530000. running mean: -38.766705\n",
      "ep 14: ep_len:1015 episode reward: total was -28.930000. running mean: -38.668338\n",
      "ep 14: ep_len:720 episode reward: total was -27.380000. running mean: -38.555455\n",
      "ep 14: ep_len:985 episode reward: total was -14.950000. running mean: -38.319400\n",
      "ep 14: ep_len:505 episode reward: total was 6.730000. running mean: -37.868906\n",
      "ep 14: ep_len:500 episode reward: total was -13.020000. running mean: -37.620417\n",
      "ep 14: ep_len:655 episode reward: total was -50.250000. running mean: -37.746713\n",
      "ep 14: ep_len:970 episode reward: total was -26.500000. running mean: -37.634246\n",
      "ep 14: ep_len:975 episode reward: total was -69.780000. running mean: -37.955703\n",
      "ep 14: ep_len:965 episode reward: total was -17.130000. running mean: -37.747446\n",
      "ep 14: ep_len:238 episode reward: total was 13.000000. running mean: -37.239972\n",
      "ep 14: ep_len:500 episode reward: total was -4.320000. running mean: -36.910772\n",
      "ep 14: ep_len:150 episode reward: total was -5.500000. running mean: -36.596664\n",
      "ep 14: ep_len:500 episode reward: total was -10.880000. running mean: -36.339498\n",
      "ep 14: ep_len:500 episode reward: total was -5.220000. running mean: -36.028303\n",
      "ep 14: ep_len:510 episode reward: total was -6.420000. running mean: -35.732220\n",
      "ep 14: ep_len:505 episode reward: total was -21.220000. running mean: -35.587097\n",
      "ep 14: ep_len:535 episode reward: total was -34.710000. running mean: -35.578326\n",
      "ep 14: ep_len:1130 episode reward: total was -180.410000. running mean: -37.026643\n",
      "ep 14: ep_len:720 episode reward: total was 4.650000. running mean: -36.609877\n",
      "ep 14: ep_len:610 episode reward: total was -24.080000. running mean: -36.484578\n",
      "ep 14: ep_len:660 episode reward: total was -18.770000. running mean: -36.307432\n",
      "ep 14: ep_len:510 episode reward: total was -28.320000. running mean: -36.227558\n",
      "ep 14: ep_len:585 episode reward: total was -9.220000. running mean: -35.957482\n",
      "ep 14: ep_len:505 episode reward: total was -34.750000. running mean: -35.945408\n",
      "ep 14: ep_len:900 episode reward: total was -44.610000. running mean: -36.032053\n",
      "ep 14: ep_len:1070 episode reward: total was -22.280000. running mean: -35.894533\n",
      "ep 14: ep_len:166 episode reward: total was 1.500000. running mean: -35.520588\n",
      "ep 14: ep_len:805 episode reward: total was -63.080000. running mean: -35.796182\n",
      "ep 14: ep_len:500 episode reward: total was -1.610000. running mean: -35.454320\n",
      "ep 14: ep_len:1585 episode reward: total was -187.400000. running mean: -36.973777\n",
      "ep 14: ep_len:500 episode reward: total was 3.170000. running mean: -36.572339\n",
      "ep 14: ep_len:540 episode reward: total was -33.310000. running mean: -36.539716\n",
      "ep 14: ep_len:750 episode reward: total was -27.500000. running mean: -36.449318\n",
      "ep 14: ep_len:770 episode reward: total was -39.920000. running mean: -36.484025\n",
      "ep 14: ep_len:880 episode reward: total was -23.110000. running mean: -36.350285\n",
      "ep 14: ep_len:311 episode reward: total was 15.000000. running mean: -35.836782\n",
      "ep 14: ep_len:500 episode reward: total was 14.000000. running mean: -35.338414\n",
      "ep 14: ep_len:650 episode reward: total was -21.610000. running mean: -35.201130\n",
      "ep 14: ep_len:620 episode reward: total was -28.310000. running mean: -35.132219\n",
      "ep 14: ep_len:500 episode reward: total was -34.170000. running mean: -35.122597\n",
      "ep 14: ep_len:1175 episode reward: total was -181.140000. running mean: -36.582771\n",
      "ep 14: ep_len:975 episode reward: total was -22.530000. running mean: -36.442243\n",
      "ep 14: ep_len:505 episode reward: total was -19.790000. running mean: -36.275721\n",
      "ep 14: ep_len:500 episode reward: total was 13.420000. running mean: -35.778763\n",
      "ep 14: ep_len:500 episode reward: total was 5.400000. running mean: -35.366976\n",
      "ep 14: ep_len:850 episode reward: total was -35.090000. running mean: -35.364206\n",
      "ep 14: ep_len:192 episode reward: total was 1.500000. running mean: -34.995564\n",
      "ep 14: ep_len:1090 episode reward: total was -134.910000. running mean: -35.994708\n",
      "ep 14: ep_len:710 episode reward: total was -37.500000. running mean: -36.009761\n",
      "ep 14: ep_len:510 episode reward: total was -9.610000. running mean: -35.745764\n",
      "ep 14: ep_len:720 episode reward: total was -54.160000. running mean: -35.929906\n",
      "ep 14: ep_len:685 episode reward: total was -45.140000. running mean: -36.022007\n",
      "ep 14: ep_len:500 episode reward: total was -43.180000. running mean: -36.093587\n",
      "ep 14: ep_len:500 episode reward: total was -14.770000. running mean: -35.880351\n",
      "ep 14: ep_len:745 episode reward: total was -38.960000. running mean: -35.911147\n",
      "ep 14: ep_len:920 episode reward: total was -24.860000. running mean: -35.800636\n",
      "ep 14: ep_len:890 episode reward: total was -10.810000. running mean: -35.550730\n",
      "ep 14: ep_len:745 episode reward: total was -54.110000. running mean: -35.736322\n",
      "ep 14: ep_len:500 episode reward: total was -42.080000. running mean: -35.799759\n",
      "ep 14: ep_len:510 episode reward: total was 10.750000. running mean: -35.334261\n",
      "ep 14: ep_len:625 episode reward: total was -63.950000. running mean: -35.620419\n",
      "ep 14: ep_len:500 episode reward: total was -12.350000. running mean: -35.387715\n",
      "ep 14: ep_len:477 episode reward: total was 17.760000. running mean: -34.856238\n",
      "ep 14: ep_len:500 episode reward: total was 10.700000. running mean: -34.400675\n",
      "ep 14: ep_len:675 episode reward: total was -27.990000. running mean: -34.336568\n",
      "ep 14: ep_len:740 episode reward: total was -14.900000. running mean: -34.142203\n",
      "ep 14: ep_len:1245 episode reward: total was -89.860000. running mean: -34.699381\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 14: ep_len:660 episode reward: total was -13.690000. running mean: -34.489287\n",
      "ep 14: ep_len:500 episode reward: total was 3.750000. running mean: -34.106894\n",
      "ep 14: ep_len:500 episode reward: total was -18.110000. running mean: -33.946925\n",
      "ep 14: ep_len:1035 episode reward: total was -20.370000. running mean: -33.811156\n",
      "ep 14: ep_len:500 episode reward: total was 1.390000. running mean: -33.459144\n",
      "ep 14: ep_len:610 episode reward: total was -25.820000. running mean: -33.382753\n",
      "ep 14: ep_len:725 episode reward: total was -28.870000. running mean: -33.337625\n",
      "ep 14: ep_len:690 episode reward: total was -30.990000. running mean: -33.314149\n",
      "ep 14: ep_len:500 episode reward: total was 1.820000. running mean: -32.962808\n",
      "ep 14: ep_len:500 episode reward: total was -14.250000. running mean: -32.775679\n",
      "ep 14: ep_len:1210 episode reward: total was -153.350000. running mean: -33.981423\n",
      "ep 14: ep_len:500 episode reward: total was 7.850000. running mean: -33.563108\n",
      "ep 14: ep_len:171 episode reward: total was 12.500000. running mean: -33.102477\n",
      "ep 14: ep_len:500 episode reward: total was -35.900000. running mean: -33.130453\n",
      "ep 14: ep_len:570 episode reward: total was -36.260000. running mean: -33.161748\n",
      "ep 14: ep_len:725 episode reward: total was -10.040000. running mean: -32.930531\n",
      "ep 14: ep_len:375 episode reward: total was -11.470000. running mean: -32.715925\n",
      "ep 14: ep_len:499 episode reward: total was 13.150000. running mean: -32.257266\n",
      "ep 14: ep_len:500 episode reward: total was -3.260000. running mean: -31.967293\n",
      "ep 14: ep_len:545 episode reward: total was -19.880000. running mean: -31.846420\n",
      "ep 14: ep_len:500 episode reward: total was 0.230000. running mean: -31.525656\n",
      "ep 14: ep_len:910 episode reward: total was -59.840000. running mean: -31.808800\n",
      "ep 14: ep_len:875 episode reward: total was -19.620000. running mean: -31.686912\n",
      "ep 14: ep_len:500 episode reward: total was 1.680000. running mean: -31.353243\n",
      "ep 14: ep_len:500 episode reward: total was -61.300000. running mean: -31.652710\n",
      "ep 14: ep_len:500 episode reward: total was -21.760000. running mean: -31.553783\n",
      "ep 14: ep_len:500 episode reward: total was -10.300000. running mean: -31.341245\n",
      "ep 14: ep_len:500 episode reward: total was 11.310000. running mean: -30.914733\n",
      "ep 14: ep_len:975 episode reward: total was -19.040000. running mean: -30.795985\n",
      "ep 14: ep_len:505 episode reward: total was -10.870000. running mean: -30.596726\n",
      "ep 14: ep_len:212 episode reward: total was 9.500000. running mean: -30.195758\n",
      "ep 14: ep_len:215 episode reward: total was -2.000000. running mean: -29.913801\n",
      "ep 14: ep_len:500 episode reward: total was -7.690000. running mean: -29.691563\n",
      "ep 14: ep_len:194 episode reward: total was 7.000000. running mean: -29.324647\n",
      "ep 14: ep_len:695 episode reward: total was -40.040000. running mean: -29.431801\n",
      "ep 14: ep_len:800 episode reward: total was -18.140000. running mean: -29.318883\n",
      "ep 14: ep_len:555 episode reward: total was -38.300000. running mean: -29.408694\n",
      "ep 14: ep_len:695 episode reward: total was -23.910000. running mean: -29.353707\n",
      "ep 14: ep_len:500 episode reward: total was -3.270000. running mean: -29.092870\n",
      "ep 14: ep_len:620 episode reward: total was -30.120000. running mean: -29.103141\n",
      "ep 14: ep_len:695 episode reward: total was -34.500000. running mean: -29.157110\n",
      "ep 14: ep_len:525 episode reward: total was -37.870000. running mean: -29.244239\n",
      "ep 14: ep_len:505 episode reward: total was -1.290000. running mean: -28.964696\n",
      "ep 14: ep_len:840 episode reward: total was -71.850000. running mean: -29.393549\n",
      "ep 14: ep_len:1235 episode reward: total was -168.270000. running mean: -30.782314\n",
      "ep 14: ep_len:830 episode reward: total was -18.150000. running mean: -30.655991\n",
      "ep 14: ep_len:740 episode reward: total was 2.580000. running mean: -30.323631\n",
      "ep 14: ep_len:580 episode reward: total was -13.030000. running mean: -30.150694\n",
      "ep 14: ep_len:375 episode reward: total was 8.500000. running mean: -29.764187\n",
      "ep 14: ep_len:179 episode reward: total was 7.000000. running mean: -29.396546\n",
      "ep 14: ep_len:840 episode reward: total was -25.140000. running mean: -29.353980\n",
      "ep 14: ep_len:1105 episode reward: total was -125.100000. running mean: -30.311440\n",
      "ep 14: ep_len:695 episode reward: total was -43.320000. running mean: -30.441526\n",
      "ep 14: ep_len:595 episode reward: total was -18.670000. running mean: -30.323811\n",
      "ep 14: ep_len:500 episode reward: total was 7.330000. running mean: -29.947273\n",
      "ep 14: ep_len:855 episode reward: total was -65.210000. running mean: -30.299900\n",
      "ep 14: ep_len:1490 episode reward: total was -161.700000. running mean: -31.613901\n",
      "ep 14: ep_len:730 episode reward: total was -41.010000. running mean: -31.707862\n",
      "ep 14: ep_len:500 episode reward: total was 21.000000. running mean: -31.180783\n",
      "ep 14: ep_len:1065 episode reward: total was -25.850000. running mean: -31.127475\n",
      "ep 14: ep_len:810 episode reward: total was -52.550000. running mean: -31.341701\n",
      "ep 14: ep_len:565 episode reward: total was -46.390000. running mean: -31.492184\n",
      "ep 14: ep_len:750 episode reward: total was -29.860000. running mean: -31.475862\n",
      "ep 14: ep_len:242 episode reward: total was 22.500000. running mean: -30.936103\n",
      "ep 14: ep_len:1065 episode reward: total was -82.240000. running mean: -31.449142\n",
      "ep 14: ep_len:530 episode reward: total was -34.340000. running mean: -31.478051\n",
      "ep 14: ep_len:675 episode reward: total was -31.040000. running mean: -31.473670\n",
      "ep 14: ep_len:500 episode reward: total was -10.890000. running mean: -31.267833\n",
      "ep 14: ep_len:189 episode reward: total was 12.500000. running mean: -30.830155\n",
      "ep 14: ep_len:500 episode reward: total was -20.110000. running mean: -30.722954\n",
      "ep 14: ep_len:965 episode reward: total was -66.180000. running mean: -31.077524\n",
      "ep 14: ep_len:800 episode reward: total was -51.510000. running mean: -31.281849\n",
      "ep 14: ep_len:785 episode reward: total was -58.290000. running mean: -31.551930\n",
      "ep 14: ep_len:565 episode reward: total was -28.210000. running mean: -31.518511\n",
      "ep 14: ep_len:173 episode reward: total was 14.000000. running mean: -31.063326\n",
      "ep 14: ep_len:338 episode reward: total was 20.500000. running mean: -30.547693\n",
      "ep 14: ep_len:428 episode reward: total was 10.000000. running mean: -30.142216\n",
      "ep 14: ep_len:845 episode reward: total was -95.810000. running mean: -30.798894\n",
      "ep 14: ep_len:500 episode reward: total was -24.540000. running mean: -30.736305\n",
      "ep 14: ep_len:222 episode reward: total was 11.500000. running mean: -30.313942\n",
      "ep 14: ep_len:740 episode reward: total was -3.930000. running mean: -30.050102\n",
      "ep 14: ep_len:945 episode reward: total was -95.610000. running mean: -30.705701\n",
      "ep 14: ep_len:500 episode reward: total was 6.870000. running mean: -30.329944\n",
      "ep 14: ep_len:257 episode reward: total was 12.000000. running mean: -29.906645\n",
      "ep 14: ep_len:500 episode reward: total was 11.770000. running mean: -29.489878\n",
      "ep 14: ep_len:625 episode reward: total was -43.240000. running mean: -29.627379\n",
      "ep 14: ep_len:433 episode reward: total was -6.770000. running mean: -29.398806\n",
      "ep 14: ep_len:965 episode reward: total was -28.280000. running mean: -29.387618\n",
      "ep 14: ep_len:545 episode reward: total was -9.260000. running mean: -29.186341\n",
      "ep 14: ep_len:515 episode reward: total was -23.230000. running mean: -29.126778\n",
      "ep 14: ep_len:500 episode reward: total was -26.840000. running mean: -29.103910\n",
      "ep 14: ep_len:825 episode reward: total was -40.820000. running mean: -29.221071\n",
      "ep 14: ep_len:505 episode reward: total was -52.770000. running mean: -29.456560\n",
      "ep 14: ep_len:500 episode reward: total was 5.680000. running mean: -29.105195\n",
      "ep 14: ep_len:545 episode reward: total was -61.060000. running mean: -29.424743\n",
      "ep 14: ep_len:555 episode reward: total was -41.850000. running mean: -29.548995\n",
      "ep 14: ep_len:615 episode reward: total was -30.050000. running mean: -29.554005\n",
      "ep 14: ep_len:1020 episode reward: total was -70.210000. running mean: -29.960565\n",
      "ep 14: ep_len:505 episode reward: total was -23.300000. running mean: -29.893960\n",
      "ep 14: ep_len:835 episode reward: total was -50.280000. running mean: -30.097820\n",
      "ep 14: ep_len:290 episode reward: total was 17.500000. running mean: -29.621842\n",
      "ep 14: ep_len:950 episode reward: total was -43.640000. running mean: -29.762024\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 14: ep_len:675 episode reward: total was -22.420000. running mean: -29.688603\n",
      "ep 14: ep_len:855 episode reward: total was -31.390000. running mean: -29.705617\n",
      "ep 14: ep_len:500 episode reward: total was 15.240000. running mean: -29.256161\n",
      "ep 14: ep_len:199 episode reward: total was 9.000000. running mean: -28.873600\n",
      "ep 14: ep_len:980 episode reward: total was -29.510000. running mean: -28.879964\n",
      "ep 14: ep_len:500 episode reward: total was 17.710000. running mean: -28.414064\n",
      "ep 14: ep_len:1340 episode reward: total was -128.670000. running mean: -29.416623\n",
      "ep 14: ep_len:515 episode reward: total was 27.500000. running mean: -28.847457\n",
      "ep 14: ep_len:765 episode reward: total was -28.720000. running mean: -28.846182\n",
      "ep 14: ep_len:835 episode reward: total was -43.110000. running mean: -28.988821\n",
      "ep 14: ep_len:500 episode reward: total was -18.800000. running mean: -28.886932\n",
      "ep 14: ep_len:520 episode reward: total was -22.240000. running mean: -28.820463\n",
      "ep 14: ep_len:500 episode reward: total was -20.860000. running mean: -28.740858\n",
      "ep 14: ep_len:795 episode reward: total was -93.150000. running mean: -29.384950\n",
      "ep 14: ep_len:161 episode reward: total was 9.000000. running mean: -29.001100\n",
      "ep 14: ep_len:500 episode reward: total was -77.340000. running mean: -29.484489\n",
      "ep 14: ep_len:550 episode reward: total was -38.340000. running mean: -29.573044\n",
      "ep 14: ep_len:500 episode reward: total was -11.210000. running mean: -29.389414\n",
      "ep 14: ep_len:1025 episode reward: total was -44.100000. running mean: -29.536520\n",
      "ep 14: ep_len:213 episode reward: total was 12.000000. running mean: -29.121155\n",
      "ep 14: ep_len:1057 episode reward: total was -125.180000. running mean: -30.081743\n",
      "ep 14: ep_len:505 episode reward: total was -0.830000. running mean: -29.789226\n",
      "ep 14: ep_len:685 episode reward: total was -21.390000. running mean: -29.705233\n",
      "ep 14: ep_len:540 episode reward: total was -20.180000. running mean: -29.609981\n",
      "ep 14: ep_len:520 episode reward: total was -31.330000. running mean: -29.627181\n",
      "ep 14: ep_len:500 episode reward: total was 3.170000. running mean: -29.299209\n",
      "ep 14: ep_len:585 episode reward: total was -68.590000. running mean: -29.692117\n",
      "ep 14: ep_len:660 episode reward: total was 9.180000. running mean: -29.303396\n",
      "ep 14: ep_len:690 episode reward: total was -22.910000. running mean: -29.239462\n",
      "ep 14: ep_len:500 episode reward: total was -18.500000. running mean: -29.132068\n",
      "ep 14: ep_len:560 episode reward: total was -30.240000. running mean: -29.143147\n",
      "ep 14: ep_len:500 episode reward: total was -17.380000. running mean: -29.025515\n",
      "ep 14: ep_len:505 episode reward: total was -6.350000. running mean: -28.798760\n",
      "ep 14: ep_len:178 episode reward: total was 10.000000. running mean: -28.410773\n",
      "ep 14: ep_len:500 episode reward: total was -27.030000. running mean: -28.396965\n",
      "ep 14: ep_len:510 episode reward: total was -81.470000. running mean: -28.927695\n",
      "ep 14: ep_len:500 episode reward: total was 14.740000. running mean: -28.491018\n",
      "ep 14: ep_len:1045 episode reward: total was -22.500000. running mean: -28.431108\n",
      "ep 14: ep_len:695 episode reward: total was -22.900000. running mean: -28.375797\n",
      "ep 14: ep_len:231 episode reward: total was 16.000000. running mean: -27.932039\n",
      "ep 14: ep_len:945 episode reward: total was -49.360000. running mean: -28.146319\n",
      "ep 14: ep_len:685 episode reward: total was -40.720000. running mean: -28.272056\n",
      "ep 14: ep_len:301 episode reward: total was 12.000000. running mean: -27.869335\n",
      "ep 14: ep_len:570 episode reward: total was -28.200000. running mean: -27.872642\n",
      "ep 14: ep_len:515 episode reward: total was -17.990000. running mean: -27.773815\n",
      "ep 14: ep_len:545 episode reward: total was -35.320000. running mean: -27.849277\n",
      "ep 14: ep_len:500 episode reward: total was -19.720000. running mean: -27.767984\n",
      "ep 14: ep_len:500 episode reward: total was -40.320000. running mean: -27.893504\n",
      "ep 14: ep_len:500 episode reward: total was -15.200000. running mean: -27.766569\n",
      "ep 14: ep_len:555 episode reward: total was -51.950000. running mean: -28.008404\n",
      "ep 14: ep_len:500 episode reward: total was -17.320000. running mean: -27.901520\n",
      "ep 14: ep_len:500 episode reward: total was -8.430000. running mean: -27.706805\n",
      "ep 14: ep_len:1440 episode reward: total was -125.930000. running mean: -28.689036\n",
      "ep 14: ep_len:500 episode reward: total was -0.350000. running mean: -28.405646\n",
      "ep 14: ep_len:710 episode reward: total was -45.090000. running mean: -28.572490\n",
      "ep 14: ep_len:710 episode reward: total was -19.320000. running mean: -28.479965\n",
      "ep 14: ep_len:785 episode reward: total was -74.000000. running mean: -28.935165\n",
      "ep 14: ep_len:1010 episode reward: total was -109.130000. running mean: -29.737113\n",
      "ep 14: ep_len:505 episode reward: total was 7.680000. running mean: -29.362942\n",
      "ep 14: ep_len:1625 episode reward: total was -124.450000. running mean: -30.313813\n",
      "ep 14: ep_len:500 episode reward: total was -9.300000. running mean: -30.103675\n",
      "ep 14: ep_len:915 episode reward: total was -31.040000. running mean: -30.113038\n",
      "ep 14: ep_len:830 episode reward: total was -31.720000. running mean: -30.129108\n",
      "ep 14: ep_len:1105 episode reward: total was -32.840000. running mean: -30.156217\n",
      "ep 14: ep_len:625 episode reward: total was -4.860000. running mean: -29.903254\n",
      "ep 14: ep_len:143 episode reward: total was 12.500000. running mean: -29.479222\n",
      "ep 14: ep_len:780 episode reward: total was -35.860000. running mean: -29.543030\n",
      "ep 14: ep_len:510 episode reward: total was 25.500000. running mean: -28.992599\n",
      "ep 14: ep_len:735 episode reward: total was -24.840000. running mean: -28.951073\n",
      "ep 14: ep_len:1480 episode reward: total was -140.920000. running mean: -30.070763\n",
      "ep 14: ep_len:500 episode reward: total was 13.270000. running mean: -29.637355\n",
      "ep 14: ep_len:895 episode reward: total was -70.980000. running mean: -30.050781\n",
      "ep 14: ep_len:500 episode reward: total was -4.740000. running mean: -29.797674\n",
      "ep 14: ep_len:257 episode reward: total was 15.000000. running mean: -29.349697\n",
      "ep 14: ep_len:1215 episode reward: total was -36.300000. running mean: -29.419200\n",
      "ep 14: ep_len:635 episode reward: total was -48.270000. running mean: -29.607708\n",
      "ep 14: ep_len:915 episode reward: total was -32.770000. running mean: -29.639331\n",
      "ep 14: ep_len:920 episode reward: total was -10.350000. running mean: -29.446438\n",
      "ep 14: ep_len:1200 episode reward: total was -175.900000. running mean: -30.910973\n",
      "ep 14: ep_len:500 episode reward: total was -17.260000. running mean: -30.774463\n",
      "ep 14: ep_len:748 episode reward: total was -82.370000. running mean: -31.290419\n",
      "ep 14: ep_len:770 episode reward: total was -19.720000. running mean: -31.174715\n",
      "ep 14: ep_len:471 episode reward: total was 30.500000. running mean: -30.557967\n",
      "ep 14: ep_len:920 episode reward: total was -18.110000. running mean: -30.433488\n",
      "ep 14: ep_len:500 episode reward: total was 28.000000. running mean: -29.849153\n",
      "ep 14: ep_len:1500 episode reward: total was -158.650000. running mean: -31.137161\n",
      "ep 14: ep_len:500 episode reward: total was -13.330000. running mean: -30.959090\n",
      "ep 14: ep_len:539 episode reward: total was -65.730000. running mean: -31.306799\n",
      "ep 14: ep_len:580 episode reward: total was -53.430000. running mean: -31.528031\n",
      "ep 14: ep_len:640 episode reward: total was -42.350000. running mean: -31.636251\n",
      "ep 14: ep_len:1150 episode reward: total was -60.760000. running mean: -31.927488\n",
      "ep 14: ep_len:500 episode reward: total was -30.450000. running mean: -31.912713\n",
      "ep 14: ep_len:500 episode reward: total was -24.910000. running mean: -31.842686\n",
      "ep 14: ep_len:500 episode reward: total was -12.260000. running mean: -31.646859\n",
      "ep 14: ep_len:675 episode reward: total was -30.200000. running mean: -31.632391\n",
      "ep 14: ep_len:221 episode reward: total was 12.000000. running mean: -31.196067\n",
      "ep 14: ep_len:500 episode reward: total was -25.400000. running mean: -31.138106\n",
      "ep 14: ep_len:640 episode reward: total was -84.620000. running mean: -31.672925\n",
      "ep 14: ep_len:750 episode reward: total was -23.600000. running mean: -31.592196\n",
      "ep 14: ep_len:500 episode reward: total was -28.170000. running mean: -31.557974\n",
      "ep 14: ep_len:880 episode reward: total was -38.230000. running mean: -31.624694\n",
      "ep 14: ep_len:730 episode reward: total was -66.260000. running mean: -31.971047\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 14: ep_len:505 episode reward: total was -9.310000. running mean: -31.744437\n",
      "ep 14: ep_len:505 episode reward: total was -19.650000. running mean: -31.623492\n",
      "ep 14: ep_len:640 episode reward: total was -64.420000. running mean: -31.951457\n",
      "ep 14: ep_len:735 episode reward: total was -49.570000. running mean: -32.127643\n",
      "ep 14: ep_len:500 episode reward: total was 7.220000. running mean: -31.734166\n",
      "ep 14: ep_len:590 episode reward: total was -35.750000. running mean: -31.774325\n",
      "ep 14: ep_len:510 episode reward: total was -46.470000. running mean: -31.921281\n",
      "ep 14: ep_len:510 episode reward: total was 1.200000. running mean: -31.590069\n",
      "ep 14: ep_len:1255 episode reward: total was -125.790000. running mean: -32.532068\n",
      "ep 14: ep_len:500 episode reward: total was 0.320000. running mean: -32.203547\n",
      "ep 14: ep_len:500 episode reward: total was -13.390000. running mean: -32.015412\n",
      "ep 14: ep_len:615 episode reward: total was -54.370000. running mean: -32.238958\n",
      "ep 14: ep_len:925 episode reward: total was -23.660000. running mean: -32.153168\n",
      "ep 14: ep_len:500 episode reward: total was -3.780000. running mean: -31.869436\n",
      "ep 14: ep_len:505 episode reward: total was -14.360000. running mean: -31.694342\n",
      "ep 14: ep_len:690 episode reward: total was -22.910000. running mean: -31.606499\n",
      "ep 14: ep_len:500 episode reward: total was -19.280000. running mean: -31.483234\n",
      "ep 14: ep_len:1300 episode reward: total was -180.670000. running mean: -32.975101\n",
      "ep 14: ep_len:500 episode reward: total was -10.370000. running mean: -32.749050\n",
      "ep 14: ep_len:605 episode reward: total was -38.230000. running mean: -32.803860\n",
      "ep 14: ep_len:975 episode reward: total was -46.060000. running mean: -32.936421\n",
      "ep 14: ep_len:1055 episode reward: total was -21.160000. running mean: -32.818657\n",
      "ep 14: ep_len:515 episode reward: total was -43.460000. running mean: -32.925070\n",
      "ep 14: ep_len:500 episode reward: total was -15.720000. running mean: -32.753020\n",
      "ep 14: ep_len:214 episode reward: total was 10.500000. running mean: -32.320489\n",
      "ep 14: ep_len:317 episode reward: total was -2.500000. running mean: -32.022285\n",
      "ep 14: ep_len:575 episode reward: total was -21.790000. running mean: -31.919962\n",
      "ep 14: ep_len:630 episode reward: total was -11.970000. running mean: -31.720462\n",
      "ep 14: ep_len:500 episode reward: total was -26.320000. running mean: -31.666458\n",
      "ep 14: ep_len:925 episode reward: total was -129.500000. running mean: -32.644793\n",
      "ep 14: ep_len:990 episode reward: total was -49.620000. running mean: -32.814545\n",
      "ep 14: ep_len:500 episode reward: total was -20.870000. running mean: -32.695100\n",
      "ep 14: ep_len:505 episode reward: total was -28.450000. running mean: -32.652649\n",
      "ep 14: ep_len:525 episode reward: total was -9.330000. running mean: -32.419422\n",
      "ep 14: ep_len:500 episode reward: total was 3.750000. running mean: -32.057728\n",
      "ep 14: ep_len:715 episode reward: total was -17.520000. running mean: -31.912351\n",
      "ep 14: ep_len:307 episode reward: total was 17.500000. running mean: -31.418227\n",
      "ep 14: ep_len:214 episode reward: total was 8.000000. running mean: -31.024045\n",
      "ep 14: ep_len:515 episode reward: total was -16.750000. running mean: -30.881304\n",
      "ep 14: ep_len:785 episode reward: total was -28.780000. running mean: -30.860291\n",
      "ep 14: ep_len:930 episode reward: total was -42.040000. running mean: -30.972088\n",
      "ep 14: ep_len:505 episode reward: total was -31.850000. running mean: -30.980868\n",
      "ep 14: ep_len:500 episode reward: total was -18.660000. running mean: -30.857659\n",
      "ep 14: ep_len:208 episode reward: total was 16.000000. running mean: -30.389082\n",
      "ep 14: ep_len:500 episode reward: total was -1.760000. running mean: -30.102791\n",
      "ep 14: ep_len:720 episode reward: total was -54.650000. running mean: -30.348264\n",
      "ep 14: ep_len:510 episode reward: total was -45.460000. running mean: -30.499381\n",
      "ep 14: ep_len:500 episode reward: total was -21.320000. running mean: -30.407587\n",
      "ep 14: ep_len:515 episode reward: total was -5.960000. running mean: -30.163111\n",
      "ep 14: ep_len:1070 episode reward: total was -38.030000. running mean: -30.241780\n",
      "ep 14: ep_len:650 episode reward: total was -40.160000. running mean: -30.340962\n",
      "ep 14: ep_len:875 episode reward: total was -22.960000. running mean: -30.267153\n",
      "ep 14: ep_len:500 episode reward: total was 11.770000. running mean: -29.846781\n",
      "ep 14: ep_len:500 episode reward: total was -18.740000. running mean: -29.735713\n",
      "ep 14: ep_len:505 episode reward: total was 12.210000. running mean: -29.316256\n",
      "ep 14: ep_len:41975 episode reward: total was -8141.570000. running mean: -110.438794\n",
      "ep 14: ep_len:755 episode reward: total was -128.830000. running mean: -110.622706\n",
      "ep 14: ep_len:600 episode reward: total was 9.600000. running mean: -109.420479\n",
      "ep 14: ep_len:585 episode reward: total was -51.400000. running mean: -108.840274\n",
      "ep 14: ep_len:845 episode reward: total was -108.940000. running mean: -108.841271\n",
      "ep 14: ep_len:600 episode reward: total was -84.700000. running mean: -108.599858\n",
      "ep 14: ep_len:500 episode reward: total was -36.930000. running mean: -107.883160\n",
      "ep 14: ep_len:840 episode reward: total was -153.910000. running mean: -108.343428\n",
      "ep 14: ep_len:780 episode reward: total was -101.930000. running mean: -108.279294\n",
      "ep 14: ep_len:500 episode reward: total was -23.000000. running mean: -107.426501\n",
      "ep 14: ep_len:500 episode reward: total was -32.000000. running mean: -106.672236\n",
      "ep 14: ep_len:500 episode reward: total was -38.910000. running mean: -105.994614\n",
      "ep 14: ep_len:500 episode reward: total was -33.840000. running mean: -105.273067\n",
      "ep 14: ep_len:575 episode reward: total was -16.280000. running mean: -104.383137\n",
      "ep 14: ep_len:615 episode reward: total was -53.720000. running mean: -103.876505\n",
      "ep 14: ep_len:945 episode reward: total was -62.950000. running mean: -103.467240\n",
      "ep 14: ep_len:1825 episode reward: total was -153.630000. running mean: -103.968868\n",
      "ep 14: ep_len:500 episode reward: total was -13.270000. running mean: -103.061879\n",
      "ep 14: ep_len:297 episode reward: total was 7.500000. running mean: -101.956261\n",
      "ep 14: ep_len:665 episode reward: total was -51.110000. running mean: -101.447798\n",
      "ep 14: ep_len:500 episode reward: total was -34.570000. running mean: -100.779020\n",
      "ep 14: ep_len:910 episode reward: total was -36.040000. running mean: -100.131630\n",
      "ep 14: ep_len:500 episode reward: total was -54.660000. running mean: -99.676913\n",
      "ep 14: ep_len:500 episode reward: total was -33.500000. running mean: -99.015144\n",
      "ep 14: ep_len:1485 episode reward: total was -202.110000. running mean: -100.046093\n",
      "ep 14: ep_len:510 episode reward: total was -27.460000. running mean: -99.320232\n",
      "ep 14: ep_len:745 episode reward: total was -98.550000. running mean: -99.312530\n",
      "ep 14: ep_len:715 episode reward: total was -80.920000. running mean: -99.128604\n",
      "ep 14: ep_len:885 episode reward: total was -48.430000. running mean: -98.621618\n",
      "ep 14: ep_len:500 episode reward: total was -13.520000. running mean: -97.770602\n",
      "ep 14: ep_len:555 episode reward: total was -37.320000. running mean: -97.166096\n",
      "ep 14: ep_len:530 episode reward: total was -69.930000. running mean: -96.893735\n",
      "ep 14: ep_len:545 episode reward: total was -42.720000. running mean: -96.351998\n",
      "ep 14: ep_len:1470 episode reward: total was -170.830000. running mean: -97.096778\n",
      "ep 14: ep_len:1020 episode reward: total was -129.310000. running mean: -97.418910\n",
      "ep 14: ep_len:500 episode reward: total was -30.770000. running mean: -96.752421\n",
      "ep 14: ep_len:655 episode reward: total was -50.940000. running mean: -96.294297\n",
      "ep 14: ep_len:720 episode reward: total was -26.890000. running mean: -95.600254\n",
      "ep 14: ep_len:535 episode reward: total was -32.800000. running mean: -94.972251\n",
      "ep 14: ep_len:474 episode reward: total was -21.760000. running mean: -94.240129\n",
      "ep 14: ep_len:685 episode reward: total was -16.470000. running mean: -93.462427\n",
      "ep 14: ep_len:760 episode reward: total was -38.440000. running mean: -92.912203\n",
      "ep 14: ep_len:500 episode reward: total was -28.950000. running mean: -92.272581\n",
      "ep 14: ep_len:560 episode reward: total was -25.190000. running mean: -91.601755\n",
      "ep 14: ep_len:555 episode reward: total was -29.310000. running mean: -90.978838\n",
      "ep 14: ep_len:575 episode reward: total was -39.300000. running mean: -90.462049\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 14: ep_len:500 episode reward: total was -15.390000. running mean: -89.711329\n",
      "ep 14: ep_len:500 episode reward: total was 0.690000. running mean: -88.807316\n",
      "ep 14: ep_len:500 episode reward: total was -4.360000. running mean: -87.962842\n",
      "ep 14: ep_len:1000 episode reward: total was -85.920000. running mean: -87.942414\n",
      "ep 14: ep_len:740 episode reward: total was -36.680000. running mean: -87.429790\n",
      "ep 14: ep_len:500 episode reward: total was -15.750000. running mean: -86.712992\n",
      "ep 14: ep_len:975 episode reward: total was -32.430000. running mean: -86.170162\n",
      "ep 14: ep_len:765 episode reward: total was -53.060000. running mean: -85.839060\n",
      "ep 14: ep_len:77 episode reward: total was -1.000000. running mean: -84.990670\n",
      "ep 14: ep_len:129 episode reward: total was 2.500000. running mean: -84.115763\n",
      "ep 14: ep_len:500 episode reward: total was -4.850000. running mean: -83.323105\n",
      "ep 14: ep_len:995 episode reward: total was -40.030000. running mean: -82.890174\n",
      "ep 14: ep_len:815 episode reward: total was -55.570000. running mean: -82.616973\n",
      "ep 14: ep_len:500 episode reward: total was 1.180000. running mean: -81.779003\n",
      "ep 14: ep_len:880 episode reward: total was -42.330000. running mean: -81.384513\n",
      "ep 14: ep_len:505 episode reward: total was -5.840000. running mean: -80.629068\n",
      "ep 14: ep_len:144 episode reward: total was -2.000000. running mean: -79.842777\n",
      "ep 14: ep_len:500 episode reward: total was -29.040000. running mean: -79.334749\n",
      "ep 14: ep_len:310 episode reward: total was 10.500000. running mean: -78.436402\n",
      "ep 14: ep_len:725 episode reward: total was -21.540000. running mean: -77.867438\n",
      "ep 14: ep_len:525 episode reward: total was -34.440000. running mean: -77.433163\n",
      "ep 14: ep_len:103 episode reward: total was 7.000000. running mean: -76.588832\n",
      "ep 14: ep_len:535 episode reward: total was -10.630000. running mean: -75.929243\n",
      "ep 14: ep_len:685 episode reward: total was -92.580000. running mean: -76.095751\n",
      "ep 14: ep_len:505 episode reward: total was -17.940000. running mean: -75.514194\n",
      "ep 14: ep_len:745 episode reward: total was -36.940000. running mean: -75.128452\n",
      "ep 14: ep_len:500 episode reward: total was -8.900000. running mean: -74.466167\n",
      "ep 14: ep_len:153 episode reward: total was 4.500000. running mean: -73.676505\n",
      "ep 14: ep_len:500 episode reward: total was -6.820000. running mean: -73.007940\n",
      "ep 14: ep_len:775 episode reward: total was -67.380000. running mean: -72.951661\n",
      "ep 14: ep_len:955 episode reward: total was -10.410000. running mean: -72.326244\n",
      "ep 14: ep_len:845 episode reward: total was -43.810000. running mean: -72.041082\n",
      "ep 14: ep_len:845 episode reward: total was -41.790000. running mean: -71.738571\n",
      "ep 14: ep_len:500 episode reward: total was -7.030000. running mean: -71.091485\n",
      "ep 14: ep_len:500 episode reward: total was -6.840000. running mean: -70.448971\n",
      "ep 14: ep_len:600 episode reward: total was -44.300000. running mean: -70.187481\n",
      "ep 14: ep_len:525 episode reward: total was -27.280000. running mean: -69.758406\n",
      "ep 14: ep_len:500 episode reward: total was -20.000000. running mean: -69.260822\n",
      "ep 14: ep_len:635 episode reward: total was -36.990000. running mean: -68.938114\n",
      "ep 14: ep_len:1215 episode reward: total was -107.710000. running mean: -69.325833\n",
      "ep 14: ep_len:500 episode reward: total was -12.440000. running mean: -68.756974\n",
      "ep 14: ep_len:570 episode reward: total was -20.850000. running mean: -68.277905\n",
      "ep 14: ep_len:500 episode reward: total was -20.160000. running mean: -67.796725\n",
      "ep 14: ep_len:650 episode reward: total was -49.510000. running mean: -67.613858\n",
      "ep 14: ep_len:237 episode reward: total was 12.000000. running mean: -66.817720\n",
      "ep 14: ep_len:630 episode reward: total was -30.480000. running mean: -66.454342\n",
      "ep 14: ep_len:870 episode reward: total was -21.470000. running mean: -66.004499\n",
      "ep 14: ep_len:505 episode reward: total was -30.670000. running mean: -65.651154\n",
      "ep 14: ep_len:500 episode reward: total was -9.940000. running mean: -65.094042\n",
      "ep 14: ep_len:500 episode reward: total was -24.850000. running mean: -64.691602\n",
      "ep 14: ep_len:500 episode reward: total was -8.870000. running mean: -64.133386\n",
      "ep 14: ep_len:830 episode reward: total was -17.710000. running mean: -63.669152\n",
      "ep 14: ep_len:500 episode reward: total was -0.900000. running mean: -63.041461\n",
      "ep 14: ep_len:750 episode reward: total was -49.570000. running mean: -62.906746\n",
      "ep 14: ep_len:900 episode reward: total was -92.200000. running mean: -63.199679\n",
      "ep 14: ep_len:500 episode reward: total was -3.840000. running mean: -62.606082\n",
      "ep 14: ep_len:500 episode reward: total was -8.590000. running mean: -62.065921\n",
      "ep 14: ep_len:935 episode reward: total was -45.130000. running mean: -61.896562\n",
      "ep 14: ep_len:800 episode reward: total was -35.820000. running mean: -61.635796\n",
      "ep 14: ep_len:165 episode reward: total was 7.500000. running mean: -60.944438\n",
      "ep 14: ep_len:505 episode reward: total was -15.560000. running mean: -60.490594\n",
      "ep 14: ep_len:290 episode reward: total was 3.690000. running mean: -59.848788\n",
      "ep 14: ep_len:655 episode reward: total was -30.600000. running mean: -59.556300\n",
      "ep 14: ep_len:189 episode reward: total was 8.500000. running mean: -58.875737\n",
      "ep 14: ep_len:625 episode reward: total was -8.000000. running mean: -58.366980\n",
      "ep 14: ep_len:610 episode reward: total was -41.220000. running mean: -58.195510\n",
      "ep 14: ep_len:296 episode reward: total was 22.500000. running mean: -57.388555\n",
      "ep 14: ep_len:500 episode reward: total was -28.460000. running mean: -57.099269\n",
      "ep 14: ep_len:1810 episode reward: total was -144.900000. running mean: -57.977277\n",
      "ep 14: ep_len:500 episode reward: total was 33.500000. running mean: -57.062504\n",
      "ep 14: ep_len:965 episode reward: total was 0.090000. running mean: -56.490979\n",
      "ep 14: ep_len:810 episode reward: total was -41.860000. running mean: -56.344669\n",
      "ep 14: ep_len:510 episode reward: total was 1.660000. running mean: -55.764622\n",
      "ep 14: ep_len:695 episode reward: total was -7.370000. running mean: -55.280676\n",
      "ep 14: ep_len:830 episode reward: total was -33.740000. running mean: -55.065269\n",
      "ep 14: ep_len:500 episode reward: total was -7.710000. running mean: -54.591717\n",
      "ep 14: ep_len:500 episode reward: total was -28.760000. running mean: -54.333399\n",
      "ep 14: ep_len:200 episode reward: total was 8.000000. running mean: -53.710065\n",
      "ep 14: ep_len:500 episode reward: total was 17.220000. running mean: -53.000765\n",
      "ep 14: ep_len:500 episode reward: total was -11.230000. running mean: -52.583057\n",
      "ep 14: ep_len:590 episode reward: total was -25.130000. running mean: -52.308527\n",
      "ep 14: ep_len:905 episode reward: total was -29.220000. running mean: -52.077641\n",
      "ep 14: ep_len:500 episode reward: total was -7.450000. running mean: -51.631365\n",
      "ep 14: ep_len:820 episode reward: total was -22.650000. running mean: -51.341551\n",
      "ep 14: ep_len:500 episode reward: total was -6.840000. running mean: -50.896536\n",
      "ep 14: ep_len:740 episode reward: total was -21.800000. running mean: -50.605570\n",
      "ep 14: ep_len:825 episode reward: total was -18.670000. running mean: -50.286215\n",
      "ep 14: ep_len:615 episode reward: total was -14.790000. running mean: -49.931252\n",
      "ep 14: ep_len:500 episode reward: total was 4.940000. running mean: -49.382540\n",
      "ep 14: ep_len:685 episode reward: total was -24.920000. running mean: -49.137915\n",
      "ep 14: ep_len:500 episode reward: total was -1.980000. running mean: -48.666335\n",
      "ep 14: ep_len:505 episode reward: total was -3.100000. running mean: -48.210672\n",
      "ep 14: ep_len:1160 episode reward: total was -30.620000. running mean: -48.034765\n",
      "ep 14: ep_len:475 episode reward: total was -46.860000. running mean: -48.023018\n",
      "ep 14: ep_len:699 episode reward: total was -112.770000. running mean: -48.670487\n",
      "ep 14: ep_len:950 episode reward: total was -21.600000. running mean: -48.399783\n",
      "ep 14: ep_len:1310 episode reward: total was -168.120000. running mean: -49.596985\n",
      "ep 14: ep_len:247 episode reward: total was 16.000000. running mean: -48.941015\n",
      "ep 14: ep_len:555 episode reward: total was -54.460000. running mean: -48.996205\n",
      "ep 14: ep_len:500 episode reward: total was 0.210000. running mean: -48.504143\n",
      "ep 14: ep_len:920 episode reward: total was -25.380000. running mean: -48.272901\n",
      "ep 14: ep_len:625 episode reward: total was -6.850000. running mean: -47.858672\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 14: ep_len:500 episode reward: total was -9.320000. running mean: -47.473286\n",
      "ep 14: ep_len:735 episode reward: total was -21.810000. running mean: -47.216653\n",
      "ep 14: ep_len:500 episode reward: total was -6.360000. running mean: -46.808086\n",
      "ep 14: ep_len:500 episode reward: total was 2.000000. running mean: -46.320005\n",
      "ep 14: ep_len:750 episode reward: total was 10.130000. running mean: -45.755505\n",
      "ep 14: ep_len:820 episode reward: total was -23.660000. running mean: -45.534550\n",
      "ep 14: ep_len:1015 episode reward: total was -10.430000. running mean: -45.183505\n",
      "ep 14: ep_len:680 episode reward: total was -42.120000. running mean: -45.152870\n",
      "ep 14: ep_len:408 episode reward: total was -11.500000. running mean: -44.816341\n",
      "ep 14: ep_len:685 episode reward: total was -13.570000. running mean: -44.503878\n",
      "ep 14: ep_len:500 episode reward: total was -2.800000. running mean: -44.086839\n",
      "ep 14: ep_len:505 episode reward: total was -2.880000. running mean: -43.674770\n",
      "ep 14: ep_len:1370 episode reward: total was -230.150000. running mean: -45.539523\n",
      "ep 14: ep_len:920 episode reward: total was -37.600000. running mean: -45.460127\n",
      "ep 14: ep_len:960 episode reward: total was -89.030000. running mean: -45.895826\n",
      "ep 14: ep_len:515 episode reward: total was -17.810000. running mean: -45.614968\n",
      "ep 14: ep_len:505 episode reward: total was -32.370000. running mean: -45.482518\n",
      "ep 14: ep_len:650 episode reward: total was -13.950000. running mean: -45.167193\n",
      "ep 14: ep_len:500 episode reward: total was -25.360000. running mean: -44.969121\n",
      "ep 14: ep_len:505 episode reward: total was 6.560000. running mean: -44.453830\n",
      "ep 14: ep_len:500 episode reward: total was -9.400000. running mean: -44.103292\n",
      "ep 14: ep_len:500 episode reward: total was -45.290000. running mean: -44.115159\n",
      "ep 14: ep_len:730 episode reward: total was -14.680000. running mean: -43.820807\n",
      "ep 14: ep_len:1510 episode reward: total was -263.200000. running mean: -46.014599\n",
      "ep 14: ep_len:590 episode reward: total was -31.160000. running mean: -45.866053\n",
      "ep 14: ep_len:860 episode reward: total was -31.230000. running mean: -45.719693\n",
      "ep 14: ep_len:560 episode reward: total was -67.270000. running mean: -45.935196\n",
      "ep 14: ep_len:505 episode reward: total was -4.310000. running mean: -45.518944\n",
      "ep 14: ep_len:441 episode reward: total was 12.660000. running mean: -44.937154\n",
      "ep 14: ep_len:735 episode reward: total was -16.760000. running mean: -44.655383\n",
      "ep 14: ep_len:770 episode reward: total was -23.780000. running mean: -44.446629\n",
      "ep 14: ep_len:167 episode reward: total was 9.500000. running mean: -43.907163\n",
      "ep 14: ep_len:505 episode reward: total was 4.110000. running mean: -43.426991\n",
      "ep 14: ep_len:88 episode reward: total was 5.500000. running mean: -42.937721\n",
      "ep 14: ep_len:500 episode reward: total was -0.780000. running mean: -42.516144\n",
      "ep 14: ep_len:635 episode reward: total was -16.280000. running mean: -42.253782\n",
      "ep 14: ep_len:635 episode reward: total was -1.490000. running mean: -41.846145\n",
      "ep 14: ep_len:500 episode reward: total was -4.270000. running mean: -41.470383\n",
      "ep 14: ep_len:500 episode reward: total was 1.340000. running mean: -41.042279\n",
      "ep 14: ep_len:555 episode reward: total was -23.970000. running mean: -40.871556\n",
      "ep 14: ep_len:500 episode reward: total was -29.000000. running mean: -40.752841\n",
      "ep 14: ep_len:835 episode reward: total was -32.720000. running mean: -40.672513\n",
      "ep 14: ep_len:660 episode reward: total was -7.750000. running mean: -40.343287\n",
      "ep 14: ep_len:755 episode reward: total was -22.780000. running mean: -40.167655\n",
      "ep 14: ep_len:510 episode reward: total was -97.000000. running mean: -40.735978\n",
      "ep 14: ep_len:135 episode reward: total was 6.000000. running mean: -40.268618\n",
      "ep 14: ep_len:605 episode reward: total was -37.220000. running mean: -40.238132\n",
      "ep 14: ep_len:565 episode reward: total was -25.180000. running mean: -40.087551\n",
      "ep 14: ep_len:830 episode reward: total was -14.190000. running mean: -39.828575\n",
      "ep 14: ep_len:500 episode reward: total was -16.830000. running mean: -39.598589\n",
      "ep 14: ep_len:755 episode reward: total was -15.280000. running mean: -39.355404\n",
      "ep 14: ep_len:246 episode reward: total was 6.500000. running mean: -38.896850\n",
      "ep 14: ep_len:660 episode reward: total was -4.840000. running mean: -38.556281\n",
      "ep 14: ep_len:500 episode reward: total was -10.770000. running mean: -38.278418\n",
      "ep 14: ep_len:500 episode reward: total was -2.560000. running mean: -37.921234\n",
      "ep 14: ep_len:1130 episode reward: total was -121.010000. running mean: -38.752122\n",
      "ep 14: ep_len:500 episode reward: total was -2.040000. running mean: -38.385000\n",
      "ep 14: ep_len:505 episode reward: total was -30.380000. running mean: -38.304950\n",
      "ep 14: ep_len:700 episode reward: total was -36.020000. running mean: -38.282101\n",
      "ep 14: ep_len:149 episode reward: total was 5.500000. running mean: -37.844280\n",
      "ep 14: ep_len:505 episode reward: total was 1.680000. running mean: -37.449037\n",
      "ep 14: ep_len:610 episode reward: total was -82.500000. running mean: -37.899547\n",
      "ep 14: ep_len:500 episode reward: total was -16.770000. running mean: -37.688251\n",
      "ep 14: ep_len:150 episode reward: total was 2.000000. running mean: -37.291369\n",
      "ep 14: ep_len:605 episode reward: total was -90.800000. running mean: -37.826455\n",
      "ep 14: ep_len:650 episode reward: total was -17.940000. running mean: -37.627591\n",
      "ep 14: ep_len:338 episode reward: total was -24.000000. running mean: -37.491315\n",
      "ep 14: ep_len:540 episode reward: total was -23.690000. running mean: -37.353301\n",
      "ep 14: ep_len:600 episode reward: total was -60.460000. running mean: -37.584368\n",
      "ep 14: ep_len:184 episode reward: total was 5.000000. running mean: -37.158525\n",
      "ep 14: ep_len:755 episode reward: total was -26.820000. running mean: -37.055140\n",
      "ep 14: ep_len:515 episode reward: total was -5.250000. running mean: -36.737088\n",
      "ep 14: ep_len:254 episode reward: total was 10.500000. running mean: -36.264717\n",
      "ep 14: ep_len:595 episode reward: total was -43.300000. running mean: -36.335070\n",
      "ep 14: ep_len:500 episode reward: total was -0.750000. running mean: -35.979219\n",
      "ep 14: ep_len:505 episode reward: total was -6.870000. running mean: -35.688127\n",
      "ep 14: ep_len:505 episode reward: total was -2.160000. running mean: -35.352846\n",
      "ep 14: ep_len:505 episode reward: total was -7.790000. running mean: -35.077217\n",
      "ep 14: ep_len:500 episode reward: total was -19.460000. running mean: -34.921045\n",
      "ep 14: ep_len:500 episode reward: total was 3.750000. running mean: -34.534335\n",
      "ep 14: ep_len:825 episode reward: total was -60.010000. running mean: -34.789091\n",
      "ep 14: ep_len:500 episode reward: total was -8.740000. running mean: -34.528601\n",
      "ep 14: ep_len:715 episode reward: total was -29.930000. running mean: -34.482615\n",
      "ep 14: ep_len:480 episode reward: total was 9.190000. running mean: -34.045888\n",
      "ep 14: ep_len:1110 episode reward: total was -98.830000. running mean: -34.693730\n",
      "ep 14: ep_len:500 episode reward: total was 13.300000. running mean: -34.213792\n",
      "ep 14: ep_len:500 episode reward: total was -22.300000. running mean: -34.094654\n",
      "ep 14: ep_len:326 episode reward: total was 22.000000. running mean: -33.533708\n",
      "ep 14: ep_len:920 episode reward: total was -27.300000. running mean: -33.471371\n",
      "ep 14: ep_len:500 episode reward: total was -27.510000. running mean: -33.411757\n",
      "ep 14: ep_len:725 episode reward: total was -18.820000. running mean: -33.265839\n",
      "ep 14: ep_len:500 episode reward: total was -13.980000. running mean: -33.072981\n",
      "ep 14: ep_len:500 episode reward: total was -24.220000. running mean: -32.984451\n",
      "ep 14: ep_len:870 episode reward: total was -2.750000. running mean: -32.682107\n",
      "ep 14: ep_len:500 episode reward: total was -35.070000. running mean: -32.705986\n",
      "ep 14: ep_len:53 episode reward: total was 5.000000. running mean: -32.328926\n",
      "ep 14: ep_len:500 episode reward: total was -36.480000. running mean: -32.370437\n",
      "ep 14: ep_len:530 episode reward: total was -23.200000. running mean: -32.278732\n",
      "ep 14: ep_len:505 episode reward: total was -5.050000. running mean: -32.006445\n",
      "ep 14: ep_len:505 episode reward: total was -23.420000. running mean: -31.920580\n",
      "ep 14: ep_len:1190 episode reward: total was -110.790000. running mean: -32.709275\n",
      "ep 14: ep_len:505 episode reward: total was -27.320000. running mean: -32.655382\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 14: ep_len:900 episode reward: total was -38.790000. running mean: -32.716728\n",
      "ep 14: ep_len:760 episode reward: total was -26.810000. running mean: -32.657661\n",
      "ep 14: ep_len:545 episode reward: total was -27.260000. running mean: -32.603684\n",
      "ep 14: ep_len:505 episode reward: total was 7.740000. running mean: -32.200247\n",
      "ep 14: ep_len:500 episode reward: total was -66.990000. running mean: -32.548145\n",
      "ep 14: ep_len:2125 episode reward: total was -277.770000. running mean: -35.000363\n",
      "ep 14: ep_len:615 episode reward: total was -9.850000. running mean: -34.748860\n",
      "ep 14: ep_len:462 episode reward: total was 14.750000. running mean: -34.253871\n",
      "ep 14: ep_len:710 episode reward: total was -32.940000. running mean: -34.240732\n",
      "ep 14: ep_len:640 episode reward: total was -57.320000. running mean: -34.471525\n",
      "ep 14: ep_len:510 episode reward: total was -20.240000. running mean: -34.329210\n",
      "ep 14: ep_len:500 episode reward: total was -19.830000. running mean: -34.184218\n",
      "ep 14: ep_len:745 episode reward: total was -29.870000. running mean: -34.141076\n",
      "ep 14: ep_len:1085 episode reward: total was -91.000000. running mean: -34.709665\n",
      "ep 14: ep_len:620 episode reward: total was -25.070000. running mean: -34.613268\n",
      "ep 14: ep_len:550 episode reward: total was -25.140000. running mean: -34.518535\n",
      "ep 14: ep_len:505 episode reward: total was -2.550000. running mean: -34.198850\n",
      "ep 14: ep_len:750 episode reward: total was -34.910000. running mean: -34.205962\n",
      "ep 14: ep_len:500 episode reward: total was -6.700000. running mean: -33.930902\n",
      "ep 14: ep_len:785 episode reward: total was -36.340000. running mean: -33.954993\n",
      "ep 14: ep_len:500 episode reward: total was -9.330000. running mean: -33.708743\n",
      "ep 14: ep_len:256 episode reward: total was 10.500000. running mean: -33.266656\n",
      "ep 14: ep_len:715 episode reward: total was -21.820000. running mean: -33.152189\n",
      "ep 14: ep_len:715 episode reward: total was -47.100000. running mean: -33.291667\n",
      "ep 14: ep_len:500 episode reward: total was -48.780000. running mean: -33.446551\n",
      "ep 14: ep_len:243 episode reward: total was 9.000000. running mean: -33.022085\n",
      "ep 14: ep_len:500 episode reward: total was 4.210000. running mean: -32.649764\n",
      "ep 14: ep_len:500 episode reward: total was 13.240000. running mean: -32.190867\n",
      "ep 14: ep_len:500 episode reward: total was 9.300000. running mean: -31.775958\n",
      "ep 14: ep_len:500 episode reward: total was 24.720000. running mean: -31.210998\n",
      "ep 14: ep_len:500 episode reward: total was -7.810000. running mean: -30.976988\n",
      "ep 14: ep_len:500 episode reward: total was -56.280000. running mean: -31.230018\n",
      "ep 14: ep_len:530 episode reward: total was -43.430000. running mean: -31.352018\n",
      "ep 14: ep_len:550 episode reward: total was 1.260000. running mean: -31.025898\n",
      "ep 14: ep_len:835 episode reward: total was -4.700000. running mean: -30.762639\n",
      "ep 14: ep_len:780 episode reward: total was -51.990000. running mean: -30.974913\n",
      "ep 14: ep_len:2681 episode reward: total was -389.660000. running mean: -34.561764\n",
      "ep 14: ep_len:500 episode reward: total was -14.380000. running mean: -34.359946\n",
      "ep 14: ep_len:5290 episode reward: total was -897.040000. running mean: -42.986746\n",
      "ep 14: ep_len:897 episode reward: total was -89.140000. running mean: -43.448279\n",
      "ep 14: ep_len:500 episode reward: total was -15.940000. running mean: -43.173196\n",
      "ep 14: ep_len:1760 episode reward: total was -146.560000. running mean: -44.207064\n",
      "ep 14: ep_len:500 episode reward: total was -10.030000. running mean: -43.865294\n",
      "ep 14: ep_len:500 episode reward: total was 28.000000. running mean: -43.146641\n",
      "ep 14: ep_len:685 episode reward: total was -24.940000. running mean: -42.964574\n",
      "ep 14: ep_len:229 episode reward: total was 6.500000. running mean: -42.469929\n",
      "epsilon:0.169237 episode_count: 11834. steps_count: 8320117.000000\n",
      "ep 15: ep_len:500 episode reward: total was 6.230000. running mean: -41.982929\n",
      "ep 15: ep_len:810 episode reward: total was -45.900000. running mean: -42.022100\n",
      "ep 15: ep_len:500 episode reward: total was -16.610000. running mean: -41.767979\n",
      "ep 15: ep_len:1435 episode reward: total was -156.240000. running mean: -42.912699\n",
      "ep 15: ep_len:690 episode reward: total was -21.850000. running mean: -42.702072\n",
      "ep 15: ep_len:685 episode reward: total was -13.630000. running mean: -42.411351\n",
      "ep 15: ep_len:500 episode reward: total was -3.220000. running mean: -42.019438\n",
      "ep 15: ep_len:500 episode reward: total was 0.750000. running mean: -41.591744\n",
      "ep 15: ep_len:800 episode reward: total was -37.840000. running mean: -41.554226\n",
      "ep 15: ep_len:505 episode reward: total was -13.300000. running mean: -41.271684\n",
      "ep 15: ep_len:695 episode reward: total was 8.580000. running mean: -40.773167\n",
      "ep 15: ep_len:720 episode reward: total was -43.540000. running mean: -40.800835\n",
      "ep 15: ep_len:525 episode reward: total was -19.380000. running mean: -40.586627\n",
      "ep 15: ep_len:870 episode reward: total was -44.770000. running mean: -40.628461\n",
      "ep 15: ep_len:855 episode reward: total was -60.440000. running mean: -40.826576\n",
      "ep 15: ep_len:510 episode reward: total was 8.800000. running mean: -40.330310\n",
      "ep 15: ep_len:670 episode reward: total was -25.980000. running mean: -40.186807\n",
      "ep 15: ep_len:500 episode reward: total was -7.540000. running mean: -39.860339\n",
      "ep 15: ep_len:865 episode reward: total was -13.730000. running mean: -39.599036\n",
      "ep 15: ep_len:500 episode reward: total was -8.090000. running mean: -39.283945\n",
      "ep 15: ep_len:1590 episode reward: total was -73.590000. running mean: -39.627006\n",
      "ep 15: ep_len:1050 episode reward: total was -73.590000. running mean: -39.966636\n",
      "ep 15: ep_len:500 episode reward: total was -9.260000. running mean: -39.659570\n",
      "ep 15: ep_len:500 episode reward: total was -7.450000. running mean: -39.337474\n",
      "ep 15: ep_len:930 episode reward: total was -48.170000. running mean: -39.425799\n",
      "ep 15: ep_len:1025 episode reward: total was -28.050000. running mean: -39.312041\n",
      "ep 15: ep_len:910 episode reward: total was -57.800000. running mean: -39.496921\n",
      "ep 15: ep_len:655 episode reward: total was -27.510000. running mean: -39.377052\n",
      "ep 15: ep_len:505 episode reward: total was 10.280000. running mean: -38.880481\n",
      "ep 15: ep_len:500 episode reward: total was -9.280000. running mean: -38.584476\n",
      "ep 15: ep_len:209 episode reward: total was 14.500000. running mean: -38.053631\n",
      "ep 15: ep_len:610 episode reward: total was -9.170000. running mean: -37.764795\n",
      "ep 15: ep_len:505 episode reward: total was 12.700000. running mean: -37.260147\n",
      "ep 15: ep_len:505 episode reward: total was -0.360000. running mean: -36.891146\n",
      "ep 15: ep_len:540 episode reward: total was -26.240000. running mean: -36.784634\n",
      "ep 15: ep_len:645 episode reward: total was -27.040000. running mean: -36.687188\n",
      "ep 15: ep_len:630 episode reward: total was -31.260000. running mean: -36.632916\n",
      "ep 15: ep_len:500 episode reward: total was -7.830000. running mean: -36.344887\n",
      "ep 15: ep_len:500 episode reward: total was -9.050000. running mean: -36.071938\n",
      "ep 15: ep_len:895 episode reward: total was -31.840000. running mean: -36.029619\n",
      "ep 15: ep_len:500 episode reward: total was -12.250000. running mean: -35.791822\n",
      "ep 15: ep_len:500 episode reward: total was 8.740000. running mean: -35.346504\n",
      "ep 15: ep_len:1260 episode reward: total was -230.860000. running mean: -37.301639\n",
      "ep 15: ep_len:650 episode reward: total was -15.430000. running mean: -37.082923\n",
      "ep 15: ep_len:18955 episode reward: total was -3644.600000. running mean: -73.158094\n",
      "ep 15: ep_len:705 episode reward: total was -28.940000. running mean: -72.715913\n",
      "ep 15: ep_len:368 episode reward: total was 14.000000. running mean: -71.848753\n",
      "ep 15: ep_len:500 episode reward: total was -18.870000. running mean: -71.318966\n",
      "ep 15: ep_len:270 episode reward: total was 4.500000. running mean: -70.560776\n",
      "ep 15: ep_len:500 episode reward: total was -88.480000. running mean: -70.739969\n",
      "ep 15: ep_len:760 episode reward: total was -21.920000. running mean: -70.251769\n",
      "ep 15: ep_len:500 episode reward: total was -19.420000. running mean: -69.743451\n",
      "ep 15: ep_len:650 episode reward: total was -36.120000. running mean: -69.407217\n",
      "ep 15: ep_len:107 episode reward: total was 1.500000. running mean: -68.698144\n",
      "ep 15: ep_len:735 episode reward: total was -56.700000. running mean: -68.578163\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 15: ep_len:730 episode reward: total was -26.010000. running mean: -68.152481\n",
      "ep 15: ep_len:605 episode reward: total was -12.140000. running mean: -67.592357\n",
      "ep 15: ep_len:810 episode reward: total was -23.760000. running mean: -67.154033\n",
      "ep 15: ep_len:525 episode reward: total was 2.150000. running mean: -66.460993\n",
      "ep 15: ep_len:540 episode reward: total was -50.970000. running mean: -66.306083\n",
      "ep 15: ep_len:645 episode reward: total was -89.680000. running mean: -66.539822\n",
      "ep 15: ep_len:630 episode reward: total was -28.380000. running mean: -66.158224\n",
      "ep 15: ep_len:1150 episode reward: total was -115.920000. running mean: -66.655841\n",
      "ep 15: ep_len:535 episode reward: total was -51.500000. running mean: -66.504283\n",
      "ep 15: ep_len:500 episode reward: total was 0.230000. running mean: -65.836940\n",
      "ep 15: ep_len:595 episode reward: total was -45.810000. running mean: -65.636671\n",
      "ep 15: ep_len:760 episode reward: total was -37.920000. running mean: -65.359504\n",
      "ep 15: ep_len:157 episode reward: total was 9.500000. running mean: -64.610909\n",
      "ep 15: ep_len:505 episode reward: total was -69.740000. running mean: -64.662200\n",
      "ep 15: ep_len:920 episode reward: total was -32.740000. running mean: -64.342978\n",
      "ep 15: ep_len:1123 episode reward: total was -161.900000. running mean: -65.318548\n",
      "ep 15: ep_len:615 episode reward: total was -12.820000. running mean: -64.793563\n",
      "ep 15: ep_len:500 episode reward: total was -2.830000. running mean: -64.173927\n",
      "ep 15: ep_len:890 episode reward: total was -53.270000. running mean: -64.064888\n",
      "ep 15: ep_len:2175 episode reward: total was -235.060000. running mean: -65.774839\n",
      "ep 15: ep_len:675 episode reward: total was -30.990000. running mean: -65.426991\n",
      "ep 15: ep_len:875 episode reward: total was -136.150000. running mean: -66.134221\n",
      "ep 15: ep_len:472 episode reward: total was 24.500000. running mean: -65.227878\n",
      "ep 15: ep_len:630 episode reward: total was -24.040000. running mean: -64.816000\n",
      "ep 15: ep_len:640 episode reward: total was -27.840000. running mean: -64.446240\n",
      "ep 15: ep_len:500 episode reward: total was -4.270000. running mean: -63.844477\n",
      "ep 15: ep_len:570 episode reward: total was -44.850000. running mean: -63.654532\n",
      "ep 15: ep_len:500 episode reward: total was -21.080000. running mean: -63.228787\n",
      "ep 15: ep_len:650 episode reward: total was -54.300000. running mean: -63.139499\n",
      "ep 15: ep_len:850 episode reward: total was -14.670000. running mean: -62.654804\n",
      "ep 15: ep_len:500 episode reward: total was -25.000000. running mean: -62.278256\n",
      "ep 15: ep_len:500 episode reward: total was -6.800000. running mean: -61.723474\n",
      "ep 15: ep_len:770 episode reward: total was -41.940000. running mean: -61.525639\n",
      "ep 15: ep_len:510 episode reward: total was -23.290000. running mean: -61.143283\n",
      "ep 15: ep_len:19325 episode reward: total was -575.450000. running mean: -66.286350\n",
      "ep 15: ep_len:505 episode reward: total was -23.840000. running mean: -65.861886\n",
      "ep 15: ep_len:500 episode reward: total was -15.390000. running mean: -65.357167\n",
      "ep 15: ep_len:590 episode reward: total was -10.280000. running mean: -64.806396\n",
      "ep 15: ep_len:510 episode reward: total was -9.780000. running mean: -64.256132\n",
      "ep 15: ep_len:885 episode reward: total was -31.140000. running mean: -63.924970\n",
      "ep 15: ep_len:500 episode reward: total was 7.100000. running mean: -63.214721\n",
      "ep 15: ep_len:189 episode reward: total was 11.500000. running mean: -62.467574\n",
      "ep 15: ep_len:960 episode reward: total was -105.430000. running mean: -62.897198\n",
      "ep 15: ep_len:620 episode reward: total was -112.420000. running mean: -63.392426\n",
      "ep 15: ep_len:620 episode reward: total was -40.520000. running mean: -63.163702\n",
      "ep 15: ep_len:530 episode reward: total was -28.280000. running mean: -62.814865\n",
      "ep 15: ep_len:640 episode reward: total was -56.890000. running mean: -62.755616\n",
      "ep 15: ep_len:500 episode reward: total was -5.270000. running mean: -62.180760\n",
      "ep 15: ep_len:216 episode reward: total was 11.500000. running mean: -61.443952\n",
      "ep 15: ep_len:211 episode reward: total was 11.000000. running mean: -60.719513\n",
      "ep 15: ep_len:500 episode reward: total was -9.200000. running mean: -60.204317\n",
      "ep 15: ep_len:505 episode reward: total was -28.940000. running mean: -59.891674\n",
      "ep 15: ep_len:740 episode reward: total was -45.030000. running mean: -59.743058\n",
      "ep 15: ep_len:500 episode reward: total was -20.350000. running mean: -59.349127\n",
      "ep 15: ep_len:700 episode reward: total was -81.960000. running mean: -59.575236\n",
      "ep 15: ep_len:890 episode reward: total was -68.970000. running mean: -59.669183\n",
      "ep 15: ep_len:1020 episode reward: total was -14.400000. running mean: -59.216492\n",
      "ep 15: ep_len:510 episode reward: total was -26.360000. running mean: -58.887927\n",
      "ep 15: ep_len:865 episode reward: total was -145.780000. running mean: -59.756847\n",
      "ep 15: ep_len:905 episode reward: total was -48.260000. running mean: -59.641879\n",
      "ep 15: ep_len:670 episode reward: total was 4.730000. running mean: -58.998160\n",
      "ep 15: ep_len:550 episode reward: total was -27.230000. running mean: -58.680478\n",
      "ep 15: ep_len:500 episode reward: total was -23.990000. running mean: -58.333574\n",
      "ep 15: ep_len:840 episode reward: total was -77.270000. running mean: -58.522938\n",
      "ep 15: ep_len:1545 episode reward: total was -287.810000. running mean: -60.815809\n",
      "ep 15: ep_len:855 episode reward: total was -19.360000. running mean: -60.401250\n",
      "ep 15: ep_len:745 episode reward: total was -38.440000. running mean: -60.181638\n",
      "ep 15: ep_len:138 episode reward: total was 10.500000. running mean: -59.474822\n",
      "ep 15: ep_len:655 episode reward: total was -32.800000. running mean: -59.208073\n",
      "ep 15: ep_len:895 episode reward: total was -62.900000. running mean: -59.244993\n",
      "ep 15: ep_len:795 episode reward: total was -39.870000. running mean: -59.051243\n",
      "ep 15: ep_len:157 episode reward: total was 11.000000. running mean: -58.350730\n",
      "ep 15: ep_len:500 episode reward: total was -6.290000. running mean: -57.830123\n",
      "ep 15: ep_len:505 episode reward: total was -32.370000. running mean: -57.575522\n",
      "ep 15: ep_len:500 episode reward: total was -1.330000. running mean: -57.013067\n",
      "ep 15: ep_len:500 episode reward: total was -26.650000. running mean: -56.709436\n",
      "ep 15: ep_len:500 episode reward: total was -53.000000. running mean: -56.672342\n",
      "ep 15: ep_len:500 episode reward: total was -22.000000. running mean: -56.325618\n",
      "ep 15: ep_len:500 episode reward: total was -28.340000. running mean: -56.045762\n",
      "ep 15: ep_len:500 episode reward: total was 26.500000. running mean: -55.220304\n",
      "ep 15: ep_len:500 episode reward: total was 2.220000. running mean: -54.645901\n",
      "ep 15: ep_len:500 episode reward: total was 1.270000. running mean: -54.086742\n",
      "ep 15: ep_len:1800 episode reward: total was -153.900000. running mean: -55.084875\n",
      "ep 15: ep_len:500 episode reward: total was 10.250000. running mean: -54.431526\n",
      "ep 15: ep_len:500 episode reward: total was 9.180000. running mean: -53.795411\n",
      "ep 15: ep_len:95 episode reward: total was 3.500000. running mean: -53.222457\n",
      "ep 15: ep_len:196 episode reward: total was 9.000000. running mean: -52.600232\n",
      "ep 15: ep_len:500 episode reward: total was 33.500000. running mean: -51.739230\n",
      "ep 15: ep_len:137 episode reward: total was -16.500000. running mean: -51.386838\n",
      "ep 15: ep_len:500 episode reward: total was -3.100000. running mean: -50.903969\n",
      "ep 15: ep_len:710 episode reward: total was -24.890000. running mean: -50.643829\n",
      "ep 15: ep_len:500 episode reward: total was 5.230000. running mean: -50.085091\n",
      "ep 15: ep_len:500 episode reward: total was -25.310000. running mean: -49.837340\n",
      "ep 15: ep_len:795 episode reward: total was -32.760000. running mean: -49.666567\n",
      "ep 15: ep_len:500 episode reward: total was -37.400000. running mean: -49.543901\n",
      "ep 15: ep_len:590 episode reward: total was -67.550000. running mean: -49.723962\n",
      "ep 15: ep_len:560 episode reward: total was -49.430000. running mean: -49.721023\n",
      "ep 15: ep_len:875 episode reward: total was -32.150000. running mean: -49.545312\n",
      "ep 15: ep_len:500 episode reward: total was -3.630000. running mean: -49.086159\n",
      "ep 15: ep_len:500 episode reward: total was -34.430000. running mean: -48.939598\n",
      "ep 15: ep_len:500 episode reward: total was -21.300000. running mean: -48.663202\n",
      "ep 15: ep_len:640 episode reward: total was -23.500000. running mean: -48.411570\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 15: ep_len:500 episode reward: total was 0.260000. running mean: -47.924854\n",
      "ep 15: ep_len:500 episode reward: total was -20.840000. running mean: -47.654005\n",
      "ep 15: ep_len:695 episode reward: total was -45.120000. running mean: -47.628665\n",
      "ep 15: ep_len:1215 episode reward: total was -42.960000. running mean: -47.581979\n",
      "ep 15: ep_len:177 episode reward: total was 8.500000. running mean: -47.021159\n",
      "ep 15: ep_len:700 episode reward: total was -34.000000. running mean: -46.890947\n",
      "ep 15: ep_len:500 episode reward: total was -8.800000. running mean: -46.510038\n",
      "ep 15: ep_len:500 episode reward: total was -2.410000. running mean: -46.069037\n",
      "ep 15: ep_len:945 episode reward: total was -31.410000. running mean: -45.922447\n",
      "ep 15: ep_len:905 episode reward: total was -2.440000. running mean: -45.487623\n",
      "ep 15: ep_len:945 episode reward: total was -6.480000. running mean: -45.097546\n",
      "ep 15: ep_len:1055 episode reward: total was -32.470000. running mean: -44.971271\n",
      "ep 15: ep_len:500 episode reward: total was 0.070000. running mean: -44.520858\n",
      "ep 15: ep_len:500 episode reward: total was -12.290000. running mean: -44.198550\n",
      "ep 15: ep_len:695 episode reward: total was -24.920000. running mean: -44.005764\n",
      "ep 15: ep_len:500 episode reward: total was -26.900000. running mean: -43.834706\n",
      "ep 15: ep_len:850 episode reward: total was -25.460000. running mean: -43.650959\n",
      "ep 15: ep_len:935 episode reward: total was -23.150000. running mean: -43.445950\n",
      "ep 15: ep_len:855 episode reward: total was -17.170000. running mean: -43.183190\n",
      "ep 15: ep_len:500 episode reward: total was -27.820000. running mean: -43.029558\n",
      "ep 15: ep_len:500 episode reward: total was -14.340000. running mean: -42.742663\n",
      "ep 15: ep_len:605 episode reward: total was -42.270000. running mean: -42.737936\n",
      "ep 15: ep_len:500 episode reward: total was 36.500000. running mean: -41.945557\n",
      "ep 15: ep_len:950 episode reward: total was -73.320000. running mean: -42.259301\n",
      "ep 15: ep_len:500 episode reward: total was -5.960000. running mean: -41.896308\n",
      "ep 15: ep_len:51 episode reward: total was 2.000000. running mean: -41.457345\n",
      "ep 15: ep_len:505 episode reward: total was 32.500000. running mean: -40.717772\n",
      "ep 15: ep_len:505 episode reward: total was -42.010000. running mean: -40.730694\n",
      "ep 15: ep_len:545 episode reward: total was -23.250000. running mean: -40.555887\n",
      "ep 15: ep_len:600 episode reward: total was -12.830000. running mean: -40.278628\n",
      "ep 15: ep_len:565 episode reward: total was -77.700000. running mean: -40.652842\n",
      "ep 15: ep_len:755 episode reward: total was -29.020000. running mean: -40.536514\n",
      "ep 15: ep_len:169 episode reward: total was 3.000000. running mean: -40.101148\n",
      "ep 15: ep_len:1055 episode reward: total was -19.780000. running mean: -39.897937\n",
      "ep 15: ep_len:500 episode reward: total was 2.250000. running mean: -39.476458\n",
      "ep 15: ep_len:500 episode reward: total was -2.190000. running mean: -39.103593\n",
      "ep 15: ep_len:1705 episode reward: total was -240.530000. running mean: -41.117857\n",
      "ep 15: ep_len:500 episode reward: total was 11.740000. running mean: -40.589278\n",
      "ep 15: ep_len:825 episode reward: total was -38.390000. running mean: -40.567286\n",
      "ep 15: ep_len:750 episode reward: total was -29.340000. running mean: -40.455013\n",
      "ep 15: ep_len:755 episode reward: total was -32.880000. running mean: -40.379263\n",
      "ep 15: ep_len:705 episode reward: total was -21.870000. running mean: -40.194170\n",
      "ep 15: ep_len:730 episode reward: total was -42.200000. running mean: -40.214228\n",
      "ep 15: ep_len:590 episode reward: total was -26.140000. running mean: -40.073486\n",
      "ep 15: ep_len:500 episode reward: total was -9.790000. running mean: -39.770651\n",
      "ep 15: ep_len:585 episode reward: total was -20.060000. running mean: -39.573545\n",
      "ep 15: ep_len:500 episode reward: total was -5.150000. running mean: -39.229309\n",
      "ep 15: ep_len:500 episode reward: total was 2.280000. running mean: -38.814216\n",
      "ep 15: ep_len:500 episode reward: total was 6.720000. running mean: -38.358874\n",
      "ep 15: ep_len:500 episode reward: total was -2.650000. running mean: -38.001785\n",
      "ep 15: ep_len:500 episode reward: total was 12.870000. running mean: -37.493067\n",
      "ep 15: ep_len:850 episode reward: total was -48.210000. running mean: -37.600237\n",
      "ep 15: ep_len:530 episode reward: total was -44.430000. running mean: -37.668534\n",
      "ep 15: ep_len:500 episode reward: total was 9.720000. running mean: -37.194649\n",
      "ep 15: ep_len:785 episode reward: total was -21.710000. running mean: -37.039803\n",
      "ep 15: ep_len:500 episode reward: total was 1.420000. running mean: -36.655204\n",
      "ep 15: ep_len:725 episode reward: total was -59.220000. running mean: -36.880852\n",
      "ep 15: ep_len:550 episode reward: total was -61.570000. running mean: -37.127744\n",
      "ep 15: ep_len:670 episode reward: total was -23.740000. running mean: -36.993866\n",
      "ep 15: ep_len:655 episode reward: total was -13.660000. running mean: -36.760528\n",
      "ep 15: ep_len:715 episode reward: total was -32.930000. running mean: -36.722223\n",
      "ep 15: ep_len:925 episode reward: total was -18.820000. running mean: -36.543200\n",
      "ep 15: ep_len:575 episode reward: total was -7.990000. running mean: -36.257668\n",
      "ep 15: ep_len:650 episode reward: total was -31.060000. running mean: -36.205692\n",
      "ep 15: ep_len:426 episode reward: total was -4.270000. running mean: -35.886335\n",
      "ep 15: ep_len:500 episode reward: total was -27.420000. running mean: -35.801671\n",
      "ep 15: ep_len:500 episode reward: total was -20.410000. running mean: -35.647755\n",
      "ep 15: ep_len:500 episode reward: total was -14.300000. running mean: -35.434277\n",
      "ep 15: ep_len:500 episode reward: total was -19.860000. running mean: -35.278534\n",
      "ep 15: ep_len:945 episode reward: total was -21.670000. running mean: -35.142449\n",
      "ep 15: ep_len:1400 episode reward: total was -149.810000. running mean: -36.289125\n",
      "ep 15: ep_len:1085 episode reward: total was -40.410000. running mean: -36.330333\n",
      "ep 15: ep_len:500 episode reward: total was 6.730000. running mean: -35.899730\n",
      "ep 15: ep_len:505 episode reward: total was 2.660000. running mean: -35.514133\n",
      "ep 15: ep_len:500 episode reward: total was -7.920000. running mean: -35.238191\n",
      "ep 15: ep_len:995 episode reward: total was -16.550000. running mean: -35.051309\n",
      "ep 15: ep_len:1355 episode reward: total was -95.310000. running mean: -35.653896\n",
      "ep 15: ep_len:530 episode reward: total was -23.230000. running mean: -35.529657\n",
      "ep 15: ep_len:725 episode reward: total was -25.870000. running mean: -35.433061\n",
      "ep 15: ep_len:765 episode reward: total was -33.350000. running mean: -35.412230\n",
      "ep 15: ep_len:500 episode reward: total was -11.520000. running mean: -35.173308\n",
      "ep 15: ep_len:605 episode reward: total was -16.220000. running mean: -34.983775\n",
      "ep 15: ep_len:710 episode reward: total was -33.980000. running mean: -34.973737\n",
      "ep 15: ep_len:500 episode reward: total was -21.270000. running mean: -34.836700\n",
      "ep 15: ep_len:199 episode reward: total was 12.000000. running mean: -34.368333\n",
      "ep 15: ep_len:1000 episode reward: total was -18.500000. running mean: -34.209649\n",
      "ep 15: ep_len:605 episode reward: total was 10.610000. running mean: -33.761453\n",
      "ep 15: ep_len:745 episode reward: total was -25.310000. running mean: -33.676938\n",
      "ep 15: ep_len:500 episode reward: total was -28.210000. running mean: -33.622269\n",
      "ep 15: ep_len:560 episode reward: total was -22.340000. running mean: -33.509446\n",
      "ep 15: ep_len:560 episode reward: total was -38.810000. running mean: -33.562452\n",
      "ep 15: ep_len:835 episode reward: total was -30.560000. running mean: -33.532427\n",
      "ep 15: ep_len:500 episode reward: total was -15.210000. running mean: -33.349203\n",
      "ep 15: ep_len:1415 episode reward: total was -62.740000. running mean: -33.643111\n",
      "ep 15: ep_len:500 episode reward: total was -13.890000. running mean: -33.445580\n",
      "ep 15: ep_len:595 episode reward: total was -24.910000. running mean: -33.360224\n",
      "ep 15: ep_len:710 episode reward: total was -49.130000. running mean: -33.517922\n",
      "ep 15: ep_len:262 episode reward: total was 14.000000. running mean: -33.042743\n",
      "ep 15: ep_len:510 episode reward: total was -12.160000. running mean: -32.833915\n",
      "ep 15: ep_len:950 episode reward: total was -27.740000. running mean: -32.782976\n",
      "ep 15: ep_len:535 episode reward: total was -18.660000. running mean: -32.641746\n",
      "ep 15: ep_len:1035 episode reward: total was -26.830000. running mean: -32.583629\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 15: ep_len:500 episode reward: total was -21.820000. running mean: -32.475993\n",
      "ep 15: ep_len:209 episode reward: total was 13.000000. running mean: -32.021233\n",
      "ep 15: ep_len:121 episode reward: total was 7.500000. running mean: -31.626020\n",
      "ep 15: ep_len:500 episode reward: total was 6.900000. running mean: -31.240760\n",
      "ep 15: ep_len:765 episode reward: total was -29.500000. running mean: -31.223352\n",
      "ep 15: ep_len:645 episode reward: total was -7.350000. running mean: -30.984619\n",
      "ep 15: ep_len:530 episode reward: total was -13.130000. running mean: -30.806073\n",
      "ep 15: ep_len:910 episode reward: total was -5.990000. running mean: -30.557912\n",
      "ep 15: ep_len:500 episode reward: total was 28.500000. running mean: -29.967333\n",
      "ep 15: ep_len:630 episode reward: total was -42.710000. running mean: -30.094760\n",
      "ep 15: ep_len:500 episode reward: total was 5.190000. running mean: -29.741912\n",
      "ep 15: ep_len:620 episode reward: total was -12.950000. running mean: -29.573993\n",
      "ep 15: ep_len:555 episode reward: total was -81.780000. running mean: -30.096053\n",
      "ep 15: ep_len:950 episode reward: total was -23.530000. running mean: -30.030392\n",
      "ep 15: ep_len:500 episode reward: total was -16.740000. running mean: -29.897488\n",
      "ep 15: ep_len:1255 episode reward: total was -176.800000. running mean: -31.366514\n",
      "ep 15: ep_len:500 episode reward: total was -12.380000. running mean: -31.176648\n",
      "ep 15: ep_len:510 episode reward: total was -26.300000. running mean: -31.127882\n",
      "ep 15: ep_len:500 episode reward: total was -18.340000. running mean: -31.000003\n",
      "ep 15: ep_len:247 episode reward: total was -3.500000. running mean: -30.725003\n",
      "ep 15: ep_len:655 episode reward: total was -32.560000. running mean: -30.743353\n",
      "ep 15: ep_len:1060 episode reward: total was -74.690000. running mean: -31.182820\n",
      "ep 15: ep_len:505 episode reward: total was -23.800000. running mean: -31.108991\n",
      "ep 15: ep_len:500 episode reward: total was -7.050000. running mean: -30.868401\n",
      "ep 15: ep_len:940 episode reward: total was -34.490000. running mean: -30.904617\n",
      "ep 15: ep_len:815 episode reward: total was -39.800000. running mean: -30.993571\n",
      "ep 15: ep_len:1515 episode reward: total was -98.020000. running mean: -31.663836\n",
      "ep 15: ep_len:735 episode reward: total was -30.870000. running mean: -31.655897\n",
      "ep 15: ep_len:500 episode reward: total was 24.500000. running mean: -31.094338\n",
      "ep 15: ep_len:500 episode reward: total was -5.120000. running mean: -30.834595\n",
      "ep 15: ep_len:625 episode reward: total was -28.910000. running mean: -30.815349\n",
      "ep 15: ep_len:605 episode reward: total was -19.040000. running mean: -30.697595\n",
      "ep 15: ep_len:715 episode reward: total was -25.890000. running mean: -30.649519\n",
      "ep 15: ep_len:218 episode reward: total was 17.000000. running mean: -30.173024\n",
      "ep 15: ep_len:1425 episode reward: total was -82.240000. running mean: -30.693694\n",
      "ep 15: ep_len:500 episode reward: total was -5.280000. running mean: -30.439557\n",
      "ep 15: ep_len:500 episode reward: total was -29.900000. running mean: -30.434161\n",
      "ep 15: ep_len:500 episode reward: total was -2.770000. running mean: -30.157520\n",
      "ep 15: ep_len:121 episode reward: total was 10.500000. running mean: -29.750945\n",
      "ep 15: ep_len:570 episode reward: total was -24.160000. running mean: -29.695035\n",
      "ep 15: ep_len:1110 episode reward: total was -34.620000. running mean: -29.744285\n",
      "ep 15: ep_len:500 episode reward: total was 12.750000. running mean: -29.319342\n",
      "ep 15: ep_len:750 episode reward: total was -34.490000. running mean: -29.371049\n",
      "ep 15: ep_len:820 episode reward: total was -43.700000. running mean: -29.514338\n",
      "ep 15: ep_len:232 episode reward: total was 17.000000. running mean: -29.049195\n",
      "ep 15: ep_len:342 episode reward: total was 10.000000. running mean: -28.658703\n",
      "ep 15: ep_len:396 episode reward: total was 13.000000. running mean: -28.242116\n",
      "ep 15: ep_len:920 episode reward: total was -96.180000. running mean: -28.921495\n",
      "ep 15: ep_len:500 episode reward: total was -8.960000. running mean: -28.721880\n",
      "ep 15: ep_len:1045 episode reward: total was -11.860000. running mean: -28.553261\n",
      "ep 15: ep_len:900 episode reward: total was -67.940000. running mean: -28.947128\n",
      "ep 15: ep_len:680 episode reward: total was -25.960000. running mean: -28.917257\n",
      "ep 15: ep_len:235 episode reward: total was 11.500000. running mean: -28.513084\n",
      "ep 15: ep_len:505 episode reward: total was -21.260000. running mean: -28.440554\n",
      "ep 15: ep_len:500 episode reward: total was -0.720000. running mean: -28.163348\n",
      "ep 15: ep_len:810 episode reward: total was -42.380000. running mean: -28.305515\n",
      "ep 15: ep_len:800 episode reward: total was -55.990000. running mean: -28.582359\n",
      "ep 15: ep_len:740 episode reward: total was -49.070000. running mean: -28.787236\n",
      "ep 15: ep_len:600 episode reward: total was 3.260000. running mean: -28.466763\n",
      "ep 15: ep_len:505 episode reward: total was -32.370000. running mean: -28.505796\n",
      "ep 15: ep_len:975 episode reward: total was -26.830000. running mean: -28.489038\n",
      "ep 15: ep_len:500 episode reward: total was -0.690000. running mean: -28.211047\n",
      "ep 15: ep_len:715 episode reward: total was -26.340000. running mean: -28.192337\n",
      "ep 15: ep_len:585 episode reward: total was -57.460000. running mean: -28.485014\n",
      "ep 15: ep_len:505 episode reward: total was -17.450000. running mean: -28.374663\n",
      "ep 15: ep_len:1630 episode reward: total was -205.610000. running mean: -30.147017\n",
      "ep 15: ep_len:1255 episode reward: total was -56.780000. running mean: -30.413347\n",
      "ep 15: ep_len:500 episode reward: total was -19.310000. running mean: -30.302313\n",
      "ep 15: ep_len:640 episode reward: total was -39.170000. running mean: -30.390990\n",
      "ep 15: ep_len:520 episode reward: total was -33.060000. running mean: -30.417680\n",
      "ep 15: ep_len:800 episode reward: total was -38.600000. running mean: -30.499503\n",
      "ep 15: ep_len:730 episode reward: total was -20.810000. running mean: -30.402608\n",
      "ep 15: ep_len:500 episode reward: total was 5.160000. running mean: -30.046982\n",
      "ep 15: ep_len:505 episode reward: total was 2.240000. running mean: -29.724112\n",
      "ep 15: ep_len:502 episode reward: total was 13.730000. running mean: -29.289571\n",
      "ep 15: ep_len:320 episode reward: total was 16.510000. running mean: -28.831576\n",
      "ep 15: ep_len:1665 episode reward: total was -205.790000. running mean: -30.601160\n",
      "ep 15: ep_len:243 episode reward: total was 18.000000. running mean: -30.115148\n",
      "ep 15: ep_len:500 episode reward: total was 39.500000. running mean: -29.418997\n",
      "ep 15: ep_len:655 episode reward: total was -23.760000. running mean: -29.362407\n",
      "ep 15: ep_len:500 episode reward: total was 33.500000. running mean: -28.733783\n",
      "ep 15: ep_len:505 episode reward: total was -6.220000. running mean: -28.508645\n",
      "ep 15: ep_len:500 episode reward: total was 6.720000. running mean: -28.156358\n",
      "ep 15: ep_len:735 episode reward: total was -79.380000. running mean: -28.668595\n",
      "ep 15: ep_len:1010 episode reward: total was -4.360000. running mean: -28.425509\n",
      "ep 15: ep_len:697 episode reward: total was -35.980000. running mean: -28.501054\n",
      "ep 15: ep_len:205 episode reward: total was 16.000000. running mean: -28.056043\n",
      "ep 15: ep_len:520 episode reward: total was -10.300000. running mean: -27.878483\n",
      "ep 15: ep_len:540 episode reward: total was -48.230000. running mean: -28.081998\n",
      "ep 15: ep_len:630 episode reward: total was -70.500000. running mean: -28.506178\n",
      "ep 15: ep_len:915 episode reward: total was -65.370000. running mean: -28.874816\n",
      "ep 15: ep_len:650 episode reward: total was -26.510000. running mean: -28.851168\n",
      "ep 15: ep_len:875 episode reward: total was -0.370000. running mean: -28.566356\n",
      "ep 15: ep_len:690 episode reward: total was -13.110000. running mean: -28.411793\n",
      "ep 15: ep_len:500 episode reward: total was -30.880000. running mean: -28.436475\n",
      "ep 15: ep_len:540 episode reward: total was -31.310000. running mean: -28.465210\n",
      "ep 15: ep_len:156 episode reward: total was 12.500000. running mean: -28.055558\n",
      "ep 15: ep_len:500 episode reward: total was -36.050000. running mean: -28.135503\n",
      "ep 15: ep_len:500 episode reward: total was -8.350000. running mean: -27.937647\n",
      "ep 15: ep_len:525 episode reward: total was 3.130000. running mean: -27.626971\n",
      "ep 15: ep_len:500 episode reward: total was -8.380000. running mean: -27.434501\n",
      "ep 15: ep_len:865 episode reward: total was -18.720000. running mean: -27.347356\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 15: ep_len:505 episode reward: total was -23.110000. running mean: -27.304983\n",
      "ep 15: ep_len:500 episode reward: total was -10.850000. running mean: -27.140433\n",
      "ep 15: ep_len:127 episode reward: total was 6.500000. running mean: -26.804029\n",
      "ep 15: ep_len:760 episode reward: total was -84.350000. running mean: -27.379488\n",
      "ep 15: ep_len:500 episode reward: total was -27.720000. running mean: -27.382893\n",
      "ep 15: ep_len:500 episode reward: total was -18.300000. running mean: -27.292064\n",
      "ep 15: ep_len:1020 episode reward: total was -26.520000. running mean: -27.284344\n",
      "ep 15: ep_len:730 episode reward: total was -19.800000. running mean: -27.209500\n",
      "ep 15: ep_len:720 episode reward: total was -22.110000. running mean: -27.158505\n",
      "ep 15: ep_len:590 episode reward: total was -60.480000. running mean: -27.491720\n",
      "ep 15: ep_len:301 episode reward: total was 6.500000. running mean: -27.151803\n",
      "ep 15: ep_len:252 episode reward: total was 7.000000. running mean: -26.810285\n",
      "ep 15: ep_len:640 episode reward: total was -9.290000. running mean: -26.635082\n",
      "ep 15: ep_len:500 episode reward: total was -13.860000. running mean: -26.507331\n",
      "ep 15: ep_len:625 episode reward: total was -39.170000. running mean: -26.633958\n",
      "ep 15: ep_len:755 episode reward: total was -36.920000. running mean: -26.736819\n",
      "ep 15: ep_len:815 episode reward: total was -45.290000. running mean: -26.922350\n",
      "ep 15: ep_len:500 episode reward: total was -21.570000. running mean: -26.868827\n",
      "ep 15: ep_len:2075 episode reward: total was -264.560000. running mean: -29.245739\n",
      "ep 15: ep_len:500 episode reward: total was 9.260000. running mean: -28.860681\n",
      "ep 15: ep_len:950 episode reward: total was -153.800000. running mean: -30.110074\n",
      "ep 15: ep_len:1520 episode reward: total was -126.290000. running mean: -31.071874\n",
      "ep 15: ep_len:510 episode reward: total was -20.240000. running mean: -30.963555\n",
      "ep 15: ep_len:650 episode reward: total was -34.100000. running mean: -30.994919\n",
      "ep 15: ep_len:710 episode reward: total was -35.050000. running mean: -31.035470\n",
      "ep 15: ep_len:1070 episode reward: total was -90.800000. running mean: -31.633115\n",
      "ep 15: ep_len:540 episode reward: total was -23.700000. running mean: -31.553784\n",
      "ep 15: ep_len:1450 episode reward: total was -111.820000. running mean: -32.356446\n",
      "ep 15: ep_len:925 episode reward: total was -23.110000. running mean: -32.263982\n",
      "ep 15: ep_len:500 episode reward: total was -10.850000. running mean: -32.049842\n",
      "ep 15: ep_len:1045 episode reward: total was -28.980000. running mean: -32.019144\n",
      "ep 15: ep_len:575 episode reward: total was -79.180000. running mean: -32.490752\n",
      "ep 15: ep_len:500 episode reward: total was -6.810000. running mean: -32.233945\n",
      "ep 15: ep_len:186 episode reward: total was -7.000000. running mean: -31.981605\n",
      "ep 15: ep_len:160 episode reward: total was 5.500000. running mean: -31.606789\n",
      "ep 15: ep_len:745 episode reward: total was -35.900000. running mean: -31.649721\n",
      "ep 15: ep_len:203 episode reward: total was -2.000000. running mean: -31.353224\n",
      "ep 15: ep_len:500 episode reward: total was -15.380000. running mean: -31.193492\n",
      "ep 15: ep_len:910 episode reward: total was -22.400000. running mean: -31.105557\n",
      "ep 15: ep_len:510 episode reward: total was -29.990000. running mean: -31.094401\n",
      "ep 15: ep_len:500 episode reward: total was -0.340000. running mean: -30.786857\n",
      "ep 15: ep_len:900 episode reward: total was -46.730000. running mean: -30.946289\n",
      "ep 15: ep_len:500 episode reward: total was 10.250000. running mean: -30.534326\n",
      "ep 15: ep_len:254 episode reward: total was 14.500000. running mean: -30.083983\n",
      "ep 15: ep_len:1005 episode reward: total was -50.560000. running mean: -30.288743\n",
      "ep 15: ep_len:1005 episode reward: total was -25.780000. running mean: -30.243655\n",
      "ep 15: ep_len:188 episode reward: total was 14.500000. running mean: -29.796219\n",
      "ep 15: ep_len:155 episode reward: total was 5.000000. running mean: -29.448257\n",
      "ep 15: ep_len:780 episode reward: total was -30.810000. running mean: -29.461874\n",
      "ep 15: ep_len:500 episode reward: total was -8.900000. running mean: -29.256255\n",
      "ep 15: ep_len:1065 episode reward: total was -41.310000. running mean: -29.376793\n",
      "ep 15: ep_len:150 episode reward: total was 8.000000. running mean: -29.003025\n",
      "ep 15: ep_len:200 episode reward: total was 14.500000. running mean: -28.567995\n",
      "ep 15: ep_len:540 episode reward: total was -31.290000. running mean: -28.595215\n",
      "ep 15: ep_len:390 episode reward: total was -20.770000. running mean: -28.516963\n",
      "ep 15: ep_len:500 episode reward: total was -10.310000. running mean: -28.334893\n",
      "ep 15: ep_len:500 episode reward: total was 30.500000. running mean: -27.746544\n",
      "ep 15: ep_len:1735 episode reward: total was -152.840000. running mean: -28.997479\n",
      "ep 15: ep_len:371 episode reward: total was 17.500000. running mean: -28.532504\n",
      "ep 15: ep_len:385 episode reward: total was -49.240000. running mean: -28.739579\n",
      "ep 15: ep_len:1020 episode reward: total was -48.750000. running mean: -28.939683\n",
      "ep 15: ep_len:500 episode reward: total was 4.270000. running mean: -28.607586\n",
      "ep 15: ep_len:955 episode reward: total was -42.580000. running mean: -28.747310\n",
      "ep 15: ep_len:845 episode reward: total was -33.710000. running mean: -28.796937\n",
      "ep 15: ep_len:715 episode reward: total was -32.820000. running mean: -28.837168\n",
      "ep 15: ep_len:690 episode reward: total was -20.370000. running mean: -28.752496\n",
      "ep 15: ep_len:776 episode reward: total was -47.380000. running mean: -28.938771\n",
      "ep 15: ep_len:945 episode reward: total was -73.500000. running mean: -29.384383\n",
      "ep 15: ep_len:985 episode reward: total was -37.290000. running mean: -29.463440\n",
      "ep 15: ep_len:348 episode reward: total was 21.000000. running mean: -28.958805\n",
      "ep 15: ep_len:500 episode reward: total was -8.460000. running mean: -28.753817\n",
      "ep 15: ep_len:705 episode reward: total was -91.040000. running mean: -29.376679\n",
      "ep 15: ep_len:910 episode reward: total was -50.380000. running mean: -29.586712\n",
      "ep 15: ep_len:500 episode reward: total was -40.760000. running mean: -29.698445\n",
      "ep 15: ep_len:625 episode reward: total was -24.870000. running mean: -29.650161\n",
      "ep 15: ep_len:500 episode reward: total was -7.000000. running mean: -29.423659\n",
      "ep 15: ep_len:8635 episode reward: total was -1591.990000. running mean: -45.049322\n",
      "ep 15: ep_len:770 episode reward: total was -42.950000. running mean: -45.028329\n",
      "ep 15: ep_len:500 episode reward: total was 14.220000. running mean: -44.435846\n",
      "ep 15: ep_len:580 episode reward: total was -54.440000. running mean: -44.535887\n",
      "ep 15: ep_len:500 episode reward: total was -18.360000. running mean: -44.274129\n",
      "ep 15: ep_len:510 episode reward: total was -20.760000. running mean: -44.038987\n",
      "ep 15: ep_len:1165 episode reward: total was -88.620000. running mean: -44.484797\n",
      "ep 15: ep_len:500 episode reward: total was -1.180000. running mean: -44.051749\n",
      "ep 15: ep_len:500 episode reward: total was -7.790000. running mean: -43.689132\n",
      "ep 15: ep_len:500 episode reward: total was 7.760000. running mean: -43.174641\n",
      "ep 15: ep_len:825 episode reward: total was -14.700000. running mean: -42.889894\n",
      "ep 15: ep_len:525 episode reward: total was -44.940000. running mean: -42.910395\n",
      "ep 15: ep_len:500 episode reward: total was 0.750000. running mean: -42.473791\n",
      "ep 15: ep_len:715 episode reward: total was -21.850000. running mean: -42.267553\n",
      "ep 15: ep_len:500 episode reward: total was 3.790000. running mean: -41.806978\n",
      "ep 15: ep_len:505 episode reward: total was 3.850000. running mean: -41.350408\n",
      "ep 15: ep_len:500 episode reward: total was -14.870000. running mean: -41.085604\n",
      "ep 15: ep_len:500 episode reward: total was -0.010000. running mean: -40.674848\n",
      "ep 15: ep_len:670 episode reward: total was -65.370000. running mean: -40.921800\n",
      "ep 15: ep_len:1055 episode reward: total was -32.810000. running mean: -40.840682\n",
      "ep 15: ep_len:500 episode reward: total was 2.250000. running mean: -40.409775\n",
      "ep 15: ep_len:1485 episode reward: total was -235.460000. running mean: -42.360277\n",
      "ep 15: ep_len:500 episode reward: total was -9.970000. running mean: -42.036374\n",
      "ep 15: ep_len:510 episode reward: total was -32.850000. running mean: -41.944510\n",
      "ep 15: ep_len:500 episode reward: total was -11.350000. running mean: -41.638565\n",
      "ep 15: ep_len:745 episode reward: total was -17.310000. running mean: -41.395280\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 15: ep_len:500 episode reward: total was -4.830000. running mean: -41.029627\n",
      "ep 15: ep_len:965 episode reward: total was -79.860000. running mean: -41.417931\n",
      "ep 15: ep_len:540 episode reward: total was -27.460000. running mean: -41.278351\n",
      "ep 15: ep_len:595 episode reward: total was -23.850000. running mean: -41.104068\n",
      "ep 15: ep_len:500 episode reward: total was -10.820000. running mean: -40.801227\n",
      "ep 15: ep_len:500 episode reward: total was -3.480000. running mean: -40.428015\n",
      "ep 15: ep_len:505 episode reward: total was -30.960000. running mean: -40.333335\n",
      "ep 15: ep_len:205 episode reward: total was 8.500000. running mean: -39.845001\n",
      "ep 15: ep_len:189 episode reward: total was 6.500000. running mean: -39.381551\n",
      "ep 15: ep_len:515 episode reward: total was -40.430000. running mean: -39.392036\n",
      "ep 15: ep_len:505 episode reward: total was -0.840000. running mean: -39.006515\n",
      "ep 15: ep_len:910 episode reward: total was -15.100000. running mean: -38.767450\n",
      "ep 15: ep_len:740 episode reward: total was -37.460000. running mean: -38.754376\n",
      "ep 15: ep_len:505 episode reward: total was -43.140000. running mean: -38.798232\n",
      "ep 15: ep_len:131 episode reward: total was 8.500000. running mean: -38.325250\n",
      "ep 15: ep_len:500 episode reward: total was 3.270000. running mean: -37.909297\n",
      "ep 15: ep_len:700 episode reward: total was -32.990000. running mean: -37.860104\n",
      "ep 15: ep_len:500 episode reward: total was 2.710000. running mean: -37.454403\n",
      "ep 15: ep_len:500 episode reward: total was -0.170000. running mean: -37.081559\n",
      "ep 15: ep_len:500 episode reward: total was -20.530000. running mean: -36.916044\n",
      "ep 15: ep_len:920 episode reward: total was -57.770000. running mean: -37.124583\n",
      "ep 15: ep_len:685 episode reward: total was -80.000000. running mean: -37.553337\n",
      "ep 15: ep_len:890 episode reward: total was -2.480000. running mean: -37.202604\n",
      "ep 15: ep_len:446 episode reward: total was 4.650000. running mean: -36.784078\n",
      "ep 15: ep_len:500 episode reward: total was -16.400000. running mean: -36.580237\n",
      "ep 15: ep_len:900 episode reward: total was -44.840000. running mean: -36.662835\n",
      "ep 15: ep_len:42240 episode reward: total was -8226.240000. running mean: -118.558606\n",
      "ep 15: ep_len:785 episode reward: total was -102.480000. running mean: -118.397820\n",
      "ep 15: ep_len:515 episode reward: total was -59.770000. running mean: -117.811542\n",
      "ep 15: ep_len:595 episode reward: total was -10.080000. running mean: -116.734227\n",
      "ep 15: ep_len:885 episode reward: total was -136.650000. running mean: -116.933384\n",
      "ep 15: ep_len:630 episode reward: total was -115.950000. running mean: -116.923551\n",
      "ep 15: ep_len:505 episode reward: total was -25.900000. running mean: -116.013315\n",
      "ep 15: ep_len:810 episode reward: total was -151.920000. running mean: -116.372382\n",
      "ep 15: ep_len:580 episode reward: total was -75.650000. running mean: -115.965158\n",
      "ep 15: ep_len:369 episode reward: total was -23.000000. running mean: -115.035507\n",
      "ep 15: ep_len:500 episode reward: total was -86.990000. running mean: -114.755051\n",
      "ep 15: ep_len:990 episode reward: total was -137.100000. running mean: -114.978501\n",
      "ep 15: ep_len:500 episode reward: total was -35.960000. running mean: -114.188316\n",
      "ep 15: ep_len:865 episode reward: total was -51.610000. running mean: -113.562533\n",
      "ep 15: ep_len:500 episode reward: total was -27.510000. running mean: -112.702007\n",
      "ep 15: ep_len:880 episode reward: total was -71.010000. running mean: -112.285087\n",
      "ep 15: ep_len:1205 episode reward: total was -123.370000. running mean: -112.395937\n",
      "ep 15: ep_len:500 episode reward: total was -22.720000. running mean: -111.499177\n",
      "ep 15: ep_len:659 episode reward: total was -102.440000. running mean: -111.408585\n",
      "ep 15: ep_len:545 episode reward: total was -59.680000. running mean: -110.891300\n",
      "ep 15: ep_len:725 episode reward: total was -39.710000. running mean: -110.179487\n",
      "ep 15: ep_len:870 episode reward: total was -76.610000. running mean: -109.843792\n",
      "ep 15: ep_len:505 episode reward: total was -55.570000. running mean: -109.301054\n",
      "ep 15: ep_len:500 episode reward: total was -29.460000. running mean: -108.502643\n",
      "ep 15: ep_len:500 episode reward: total was -53.620000. running mean: -107.953817\n",
      "ep 15: ep_len:500 episode reward: total was -20.840000. running mean: -107.082679\n",
      "ep 15: ep_len:665 episode reward: total was -98.190000. running mean: -106.993752\n",
      "ep 15: ep_len:1850 episode reward: total was -267.660000. running mean: -108.600414\n",
      "ep 15: ep_len:620 episode reward: total was -58.400000. running mean: -108.098410\n",
      "ep 15: ep_len:510 episode reward: total was -33.370000. running mean: -107.351126\n",
      "ep 15: ep_len:500 episode reward: total was -20.480000. running mean: -106.482415\n",
      "ep 15: ep_len:1790 episode reward: total was -195.890000. running mean: -107.376491\n",
      "ep 15: ep_len:730 episode reward: total was -61.210000. running mean: -106.914826\n",
      "ep 15: ep_len:1785 episode reward: total was -165.410000. running mean: -107.499778\n",
      "ep 15: ep_len:980 episode reward: total was -127.370000. running mean: -107.698480\n",
      "ep 15: ep_len:500 episode reward: total was -8.250000. running mean: -106.703995\n",
      "ep 15: ep_len:520 episode reward: total was -46.080000. running mean: -106.097755\n",
      "ep 15: ep_len:995 episode reward: total was -3.920000. running mean: -105.075977\n",
      "ep 15: ep_len:500 episode reward: total was -36.420000. running mean: -104.389418\n",
      "ep 15: ep_len:509 episode reward: total was -15.810000. running mean: -103.503623\n",
      "ep 15: ep_len:770 episode reward: total was -4.490000. running mean: -102.513487\n",
      "ep 15: ep_len:875 episode reward: total was -41.300000. running mean: -101.901352\n",
      "ep 15: ep_len:560 episode reward: total was -6.410000. running mean: -100.946439\n",
      "ep 15: ep_len:500 episode reward: total was -8.100000. running mean: -100.017974\n",
      "ep 15: ep_len:500 episode reward: total was -57.860000. running mean: -99.596395\n",
      "ep 15: ep_len:500 episode reward: total was 2.430000. running mean: -98.576131\n",
      "ep 15: ep_len:500 episode reward: total was -18.360000. running mean: -97.773969\n",
      "ep 15: ep_len:715 episode reward: total was -34.980000. running mean: -97.146030\n",
      "ep 15: ep_len:505 episode reward: total was -30.330000. running mean: -96.477869\n",
      "ep 15: ep_len:970 episode reward: total was -105.660000. running mean: -96.569691\n",
      "ep 15: ep_len:257 episode reward: total was 9.000000. running mean: -95.513994\n",
      "ep 15: ep_len:400 episode reward: total was -30.650000. running mean: -94.865354\n",
      "ep 15: ep_len:675 episode reward: total was -88.670000. running mean: -94.803400\n",
      "ep 15: ep_len:745 episode reward: total was -29.870000. running mean: -94.154066\n",
      "ep 15: ep_len:291 episode reward: total was 14.000000. running mean: -93.072526\n",
      "ep 15: ep_len:740 episode reward: total was -37.960000. running mean: -92.521400\n",
      "ep 15: ep_len:510 episode reward: total was -19.800000. running mean: -91.794186\n",
      "ep 15: ep_len:1115 episode reward: total was -59.720000. running mean: -91.473445\n",
      "ep 15: ep_len:550 episode reward: total was -22.180000. running mean: -90.780510\n",
      "ep 15: ep_len:240 episode reward: total was 1.510000. running mean: -89.857605\n",
      "ep 15: ep_len:530 episode reward: total was -30.270000. running mean: -89.261729\n",
      "ep 15: ep_len:500 episode reward: total was -12.400000. running mean: -88.493112\n",
      "ep 15: ep_len:211 episode reward: total was 14.000000. running mean: -87.468181\n",
      "ep 15: ep_len:500 episode reward: total was -52.200000. running mean: -87.115499\n",
      "ep 15: ep_len:775 episode reward: total was 5.540000. running mean: -86.188944\n",
      "ep 15: ep_len:500 episode reward: total was -24.230000. running mean: -85.569354\n",
      "ep 15: ep_len:500 episode reward: total was -6.790000. running mean: -84.781561\n",
      "ep 15: ep_len:208 episode reward: total was 10.000000. running mean: -83.833745\n",
      "ep 15: ep_len:500 episode reward: total was -16.060000. running mean: -83.156008\n",
      "ep 15: ep_len:655 episode reward: total was -51.260000. running mean: -82.837048\n",
      "ep 15: ep_len:63 episode reward: total was 6.000000. running mean: -81.948677\n",
      "ep 15: ep_len:1065 episode reward: total was -27.460000. running mean: -81.403790\n",
      "ep 15: ep_len:765 episode reward: total was -33.350000. running mean: -80.923253\n",
      "ep 15: ep_len:500 episode reward: total was -4.370000. running mean: -80.157720\n",
      "ep 15: ep_len:265 episode reward: total was 17.500000. running mean: -79.181143\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 15: ep_len:575 episode reward: total was -46.370000. running mean: -78.853031\n",
      "ep 15: ep_len:255 episode reward: total was 13.010000. running mean: -77.934401\n",
      "ep 15: ep_len:505 episode reward: total was -14.980000. running mean: -77.304857\n",
      "ep 15: ep_len:665 episode reward: total was -15.890000. running mean: -76.690708\n",
      "ep 15: ep_len:1240 episode reward: total was -21.260000. running mean: -76.136401\n",
      "ep 15: ep_len:760 episode reward: total was -27.880000. running mean: -75.653837\n",
      "ep 15: ep_len:575 episode reward: total was 2.400000. running mean: -74.873299\n",
      "ep 15: ep_len:550 episode reward: total was -20.160000. running mean: -74.326166\n",
      "ep 15: ep_len:595 episode reward: total was -23.100000. running mean: -73.813904\n",
      "ep 15: ep_len:500 episode reward: total was -3.810000. running mean: -73.113865\n",
      "ep 15: ep_len:500 episode reward: total was -13.530000. running mean: -72.518027\n",
      "ep 15: ep_len:755 episode reward: total was -71.750000. running mean: -72.510346\n",
      "ep 15: ep_len:1220 episode reward: total was -133.950000. running mean: -73.124743\n",
      "ep 15: ep_len:214 episode reward: total was 7.500000. running mean: -72.318495\n",
      "ep 15: ep_len:605 episode reward: total was 1.630000. running mean: -71.579011\n",
      "ep 15: ep_len:545 episode reward: total was -29.230000. running mean: -71.155520\n",
      "ep 15: ep_len:500 episode reward: total was -6.720000. running mean: -70.511165\n",
      "ep 15: ep_len:500 episode reward: total was 0.380000. running mean: -69.802254\n",
      "ep 15: ep_len:587 episode reward: total was -66.580000. running mean: -69.770031\n",
      "ep 15: ep_len:500 episode reward: total was 14.680000. running mean: -68.925531\n",
      "ep 15: ep_len:500 episode reward: total was -14.030000. running mean: -68.376575\n",
      "ep 15: ep_len:500 episode reward: total was -1.270000. running mean: -67.705510\n",
      "ep 15: ep_len:500 episode reward: total was -20.780000. running mean: -67.236255\n",
      "ep 15: ep_len:500 episode reward: total was -9.970000. running mean: -66.663592\n",
      "ep 15: ep_len:500 episode reward: total was -10.890000. running mean: -66.105856\n",
      "ep 15: ep_len:500 episode reward: total was -15.440000. running mean: -65.599198\n",
      "ep 15: ep_len:750 episode reward: total was -40.450000. running mean: -65.347706\n",
      "ep 15: ep_len:525 episode reward: total was -3.570000. running mean: -64.729929\n",
      "ep 15: ep_len:525 episode reward: total was -14.640000. running mean: -64.229029\n",
      "ep 15: ep_len:500 episode reward: total was -25.950000. running mean: -63.846239\n",
      "ep 15: ep_len:1085 episode reward: total was -71.390000. running mean: -63.921677\n",
      "ep 15: ep_len:940 episode reward: total was -33.220000. running mean: -63.614660\n",
      "ep 15: ep_len:520 episode reward: total was -54.040000. running mean: -63.518913\n",
      "ep 15: ep_len:431 episode reward: total was 11.180000. running mean: -62.771924\n",
      "ep 15: ep_len:1167 episode reward: total was -80.750000. running mean: -62.951705\n",
      "ep 15: ep_len:745 episode reward: total was -32.900000. running mean: -62.651188\n",
      "ep 15: ep_len:600 episode reward: total was -47.300000. running mean: -62.497676\n",
      "ep 15: ep_len:270 episode reward: total was 18.500000. running mean: -61.687699\n",
      "ep 15: ep_len:655 episode reward: total was -11.870000. running mean: -61.189522\n",
      "ep 15: ep_len:500 episode reward: total was -6.310000. running mean: -60.640727\n",
      "ep 15: ep_len:505 episode reward: total was 39.000000. running mean: -59.644320\n",
      "ep 15: ep_len:500 episode reward: total was -20.900000. running mean: -59.256876\n",
      "ep 15: ep_len:790 episode reward: total was -26.750000. running mean: -58.931808\n",
      "ep 15: ep_len:830 episode reward: total was -10.660000. running mean: -58.449090\n",
      "ep 15: ep_len:500 episode reward: total was -0.750000. running mean: -57.872099\n",
      "ep 15: ep_len:800 episode reward: total was -30.770000. running mean: -57.601078\n",
      "ep 15: ep_len:640 episode reward: total was -41.190000. running mean: -57.436967\n",
      "ep 15: ep_len:500 episode reward: total was -12.200000. running mean: -56.984597\n",
      "ep 15: ep_len:188 episode reward: total was 12.500000. running mean: -56.289751\n",
      "ep 15: ep_len:500 episode reward: total was 13.730000. running mean: -55.589554\n",
      "ep 15: ep_len:500 episode reward: total was 9.230000. running mean: -54.941358\n",
      "ep 15: ep_len:640 episode reward: total was -20.470000. running mean: -54.596645\n",
      "ep 15: ep_len:860 episode reward: total was -10.670000. running mean: -54.157378\n",
      "ep 15: ep_len:1325 episode reward: total was -104.580000. running mean: -54.661604\n",
      "ep 15: ep_len:895 episode reward: total was -27.180000. running mean: -54.386788\n",
      "ep 15: ep_len:500 episode reward: total was -23.830000. running mean: -54.081221\n",
      "ep 15: ep_len:935 episode reward: total was -32.790000. running mean: -53.868308\n",
      "ep 15: ep_len:885 episode reward: total was -9.990000. running mean: -53.429525\n",
      "ep 15: ep_len:500 episode reward: total was -19.830000. running mean: -53.093530\n",
      "ep 15: ep_len:279 episode reward: total was 23.500000. running mean: -52.327595\n",
      "ep 15: ep_len:635 episode reward: total was -19.990000. running mean: -52.004219\n",
      "ep 15: ep_len:682 episode reward: total was -23.920000. running mean: -51.723377\n",
      "ep 15: ep_len:620 episode reward: total was -24.060000. running mean: -51.446743\n",
      "ep 15: ep_len:640 episode reward: total was -14.930000. running mean: -51.081575\n",
      "ep 15: ep_len:530 episode reward: total was -46.950000. running mean: -51.040260\n",
      "ep 15: ep_len:500 episode reward: total was -37.730000. running mean: -50.907157\n",
      "ep 15: ep_len:500 episode reward: total was 6.080000. running mean: -50.337285\n",
      "ep 15: ep_len:505 episode reward: total was 2.260000. running mean: -49.811313\n",
      "ep 15: ep_len:1355 episode reward: total was -151.440000. running mean: -50.827599\n",
      "ep 15: ep_len:285 episode reward: total was 14.000000. running mean: -50.179323\n",
      "ep 15: ep_len:810 episode reward: total was -39.320000. running mean: -50.070730\n",
      "ep 15: ep_len:500 episode reward: total was -3.860000. running mean: -49.608623\n",
      "ep 15: ep_len:745 episode reward: total was -28.860000. running mean: -49.401137\n",
      "ep 15: ep_len:880 episode reward: total was -41.720000. running mean: -49.324325\n",
      "ep 15: ep_len:500 episode reward: total was -4.810000. running mean: -48.879182\n",
      "ep 15: ep_len:935 episode reward: total was -10.030000. running mean: -48.490690\n",
      "ep 15: ep_len:500 episode reward: total was 3.750000. running mean: -47.968283\n",
      "ep 15: ep_len:500 episode reward: total was -6.550000. running mean: -47.554101\n",
      "ep 15: ep_len:500 episode reward: total was -2.290000. running mean: -47.101460\n",
      "ep 15: ep_len:820 episode reward: total was -32.230000. running mean: -46.952745\n",
      "ep 15: ep_len:163 episode reward: total was 11.500000. running mean: -46.368217\n",
      "ep 15: ep_len:850 episode reward: total was -9.690000. running mean: -46.001435\n",
      "ep 15: ep_len:505 episode reward: total was -44.490000. running mean: -45.986321\n",
      "ep 15: ep_len:745 episode reward: total was -21.790000. running mean: -45.744358\n",
      "ep 15: ep_len:500 episode reward: total was -15.390000. running mean: -45.440814\n",
      "ep 15: ep_len:590 episode reward: total was -20.720000. running mean: -45.193606\n",
      "ep 15: ep_len:500 episode reward: total was -15.450000. running mean: -44.896170\n",
      "ep 15: ep_len:500 episode reward: total was -30.620000. running mean: -44.753408\n",
      "ep 15: ep_len:950 episode reward: total was -37.510000. running mean: -44.680974\n",
      "ep 15: ep_len:10110 episode reward: total was -1760.480000. running mean: -61.838964\n",
      "ep 15: ep_len:500 episode reward: total was 7.220000. running mean: -61.148375\n",
      "ep 15: ep_len:500 episode reward: total was -27.010000. running mean: -60.806991\n",
      "ep 15: ep_len:354 episode reward: total was 15.500000. running mean: -60.043921\n",
      "ep 15: ep_len:820 episode reward: total was -10.420000. running mean: -59.547682\n",
      "ep 15: ep_len:670 episode reward: total was -24.480000. running mean: -59.197005\n",
      "ep 15: ep_len:605 episode reward: total was -48.820000. running mean: -59.093235\n",
      "ep 15: ep_len:500 episode reward: total was 0.740000. running mean: -58.494903\n",
      "ep 15: ep_len:500 episode reward: total was 27.500000. running mean: -57.634954\n",
      "ep 15: ep_len:550 episode reward: total was -2.580000. running mean: -57.084404\n",
      "ep 15: ep_len:1080 episode reward: total was -24.070000. running mean: -56.754260\n",
      "ep 15: ep_len:670 episode reward: total was -27.480000. running mean: -56.461517\n",
      "ep 15: ep_len:775 episode reward: total was -17.520000. running mean: -56.072102\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 15: ep_len:500 episode reward: total was -24.930000. running mean: -55.760681\n",
      "ep 15: ep_len:500 episode reward: total was 8.740000. running mean: -55.115674\n",
      "ep 15: ep_len:500 episode reward: total was 20.740000. running mean: -54.357118\n",
      "ep 15: ep_len:1040 episode reward: total was -18.820000. running mean: -54.001747\n",
      "ep 15: ep_len:250 episode reward: total was 14.500000. running mean: -53.316729\n",
      "ep 15: ep_len:575 episode reward: total was -14.050000. running mean: -52.924062\n",
      "ep 15: ep_len:178 episode reward: total was 8.500000. running mean: -52.309821\n",
      "ep 15: ep_len:505 episode reward: total was -29.860000. running mean: -52.085323\n",
      "ep 15: ep_len:150 episode reward: total was 6.000000. running mean: -51.504470\n",
      "ep 15: ep_len:500 episode reward: total was -4.790000. running mean: -51.037325\n",
      "ep 15: ep_len:710 episode reward: total was -14.720000. running mean: -50.674152\n",
      "ep 15: ep_len:1310 episode reward: total was -142.870000. running mean: -51.596110\n",
      "ep 15: ep_len:500 episode reward: total was 11.280000. running mean: -50.967349\n",
      "ep 15: ep_len:575 episode reward: total was 5.860000. running mean: -50.399076\n",
      "ep 15: ep_len:500 episode reward: total was -40.120000. running mean: -50.296285\n",
      "ep 15: ep_len:500 episode reward: total was 1.240000. running mean: -49.780922\n",
      "ep 15: ep_len:840 episode reward: total was -40.790000. running mean: -49.691013\n",
      "ep 15: ep_len:600 episode reward: total was -22.790000. running mean: -49.422003\n",
      "ep 15: ep_len:740 episode reward: total was -22.810000. running mean: -49.155883\n",
      "ep 15: ep_len:595 episode reward: total was -31.670000. running mean: -48.981024\n",
      "ep 15: ep_len:500 episode reward: total was -6.740000. running mean: -48.558614\n",
      "ep 15: ep_len:500 episode reward: total was -14.960000. running mean: -48.222627\n",
      "ep 15: ep_len:505 episode reward: total was -25.320000. running mean: -47.993601\n",
      "ep 15: ep_len:700 episode reward: total was -22.890000. running mean: -47.742565\n",
      "ep 15: ep_len:336 episode reward: total was 26.000000. running mean: -47.005140\n",
      "ep 15: ep_len:500 episode reward: total was 4.760000. running mean: -46.487488\n",
      "ep 15: ep_len:505 episode reward: total was -25.820000. running mean: -46.280813\n",
      "ep 15: ep_len:1665 episode reward: total was -244.410000. running mean: -48.262105\n",
      "ep 15: ep_len:815 episode reward: total was -16.720000. running mean: -47.946684\n",
      "ep 15: ep_len:615 episode reward: total was -46.290000. running mean: -47.930117\n",
      "ep 15: ep_len:940 episode reward: total was -1.320000. running mean: -47.464016\n",
      "ep 15: ep_len:700 episode reward: total was -24.910000. running mean: -47.238476\n",
      "ep 15: ep_len:119 episode reward: total was 5.500000. running mean: -46.711091\n",
      "ep 15: ep_len:500 episode reward: total was -17.230000. running mean: -46.416280\n",
      "ep 15: ep_len:4215 episode reward: total was -659.230000. running mean: -52.544417\n",
      "ep 15: ep_len:500 episode reward: total was -22.800000. running mean: -52.246973\n",
      "ep 15: ep_len:116 episode reward: total was 5.500000. running mean: -51.669504\n",
      "ep 15: ep_len:505 episode reward: total was 1.620000. running mean: -51.136609\n",
      "ep 15: ep_len:630 episode reward: total was -20.000000. running mean: -50.825242\n",
      "ep 15: ep_len:670 episode reward: total was -3.680000. running mean: -50.353790\n",
      "ep 15: ep_len:5940 episode reward: total was -665.360000. running mean: -56.503852\n",
      "ep 15: ep_len:780 episode reward: total was -16.820000. running mean: -56.107014\n",
      "ep 15: ep_len:505 episode reward: total was -1.810000. running mean: -55.564043\n",
      "ep 15: ep_len:323 episode reward: total was 17.500000. running mean: -54.833403\n",
      "ep 15: ep_len:500 episode reward: total was 12.730000. running mean: -54.157769\n",
      "ep 15: ep_len:740 episode reward: total was -15.580000. running mean: -53.771991\n",
      "ep 15: ep_len:670 episode reward: total was -70.420000. running mean: -53.938471\n",
      "ep 15: ep_len:500 episode reward: total was 11.290000. running mean: -53.286187\n",
      "ep 15: ep_len:575 episode reward: total was -24.150000. running mean: -52.994825\n",
      "ep 15: ep_len:500 episode reward: total was -8.840000. running mean: -52.553277\n",
      "ep 15: ep_len:500 episode reward: total was -17.930000. running mean: -52.207044\n",
      "ep 15: ep_len:2225 episode reward: total was -372.330000. running mean: -55.408273\n",
      "ep 15: ep_len:590 episode reward: total was -38.260000. running mean: -55.236791\n",
      "ep 15: ep_len:760 episode reward: total was -25.280000. running mean: -54.937223\n",
      "ep 15: ep_len:565 episode reward: total was -29.920000. running mean: -54.687050\n",
      "ep 15: ep_len:1535 episode reward: total was -71.950000. running mean: -54.859680\n",
      "ep 15: ep_len:860 episode reward: total was -36.300000. running mean: -54.674083\n",
      "ep 15: ep_len:510 episode reward: total was -15.810000. running mean: -54.285442\n",
      "ep 15: ep_len:590 episode reward: total was -41.320000. running mean: -54.155788\n",
      "ep 15: ep_len:725 episode reward: total was -28.870000. running mean: -53.902930\n",
      "ep 15: ep_len:935 episode reward: total was -43.270000. running mean: -53.796601\n",
      "ep 15: ep_len:500 episode reward: total was 8.280000. running mean: -53.175835\n",
      "ep 15: ep_len:500 episode reward: total was -27.910000. running mean: -52.923176\n",
      "ep 15: ep_len:650 episode reward: total was -57.820000. running mean: -52.972145\n",
      "ep 15: ep_len:500 episode reward: total was 23.720000. running mean: -52.205223\n",
      "ep 15: ep_len:500 episode reward: total was -2.870000. running mean: -51.711871\n",
      "ep 15: ep_len:45 episode reward: total was 1.500000. running mean: -51.179752\n",
      "ep 15: ep_len:570 episode reward: total was -46.210000. running mean: -51.130055\n",
      "ep 15: ep_len:670 episode reward: total was -8.680000. running mean: -50.705554\n",
      "ep 15: ep_len:500 episode reward: total was -13.480000. running mean: -50.333299\n",
      "ep 15: ep_len:895 episode reward: total was -80.560000. running mean: -50.635566\n",
      "ep 15: ep_len:500 episode reward: total was -6.880000. running mean: -50.198010\n",
      "ep 15: ep_len:800 episode reward: total was -24.770000. running mean: -49.943730\n",
      "ep 15: ep_len:860 episode reward: total was -47.620000. running mean: -49.920493\n",
      "ep 15: ep_len:825 episode reward: total was -52.940000. running mean: -49.950688\n",
      "ep 15: ep_len:500 episode reward: total was -15.210000. running mean: -49.603281\n",
      "ep 15: ep_len:292 episode reward: total was 18.500000. running mean: -48.922248\n",
      "ep 15: ep_len:865 episode reward: total was -6.350000. running mean: -48.496525\n",
      "ep 15: ep_len:784 episode reward: total was -74.150000. running mean: -48.753060\n",
      "ep 15: ep_len:1425 episode reward: total was -50.730000. running mean: -48.772830\n",
      "ep 15: ep_len:500 episode reward: total was -6.230000. running mean: -48.347401\n",
      "ep 15: ep_len:464 episode reward: total was 18.760000. running mean: -47.676327\n",
      "ep 15: ep_len:1070 episode reward: total was -7.220000. running mean: -47.271764\n",
      "ep 15: ep_len:645 episode reward: total was -60.370000. running mean: -47.402746\n",
      "ep 15: ep_len:500 episode reward: total was -28.340000. running mean: -47.212119\n",
      "ep 15: ep_len:500 episode reward: total was -55.230000. running mean: -47.292298\n",
      "ep 15: ep_len:745 episode reward: total was -38.500000. running mean: -47.204375\n",
      "ep 15: ep_len:835 episode reward: total was -85.240000. running mean: -47.584731\n",
      "ep 15: ep_len:725 episode reward: total was -45.060000. running mean: -47.559484\n",
      "ep 15: ep_len:505 episode reward: total was -6.620000. running mean: -47.150089\n",
      "ep 15: ep_len:500 episode reward: total was -8.380000. running mean: -46.762388\n",
      "ep 15: ep_len:730 episode reward: total was -33.940000. running mean: -46.634164\n",
      "ep 15: ep_len:228 episode reward: total was 12.000000. running mean: -46.047822\n",
      "ep 15: ep_len:700 episode reward: total was -16.700000. running mean: -45.754344\n",
      "ep 15: ep_len:795 episode reward: total was -32.280000. running mean: -45.619601\n",
      "ep 15: ep_len:540 episode reward: total was -7.840000. running mean: -45.241805\n",
      "ep 15: ep_len:313 episode reward: total was 19.000000. running mean: -44.599387\n",
      "ep 15: ep_len:760 episode reward: total was -32.870000. running mean: -44.482093\n",
      "ep 15: ep_len:500 episode reward: total was -6.970000. running mean: -44.106972\n",
      "ep 15: ep_len:835 episode reward: total was -38.880000. running mean: -44.054702\n",
      "ep 15: ep_len:500 episode reward: total was 1.210000. running mean: -43.602055\n",
      "ep 15: ep_len:500 episode reward: total was 12.750000. running mean: -43.038535\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 15: ep_len:510 episode reward: total was -17.700000. running mean: -42.785149\n",
      "ep 15: ep_len:515 episode reward: total was -18.700000. running mean: -42.544298\n",
      "ep 15: ep_len:500 episode reward: total was 5.800000. running mean: -42.060855\n",
      "ep 15: ep_len:500 episode reward: total was -73.820000. running mean: -42.378446\n",
      "ep 15: ep_len:515 episode reward: total was -40.430000. running mean: -42.358962\n",
      "ep 15: ep_len:191 episode reward: total was 13.000000. running mean: -41.805372\n",
      "ep 15: ep_len:515 episode reward: total was -21.210000. running mean: -41.599418\n",
      "ep 15: ep_len:500 episode reward: total was -7.220000. running mean: -41.255624\n",
      "ep 15: ep_len:505 episode reward: total was -5.110000. running mean: -40.894168\n",
      "ep 15: ep_len:2860 episode reward: total was -374.650000. running mean: -44.231726\n",
      "ep 15: ep_len:515 episode reward: total was -39.420000. running mean: -44.183609\n",
      "ep 15: ep_len:500 episode reward: total was 2.060000. running mean: -43.721173\n",
      "ep 15: ep_len:940 episode reward: total was -31.920000. running mean: -43.603161\n",
      "ep 15: ep_len:500 episode reward: total was -13.400000. running mean: -43.301130\n",
      "ep 15: ep_len:1959 episode reward: total was -169.810000. running mean: -44.566218\n",
      "ep 15: ep_len:500 episode reward: total was -25.210000. running mean: -44.372656\n",
      "ep 15: ep_len:500 episode reward: total was 29.000000. running mean: -43.638930\n",
      "ep 15: ep_len:500 episode reward: total was 1.790000. running mean: -43.184640\n",
      "ep 15: ep_len:178 episode reward: total was 11.500000. running mean: -42.637794\n",
      "epsilon:0.153890 episode_count: 12621. steps_count: 8930250.000000\n",
      "ep 16: ep_len:500 episode reward: total was 8.710000. running mean: -42.124316\n",
      "ep 16: ep_len:1155 episode reward: total was -200.840000. running mean: -43.711473\n",
      "ep 16: ep_len:840 episode reward: total was 11.580000. running mean: -43.158558\n",
      "ep 16: ep_len:700 episode reward: total was -35.860000. running mean: -43.085573\n",
      "ep 16: ep_len:500 episode reward: total was 14.250000. running mean: -42.512217\n",
      "ep 16: ep_len:1000 episode reward: total was -87.420000. running mean: -42.961295\n",
      "ep 16: ep_len:830 episode reward: total was -31.330000. running mean: -42.844982\n",
      "ep 16: ep_len:610 episode reward: total was 8.780000. running mean: -42.328732\n",
      "ep 16: ep_len:815 episode reward: total was -60.520000. running mean: -42.510645\n",
      "ep 16: ep_len:500 episode reward: total was 6.590000. running mean: -42.019638\n",
      "ep 16: ep_len:560 episode reward: total was -14.080000. running mean: -41.740242\n",
      "ep 16: ep_len:935 episode reward: total was -19.650000. running mean: -41.519339\n",
      "ep 16: ep_len:510 episode reward: total was -15.190000. running mean: -41.256046\n",
      "ep 16: ep_len:1260 episode reward: total was -37.730000. running mean: -41.220785\n",
      "ep 16: ep_len:1250 episode reward: total was -17.230000. running mean: -40.980878\n",
      "ep 16: ep_len:500 episode reward: total was 15.240000. running mean: -40.418669\n",
      "ep 16: ep_len:975 episode reward: total was -7.440000. running mean: -40.088882\n",
      "ep 16: ep_len:640 episode reward: total was -34.120000. running mean: -40.029193\n",
      "ep 16: ep_len:158 episode reward: total was 8.500000. running mean: -39.543901\n",
      "ep 16: ep_len:565 episode reward: total was -14.070000. running mean: -39.289162\n",
      "ep 16: ep_len:500 episode reward: total was -23.030000. running mean: -39.126571\n",
      "ep 16: ep_len:1430 episode reward: total was -70.890000. running mean: -39.444205\n",
      "ep 16: ep_len:995 episode reward: total was -65.730000. running mean: -39.707063\n",
      "ep 16: ep_len:500 episode reward: total was -10.290000. running mean: -39.412892\n",
      "ep 16: ep_len:500 episode reward: total was -15.390000. running mean: -39.172663\n",
      "ep 16: ep_len:101 episode reward: total was 4.000000. running mean: -38.740937\n",
      "ep 16: ep_len:865 episode reward: total was -32.690000. running mean: -38.680427\n",
      "ep 16: ep_len:500 episode reward: total was -13.460000. running mean: -38.428223\n",
      "ep 16: ep_len:505 episode reward: total was -12.760000. running mean: -38.171541\n",
      "ep 16: ep_len:500 episode reward: total was -34.690000. running mean: -38.136726\n",
      "ep 16: ep_len:545 episode reward: total was -21.180000. running mean: -37.967158\n",
      "ep 16: ep_len:510 episode reward: total was -26.600000. running mean: -37.853487\n",
      "ep 16: ep_len:605 episode reward: total was -1.150000. running mean: -37.486452\n",
      "ep 16: ep_len:810 episode reward: total was -17.600000. running mean: -37.287587\n",
      "ep 16: ep_len:585 episode reward: total was -21.440000. running mean: -37.129111\n",
      "ep 16: ep_len:635 episode reward: total was -8.600000. running mean: -36.843820\n",
      "ep 16: ep_len:725 episode reward: total was -22.840000. running mean: -36.703782\n",
      "ep 16: ep_len:565 episode reward: total was -19.120000. running mean: -36.527944\n",
      "ep 16: ep_len:493 episode reward: total was 18.700000. running mean: -35.975665\n",
      "ep 16: ep_len:815 episode reward: total was -50.940000. running mean: -36.125308\n",
      "ep 16: ep_len:500 episode reward: total was -35.440000. running mean: -36.118455\n",
      "ep 16: ep_len:535 episode reward: total was -18.170000. running mean: -35.938971\n",
      "ep 16: ep_len:505 episode reward: total was -2.300000. running mean: -35.602581\n",
      "ep 16: ep_len:545 episode reward: total was 9.720000. running mean: -35.149355\n",
      "ep 16: ep_len:500 episode reward: total was 12.310000. running mean: -34.674761\n",
      "ep 16: ep_len:770 episode reward: total was -10.650000. running mean: -34.434514\n",
      "ep 16: ep_len:765 episode reward: total was -20.740000. running mean: -34.297569\n",
      "ep 16: ep_len:870 episode reward: total was -46.790000. running mean: -34.422493\n",
      "ep 16: ep_len:500 episode reward: total was -14.100000. running mean: -34.219268\n",
      "ep 16: ep_len:975 episode reward: total was -19.860000. running mean: -34.075675\n",
      "ep 16: ep_len:505 episode reward: total was 22.710000. running mean: -33.507819\n",
      "ep 16: ep_len:500 episode reward: total was -1.240000. running mean: -33.185141\n",
      "ep 16: ep_len:905 episode reward: total was -15.890000. running mean: -33.012189\n",
      "ep 16: ep_len:810 episode reward: total was -22.220000. running mean: -32.904267\n",
      "ep 16: ep_len:925 episode reward: total was 2.760000. running mean: -32.547625\n",
      "ep 16: ep_len:500 episode reward: total was -9.420000. running mean: -32.316348\n",
      "ep 16: ep_len:500 episode reward: total was -17.610000. running mean: -32.169285\n",
      "ep 16: ep_len:645 episode reward: total was -18.960000. running mean: -32.037192\n",
      "ep 16: ep_len:560 episode reward: total was -18.090000. running mean: -31.897720\n",
      "ep 16: ep_len:159 episode reward: total was 5.000000. running mean: -31.528743\n",
      "ep 16: ep_len:895 episode reward: total was -26.700000. running mean: -31.480455\n",
      "ep 16: ep_len:500 episode reward: total was 2.130000. running mean: -31.144351\n",
      "ep 16: ep_len:1040 episode reward: total was -90.890000. running mean: -31.741807\n",
      "ep 16: ep_len:690 episode reward: total was -22.570000. running mean: -31.650089\n",
      "ep 16: ep_len:535 episode reward: total was -34.330000. running mean: -31.676888\n",
      "ep 16: ep_len:635 episode reward: total was -27.060000. running mean: -31.630719\n",
      "ep 16: ep_len:700 episode reward: total was -15.300000. running mean: -31.467412\n",
      "ep 16: ep_len:212 episode reward: total was 15.000000. running mean: -31.002738\n",
      "ep 16: ep_len:1025 episode reward: total was -149.670000. running mean: -32.189411\n",
      "ep 16: ep_len:700 episode reward: total was -34.550000. running mean: -32.213017\n",
      "ep 16: ep_len:505 episode reward: total was -54.620000. running mean: -32.437087\n",
      "ep 16: ep_len:500 episode reward: total was -3.230000. running mean: -32.145016\n",
      "ep 16: ep_len:500 episode reward: total was 1.580000. running mean: -31.807765\n",
      "ep 16: ep_len:500 episode reward: total was 9.690000. running mean: -31.392788\n",
      "ep 16: ep_len:2295 episode reward: total was -196.600000. running mean: -33.044860\n",
      "ep 16: ep_len:500 episode reward: total was -26.380000. running mean: -32.978211\n",
      "ep 16: ep_len:850 episode reward: total was -8.530000. running mean: -32.733729\n",
      "ep 16: ep_len:500 episode reward: total was -12.350000. running mean: -32.529892\n",
      "ep 16: ep_len:645 episode reward: total was -21.990000. running mean: -32.424493\n",
      "ep 16: ep_len:520 episode reward: total was -11.100000. running mean: -32.211248\n",
      "ep 16: ep_len:550 episode reward: total was -2.210000. running mean: -31.911236\n",
      "ep 16: ep_len:830 episode reward: total was -23.720000. running mean: -31.829323\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 16: ep_len:660 episode reward: total was -20.950000. running mean: -31.720530\n",
      "ep 16: ep_len:615 episode reward: total was -10.620000. running mean: -31.509525\n",
      "ep 16: ep_len:500 episode reward: total was 11.220000. running mean: -31.082229\n",
      "ep 16: ep_len:770 episode reward: total was -58.070000. running mean: -31.352107\n",
      "ep 16: ep_len:620 episode reward: total was -14.990000. running mean: -31.188486\n",
      "ep 16: ep_len:840 episode reward: total was -86.240000. running mean: -31.739001\n",
      "ep 16: ep_len:500 episode reward: total was -4.230000. running mean: -31.463911\n",
      "ep 16: ep_len:500 episode reward: total was 31.000000. running mean: -30.839272\n",
      "ep 16: ep_len:920 episode reward: total was -51.120000. running mean: -31.042079\n",
      "ep 16: ep_len:199 episode reward: total was 12.000000. running mean: -30.611659\n",
      "ep 16: ep_len:500 episode reward: total was -10.800000. running mean: -30.413542\n",
      "ep 16: ep_len:500 episode reward: total was 5.710000. running mean: -30.052307\n",
      "ep 16: ep_len:795 episode reward: total was -44.730000. running mean: -30.199084\n",
      "ep 16: ep_len:670 episode reward: total was -33.050000. running mean: -30.227593\n",
      "ep 16: ep_len:505 episode reward: total was -24.320000. running mean: -30.168517\n",
      "ep 16: ep_len:256 episode reward: total was 1.500000. running mean: -29.851832\n",
      "ep 16: ep_len:855 episode reward: total was -55.950000. running mean: -30.112813\n",
      "ep 16: ep_len:500 episode reward: total was -3.730000. running mean: -29.848985\n",
      "ep 16: ep_len:515 episode reward: total was -61.640000. running mean: -30.166895\n",
      "ep 16: ep_len:269 episode reward: total was -28.000000. running mean: -30.145226\n",
      "ep 16: ep_len:710 episode reward: total was -55.160000. running mean: -30.395374\n",
      "ep 16: ep_len:645 episode reward: total was -28.050000. running mean: -30.371920\n",
      "ep 16: ep_len:500 episode reward: total was -2.360000. running mean: -30.091801\n",
      "ep 16: ep_len:132 episode reward: total was 7.000000. running mean: -29.720883\n",
      "ep 16: ep_len:500 episode reward: total was 3.350000. running mean: -29.390174\n",
      "ep 16: ep_len:955 episode reward: total was -22.070000. running mean: -29.316973\n",
      "ep 16: ep_len:500 episode reward: total was -27.070000. running mean: -29.294503\n",
      "ep 16: ep_len:500 episode reward: total was -16.250000. running mean: -29.164058\n",
      "ep 16: ep_len:900 episode reward: total was -12.490000. running mean: -28.997317\n",
      "ep 16: ep_len:1100 episode reward: total was -35.330000. running mean: -29.060644\n",
      "ep 16: ep_len:766 episode reward: total was -91.040000. running mean: -29.680438\n",
      "ep 16: ep_len:500 episode reward: total was -27.000000. running mean: -29.653633\n",
      "ep 16: ep_len:1090 episode reward: total was -26.750000. running mean: -29.624597\n",
      "ep 16: ep_len:835 episode reward: total was -19.190000. running mean: -29.520251\n",
      "ep 16: ep_len:755 episode reward: total was -15.360000. running mean: -29.378648\n",
      "ep 16: ep_len:530 episode reward: total was -47.960000. running mean: -29.564462\n",
      "ep 16: ep_len:500 episode reward: total was -31.000000. running mean: -29.578817\n",
      "ep 16: ep_len:1005 episode reward: total was -14.980000. running mean: -29.432829\n",
      "ep 16: ep_len:800 episode reward: total was -54.490000. running mean: -29.683401\n",
      "ep 16: ep_len:690 episode reward: total was -35.030000. running mean: -29.736867\n",
      "ep 16: ep_len:695 episode reward: total was -23.910000. running mean: -29.678598\n",
      "ep 16: ep_len:500 episode reward: total was -9.500000. running mean: -29.476812\n",
      "ep 16: ep_len:830 episode reward: total was -39.800000. running mean: -29.580044\n",
      "ep 16: ep_len:635 episode reward: total was -54.590000. running mean: -29.830144\n",
      "ep 16: ep_len:500 episode reward: total was -42.080000. running mean: -29.952642\n",
      "ep 16: ep_len:500 episode reward: total was 7.240000. running mean: -29.580716\n",
      "ep 16: ep_len:1325 episode reward: total was -67.060000. running mean: -29.955509\n",
      "ep 16: ep_len:500 episode reward: total was -21.070000. running mean: -29.866654\n",
      "ep 16: ep_len:825 episode reward: total was -51.930000. running mean: -30.087287\n",
      "ep 16: ep_len:344 episode reward: total was -68.000000. running mean: -30.466414\n",
      "ep 16: ep_len:500 episode reward: total was 3.780000. running mean: -30.123950\n",
      "ep 16: ep_len:2415 episode reward: total was -377.000000. running mean: -33.592710\n",
      "ep 16: ep_len:500 episode reward: total was -3.410000. running mean: -33.290883\n",
      "ep 16: ep_len:865 episode reward: total was -22.620000. running mean: -33.184175\n",
      "ep 16: ep_len:1480 episode reward: total was -143.510000. running mean: -34.287433\n",
      "ep 16: ep_len:500 episode reward: total was 3.060000. running mean: -33.913958\n",
      "ep 16: ep_len:505 episode reward: total was -22.820000. running mean: -33.803019\n",
      "ep 16: ep_len:214 episode reward: total was 10.500000. running mean: -33.359989\n",
      "ep 16: ep_len:630 episode reward: total was -21.010000. running mean: -33.236489\n",
      "ep 16: ep_len:146 episode reward: total was -3.000000. running mean: -32.934124\n",
      "ep 16: ep_len:505 episode reward: total was -49.310000. running mean: -33.097883\n",
      "ep 16: ep_len:725 episode reward: total was -25.870000. running mean: -33.025604\n",
      "ep 16: ep_len:500 episode reward: total was 7.700000. running mean: -32.618348\n",
      "ep 16: ep_len:500 episode reward: total was 9.240000. running mean: -32.199764\n",
      "ep 16: ep_len:630 episode reward: total was -30.100000. running mean: -32.178767\n",
      "ep 16: ep_len:580 episode reward: total was -49.540000. running mean: -32.352379\n",
      "ep 16: ep_len:525 episode reward: total was -14.150000. running mean: -32.170355\n",
      "ep 16: ep_len:505 episode reward: total was -5.430000. running mean: -31.902952\n",
      "ep 16: ep_len:880 episode reward: total was -7.570000. running mean: -31.659622\n",
      "ep 16: ep_len:739 episode reward: total was -128.470000. running mean: -32.627726\n",
      "ep 16: ep_len:500 episode reward: total was 16.240000. running mean: -32.139049\n",
      "ep 16: ep_len:500 episode reward: total was -13.770000. running mean: -31.955358\n",
      "ep 16: ep_len:326 episode reward: total was 6.270000. running mean: -31.573105\n",
      "ep 16: ep_len:500 episode reward: total was 4.270000. running mean: -31.214674\n",
      "ep 16: ep_len:500 episode reward: total was 16.240000. running mean: -30.740127\n",
      "ep 16: ep_len:600 episode reward: total was -11.990000. running mean: -30.552626\n",
      "ep 16: ep_len:855 episode reward: total was -77.090000. running mean: -31.017999\n",
      "ep 16: ep_len:157 episode reward: total was 7.000000. running mean: -30.637819\n",
      "ep 16: ep_len:655 episode reward: total was -39.140000. running mean: -30.722841\n",
      "ep 16: ep_len:500 episode reward: total was 0.670000. running mean: -30.408913\n",
      "ep 16: ep_len:500 episode reward: total was -7.490000. running mean: -30.179724\n",
      "ep 16: ep_len:505 episode reward: total was -2.110000. running mean: -29.899026\n",
      "ep 16: ep_len:625 episode reward: total was -27.080000. running mean: -29.870836\n",
      "ep 16: ep_len:500 episode reward: total was -28.990000. running mean: -29.862028\n",
      "ep 16: ep_len:500 episode reward: total was 3.730000. running mean: -29.526107\n",
      "ep 16: ep_len:313 episode reward: total was 17.000000. running mean: -29.060846\n",
      "ep 16: ep_len:910 episode reward: total was -36.280000. running mean: -29.133038\n",
      "ep 16: ep_len:700 episode reward: total was -20.870000. running mean: -29.050408\n",
      "ep 16: ep_len:730 episode reward: total was -60.370000. running mean: -29.363603\n",
      "ep 16: ep_len:500 episode reward: total was -21.300000. running mean: -29.282967\n",
      "ep 16: ep_len:150 episode reward: total was 8.000000. running mean: -28.910138\n",
      "ep 16: ep_len:500 episode reward: total was -5.830000. running mean: -28.679336\n",
      "ep 16: ep_len:152 episode reward: total was 6.000000. running mean: -28.332543\n",
      "ep 16: ep_len:1040 episode reward: total was -26.450000. running mean: -28.313718\n",
      "ep 16: ep_len:1215 episode reward: total was -108.700000. running mean: -29.117580\n",
      "ep 16: ep_len:505 episode reward: total was -34.120000. running mean: -29.167605\n",
      "ep 16: ep_len:540 episode reward: total was -25.370000. running mean: -29.129629\n",
      "ep 16: ep_len:500 episode reward: total was -8.360000. running mean: -28.921932\n",
      "ep 16: ep_len:500 episode reward: total was -23.840000. running mean: -28.871113\n",
      "ep 16: ep_len:500 episode reward: total was -2.300000. running mean: -28.605402\n",
      "ep 16: ep_len:69 episode reward: total was 5.000000. running mean: -28.269348\n",
      "ep 16: ep_len:555 episode reward: total was -21.160000. running mean: -28.198254\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 16: ep_len:535 episode reward: total was -25.730000. running mean: -28.173572\n",
      "ep 16: ep_len:500 episode reward: total was -2.270000. running mean: -27.914536\n",
      "ep 16: ep_len:585 episode reward: total was -12.280000. running mean: -27.758191\n",
      "ep 16: ep_len:500 episode reward: total was -21.810000. running mean: -27.698709\n",
      "ep 16: ep_len:675 episode reward: total was -29.000000. running mean: -27.711722\n",
      "ep 16: ep_len:232 episode reward: total was 12.500000. running mean: -27.309604\n",
      "ep 16: ep_len:820 episode reward: total was -28.710000. running mean: -27.323608\n",
      "ep 16: ep_len:224 episode reward: total was 13.000000. running mean: -26.920372\n",
      "ep 16: ep_len:2555 episode reward: total was -430.490000. running mean: -30.956069\n",
      "ep 16: ep_len:545 episode reward: total was 0.320000. running mean: -30.643308\n",
      "ep 16: ep_len:1520 episode reward: total was -235.370000. running mean: -32.690575\n",
      "ep 16: ep_len:505 episode reward: total was -4.810000. running mean: -32.411769\n",
      "ep 16: ep_len:570 episode reward: total was -43.350000. running mean: -32.521151\n",
      "ep 16: ep_len:685 episode reward: total was -39.080000. running mean: -32.586740\n",
      "ep 16: ep_len:745 episode reward: total was -50.070000. running mean: -32.761573\n",
      "ep 16: ep_len:835 episode reward: total was -85.770000. running mean: -33.291657\n",
      "ep 16: ep_len:625 episode reward: total was -30.110000. running mean: -33.259840\n",
      "ep 16: ep_len:900 episode reward: total was -17.670000. running mean: -33.103942\n",
      "ep 16: ep_len:500 episode reward: total was -20.410000. running mean: -32.977002\n",
      "ep 16: ep_len:620 episode reward: total was -20.020000. running mean: -32.847432\n",
      "ep 16: ep_len:500 episode reward: total was -12.970000. running mean: -32.648658\n",
      "ep 16: ep_len:4265 episode reward: total was -716.670000. running mean: -39.488871\n",
      "ep 16: ep_len:500 episode reward: total was -12.300000. running mean: -39.216983\n",
      "ep 16: ep_len:750 episode reward: total was -44.000000. running mean: -39.264813\n",
      "ep 16: ep_len:760 episode reward: total was -39.940000. running mean: -39.271565\n",
      "ep 16: ep_len:930 episode reward: total was -80.110000. running mean: -39.679949\n",
      "ep 16: ep_len:206 episode reward: total was 5.500000. running mean: -39.228150\n",
      "ep 16: ep_len:605 episode reward: total was -30.150000. running mean: -39.137368\n",
      "ep 16: ep_len:915 episode reward: total was -26.740000. running mean: -39.013394\n",
      "ep 16: ep_len:500 episode reward: total was -4.640000. running mean: -38.669661\n",
      "ep 16: ep_len:630 episode reward: total was -31.100000. running mean: -38.593964\n",
      "ep 16: ep_len:700 episode reward: total was -63.290000. running mean: -38.840924\n",
      "ep 16: ep_len:500 episode reward: total was -47.250000. running mean: -38.925015\n",
      "ep 16: ep_len:500 episode reward: total was -1.270000. running mean: -38.548465\n",
      "ep 16: ep_len:500 episode reward: total was -6.690000. running mean: -38.229880\n",
      "ep 16: ep_len:400 episode reward: total was 22.000000. running mean: -37.627581\n",
      "ep 16: ep_len:745 episode reward: total was -20.780000. running mean: -37.459106\n",
      "ep 16: ep_len:575 episode reward: total was -20.110000. running mean: -37.285615\n",
      "ep 16: ep_len:675 episode reward: total was -36.240000. running mean: -37.275158\n",
      "ep 16: ep_len:416 episode reward: total was -7.260000. running mean: -36.975007\n",
      "ep 16: ep_len:500 episode reward: total was -12.300000. running mean: -36.728257\n",
      "ep 16: ep_len:500 episode reward: total was 10.680000. running mean: -36.254174\n",
      "ep 16: ep_len:470 episode reward: total was 18.260000. running mean: -35.709032\n",
      "ep 16: ep_len:500 episode reward: total was -22.800000. running mean: -35.579942\n",
      "ep 16: ep_len:500 episode reward: total was -4.310000. running mean: -35.267243\n",
      "ep 16: ep_len:995 episode reward: total was -77.540000. running mean: -35.689970\n",
      "ep 16: ep_len:500 episode reward: total was -40.000000. running mean: -35.733071\n",
      "ep 16: ep_len:500 episode reward: total was 7.730000. running mean: -35.298440\n",
      "ep 16: ep_len:535 episode reward: total was -41.390000. running mean: -35.359355\n",
      "ep 16: ep_len:500 episode reward: total was -21.650000. running mean: -35.222262\n",
      "ep 16: ep_len:770 episode reward: total was -39.400000. running mean: -35.264039\n",
      "ep 16: ep_len:1850 episode reward: total was -218.060000. running mean: -37.091999\n",
      "ep 16: ep_len:525 episode reward: total was -25.260000. running mean: -36.973679\n",
      "ep 16: ep_len:500 episode reward: total was 26.000000. running mean: -36.343942\n",
      "ep 16: ep_len:775 episode reward: total was -37.520000. running mean: -36.355703\n",
      "ep 16: ep_len:590 episode reward: total was -25.620000. running mean: -36.248346\n",
      "ep 16: ep_len:540 episode reward: total was -21.190000. running mean: -36.097762\n",
      "ep 16: ep_len:500 episode reward: total was 12.200000. running mean: -35.614785\n",
      "ep 16: ep_len:500 episode reward: total was -31.850000. running mean: -35.577137\n",
      "ep 16: ep_len:500 episode reward: total was -46.520000. running mean: -35.686565\n",
      "ep 16: ep_len:500 episode reward: total was -26.180000. running mean: -35.591500\n",
      "ep 16: ep_len:865 episode reward: total was -24.480000. running mean: -35.480385\n",
      "ep 16: ep_len:655 episode reward: total was -30.710000. running mean: -35.432681\n",
      "ep 16: ep_len:500 episode reward: total was 21.260000. running mean: -34.865754\n",
      "ep 16: ep_len:600 episode reward: total was -55.410000. running mean: -35.071197\n",
      "ep 16: ep_len:790 episode reward: total was -42.240000. running mean: -35.142885\n",
      "ep 16: ep_len:500 episode reward: total was 5.220000. running mean: -34.739256\n",
      "ep 16: ep_len:910 episode reward: total was -65.900000. running mean: -35.050863\n",
      "ep 16: ep_len:765 episode reward: total was -15.240000. running mean: -34.852755\n",
      "ep 16: ep_len:540 episode reward: total was -29.040000. running mean: -34.794627\n",
      "ep 16: ep_len:735 episode reward: total was -58.170000. running mean: -35.028381\n",
      "ep 16: ep_len:640 episode reward: total was -2.250000. running mean: -34.700597\n",
      "ep 16: ep_len:580 episode reward: total was -1.750000. running mean: -34.371091\n",
      "ep 16: ep_len:530 episode reward: total was -13.100000. running mean: -34.158380\n",
      "ep 16: ep_len:1020 episode reward: total was -41.980000. running mean: -34.236596\n",
      "ep 16: ep_len:505 episode reward: total was -1.840000. running mean: -33.912630\n",
      "ep 16: ep_len:189 episode reward: total was 5.000000. running mean: -33.523504\n",
      "ep 16: ep_len:500 episode reward: total was -6.140000. running mean: -33.249669\n",
      "ep 16: ep_len:161 episode reward: total was 10.000000. running mean: -32.817172\n",
      "ep 16: ep_len:750 episode reward: total was -17.460000. running mean: -32.663601\n",
      "ep 16: ep_len:500 episode reward: total was -20.280000. running mean: -32.539765\n",
      "ep 16: ep_len:4045 episode reward: total was -658.560000. running mean: -38.799967\n",
      "ep 16: ep_len:500 episode reward: total was -22.400000. running mean: -38.635967\n",
      "ep 16: ep_len:500 episode reward: total was 29.000000. running mean: -37.959608\n",
      "ep 16: ep_len:505 episode reward: total was 5.260000. running mean: -37.527411\n",
      "ep 16: ep_len:500 episode reward: total was 7.730000. running mean: -37.074837\n",
      "ep 16: ep_len:737 episode reward: total was -57.860000. running mean: -37.282689\n",
      "ep 16: ep_len:500 episode reward: total was -10.240000. running mean: -37.012262\n",
      "ep 16: ep_len:765 episode reward: total was -31.970000. running mean: -36.961839\n",
      "ep 16: ep_len:625 episode reward: total was -28.830000. running mean: -36.880521\n",
      "ep 16: ep_len:1235 episode reward: total was -175.340000. running mean: -38.265116\n",
      "ep 16: ep_len:895 episode reward: total was -8.920000. running mean: -37.971665\n",
      "ep 16: ep_len:535 episode reward: total was -17.400000. running mean: -37.765948\n",
      "ep 16: ep_len:500 episode reward: total was -15.770000. running mean: -37.545989\n",
      "ep 16: ep_len:254 episode reward: total was 10.530000. running mean: -37.065229\n",
      "ep 16: ep_len:172 episode reward: total was 12.500000. running mean: -36.569576\n",
      "ep 16: ep_len:605 episode reward: total was -34.160000. running mean: -36.545481\n",
      "ep 16: ep_len:1080 episode reward: total was -96.350000. running mean: -37.143526\n",
      "ep 16: ep_len:500 episode reward: total was -0.750000. running mean: -36.779591\n",
      "ep 16: ep_len:476 episode reward: total was -23.210000. running mean: -36.643895\n",
      "ep 16: ep_len:975 episode reward: total was -31.190000. running mean: -36.589356\n",
      "ep 16: ep_len:785 episode reward: total was -88.370000. running mean: -37.107162\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 16: ep_len:1455 episode reward: total was -178.940000. running mean: -38.525491\n",
      "ep 16: ep_len:720 episode reward: total was -37.970000. running mean: -38.519936\n",
      "ep 16: ep_len:500 episode reward: total was -26.470000. running mean: -38.399436\n",
      "ep 16: ep_len:500 episode reward: total was 1.210000. running mean: -38.003342\n",
      "ep 16: ep_len:770 episode reward: total was -14.140000. running mean: -37.764709\n",
      "ep 16: ep_len:695 episode reward: total was -29.970000. running mean: -37.686761\n",
      "ep 16: ep_len:995 episode reward: total was -69.740000. running mean: -38.007294\n",
      "ep 16: ep_len:500 episode reward: total was -5.820000. running mean: -37.685421\n",
      "ep 16: ep_len:500 episode reward: total was -35.990000. running mean: -37.668467\n",
      "ep 16: ep_len:500 episode reward: total was -0.880000. running mean: -37.300582\n",
      "ep 16: ep_len:595 episode reward: total was -23.100000. running mean: -37.158576\n",
      "ep 16: ep_len:1170 episode reward: total was -21.130000. running mean: -36.998290\n",
      "ep 16: ep_len:500 episode reward: total was 12.700000. running mean: -36.501308\n",
      "ep 16: ep_len:930 episode reward: total was -99.730000. running mean: -37.133594\n",
      "ep 16: ep_len:500 episode reward: total was -15.760000. running mean: -36.919858\n",
      "ep 16: ep_len:188 episode reward: total was 9.500000. running mean: -36.455660\n",
      "ep 16: ep_len:194 episode reward: total was 11.500000. running mean: -35.976103\n",
      "ep 16: ep_len:425 episode reward: total was 17.500000. running mean: -35.441342\n",
      "ep 16: ep_len:655 episode reward: total was -36.110000. running mean: -35.448029\n",
      "ep 16: ep_len:500 episode reward: total was 0.590000. running mean: -35.087649\n",
      "ep 16: ep_len:500 episode reward: total was 5.800000. running mean: -34.678772\n",
      "ep 16: ep_len:1035 episode reward: total was -36.150000. running mean: -34.693484\n",
      "ep 16: ep_len:188 episode reward: total was 14.000000. running mean: -34.206550\n",
      "ep 16: ep_len:640 episode reward: total was -12.910000. running mean: -33.993584\n",
      "ep 16: ep_len:242 episode reward: total was 21.000000. running mean: -33.443648\n",
      "ep 16: ep_len:585 episode reward: total was -9.650000. running mean: -33.205712\n",
      "ep 16: ep_len:383 episode reward: total was 12.500000. running mean: -32.748655\n",
      "ep 16: ep_len:675 episode reward: total was -50.210000. running mean: -32.923268\n",
      "ep 16: ep_len:391 episode reward: total was 2.800000. running mean: -32.566035\n",
      "ep 16: ep_len:795 episode reward: total was -38.860000. running mean: -32.628975\n",
      "ep 16: ep_len:550 episode reward: total was -27.230000. running mean: -32.574985\n",
      "ep 16: ep_len:500 episode reward: total was -9.260000. running mean: -32.341835\n",
      "ep 16: ep_len:505 episode reward: total was -28.300000. running mean: -32.301417\n",
      "ep 16: ep_len:970 episode reward: total was -38.410000. running mean: -32.362503\n",
      "ep 16: ep_len:695 episode reward: total was -7.340000. running mean: -32.112278\n",
      "ep 16: ep_len:500 episode reward: total was 16.220000. running mean: -31.628955\n",
      "ep 16: ep_len:500 episode reward: total was 11.740000. running mean: -31.195266\n",
      "ep 16: ep_len:1070 episode reward: total was -51.660000. running mean: -31.399913\n",
      "ep 16: ep_len:2335 episode reward: total was -336.080000. running mean: -34.446714\n",
      "ep 16: ep_len:1000 episode reward: total was -54.610000. running mean: -34.648347\n",
      "ep 16: ep_len:500 episode reward: total was -11.200000. running mean: -34.413863\n",
      "ep 16: ep_len:715 episode reward: total was -14.530000. running mean: -34.215024\n",
      "ep 16: ep_len:167 episode reward: total was 12.000000. running mean: -33.752874\n",
      "ep 16: ep_len:403 episode reward: total was -10.500000. running mean: -33.520346\n",
      "ep 16: ep_len:920 episode reward: total was -43.160000. running mean: -33.616742\n",
      "ep 16: ep_len:655 episode reward: total was -50.390000. running mean: -33.784475\n",
      "ep 16: ep_len:710 episode reward: total was -20.330000. running mean: -33.649930\n",
      "ep 16: ep_len:500 episode reward: total was 7.190000. running mean: -33.241531\n",
      "ep 16: ep_len:500 episode reward: total was 4.280000. running mean: -32.866315\n",
      "ep 16: ep_len:500 episode reward: total was -16.830000. running mean: -32.705952\n",
      "ep 16: ep_len:268 episode reward: total was 14.500000. running mean: -32.233893\n",
      "ep 16: ep_len:327 episode reward: total was -3.800000. running mean: -31.949554\n",
      "ep 16: ep_len:276 episode reward: total was 19.000000. running mean: -31.440058\n",
      "ep 16: ep_len:1105 episode reward: total was -113.960000. running mean: -32.265258\n",
      "ep 16: ep_len:740 episode reward: total was -30.820000. running mean: -32.250805\n",
      "ep 16: ep_len:935 episode reward: total was -88.070000. running mean: -32.808997\n",
      "ep 16: ep_len:500 episode reward: total was -8.250000. running mean: -32.563407\n",
      "ep 16: ep_len:500 episode reward: total was -18.760000. running mean: -32.425373\n",
      "ep 16: ep_len:765 episode reward: total was -81.340000. running mean: -32.914519\n",
      "ep 16: ep_len:510 episode reward: total was -15.190000. running mean: -32.737274\n",
      "ep 16: ep_len:915 episode reward: total was -44.780000. running mean: -32.857701\n",
      "ep 16: ep_len:228 episode reward: total was 18.000000. running mean: -32.349124\n",
      "ep 16: ep_len:500 episode reward: total was 1.180000. running mean: -32.013833\n",
      "ep 16: ep_len:515 episode reward: total was -23.180000. running mean: -31.925495\n",
      "ep 16: ep_len:510 episode reward: total was -97.000000. running mean: -32.576240\n",
      "ep 16: ep_len:15820 episode reward: total was -2948.570000. running mean: -61.736177\n",
      "ep 16: ep_len:765 episode reward: total was 1.130000. running mean: -61.107516\n",
      "ep 16: ep_len:705 episode reward: total was -21.350000. running mean: -60.709940\n",
      "ep 16: ep_len:540 episode reward: total was -38.360000. running mean: -60.486441\n",
      "ep 16: ep_len:550 episode reward: total was -20.250000. running mean: -60.084077\n",
      "ep 16: ep_len:920 episode reward: total was -34.720000. running mean: -59.830436\n",
      "ep 16: ep_len:249 episode reward: total was 17.000000. running mean: -59.062131\n",
      "ep 16: ep_len:1090 episode reward: total was -20.870000. running mean: -58.680210\n",
      "ep 16: ep_len:500 episode reward: total was -9.840000. running mean: -58.191808\n",
      "ep 16: ep_len:328 episode reward: total was 4.250000. running mean: -57.567390\n",
      "ep 16: ep_len:525 episode reward: total was -14.150000. running mean: -57.133216\n",
      "ep 16: ep_len:1130 episode reward: total was -109.300000. running mean: -57.654884\n",
      "ep 16: ep_len:505 episode reward: total was -20.950000. running mean: -57.287835\n",
      "ep 16: ep_len:675 episode reward: total was 6.640000. running mean: -56.648557\n",
      "ep 16: ep_len:500 episode reward: total was -30.570000. running mean: -56.387771\n",
      "ep 16: ep_len:500 episode reward: total was -53.100000. running mean: -56.354893\n",
      "ep 16: ep_len:500 episode reward: total was -10.190000. running mean: -55.893244\n",
      "ep 16: ep_len:505 episode reward: total was -24.590000. running mean: -55.580212\n",
      "ep 16: ep_len:720 episode reward: total was -19.300000. running mean: -55.217410\n",
      "ep 16: ep_len:209 episode reward: total was 11.500000. running mean: -54.550236\n",
      "ep 16: ep_len:1065 episode reward: total was -59.550000. running mean: -54.600233\n",
      "ep 16: ep_len:500 episode reward: total was -36.180000. running mean: -54.416031\n",
      "ep 16: ep_len:500 episode reward: total was -0.260000. running mean: -53.874471\n",
      "ep 16: ep_len:505 episode reward: total was -3.930000. running mean: -53.375026\n",
      "ep 16: ep_len:500 episode reward: total was 6.350000. running mean: -52.777776\n",
      "ep 16: ep_len:500 episode reward: total was -52.850000. running mean: -52.778498\n",
      "ep 16: ep_len:505 episode reward: total was -37.930000. running mean: -52.630013\n",
      "ep 16: ep_len:500 episode reward: total was -9.630000. running mean: -52.200013\n",
      "ep 16: ep_len:633 episode reward: total was -68.460000. running mean: -52.362613\n",
      "ep 16: ep_len:620 episode reward: total was -50.810000. running mean: -52.347087\n",
      "ep 16: ep_len:975 episode reward: total was -35.710000. running mean: -52.180716\n",
      "ep 16: ep_len:1390 episode reward: total was -160.890000. running mean: -53.267809\n",
      "ep 16: ep_len:580 episode reward: total was -53.920000. running mean: -53.274331\n",
      "ep 16: ep_len:695 episode reward: total was -59.290000. running mean: -53.334487\n",
      "ep 16: ep_len:685 episode reward: total was -33.020000. running mean: -53.131342\n",
      "ep 16: ep_len:1075 episode reward: total was -114.050000. running mean: -53.740529\n",
      "ep 16: ep_len:505 episode reward: total was -11.890000. running mean: -53.322024\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 16: ep_len:1750 episode reward: total was -137.320000. running mean: -54.162003\n",
      "ep 16: ep_len:500 episode reward: total was -6.260000. running mean: -53.682983\n",
      "ep 16: ep_len:500 episode reward: total was 32.500000. running mean: -52.821154\n",
      "ep 16: ep_len:500 episode reward: total was -5.370000. running mean: -52.346642\n",
      "ep 16: ep_len:970 episode reward: total was -39.250000. running mean: -52.215676\n",
      "ep 16: ep_len:540 episode reward: total was -13.110000. running mean: -51.824619\n",
      "ep 16: ep_len:247 episode reward: total was 12.500000. running mean: -51.181373\n",
      "ep 16: ep_len:730 episode reward: total was -30.910000. running mean: -50.978659\n",
      "ep 16: ep_len:500 episode reward: total was -10.570000. running mean: -50.574572\n",
      "ep 16: ep_len:660 episode reward: total was -22.940000. running mean: -50.298227\n",
      "ep 16: ep_len:500 episode reward: total was -47.220000. running mean: -50.267444\n",
      "ep 16: ep_len:351 episode reward: total was 18.500000. running mean: -49.579770\n",
      "ep 16: ep_len:500 episode reward: total was -11.410000. running mean: -49.198072\n",
      "ep 16: ep_len:880 episode reward: total was -72.020000. running mean: -49.426292\n",
      "ep 16: ep_len:500 episode reward: total was -14.810000. running mean: -49.080129\n",
      "ep 16: ep_len:211 episode reward: total was 12.000000. running mean: -48.469327\n",
      "ep 16: ep_len:1300 episode reward: total was -86.290000. running mean: -48.847534\n",
      "ep 16: ep_len:1225 episode reward: total was -202.630000. running mean: -50.385359\n",
      "ep 16: ep_len:268 episode reward: total was 13.000000. running mean: -49.751505\n",
      "ep 16: ep_len:500 episode reward: total was -7.400000. running mean: -49.327990\n",
      "ep 16: ep_len:885 episode reward: total was -16.850000. running mean: -49.003210\n",
      "ep 16: ep_len:1030 episode reward: total was -51.850000. running mean: -49.031678\n",
      "ep 16: ep_len:500 episode reward: total was -4.680000. running mean: -48.588161\n",
      "ep 16: ep_len:535 episode reward: total was -31.270000. running mean: -48.414980\n",
      "ep 16: ep_len:1050 episode reward: total was -29.450000. running mean: -48.225330\n",
      "ep 16: ep_len:276 episode reward: total was 17.000000. running mean: -47.573077\n",
      "ep 16: ep_len:500 episode reward: total was -28.340000. running mean: -47.380746\n",
      "ep 16: ep_len:1295 episode reward: total was -128.320000. running mean: -48.190138\n",
      "ep 16: ep_len:1460 episode reward: total was -209.230000. running mean: -49.800537\n",
      "ep 16: ep_len:426 episode reward: total was 21.500000. running mean: -49.087532\n",
      "ep 16: ep_len:505 episode reward: total was -28.500000. running mean: -48.881656\n",
      "ep 16: ep_len:1105 episode reward: total was -114.810000. running mean: -49.540940\n",
      "ep 16: ep_len:505 episode reward: total was -18.260000. running mean: -49.228130\n",
      "ep 16: ep_len:1155 episode reward: total was -43.760000. running mean: -49.173449\n",
      "ep 16: ep_len:1135 episode reward: total was -36.820000. running mean: -49.049915\n",
      "ep 16: ep_len:500 episode reward: total was -11.490000. running mean: -48.674315\n",
      "ep 16: ep_len:500 episode reward: total was -5.590000. running mean: -48.243472\n",
      "ep 16: ep_len:754 episode reward: total was -25.360000. running mean: -48.014638\n",
      "ep 16: ep_len:865 episode reward: total was 0.680000. running mean: -47.527691\n",
      "ep 16: ep_len:500 episode reward: total was -7.300000. running mean: -47.125414\n",
      "ep 16: ep_len:880 episode reward: total was -48.860000. running mean: -47.142760\n",
      "ep 16: ep_len:650 episode reward: total was -12.620000. running mean: -46.797532\n",
      "ep 16: ep_len:835 episode reward: total was -39.790000. running mean: -46.727457\n",
      "ep 16: ep_len:500 episode reward: total was -15.600000. running mean: -46.416183\n",
      "ep 16: ep_len:500 episode reward: total was 5.770000. running mean: -45.894321\n",
      "ep 16: ep_len:500 episode reward: total was -12.140000. running mean: -45.556778\n",
      "ep 16: ep_len:500 episode reward: total was 3.210000. running mean: -45.069110\n",
      "ep 16: ep_len:327 episode reward: total was -49.500000. running mean: -45.113419\n",
      "ep 16: ep_len:474 episode reward: total was 13.240000. running mean: -44.529884\n",
      "ep 16: ep_len:720 episode reward: total was -21.340000. running mean: -44.297986\n",
      "ep 16: ep_len:10 episode reward: total was -2.000000. running mean: -43.875006\n",
      "ep 16: ep_len:505 episode reward: total was -0.310000. running mean: -43.439356\n",
      "ep 16: ep_len:1190 episode reward: total was -216.840000. running mean: -45.173362\n",
      "ep 16: ep_len:660 episode reward: total was -15.900000. running mean: -44.880629\n",
      "ep 16: ep_len:500 episode reward: total was 5.220000. running mean: -44.379622\n",
      "ep 16: ep_len:510 episode reward: total was 9.220000. running mean: -43.843626\n",
      "ep 16: ep_len:505 episode reward: total was -9.290000. running mean: -43.498090\n",
      "ep 16: ep_len:585 episode reward: total was -43.320000. running mean: -43.496309\n",
      "ep 16: ep_len:500 episode reward: total was 5.250000. running mean: -43.008846\n",
      "ep 16: ep_len:710 episode reward: total was -20.390000. running mean: -42.782657\n",
      "ep 16: ep_len:500 episode reward: total was -18.450000. running mean: -42.539331\n",
      "ep 16: ep_len:875 episode reward: total was -56.910000. running mean: -42.683037\n",
      "ep 16: ep_len:915 episode reward: total was -24.730000. running mean: -42.503507\n",
      "ep 16: ep_len:585 episode reward: total was -30.190000. running mean: -42.380372\n",
      "ep 16: ep_len:500 episode reward: total was -23.360000. running mean: -42.190168\n",
      "ep 16: ep_len:785 episode reward: total was -29.910000. running mean: -42.067367\n",
      "ep 16: ep_len:830 episode reward: total was -13.220000. running mean: -41.778893\n",
      "ep 16: ep_len:970 episode reward: total was -62.330000. running mean: -41.984404\n",
      "ep 16: ep_len:196 episode reward: total was 12.000000. running mean: -41.444560\n",
      "ep 16: ep_len:351 episode reward: total was -6.000000. running mean: -41.090114\n",
      "ep 16: ep_len:540 episode reward: total was -22.200000. running mean: -40.901213\n",
      "ep 16: ep_len:500 episode reward: total was -23.930000. running mean: -40.731501\n",
      "ep 16: ep_len:500 episode reward: total was 17.250000. running mean: -40.151686\n",
      "ep 16: ep_len:500 episode reward: total was 1.760000. running mean: -39.732569\n",
      "ep 16: ep_len:500 episode reward: total was -12.760000. running mean: -39.462844\n",
      "ep 16: ep_len:500 episode reward: total was -9.270000. running mean: -39.160915\n",
      "ep 16: ep_len:500 episode reward: total was -38.470000. running mean: -39.154006\n",
      "ep 16: ep_len:500 episode reward: total was -11.690000. running mean: -38.879366\n",
      "ep 16: ep_len:500 episode reward: total was -8.040000. running mean: -38.570972\n",
      "ep 16: ep_len:525 episode reward: total was -17.670000. running mean: -38.361963\n",
      "ep 16: ep_len:206 episode reward: total was 10.000000. running mean: -37.878343\n",
      "ep 16: ep_len:500 episode reward: total was -10.240000. running mean: -37.601959\n",
      "ep 16: ep_len:1405 episode reward: total was -209.920000. running mean: -39.325140\n",
      "ep 16: ep_len:955 episode reward: total was -18.480000. running mean: -39.116688\n",
      "ep 16: ep_len:805 episode reward: total was -30.200000. running mean: -39.027522\n",
      "ep 16: ep_len:835 episode reward: total was -9.060000. running mean: -38.727846\n",
      "ep 16: ep_len:139 episode reward: total was 9.500000. running mean: -38.245568\n",
      "ep 16: ep_len:500 episode reward: total was 9.750000. running mean: -37.765612\n",
      "ep 16: ep_len:690 episode reward: total was -51.160000. running mean: -37.899556\n",
      "ep 16: ep_len:680 episode reward: total was -19.280000. running mean: -37.713361\n",
      "ep 16: ep_len:10700 episode reward: total was -2072.870000. running mean: -58.064927\n",
      "ep 16: ep_len:500 episode reward: total was -11.560000. running mean: -57.599878\n",
      "ep 16: ep_len:1100 episode reward: total was -33.250000. running mean: -57.356379\n",
      "ep 16: ep_len:910 episode reward: total was -29.160000. running mean: -57.074415\n",
      "ep 16: ep_len:690 episode reward: total was -20.890000. running mean: -56.712571\n",
      "ep 16: ep_len:452 episode reward: total was -0.260000. running mean: -56.148045\n",
      "ep 16: ep_len:500 episode reward: total was -20.930000. running mean: -55.795865\n",
      "ep 16: ep_len:510 episode reward: total was -17.700000. running mean: -55.414906\n",
      "ep 16: ep_len:500 episode reward: total was -8.230000. running mean: -54.943057\n",
      "ep 16: ep_len:1000 episode reward: total was -192.980000. running mean: -56.323427\n",
      "ep 16: ep_len:740 episode reward: total was -11.070000. running mean: -55.870892\n",
      "ep 16: ep_len:580 episode reward: total was -30.200000. running mean: -55.614183\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 16: ep_len:930 episode reward: total was -86.060000. running mean: -55.918641\n",
      "ep 16: ep_len:610 episode reward: total was -16.000000. running mean: -55.519455\n",
      "ep 16: ep_len:500 episode reward: total was -7.100000. running mean: -55.035261\n",
      "ep 16: ep_len:1125 episode reward: total was -1.730000. running mean: -54.502208\n",
      "ep 16: ep_len:545 episode reward: total was -41.520000. running mean: -54.372386\n",
      "ep 16: ep_len:1293 episode reward: total was -147.610000. running mean: -55.304762\n",
      "ep 16: ep_len:570 episode reward: total was -32.240000. running mean: -55.074114\n",
      "ep 16: ep_len:500 episode reward: total was -6.500000. running mean: -54.588373\n",
      "ep 16: ep_len:500 episode reward: total was -17.810000. running mean: -54.220589\n",
      "ep 16: ep_len:505 episode reward: total was -10.240000. running mean: -53.780784\n",
      "ep 16: ep_len:500 episode reward: total was -19.430000. running mean: -53.437276\n",
      "ep 16: ep_len:920 episode reward: total was -48.680000. running mean: -53.389703\n",
      "ep 16: ep_len:1996 episode reward: total was -221.460000. running mean: -55.070406\n",
      "ep 16: ep_len:505 episode reward: total was 7.900000. running mean: -54.440702\n",
      "ep 16: ep_len:500 episode reward: total was -14.960000. running mean: -54.045895\n",
      "ep 16: ep_len:790 episode reward: total was -6.750000. running mean: -53.572936\n",
      "ep 16: ep_len:570 episode reward: total was -29.210000. running mean: -53.329307\n",
      "ep 16: ep_len:850 episode reward: total was -20.060000. running mean: -52.996614\n",
      "ep 16: ep_len:520 episode reward: total was -23.340000. running mean: -52.700047\n",
      "ep 16: ep_len:505 episode reward: total was -3.740000. running mean: -52.210447\n",
      "ep 16: ep_len:870 episode reward: total was -18.060000. running mean: -51.868942\n",
      "ep 16: ep_len:655 episode reward: total was -43.180000. running mean: -51.782053\n",
      "ep 16: ep_len:775 episode reward: total was -11.380000. running mean: -51.378032\n",
      "ep 16: ep_len:500 episode reward: total was 5.780000. running mean: -50.806452\n",
      "ep 16: ep_len:600 episode reward: total was -40.750000. running mean: -50.705888\n",
      "ep 16: ep_len:500 episode reward: total was 11.740000. running mean: -50.081429\n",
      "ep 16: ep_len:500 episode reward: total was 13.270000. running mean: -49.447914\n",
      "ep 16: ep_len:2260 episode reward: total was -295.990000. running mean: -51.913335\n",
      "ep 16: ep_len:735 episode reward: total was -58.140000. running mean: -51.975602\n",
      "ep 16: ep_len:221 episode reward: total was 14.500000. running mean: -51.310846\n",
      "ep 16: ep_len:1380 episode reward: total was -165.440000. running mean: -52.452137\n",
      "ep 16: ep_len:1325 episode reward: total was -35.150000. running mean: -52.279116\n",
      "ep 16: ep_len:520 episode reward: total was -53.570000. running mean: -52.292025\n",
      "ep 16: ep_len:488 episode reward: total was -69.240000. running mean: -52.461505\n",
      "ep 16: ep_len:685 episode reward: total was -25.950000. running mean: -52.196390\n",
      "ep 16: ep_len:545 episode reward: total was -16.130000. running mean: -51.835726\n",
      "ep 16: ep_len:500 episode reward: total was 12.260000. running mean: -51.194769\n",
      "ep 16: ep_len:500 episode reward: total was 7.800000. running mean: -50.604821\n",
      "ep 16: ep_len:910 episode reward: total was -72.810000. running mean: -50.826873\n",
      "ep 16: ep_len:505 episode reward: total was -29.430000. running mean: -50.612904\n",
      "ep 16: ep_len:565 episode reward: total was -22.150000. running mean: -50.328275\n",
      "ep 16: ep_len:500 episode reward: total was -8.680000. running mean: -49.911792\n",
      "ep 16: ep_len:500 episode reward: total was 6.930000. running mean: -49.343374\n",
      "ep 16: ep_len:500 episode reward: total was 2.220000. running mean: -48.827740\n",
      "ep 16: ep_len:725 episode reward: total was -22.320000. running mean: -48.562663\n",
      "ep 16: ep_len:500 episode reward: total was 11.830000. running mean: -47.958736\n",
      "ep 16: ep_len:1197 episode reward: total was -135.240000. running mean: -48.831549\n",
      "ep 16: ep_len:182 episode reward: total was 13.500000. running mean: -48.208234\n",
      "ep 16: ep_len:380 episode reward: total was -5.670000. running mean: -47.782851\n",
      "ep 16: ep_len:905 episode reward: total was -61.840000. running mean: -47.923423\n",
      "ep 16: ep_len:520 episode reward: total was 0.860000. running mean: -47.435588\n",
      "ep 16: ep_len:780 episode reward: total was -28.790000. running mean: -47.249133\n",
      "ep 16: ep_len:97 episode reward: total was 8.000000. running mean: -46.696641\n",
      "ep 16: ep_len:500 episode reward: total was 17.250000. running mean: -46.057175\n",
      "ep 16: ep_len:1115 episode reward: total was -27.490000. running mean: -45.871503\n",
      "ep 16: ep_len:500 episode reward: total was -11.810000. running mean: -45.530888\n",
      "ep 16: ep_len:500 episode reward: total was 6.780000. running mean: -45.007779\n",
      "ep 16: ep_len:860 episode reward: total was -31.750000. running mean: -44.875201\n",
      "ep 16: ep_len:500 episode reward: total was -55.720000. running mean: -44.983649\n",
      "ep 16: ep_len:201 episode reward: total was 15.500000. running mean: -44.378813\n",
      "ep 16: ep_len:500 episode reward: total was -11.960000. running mean: -44.054625\n",
      "ep 16: ep_len:600 episode reward: total was -6.730000. running mean: -43.681379\n",
      "ep 16: ep_len:234 episode reward: total was 14.000000. running mean: -43.104565\n",
      "ep 16: ep_len:500 episode reward: total was -31.520000. running mean: -42.988719\n",
      "ep 16: ep_len:119 episode reward: total was 4.000000. running mean: -42.518832\n",
      "ep 16: ep_len:500 episode reward: total was -7.120000. running mean: -42.164844\n",
      "ep 16: ep_len:500 episode reward: total was -9.720000. running mean: -41.840395\n",
      "ep 16: ep_len:126 episode reward: total was 8.000000. running mean: -41.341991\n",
      "ep 16: ep_len:500 episode reward: total was 14.280000. running mean: -40.785771\n",
      "ep 16: ep_len:795 episode reward: total was -43.910000. running mean: -40.817014\n",
      "ep 16: ep_len:670 episode reward: total was -63.890000. running mean: -41.047743\n",
      "ep 16: ep_len:585 episode reward: total was -35.240000. running mean: -40.989666\n",
      "ep 16: ep_len:170 episode reward: total was 10.000000. running mean: -40.479769\n",
      "ep 16: ep_len:500 episode reward: total was -14.440000. running mean: -40.219372\n",
      "ep 16: ep_len:665 episode reward: total was -15.860000. running mean: -39.975778\n",
      "ep 16: ep_len:865 episode reward: total was -39.730000. running mean: -39.973320\n",
      "ep 16: ep_len:785 episode reward: total was -28.780000. running mean: -39.861387\n",
      "ep 16: ep_len:1640 episode reward: total was -250.610000. running mean: -41.968873\n",
      "ep 16: ep_len:500 episode reward: total was 16.760000. running mean: -41.381584\n",
      "ep 16: ep_len:500 episode reward: total was -13.790000. running mean: -41.105668\n",
      "ep 16: ep_len:950 episode reward: total was -17.580000. running mean: -40.870412\n",
      "ep 16: ep_len:337 episode reward: total was 1.180000. running mean: -40.449908\n",
      "ep 16: ep_len:249 episode reward: total was 14.000000. running mean: -39.905409\n",
      "ep 16: ep_len:500 episode reward: total was -4.580000. running mean: -39.552155\n",
      "ep 16: ep_len:1000 episode reward: total was -172.780000. running mean: -40.884433\n",
      "ep 16: ep_len:500 episode reward: total was -41.860000. running mean: -40.894189\n",
      "ep 16: ep_len:1435 episode reward: total was -253.720000. running mean: -43.022447\n",
      "ep 16: ep_len:500 episode reward: total was 1.880000. running mean: -42.573422\n",
      "ep 16: ep_len:795 episode reward: total was -29.370000. running mean: -42.441388\n",
      "ep 16: ep_len:750 episode reward: total was -17.450000. running mean: -42.191474\n",
      "ep 16: ep_len:900 episode reward: total was -55.370000. running mean: -42.323259\n",
      "ep 16: ep_len:665 episode reward: total was -18.320000. running mean: -42.083227\n",
      "ep 16: ep_len:199 episode reward: total was 8.500000. running mean: -41.577395\n",
      "ep 16: ep_len:500 episode reward: total was 4.600000. running mean: -41.115621\n",
      "ep 16: ep_len:500 episode reward: total was 1.730000. running mean: -40.687164\n",
      "ep 16: ep_len:910 episode reward: total was -12.590000. running mean: -40.406193\n",
      "ep 16: ep_len:500 episode reward: total was 9.170000. running mean: -39.910431\n",
      "ep 16: ep_len:570 episode reward: total was -37.780000. running mean: -39.889127\n",
      "ep 16: ep_len:695 episode reward: total was -30.000000. running mean: -39.790235\n",
      "ep 16: ep_len:500 episode reward: total was -7.700000. running mean: -39.469333\n",
      "ep 16: ep_len:600 episode reward: total was -35.270000. running mean: -39.427340\n",
      "ep 16: ep_len:500 episode reward: total was -18.480000. running mean: -39.217866\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 16: ep_len:1315 episode reward: total was -46.310000. running mean: -39.288788\n",
      "ep 16: ep_len:865 episode reward: total was -15.850000. running mean: -39.054400\n",
      "ep 16: ep_len:740 episode reward: total was -50.990000. running mean: -39.173756\n",
      "ep 16: ep_len:500 episode reward: total was 0.650000. running mean: -38.775518\n",
      "ep 16: ep_len:860 episode reward: total was -70.490000. running mean: -39.092663\n",
      "ep 16: ep_len:138 episode reward: total was 11.000000. running mean: -38.591736\n",
      "ep 16: ep_len:500 episode reward: total was -2.070000. running mean: -38.226519\n",
      "ep 16: ep_len:725 episode reward: total was -50.600000. running mean: -38.350254\n",
      "ep 16: ep_len:172 episode reward: total was 9.500000. running mean: -37.871751\n",
      "ep 16: ep_len:805 episode reward: total was -26.220000. running mean: -37.755234\n",
      "ep 16: ep_len:500 episode reward: total was 4.270000. running mean: -37.334981\n",
      "ep 16: ep_len:500 episode reward: total was 36.500000. running mean: -36.596632\n",
      "ep 16: ep_len:815 episode reward: total was -20.280000. running mean: -36.433465\n",
      "ep 16: ep_len:780 episode reward: total was -19.670000. running mean: -36.265831\n",
      "ep 16: ep_len:173 episode reward: total was 10.000000. running mean: -35.803172\n",
      "ep 16: ep_len:500 episode reward: total was -28.490000. running mean: -35.730041\n",
      "ep 16: ep_len:820 episode reward: total was -8.980000. running mean: -35.462540\n",
      "ep 16: ep_len:800 episode reward: total was -27.250000. running mean: -35.380415\n",
      "ep 16: ep_len:620 episode reward: total was -34.160000. running mean: -35.368211\n",
      "ep 16: ep_len:500 episode reward: total was -18.710000. running mean: -35.201629\n",
      "ep 16: ep_len:138 episode reward: total was 9.000000. running mean: -34.759612\n",
      "ep 16: ep_len:500 episode reward: total was -13.830000. running mean: -34.550316\n",
      "ep 16: ep_len:505 episode reward: total was 5.210000. running mean: -34.152713\n",
      "ep 16: ep_len:245 episode reward: total was 9.500000. running mean: -33.716186\n",
      "ep 16: ep_len:600 episode reward: total was -82.450000. running mean: -34.203524\n",
      "ep 16: ep_len:725 episode reward: total was -21.830000. running mean: -34.079789\n",
      "ep 16: ep_len:1410 episode reward: total was -99.570000. running mean: -34.734691\n",
      "ep 16: ep_len:835 episode reward: total was -40.800000. running mean: -34.795344\n",
      "ep 16: ep_len:865 episode reward: total was -140.700000. running mean: -35.854390\n",
      "ep 16: ep_len:995 episode reward: total was -0.370000. running mean: -35.499547\n",
      "ep 16: ep_len:640 episode reward: total was -16.000000. running mean: -35.304551\n",
      "ep 16: ep_len:500 episode reward: total was -42.050000. running mean: -35.372006\n",
      "ep 16: ep_len:500 episode reward: total was 1.570000. running mean: -35.002586\n",
      "ep 16: ep_len:651 episode reward: total was -12.870000. running mean: -34.781260\n",
      "ep 16: ep_len:595 episode reward: total was 9.860000. running mean: -34.334847\n",
      "ep 16: ep_len:605 episode reward: total was -29.140000. running mean: -34.282899\n",
      "ep 16: ep_len:610 episode reward: total was 2.630000. running mean: -33.913770\n",
      "ep 16: ep_len:476 episode reward: total was -33.830000. running mean: -33.912932\n",
      "ep 16: ep_len:500 episode reward: total was 5.010000. running mean: -33.523703\n",
      "ep 16: ep_len:935 episode reward: total was -41.250000. running mean: -33.600966\n",
      "ep 16: ep_len:1305 episode reward: total was -175.200000. running mean: -35.016956\n",
      "ep 16: ep_len:1050 episode reward: total was -34.610000. running mean: -35.012886\n",
      "ep 16: ep_len:500 episode reward: total was 12.750000. running mean: -34.535258\n",
      "ep 16: ep_len:710 episode reward: total was -23.360000. running mean: -34.423505\n",
      "ep 16: ep_len:580 episode reward: total was 3.150000. running mean: -34.047770\n",
      "ep 16: ep_len:500 episode reward: total was -20.740000. running mean: -33.914692\n",
      "ep 16: ep_len:500 episode reward: total was -36.540000. running mean: -33.940945\n",
      "ep 16: ep_len:500 episode reward: total was -5.470000. running mean: -33.656236\n",
      "ep 16: ep_len:800 episode reward: total was -20.310000. running mean: -33.522773\n",
      "ep 16: ep_len:620 episode reward: total was -48.300000. running mean: -33.670546\n",
      "ep 16: ep_len:1090 episode reward: total was -65.040000. running mean: -33.984240\n",
      "ep 16: ep_len:264 episode reward: total was 15.500000. running mean: -33.489398\n",
      "ep 16: ep_len:910 episode reward: total was -23.660000. running mean: -33.391104\n",
      "ep 16: ep_len:500 episode reward: total was -0.050000. running mean: -33.057693\n",
      "ep 16: ep_len:945 episode reward: total was -3.350000. running mean: -32.760616\n",
      "ep 16: ep_len:740 episode reward: total was -13.470000. running mean: -32.567710\n",
      "ep 16: ep_len:555 episode reward: total was -29.240000. running mean: -32.534433\n",
      "ep 16: ep_len:500 episode reward: total was 6.730000. running mean: -32.141788\n",
      "ep 16: ep_len:645 episode reward: total was -33.100000. running mean: -32.151370\n",
      "ep 16: ep_len:980 episode reward: total was -74.450000. running mean: -32.574357\n",
      "ep 16: ep_len:500 episode reward: total was -16.640000. running mean: -32.415013\n",
      "ep 16: ep_len:605 episode reward: total was -3.210000. running mean: -32.122963\n",
      "ep 16: ep_len:515 episode reward: total was -33.530000. running mean: -32.137033\n",
      "ep 16: ep_len:433 episode reward: total was 32.500000. running mean: -31.490663\n",
      "ep 16: ep_len:985 episode reward: total was -21.550000. running mean: -31.391256\n",
      "ep 16: ep_len:500 episode reward: total was -7.260000. running mean: -31.149944\n",
      "ep 16: ep_len:492 episode reward: total was 12.120000. running mean: -30.717244\n",
      "ep 16: ep_len:570 episode reward: total was -13.410000. running mean: -30.544172\n",
      "ep 16: ep_len:835 episode reward: total was -94.880000. running mean: -31.187530\n",
      "ep 16: ep_len:865 episode reward: total was -21.820000. running mean: -31.093855\n",
      "ep 16: ep_len:500 episode reward: total was 6.260000. running mean: -30.720316\n",
      "ep 16: ep_len:575 episode reward: total was -15.060000. running mean: -30.563713\n",
      "ep 16: ep_len:590 episode reward: total was -18.060000. running mean: -30.438676\n",
      "ep 16: ep_len:1312 episode reward: total was -178.220000. running mean: -31.916489\n",
      "ep 16: ep_len:575 episode reward: total was -43.310000. running mean: -32.030424\n",
      "ep 16: ep_len:500 episode reward: total was 10.180000. running mean: -31.608320\n",
      "ep 16: ep_len:795 episode reward: total was -32.800000. running mean: -31.620237\n",
      "ep 16: ep_len:610 episode reward: total was -23.040000. running mean: -31.534435\n",
      "ep 16: ep_len:695 episode reward: total was -20.850000. running mean: -31.427590\n",
      "ep 16: ep_len:175 episode reward: total was 5.500000. running mean: -31.058314\n",
      "ep 16: ep_len:985 episode reward: total was -22.700000. running mean: -30.974731\n",
      "ep 16: ep_len:500 episode reward: total was -4.240000. running mean: -30.707384\n",
      "ep 16: ep_len:220 episode reward: total was 10.000000. running mean: -30.300310\n",
      "ep 16: ep_len:2155 episode reward: total was -368.420000. running mean: -33.681507\n",
      "ep 16: ep_len:500 episode reward: total was -2.220000. running mean: -33.366892\n",
      "ep 16: ep_len:500 episode reward: total was 1.830000. running mean: -33.014923\n",
      "ep 16: ep_len:520 episode reward: total was -35.550000. running mean: -33.040274\n",
      "ep 16: ep_len:730 episode reward: total was -36.750000. running mean: -33.077371\n",
      "ep 16: ep_len:500 episode reward: total was 23.500000. running mean: -32.511597\n",
      "ep 16: ep_len:500 episode reward: total was -13.800000. running mean: -32.324481\n",
      "ep 16: ep_len:1020 episode reward: total was -14.910000. running mean: -32.150337\n",
      "ep 16: ep_len:328 episode reward: total was 20.500000. running mean: -31.623833\n",
      "ep 16: ep_len:174 episode reward: total was 9.500000. running mean: -31.212595\n",
      "ep 16: ep_len:960 episode reward: total was -12.010000. running mean: -31.020569\n",
      "ep 16: ep_len:570 episode reward: total was -12.350000. running mean: -30.833863\n",
      "ep 16: ep_len:875 episode reward: total was -43.510000. running mean: -30.960625\n",
      "ep 16: ep_len:905 episode reward: total was 8.640000. running mean: -30.564618\n",
      "ep 16: ep_len:845 episode reward: total was -12.920000. running mean: -30.388172\n",
      "ep 16: ep_len:201 episode reward: total was 8.000000. running mean: -30.004290\n",
      "ep 16: ep_len:500 episode reward: total was 13.760000. running mean: -29.566648\n",
      "ep 16: ep_len:500 episode reward: total was 2.710000. running mean: -29.243881\n",
      "ep 16: ep_len:1545 episode reward: total was -246.920000. running mean: -31.420642\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 16: ep_len:790 episode reward: total was -28.770000. running mean: -31.394136\n",
      "ep 16: ep_len:695 episode reward: total was -76.430000. running mean: -31.844494\n",
      "ep 16: ep_len:219 episode reward: total was 14.000000. running mean: -31.386050\n",
      "ep 16: ep_len:500 episode reward: total was -32.410000. running mean: -31.396289\n",
      "ep 16: ep_len:655 episode reward: total was -17.900000. running mean: -31.261326\n",
      "ep 16: ep_len:500 episode reward: total was 5.710000. running mean: -30.891613\n",
      "ep 16: ep_len:4265 episode reward: total was -686.400000. running mean: -37.446697\n",
      "ep 16: ep_len:645 episode reward: total was -0.800000. running mean: -37.080230\n",
      "ep 16: ep_len:580 episode reward: total was -41.870000. running mean: -37.128127\n",
      "ep 16: ep_len:645 episode reward: total was -13.910000. running mean: -36.895946\n",
      "ep 16: ep_len:203 episode reward: total was 8.000000. running mean: -36.446987\n",
      "ep 16: ep_len:500 episode reward: total was -10.170000. running mean: -36.184217\n",
      "ep 16: ep_len:540 episode reward: total was -53.480000. running mean: -36.357175\n",
      "ep 16: ep_len:750 episode reward: total was -23.770000. running mean: -36.231303\n",
      "ep 16: ep_len:500 episode reward: total was -2.190000. running mean: -35.890890\n",
      "ep 16: ep_len:635 episode reward: total was -46.220000. running mean: -35.994181\n",
      "ep 16: ep_len:545 episode reward: total was -26.230000. running mean: -35.896539\n",
      "ep 16: ep_len:610 episode reward: total was -47.850000. running mean: -36.016074\n",
      "ep 16: ep_len:500 episode reward: total was 7.510000. running mean: -35.580813\n",
      "ep 16: ep_len:870 episode reward: total was -113.470000. running mean: -36.359705\n",
      "ep 16: ep_len:500 episode reward: total was -13.430000. running mean: -36.130408\n",
      "ep 16: ep_len:1463 episode reward: total was -257.190000. running mean: -38.341004\n",
      "ep 16: ep_len:900 episode reward: total was -125.050000. running mean: -39.208094\n",
      "ep 16: ep_len:575 episode reward: total was -17.080000. running mean: -38.986813\n",
      "ep 16: ep_len:930 episode reward: total was -23.120000. running mean: -38.828145\n",
      "ep 16: ep_len:500 episode reward: total was 2.660000. running mean: -38.413263\n",
      "ep 16: ep_len:1315 episode reward: total was -88.070000. running mean: -38.909831\n",
      "ep 16: ep_len:815 episode reward: total was -27.700000. running mean: -38.797732\n",
      "ep 16: ep_len:500 episode reward: total was -14.250000. running mean: -38.552255\n",
      "ep 16: ep_len:930 episode reward: total was -103.780000. running mean: -39.204532\n",
      "ep 16: ep_len:575 episode reward: total was 10.760000. running mean: -38.704887\n",
      "ep 16: ep_len:955 episode reward: total was -54.430000. running mean: -38.862138\n",
      "ep 16: ep_len:535 episode reward: total was -22.210000. running mean: -38.695617\n",
      "ep 16: ep_len:830 episode reward: total was -120.630000. running mean: -39.514961\n",
      "ep 16: ep_len:645 episode reward: total was -18.440000. running mean: -39.304211\n",
      "ep 16: ep_len:505 episode reward: total was -9.010000. running mean: -39.001269\n",
      "ep 16: ep_len:500 episode reward: total was -30.970000. running mean: -38.920956\n",
      "ep 16: ep_len:500 episode reward: total was -28.490000. running mean: -38.816647\n",
      "ep 16: ep_len:500 episode reward: total was 12.290000. running mean: -38.305580\n",
      "ep 16: ep_len:500 episode reward: total was -12.440000. running mean: -38.046924\n",
      "ep 16: ep_len:500 episode reward: total was -15.620000. running mean: -37.822655\n",
      "ep 16: ep_len:535 episode reward: total was 1.150000. running mean: -37.432929\n",
      "ep 16: ep_len:790 episode reward: total was -61.710000. running mean: -37.675699\n",
      "ep 16: ep_len:660 episode reward: total was -52.230000. running mean: -37.821242\n",
      "ep 16: ep_len:790 episode reward: total was -53.990000. running mean: -37.982930\n",
      "ep 16: ep_len:715 episode reward: total was -16.270000. running mean: -37.765801\n",
      "ep 16: ep_len:220 episode reward: total was 16.000000. running mean: -37.228143\n",
      "ep 16: ep_len:910 episode reward: total was -5.770000. running mean: -36.913561\n",
      "ep 16: ep_len:575 episode reward: total was -69.080000. running mean: -37.235226\n",
      "ep 16: ep_len:171 episode reward: total was 12.500000. running mean: -36.737873\n",
      "ep 16: ep_len:2395 episode reward: total was -280.630000. running mean: -39.176795\n",
      "ep 16: ep_len:500 episode reward: total was 9.170000. running mean: -38.693327\n",
      "ep 16: ep_len:445 episode reward: total was -20.730000. running mean: -38.513693\n",
      "ep 16: ep_len:760 episode reward: total was -34.890000. running mean: -38.477456\n",
      "ep 16: ep_len:685 episode reward: total was -62.800000. running mean: -38.720682\n",
      "ep 16: ep_len:505 episode reward: total was -16.240000. running mean: -38.495875\n",
      "ep 16: ep_len:500 episode reward: total was -11.850000. running mean: -38.229416\n",
      "ep 16: ep_len:780 episode reward: total was -39.900000. running mean: -38.246122\n",
      "ep 16: ep_len:780 episode reward: total was -62.090000. running mean: -38.484561\n",
      "ep 16: ep_len:670 episode reward: total was -36.080000. running mean: -38.460515\n",
      "ep 16: ep_len:565 episode reward: total was -12.050000. running mean: -38.196410\n",
      "ep 16: ep_len:500 episode reward: total was 5.920000. running mean: -37.755246\n",
      "ep 16: ep_len:418 episode reward: total was 22.000000. running mean: -37.157694\n",
      "ep 16: ep_len:189 episode reward: total was 9.500000. running mean: -36.691117\n",
      "ep 16: ep_len:580 episode reward: total was -32.220000. running mean: -36.646406\n",
      "ep 16: ep_len:835 episode reward: total was -13.860000. running mean: -36.418541\n",
      "ep 16: ep_len:500 episode reward: total was -17.350000. running mean: -36.227856\n",
      "ep 16: ep_len:885 episode reward: total was -31.020000. running mean: -36.175778\n",
      "ep 16: ep_len:1200 episode reward: total was -210.240000. running mean: -37.916420\n",
      "ep 16: ep_len:860 episode reward: total was -56.520000. running mean: -38.102456\n",
      "ep 16: ep_len:500 episode reward: total was -20.900000. running mean: -37.930431\n",
      "ep 16: ep_len:500 episode reward: total was -14.200000. running mean: -37.693127\n",
      "ep 16: ep_len:500 episode reward: total was -9.210000. running mean: -37.408295\n",
      "ep 16: ep_len:525 episode reward: total was 2.260000. running mean: -37.011612\n",
      "ep 16: ep_len:438 episode reward: total was -8.340000. running mean: -36.724896\n",
      "ep 16: ep_len:592 episode reward: total was -93.320000. running mean: -37.290847\n",
      "ep 16: ep_len:230 episode reward: total was 8.000000. running mean: -36.837939\n",
      "ep 16: ep_len:500 episode reward: total was -30.880000. running mean: -36.778360\n",
      "ep 16: ep_len:500 episode reward: total was 19.790000. running mean: -36.212676\n",
      "ep 16: ep_len:793 episode reward: total was -144.400000. running mean: -37.294549\n",
      "ep 16: ep_len:500 episode reward: total was -13.690000. running mean: -37.058504\n",
      "ep 16: ep_len:2605 episode reward: total was -349.460000. running mean: -40.182519\n",
      "ep 16: ep_len:505 episode reward: total was -52.570000. running mean: -40.306393\n",
      "ep 16: ep_len:500 episode reward: total was 14.520000. running mean: -39.758129\n",
      "ep 16: ep_len:855 episode reward: total was -96.260000. running mean: -40.323148\n",
      "ep 16: ep_len:500 episode reward: total was -27.850000. running mean: -40.198417\n",
      "ep 16: ep_len:500 episode reward: total was -7.520000. running mean: -39.871633\n",
      "ep 16: ep_len:665 episode reward: total was -38.110000. running mean: -39.854016\n",
      "ep 16: ep_len:500 episode reward: total was 35.000000. running mean: -39.105476\n",
      "ep 16: ep_len:900 episode reward: total was -10.360000. running mean: -38.818021\n",
      "epsilon:0.138602 episode_count: 13405. steps_count: 9475191.000000\n",
      "ep 17: ep_len:500 episode reward: total was -29.940000. running mean: -38.729241\n",
      "ep 17: ep_len:820 episode reward: total was -64.030000. running mean: -38.982249\n",
      "ep 17: ep_len:500 episode reward: total was -12.880000. running mean: -38.721226\n",
      "ep 17: ep_len:575 episode reward: total was -46.370000. running mean: -38.797714\n",
      "ep 17: ep_len:500 episode reward: total was 18.780000. running mean: -38.221937\n",
      "ep 17: ep_len:500 episode reward: total was -17.100000. running mean: -38.010717\n",
      "ep 17: ep_len:805 episode reward: total was -22.250000. running mean: -37.853110\n",
      "ep 17: ep_len:690 episode reward: total was -4.860000. running mean: -37.523179\n",
      "ep 17: ep_len:965 episode reward: total was -26.210000. running mean: -37.410047\n",
      "ep 17: ep_len:975 episode reward: total was -18.520000. running mean: -37.221147\n",
      "ep 17: ep_len:580 episode reward: total was -30.200000. running mean: -37.150935\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 17: ep_len:930 episode reward: total was -33.730000. running mean: -37.116726\n",
      "ep 17: ep_len:500 episode reward: total was 11.800000. running mean: -36.627559\n",
      "ep 17: ep_len:935 episode reward: total was -57.770000. running mean: -36.838983\n",
      "ep 17: ep_len:820 episode reward: total was -36.790000. running mean: -36.838493\n",
      "ep 17: ep_len:500 episode reward: total was 12.260000. running mean: -36.347508\n",
      "ep 17: ep_len:500 episode reward: total was -12.080000. running mean: -36.104833\n",
      "ep 17: ep_len:500 episode reward: total was -10.520000. running mean: -35.848985\n",
      "ep 17: ep_len:243 episode reward: total was 18.500000. running mean: -35.305495\n",
      "ep 17: ep_len:585 episode reward: total was -29.180000. running mean: -35.244240\n",
      "ep 17: ep_len:500 episode reward: total was -4.630000. running mean: -34.938098\n",
      "ep 17: ep_len:1480 episode reward: total was -81.930000. running mean: -35.408017\n",
      "ep 17: ep_len:233 episode reward: total was 11.000000. running mean: -34.943937\n",
      "ep 17: ep_len:925 episode reward: total was -52.740000. running mean: -35.121897\n",
      "ep 17: ep_len:1365 episode reward: total was -218.480000. running mean: -36.955478\n",
      "ep 17: ep_len:462 episode reward: total was 6.770000. running mean: -36.518224\n",
      "ep 17: ep_len:168 episode reward: total was 6.500000. running mean: -36.088041\n",
      "ep 17: ep_len:720 episode reward: total was -30.400000. running mean: -36.031161\n",
      "ep 17: ep_len:560 episode reward: total was -25.190000. running mean: -35.922749\n",
      "ep 17: ep_len:14670 episode reward: total was -2725.640000. running mean: -62.819922\n",
      "ep 17: ep_len:700 episode reward: total was -21.880000. running mean: -62.410523\n",
      "ep 17: ep_len:505 episode reward: total was 9.730000. running mean: -61.689117\n",
      "ep 17: ep_len:805 episode reward: total was -57.960000. running mean: -61.651826\n",
      "ep 17: ep_len:520 episode reward: total was -20.710000. running mean: -61.242408\n",
      "ep 17: ep_len:665 episode reward: total was -19.930000. running mean: -60.829284\n",
      "ep 17: ep_len:710 episode reward: total was -14.680000. running mean: -60.367791\n",
      "ep 17: ep_len:565 episode reward: total was -17.590000. running mean: -59.940013\n",
      "ep 17: ep_len:500 episode reward: total was -8.890000. running mean: -59.429513\n",
      "ep 17: ep_len:595 episode reward: total was -36.230000. running mean: -59.197518\n",
      "ep 17: ep_len:500 episode reward: total was 17.710000. running mean: -58.428443\n",
      "ep 17: ep_len:770 episode reward: total was -55.050000. running mean: -58.394658\n",
      "ep 17: ep_len:530 episode reward: total was -8.330000. running mean: -57.894012\n",
      "ep 17: ep_len:215 episode reward: total was 15.500000. running mean: -57.160072\n",
      "ep 17: ep_len:530 episode reward: total was -43.580000. running mean: -57.024271\n",
      "ep 17: ep_len:990 episode reward: total was -27.700000. running mean: -56.731028\n",
      "ep 17: ep_len:570 episode reward: total was -54.950000. running mean: -56.713218\n",
      "ep 17: ep_len:650 episode reward: total was -22.960000. running mean: -56.375686\n",
      "ep 17: ep_len:19285 episode reward: total was -3733.310000. running mean: -93.145029\n",
      "ep 17: ep_len:865 episode reward: total was -36.880000. running mean: -92.582379\n",
      "ep 17: ep_len:860 episode reward: total was -57.920000. running mean: -92.235755\n",
      "ep 17: ep_len:201 episode reward: total was 3.500000. running mean: -91.278397\n",
      "ep 17: ep_len:920 episode reward: total was -8.900000. running mean: -90.454613\n",
      "ep 17: ep_len:168 episode reward: total was 4.500000. running mean: -89.505067\n",
      "ep 17: ep_len:774 episode reward: total was -147.450000. running mean: -90.084516\n",
      "ep 17: ep_len:765 episode reward: total was -27.550000. running mean: -89.459171\n",
      "ep 17: ep_len:505 episode reward: total was -2.290000. running mean: -88.587480\n",
      "ep 17: ep_len:875 episode reward: total was -7.040000. running mean: -87.772005\n",
      "ep 17: ep_len:505 episode reward: total was -26.580000. running mean: -87.160085\n",
      "ep 17: ep_len:900 episode reward: total was -28.600000. running mean: -86.574484\n",
      "ep 17: ep_len:500 episode reward: total was -15.660000. running mean: -85.865339\n",
      "ep 17: ep_len:820 episode reward: total was -69.110000. running mean: -85.697786\n",
      "ep 17: ep_len:515 episode reward: total was -11.420000. running mean: -84.955008\n",
      "ep 17: ep_len:535 episode reward: total was -29.280000. running mean: -84.398258\n",
      "ep 17: ep_len:204 episode reward: total was 11.000000. running mean: -83.444275\n",
      "ep 17: ep_len:840 episode reward: total was -39.350000. running mean: -83.003332\n",
      "ep 17: ep_len:500 episode reward: total was 13.730000. running mean: -82.035999\n",
      "ep 17: ep_len:1160 episode reward: total was -152.860000. running mean: -82.744239\n",
      "ep 17: ep_len:830 episode reward: total was -27.780000. running mean: -82.194597\n",
      "ep 17: ep_len:505 episode reward: total was -72.770000. running mean: -82.100351\n",
      "ep 17: ep_len:555 episode reward: total was -21.160000. running mean: -81.490947\n",
      "ep 17: ep_len:394 episode reward: total was 21.000000. running mean: -80.466038\n",
      "ep 17: ep_len:895 episode reward: total was -49.840000. running mean: -80.159777\n",
      "ep 17: ep_len:700 episode reward: total was -24.450000. running mean: -79.602680\n",
      "ep 17: ep_len:1065 episode reward: total was -148.900000. running mean: -80.295653\n",
      "ep 17: ep_len:1486 episode reward: total was -146.340000. running mean: -80.956096\n",
      "ep 17: ep_len:510 episode reward: total was 0.220000. running mean: -80.144335\n",
      "ep 17: ep_len:500 episode reward: total was -41.620000. running mean: -79.759092\n",
      "ep 17: ep_len:650 episode reward: total was -21.320000. running mean: -79.174701\n",
      "ep 17: ep_len:590 episode reward: total was -28.000000. running mean: -78.662954\n",
      "ep 17: ep_len:650 episode reward: total was -12.890000. running mean: -78.005224\n",
      "ep 17: ep_len:500 episode reward: total was -12.380000. running mean: -77.348972\n",
      "ep 17: ep_len:665 episode reward: total was -20.910000. running mean: -76.784582\n",
      "ep 17: ep_len:89 episode reward: total was 5.500000. running mean: -75.961737\n",
      "ep 17: ep_len:665 episode reward: total was -43.180000. running mean: -75.633919\n",
      "ep 17: ep_len:225 episode reward: total was 15.000000. running mean: -74.727580\n",
      "ep 17: ep_len:855 episode reward: total was -98.990000. running mean: -74.970204\n",
      "ep 17: ep_len:570 episode reward: total was -24.160000. running mean: -74.462102\n",
      "ep 17: ep_len:500 episode reward: total was -15.510000. running mean: -73.872581\n",
      "ep 17: ep_len:595 episode reward: total was -24.600000. running mean: -73.379855\n",
      "ep 17: ep_len:500 episode reward: total was -20.380000. running mean: -72.849857\n",
      "ep 17: ep_len:500 episode reward: total was -16.000000. running mean: -72.281358\n",
      "ep 17: ep_len:500 episode reward: total was -30.690000. running mean: -71.865445\n",
      "ep 17: ep_len:565 episode reward: total was -58.510000. running mean: -71.731890\n",
      "ep 17: ep_len:565 episode reward: total was -52.450000. running mean: -71.539071\n",
      "ep 17: ep_len:500 episode reward: total was -45.290000. running mean: -71.276581\n",
      "ep 17: ep_len:925 episode reward: total was -73.590000. running mean: -71.299715\n",
      "ep 17: ep_len:505 episode reward: total was -1.770000. running mean: -70.604418\n",
      "ep 17: ep_len:730 episode reward: total was -4.820000. running mean: -69.946574\n",
      "ep 17: ep_len:500 episode reward: total was -21.970000. running mean: -69.466808\n",
      "ep 17: ep_len:815 episode reward: total was -35.010000. running mean: -69.122240\n",
      "ep 17: ep_len:500 episode reward: total was -0.270000. running mean: -68.433717\n",
      "ep 17: ep_len:163 episode reward: total was 10.500000. running mean: -67.644380\n",
      "ep 17: ep_len:630 episode reward: total was -72.520000. running mean: -67.693136\n",
      "ep 17: ep_len:500 episode reward: total was 7.240000. running mean: -66.943805\n",
      "ep 17: ep_len:500 episode reward: total was -44.470000. running mean: -66.719067\n",
      "ep 17: ep_len:789 episode reward: total was -61.080000. running mean: -66.662676\n",
      "ep 17: ep_len:605 episode reward: total was -24.090000. running mean: -66.236949\n",
      "ep 17: ep_len:780 episode reward: total was -16.220000. running mean: -65.736780\n",
      "ep 17: ep_len:206 episode reward: total was 10.000000. running mean: -64.979412\n",
      "ep 17: ep_len:500 episode reward: total was -4.640000. running mean: -64.376018\n",
      "ep 17: ep_len:710 episode reward: total was -25.520000. running mean: -63.987458\n",
      "ep 17: ep_len:500 episode reward: total was 27.500000. running mean: -63.072583\n",
      "ep 17: ep_len:500 episode reward: total was -14.840000. running mean: -62.590257\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 17: ep_len:500 episode reward: total was -12.790000. running mean: -62.092255\n",
      "ep 17: ep_len:195 episode reward: total was 3.000000. running mean: -61.441332\n",
      "ep 17: ep_len:1110 episode reward: total was -38.310000. running mean: -61.210019\n",
      "ep 17: ep_len:500 episode reward: total was -32.700000. running mean: -60.924919\n",
      "ep 17: ep_len:840 episode reward: total was -31.150000. running mean: -60.627170\n",
      "ep 17: ep_len:830 episode reward: total was -49.900000. running mean: -60.519898\n",
      "ep 17: ep_len:935 episode reward: total was -145.200000. running mean: -61.366699\n",
      "ep 17: ep_len:500 episode reward: total was -15.210000. running mean: -60.905132\n",
      "ep 17: ep_len:9320 episode reward: total was -478.250000. running mean: -65.078581\n",
      "ep 17: ep_len:700 episode reward: total was -20.480000. running mean: -64.632595\n",
      "ep 17: ep_len:810 episode reward: total was -21.320000. running mean: -64.199469\n",
      "ep 17: ep_len:505 episode reward: total was 20.500000. running mean: -63.352474\n",
      "ep 17: ep_len:705 episode reward: total was -29.950000. running mean: -63.018449\n",
      "ep 17: ep_len:790 episode reward: total was -25.740000. running mean: -62.645665\n",
      "ep 17: ep_len:98 episode reward: total was 6.500000. running mean: -61.954208\n",
      "ep 17: ep_len:545 episode reward: total was -25.220000. running mean: -61.586866\n",
      "ep 17: ep_len:875 episode reward: total was -42.740000. running mean: -61.398398\n",
      "ep 17: ep_len:500 episode reward: total was -5.070000. running mean: -60.835114\n",
      "ep 17: ep_len:745 episode reward: total was -47.940000. running mean: -60.706162\n",
      "ep 17: ep_len:505 episode reward: total was -37.420000. running mean: -60.473301\n",
      "ep 17: ep_len:505 episode reward: total was 6.730000. running mean: -59.801268\n",
      "ep 17: ep_len:500 episode reward: total was -13.030000. running mean: -59.333555\n",
      "ep 17: ep_len:500 episode reward: total was -5.910000. running mean: -58.799320\n",
      "ep 17: ep_len:505 episode reward: total was -21.990000. running mean: -58.431226\n",
      "ep 17: ep_len:500 episode reward: total was 3.720000. running mean: -57.809714\n",
      "ep 17: ep_len:2305 episode reward: total was -312.580000. running mean: -60.357417\n",
      "ep 17: ep_len:398 episode reward: total was 23.000000. running mean: -59.523843\n",
      "ep 17: ep_len:545 episode reward: total was -36.870000. running mean: -59.297304\n",
      "ep 17: ep_len:1570 episode reward: total was -82.800000. running mean: -59.532331\n",
      "ep 17: ep_len:525 episode reward: total was -18.680000. running mean: -59.123808\n",
      "ep 17: ep_len:500 episode reward: total was -13.770000. running mean: -58.670270\n",
      "ep 17: ep_len:197 episode reward: total was 10.500000. running mean: -57.978567\n",
      "ep 17: ep_len:590 episode reward: total was -27.150000. running mean: -57.670282\n",
      "ep 17: ep_len:232 episode reward: total was 17.000000. running mean: -56.923579\n",
      "ep 17: ep_len:500 episode reward: total was 0.040000. running mean: -56.353943\n",
      "ep 17: ep_len:715 episode reward: total was -25.890000. running mean: -56.049304\n",
      "ep 17: ep_len:500 episode reward: total was 7.270000. running mean: -55.416111\n",
      "ep 17: ep_len:132 episode reward: total was 10.000000. running mean: -54.761949\n",
      "ep 17: ep_len:685 episode reward: total was -2.220000. running mean: -54.236530\n",
      "ep 17: ep_len:555 episode reward: total was -30.250000. running mean: -53.996665\n",
      "ep 17: ep_len:500 episode reward: total was -45.510000. running mean: -53.911798\n",
      "ep 17: ep_len:500 episode reward: total was -0.330000. running mean: -53.375980\n",
      "ep 17: ep_len:505 episode reward: total was 7.890000. running mean: -52.763320\n",
      "ep 17: ep_len:500 episode reward: total was -58.350000. running mean: -52.819187\n",
      "ep 17: ep_len:500 episode reward: total was 0.440000. running mean: -52.286595\n",
      "ep 17: ep_len:860 episode reward: total was -4.490000. running mean: -51.808629\n",
      "ep 17: ep_len:725 episode reward: total was -32.420000. running mean: -51.614743\n",
      "ep 17: ep_len:640 episode reward: total was -18.450000. running mean: -51.283095\n",
      "ep 17: ep_len:500 episode reward: total was -13.800000. running mean: -50.908265\n",
      "ep 17: ep_len:690 episode reward: total was -10.430000. running mean: -50.503482\n",
      "ep 17: ep_len:500 episode reward: total was -9.970000. running mean: -50.098147\n",
      "ep 17: ep_len:580 episode reward: total was -23.750000. running mean: -49.834666\n",
      "ep 17: ep_len:790 episode reward: total was -22.520000. running mean: -49.561519\n",
      "ep 17: ep_len:530 episode reward: total was -45.940000. running mean: -49.525304\n",
      "ep 17: ep_len:500 episode reward: total was 16.730000. running mean: -48.862751\n",
      "ep 17: ep_len:500 episode reward: total was -38.210000. running mean: -48.756223\n",
      "ep 17: ep_len:645 episode reward: total was -24.010000. running mean: -48.508761\n",
      "ep 17: ep_len:1170 episode reward: total was -78.680000. running mean: -48.810473\n",
      "ep 17: ep_len:505 episode reward: total was 6.700000. running mean: -48.255369\n",
      "ep 17: ep_len:500 episode reward: total was -6.960000. running mean: -47.842415\n",
      "ep 17: ep_len:655 episode reward: total was -43.180000. running mean: -47.795791\n",
      "ep 17: ep_len:720 episode reward: total was -21.840000. running mean: -47.536233\n",
      "ep 17: ep_len:1040 episode reward: total was -32.210000. running mean: -47.382971\n",
      "ep 17: ep_len:900 episode reward: total was -2.970000. running mean: -46.938841\n",
      "ep 17: ep_len:182 episode reward: total was 9.000000. running mean: -46.379452\n",
      "ep 17: ep_len:500 episode reward: total was -16.450000. running mean: -46.080158\n",
      "ep 17: ep_len:870 episode reward: total was 6.040000. running mean: -45.558956\n",
      "ep 17: ep_len:505 episode reward: total was 37.500000. running mean: -44.728367\n",
      "ep 17: ep_len:500 episode reward: total was -35.440000. running mean: -44.635483\n",
      "ep 17: ep_len:1871 episode reward: total was -274.040000. running mean: -46.929528\n",
      "ep 17: ep_len:500 episode reward: total was -15.720000. running mean: -46.617433\n",
      "ep 17: ep_len:500 episode reward: total was -31.720000. running mean: -46.468459\n",
      "ep 17: ep_len:1372 episode reward: total was -156.800000. running mean: -47.571774\n",
      "ep 17: ep_len:765 episode reward: total was 18.150000. running mean: -46.914556\n",
      "ep 17: ep_len:500 episode reward: total was 30.500000. running mean: -46.140411\n",
      "ep 17: ep_len:500 episode reward: total was 0.180000. running mean: -45.677207\n",
      "ep 17: ep_len:685 episode reward: total was -17.280000. running mean: -45.393235\n",
      "ep 17: ep_len:550 episode reward: total was -1.700000. running mean: -44.956302\n",
      "ep 17: ep_len:500 episode reward: total was -25.730000. running mean: -44.764039\n",
      "ep 17: ep_len:695 episode reward: total was -35.020000. running mean: -44.666599\n",
      "ep 17: ep_len:152 episode reward: total was 12.500000. running mean: -44.094933\n",
      "ep 17: ep_len:825 episode reward: total was -42.840000. running mean: -44.082384\n",
      "ep 17: ep_len:223 episode reward: total was 12.000000. running mean: -43.521560\n",
      "ep 17: ep_len:925 episode reward: total was -35.590000. running mean: -43.442244\n",
      "ep 17: ep_len:500 episode reward: total was -20.030000. running mean: -43.208122\n",
      "ep 17: ep_len:1540 episode reward: total was -230.280000. running mean: -45.078840\n",
      "ep 17: ep_len:505 episode reward: total was 6.210000. running mean: -44.565952\n",
      "ep 17: ep_len:500 episode reward: total was 5.720000. running mean: -44.063092\n",
      "ep 17: ep_len:960 episode reward: total was -10.300000. running mean: -43.725462\n",
      "ep 17: ep_len:775 episode reward: total was -36.880000. running mean: -43.657007\n",
      "ep 17: ep_len:875 episode reward: total was -58.050000. running mean: -43.800937\n",
      "ep 17: ep_len:338 episode reward: total was 21.500000. running mean: -43.147928\n",
      "ep 17: ep_len:610 episode reward: total was -64.480000. running mean: -43.361248\n",
      "ep 17: ep_len:655 episode reward: total was -15.570000. running mean: -43.083336\n",
      "ep 17: ep_len:745 episode reward: total was -13.210000. running mean: -42.784602\n",
      "ep 17: ep_len:550 episode reward: total was -13.090000. running mean: -42.487656\n",
      "ep 17: ep_len:950 episode reward: total was -56.660000. running mean: -42.629380\n",
      "ep 17: ep_len:500 episode reward: total was -27.820000. running mean: -42.481286\n",
      "ep 17: ep_len:500 episode reward: total was 16.730000. running mean: -41.889173\n",
      "ep 17: ep_len:940 episode reward: total was -32.410000. running mean: -41.794381\n",
      "ep 17: ep_len:720 episode reward: total was -31.940000. running mean: -41.695838\n",
      "ep 17: ep_len:805 episode reward: total was -32.030000. running mean: -41.599179\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 17: ep_len:500 episode reward: total was -10.890000. running mean: -41.292087\n",
      "ep 17: ep_len:885 episode reward: total was -12.490000. running mean: -41.004067\n",
      "ep 17: ep_len:705 episode reward: total was -16.820000. running mean: -40.762226\n",
      "ep 17: ep_len:500 episode reward: total was -4.800000. running mean: -40.402604\n",
      "ep 17: ep_len:900 episode reward: total was -1.870000. running mean: -40.017278\n",
      "ep 17: ep_len:500 episode reward: total was -35.590000. running mean: -39.973005\n",
      "ep 17: ep_len:540 episode reward: total was -18.160000. running mean: -39.754875\n",
      "ep 17: ep_len:182 episode reward: total was 15.000000. running mean: -39.207326\n",
      "ep 17: ep_len:500 episode reward: total was -2.400000. running mean: -38.839253\n",
      "ep 17: ep_len:720 episode reward: total was -21.840000. running mean: -38.669260\n",
      "ep 17: ep_len:500 episode reward: total was 2.870000. running mean: -38.253868\n",
      "ep 17: ep_len:680 episode reward: total was -33.030000. running mean: -38.201629\n",
      "ep 17: ep_len:725 episode reward: total was -27.550000. running mean: -38.095113\n",
      "ep 17: ep_len:500 episode reward: total was 5.130000. running mean: -37.662862\n",
      "ep 17: ep_len:500 episode reward: total was -9.300000. running mean: -37.379233\n",
      "ep 17: ep_len:585 episode reward: total was -6.370000. running mean: -37.069141\n",
      "ep 17: ep_len:500 episode reward: total was -10.280000. running mean: -36.801249\n",
      "ep 17: ep_len:500 episode reward: total was -3.270000. running mean: -36.465937\n",
      "ep 17: ep_len:680 episode reward: total was -26.450000. running mean: -36.365777\n",
      "ep 17: ep_len:500 episode reward: total was 8.750000. running mean: -35.914620\n",
      "ep 17: ep_len:500 episode reward: total was -6.420000. running mean: -35.619673\n",
      "ep 17: ep_len:500 episode reward: total was 15.750000. running mean: -35.105977\n",
      "ep 17: ep_len:625 episode reward: total was -47.280000. running mean: -35.227717\n",
      "ep 17: ep_len:505 episode reward: total was 1.580000. running mean: -34.859640\n",
      "ep 17: ep_len:775 episode reward: total was -20.200000. running mean: -34.713043\n",
      "ep 17: ep_len:1250 episode reward: total was -102.590000. running mean: -35.391813\n",
      "ep 17: ep_len:505 episode reward: total was 12.190000. running mean: -34.915995\n",
      "ep 17: ep_len:750 episode reward: total was -19.240000. running mean: -34.759235\n",
      "ep 17: ep_len:740 episode reward: total was -22.810000. running mean: -34.639742\n",
      "ep 17: ep_len:500 episode reward: total was 5.950000. running mean: -34.233845\n",
      "ep 17: ep_len:500 episode reward: total was -16.220000. running mean: -34.053707\n",
      "ep 17: ep_len:820 episode reward: total was -51.530000. running mean: -34.228470\n",
      "ep 17: ep_len:500 episode reward: total was 12.380000. running mean: -33.762385\n",
      "ep 17: ep_len:115 episode reward: total was 7.000000. running mean: -33.354761\n",
      "ep 17: ep_len:256 episode reward: total was 15.000000. running mean: -32.871213\n",
      "ep 17: ep_len:905 episode reward: total was -40.900000. running mean: -32.951501\n",
      "ep 17: ep_len:500 episode reward: total was 5.930000. running mean: -32.562686\n",
      "ep 17: ep_len:690 episode reward: total was -15.840000. running mean: -32.395459\n",
      "ep 17: ep_len:387 episode reward: total was -2.390000. running mean: -32.095405\n",
      "ep 17: ep_len:640 episode reward: total was -18.260000. running mean: -31.957051\n",
      "ep 17: ep_len:68 episode reward: total was 5.000000. running mean: -31.587480\n",
      "ep 17: ep_len:500 episode reward: total was -11.280000. running mean: -31.384405\n",
      "ep 17: ep_len:500 episode reward: total was -3.390000. running mean: -31.104461\n",
      "ep 17: ep_len:500 episode reward: total was 9.260000. running mean: -30.700817\n",
      "ep 17: ep_len:1200 episode reward: total was -51.260000. running mean: -30.906409\n",
      "ep 17: ep_len:685 episode reward: total was -26.960000. running mean: -30.866944\n",
      "ep 17: ep_len:232 episode reward: total was 17.000000. running mean: -30.388275\n",
      "ep 17: ep_len:760 episode reward: total was -41.360000. running mean: -30.497992\n",
      "ep 17: ep_len:505 episode reward: total was -26.060000. running mean: -30.453612\n",
      "ep 17: ep_len:216 episode reward: total was 18.500000. running mean: -29.964076\n",
      "ep 17: ep_len:520 episode reward: total was -15.170000. running mean: -29.816135\n",
      "ep 17: ep_len:515 episode reward: total was -14.170000. running mean: -29.659674\n",
      "ep 17: ep_len:615 episode reward: total was -19.030000. running mean: -29.553377\n",
      "ep 17: ep_len:510 episode reward: total was -17.210000. running mean: -29.429944\n",
      "ep 17: ep_len:500 episode reward: total was -8.860000. running mean: -29.224244\n",
      "ep 17: ep_len:204 episode reward: total was 15.500000. running mean: -28.777002\n",
      "ep 17: ep_len:605 episode reward: total was -16.010000. running mean: -28.649332\n",
      "ep 17: ep_len:660 episode reward: total was -17.920000. running mean: -28.542038\n",
      "ep 17: ep_len:500 episode reward: total was -9.290000. running mean: -28.349518\n",
      "ep 17: ep_len:233 episode reward: total was 21.500000. running mean: -27.851023\n",
      "ep 17: ep_len:505 episode reward: total was -19.250000. running mean: -27.765013\n",
      "ep 17: ep_len:665 episode reward: total was -14.880000. running mean: -27.636162\n",
      "ep 17: ep_len:500 episode reward: total was 39.500000. running mean: -26.964801\n",
      "ep 17: ep_len:785 episode reward: total was 11.150000. running mean: -26.583653\n",
      "ep 17: ep_len:167 episode reward: total was 9.000000. running mean: -26.227816\n",
      "ep 17: ep_len:500 episode reward: total was 2.230000. running mean: -25.943238\n",
      "ep 17: ep_len:740 episode reward: total was -43.500000. running mean: -26.118806\n",
      "ep 17: ep_len:500 episode reward: total was 1.710000. running mean: -25.840518\n",
      "ep 17: ep_len:745 episode reward: total was -26.840000. running mean: -25.850513\n",
      "ep 17: ep_len:540 episode reward: total was -32.220000. running mean: -25.914207\n",
      "ep 17: ep_len:1185 episode reward: total was -148.170000. running mean: -27.136765\n",
      "ep 17: ep_len:880 episode reward: total was -4.400000. running mean: -26.909398\n",
      "ep 17: ep_len:685 episode reward: total was 7.640000. running mean: -26.563904\n",
      "ep 17: ep_len:740 episode reward: total was -4.590000. running mean: -26.344165\n",
      "ep 17: ep_len:325 episode reward: total was -36.990000. running mean: -26.450623\n",
      "ep 17: ep_len:165 episode reward: total was 6.000000. running mean: -26.126117\n",
      "ep 17: ep_len:139 episode reward: total was 6.000000. running mean: -25.804856\n",
      "ep 17: ep_len:615 episode reward: total was -32.150000. running mean: -25.868307\n",
      "ep 17: ep_len:1050 episode reward: total was -84.320000. running mean: -26.452824\n",
      "ep 17: ep_len:820 episode reward: total was -70.310000. running mean: -26.891396\n",
      "ep 17: ep_len:545 episode reward: total was 2.940000. running mean: -26.593082\n",
      "ep 17: ep_len:1030 episode reward: total was -30.010000. running mean: -26.627251\n",
      "ep 17: ep_len:845 episode reward: total was -76.130000. running mean: -27.122278\n",
      "ep 17: ep_len:1500 episode reward: total was -87.950000. running mean: -27.730556\n",
      "ep 17: ep_len:685 episode reward: total was -21.390000. running mean: -27.667150\n",
      "ep 17: ep_len:1390 episode reward: total was -221.510000. running mean: -29.605579\n",
      "ep 17: ep_len:500 episode reward: total was 13.330000. running mean: -29.176223\n",
      "ep 17: ep_len:590 episode reward: total was -21.090000. running mean: -29.095361\n",
      "ep 17: ep_len:366 episode reward: total was 18.500000. running mean: -28.619407\n",
      "ep 17: ep_len:1215 episode reward: total was -37.210000. running mean: -28.705313\n",
      "ep 17: ep_len:985 episode reward: total was -52.870000. running mean: -28.946960\n",
      "ep 17: ep_len:500 episode reward: total was -26.960000. running mean: -28.927090\n",
      "ep 17: ep_len:555 episode reward: total was -10.500000. running mean: -28.742819\n",
      "ep 17: ep_len:147 episode reward: total was 11.500000. running mean: -28.340391\n",
      "ep 17: ep_len:256 episode reward: total was 21.000000. running mean: -27.846987\n",
      "ep 17: ep_len:1080 episode reward: total was -11.120000. running mean: -27.679717\n",
      "ep 17: ep_len:880 episode reward: total was -62.160000. running mean: -28.024520\n",
      "ep 17: ep_len:625 episode reward: total was -17.920000. running mean: -27.923475\n",
      "ep 17: ep_len:500 episode reward: total was -9.050000. running mean: -27.734740\n",
      "ep 17: ep_len:555 episode reward: total was -21.160000. running mean: -27.668993\n",
      "ep 17: ep_len:233 episode reward: total was 20.000000. running mean: -27.192303\n",
      "ep 17: ep_len:273 episode reward: total was 20.000000. running mean: -26.720380\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 17: ep_len:415 episode reward: total was -66.960000. running mean: -27.122776\n",
      "ep 17: ep_len:1765 episode reward: total was -223.250000. running mean: -29.084048\n",
      "ep 17: ep_len:585 episode reward: total was -9.990000. running mean: -28.893108\n",
      "ep 17: ep_len:570 episode reward: total was -17.090000. running mean: -28.775077\n",
      "ep 17: ep_len:910 episode reward: total was -48.730000. running mean: -28.974626\n",
      "ep 17: ep_len:169 episode reward: total was 10.500000. running mean: -28.579880\n",
      "ep 17: ep_len:655 episode reward: total was -14.900000. running mean: -28.443081\n",
      "ep 17: ep_len:500 episode reward: total was -22.830000. running mean: -28.386950\n",
      "ep 17: ep_len:403 episode reward: total was -75.500000. running mean: -28.858081\n",
      "ep 17: ep_len:635 episode reward: total was -48.270000. running mean: -29.052200\n",
      "ep 17: ep_len:730 episode reward: total was -37.980000. running mean: -29.141478\n",
      "ep 17: ep_len:780 episode reward: total was -41.920000. running mean: -29.269263\n",
      "ep 17: ep_len:790 episode reward: total was -40.480000. running mean: -29.381370\n",
      "ep 17: ep_len:500 episode reward: total was -43.550000. running mean: -29.523057\n",
      "ep 17: ep_len:1835 episode reward: total was -205.420000. running mean: -31.282026\n",
      "ep 17: ep_len:825 episode reward: total was -39.810000. running mean: -31.367306\n",
      "ep 17: ep_len:500 episode reward: total was -1.300000. running mean: -31.066633\n",
      "ep 17: ep_len:510 episode reward: total was -29.330000. running mean: -31.049266\n",
      "ep 17: ep_len:545 episode reward: total was -39.330000. running mean: -31.132074\n",
      "ep 17: ep_len:1035 episode reward: total was -38.050000. running mean: -31.201253\n",
      "ep 17: ep_len:369 episode reward: total was 3.170000. running mean: -30.857541\n",
      "ep 17: ep_len:980 episode reward: total was -53.640000. running mean: -31.085365\n",
      "ep 17: ep_len:500 episode reward: total was -9.240000. running mean: -30.866911\n",
      "ep 17: ep_len:635 episode reward: total was -34.620000. running mean: -30.904442\n",
      "ep 17: ep_len:356 episode reward: total was -2.000000. running mean: -30.615398\n",
      "ep 17: ep_len:500 episode reward: total was -22.800000. running mean: -30.537244\n",
      "ep 17: ep_len:880 episode reward: total was -13.310000. running mean: -30.364972\n",
      "ep 17: ep_len:900 episode reward: total was -12.780000. running mean: -30.189122\n",
      "ep 17: ep_len:695 episode reward: total was -5.690000. running mean: -29.944131\n",
      "ep 17: ep_len:88 episode reward: total was 1.000000. running mean: -29.634689\n",
      "ep 17: ep_len:500 episode reward: total was 2.680000. running mean: -29.311542\n",
      "ep 17: ep_len:500 episode reward: total was 18.720000. running mean: -28.831227\n",
      "ep 17: ep_len:1850 episode reward: total was -160.440000. running mean: -30.147315\n",
      "ep 17: ep_len:500 episode reward: total was 32.500000. running mean: -29.520842\n",
      "ep 17: ep_len:580 episode reward: total was -30.260000. running mean: -29.528233\n",
      "ep 17: ep_len:5690 episode reward: total was -1003.400000. running mean: -39.266951\n",
      "ep 17: ep_len:500 episode reward: total was -0.680000. running mean: -38.881081\n",
      "ep 17: ep_len:945 episode reward: total was -11.510000. running mean: -38.607370\n",
      "ep 17: ep_len:800 episode reward: total was -70.190000. running mean: -38.923197\n",
      "ep 17: ep_len:795 episode reward: total was -51.710000. running mean: -39.051065\n",
      "ep 17: ep_len:920 episode reward: total was -60.230000. running mean: -39.262854\n",
      "ep 17: ep_len:180 episode reward: total was 4.010000. running mean: -38.830126\n",
      "ep 17: ep_len:560 episode reward: total was -35.290000. running mean: -38.794724\n",
      "ep 17: ep_len:610 episode reward: total was 5.440000. running mean: -38.352377\n",
      "ep 17: ep_len:500 episode reward: total was -65.000000. running mean: -38.618853\n",
      "ep 17: ep_len:175 episode reward: total was 8.500000. running mean: -38.147665\n",
      "ep 17: ep_len:116 episode reward: total was 7.000000. running mean: -37.696188\n",
      "ep 17: ep_len:1225 episode reward: total was -228.860000. running mean: -39.607826\n",
      "ep 17: ep_len:500 episode reward: total was 1.230000. running mean: -39.199448\n",
      "ep 17: ep_len:705 episode reward: total was -17.310000. running mean: -38.980554\n",
      "ep 17: ep_len:605 episode reward: total was -32.990000. running mean: -38.920648\n",
      "ep 17: ep_len:530 episode reward: total was -22.220000. running mean: -38.753642\n",
      "ep 17: ep_len:890 episode reward: total was -30.840000. running mean: -38.674505\n",
      "ep 17: ep_len:500 episode reward: total was -1.180000. running mean: -38.299560\n",
      "ep 17: ep_len:505 episode reward: total was -7.870000. running mean: -37.995264\n",
      "ep 17: ep_len:770 episode reward: total was -23.510000. running mean: -37.850412\n",
      "ep 17: ep_len:500 episode reward: total was -0.910000. running mean: -37.481008\n",
      "ep 17: ep_len:500 episode reward: total was -12.260000. running mean: -37.228798\n",
      "ep 17: ep_len:500 episode reward: total was -15.660000. running mean: -37.013110\n",
      "ep 17: ep_len:590 episode reward: total was 1.080000. running mean: -36.632179\n",
      "ep 17: ep_len:382 episode reward: total was 25.000000. running mean: -36.015857\n",
      "ep 17: ep_len:192 episode reward: total was 13.000000. running mean: -35.525698\n",
      "ep 17: ep_len:750 episode reward: total was -19.770000. running mean: -35.368141\n",
      "ep 17: ep_len:615 episode reward: total was -38.210000. running mean: -35.396560\n",
      "ep 17: ep_len:540 episode reward: total was -14.240000. running mean: -35.184994\n",
      "ep 17: ep_len:960 episode reward: total was -2.500000. running mean: -34.858144\n",
      "ep 17: ep_len:685 episode reward: total was -18.360000. running mean: -34.693163\n",
      "ep 17: ep_len:500 episode reward: total was -6.800000. running mean: -34.414231\n",
      "ep 17: ep_len:1070 episode reward: total was -48.160000. running mean: -34.551689\n",
      "ep 17: ep_len:248 episode reward: total was 9.500000. running mean: -34.111172\n",
      "ep 17: ep_len:500 episode reward: total was -13.430000. running mean: -33.904360\n",
      "ep 17: ep_len:500 episode reward: total was 9.780000. running mean: -33.467517\n",
      "ep 17: ep_len:239 episode reward: total was 14.500000. running mean: -32.987841\n",
      "ep 17: ep_len:500 episode reward: total was -9.310000. running mean: -32.751063\n",
      "ep 17: ep_len:500 episode reward: total was -12.660000. running mean: -32.550152\n",
      "ep 17: ep_len:1110 episode reward: total was -134.490000. running mean: -33.569551\n",
      "ep 17: ep_len:500 episode reward: total was 3.970000. running mean: -33.194155\n",
      "ep 17: ep_len:2120 episode reward: total was -207.390000. running mean: -34.936114\n",
      "ep 17: ep_len:570 episode reward: total was -18.370000. running mean: -34.770453\n",
      "ep 17: ep_len:725 episode reward: total was -34.960000. running mean: -34.772348\n",
      "ep 17: ep_len:1545 episode reward: total was -87.000000. running mean: -35.294625\n",
      "ep 17: ep_len:500 episode reward: total was 10.180000. running mean: -34.839878\n",
      "ep 17: ep_len:685 episode reward: total was -57.260000. running mean: -35.064080\n",
      "ep 17: ep_len:690 episode reward: total was -28.970000. running mean: -35.003139\n",
      "ep 17: ep_len:500 episode reward: total was -47.000000. running mean: -35.123107\n",
      "ep 17: ep_len:1020 episode reward: total was -98.000000. running mean: -35.751876\n",
      "ep 17: ep_len:500 episode reward: total was -9.360000. running mean: -35.487958\n",
      "ep 17: ep_len:1580 episode reward: total was -64.330000. running mean: -35.776378\n",
      "ep 17: ep_len:197 episode reward: total was 12.500000. running mean: -35.293614\n",
      "ep 17: ep_len:970 episode reward: total was -14.990000. running mean: -35.090578\n",
      "ep 17: ep_len:500 episode reward: total was 22.000000. running mean: -34.519672\n",
      "ep 17: ep_len:500 episode reward: total was -38.990000. running mean: -34.564376\n",
      "ep 17: ep_len:965 episode reward: total was -40.840000. running mean: -34.627132\n",
      "ep 17: ep_len:500 episode reward: total was -79.970000. running mean: -35.080561\n",
      "ep 17: ep_len:146 episode reward: total was 13.000000. running mean: -34.599755\n",
      "ep 17: ep_len:800 episode reward: total was -37.840000. running mean: -34.632157\n",
      "ep 17: ep_len:252 episode reward: total was 14.500000. running mean: -34.140836\n",
      "ep 17: ep_len:925 episode reward: total was -23.900000. running mean: -34.038427\n",
      "ep 17: ep_len:800 episode reward: total was -7.350000. running mean: -33.771543\n",
      "ep 17: ep_len:500 episode reward: total was -30.080000. running mean: -33.734628\n",
      "ep 17: ep_len:271 episode reward: total was 18.000000. running mean: -33.217282\n",
      "ep 17: ep_len:505 episode reward: total was 0.180000. running mean: -32.883309\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 17: ep_len:1295 episode reward: total was -105.670000. running mean: -33.611176\n",
      "ep 17: ep_len:505 episode reward: total was 4.060000. running mean: -33.234464\n",
      "ep 17: ep_len:241 episode reward: total was 18.000000. running mean: -32.722119\n",
      "ep 17: ep_len:960 episode reward: total was -46.610000. running mean: -32.860998\n",
      "ep 17: ep_len:500 episode reward: total was -3.600000. running mean: -32.568388\n",
      "ep 17: ep_len:193 episode reward: total was 16.000000. running mean: -32.082704\n",
      "ep 17: ep_len:620 episode reward: total was 3.870000. running mean: -31.723177\n",
      "ep 17: ep_len:505 episode reward: total was -26.120000. running mean: -31.667145\n",
      "ep 17: ep_len:500 episode reward: total was -50.100000. running mean: -31.851474\n",
      "ep 17: ep_len:590 episode reward: total was -9.270000. running mean: -31.625659\n",
      "ep 17: ep_len:500 episode reward: total was 44.000000. running mean: -30.869403\n",
      "ep 17: ep_len:375 episode reward: total was -5.780000. running mean: -30.618509\n",
      "ep 17: ep_len:500 episode reward: total was -17.320000. running mean: -30.485523\n",
      "ep 17: ep_len:1000 episode reward: total was -122.770000. running mean: -31.408368\n",
      "ep 17: ep_len:1540 episode reward: total was -108.070000. running mean: -32.174985\n",
      "ep 17: ep_len:500 episode reward: total was 8.710000. running mean: -31.766135\n",
      "ep 17: ep_len:351 episode reward: total was -36.180000. running mean: -31.810273\n",
      "ep 17: ep_len:525 episode reward: total was -38.390000. running mean: -31.876071\n",
      "ep 17: ep_len:500 episode reward: total was 7.790000. running mean: -31.479410\n",
      "ep 17: ep_len:1105 episode reward: total was -24.490000. running mean: -31.409516\n",
      "ep 17: ep_len:1980 episode reward: total was -95.240000. running mean: -32.047821\n",
      "ep 17: ep_len:735 episode reward: total was -17.650000. running mean: -31.903842\n",
      "ep 17: ep_len:930 episode reward: total was -3.260000. running mean: -31.617404\n",
      "ep 17: ep_len:649 episode reward: total was -42.440000. running mean: -31.725630\n",
      "ep 17: ep_len:500 episode reward: total was -5.380000. running mean: -31.462174\n",
      "ep 17: ep_len:510 episode reward: total was -14.260000. running mean: -31.290152\n",
      "ep 17: ep_len:500 episode reward: total was -6.990000. running mean: -31.047150\n",
      "ep 17: ep_len:500 episode reward: total was -12.540000. running mean: -30.862079\n",
      "ep 17: ep_len:1065 episode reward: total was -75.690000. running mean: -31.310358\n",
      "ep 17: ep_len:500 episode reward: total was -14.070000. running mean: -31.137955\n",
      "ep 17: ep_len:600 episode reward: total was -24.830000. running mean: -31.074875\n",
      "ep 17: ep_len:550 episode reward: total was -18.140000. running mean: -30.945526\n",
      "ep 17: ep_len:8200 episode reward: total was -1581.270000. running mean: -46.448771\n",
      "ep 17: ep_len:760 episode reward: total was -39.940000. running mean: -46.383683\n",
      "ep 17: ep_len:462 episode reward: total was 19.230000. running mean: -45.727546\n",
      "ep 17: ep_len:545 episode reward: total was -37.310000. running mean: -45.643371\n",
      "ep 17: ep_len:700 episode reward: total was -15.740000. running mean: -45.344337\n",
      "ep 17: ep_len:500 episode reward: total was 14.230000. running mean: -44.748594\n",
      "ep 17: ep_len:500 episode reward: total was -14.530000. running mean: -44.446408\n",
      "ep 17: ep_len:500 episode reward: total was 13.940000. running mean: -43.862544\n",
      "ep 17: ep_len:505 episode reward: total was 8.230000. running mean: -43.341618\n",
      "ep 17: ep_len:590 episode reward: total was -73.290000. running mean: -43.641102\n",
      "ep 17: ep_len:915 episode reward: total was -31.280000. running mean: -43.517491\n",
      "ep 17: ep_len:585 episode reward: total was -37.260000. running mean: -43.454916\n",
      "ep 17: ep_len:680 episode reward: total was -55.250000. running mean: -43.572867\n",
      "ep 17: ep_len:900 episode reward: total was -2.480000. running mean: -43.161938\n",
      "ep 17: ep_len:500 episode reward: total was -15.300000. running mean: -42.883319\n",
      "ep 17: ep_len:184 episode reward: total was 6.000000. running mean: -42.394486\n",
      "ep 17: ep_len:1045 episode reward: total was -6.820000. running mean: -42.038741\n",
      "ep 17: ep_len:850 episode reward: total was -22.560000. running mean: -41.843954\n",
      "ep 17: ep_len:605 episode reward: total was -29.140000. running mean: -41.716914\n",
      "ep 17: ep_len:500 episode reward: total was -8.220000. running mean: -41.381945\n",
      "ep 17: ep_len:920 episode reward: total was -36.890000. running mean: -41.337026\n",
      "ep 17: ep_len:500 episode reward: total was -7.270000. running mean: -40.996355\n",
      "ep 17: ep_len:585 episode reward: total was -35.010000. running mean: -40.936492\n",
      "ep 17: ep_len:279 episode reward: total was 15.500000. running mean: -40.372127\n",
      "ep 17: ep_len:500 episode reward: total was 4.060000. running mean: -39.927806\n",
      "ep 17: ep_len:945 episode reward: total was -52.700000. running mean: -40.055527\n",
      "ep 17: ep_len:665 episode reward: total was -20.470000. running mean: -39.859672\n",
      "ep 17: ep_len:515 episode reward: total was -17.200000. running mean: -39.633075\n",
      "ep 17: ep_len:655 episode reward: total was -11.160000. running mean: -39.348345\n",
      "ep 17: ep_len:500 episode reward: total was -11.290000. running mean: -39.067761\n",
      "ep 17: ep_len:1475 episode reward: total was -182.940000. running mean: -40.506484\n",
      "ep 17: ep_len:488 episode reward: total was 31.000000. running mean: -39.791419\n",
      "ep 17: ep_len:755 episode reward: total was -1.830000. running mean: -39.411805\n",
      "ep 17: ep_len:500 episode reward: total was -54.750000. running mean: -39.565187\n",
      "ep 17: ep_len:505 episode reward: total was -19.880000. running mean: -39.368335\n",
      "ep 17: ep_len:171 episode reward: total was 11.500000. running mean: -38.859651\n",
      "ep 17: ep_len:184 episode reward: total was 17.000000. running mean: -38.301055\n",
      "ep 17: ep_len:950 episode reward: total was -4.830000. running mean: -37.966344\n",
      "ep 17: ep_len:790 episode reward: total was -33.300000. running mean: -37.919681\n",
      "ep 17: ep_len:500 episode reward: total was -18.240000. running mean: -37.722884\n",
      "ep 17: ep_len:500 episode reward: total was -20.290000. running mean: -37.548555\n",
      "ep 17: ep_len:500 episode reward: total was -17.640000. running mean: -37.349470\n",
      "ep 17: ep_len:500 episode reward: total was 5.800000. running mean: -36.917975\n",
      "ep 17: ep_len:710 episode reward: total was -20.330000. running mean: -36.752095\n",
      "ep 17: ep_len:500 episode reward: total was -18.790000. running mean: -36.572474\n",
      "ep 17: ep_len:201 episode reward: total was 15.500000. running mean: -36.051750\n",
      "ep 17: ep_len:500 episode reward: total was -20.620000. running mean: -35.897432\n",
      "ep 17: ep_len:740 episode reward: total was -31.900000. running mean: -35.857458\n",
      "ep 17: ep_len:1415 episode reward: total was -34.170000. running mean: -35.840583\n",
      "ep 17: ep_len:750 episode reward: total was -37.230000. running mean: -35.854477\n",
      "ep 17: ep_len:500 episode reward: total was 6.380000. running mean: -35.432133\n",
      "ep 17: ep_len:460 episode reward: total was 10.220000. running mean: -34.975611\n",
      "ep 17: ep_len:1200 episode reward: total was -26.130000. running mean: -34.887155\n",
      "ep 17: ep_len:510 episode reward: total was -16.170000. running mean: -34.699984\n",
      "ep 17: ep_len:821 episode reward: total was -81.180000. running mean: -35.164784\n",
      "ep 17: ep_len:895 episode reward: total was -140.670000. running mean: -36.219836\n",
      "ep 17: ep_len:710 episode reward: total was -65.290000. running mean: -36.510538\n",
      "ep 17: ep_len:630 episode reward: total was -11.570000. running mean: -36.261132\n",
      "ep 17: ep_len:2355 episode reward: total was -390.460000. running mean: -39.803121\n",
      "ep 17: ep_len:700 episode reward: total was -26.040000. running mean: -39.665490\n",
      "ep 17: ep_len:500 episode reward: total was 1.450000. running mean: -39.254335\n",
      "ep 17: ep_len:1125 episode reward: total was -7.750000. running mean: -38.939291\n",
      "ep 17: ep_len:500 episode reward: total was -24.030000. running mean: -38.790198\n",
      "ep 17: ep_len:655 episode reward: total was -56.630000. running mean: -38.968596\n",
      "ep 17: ep_len:720 episode reward: total was -41.490000. running mean: -38.993810\n",
      "ep 17: ep_len:725 episode reward: total was -57.180000. running mean: -39.175672\n",
      "ep 17: ep_len:505 episode reward: total was 0.940000. running mean: -38.774516\n",
      "ep 17: ep_len:223 episode reward: total was 13.000000. running mean: -38.256771\n",
      "ep 17: ep_len:510 episode reward: total was 7.200000. running mean: -37.802203\n",
      "ep 17: ep_len:500 episode reward: total was -21.820000. running mean: -37.642381\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 17: ep_len:970 episode reward: total was -67.800000. running mean: -37.943957\n",
      "ep 17: ep_len:1975 episode reward: total was -224.600000. running mean: -39.810517\n",
      "ep 17: ep_len:505 episode reward: total was -4.540000. running mean: -39.457812\n",
      "ep 17: ep_len:525 episode reward: total was -27.820000. running mean: -39.341434\n",
      "ep 17: ep_len:520 episode reward: total was -12.140000. running mean: -39.069420\n",
      "ep 17: ep_len:500 episode reward: total was 0.700000. running mean: -38.671726\n",
      "ep 17: ep_len:500 episode reward: total was -16.280000. running mean: -38.447808\n",
      "ep 17: ep_len:500 episode reward: total was -13.860000. running mean: -38.201930\n",
      "ep 17: ep_len:500 episode reward: total was 1.730000. running mean: -37.802611\n",
      "ep 17: ep_len:855 episode reward: total was -21.550000. running mean: -37.640085\n",
      "ep 17: ep_len:500 episode reward: total was -39.630000. running mean: -37.659984\n",
      "ep 17: ep_len:795 episode reward: total was -29.390000. running mean: -37.577284\n",
      "ep 17: ep_len:1455 episode reward: total was -156.720000. running mean: -38.768711\n",
      "ep 17: ep_len:640 episode reward: total was -39.170000. running mean: -38.772724\n",
      "ep 17: ep_len:500 episode reward: total was -8.440000. running mean: -38.469397\n",
      "ep 17: ep_len:770 episode reward: total was 6.890000. running mean: -38.015803\n",
      "ep 17: ep_len:1540 episode reward: total was -172.710000. running mean: -39.362745\n",
      "ep 17: ep_len:500 episode reward: total was -16.730000. running mean: -39.136417\n",
      "ep 17: ep_len:1630 episode reward: total was -170.960000. running mean: -40.454653\n",
      "ep 17: ep_len:1025 episode reward: total was -52.510000. running mean: -40.575207\n",
      "ep 17: ep_len:705 episode reward: total was 12.830000. running mean: -40.041155\n",
      "ep 17: ep_len:843 episode reward: total was -76.250000. running mean: -40.403243\n",
      "ep 17: ep_len:710 episode reward: total was -12.770000. running mean: -40.126911\n",
      "ep 17: ep_len:500 episode reward: total was 16.790000. running mean: -39.557742\n",
      "ep 17: ep_len:443 episode reward: total was -24.790000. running mean: -39.410064\n",
      "ep 17: ep_len:500 episode reward: total was 4.760000. running mean: -38.968364\n",
      "ep 17: ep_len:630 episode reward: total was -19.540000. running mean: -38.774080\n",
      "ep 17: ep_len:500 episode reward: total was -0.300000. running mean: -38.389339\n",
      "ep 17: ep_len:160 episode reward: total was 7.500000. running mean: -37.930446\n",
      "ep 17: ep_len:500 episode reward: total was 3.380000. running mean: -37.517341\n",
      "ep 17: ep_len:500 episode reward: total was -8.340000. running mean: -37.225568\n",
      "ep 17: ep_len:500 episode reward: total was 3.410000. running mean: -36.819212\n",
      "ep 17: ep_len:515 episode reward: total was -20.230000. running mean: -36.653320\n",
      "ep 17: ep_len:885 episode reward: total was -21.700000. running mean: -36.503787\n",
      "ep 17: ep_len:710 episode reward: total was -39.760000. running mean: -36.536349\n",
      "ep 17: ep_len:860 episode reward: total was -26.970000. running mean: -36.440686\n",
      "ep 17: ep_len:500 episode reward: total was 0.560000. running mean: -36.070679\n",
      "ep 17: ep_len:500 episode reward: total was 2.860000. running mean: -35.681372\n",
      "ep 17: ep_len:500 episode reward: total was 5.310000. running mean: -35.271458\n",
      "ep 17: ep_len:841 episode reward: total was -17.180000. running mean: -35.090544\n",
      "ep 17: ep_len:101 episode reward: total was 7.000000. running mean: -34.669638\n",
      "ep 17: ep_len:500 episode reward: total was 14.740000. running mean: -34.175542\n",
      "ep 17: ep_len:765 episode reward: total was -33.870000. running mean: -34.172486\n",
      "ep 17: ep_len:500 episode reward: total was -6.290000. running mean: -33.893661\n",
      "ep 17: ep_len:176 episode reward: total was 13.000000. running mean: -33.424725\n",
      "ep 17: ep_len:500 episode reward: total was 5.650000. running mean: -33.033978\n",
      "ep 17: ep_len:895 episode reward: total was -38.300000. running mean: -33.086638\n",
      "ep 17: ep_len:800 episode reward: total was -82.280000. running mean: -33.578571\n",
      "ep 17: ep_len:137 episode reward: total was 9.000000. running mean: -33.152786\n",
      "ep 17: ep_len:170 episode reward: total was 8.000000. running mean: -32.741258\n",
      "ep 17: ep_len:615 episode reward: total was -6.030000. running mean: -32.474145\n",
      "ep 17: ep_len:550 episode reward: total was -15.990000. running mean: -32.309304\n",
      "ep 17: ep_len:610 episode reward: total was -7.300000. running mean: -32.059211\n",
      "ep 17: ep_len:500 episode reward: total was 3.930000. running mean: -31.699319\n",
      "ep 17: ep_len:730 episode reward: total was -75.840000. running mean: -32.140726\n",
      "ep 17: ep_len:155 episode reward: total was 2.000000. running mean: -31.799318\n",
      "ep 17: ep_len:500 episode reward: total was -2.350000. running mean: -31.504825\n",
      "ep 17: ep_len:775 episode reward: total was -28.800000. running mean: -31.477777\n",
      "ep 17: ep_len:500 episode reward: total was 7.680000. running mean: -31.086199\n",
      "ep 17: ep_len:352 episode reward: total was 24.500000. running mean: -30.530337\n",
      "ep 17: ep_len:630 episode reward: total was 4.690000. running mean: -30.178134\n",
      "ep 17: ep_len:167 episode reward: total was 16.500000. running mean: -29.711352\n",
      "ep 17: ep_len:228 episode reward: total was 15.500000. running mean: -29.259239\n",
      "ep 17: ep_len:505 episode reward: total was -23.470000. running mean: -29.201346\n",
      "ep 17: ep_len:680 episode reward: total was -12.430000. running mean: -29.033633\n",
      "ep 17: ep_len:855 episode reward: total was -23.590000. running mean: -28.979197\n",
      "ep 17: ep_len:760 episode reward: total was -26.780000. running mean: -28.957205\n",
      "ep 17: ep_len:525 episode reward: total was -19.200000. running mean: -28.859633\n",
      "ep 17: ep_len:500 episode reward: total was 3.720000. running mean: -28.533836\n",
      "ep 17: ep_len:500 episode reward: total was 24.500000. running mean: -28.003498\n",
      "ep 17: ep_len:500 episode reward: total was 2.190000. running mean: -27.701563\n",
      "ep 17: ep_len:500 episode reward: total was -8.000000. running mean: -27.504547\n",
      "ep 17: ep_len:500 episode reward: total was -5.620000. running mean: -27.285702\n",
      "ep 17: ep_len:980 episode reward: total was -135.940000. running mean: -28.372245\n",
      "ep 17: ep_len:500 episode reward: total was -0.900000. running mean: -28.097522\n",
      "ep 17: ep_len:1465 episode reward: total was -259.720000. running mean: -30.413747\n",
      "ep 17: ep_len:500 episode reward: total was 1.910000. running mean: -30.090510\n",
      "ep 17: ep_len:705 episode reward: total was -25.910000. running mean: -30.048705\n",
      "ep 17: ep_len:875 episode reward: total was -29.590000. running mean: -30.044118\n",
      "ep 17: ep_len:825 episode reward: total was -20.800000. running mean: -29.951676\n",
      "ep 17: ep_len:610 episode reward: total was -16.290000. running mean: -29.815060\n",
      "ep 17: ep_len:500 episode reward: total was -14.380000. running mean: -29.660709\n",
      "ep 17: ep_len:525 episode reward: total was -49.500000. running mean: -29.859102\n",
      "ep 17: ep_len:500 episode reward: total was 3.650000. running mean: -29.524011\n",
      "ep 17: ep_len:860 episode reward: total was -4.090000. running mean: -29.269671\n",
      "ep 17: ep_len:500 episode reward: total was 3.230000. running mean: -28.944674\n",
      "ep 17: ep_len:670 episode reward: total was -21.420000. running mean: -28.869427\n",
      "ep 17: ep_len:520 episode reward: total was -15.170000. running mean: -28.732433\n",
      "ep 17: ep_len:500 episode reward: total was 3.210000. running mean: -28.413009\n",
      "ep 17: ep_len:500 episode reward: total was -0.510000. running mean: -28.133979\n",
      "ep 17: ep_len:500 episode reward: total was 26.000000. running mean: -27.592639\n",
      "ep 17: ep_len:845 episode reward: total was -26.300000. running mean: -27.579712\n",
      "ep 17: ep_len:500 episode reward: total was 4.050000. running mean: -27.263415\n",
      "ep 17: ep_len:301 episode reward: total was -15.390000. running mean: -27.144681\n",
      "ep 17: ep_len:670 episode reward: total was -43.150000. running mean: -27.304734\n",
      "ep 17: ep_len:740 episode reward: total was -51.090000. running mean: -27.542587\n",
      "ep 17: ep_len:1040 episode reward: total was -24.980000. running mean: -27.516961\n",
      "ep 17: ep_len:184 episode reward: total was 15.000000. running mean: -27.091792\n",
      "ep 17: ep_len:890 episode reward: total was -11.040000. running mean: -26.931274\n",
      "ep 17: ep_len:2260 episode reward: total was -287.660000. running mean: -29.538561\n",
      "ep 17: ep_len:500 episode reward: total was 33.500000. running mean: -28.908175\n",
      "ep 17: ep_len:500 episode reward: total was -3.910000. running mean: -28.658194\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 17: ep_len:780 episode reward: total was -15.660000. running mean: -28.528212\n",
      "ep 17: ep_len:505 episode reward: total was 7.650000. running mean: -28.166430\n",
      "ep 17: ep_len:715 episode reward: total was -9.930000. running mean: -27.984065\n",
      "ep 17: ep_len:845 episode reward: total was -24.280000. running mean: -27.947025\n",
      "ep 17: ep_len:575 episode reward: total was -23.140000. running mean: -27.898954\n",
      "ep 17: ep_len:500 episode reward: total was -4.370000. running mean: -27.663665\n",
      "ep 17: ep_len:133 episode reward: total was 10.000000. running mean: -27.287028\n",
      "ep 17: ep_len:500 episode reward: total was -3.390000. running mean: -27.048058\n",
      "ep 17: ep_len:500 episode reward: total was 14.800000. running mean: -26.629577\n",
      "ep 17: ep_len:500 episode reward: total was 9.470000. running mean: -26.268581\n",
      "ep 17: ep_len:500 episode reward: total was -24.360000. running mean: -26.249496\n",
      "ep 17: ep_len:500 episode reward: total was -2.380000. running mean: -26.010801\n",
      "ep 17: ep_len:850 episode reward: total was -45.820000. running mean: -26.208893\n",
      "ep 17: ep_len:500 episode reward: total was -17.770000. running mean: -26.124504\n",
      "ep 17: ep_len:985 episode reward: total was -14.830000. running mean: -26.011559\n",
      "ep 17: ep_len:815 episode reward: total was -9.170000. running mean: -25.843143\n",
      "ep 17: ep_len:520 episode reward: total was -32.460000. running mean: -25.909312\n",
      "ep 17: ep_len:625 episode reward: total was -46.270000. running mean: -26.112919\n",
      "ep 17: ep_len:500 episode reward: total was 32.000000. running mean: -25.531789\n",
      "ep 17: ep_len:500 episode reward: total was 6.590000. running mean: -25.210572\n",
      "ep 17: ep_len:565 episode reward: total was -3.590000. running mean: -24.994366\n",
      "ep 17: ep_len:975 episode reward: total was -23.170000. running mean: -24.976122\n",
      "ep 17: ep_len:500 episode reward: total was -27.170000. running mean: -24.998061\n",
      "ep 17: ep_len:313 episode reward: total was -1.320000. running mean: -24.761280\n",
      "ep 17: ep_len:500 episode reward: total was -4.300000. running mean: -24.556668\n",
      "ep 17: ep_len:1621 episode reward: total was -244.240000. running mean: -26.753501\n",
      "ep 17: ep_len:247 episode reward: total was 18.500000. running mean: -26.300966\n",
      "ep 17: ep_len:535 episode reward: total was 10.190000. running mean: -25.936056\n",
      "ep 17: ep_len:500 episode reward: total was 7.760000. running mean: -25.599096\n",
      "ep 17: ep_len:505 episode reward: total was -12.440000. running mean: -25.467505\n",
      "ep 17: ep_len:925 episode reward: total was -37.920000. running mean: -25.592030\n",
      "ep 17: ep_len:505 episode reward: total was -9.730000. running mean: -25.433409\n",
      "ep 17: ep_len:500 episode reward: total was -4.380000. running mean: -25.222875\n",
      "ep 17: ep_len:1480 episode reward: total was -143.690000. running mean: -26.407546\n",
      "ep 17: ep_len:500 episode reward: total was 8.830000. running mean: -26.055171\n",
      "ep 17: ep_len:980 episode reward: total was -97.090000. running mean: -26.765519\n",
      "ep 17: ep_len:870 episode reward: total was -24.570000. running mean: -26.743564\n",
      "ep 17: ep_len:770 episode reward: total was -20.780000. running mean: -26.683928\n",
      "ep 17: ep_len:510 episode reward: total was -37.410000. running mean: -26.791189\n",
      "ep 17: ep_len:775 episode reward: total was -27.790000. running mean: -26.801177\n",
      "ep 17: ep_len:500 episode reward: total was -21.440000. running mean: -26.747566\n",
      "ep 17: ep_len:505 episode reward: total was -27.810000. running mean: -26.758190\n",
      "ep 17: ep_len:500 episode reward: total was 14.280000. running mean: -26.347808\n",
      "ep 17: ep_len:500 episode reward: total was -8.440000. running mean: -26.168730\n",
      "ep 17: ep_len:910 episode reward: total was -66.390000. running mean: -26.570943\n",
      "ep 17: ep_len:925 episode reward: total was -8.350000. running mean: -26.388733\n",
      "ep 17: ep_len:665 episode reward: total was -15.300000. running mean: -26.277846\n",
      "ep 17: ep_len:860 episode reward: total was -34.720000. running mean: -26.362267\n",
      "ep 17: ep_len:915 episode reward: total was -95.200000. running mean: -27.050645\n",
      "ep 17: ep_len:550 episode reward: total was -36.320000. running mean: -27.143338\n",
      "ep 17: ep_len:590 episode reward: total was -49.370000. running mean: -27.365605\n",
      "ep 17: ep_len:500 episode reward: total was -2.270000. running mean: -27.114649\n",
      "ep 17: ep_len:795 episode reward: total was -86.820000. running mean: -27.711702\n",
      "ep 17: ep_len:755 episode reward: total was -28.810000. running mean: -27.722685\n",
      "ep 17: ep_len:1461 episode reward: total was -289.490000. running mean: -30.340358\n",
      "ep 17: ep_len:500 episode reward: total was -10.060000. running mean: -30.137555\n",
      "ep 17: ep_len:500 episode reward: total was -6.270000. running mean: -29.898879\n",
      "ep 17: ep_len:740 episode reward: total was -12.850000. running mean: -29.728391\n",
      "ep 17: ep_len:665 episode reward: total was -17.840000. running mean: -29.609507\n",
      "ep 17: ep_len:500 episode reward: total was -10.250000. running mean: -29.415912\n",
      "ep 17: ep_len:735 episode reward: total was -41.000000. running mean: -29.531752\n",
      "ep 17: ep_len:600 episode reward: total was -23.090000. running mean: -29.467335\n",
      "ep 17: ep_len:500 episode reward: total was 7.220000. running mean: -29.100462\n",
      "ep 17: ep_len:505 episode reward: total was 5.790000. running mean: -28.751557\n",
      "ep 17: ep_len:630 episode reward: total was -16.290000. running mean: -28.626941\n",
      "ep 17: ep_len:197 episode reward: total was 13.500000. running mean: -28.205672\n",
      "ep 17: ep_len:1280 episode reward: total was -165.150000. running mean: -29.575115\n",
      "ep 17: ep_len:730 episode reward: total was -32.370000. running mean: -29.603064\n",
      "ep 17: ep_len:500 episode reward: total was -21.360000. running mean: -29.520633\n",
      "ep 17: ep_len:795 episode reward: total was -57.040000. running mean: -29.795827\n",
      "ep 17: ep_len:500 episode reward: total was 6.780000. running mean: -29.430069\n",
      "ep 17: ep_len:4190 episode reward: total was -738.060000. running mean: -36.516368\n",
      "ep 17: ep_len:500 episode reward: total was 21.780000. running mean: -35.933404\n",
      "ep 17: ep_len:740 episode reward: total was -25.810000. running mean: -35.832170\n",
      "ep 17: ep_len:920 episode reward: total was -18.090000. running mean: -35.654749\n",
      "ep 17: ep_len:545 episode reward: total was -42.390000. running mean: -35.722101\n",
      "ep 17: ep_len:690 episode reward: total was -16.930000. running mean: -35.534180\n",
      "ep 17: ep_len:590 episode reward: total was -33.210000. running mean: -35.510938\n",
      "ep 17: ep_len:810 episode reward: total was -27.040000. running mean: -35.426229\n",
      "ep 17: ep_len:254 episode reward: total was 19.500000. running mean: -34.876967\n",
      "ep 17: ep_len:222 episode reward: total was 12.000000. running mean: -34.408197\n",
      "ep 17: ep_len:610 episode reward: total was -0.290000. running mean: -34.067015\n",
      "ep 17: ep_len:900 episode reward: total was -53.770000. running mean: -34.264045\n",
      "ep 17: ep_len:1505 episode reward: total was -218.580000. running mean: -36.107205\n",
      "ep 17: ep_len:755 episode reward: total was -22.780000. running mean: -35.973932\n",
      "ep 17: ep_len:720 episode reward: total was -76.380000. running mean: -36.377993\n",
      "ep 17: ep_len:575 episode reward: total was -16.070000. running mean: -36.174913\n",
      "ep 17: ep_len:685 episode reward: total was -18.850000. running mean: -36.001664\n",
      "ep 17: ep_len:570 episode reward: total was -18.740000. running mean: -35.829047\n",
      "ep 17: ep_len:4325 episode reward: total was -746.360000. running mean: -42.934357\n",
      "ep 17: ep_len:500 episode reward: total was 13.270000. running mean: -42.372313\n",
      "ep 17: ep_len:184 episode reward: total was 13.500000. running mean: -41.813590\n",
      "ep 17: ep_len:610 episode reward: total was -33.240000. running mean: -41.727854\n",
      "ep 17: ep_len:695 episode reward: total was -19.900000. running mean: -41.509576\n",
      "ep 17: ep_len:223 episode reward: total was 17.500000. running mean: -40.919480\n",
      "ep 17: ep_len:1245 episode reward: total was -12.170000. running mean: -40.631985\n",
      "ep 17: ep_len:4890 episode reward: total was -862.910000. running mean: -48.854765\n",
      "ep 17: ep_len:254 episode reward: total was 17.500000. running mean: -48.191218\n",
      "ep 17: ep_len:715 episode reward: total was -12.760000. running mean: -47.836906\n",
      "ep 17: ep_len:500 episode reward: total was 2.750000. running mean: -47.331037\n",
      "ep 17: ep_len:550 episode reward: total was -47.430000. running mean: -47.332026\n",
      "ep 17: ep_len:515 episode reward: total was 2.720000. running mean: -46.831506\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 17: ep_len:500 episode reward: total was -9.910000. running mean: -46.462291\n",
      "ep 17: ep_len:500 episode reward: total was -4.180000. running mean: -46.039468\n",
      "ep 17: ep_len:500 episode reward: total was -17.410000. running mean: -45.753173\n",
      "ep 17: ep_len:500 episode reward: total was -23.560000. running mean: -45.531242\n",
      "ep 17: ep_len:585 episode reward: total was -24.130000. running mean: -45.317229\n",
      "ep 17: ep_len:920 episode reward: total was -30.530000. running mean: -45.169357\n",
      "ep 17: ep_len:500 episode reward: total was 1.790000. running mean: -44.699763\n",
      "ep 17: ep_len:700 episode reward: total was -17.840000. running mean: -44.431166\n",
      "ep 17: ep_len:426 episode reward: total was 7.730000. running mean: -43.909554\n",
      "ep 17: ep_len:1470 episode reward: total was -135.010000. running mean: -44.820558\n",
      "ep 17: ep_len:630 episode reward: total was -43.230000. running mean: -44.804653\n",
      "ep 17: ep_len:605 episode reward: total was -3.220000. running mean: -44.388806\n",
      "ep 17: ep_len:487 episode reward: total was 29.000000. running mean: -43.654918\n",
      "ep 17: ep_len:438 episode reward: total was -5.290000. running mean: -43.271269\n",
      "ep 17: ep_len:940 episode reward: total was -35.760000. running mean: -43.196156\n",
      "ep 17: ep_len:500 episode reward: total was 18.290000. running mean: -42.581295\n",
      "ep 17: ep_len:650 episode reward: total was -67.430000. running mean: -42.829782\n",
      "ep 17: ep_len:680 episode reward: total was -18.890000. running mean: -42.590384\n",
      "ep 17: ep_len:795 episode reward: total was -13.680000. running mean: -42.301280\n",
      "ep 17: ep_len:500 episode reward: total was -31.000000. running mean: -42.188267\n",
      "ep 17: ep_len:500 episode reward: total was -41.990000. running mean: -42.186285\n",
      "ep 17: ep_len:530 episode reward: total was -20.200000. running mean: -41.966422\n",
      "ep 17: ep_len:500 episode reward: total was -7.260000. running mean: -41.619358\n",
      "ep 17: ep_len:895 episode reward: total was -61.370000. running mean: -41.816864\n",
      "ep 17: ep_len:254 episode reward: total was 19.500000. running mean: -41.203695\n",
      "ep 17: ep_len:1450 episode reward: total was -80.450000. running mean: -41.596158\n",
      "ep 17: ep_len:510 episode reward: total was -12.430000. running mean: -41.304497\n",
      "ep 17: ep_len:665 episode reward: total was -50.230000. running mean: -41.393752\n",
      "ep 17: ep_len:775 episode reward: total was -37.890000. running mean: -41.358714\n",
      "ep 17: ep_len:750 episode reward: total was -4.220000. running mean: -40.987327\n",
      "ep 17: ep_len:830 episode reward: total was -5.810000. running mean: -40.635554\n",
      "ep 17: ep_len:575 episode reward: total was -63.500000. running mean: -40.864198\n",
      "ep 17: ep_len:565 episode reward: total was -18.920000. running mean: -40.644756\n",
      "ep 17: ep_len:645 episode reward: total was -103.280000. running mean: -41.271109\n",
      "ep 17: ep_len:492 episode reward: total was 13.770000. running mean: -40.720698\n",
      "ep 17: ep_len:760 episode reward: total was -29.840000. running mean: -40.611891\n",
      "ep 17: ep_len:500 episode reward: total was 0.860000. running mean: -40.197172\n",
      "ep 17: ep_len:750 episode reward: total was -38.600000. running mean: -40.181200\n",
      "ep 17: ep_len:505 episode reward: total was -26.400000. running mean: -40.043388\n",
      "ep 17: ep_len:760 episode reward: total was -18.730000. running mean: -39.830254\n",
      "ep 17: ep_len:1055 episode reward: total was -80.900000. running mean: -40.240952\n",
      "ep 17: ep_len:650 episode reward: total was -26.020000. running mean: -40.098742\n",
      "ep 17: ep_len:520 episode reward: total was 0.480000. running mean: -39.692955\n",
      "ep 17: ep_len:510 episode reward: total was -21.880000. running mean: -39.514825\n",
      "ep 17: ep_len:755 episode reward: total was -17.730000. running mean: -39.296977\n",
      "ep 17: ep_len:161 episode reward: total was 7.000000. running mean: -38.834007\n",
      "ep 17: ep_len:725 episode reward: total was -17.160000. running mean: -38.617267\n",
      "ep 17: ep_len:700 episode reward: total was -23.900000. running mean: -38.470095\n",
      "ep 17: ep_len:500 episode reward: total was 17.770000. running mean: -37.907694\n",
      "ep 17: ep_len:254 episode reward: total was 14.500000. running mean: -37.383617\n",
      "ep 17: ep_len:765 episode reward: total was -30.840000. running mean: -37.318180\n",
      "ep 17: ep_len:500 episode reward: total was 11.010000. running mean: -36.834899\n",
      "ep 17: ep_len:915 episode reward: total was -26.680000. running mean: -36.733350\n",
      "ep 17: ep_len:500 episode reward: total was -18.880000. running mean: -36.554816\n",
      "ep 17: ep_len:505 episode reward: total was -15.200000. running mean: -36.341268\n",
      "ep 17: ep_len:500 episode reward: total was 0.230000. running mean: -35.975555\n",
      "ep 17: ep_len:156 episode reward: total was 6.500000. running mean: -35.550800\n",
      "ep 17: ep_len:505 episode reward: total was -1.830000. running mean: -35.213592\n",
      "ep 17: ep_len:540 episode reward: total was -50.280000. running mean: -35.364256\n",
      "ep 17: ep_len:550 episode reward: total was -40.930000. running mean: -35.419913\n",
      "ep 17: ep_len:550 episode reward: total was -35.310000. running mean: -35.418814\n",
      "ep 17: ep_len:500 episode reward: total was 1.270000. running mean: -35.051926\n",
      "ep 17: ep_len:585 episode reward: total was -45.340000. running mean: -35.154807\n",
      "ep 17: ep_len:555 episode reward: total was -60.550000. running mean: -35.408759\n",
      "ep 17: ep_len:2768 episode reward: total was -362.790000. running mean: -38.682571\n",
      "ep 17: ep_len:890 episode reward: total was -40.300000. running mean: -38.698745\n",
      "ep 17: ep_len:6115 episode reward: total was -1138.210000. running mean: -49.693858\n",
      "ep 17: ep_len:1246 episode reward: total was -47.350000. running mean: -49.670419\n",
      "ep 17: ep_len:248 episode reward: total was -46.000000. running mean: -49.633715\n",
      "ep 17: ep_len:2078 episode reward: total was -236.260000. running mean: -51.499978\n",
      "ep 17: ep_len:665 episode reward: total was -68.410000. running mean: -51.669078\n",
      "ep 17: ep_len:500 episode reward: total was 33.500000. running mean: -50.817387\n",
      "ep 17: ep_len:665 episode reward: total was -14.400000. running mean: -50.453214\n",
      "epsilon:0.123041 episode_count: 14203. steps_count: 10061295.000000\n",
      "ep 18: ep_len:500 episode reward: total was 10.270000. running mean: -49.845981\n",
      "ep 18: ep_len:810 episode reward: total was -44.890000. running mean: -49.796422\n",
      "ep 18: ep_len:690 episode reward: total was -41.090000. running mean: -49.709357\n",
      "ep 18: ep_len:2568 episode reward: total was -279.260000. running mean: -52.004864\n",
      "ep 18: ep_len:500 episode reward: total was -5.260000. running mean: -51.537415\n",
      "ep 18: ep_len:500 episode reward: total was -16.610000. running mean: -51.188141\n",
      "ep 18: ep_len:710 episode reward: total was -37.010000. running mean: -51.046360\n",
      "ep 18: ep_len:515 episode reward: total was 5.250000. running mean: -50.483396\n",
      "ep 18: ep_len:790 episode reward: total was -56.040000. running mean: -50.538962\n",
      "ep 18: ep_len:500 episode reward: total was -1.460000. running mean: -50.048172\n",
      "ep 18: ep_len:500 episode reward: total was 0.680000. running mean: -49.540891\n",
      "ep 18: ep_len:660 episode reward: total was -41.640000. running mean: -49.461882\n",
      "ep 18: ep_len:2085 episode reward: total was -273.590000. running mean: -51.703163\n",
      "ep 18: ep_len:196 episode reward: total was 11.000000. running mean: -51.076131\n",
      "ep 18: ep_len:1226 episode reward: total was -136.960000. running mean: -51.934970\n",
      "ep 18: ep_len:800 episode reward: total was -63.090000. running mean: -52.046520\n",
      "ep 18: ep_len:500 episode reward: total was 10.270000. running mean: -51.423355\n",
      "ep 18: ep_len:860 episode reward: total was -9.550000. running mean: -51.004622\n",
      "ep 18: ep_len:545 episode reward: total was 8.430000. running mean: -50.410275\n",
      "ep 18: ep_len:294 episode reward: total was 15.500000. running mean: -49.751173\n",
      "ep 18: ep_len:535 episode reward: total was -21.200000. running mean: -49.465661\n",
      "ep 18: ep_len:500 episode reward: total was -5.800000. running mean: -49.029004\n",
      "ep 18: ep_len:2223 episode reward: total was -141.040000. running mean: -49.949114\n",
      "ep 18: ep_len:910 episode reward: total was -67.920000. running mean: -50.128823\n",
      "ep 18: ep_len:1790 episode reward: total was -228.820000. running mean: -51.915735\n",
      "ep 18: ep_len:575 episode reward: total was -0.940000. running mean: -51.405978\n",
      "ep 18: ep_len:535 episode reward: total was -64.800000. running mean: -51.539918\n",
      "ep 18: ep_len:525 episode reward: total was -26.270000. running mean: -51.287219\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 18: ep_len:500 episode reward: total was -21.390000. running mean: -50.988246\n",
      "ep 18: ep_len:735 episode reward: total was -16.450000. running mean: -50.642864\n",
      "ep 18: ep_len:710 episode reward: total was -9.180000. running mean: -50.228235\n",
      "ep 18: ep_len:795 episode reward: total was -9.180000. running mean: -49.817753\n",
      "ep 18: ep_len:262 episode reward: total was 9.500000. running mean: -49.224575\n",
      "ep 18: ep_len:500 episode reward: total was 12.750000. running mean: -48.604830\n",
      "ep 18: ep_len:805 episode reward: total was -3.650000. running mean: -48.155281\n",
      "ep 18: ep_len:625 episode reward: total was -117.470000. running mean: -48.848429\n",
      "ep 18: ep_len:500 episode reward: total was 14.770000. running mean: -48.212244\n",
      "ep 18: ep_len:705 episode reward: total was -37.020000. running mean: -48.100322\n",
      "ep 18: ep_len:720 episode reward: total was -33.800000. running mean: -47.957319\n",
      "ep 18: ep_len:500 episode reward: total was 21.230000. running mean: -47.265445\n",
      "ep 18: ep_len:500 episode reward: total was -9.050000. running mean: -46.883291\n",
      "ep 18: ep_len:500 episode reward: total was -17.310000. running mean: -46.587558\n",
      "ep 18: ep_len:500 episode reward: total was -10.680000. running mean: -46.228482\n",
      "ep 18: ep_len:505 episode reward: total was 18.790000. running mean: -45.578298\n",
      "ep 18: ep_len:610 episode reward: total was 14.260000. running mean: -44.979915\n",
      "ep 18: ep_len:505 episode reward: total was -5.790000. running mean: -44.588016\n",
      "ep 18: ep_len:500 episode reward: total was 38.000000. running mean: -43.762135\n",
      "ep 18: ep_len:745 episode reward: total was -21.270000. running mean: -43.537214\n",
      "ep 18: ep_len:890 episode reward: total was -48.770000. running mean: -43.589542\n",
      "ep 18: ep_len:273 episode reward: total was 19.500000. running mean: -42.958646\n",
      "ep 18: ep_len:625 episode reward: total was -23.040000. running mean: -42.759460\n",
      "ep 18: ep_len:830 episode reward: total was -146.340000. running mean: -43.795265\n",
      "ep 18: ep_len:2125 episode reward: total was -310.520000. running mean: -46.462513\n",
      "ep 18: ep_len:500 episode reward: total was -1.790000. running mean: -46.015788\n",
      "ep 18: ep_len:920 episode reward: total was -36.000000. running mean: -45.915630\n",
      "ep 18: ep_len:675 episode reward: total was 31.750000. running mean: -45.138973\n",
      "ep 18: ep_len:510 episode reward: total was -23.270000. running mean: -44.920284\n",
      "ep 18: ep_len:535 episode reward: total was -15.500000. running mean: -44.626081\n",
      "ep 18: ep_len:452 episode reward: total was 34.500000. running mean: -43.834820\n",
      "ep 18: ep_len:1210 episode reward: total was -231.920000. running mean: -45.715672\n",
      "ep 18: ep_len:875 episode reward: total was -27.190000. running mean: -45.530415\n",
      "ep 18: ep_len:500 episode reward: total was -17.260000. running mean: -45.247711\n",
      "ep 18: ep_len:224 episode reward: total was 11.500000. running mean: -44.680234\n",
      "ep 18: ep_len:500 episode reward: total was 11.250000. running mean: -44.120932\n",
      "ep 18: ep_len:494 episode reward: total was 18.700000. running mean: -43.492722\n",
      "ep 18: ep_len:1145 episode reward: total was -92.700000. running mean: -43.984795\n",
      "ep 18: ep_len:625 episode reward: total was -29.100000. running mean: -43.835947\n",
      "ep 18: ep_len:500 episode reward: total was -70.790000. running mean: -44.105488\n",
      "ep 18: ep_len:670 episode reward: total was -35.560000. running mean: -44.020033\n",
      "ep 18: ep_len:745 episode reward: total was -14.720000. running mean: -43.727032\n",
      "ep 18: ep_len:118 episode reward: total was 5.500000. running mean: -43.234762\n",
      "ep 18: ep_len:930 episode reward: total was -34.730000. running mean: -43.149714\n",
      "ep 18: ep_len:500 episode reward: total was 17.710000. running mean: -42.541117\n",
      "ep 18: ep_len:558 episode reward: total was -42.920000. running mean: -42.544906\n",
      "ep 18: ep_len:505 episode reward: total was -46.510000. running mean: -42.584557\n",
      "ep 18: ep_len:520 episode reward: total was -26.770000. running mean: -42.426411\n",
      "ep 18: ep_len:500 episode reward: total was -2.340000. running mean: -42.025547\n",
      "ep 18: ep_len:500 episode reward: total was -45.710000. running mean: -42.062392\n",
      "ep 18: ep_len:710 episode reward: total was -11.880000. running mean: -41.760568\n",
      "ep 18: ep_len:945 episode reward: total was 9.570000. running mean: -41.247262\n",
      "ep 18: ep_len:500 episode reward: total was -5.310000. running mean: -40.887890\n",
      "ep 18: ep_len:790 episode reward: total was -40.210000. running mean: -40.881111\n",
      "ep 18: ep_len:81 episode reward: total was 5.000000. running mean: -40.422300\n",
      "ep 18: ep_len:530 episode reward: total was -20.200000. running mean: -40.220077\n",
      "ep 18: ep_len:510 episode reward: total was -8.190000. running mean: -39.899776\n",
      "ep 18: ep_len:615 episode reward: total was -39.340000. running mean: -39.894178\n",
      "ep 18: ep_len:625 episode reward: total was -2.150000. running mean: -39.516736\n",
      "ep 18: ep_len:505 episode reward: total was -5.730000. running mean: -39.178869\n",
      "ep 18: ep_len:685 episode reward: total was -70.360000. running mean: -39.490680\n",
      "ep 18: ep_len:800 episode reward: total was -70.160000. running mean: -39.797374\n",
      "ep 18: ep_len:500 episode reward: total was 12.720000. running mean: -39.272200\n",
      "ep 18: ep_len:815 episode reward: total was -38.820000. running mean: -39.267678\n",
      "ep 18: ep_len:500 episode reward: total was -1.300000. running mean: -38.888001\n",
      "ep 18: ep_len:19745 episode reward: total was -2899.630000. running mean: -67.495421\n",
      "ep 18: ep_len:685 episode reward: total was -72.490000. running mean: -67.545367\n",
      "ep 18: ep_len:680 episode reward: total was -4.370000. running mean: -66.913613\n",
      "ep 18: ep_len:915 episode reward: total was 0.700000. running mean: -66.237477\n",
      "ep 18: ep_len:500 episode reward: total was -6.320000. running mean: -65.638302\n",
      "ep 18: ep_len:730 episode reward: total was -38.990000. running mean: -65.371819\n",
      "ep 18: ep_len:500 episode reward: total was -29.840000. running mean: -65.016501\n",
      "ep 18: ep_len:1080 episode reward: total was -43.440000. running mean: -64.800736\n",
      "ep 18: ep_len:500 episode reward: total was 6.660000. running mean: -64.086129\n",
      "ep 18: ep_len:500 episode reward: total was -33.450000. running mean: -63.779767\n",
      "ep 18: ep_len:828 episode reward: total was -75.140000. running mean: -63.893370\n",
      "ep 18: ep_len:620 episode reward: total was -31.130000. running mean: -63.565736\n",
      "ep 18: ep_len:248 episode reward: total was 9.500000. running mean: -62.835079\n",
      "ep 18: ep_len:535 episode reward: total was -40.360000. running mean: -62.610328\n",
      "ep 18: ep_len:129 episode reward: total was -5.500000. running mean: -62.039225\n",
      "ep 18: ep_len:500 episode reward: total was -9.470000. running mean: -61.513532\n",
      "ep 18: ep_len:500 episode reward: total was -18.350000. running mean: -61.081897\n",
      "ep 18: ep_len:500 episode reward: total was -13.610000. running mean: -60.607178\n",
      "ep 18: ep_len:500 episode reward: total was 10.210000. running mean: -59.899006\n",
      "ep 18: ep_len:730 episode reward: total was -36.970000. running mean: -59.669716\n",
      "ep 18: ep_len:182 episode reward: total was 16.500000. running mean: -58.908019\n",
      "ep 18: ep_len:850 episode reward: total was -58.950000. running mean: -58.908439\n",
      "ep 18: ep_len:865 episode reward: total was 16.530000. running mean: -58.154054\n",
      "ep 18: ep_len:745 episode reward: total was -41.790000. running mean: -57.990414\n",
      "ep 18: ep_len:1142 episode reward: total was -83.500000. running mean: -58.245510\n",
      "ep 18: ep_len:950 episode reward: total was -28.670000. running mean: -57.949755\n",
      "ep 18: ep_len:500 episode reward: total was -25.860000. running mean: -57.628857\n",
      "ep 18: ep_len:545 episode reward: total was -75.720000. running mean: -57.809769\n",
      "ep 18: ep_len:500 episode reward: total was -24.390000. running mean: -57.475571\n",
      "ep 18: ep_len:755 episode reward: total was -27.830000. running mean: -57.179115\n",
      "ep 18: ep_len:1550 episode reward: total was -254.500000. running mean: -59.152324\n",
      "ep 18: ep_len:725 episode reward: total was -34.440000. running mean: -58.905201\n",
      "ep 18: ep_len:760 episode reward: total was -33.880000. running mean: -58.654949\n",
      "ep 18: ep_len:96 episode reward: total was 8.000000. running mean: -57.988399\n",
      "ep 18: ep_len:500 episode reward: total was 12.270000. running mean: -57.285815\n",
      "ep 18: ep_len:885 episode reward: total was -58.360000. running mean: -57.296557\n",
      "ep 18: ep_len:505 episode reward: total was -15.220000. running mean: -56.875792\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 18: ep_len:253 episode reward: total was 14.500000. running mean: -56.162034\n",
      "ep 18: ep_len:765 episode reward: total was -21.060000. running mean: -55.811013\n",
      "ep 18: ep_len:505 episode reward: total was -1.810000. running mean: -55.271003\n",
      "ep 18: ep_len:500 episode reward: total was 9.180000. running mean: -54.626493\n",
      "ep 18: ep_len:1755 episode reward: total was -226.100000. running mean: -56.341228\n",
      "ep 18: ep_len:500 episode reward: total was -16.760000. running mean: -55.945416\n",
      "ep 18: ep_len:500 episode reward: total was -27.020000. running mean: -55.656162\n",
      "ep 18: ep_len:500 episode reward: total was -26.380000. running mean: -55.363400\n",
      "ep 18: ep_len:2360 episode reward: total was -356.880000. running mean: -58.378566\n",
      "ep 18: ep_len:500 episode reward: total was 2.680000. running mean: -57.767980\n",
      "ep 18: ep_len:500 episode reward: total was -9.990000. running mean: -57.290201\n",
      "ep 18: ep_len:1560 episode reward: total was -186.810000. running mean: -58.585399\n",
      "ep 18: ep_len:500 episode reward: total was -31.370000. running mean: -58.313245\n",
      "ep 18: ep_len:500 episode reward: total was -13.280000. running mean: -57.862912\n",
      "ep 18: ep_len:127 episode reward: total was 6.500000. running mean: -57.219283\n",
      "ep 18: ep_len:500 episode reward: total was 33.500000. running mean: -56.312090\n",
      "ep 18: ep_len:215 episode reward: total was 8.000000. running mean: -55.668969\n",
      "ep 18: ep_len:500 episode reward: total was -25.820000. running mean: -55.370480\n",
      "ep 18: ep_len:875 episode reward: total was -15.460000. running mean: -54.971375\n",
      "ep 18: ep_len:560 episode reward: total was -27.210000. running mean: -54.693761\n",
      "ep 18: ep_len:252 episode reward: total was 22.000000. running mean: -53.926824\n",
      "ep 18: ep_len:500 episode reward: total was -25.310000. running mean: -53.640655\n",
      "ep 18: ep_len:695 episode reward: total was -55.770000. running mean: -53.661949\n",
      "ep 18: ep_len:515 episode reward: total was -50.010000. running mean: -53.625429\n",
      "ep 18: ep_len:935 episode reward: total was -9.080000. running mean: -53.179975\n",
      "ep 18: ep_len:500 episode reward: total was -8.160000. running mean: -52.729775\n",
      "ep 18: ep_len:540 episode reward: total was -14.500000. running mean: -52.347477\n",
      "ep 18: ep_len:855 episode reward: total was -16.500000. running mean: -51.989003\n",
      "ep 18: ep_len:970 episode reward: total was -9.970000. running mean: -51.568813\n",
      "ep 18: ep_len:500 episode reward: total was -6.460000. running mean: -51.117725\n",
      "ep 18: ep_len:640 episode reward: total was -24.020000. running mean: -50.846747\n",
      "ep 18: ep_len:500 episode reward: total was -0.300000. running mean: -50.341280\n",
      "ep 18: ep_len:505 episode reward: total was 12.790000. running mean: -49.709967\n",
      "ep 18: ep_len:720 episode reward: total was 4.590000. running mean: -49.166967\n",
      "ep 18: ep_len:865 episode reward: total was -64.580000. running mean: -49.321098\n",
      "ep 18: ep_len:750 episode reward: total was -136.400000. running mean: -50.191887\n",
      "ep 18: ep_len:500 episode reward: total was -1.850000. running mean: -49.708468\n",
      "ep 18: ep_len:500 episode reward: total was -9.910000. running mean: -49.310483\n",
      "ep 18: ep_len:500 episode reward: total was -9.210000. running mean: -48.909478\n",
      "ep 18: ep_len:645 episode reward: total was -27.040000. running mean: -48.690784\n",
      "ep 18: ep_len:500 episode reward: total was -19.430000. running mean: -48.398176\n",
      "ep 18: ep_len:800 episode reward: total was -55.010000. running mean: -48.464294\n",
      "ep 18: ep_len:500 episode reward: total was 3.530000. running mean: -47.944351\n",
      "ep 18: ep_len:625 episode reward: total was -51.320000. running mean: -47.978107\n",
      "ep 18: ep_len:710 episode reward: total was -22.870000. running mean: -47.727026\n",
      "ep 18: ep_len:118 episode reward: total was 4.000000. running mean: -47.209756\n",
      "ep 18: ep_len:685 episode reward: total was -51.690000. running mean: -47.254559\n",
      "ep 18: ep_len:935 episode reward: total was -33.690000. running mean: -47.118913\n",
      "ep 18: ep_len:505 episode reward: total was 5.750000. running mean: -46.590224\n",
      "ep 18: ep_len:103 episode reward: total was 7.500000. running mean: -46.049322\n",
      "ep 18: ep_len:505 episode reward: total was 4.160000. running mean: -45.547228\n",
      "ep 18: ep_len:500 episode reward: total was 33.500000. running mean: -44.756756\n",
      "ep 18: ep_len:500 episode reward: total was -3.780000. running mean: -44.346989\n",
      "ep 18: ep_len:925 episode reward: total was -114.840000. running mean: -45.051919\n",
      "ep 18: ep_len:500 episode reward: total was -32.920000. running mean: -44.930599\n",
      "ep 18: ep_len:500 episode reward: total was 38.000000. running mean: -44.101293\n",
      "ep 18: ep_len:500 episode reward: total was -18.850000. running mean: -43.848781\n",
      "ep 18: ep_len:500 episode reward: total was -6.910000. running mean: -43.479393\n",
      "ep 18: ep_len:55 episode reward: total was 1.000000. running mean: -43.034599\n",
      "ep 18: ep_len:505 episode reward: total was 34.500000. running mean: -42.259253\n",
      "ep 18: ep_len:500 episode reward: total was -18.270000. running mean: -42.019360\n",
      "ep 18: ep_len:500 episode reward: total was 7.640000. running mean: -41.522767\n",
      "ep 18: ep_len:605 episode reward: total was -10.270000. running mean: -41.210239\n",
      "ep 18: ep_len:505 episode reward: total was -34.740000. running mean: -41.145537\n",
      "ep 18: ep_len:860 episode reward: total was -12.400000. running mean: -40.858081\n",
      "ep 18: ep_len:276 episode reward: total was 21.500000. running mean: -40.234500\n",
      "ep 18: ep_len:745 episode reward: total was -24.820000. running mean: -40.080355\n",
      "ep 18: ep_len:246 episode reward: total was 14.000000. running mean: -39.539552\n",
      "ep 18: ep_len:1155 episode reward: total was -109.970000. running mean: -40.243856\n",
      "ep 18: ep_len:500 episode reward: total was -10.970000. running mean: -39.951118\n",
      "ep 18: ep_len:1705 episode reward: total was -227.890000. running mean: -41.830507\n",
      "ep 18: ep_len:500 episode reward: total was 11.250000. running mean: -41.299702\n",
      "ep 18: ep_len:500 episode reward: total was -1.290000. running mean: -40.899605\n",
      "ep 18: ep_len:665 episode reward: total was -24.980000. running mean: -40.740409\n",
      "ep 18: ep_len:790 episode reward: total was -35.840000. running mean: -40.691404\n",
      "ep 18: ep_len:705 episode reward: total was -18.840000. running mean: -40.472890\n",
      "ep 18: ep_len:570 episode reward: total was -38.300000. running mean: -40.451161\n",
      "ep 18: ep_len:590 episode reward: total was -32.200000. running mean: -40.368650\n",
      "ep 18: ep_len:505 episode reward: total was -44.030000. running mean: -40.405263\n",
      "ep 18: ep_len:500 episode reward: total was 4.890000. running mean: -39.952311\n",
      "ep 18: ep_len:500 episode reward: total was -10.180000. running mean: -39.654588\n",
      "ep 18: ep_len:4175 episode reward: total was -729.980000. running mean: -46.557842\n",
      "ep 18: ep_len:580 episode reward: total was -2.280000. running mean: -46.115063\n",
      "ep 18: ep_len:820 episode reward: total was -24.360000. running mean: -45.897513\n",
      "ep 18: ep_len:500 episode reward: total was 2.250000. running mean: -45.416038\n",
      "ep 18: ep_len:1135 episode reward: total was -143.220000. running mean: -46.394077\n",
      "ep 18: ep_len:151 episode reward: total was 7.500000. running mean: -45.855136\n",
      "ep 18: ep_len:500 episode reward: total was 6.440000. running mean: -45.332185\n",
      "ep 18: ep_len:364 episode reward: total was 15.000000. running mean: -44.728863\n",
      "ep 18: ep_len:805 episode reward: total was -10.560000. running mean: -44.387175\n",
      "ep 18: ep_len:735 episode reward: total was -35.430000. running mean: -44.297603\n",
      "ep 18: ep_len:500 episode reward: total was -1.550000. running mean: -43.870127\n",
      "ep 18: ep_len:500 episode reward: total was 2.770000. running mean: -43.403726\n",
      "ep 18: ep_len:1092 episode reward: total was -83.900000. running mean: -43.808688\n",
      "ep 18: ep_len:560 episode reward: total was -21.640000. running mean: -43.587001\n",
      "ep 18: ep_len:195 episode reward: total was 13.500000. running mean: -43.016131\n",
      "ep 18: ep_len:990 episode reward: total was -30.440000. running mean: -42.890370\n",
      "ep 18: ep_len:374 episode reward: total was 28.000000. running mean: -42.181466\n",
      "ep 18: ep_len:700 episode reward: total was -25.920000. running mean: -42.018852\n",
      "ep 18: ep_len:570 episode reward: total was -13.050000. running mean: -41.729163\n",
      "ep 18: ep_len:505 episode reward: total was -44.210000. running mean: -41.753972\n",
      "ep 18: ep_len:410 episode reward: total was 8.250000. running mean: -41.253932\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 18: ep_len:500 episode reward: total was -2.800000. running mean: -40.869393\n",
      "ep 18: ep_len:500 episode reward: total was 18.230000. running mean: -40.278399\n",
      "ep 18: ep_len:500 episode reward: total was 7.730000. running mean: -39.798315\n",
      "ep 18: ep_len:500 episode reward: total was -3.210000. running mean: -39.432431\n",
      "ep 18: ep_len:500 episode reward: total was 3.730000. running mean: -39.000807\n",
      "ep 18: ep_len:500 episode reward: total was -5.870000. running mean: -38.669499\n",
      "ep 18: ep_len:560 episode reward: total was -33.270000. running mean: -38.615504\n",
      "ep 18: ep_len:635 episode reward: total was -16.190000. running mean: -38.391249\n",
      "ep 18: ep_len:685 episode reward: total was -46.390000. running mean: -38.471237\n",
      "ep 18: ep_len:700 episode reward: total was -40.060000. running mean: -38.487124\n",
      "ep 18: ep_len:500 episode reward: total was -9.880000. running mean: -38.201053\n",
      "ep 18: ep_len:1280 episode reward: total was -91.420000. running mean: -38.733242\n",
      "ep 18: ep_len:500 episode reward: total was 17.300000. running mean: -38.172910\n",
      "ep 18: ep_len:745 episode reward: total was -29.350000. running mean: -38.084681\n",
      "ep 18: ep_len:690 episode reward: total was -15.840000. running mean: -37.862234\n",
      "ep 18: ep_len:505 episode reward: total was 7.400000. running mean: -37.409612\n",
      "ep 18: ep_len:520 episode reward: total was -12.140000. running mean: -37.156916\n",
      "ep 18: ep_len:895 episode reward: total was -13.980000. running mean: -36.925146\n",
      "ep 18: ep_len:565 episode reward: total was -20.130000. running mean: -36.757195\n",
      "ep 18: ep_len:198 episode reward: total was 12.000000. running mean: -36.269623\n",
      "ep 18: ep_len:1000 episode reward: total was -19.570000. running mean: -36.102627\n",
      "ep 18: ep_len:600 episode reward: total was -27.130000. running mean: -36.012901\n",
      "ep 18: ep_len:500 episode reward: total was -35.440000. running mean: -36.007172\n",
      "ep 18: ep_len:500 episode reward: total was -2.960000. running mean: -35.676700\n",
      "ep 18: ep_len:500 episode reward: total was -6.210000. running mean: -35.382033\n",
      "ep 18: ep_len:44 episode reward: total was 1.000000. running mean: -35.018213\n",
      "ep 18: ep_len:500 episode reward: total was -3.230000. running mean: -34.700330\n",
      "ep 18: ep_len:795 episode reward: total was -26.540000. running mean: -34.618727\n",
      "ep 18: ep_len:1511 episode reward: total was -200.670000. running mean: -36.279240\n",
      "ep 18: ep_len:1130 episode reward: total was -26.820000. running mean: -36.184647\n",
      "ep 18: ep_len:505 episode reward: total was 22.750000. running mean: -35.595301\n",
      "ep 18: ep_len:249 episode reward: total was 21.500000. running mean: -35.024348\n",
      "ep 18: ep_len:775 episode reward: total was -23.880000. running mean: -34.912904\n",
      "ep 18: ep_len:595 episode reward: total was -72.120000. running mean: -35.284975\n",
      "ep 18: ep_len:510 episode reward: total was -24.770000. running mean: -35.179826\n",
      "ep 18: ep_len:505 episode reward: total was -19.240000. running mean: -35.020427\n",
      "ep 18: ep_len:172 episode reward: total was 12.500000. running mean: -34.545223\n",
      "ep 18: ep_len:570 episode reward: total was 0.080000. running mean: -34.198971\n",
      "ep 18: ep_len:955 episode reward: total was -23.520000. running mean: -34.092181\n",
      "ep 18: ep_len:745 episode reward: total was 0.660000. running mean: -33.744659\n",
      "ep 18: ep_len:226 episode reward: total was 12.000000. running mean: -33.287213\n",
      "ep 18: ep_len:194 episode reward: total was 1.500000. running mean: -32.939341\n",
      "ep 18: ep_len:500 episode reward: total was 5.390000. running mean: -32.556047\n",
      "ep 18: ep_len:655 episode reward: total was -16.400000. running mean: -32.394487\n",
      "ep 18: ep_len:780 episode reward: total was 6.700000. running mean: -32.003542\n",
      "ep 18: ep_len:500 episode reward: total was -2.280000. running mean: -31.706306\n",
      "ep 18: ep_len:660 episode reward: total was -12.870000. running mean: -31.517943\n",
      "ep 18: ep_len:500 episode reward: total was 8.740000. running mean: -31.115364\n",
      "ep 18: ep_len:500 episode reward: total was -22.370000. running mean: -31.027910\n",
      "ep 18: ep_len:500 episode reward: total was -5.930000. running mean: -30.776931\n",
      "ep 18: ep_len:520 episode reward: total was -29.310000. running mean: -30.762262\n",
      "ep 18: ep_len:510 episode reward: total was -18.220000. running mean: -30.636839\n",
      "ep 18: ep_len:655 episode reward: total was -46.210000. running mean: -30.792571\n",
      "ep 18: ep_len:1265 episode reward: total was -182.350000. running mean: -32.308145\n",
      "ep 18: ep_len:500 episode reward: total was 25.790000. running mean: -31.727164\n",
      "ep 18: ep_len:575 episode reward: total was -4.830000. running mean: -31.458192\n",
      "ep 18: ep_len:845 episode reward: total was -8.690000. running mean: -31.230510\n",
      "ep 18: ep_len:338 episode reward: total was 8.010000. running mean: -30.838105\n",
      "ep 18: ep_len:166 episode reward: total was 15.000000. running mean: -30.379724\n",
      "ep 18: ep_len:147 episode reward: total was 10.000000. running mean: -29.975927\n",
      "ep 18: ep_len:625 episode reward: total was -37.150000. running mean: -30.047668\n",
      "ep 18: ep_len:1065 episode reward: total was -77.190000. running mean: -30.519091\n",
      "ep 18: ep_len:505 episode reward: total was -3.730000. running mean: -30.251200\n",
      "ep 18: ep_len:545 episode reward: total was 11.950000. running mean: -29.829188\n",
      "ep 18: ep_len:1080 episode reward: total was -184.760000. running mean: -31.378496\n",
      "ep 18: ep_len:775 episode reward: total was -79.270000. running mean: -31.857411\n",
      "ep 18: ep_len:1460 episode reward: total was -151.660000. running mean: -33.055437\n",
      "ep 18: ep_len:730 episode reward: total was -19.800000. running mean: -32.922883\n",
      "ep 18: ep_len:500 episode reward: total was -16.770000. running mean: -32.761354\n",
      "ep 18: ep_len:775 episode reward: total was 13.180000. running mean: -32.301940\n",
      "ep 18: ep_len:545 episode reward: total was -25.710000. running mean: -32.236021\n",
      "ep 18: ep_len:357 episode reward: total was 14.500000. running mean: -31.768661\n",
      "ep 18: ep_len:277 episode reward: total was 14.500000. running mean: -31.305974\n",
      "ep 18: ep_len:1005 episode reward: total was -58.640000. running mean: -31.579314\n",
      "ep 18: ep_len:500 episode reward: total was -5.200000. running mean: -31.315521\n",
      "ep 18: ep_len:500 episode reward: total was -19.370000. running mean: -31.196066\n",
      "ep 18: ep_len:550 episode reward: total was -32.280000. running mean: -31.206905\n",
      "ep 18: ep_len:186 episode reward: total was 17.000000. running mean: -30.724836\n",
      "ep 18: ep_len:1451 episode reward: total was -226.170000. running mean: -32.679288\n",
      "ep 18: ep_len:860 episode reward: total was -52.180000. running mean: -32.874295\n",
      "ep 18: ep_len:500 episode reward: total was 5.230000. running mean: -32.493252\n",
      "ep 18: ep_len:855 episode reward: total was -59.830000. running mean: -32.766620\n",
      "ep 18: ep_len:665 episode reward: total was -40.130000. running mean: -32.840253\n",
      "ep 18: ep_len:236 episode reward: total was 16.000000. running mean: -32.351851\n",
      "ep 18: ep_len:383 episode reward: total was 27.500000. running mean: -31.753332\n",
      "ep 18: ep_len:307 episode reward: total was 16.000000. running mean: -31.275799\n",
      "ep 18: ep_len:895 episode reward: total was -68.860000. running mean: -31.651641\n",
      "ep 18: ep_len:695 episode reward: total was -2.680000. running mean: -31.361925\n",
      "ep 18: ep_len:237 episode reward: total was 14.500000. running mean: -30.903305\n",
      "ep 18: ep_len:500 episode reward: total was 3.220000. running mean: -30.562072\n",
      "ep 18: ep_len:500 episode reward: total was -4.290000. running mean: -30.299352\n",
      "ep 18: ep_len:116 episode reward: total was 9.000000. running mean: -29.906358\n",
      "ep 18: ep_len:500 episode reward: total was -46.350000. running mean: -30.070794\n",
      "ep 18: ep_len:500 episode reward: total was 16.790000. running mean: -29.602187\n",
      "ep 18: ep_len:500 episode reward: total was -2.280000. running mean: -29.328965\n",
      "ep 18: ep_len:454 episode reward: total was -4.800000. running mean: -29.083675\n",
      "ep 18: ep_len:845 episode reward: total was -37.750000. running mean: -29.170338\n",
      "ep 18: ep_len:655 episode reward: total was -27.810000. running mean: -29.156735\n",
      "ep 18: ep_len:520 episode reward: total was -16.180000. running mean: -29.026968\n",
      "ep 18: ep_len:500 episode reward: total was -6.350000. running mean: -28.800198\n",
      "ep 18: ep_len:1105 episode reward: total was -16.250000. running mean: -28.674696\n",
      "ep 18: ep_len:505 episode reward: total was -23.280000. running mean: -28.620749\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 18: ep_len:725 episode reward: total was -20.320000. running mean: -28.537741\n",
      "ep 18: ep_len:715 episode reward: total was -19.150000. running mean: -28.443864\n",
      "ep 18: ep_len:675 episode reward: total was -31.810000. running mean: -28.477525\n",
      "ep 18: ep_len:358 episode reward: total was -3.280000. running mean: -28.225550\n",
      "ep 18: ep_len:1200 episode reward: total was -24.930000. running mean: -28.192595\n",
      "ep 18: ep_len:500 episode reward: total was -11.760000. running mean: -28.028269\n",
      "ep 18: ep_len:835 episode reward: total was -21.560000. running mean: -27.963586\n",
      "ep 18: ep_len:168 episode reward: total was 15.000000. running mean: -27.533950\n",
      "ep 18: ep_len:755 episode reward: total was -23.290000. running mean: -27.491511\n",
      "ep 18: ep_len:515 episode reward: total was -23.780000. running mean: -27.454396\n",
      "ep 18: ep_len:855 episode reward: total was -8.220000. running mean: -27.262052\n",
      "ep 18: ep_len:505 episode reward: total was 9.730000. running mean: -26.892131\n",
      "ep 18: ep_len:344 episode reward: total was 17.500000. running mean: -26.448210\n",
      "ep 18: ep_len:500 episode reward: total was -9.730000. running mean: -26.281028\n",
      "ep 18: ep_len:505 episode reward: total was 17.750000. running mean: -25.840717\n",
      "ep 18: ep_len:212 episode reward: total was 15.000000. running mean: -25.432310\n",
      "ep 18: ep_len:317 episode reward: total was -10.860000. running mean: -25.286587\n",
      "ep 18: ep_len:1000 episode reward: total was -117.200000. running mean: -26.205721\n",
      "ep 18: ep_len:1110 episode reward: total was -38.220000. running mean: -26.325864\n",
      "ep 18: ep_len:500 episode reward: total was -8.800000. running mean: -26.150605\n",
      "ep 18: ep_len:240 episode reward: total was 15.000000. running mean: -25.739099\n",
      "ep 18: ep_len:555 episode reward: total was -15.100000. running mean: -25.632708\n",
      "ep 18: ep_len:910 episode reward: total was -6.300000. running mean: -25.439381\n",
      "ep 18: ep_len:835 episode reward: total was -47.070000. running mean: -25.655687\n",
      "ep 18: ep_len:1100 episode reward: total was -13.010000. running mean: -25.529231\n",
      "ep 18: ep_len:795 episode reward: total was -57.640000. running mean: -25.850338\n",
      "ep 18: ep_len:255 episode reward: total was 16.500000. running mean: -25.426835\n",
      "ep 18: ep_len:500 episode reward: total was 4.730000. running mean: -25.125267\n",
      "ep 18: ep_len:500 episode reward: total was -16.140000. running mean: -25.035414\n",
      "ep 18: ep_len:500 episode reward: total was -43.000000. running mean: -25.215060\n",
      "ep 18: ep_len:1035 episode reward: total was -131.300000. running mean: -26.275909\n",
      "ep 18: ep_len:500 episode reward: total was 13.790000. running mean: -25.875250\n",
      "ep 18: ep_len:675 episode reward: total was -13.850000. running mean: -25.754998\n",
      "ep 18: ep_len:755 episode reward: total was 1.810000. running mean: -25.479348\n",
      "ep 18: ep_len:620 episode reward: total was -26.230000. running mean: -25.486854\n",
      "ep 18: ep_len:500 episode reward: total was -16.280000. running mean: -25.394786\n",
      "ep 18: ep_len:515 episode reward: total was -11.210000. running mean: -25.252938\n",
      "ep 18: ep_len:560 episode reward: total was -72.660000. running mean: -25.727008\n",
      "ep 18: ep_len:665 episode reward: total was -10.380000. running mean: -25.573538\n",
      "ep 18: ep_len:630 episode reward: total was 10.680000. running mean: -25.211003\n",
      "ep 18: ep_len:500 episode reward: total was 7.330000. running mean: -24.885593\n",
      "ep 18: ep_len:640 episode reward: total was -14.720000. running mean: -24.783937\n",
      "ep 18: ep_len:442 episode reward: total was -80.930000. running mean: -25.345397\n",
      "ep 18: ep_len:560 episode reward: total was -18.620000. running mean: -25.278144\n",
      "ep 18: ep_len:505 episode reward: total was -72.770000. running mean: -25.753062\n",
      "ep 18: ep_len:500 episode reward: total was 16.730000. running mean: -25.328231\n",
      "ep 18: ep_len:935 episode reward: total was -93.260000. running mean: -26.007549\n",
      "ep 18: ep_len:675 episode reward: total was -11.830000. running mean: -25.865774\n",
      "ep 18: ep_len:500 episode reward: total was 2.680000. running mean: -25.580316\n",
      "ep 18: ep_len:625 episode reward: total was -45.230000. running mean: -25.776813\n",
      "ep 18: ep_len:500 episode reward: total was -6.270000. running mean: -25.581745\n",
      "ep 18: ep_len:500 episode reward: total was 1.670000. running mean: -25.309227\n",
      "ep 18: ep_len:231 episode reward: total was 12.500000. running mean: -24.931135\n",
      "ep 18: ep_len:950 episode reward: total was 20.880000. running mean: -24.473024\n",
      "ep 18: ep_len:750 episode reward: total was -61.170000. running mean: -24.839993\n",
      "ep 18: ep_len:500 episode reward: total was -7.700000. running mean: -24.668593\n",
      "ep 18: ep_len:500 episode reward: total was -4.640000. running mean: -24.468307\n",
      "ep 18: ep_len:647 episode reward: total was -62.370000. running mean: -24.847324\n",
      "ep 18: ep_len:560 episode reward: total was -0.210000. running mean: -24.600951\n",
      "ep 18: ep_len:505 episode reward: total was -19.240000. running mean: -24.547342\n",
      "ep 18: ep_len:1470 episode reward: total was -97.100000. running mean: -25.272868\n",
      "ep 18: ep_len:1075 episode reward: total was -207.470000. running mean: -27.094840\n",
      "ep 18: ep_len:965 episode reward: total was -23.110000. running mean: -27.054991\n",
      "ep 18: ep_len:695 episode reward: total was -19.870000. running mean: -26.983141\n",
      "ep 18: ep_len:381 episode reward: total was 30.500000. running mean: -26.408310\n",
      "ep 18: ep_len:505 episode reward: total was -0.320000. running mean: -26.147427\n",
      "ep 18: ep_len:1715 episode reward: total was -88.120000. running mean: -26.767152\n",
      "ep 18: ep_len:910 episode reward: total was 0.060000. running mean: -26.498881\n",
      "ep 18: ep_len:500 episode reward: total was 39.500000. running mean: -25.838892\n",
      "ep 18: ep_len:930 episode reward: total was -50.460000. running mean: -26.085103\n",
      "ep 18: ep_len:1010 episode reward: total was -24.070000. running mean: -26.064952\n",
      "ep 18: ep_len:500 episode reward: total was 6.330000. running mean: -25.741003\n",
      "ep 18: ep_len:145 episode reward: total was 10.000000. running mean: -25.383593\n",
      "ep 18: ep_len:1040 episode reward: total was -5.850000. running mean: -25.188257\n",
      "ep 18: ep_len:760 episode reward: total was -32.840000. running mean: -25.264774\n",
      "ep 18: ep_len:930 episode reward: total was -5.310000. running mean: -25.065226\n",
      "ep 18: ep_len:1180 episode reward: total was -137.070000. running mean: -26.185274\n",
      "ep 18: ep_len:256 episode reward: total was 21.000000. running mean: -25.713421\n",
      "ep 18: ep_len:505 episode reward: total was 13.710000. running mean: -25.319187\n",
      "ep 18: ep_len:945 episode reward: total was -40.580000. running mean: -25.471795\n",
      "ep 18: ep_len:500 episode reward: total was -4.490000. running mean: -25.261977\n",
      "ep 18: ep_len:1870 episode reward: total was -75.180000. running mean: -25.761158\n",
      "ep 18: ep_len:1145 episode reward: total was -30.470000. running mean: -25.808246\n",
      "ep 18: ep_len:500 episode reward: total was 2.490000. running mean: -25.525264\n",
      "ep 18: ep_len:137 episode reward: total was 9.000000. running mean: -25.180011\n",
      "ep 18: ep_len:500 episode reward: total was -2.380000. running mean: -24.952011\n",
      "ep 18: ep_len:500 episode reward: total was 8.060000. running mean: -24.621891\n",
      "ep 18: ep_len:500 episode reward: total was 4.170000. running mean: -24.333972\n",
      "ep 18: ep_len:500 episode reward: total was -10.190000. running mean: -24.192532\n",
      "ep 18: ep_len:580 episode reward: total was -31.210000. running mean: -24.262707\n",
      "ep 18: ep_len:860 episode reward: total was -29.270000. running mean: -24.312780\n",
      "ep 18: ep_len:750 episode reward: total was 20.630000. running mean: -23.863352\n",
      "ep 18: ep_len:500 episode reward: total was 41.500000. running mean: -23.209718\n",
      "ep 18: ep_len:1695 episode reward: total was -173.980000. running mean: -24.717421\n",
      "ep 18: ep_len:500 episode reward: total was -41.760000. running mean: -24.887847\n",
      "ep 18: ep_len:504 episode reward: total was -35.130000. running mean: -24.990268\n",
      "ep 18: ep_len:1010 episode reward: total was -79.840000. running mean: -25.538766\n",
      "ep 18: ep_len:615 episode reward: total was 4.750000. running mean: -25.235878\n",
      "ep 18: ep_len:960 episode reward: total was -9.940000. running mean: -25.082919\n",
      "ep 18: ep_len:910 episode reward: total was -25.500000. running mean: -25.087090\n",
      "ep 18: ep_len:500 episode reward: total was -23.320000. running mean: -25.069419\n",
      "ep 18: ep_len:890 episode reward: total was 4.100000. running mean: -24.777725\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 18: ep_len:780 episode reward: total was -7.840000. running mean: -24.608348\n",
      "ep 18: ep_len:180 episode reward: total was 10.500000. running mean: -24.257264\n",
      "ep 18: ep_len:835 episode reward: total was -8.380000. running mean: -24.098492\n",
      "ep 18: ep_len:755 episode reward: total was -27.060000. running mean: -24.128107\n",
      "ep 18: ep_len:1225 episode reward: total was -226.840000. running mean: -26.155226\n",
      "ep 18: ep_len:700 episode reward: total was -57.230000. running mean: -26.465973\n",
      "ep 18: ep_len:1030 episode reward: total was -15.180000. running mean: -26.353114\n",
      "ep 18: ep_len:670 episode reward: total was 1.980000. running mean: -26.069783\n",
      "ep 18: ep_len:505 episode reward: total was -14.220000. running mean: -25.951285\n",
      "ep 18: ep_len:1000 episode reward: total was -11.860000. running mean: -25.810372\n",
      "ep 18: ep_len:9925 episode reward: total was -1933.590000. running mean: -44.888168\n",
      "ep 18: ep_len:770 episode reward: total was -15.280000. running mean: -44.592087\n",
      "ep 18: ep_len:500 episode reward: total was -37.950000. running mean: -44.525666\n",
      "ep 18: ep_len:650 episode reward: total was -24.240000. running mean: -44.322809\n",
      "ep 18: ep_len:580 episode reward: total was -20.180000. running mean: -44.081381\n",
      "ep 18: ep_len:535 episode reward: total was -13.120000. running mean: -43.771767\n",
      "ep 18: ep_len:1105 episode reward: total was -40.260000. running mean: -43.736649\n",
      "ep 18: ep_len:500 episode reward: total was -10.790000. running mean: -43.407183\n",
      "ep 18: ep_len:500 episode reward: total was 9.690000. running mean: -42.876211\n",
      "ep 18: ep_len:590 episode reward: total was -76.290000. running mean: -43.210349\n",
      "ep 18: ep_len:500 episode reward: total was 7.760000. running mean: -42.700645\n",
      "ep 18: ep_len:545 episode reward: total was -27.240000. running mean: -42.546039\n",
      "ep 18: ep_len:505 episode reward: total was 1.280000. running mean: -42.107779\n",
      "ep 18: ep_len:710 episode reward: total was -9.740000. running mean: -41.784101\n",
      "ep 18: ep_len:500 episode reward: total was 11.340000. running mean: -41.252860\n",
      "ep 18: ep_len:190 episode reward: total was 11.500000. running mean: -40.725331\n",
      "ep 18: ep_len:500 episode reward: total was -59.370000. running mean: -40.911778\n",
      "ep 18: ep_len:500 episode reward: total was 1.120000. running mean: -40.491460\n",
      "ep 18: ep_len:585 episode reward: total was -57.460000. running mean: -40.661146\n",
      "ep 18: ep_len:620 episode reward: total was -56.870000. running mean: -40.823234\n",
      "ep 18: ep_len:965 episode reward: total was -46.240000. running mean: -40.877402\n",
      "ep 18: ep_len:500 episode reward: total was 15.290000. running mean: -40.315728\n",
      "ep 18: ep_len:1020 episode reward: total was -53.230000. running mean: -40.444870\n",
      "ep 18: ep_len:500 episode reward: total was -10.540000. running mean: -40.145822\n",
      "ep 18: ep_len:525 episode reward: total was -8.180000. running mean: -39.826164\n",
      "ep 18: ep_len:500 episode reward: total was -11.930000. running mean: -39.547202\n",
      "ep 18: ep_len:735 episode reward: total was -117.730000. running mean: -40.329030\n",
      "ep 18: ep_len:515 episode reward: total was -7.100000. running mean: -39.996740\n",
      "ep 18: ep_len:500 episode reward: total was 11.800000. running mean: -39.478772\n",
      "ep 18: ep_len:500 episode reward: total was -4.340000. running mean: -39.127384\n",
      "ep 18: ep_len:505 episode reward: total was -61.170000. running mean: -39.347811\n",
      "ep 18: ep_len:500 episode reward: total was 14.280000. running mean: -38.811533\n",
      "ep 18: ep_len:510 episode reward: total was -33.370000. running mean: -38.757117\n",
      "ep 18: ep_len:515 episode reward: total was -30.300000. running mean: -38.672546\n",
      "ep 18: ep_len:245 episode reward: total was 14.000000. running mean: -38.145821\n",
      "ep 18: ep_len:570 episode reward: total was -21.100000. running mean: -37.975362\n",
      "ep 18: ep_len:1120 episode reward: total was 5.900000. running mean: -37.536609\n",
      "ep 18: ep_len:860 episode reward: total was 0.470000. running mean: -37.156543\n",
      "ep 18: ep_len:635 episode reward: total was -35.370000. running mean: -37.138677\n",
      "ep 18: ep_len:1085 episode reward: total was -98.940000. running mean: -37.756690\n",
      "ep 18: ep_len:500 episode reward: total was 19.240000. running mean: -37.186724\n",
      "ep 18: ep_len:785 episode reward: total was -25.560000. running mean: -37.070456\n",
      "ep 18: ep_len:500 episode reward: total was 14.750000. running mean: -36.552252\n",
      "ep 18: ep_len:975 episode reward: total was -5.220000. running mean: -36.238929\n",
      "ep 18: ep_len:500 episode reward: total was 5.930000. running mean: -35.817240\n",
      "ep 18: ep_len:1670 episode reward: total was -89.710000. running mean: -36.356168\n",
      "ep 18: ep_len:630 episode reward: total was -55.350000. running mean: -36.546106\n",
      "ep 18: ep_len:725 episode reward: total was -22.840000. running mean: -36.409045\n",
      "ep 18: ep_len:258 episode reward: total was 7.500000. running mean: -35.969954\n",
      "ep 18: ep_len:500 episode reward: total was -12.170000. running mean: -35.731955\n",
      "ep 18: ep_len:565 episode reward: total was 5.590000. running mean: -35.318735\n",
      "ep 18: ep_len:42315 episode reward: total was -8284.460000. running mean: -117.810148\n",
      "ep 18: ep_len:750 episode reward: total was -57.130000. running mean: -117.203346\n",
      "ep 18: ep_len:705 episode reward: total was -68.330000. running mean: -116.714613\n",
      "ep 18: ep_len:615 episode reward: total was -53.360000. running mean: -116.081067\n",
      "ep 18: ep_len:1940 episode reward: total was -269.880000. running mean: -117.619056\n",
      "ep 18: ep_len:670 episode reward: total was -73.080000. running mean: -117.173666\n",
      "ep 18: ep_len:525 episode reward: total was -32.890000. running mean: -116.330829\n",
      "ep 18: ep_len:825 episode reward: total was -135.240000. running mean: -116.519921\n",
      "ep 18: ep_len:580 episode reward: total was -76.630000. running mean: -116.121021\n",
      "ep 18: ep_len:505 episode reward: total was 14.640000. running mean: -114.813411\n",
      "ep 18: ep_len:500 episode reward: total was -3.840000. running mean: -113.703677\n",
      "ep 18: ep_len:500 episode reward: total was -0.050000. running mean: -112.567140\n",
      "ep 18: ep_len:1175 episode reward: total was -55.560000. running mean: -111.997069\n",
      "ep 18: ep_len:161 episode reward: total was 13.000000. running mean: -110.747098\n",
      "ep 18: ep_len:505 episode reward: total was -14.890000. running mean: -109.788527\n",
      "ep 18: ep_len:500 episode reward: total was 10.260000. running mean: -108.588042\n",
      "ep 18: ep_len:1222 episode reward: total was -94.550000. running mean: -108.447662\n",
      "ep 18: ep_len:500 episode reward: total was 10.800000. running mean: -107.255185\n",
      "ep 18: ep_len:710 episode reward: total was -15.720000. running mean: -106.339833\n",
      "ep 18: ep_len:500 episode reward: total was -69.810000. running mean: -105.974535\n",
      "ep 18: ep_len:590 episode reward: total was -59.670000. running mean: -105.511489\n",
      "ep 18: ep_len:2065 episode reward: total was -353.460000. running mean: -107.990975\n",
      "ep 18: ep_len:500 episode reward: total was 4.090000. running mean: -106.870165\n",
      "ep 18: ep_len:680 episode reward: total was -46.090000. running mean: -106.262363\n",
      "ep 18: ep_len:500 episode reward: total was 1.740000. running mean: -105.182340\n",
      "ep 18: ep_len:1862 episode reward: total was -329.090000. running mean: -107.421416\n",
      "ep 18: ep_len:735 episode reward: total was -5.420000. running mean: -106.401402\n",
      "ep 18: ep_len:725 episode reward: total was -79.370000. running mean: -106.131088\n",
      "ep 18: ep_len:1385 episode reward: total was -69.480000. running mean: -105.764577\n",
      "ep 18: ep_len:650 episode reward: total was -56.870000. running mean: -105.275631\n",
      "ep 18: ep_len:545 episode reward: total was -30.270000. running mean: -104.525575\n",
      "ep 18: ep_len:500 episode reward: total was 16.180000. running mean: -103.318519\n",
      "ep 18: ep_len:500 episode reward: total was -18.330000. running mean: -102.468634\n",
      "ep 18: ep_len:500 episode reward: total was -5.500000. running mean: -101.498948\n",
      "ep 18: ep_len:1360 episode reward: total was -168.020000. running mean: -102.164158\n",
      "ep 18: ep_len:980 episode reward: total was -84.950000. running mean: -101.992017\n",
      "ep 18: ep_len:500 episode reward: total was -25.360000. running mean: -101.225696\n",
      "ep 18: ep_len:500 episode reward: total was -66.700000. running mean: -100.880440\n",
      "ep 18: ep_len:960 episode reward: total was -49.360000. running mean: -100.365235\n",
      "ep 18: ep_len:510 episode reward: total was -19.230000. running mean: -99.553883\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 18: ep_len:426 episode reward: total was -14.250000. running mean: -98.700844\n",
      "ep 18: ep_len:535 episode reward: total was -31.790000. running mean: -98.031736\n",
      "ep 18: ep_len:835 episode reward: total was -19.130000. running mean: -97.242718\n",
      "ep 18: ep_len:685 episode reward: total was -11.880000. running mean: -96.389091\n",
      "ep 18: ep_len:122 episode reward: total was 9.000000. running mean: -95.335200\n",
      "ep 18: ep_len:540 episode reward: total was -30.250000. running mean: -94.684348\n",
      "ep 18: ep_len:500 episode reward: total was -4.730000. running mean: -93.784805\n",
      "ep 18: ep_len:500 episode reward: total was 6.960000. running mean: -92.777357\n",
      "ep 18: ep_len:710 episode reward: total was -57.390000. running mean: -92.423483\n",
      "ep 18: ep_len:685 episode reward: total was -11.290000. running mean: -91.612148\n",
      "ep 18: ep_len:615 episode reward: total was -28.110000. running mean: -90.977127\n",
      "ep 18: ep_len:1045 episode reward: total was -112.090000. running mean: -91.188255\n",
      "ep 18: ep_len:148 episode reward: total was 8.500000. running mean: -90.191373\n",
      "ep 18: ep_len:567 episode reward: total was -42.590000. running mean: -89.715359\n",
      "ep 18: ep_len:975 episode reward: total was -43.850000. running mean: -89.256706\n",
      "ep 18: ep_len:745 episode reward: total was -13.370000. running mean: -88.497838\n",
      "ep 18: ep_len:207 episode reward: total was 15.000000. running mean: -87.462860\n",
      "ep 18: ep_len:377 episode reward: total was -9.870000. running mean: -86.686931\n",
      "ep 18: ep_len:76 episode reward: total was 7.500000. running mean: -85.745062\n",
      "ep 18: ep_len:157 episode reward: total was 9.500000. running mean: -84.792612\n",
      "ep 18: ep_len:505 episode reward: total was 4.650000. running mean: -83.898185\n",
      "ep 18: ep_len:890 episode reward: total was -34.780000. running mean: -83.407004\n",
      "ep 18: ep_len:500 episode reward: total was -32.590000. running mean: -82.898834\n",
      "ep 18: ep_len:500 episode reward: total was 3.170000. running mean: -82.038145\n",
      "ep 18: ep_len:810 episode reward: total was -24.840000. running mean: -81.466164\n",
      "ep 18: ep_len:173 episode reward: total was 14.000000. running mean: -80.511502\n",
      "ep 18: ep_len:2085 episode reward: total was -214.370000. running mean: -81.850087\n",
      "ep 18: ep_len:247 episode reward: total was 24.500000. running mean: -80.786586\n",
      "ep 18: ep_len:95 episode reward: total was 1.000000. running mean: -79.968720\n",
      "ep 18: ep_len:500 episode reward: total was -10.890000. running mean: -79.277933\n",
      "ep 18: ep_len:317 episode reward: total was 24.000000. running mean: -78.245154\n",
      "ep 18: ep_len:500 episode reward: total was -19.430000. running mean: -77.657002\n",
      "ep 18: ep_len:147 episode reward: total was 11.500000. running mean: -76.765432\n",
      "ep 18: ep_len:520 episode reward: total was -31.820000. running mean: -76.315978\n",
      "ep 18: ep_len:500 episode reward: total was -4.000000. running mean: -75.592818\n",
      "ep 18: ep_len:500 episode reward: total was -17.800000. running mean: -75.014890\n",
      "ep 18: ep_len:77 episode reward: total was 7.500000. running mean: -74.189741\n",
      "ep 18: ep_len:655 episode reward: total was -35.120000. running mean: -73.799044\n",
      "ep 18: ep_len:825 episode reward: total was -15.840000. running mean: -73.219453\n",
      "ep 18: ep_len:630 episode reward: total was -16.290000. running mean: -72.650159\n",
      "ep 18: ep_len:650 episode reward: total was 8.800000. running mean: -71.835657\n",
      "ep 18: ep_len:535 episode reward: total was -57.370000. running mean: -71.691001\n",
      "ep 18: ep_len:645 episode reward: total was -17.430000. running mean: -71.148391\n",
      "ep 18: ep_len:900 episode reward: total was -51.780000. running mean: -70.954707\n",
      "ep 18: ep_len:785 episode reward: total was -22.200000. running mean: -70.467160\n",
      "ep 18: ep_len:500 episode reward: total was -3.440000. running mean: -69.796888\n",
      "ep 18: ep_len:505 episode reward: total was 14.230000. running mean: -68.956619\n",
      "ep 18: ep_len:745 episode reward: total was -10.640000. running mean: -68.373453\n",
      "ep 18: ep_len:500 episode reward: total was -26.000000. running mean: -67.949718\n",
      "ep 18: ep_len:500 episode reward: total was -8.470000. running mean: -67.354921\n",
      "ep 18: ep_len:193 episode reward: total was 14.500000. running mean: -66.536372\n",
      "ep 18: ep_len:500 episode reward: total was 7.970000. running mean: -65.791308\n",
      "ep 18: ep_len:500 episode reward: total was -10.810000. running mean: -65.241495\n",
      "ep 18: ep_len:720 episode reward: total was 5.630000. running mean: -64.532780\n",
      "ep 18: ep_len:535 episode reward: total was -13.120000. running mean: -64.018652\n",
      "ep 18: ep_len:500 episode reward: total was 3.040000. running mean: -63.348066\n",
      "ep 18: ep_len:500 episode reward: total was -5.890000. running mean: -62.773485\n",
      "ep 18: ep_len:500 episode reward: total was -32.930000. running mean: -62.475050\n",
      "ep 18: ep_len:760 episode reward: total was -40.950000. running mean: -62.259800\n",
      "ep 18: ep_len:605 episode reward: total was -18.930000. running mean: -61.826502\n",
      "ep 18: ep_len:505 episode reward: total was 2.840000. running mean: -61.179837\n",
      "ep 18: ep_len:500 episode reward: total was -6.750000. running mean: -60.635538\n",
      "ep 18: ep_len:600 episode reward: total was -0.980000. running mean: -60.038983\n",
      "ep 18: ep_len:500 episode reward: total was 15.690000. running mean: -59.281693\n",
      "ep 18: ep_len:760 episode reward: total was -9.650000. running mean: -58.785376\n",
      "ep 18: ep_len:740 episode reward: total was -21.800000. running mean: -58.415523\n",
      "ep 18: ep_len:520 episode reward: total was -2.110000. running mean: -57.852467\n",
      "ep 18: ep_len:500 episode reward: total was 8.250000. running mean: -57.191443\n",
      "ep 18: ep_len:500 episode reward: total was 5.520000. running mean: -56.564328\n",
      "ep 18: ep_len:970 episode reward: total was -35.480000. running mean: -56.353485\n",
      "ep 18: ep_len:770 episode reward: total was -27.800000. running mean: -56.067950\n",
      "ep 18: ep_len:660 episode reward: total was -26.790000. running mean: -55.775171\n",
      "ep 18: ep_len:479 episode reward: total was -17.450000. running mean: -55.391919\n",
      "ep 18: ep_len:1090 episode reward: total was -22.420000. running mean: -55.062200\n",
      "ep 18: ep_len:775 episode reward: total was -59.100000. running mean: -55.102578\n",
      "ep 18: ep_len:645 episode reward: total was -17.920000. running mean: -54.730752\n",
      "ep 18: ep_len:321 episode reward: total was 21.500000. running mean: -53.968444\n",
      "ep 18: ep_len:500 episode reward: total was -23.440000. running mean: -53.663160\n",
      "ep 18: ep_len:500 episode reward: total was 0.320000. running mean: -53.123328\n",
      "ep 18: ep_len:500 episode reward: total was 41.000000. running mean: -52.182095\n",
      "ep 18: ep_len:500 episode reward: total was -8.900000. running mean: -51.749274\n",
      "ep 18: ep_len:995 episode reward: total was -14.270000. running mean: -51.374481\n",
      "ep 18: ep_len:500 episode reward: total was 17.250000. running mean: -50.688237\n",
      "ep 18: ep_len:710 episode reward: total was 5.210000. running mean: -50.129254\n",
      "ep 18: ep_len:850 episode reward: total was -16.530000. running mean: -49.793262\n",
      "ep 18: ep_len:715 episode reward: total was -47.100000. running mean: -49.766329\n",
      "ep 18: ep_len:500 episode reward: total was -8.160000. running mean: -49.350266\n",
      "ep 18: ep_len:620 episode reward: total was 2.790000. running mean: -48.828863\n",
      "ep 18: ep_len:500 episode reward: total was 1.530000. running mean: -48.325274\n",
      "ep 18: ep_len:500 episode reward: total was 11.030000. running mean: -47.731722\n",
      "ep 18: ep_len:655 episode reward: total was -8.840000. running mean: -47.342805\n",
      "ep 18: ep_len:1715 episode reward: total was -119.320000. running mean: -48.062576\n",
      "ep 18: ep_len:850 episode reward: total was -25.620000. running mean: -47.838151\n",
      "ep 18: ep_len:500 episode reward: total was -11.190000. running mean: -47.471669\n",
      "ep 18: ep_len:725 episode reward: total was -14.760000. running mean: -47.144553\n",
      "ep 18: ep_len:620 episode reward: total was -8.910000. running mean: -46.762207\n",
      "ep 18: ep_len:645 episode reward: total was -26.450000. running mean: -46.559085\n",
      "ep 18: ep_len:167 episode reward: total was 11.000000. running mean: -45.983494\n",
      "ep 18: ep_len:1535 episode reward: total was -194.090000. running mean: -47.464559\n",
      "ep 18: ep_len:729 episode reward: total was -16.760000. running mean: -47.157514\n",
      "ep 18: ep_len:500 episode reward: total was 11.430000. running mean: -46.571638\n",
      "ep 18: ep_len:515 episode reward: total was 17.460000. running mean: -45.931322\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 18: ep_len:500 episode reward: total was -38.560000. running mean: -45.857609\n",
      "ep 18: ep_len:585 episode reward: total was -50.200000. running mean: -45.901033\n",
      "ep 18: ep_len:295 episode reward: total was 1.630000. running mean: -45.425722\n",
      "ep 18: ep_len:905 episode reward: total was 7.160000. running mean: -44.899865\n",
      "ep 18: ep_len:1340 episode reward: total was -149.530000. running mean: -45.946167\n",
      "ep 18: ep_len:249 episode reward: total was 15.500000. running mean: -45.331705\n",
      "ep 18: ep_len:800 episode reward: total was -38.850000. running mean: -45.266888\n",
      "ep 18: ep_len:500 episode reward: total was 20.220000. running mean: -44.612019\n",
      "ep 18: ep_len:970 episode reward: total was 3.560000. running mean: -44.130299\n",
      "ep 18: ep_len:835 episode reward: total was -40.800000. running mean: -44.096996\n",
      "ep 18: ep_len:500 episode reward: total was -16.940000. running mean: -43.825426\n",
      "ep 18: ep_len:500 episode reward: total was -35.440000. running mean: -43.741572\n",
      "ep 18: ep_len:765 episode reward: total was 17.170000. running mean: -43.132456\n",
      "ep 18: ep_len:500 episode reward: total was -0.510000. running mean: -42.706231\n",
      "ep 18: ep_len:620 episode reward: total was -30.120000. running mean: -42.580369\n",
      "ep 18: ep_len:855 episode reward: total was -28.610000. running mean: -42.440665\n",
      "ep 18: ep_len:980 episode reward: total was 5.690000. running mean: -41.959359\n",
      "ep 18: ep_len:560 episode reward: total was -28.880000. running mean: -41.828565\n",
      "ep 18: ep_len:960 episode reward: total was -27.370000. running mean: -41.683979\n",
      "ep 18: ep_len:745 episode reward: total was 0.910000. running mean: -41.258040\n",
      "ep 18: ep_len:520 episode reward: total was -41.430000. running mean: -41.259759\n",
      "ep 18: ep_len:500 episode reward: total was 17.840000. running mean: -40.668762\n",
      "ep 18: ep_len:500 episode reward: total was 15.010000. running mean: -40.111974\n",
      "ep 18: ep_len:1025 episode reward: total was -24.070000. running mean: -39.951554\n",
      "ep 18: ep_len:10820 episode reward: total was -2058.660000. running mean: -60.138639\n",
      "ep 18: ep_len:500 episode reward: total was 3.240000. running mean: -59.504852\n",
      "ep 18: ep_len:535 episode reward: total was -42.410000. running mean: -59.333904\n",
      "ep 18: ep_len:500 episode reward: total was 16.250000. running mean: -58.578065\n",
      "ep 18: ep_len:500 episode reward: total was -2.740000. running mean: -58.019684\n",
      "ep 18: ep_len:500 episode reward: total was 16.640000. running mean: -57.273087\n",
      "ep 18: ep_len:670 episode reward: total was 0.050000. running mean: -56.699856\n",
      "ep 18: ep_len:500 episode reward: total was 36.500000. running mean: -55.767858\n",
      "ep 18: ep_len:505 episode reward: total was -8.690000. running mean: -55.297079\n",
      "ep 18: ep_len:650 episode reward: total was -45.210000. running mean: -55.196208\n",
      "ep 18: ep_len:500 episode reward: total was -5.530000. running mean: -54.699546\n",
      "ep 18: ep_len:870 episode reward: total was -19.740000. running mean: -54.349951\n",
      "ep 18: ep_len:850 episode reward: total was 2.100000. running mean: -53.785451\n",
      "ep 18: ep_len:520 episode reward: total was -30.320000. running mean: -53.550797\n",
      "ep 18: ep_len:500 episode reward: total was 17.740000. running mean: -52.837889\n",
      "ep 18: ep_len:735 episode reward: total was -18.780000. running mean: -52.497310\n",
      "ep 18: ep_len:294 episode reward: total was 20.000000. running mean: -51.772337\n",
      "ep 18: ep_len:570 episode reward: total was -23.150000. running mean: -51.486114\n",
      "ep 18: ep_len:885 episode reward: total was -7.810000. running mean: -51.049352\n",
      "ep 18: ep_len:121 episode reward: total was 3.000000. running mean: -50.508859\n",
      "ep 18: ep_len:665 episode reward: total was -63.360000. running mean: -50.637370\n",
      "ep 18: ep_len:500 episode reward: total was 2.770000. running mean: -50.103297\n",
      "ep 18: ep_len:740 episode reward: total was 3.010000. running mean: -49.572164\n",
      "ep 18: ep_len:745 episode reward: total was -31.220000. running mean: -49.388642\n",
      "ep 18: ep_len:500 episode reward: total was -58.850000. running mean: -49.483256\n",
      "ep 18: ep_len:650 episode reward: total was -5.990000. running mean: -49.048323\n",
      "ep 18: ep_len:500 episode reward: total was 15.230000. running mean: -48.405540\n",
      "ep 18: ep_len:790 episode reward: total was -39.880000. running mean: -48.320284\n",
      "ep 18: ep_len:500 episode reward: total was -5.720000. running mean: -47.894282\n",
      "ep 18: ep_len:690 episode reward: total was -22.390000. running mean: -47.639239\n",
      "ep 18: ep_len:500 episode reward: total was -77.000000. running mean: -47.932846\n",
      "ep 18: ep_len:141 episode reward: total was 11.500000. running mean: -47.338518\n",
      "ep 18: ep_len:750 episode reward: total was -16.050000. running mean: -47.025633\n",
      "ep 18: ep_len:500 episode reward: total was 6.320000. running mean: -46.492176\n",
      "ep 18: ep_len:500 episode reward: total was 3.220000. running mean: -45.995055\n",
      "ep 18: ep_len:283 episode reward: total was 13.000000. running mean: -45.405104\n",
      "ep 18: ep_len:500 episode reward: total was -21.360000. running mean: -45.164653\n",
      "ep 18: ep_len:194 episode reward: total was 17.500000. running mean: -44.538006\n",
      "ep 18: ep_len:690 episode reward: total was -8.770000. running mean: -44.180326\n",
      "ep 18: ep_len:500 episode reward: total was 12.290000. running mean: -43.615623\n",
      "ep 18: ep_len:500 episode reward: total was -5.410000. running mean: -43.233567\n",
      "ep 18: ep_len:1775 episode reward: total was -189.090000. running mean: -44.692131\n",
      "ep 18: ep_len:765 episode reward: total was -16.700000. running mean: -44.412210\n",
      "ep 18: ep_len:500 episode reward: total was 29.500000. running mean: -43.673088\n",
      "ep 18: ep_len:500 episode reward: total was -11.320000. running mean: -43.349557\n",
      "ep 18: ep_len:645 episode reward: total was -19.970000. running mean: -43.115761\n",
      "ep 18: ep_len:640 episode reward: total was -17.250000. running mean: -42.857104\n",
      "ep 18: ep_len:4415 episode reward: total was -738.100000. running mean: -49.809533\n",
      "ep 18: ep_len:580 episode reward: total was -13.670000. running mean: -49.448137\n",
      "ep 18: ep_len:124 episode reward: total was 9.000000. running mean: -48.863656\n",
      "ep 18: ep_len:830 episode reward: total was -122.890000. running mean: -49.603919\n",
      "ep 18: ep_len:346 episode reward: total was 18.000000. running mean: -48.927880\n",
      "ep 18: ep_len:500 episode reward: total was -30.020000. running mean: -48.738801\n",
      "ep 18: ep_len:4710 episode reward: total was -401.180000. running mean: -52.263213\n",
      "ep 18: ep_len:174 episode reward: total was 12.500000. running mean: -51.615581\n",
      "ep 18: ep_len:725 episode reward: total was -24.860000. running mean: -51.348026\n",
      "ep 18: ep_len:500 episode reward: total was 4.270000. running mean: -50.791845\n",
      "ep 18: ep_len:303 episode reward: total was 23.000000. running mean: -50.053927\n",
      "ep 18: ep_len:500 episode reward: total was 12.300000. running mean: -49.430388\n",
      "ep 18: ep_len:500 episode reward: total was 8.250000. running mean: -48.853584\n",
      "ep 18: ep_len:500 episode reward: total was -8.380000. running mean: -48.448848\n",
      "ep 18: ep_len:710 episode reward: total was -18.830000. running mean: -48.152659\n",
      "ep 18: ep_len:900 episode reward: total was -81.790000. running mean: -48.489033\n",
      "ep 18: ep_len:500 episode reward: total was -1.850000. running mean: -48.022642\n",
      "ep 18: ep_len:500 episode reward: total was -3.930000. running mean: -47.581716\n",
      "ep 18: ep_len:2637 episode reward: total was -339.170000. running mean: -50.497599\n",
      "ep 18: ep_len:500 episode reward: total was -4.780000. running mean: -50.040423\n",
      "ep 18: ep_len:820 episode reward: total was -13.340000. running mean: -49.673419\n",
      "ep 18: ep_len:460 episode reward: total was 13.680000. running mean: -49.039884\n",
      "ep 18: ep_len:1155 episode reward: total was -88.640000. running mean: -49.435886\n",
      "ep 18: ep_len:500 episode reward: total was 12.780000. running mean: -48.813727\n",
      "ep 18: ep_len:505 episode reward: total was -12.800000. running mean: -48.453589\n",
      "ep 18: ep_len:335 episode reward: total was 17.000000. running mean: -47.799054\n",
      "ep 18: ep_len:730 episode reward: total was -30.390000. running mean: -47.624963\n",
      "ep 18: ep_len:500 episode reward: total was 8.220000. running mean: -47.066513\n",
      "ep 18: ep_len:545 episode reward: total was -9.060000. running mean: -46.686448\n",
      "ep 18: ep_len:780 episode reward: total was -87.370000. running mean: -47.093284\n",
      "ep 18: ep_len:500 episode reward: total was -8.770000. running mean: -46.710051\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 18: ep_len:760 episode reward: total was -12.770000. running mean: -46.370650\n",
      "ep 18: ep_len:500 episode reward: total was -18.270000. running mean: -46.089644\n",
      "ep 18: ep_len:500 episode reward: total was 7.300000. running mean: -45.555748\n",
      "ep 18: ep_len:530 episode reward: total was -23.230000. running mean: -45.332490\n",
      "ep 18: ep_len:500 episode reward: total was 9.440000. running mean: -44.784765\n",
      "ep 18: ep_len:895 episode reward: total was -51.790000. running mean: -44.854817\n",
      "ep 18: ep_len:500 episode reward: total was 1.570000. running mean: -44.390569\n",
      "ep 18: ep_len:795 episode reward: total was -13.740000. running mean: -44.084064\n",
      "ep 18: ep_len:685 episode reward: total was -54.230000. running mean: -44.185523\n",
      "ep 18: ep_len:745 episode reward: total was -21.760000. running mean: -43.961268\n",
      "ep 18: ep_len:735 episode reward: total was -15.730000. running mean: -43.678955\n",
      "ep 18: ep_len:289 episode reward: total was 22.500000. running mean: -43.017166\n",
      "ep 18: ep_len:845 episode reward: total was -1.310000. running mean: -42.600094\n",
      "ep 18: ep_len:617 episode reward: total was -68.980000. running mean: -42.863893\n",
      "ep 18: ep_len:1490 episode reward: total was -184.930000. running mean: -44.284554\n",
      "ep 18: ep_len:500 episode reward: total was -6.400000. running mean: -43.905708\n",
      "ep 18: ep_len:1118 episode reward: total was -121.040000. running mean: -44.677051\n",
      "ep 18: ep_len:1030 episode reward: total was -8.840000. running mean: -44.318681\n",
      "ep 18: ep_len:920 episode reward: total was 9.220000. running mean: -43.783294\n",
      "ep 18: ep_len:565 episode reward: total was -17.860000. running mean: -43.524061\n",
      "ep 18: ep_len:500 episode reward: total was -23.380000. running mean: -43.322621\n",
      "ep 18: ep_len:895 episode reward: total was -23.410000. running mean: -43.123494\n",
      "ep 18: ep_len:950 episode reward: total was -122.380000. running mean: -43.916059\n",
      "ep 18: ep_len:720 episode reward: total was -36.990000. running mean: -43.846799\n",
      "ep 18: ep_len:500 episode reward: total was -17.530000. running mean: -43.583631\n",
      "ep 18: ep_len:500 episode reward: total was 13.480000. running mean: -43.012994\n",
      "ep 18: ep_len:785 episode reward: total was -43.930000. running mean: -43.022165\n",
      "ep 18: ep_len:139 episode reward: total was 10.500000. running mean: -42.486943\n",
      "ep 18: ep_len:515 episode reward: total was 6.200000. running mean: -42.000073\n",
      "ep 18: ep_len:700 episode reward: total was -21.880000. running mean: -41.798873\n",
      "ep 18: ep_len:575 episode reward: total was -6.380000. running mean: -41.444684\n",
      "ep 18: ep_len:885 episode reward: total was -0.260000. running mean: -41.032837\n",
      "ep 18: ep_len:1315 episode reward: total was -205.040000. running mean: -42.672909\n",
      "ep 18: ep_len:500 episode reward: total was 7.270000. running mean: -42.173480\n",
      "ep 18: ep_len:500 episode reward: total was 12.780000. running mean: -41.623945\n",
      "ep 18: ep_len:600 episode reward: total was -18.800000. running mean: -41.395705\n",
      "ep 18: ep_len:500 episode reward: total was -12.210000. running mean: -41.103848\n",
      "ep 18: ep_len:128 episode reward: total was 9.500000. running mean: -40.597810\n",
      "ep 18: ep_len:500 episode reward: total was 16.800000. running mean: -40.023832\n",
      "ep 18: ep_len:637 episode reward: total was -46.150000. running mean: -40.085093\n",
      "ep 18: ep_len:500 episode reward: total was -68.740000. running mean: -40.371643\n",
      "ep 18: ep_len:525 episode reward: total was -23.240000. running mean: -40.200326\n",
      "ep 18: ep_len:545 episode reward: total was -24.180000. running mean: -40.040123\n",
      "ep 18: ep_len:840 episode reward: total was 17.320000. running mean: -39.466522\n",
      "ep 18: ep_len:500 episode reward: total was 6.010000. running mean: -39.011756\n",
      "ep 18: ep_len:2595 episode reward: total was -380.650000. running mean: -42.428139\n",
      "ep 18: ep_len:515 episode reward: total was -38.530000. running mean: -42.389157\n",
      "ep 18: ep_len:500 episode reward: total was 39.500000. running mean: -41.570266\n",
      "ep 18: ep_len:1102 episode reward: total was -59.120000. running mean: -41.745763\n",
      "ep 18: ep_len:500 episode reward: total was -10.370000. running mean: -41.432006\n",
      "ep 18: ep_len:1465 episode reward: total was -24.990000. running mean: -41.267586\n",
      "ep 18: ep_len:730 episode reward: total was -60.200000. running mean: -41.456910\n",
      "ep 18: ep_len:426 episode reward: total was -7.940000. running mean: -41.121741\n",
      "ep 18: ep_len:600 episode reward: total was -20.030000. running mean: -40.910823\n",
      "epsilon:0.107539 episode_count: 14998. steps_count: 10667291.000000\n",
      "ep 19: ep_len:500 episode reward: total was 13.800000. running mean: -40.363715\n",
      "ep 19: ep_len:810 episode reward: total was -43.880000. running mean: -40.398878\n",
      "ep 19: ep_len:730 episode reward: total was 4.140000. running mean: -39.953489\n",
      "ep 19: ep_len:1055 episode reward: total was -114.090000. running mean: -40.694854\n",
      "ep 19: ep_len:500 episode reward: total was -37.520000. running mean: -40.663106\n",
      "ep 19: ep_len:560 episode reward: total was 7.030000. running mean: -40.186175\n",
      "ep 19: ep_len:1030 episode reward: total was 5.240000. running mean: -39.731913\n",
      "ep 19: ep_len:500 episode reward: total was -20.380000. running mean: -39.538394\n",
      "ep 19: ep_len:1040 episode reward: total was -16.770000. running mean: -39.310710\n",
      "ep 19: ep_len:500 episode reward: total was -6.990000. running mean: -38.987503\n",
      "ep 19: ep_len:500 episode reward: total was 4.200000. running mean: -38.555628\n",
      "ep 19: ep_len:500 episode reward: total was -3.810000. running mean: -38.208171\n",
      "ep 19: ep_len:955 episode reward: total was -7.430000. running mean: -37.900390\n",
      "ep 19: ep_len:1240 episode reward: total was -11.650000. running mean: -37.637886\n",
      "ep 19: ep_len:815 episode reward: total was -27.710000. running mean: -37.538607\n",
      "ep 19: ep_len:500 episode reward: total was 11.740000. running mean: -37.045821\n",
      "ep 19: ep_len:500 episode reward: total was -15.260000. running mean: -36.827963\n",
      "ep 19: ep_len:500 episode reward: total was 1.390000. running mean: -36.445783\n",
      "ep 19: ep_len:565 episode reward: total was -42.840000. running mean: -36.509725\n",
      "ep 19: ep_len:500 episode reward: total was 1.360000. running mean: -36.131028\n",
      "ep 19: ep_len:1490 episode reward: total was -82.920000. running mean: -36.598918\n",
      "ep 19: ep_len:995 episode reward: total was -63.220000. running mean: -36.865128\n",
      "ep 19: ep_len:2135 episode reward: total was -360.140000. running mean: -40.097877\n",
      "ep 19: ep_len:545 episode reward: total was 1.110000. running mean: -39.685798\n",
      "ep 19: ep_len:500 episode reward: total was -26.520000. running mean: -39.554140\n",
      "ep 19: ep_len:590 episode reward: total was 2.640000. running mean: -39.132199\n",
      "ep 19: ep_len:14710 episode reward: total was -2647.040000. running mean: -65.211277\n",
      "ep 19: ep_len:500 episode reward: total was 6.630000. running mean: -64.492864\n",
      "ep 19: ep_len:730 episode reward: total was -17.120000. running mean: -64.019136\n",
      "ep 19: ep_len:760 episode reward: total was -23.320000. running mean: -63.612144\n",
      "ep 19: ep_len:231 episode reward: total was 5.000000. running mean: -62.926023\n",
      "ep 19: ep_len:505 episode reward: total was -9.140000. running mean: -62.388163\n",
      "ep 19: ep_len:890 episode reward: total was 3.240000. running mean: -61.731881\n",
      "ep 19: ep_len:500 episode reward: total was -8.230000. running mean: -61.196862\n",
      "ep 19: ep_len:500 episode reward: total was -18.240000. running mean: -60.767293\n",
      "ep 19: ep_len:710 episode reward: total was -9.740000. running mean: -60.257021\n",
      "ep 19: ep_len:580 episode reward: total was -65.520000. running mean: -60.309650\n",
      "ep 19: ep_len:493 episode reward: total was 16.220000. running mean: -59.544354\n",
      "ep 19: ep_len:600 episode reward: total was 2.970000. running mean: -58.919210\n",
      "ep 19: ep_len:500 episode reward: total was 11.250000. running mean: -58.217518\n",
      "ep 19: ep_len:330 episode reward: total was 21.500000. running mean: -57.420343\n",
      "ep 19: ep_len:690 episode reward: total was -34.930000. running mean: -57.195440\n",
      "ep 19: ep_len:785 episode reward: total was -26.980000. running mean: -56.893285\n",
      "ep 19: ep_len:510 episode reward: total was 4.750000. running mean: -56.276852\n",
      "ep 19: ep_len:1307 episode reward: total was -97.470000. running mean: -56.688784\n",
      "ep 19: ep_len:164 episode reward: total was 14.500000. running mean: -55.976896\n",
      "ep 19: ep_len:500 episode reward: total was 15.330000. running mean: -55.263827\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 19: ep_len:745 episode reward: total was -24.790000. running mean: -54.959089\n",
      "ep 19: ep_len:890 episode reward: total was -46.750000. running mean: -54.876998\n",
      "ep 19: ep_len:685 episode reward: total was -20.870000. running mean: -54.536928\n",
      "ep 19: ep_len:125 episode reward: total was 6.500000. running mean: -53.926559\n",
      "ep 19: ep_len:810 episode reward: total was -31.880000. running mean: -53.706093\n",
      "ep 19: ep_len:680 episode reward: total was -45.150000. running mean: -53.620532\n",
      "ep 19: ep_len:500 episode reward: total was -20.410000. running mean: -53.288427\n",
      "ep 19: ep_len:660 episode reward: total was -13.880000. running mean: -52.894343\n",
      "ep 19: ep_len:106 episode reward: total was 9.000000. running mean: -52.275399\n",
      "ep 19: ep_len:865 episode reward: total was -22.230000. running mean: -51.974945\n",
      "ep 19: ep_len:685 episode reward: total was -25.460000. running mean: -51.709796\n",
      "ep 19: ep_len:500 episode reward: total was -50.680000. running mean: -51.699498\n",
      "ep 19: ep_len:18375 episode reward: total was -1352.660000. running mean: -64.709103\n",
      "ep 19: ep_len:500 episode reward: total was -27.330000. running mean: -64.335312\n",
      "ep 19: ep_len:830 episode reward: total was -22.890000. running mean: -63.920859\n",
      "ep 19: ep_len:209 episode reward: total was 11.500000. running mean: -63.166650\n",
      "ep 19: ep_len:500 episode reward: total was 15.260000. running mean: -62.382383\n",
      "ep 19: ep_len:500 episode reward: total was 19.700000. running mean: -61.561560\n",
      "ep 19: ep_len:1120 episode reward: total was -112.950000. running mean: -62.075444\n",
      "ep 19: ep_len:595 episode reward: total was -44.310000. running mean: -61.897790\n",
      "ep 19: ep_len:505 episode reward: total was -15.830000. running mean: -61.437112\n",
      "ep 19: ep_len:665 episode reward: total was -34.070000. running mean: -61.163441\n",
      "ep 19: ep_len:735 episode reward: total was -18.260000. running mean: -60.734406\n",
      "ep 19: ep_len:500 episode reward: total was 16.240000. running mean: -59.964662\n",
      "ep 19: ep_len:730 episode reward: total was -20.810000. running mean: -59.573116\n",
      "ep 19: ep_len:406 episode reward: total was -22.560000. running mean: -59.202984\n",
      "ep 19: ep_len:505 episode reward: total was -8.760000. running mean: -58.698555\n",
      "ep 19: ep_len:500 episode reward: total was 12.230000. running mean: -57.989269\n",
      "ep 19: ep_len:890 episode reward: total was -28.170000. running mean: -57.691076\n",
      "ep 19: ep_len:2220 episode reward: total was -265.440000. running mean: -59.768566\n",
      "ep 19: ep_len:500 episode reward: total was -16.520000. running mean: -59.336080\n",
      "ep 19: ep_len:700 episode reward: total was -16.310000. running mean: -58.905819\n",
      "ep 19: ep_len:500 episode reward: total was -6.310000. running mean: -58.379861\n",
      "ep 19: ep_len:680 episode reward: total was -13.810000. running mean: -57.934162\n",
      "ep 19: ep_len:95 episode reward: total was 3.500000. running mean: -57.319821\n",
      "ep 19: ep_len:675 episode reward: total was 1.800000. running mean: -56.728622\n",
      "ep 19: ep_len:500 episode reward: total was 5.840000. running mean: -56.102936\n",
      "ep 19: ep_len:570 episode reward: total was -23.240000. running mean: -55.774307\n",
      "ep 19: ep_len:500 episode reward: total was -21.530000. running mean: -55.431864\n",
      "ep 19: ep_len:2060 episode reward: total was -254.770000. running mean: -57.425245\n",
      "ep 19: ep_len:500 episode reward: total was -16.980000. running mean: -57.020793\n",
      "ep 19: ep_len:610 episode reward: total was -5.610000. running mean: -56.506685\n",
      "ep 19: ep_len:610 episode reward: total was -56.910000. running mean: -56.510718\n",
      "ep 19: ep_len:545 episode reward: total was -30.270000. running mean: -56.248311\n",
      "ep 19: ep_len:500 episode reward: total was 3.780000. running mean: -55.648028\n",
      "ep 19: ep_len:505 episode reward: total was 32.500000. running mean: -54.766547\n",
      "ep 19: ep_len:525 episode reward: total was -76.460000. running mean: -54.983482\n",
      "ep 19: ep_len:500 episode reward: total was 19.760000. running mean: -54.236047\n",
      "ep 19: ep_len:525 episode reward: total was -22.260000. running mean: -53.916287\n",
      "ep 19: ep_len:500 episode reward: total was -21.420000. running mean: -53.591324\n",
      "ep 19: ep_len:379 episode reward: total was 31.500000. running mean: -52.740410\n",
      "ep 19: ep_len:500 episode reward: total was 18.690000. running mean: -52.026106\n",
      "ep 19: ep_len:660 episode reward: total was -72.460000. running mean: -52.230445\n",
      "ep 19: ep_len:500 episode reward: total was 7.700000. running mean: -51.631141\n",
      "ep 19: ep_len:500 episode reward: total was -35.070000. running mean: -51.465529\n",
      "ep 19: ep_len:403 episode reward: total was -26.500000. running mean: -51.215874\n",
      "ep 19: ep_len:930 episode reward: total was 18.880000. running mean: -50.514915\n",
      "ep 19: ep_len:590 episode reward: total was -34.710000. running mean: -50.356866\n",
      "ep 19: ep_len:600 episode reward: total was -28.230000. running mean: -50.135598\n",
      "ep 19: ep_len:121 episode reward: total was 9.000000. running mean: -49.544242\n",
      "ep 19: ep_len:525 episode reward: total was 6.340000. running mean: -48.985399\n",
      "ep 19: ep_len:500 episode reward: total was 3.820000. running mean: -48.457345\n",
      "ep 19: ep_len:500 episode reward: total was -10.060000. running mean: -48.073372\n",
      "ep 19: ep_len:505 episode reward: total was -9.810000. running mean: -47.690738\n",
      "ep 19: ep_len:500 episode reward: total was 16.760000. running mean: -47.046231\n",
      "ep 19: ep_len:1180 episode reward: total was -52.420000. running mean: -47.099968\n",
      "ep 19: ep_len:500 episode reward: total was -34.940000. running mean: -46.978369\n",
      "ep 19: ep_len:575 episode reward: total was -33.910000. running mean: -46.847685\n",
      "ep 19: ep_len:1175 episode reward: total was -35.210000. running mean: -46.731308\n",
      "ep 19: ep_len:500 episode reward: total was 11.280000. running mean: -46.151195\n",
      "ep 19: ep_len:915 episode reward: total was -14.420000. running mean: -45.833883\n",
      "ep 19: ep_len:620 episode reward: total was -77.920000. running mean: -46.154744\n",
      "ep 19: ep_len:500 episode reward: total was -29.410000. running mean: -45.987297\n",
      "ep 19: ep_len:660 episode reward: total was -16.390000. running mean: -45.691324\n",
      "ep 19: ep_len:870 episode reward: total was -75.070000. running mean: -45.985111\n",
      "ep 19: ep_len:820 episode reward: total was -22.430000. running mean: -45.749560\n",
      "ep 19: ep_len:785 episode reward: total was -19.170000. running mean: -45.483764\n",
      "ep 19: ep_len:78 episode reward: total was 6.000000. running mean: -44.968926\n",
      "ep 19: ep_len:500 episode reward: total was -6.950000. running mean: -44.588737\n",
      "ep 19: ep_len:990 episode reward: total was -42.200000. running mean: -44.564850\n",
      "ep 19: ep_len:500 episode reward: total was 2.800000. running mean: -44.091201\n",
      "ep 19: ep_len:500 episode reward: total was -34.490000. running mean: -43.995189\n",
      "ep 19: ep_len:515 episode reward: total was -34.370000. running mean: -43.898937\n",
      "ep 19: ep_len:500 episode reward: total was 8.740000. running mean: -43.372548\n",
      "ep 19: ep_len:500 episode reward: total was -12.510000. running mean: -43.063922\n",
      "ep 19: ep_len:810 episode reward: total was -49.940000. running mean: -43.132683\n",
      "ep 19: ep_len:605 episode reward: total was -14.000000. running mean: -42.841356\n",
      "ep 19: ep_len:500 episode reward: total was 18.730000. running mean: -42.225643\n",
      "ep 19: ep_len:2575 episode reward: total was -387.840000. running mean: -45.681786\n",
      "ep 19: ep_len:500 episode reward: total was 19.300000. running mean: -45.031968\n",
      "ep 19: ep_len:935 episode reward: total was -3.050000. running mean: -44.612149\n",
      "ep 19: ep_len:1505 episode reward: total was -147.500000. running mean: -45.641027\n",
      "ep 19: ep_len:500 episode reward: total was -11.170000. running mean: -45.296317\n",
      "ep 19: ep_len:500 episode reward: total was 26.710000. running mean: -44.576254\n",
      "ep 19: ep_len:620 episode reward: total was -36.670000. running mean: -44.497191\n",
      "ep 19: ep_len:206 episode reward: total was 17.500000. running mean: -43.877219\n",
      "ep 19: ep_len:500 episode reward: total was -13.460000. running mean: -43.573047\n",
      "ep 19: ep_len:705 episode reward: total was -8.740000. running mean: -43.224717\n",
      "ep 19: ep_len:500 episode reward: total was -1.760000. running mean: -42.810070\n",
      "ep 19: ep_len:500 episode reward: total was 23.720000. running mean: -42.144769\n",
      "ep 19: ep_len:615 episode reward: total was -41.210000. running mean: -42.135421\n",
      "ep 19: ep_len:500 episode reward: total was -41.470000. running mean: -42.128767\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 19: ep_len:505 episode reward: total was -3.350000. running mean: -41.740979\n",
      "ep 19: ep_len:249 episode reward: total was 18.500000. running mean: -41.138570\n",
      "ep 19: ep_len:500 episode reward: total was -10.520000. running mean: -40.832384\n",
      "ep 19: ep_len:500 episode reward: total was -18.850000. running mean: -40.612560\n",
      "ep 19: ep_len:500 episode reward: total was 4.330000. running mean: -40.163134\n",
      "ep 19: ep_len:875 episode reward: total was -6.570000. running mean: -39.827203\n",
      "ep 19: ep_len:500 episode reward: total was -28.400000. running mean: -39.712931\n",
      "ep 19: ep_len:640 episode reward: total was -16.920000. running mean: -39.485002\n",
      "ep 19: ep_len:585 episode reward: total was 15.150000. running mean: -38.938652\n",
      "ep 19: ep_len:505 episode reward: total was 15.790000. running mean: -38.391365\n",
      "ep 19: ep_len:500 episode reward: total was -0.850000. running mean: -38.015952\n",
      "ep 19: ep_len:635 episode reward: total was -46.250000. running mean: -38.098292\n",
      "ep 19: ep_len:207 episode reward: total was 7.500000. running mean: -37.642309\n",
      "ep 19: ep_len:720 episode reward: total was -16.910000. running mean: -37.434986\n",
      "ep 19: ep_len:605 episode reward: total was -26.200000. running mean: -37.322636\n",
      "ep 19: ep_len:505 episode reward: total was 20.240000. running mean: -36.747010\n",
      "ep 19: ep_len:920 episode reward: total was -11.900000. running mean: -36.498540\n",
      "ep 19: ep_len:830 episode reward: total was -11.360000. running mean: -36.247154\n",
      "ep 19: ep_len:500 episode reward: total was -9.760000. running mean: -35.982283\n",
      "ep 19: ep_len:900 episode reward: total was -35.430000. running mean: -35.976760\n",
      "ep 19: ep_len:313 episode reward: total was 25.000000. running mean: -35.366992\n",
      "ep 19: ep_len:500 episode reward: total was -6.250000. running mean: -35.075822\n",
      "ep 19: ep_len:895 episode reward: total was -19.280000. running mean: -34.917864\n",
      "ep 19: ep_len:620 episode reward: total was -55.390000. running mean: -35.122586\n",
      "ep 19: ep_len:500 episode reward: total was -16.770000. running mean: -34.939060\n",
      "ep 19: ep_len:214 episode reward: total was 18.500000. running mean: -34.404669\n",
      "ep 19: ep_len:505 episode reward: total was -19.390000. running mean: -34.254522\n",
      "ep 19: ep_len:855 episode reward: total was 1.900000. running mean: -33.892977\n",
      "ep 19: ep_len:500 episode reward: total was -24.330000. running mean: -33.797347\n",
      "ep 19: ep_len:650 episode reward: total was -33.630000. running mean: -33.795674\n",
      "ep 19: ep_len:500 episode reward: total was -14.670000. running mean: -33.604417\n",
      "ep 19: ep_len:500 episode reward: total was 4.790000. running mean: -33.220473\n",
      "ep 19: ep_len:500 episode reward: total was -6.290000. running mean: -32.951168\n",
      "ep 19: ep_len:221 episode reward: total was 17.500000. running mean: -32.446657\n",
      "ep 19: ep_len:610 episode reward: total was -42.800000. running mean: -32.550190\n",
      "ep 19: ep_len:500 episode reward: total was 35.000000. running mean: -31.874688\n",
      "ep 19: ep_len:500 episode reward: total was 10.240000. running mean: -31.453541\n",
      "ep 19: ep_len:515 episode reward: total was -16.190000. running mean: -31.300906\n",
      "ep 19: ep_len:500 episode reward: total was -9.240000. running mean: -31.080297\n",
      "ep 19: ep_len:715 episode reward: total was 3.180000. running mean: -30.737694\n",
      "ep 19: ep_len:645 episode reward: total was -21.990000. running mean: -30.650217\n",
      "ep 19: ep_len:795 episode reward: total was -16.640000. running mean: -30.510115\n",
      "ep 19: ep_len:1015 episode reward: total was -40.000000. running mean: -30.605014\n",
      "ep 19: ep_len:500 episode reward: total was 7.540000. running mean: -30.223563\n",
      "ep 19: ep_len:378 episode reward: total was 27.000000. running mean: -29.651328\n",
      "ep 19: ep_len:500 episode reward: total was 6.750000. running mean: -29.287315\n",
      "ep 19: ep_len:600 episode reward: total was -85.710000. running mean: -29.851541\n",
      "ep 19: ep_len:655 episode reward: total was -23.990000. running mean: -29.792926\n",
      "ep 19: ep_len:1055 episode reward: total was -13.900000. running mean: -29.633997\n",
      "ep 19: ep_len:500 episode reward: total was -20.840000. running mean: -29.546057\n",
      "ep 19: ep_len:300 episode reward: total was 22.500000. running mean: -29.025596\n",
      "ep 19: ep_len:620 episode reward: total was -35.140000. running mean: -29.086740\n",
      "ep 19: ep_len:585 episode reward: total was -26.640000. running mean: -29.062273\n",
      "ep 19: ep_len:655 episode reward: total was -22.330000. running mean: -28.994950\n",
      "ep 19: ep_len:500 episode reward: total was 5.090000. running mean: -28.654101\n",
      "ep 19: ep_len:500 episode reward: total was 7.630000. running mean: -28.291260\n",
      "ep 19: ep_len:500 episode reward: total was 4.730000. running mean: -27.961047\n",
      "ep 19: ep_len:500 episode reward: total was -12.270000. running mean: -27.804136\n",
      "ep 19: ep_len:600 episode reward: total was 13.360000. running mean: -27.392495\n",
      "ep 19: ep_len:505 episode reward: total was 0.570000. running mean: -27.112870\n",
      "ep 19: ep_len:545 episode reward: total was -34.310000. running mean: -27.184841\n",
      "ep 19: ep_len:525 episode reward: total was 10.070000. running mean: -26.812293\n",
      "ep 19: ep_len:865 episode reward: total was -3.130000. running mean: -26.575470\n",
      "ep 19: ep_len:625 episode reward: total was 2.530000. running mean: -26.284415\n",
      "ep 19: ep_len:645 episode reward: total was -34.110000. running mean: -26.362671\n",
      "ep 19: ep_len:500 episode reward: total was -15.990000. running mean: -26.258945\n",
      "ep 19: ep_len:1020 episode reward: total was -94.680000. running mean: -26.943155\n",
      "ep 19: ep_len:710 episode reward: total was -6.700000. running mean: -26.740724\n",
      "ep 19: ep_len:163 episode reward: total was 13.500000. running mean: -26.338316\n",
      "ep 19: ep_len:795 episode reward: total was -33.810000. running mean: -26.413033\n",
      "ep 19: ep_len:730 episode reward: total was -15.760000. running mean: -26.306503\n",
      "ep 19: ep_len:880 episode reward: total was -32.960000. running mean: -26.373038\n",
      "ep 19: ep_len:875 episode reward: total was -6.000000. running mean: -26.169307\n",
      "ep 19: ep_len:500 episode reward: total was -13.980000. running mean: -26.047414\n",
      "ep 19: ep_len:419 episode reward: total was 8.720000. running mean: -25.699740\n",
      "ep 19: ep_len:500 episode reward: total was 6.750000. running mean: -25.375243\n",
      "ep 19: ep_len:500 episode reward: total was 25.730000. running mean: -24.864190\n",
      "ep 19: ep_len:500 episode reward: total was -6.120000. running mean: -24.676748\n",
      "ep 19: ep_len:505 episode reward: total was 23.780000. running mean: -24.192181\n",
      "ep 19: ep_len:500 episode reward: total was 7.180000. running mean: -23.878459\n",
      "ep 19: ep_len:740 episode reward: total was 4.190000. running mean: -23.597775\n",
      "ep 19: ep_len:500 episode reward: total was -3.450000. running mean: -23.396297\n",
      "ep 19: ep_len:505 episode reward: total was 8.750000. running mean: -23.074834\n",
      "ep 19: ep_len:790 episode reward: total was -41.030000. running mean: -23.254386\n",
      "ep 19: ep_len:500 episode reward: total was -8.890000. running mean: -23.110742\n",
      "ep 19: ep_len:1120 episode reward: total was -165.240000. running mean: -24.532034\n",
      "ep 19: ep_len:1760 episode reward: total was -217.720000. running mean: -26.463914\n",
      "ep 19: ep_len:510 episode reward: total was -25.290000. running mean: -26.452175\n",
      "ep 19: ep_len:500 episode reward: total was 30.500000. running mean: -25.882653\n",
      "ep 19: ep_len:770 episode reward: total was -19.720000. running mean: -25.821026\n",
      "ep 19: ep_len:500 episode reward: total was 3.500000. running mean: -25.527816\n",
      "ep 19: ep_len:500 episode reward: total was -16.710000. running mean: -25.439638\n",
      "ep 19: ep_len:500 episode reward: total was 7.220000. running mean: -25.113042\n",
      "ep 19: ep_len:555 episode reward: total was -21.160000. running mean: -25.073511\n",
      "ep 19: ep_len:180 episode reward: total was 15.000000. running mean: -24.672776\n",
      "ep 19: ep_len:188 episode reward: total was 15.500000. running mean: -24.271048\n",
      "ep 19: ep_len:545 episode reward: total was -32.290000. running mean: -24.351238\n",
      "ep 19: ep_len:535 episode reward: total was 5.560000. running mean: -24.052126\n",
      "ep 19: ep_len:590 episode reward: total was -44.700000. running mean: -24.258604\n",
      "ep 19: ep_len:500 episode reward: total was 0.620000. running mean: -24.009818\n",
      "ep 19: ep_len:500 episode reward: total was 24.260000. running mean: -23.527120\n",
      "ep 19: ep_len:595 episode reward: total was 16.100000. running mean: -23.130849\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 19: ep_len:800 episode reward: total was -36.260000. running mean: -23.262140\n",
      "ep 19: ep_len:505 episode reward: total was -29.340000. running mean: -23.322919\n",
      "ep 19: ep_len:1140 episode reward: total was -28.760000. running mean: -23.377290\n",
      "ep 19: ep_len:870 episode reward: total was -1.130000. running mean: -23.154817\n",
      "ep 19: ep_len:269 episode reward: total was 22.500000. running mean: -22.698269\n",
      "ep 19: ep_len:500 episode reward: total was 3.470000. running mean: -22.436586\n",
      "ep 19: ep_len:500 episode reward: total was -6.910000. running mean: -22.281320\n",
      "ep 19: ep_len:530 episode reward: total was -9.580000. running mean: -22.154307\n",
      "ep 19: ep_len:915 episode reward: total was -31.820000. running mean: -22.250964\n",
      "ep 19: ep_len:585 episode reward: total was 1.620000. running mean: -22.012254\n",
      "ep 19: ep_len:500 episode reward: total was 8.720000. running mean: -21.704932\n",
      "ep 19: ep_len:500 episode reward: total was 19.760000. running mean: -21.290282\n",
      "ep 19: ep_len:500 episode reward: total was 5.920000. running mean: -21.018180\n",
      "ep 19: ep_len:855 episode reward: total was -14.430000. running mean: -20.952298\n",
      "ep 19: ep_len:690 episode reward: total was -41.500000. running mean: -21.157775\n",
      "ep 19: ep_len:500 episode reward: total was 2.740000. running mean: -20.918797\n",
      "ep 19: ep_len:860 episode reward: total was 11.980000. running mean: -20.589809\n",
      "ep 19: ep_len:600 episode reward: total was -6.340000. running mean: -20.447311\n",
      "ep 19: ep_len:140 episode reward: total was 11.500000. running mean: -20.127838\n",
      "ep 19: ep_len:500 episode reward: total was 17.260000. running mean: -19.753959\n",
      "ep 19: ep_len:500 episode reward: total was 9.870000. running mean: -19.457720\n",
      "ep 19: ep_len:500 episode reward: total was 6.350000. running mean: -19.199643\n",
      "ep 19: ep_len:500 episode reward: total was -19.340000. running mean: -19.201046\n",
      "ep 19: ep_len:1150 episode reward: total was -24.260000. running mean: -19.251636\n",
      "ep 19: ep_len:1220 episode reward: total was -152.140000. running mean: -20.580519\n",
      "ep 19: ep_len:500 episode reward: total was -4.830000. running mean: -20.423014\n",
      "ep 19: ep_len:500 episode reward: total was 4.760000. running mean: -20.171184\n",
      "ep 19: ep_len:585 episode reward: total was -30.680000. running mean: -20.276272\n",
      "ep 19: ep_len:287 episode reward: total was 9.500000. running mean: -19.978510\n",
      "ep 19: ep_len:183 episode reward: total was 16.500000. running mean: -19.613724\n",
      "ep 19: ep_len:165 episode reward: total was 9.000000. running mean: -19.327587\n",
      "ep 19: ep_len:560 episode reward: total was -38.320000. running mean: -19.517511\n",
      "ep 19: ep_len:1045 episode reward: total was -57.550000. running mean: -19.897836\n",
      "ep 19: ep_len:500 episode reward: total was 10.790000. running mean: -19.590958\n",
      "ep 19: ep_len:454 episode reward: total was -3.090000. running mean: -19.425948\n",
      "ep 19: ep_len:980 episode reward: total was -21.020000. running mean: -19.441889\n",
      "ep 19: ep_len:1010 episode reward: total was -41.690000. running mean: -19.664370\n",
      "ep 19: ep_len:1550 episode reward: total was -131.280000. running mean: -20.780526\n",
      "ep 19: ep_len:860 episode reward: total was -9.340000. running mean: -20.666121\n",
      "ep 19: ep_len:755 episode reward: total was 5.700000. running mean: -20.402460\n",
      "ep 19: ep_len:500 episode reward: total was 3.260000. running mean: -20.165835\n",
      "ep 19: ep_len:610 episode reward: total was -21.050000. running mean: -20.174677\n",
      "ep 19: ep_len:670 episode reward: total was -23.960000. running mean: -20.212530\n",
      "ep 19: ep_len:335 episode reward: total was 24.500000. running mean: -19.765405\n",
      "ep 19: ep_len:985 episode reward: total was -40.500000. running mean: -19.972751\n",
      "ep 19: ep_len:950 episode reward: total was -45.920000. running mean: -20.232223\n",
      "ep 19: ep_len:695 episode reward: total was -4.800000. running mean: -20.077901\n",
      "ep 19: ep_len:500 episode reward: total was 10.760000. running mean: -19.769522\n",
      "ep 19: ep_len:208 episode reward: total was 17.500000. running mean: -19.396827\n",
      "ep 19: ep_len:605 episode reward: total was 6.410000. running mean: -19.138758\n",
      "ep 19: ep_len:1055 episode reward: total was -40.590000. running mean: -19.353271\n",
      "ep 19: ep_len:505 episode reward: total was 15.270000. running mean: -19.007038\n",
      "ep 19: ep_len:500 episode reward: total was 18.260000. running mean: -18.634368\n",
      "ep 19: ep_len:665 episode reward: total was -44.170000. running mean: -18.889724\n",
      "ep 19: ep_len:146 episode reward: total was 8.500000. running mean: -18.615827\n",
      "ep 19: ep_len:307 episode reward: total was 16.000000. running mean: -18.269669\n",
      "ep 19: ep_len:965 episode reward: total was -111.240000. running mean: -19.199372\n",
      "ep 19: ep_len:750 episode reward: total was -34.390000. running mean: -19.351278\n",
      "ep 19: ep_len:920 episode reward: total was -67.460000. running mean: -19.832365\n",
      "ep 19: ep_len:515 episode reward: total was 8.780000. running mean: -19.546242\n",
      "ep 19: ep_len:184 episode reward: total was 10.500000. running mean: -19.245779\n",
      "ep 19: ep_len:500 episode reward: total was 12.410000. running mean: -18.929222\n",
      "ep 19: ep_len:161 episode reward: total was 10.000000. running mean: -18.639929\n",
      "ep 19: ep_len:500 episode reward: total was 35.500000. running mean: -18.098530\n",
      "ep 19: ep_len:605 episode reward: total was -71.250000. running mean: -18.630045\n",
      "ep 19: ep_len:500 episode reward: total was -3.260000. running mean: -18.476344\n",
      "ep 19: ep_len:1105 episode reward: total was 1.380000. running mean: -18.277781\n",
      "ep 19: ep_len:750 episode reward: total was -23.800000. running mean: -18.333003\n",
      "ep 19: ep_len:500 episode reward: total was -31.720000. running mean: -18.466873\n",
      "ep 19: ep_len:505 episode reward: total was -4.290000. running mean: -18.325104\n",
      "ep 19: ep_len:500 episode reward: total was -20.780000. running mean: -18.349653\n",
      "ep 19: ep_len:790 episode reward: total was -25.740000. running mean: -18.423557\n",
      "ep 19: ep_len:500 episode reward: total was 2.720000. running mean: -18.212121\n",
      "ep 19: ep_len:545 episode reward: total was -13.100000. running mean: -18.161000\n",
      "ep 19: ep_len:540 episode reward: total was -37.350000. running mean: -18.352890\n",
      "ep 19: ep_len:580 episode reward: total was -34.240000. running mean: -18.511761\n",
      "ep 19: ep_len:630 episode reward: total was -44.230000. running mean: -18.768943\n",
      "ep 19: ep_len:930 episode reward: total was -32.530000. running mean: -18.906554\n",
      "ep 19: ep_len:505 episode reward: total was -8.280000. running mean: -18.800288\n",
      "ep 19: ep_len:1020 episode reward: total was 2.470000. running mean: -18.587586\n",
      "ep 19: ep_len:185 episode reward: total was 11.500000. running mean: -18.286710\n",
      "ep 19: ep_len:925 episode reward: total was -16.990000. running mean: -18.273743\n",
      "ep 19: ep_len:510 episode reward: total was -4.400000. running mean: -18.135005\n",
      "ep 19: ep_len:705 episode reward: total was -11.770000. running mean: -18.071355\n",
      "ep 19: ep_len:500 episode reward: total was -7.680000. running mean: -17.967442\n",
      "ep 19: ep_len:1005 episode reward: total was -5.910000. running mean: -17.846867\n",
      "ep 19: ep_len:500 episode reward: total was -9.270000. running mean: -17.761098\n",
      "ep 19: ep_len:302 episode reward: total was 21.500000. running mean: -17.368487\n",
      "ep 19: ep_len:308 episode reward: total was 6.240000. running mean: -17.132403\n",
      "ep 19: ep_len:1115 episode reward: total was -118.990000. running mean: -18.150979\n",
      "ep 19: ep_len:835 episode reward: total was -29.690000. running mean: -18.266369\n",
      "ep 19: ep_len:970 episode reward: total was -88.000000. running mean: -18.963705\n",
      "ep 19: ep_len:505 episode reward: total was -3.220000. running mean: -18.806268\n",
      "ep 19: ep_len:950 episode reward: total was -7.450000. running mean: -18.692705\n",
      "ep 19: ep_len:505 episode reward: total was -26.810000. running mean: -18.773878\n",
      "ep 19: ep_len:975 episode reward: total was -40.570000. running mean: -18.991840\n",
      "ep 19: ep_len:945 episode reward: total was -36.210000. running mean: -19.164021\n",
      "ep 19: ep_len:190 episode reward: total was 11.500000. running mean: -18.857381\n",
      "ep 19: ep_len:795 episode reward: total was -4.200000. running mean: -18.710807\n",
      "ep 19: ep_len:500 episode reward: total was 9.910000. running mean: -18.424599\n",
      "ep 19: ep_len:505 episode reward: total was -69.490000. running mean: -18.935253\n",
      "ep 19: ep_len:500 episode reward: total was -30.660000. running mean: -19.052501\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 19: ep_len:500 episode reward: total was 11.310000. running mean: -18.748876\n",
      "ep 19: ep_len:920 episode reward: total was -31.870000. running mean: -18.880087\n",
      "ep 19: ep_len:545 episode reward: total was -14.140000. running mean: -18.832686\n",
      "ep 19: ep_len:500 episode reward: total was 11.770000. running mean: -18.526659\n",
      "ep 19: ep_len:725 episode reward: total was 0.710000. running mean: -18.334292\n",
      "ep 19: ep_len:229 episode reward: total was 19.500000. running mean: -17.955950\n",
      "ep 19: ep_len:850 episode reward: total was -10.220000. running mean: -17.878590\n",
      "ep 19: ep_len:500 episode reward: total was -6.240000. running mean: -17.762204\n",
      "ep 19: ep_len:710 episode reward: total was -22.870000. running mean: -17.813282\n",
      "ep 19: ep_len:500 episode reward: total was -0.820000. running mean: -17.643349\n",
      "ep 19: ep_len:500 episode reward: total was -1.230000. running mean: -17.479216\n",
      "ep 19: ep_len:820 episode reward: total was -31.710000. running mean: -17.621524\n",
      "ep 19: ep_len:500 episode reward: total was 6.650000. running mean: -17.378808\n",
      "ep 19: ep_len:500 episode reward: total was 1.750000. running mean: -17.187520\n",
      "ep 19: ep_len:1610 episode reward: total was -106.630000. running mean: -18.081945\n",
      "ep 19: ep_len:500 episode reward: total was 8.250000. running mean: -17.818626\n",
      "ep 19: ep_len:585 episode reward: total was -7.970000. running mean: -17.720139\n",
      "ep 19: ep_len:695 episode reward: total was -10.780000. running mean: -17.650738\n",
      "ep 19: ep_len:267 episode reward: total was 22.500000. running mean: -17.249231\n",
      "ep 19: ep_len:2655 episode reward: total was -381.770000. running mean: -20.894438\n",
      "ep 19: ep_len:565 episode reward: total was -32.740000. running mean: -21.012894\n",
      "ep 19: ep_len:314 episode reward: total was 22.000000. running mean: -20.582765\n",
      "ep 19: ep_len:555 episode reward: total was -13.080000. running mean: -20.507737\n",
      "ep 19: ep_len:565 episode reward: total was -13.060000. running mean: -20.433260\n",
      "ep 19: ep_len:860 episode reward: total was 14.240000. running mean: -20.086527\n",
      "ep 19: ep_len:500 episode reward: total was 6.410000. running mean: -19.821562\n",
      "ep 19: ep_len:500 episode reward: total was -26.740000. running mean: -19.890746\n",
      "ep 19: ep_len:500 episode reward: total was -21.660000. running mean: -19.908439\n",
      "ep 19: ep_len:2455 episode reward: total was -314.300000. running mean: -22.852355\n",
      "ep 19: ep_len:500 episode reward: total was -9.760000. running mean: -22.721431\n",
      "ep 19: ep_len:500 episode reward: total was -5.690000. running mean: -22.551117\n",
      "ep 19: ep_len:1530 episode reward: total was -73.290000. running mean: -23.058506\n",
      "ep 19: ep_len:520 episode reward: total was -19.230000. running mean: -23.020221\n",
      "ep 19: ep_len:805 episode reward: total was -24.530000. running mean: -23.035318\n",
      "ep 19: ep_len:730 episode reward: total was -27.880000. running mean: -23.083765\n",
      "ep 19: ep_len:1380 episode reward: total was -79.880000. running mean: -23.651728\n",
      "ep 19: ep_len:500 episode reward: total was 2.640000. running mean: -23.388810\n",
      "ep 19: ep_len:1485 episode reward: total was -88.990000. running mean: -24.044822\n",
      "ep 19: ep_len:233 episode reward: total was 12.500000. running mean: -23.679374\n",
      "ep 19: ep_len:500 episode reward: total was 3.720000. running mean: -23.405380\n",
      "ep 19: ep_len:910 episode reward: total was -47.200000. running mean: -23.643326\n",
      "ep 19: ep_len:795 episode reward: total was -19.670000. running mean: -23.603593\n",
      "ep 19: ep_len:500 episode reward: total was 6.780000. running mean: -23.299757\n",
      "ep 19: ep_len:500 episode reward: total was -10.820000. running mean: -23.174960\n",
      "ep 19: ep_len:147 episode reward: total was 11.500000. running mean: -22.828210\n",
      "ep 19: ep_len:825 episode reward: total was -18.600000. running mean: -22.785928\n",
      "ep 19: ep_len:590 episode reward: total was 8.430000. running mean: -22.473769\n",
      "ep 19: ep_len:780 episode reward: total was -24.290000. running mean: -22.491931\n",
      "ep 19: ep_len:785 episode reward: total was -13.640000. running mean: -22.403412\n",
      "ep 19: ep_len:500 episode reward: total was -8.290000. running mean: -22.262278\n",
      "ep 19: ep_len:1315 episode reward: total was -19.680000. running mean: -22.236455\n",
      "ep 19: ep_len:500 episode reward: total was 4.510000. running mean: -21.968990\n",
      "ep 19: ep_len:2045 episode reward: total was -171.190000. running mean: -23.461200\n",
      "ep 19: ep_len:1290 episode reward: total was -27.480000. running mean: -23.501388\n",
      "ep 19: ep_len:663 episode reward: total was -59.310000. running mean: -23.859474\n",
      "ep 19: ep_len:213 episode reward: total was 16.500000. running mean: -23.455880\n",
      "ep 19: ep_len:255 episode reward: total was 16.500000. running mean: -23.056321\n",
      "ep 19: ep_len:500 episode reward: total was -3.360000. running mean: -22.859358\n",
      "ep 19: ep_len:500 episode reward: total was -20.160000. running mean: -22.832364\n",
      "ep 19: ep_len:1155 episode reward: total was -15.630000. running mean: -22.760340\n",
      "ep 19: ep_len:530 episode reward: total was -10.100000. running mean: -22.633737\n",
      "ep 19: ep_len:510 episode reward: total was -19.720000. running mean: -22.604600\n",
      "ep 19: ep_len:740 episode reward: total was -44.930000. running mean: -22.827854\n",
      "ep 19: ep_len:510 episode reward: total was -11.150000. running mean: -22.711075\n",
      "ep 19: ep_len:500 episode reward: total was 42.500000. running mean: -22.058964\n",
      "ep 19: ep_len:1837 episode reward: total was -266.000000. running mean: -24.498375\n",
      "ep 19: ep_len:309 episode reward: total was 20.500000. running mean: -24.048391\n",
      "ep 19: ep_len:1035 episode reward: total was -86.060000. running mean: -24.668507\n",
      "ep 19: ep_len:575 episode reward: total was -33.240000. running mean: -24.754222\n",
      "ep 19: ep_len:500 episode reward: total was 0.170000. running mean: -24.504980\n",
      "ep 19: ep_len:910 episode reward: total was -21.460000. running mean: -24.474530\n",
      "ep 19: ep_len:885 episode reward: total was -24.540000. running mean: -24.475185\n",
      "ep 19: ep_len:720 episode reward: total was -11.020000. running mean: -24.340633\n",
      "ep 19: ep_len:800 episode reward: total was -13.840000. running mean: -24.235627\n",
      "ep 19: ep_len:827 episode reward: total was -31.300000. running mean: -24.306270\n",
      "ep 19: ep_len:940 episode reward: total was -3.410000. running mean: -24.097308\n",
      "ep 19: ep_len:690 episode reward: total was -44.120000. running mean: -24.297534\n",
      "ep 19: ep_len:325 episode reward: total was 22.000000. running mean: -23.834559\n",
      "ep 19: ep_len:620 episode reward: total was -10.520000. running mean: -23.701414\n",
      "ep 19: ep_len:1109 episode reward: total was -208.390000. running mean: -25.548299\n",
      "ep 19: ep_len:990 episode reward: total was -3.020000. running mean: -25.323016\n",
      "ep 19: ep_len:540 episode reward: total was 4.440000. running mean: -25.025386\n",
      "ep 19: ep_len:500 episode reward: total was -15.330000. running mean: -24.928432\n",
      "ep 19: ep_len:500 episode reward: total was 17.430000. running mean: -24.504848\n",
      "ep 19: ep_len:1095 episode reward: total was -84.390000. running mean: -25.103700\n",
      "ep 19: ep_len:910 episode reward: total was -16.250000. running mean: -25.015163\n",
      "ep 19: ep_len:485 episode reward: total was 9.730000. running mean: -24.667711\n",
      "ep 19: ep_len:585 episode reward: total was -23.120000. running mean: -24.652234\n",
      "ep 19: ep_len:384 episode reward: total was 20.500000. running mean: -24.200712\n",
      "ep 19: ep_len:585 episode reward: total was -17.260000. running mean: -24.131304\n",
      "ep 19: ep_len:500 episode reward: total was -10.060000. running mean: -23.990591\n",
      "ep 19: ep_len:556 episode reward: total was -13.560000. running mean: -23.886285\n",
      "ep 19: ep_len:500 episode reward: total was 9.240000. running mean: -23.555023\n",
      "ep 19: ep_len:505 episode reward: total was 9.710000. running mean: -23.222372\n",
      "ep 19: ep_len:835 episode reward: total was -21.220000. running mean: -23.202349\n",
      "ep 19: ep_len:530 episode reward: total was -24.240000. running mean: -23.212725\n",
      "ep 19: ep_len:500 episode reward: total was 5.770000. running mean: -22.922898\n",
      "ep 19: ep_len:770 episode reward: total was -24.770000. running mean: -22.941369\n",
      "ep 19: ep_len:500 episode reward: total was -4.740000. running mean: -22.759355\n",
      "ep 19: ep_len:215 episode reward: total was 14.000000. running mean: -22.391762\n",
      "ep 19: ep_len:500 episode reward: total was 6.410000. running mean: -22.103744\n",
      "ep 19: ep_len:940 episode reward: total was -14.410000. running mean: -22.026807\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 19: ep_len:580 episode reward: total was -20.100000. running mean: -22.007539\n",
      "ep 19: ep_len:500 episode reward: total was -0.680000. running mean: -21.794263\n",
      "ep 19: ep_len:540 episode reward: total was -42.400000. running mean: -22.000321\n",
      "ep 19: ep_len:500 episode reward: total was -10.300000. running mean: -21.883317\n",
      "ep 19: ep_len:1010 episode reward: total was -33.570000. running mean: -22.000184\n",
      "ep 19: ep_len:260 episode reward: total was 18.500000. running mean: -21.595182\n",
      "ep 19: ep_len:1031 episode reward: total was -117.200000. running mean: -22.551230\n",
      "ep 19: ep_len:500 episode reward: total was -9.780000. running mean: -22.423518\n",
      "ep 19: ep_len:580 episode reward: total was -51.900000. running mean: -22.718283\n",
      "ep 19: ep_len:665 episode reward: total was -12.240000. running mean: -22.613500\n",
      "ep 19: ep_len:520 episode reward: total was -50.520000. running mean: -22.892565\n",
      "ep 19: ep_len:500 episode reward: total was -86.000000. running mean: -23.523640\n",
      "ep 19: ep_len:1215 episode reward: total was -155.850000. running mean: -24.846903\n",
      "ep 19: ep_len:500 episode reward: total was -6.730000. running mean: -24.665734\n",
      "ep 19: ep_len:500 episode reward: total was 8.250000. running mean: -24.336577\n",
      "ep 19: ep_len:500 episode reward: total was -6.020000. running mean: -24.153411\n",
      "ep 19: ep_len:500 episode reward: total was -20.960000. running mean: -24.121477\n",
      "ep 19: ep_len:500 episode reward: total was 38.000000. running mean: -23.500262\n",
      "ep 19: ep_len:910 episode reward: total was -17.260000. running mean: -23.437859\n",
      "ep 19: ep_len:500 episode reward: total was 22.790000. running mean: -22.975581\n",
      "ep 19: ep_len:540 episode reward: total was -23.210000. running mean: -22.977925\n",
      "ep 19: ep_len:880 episode reward: total was -44.230000. running mean: -23.190446\n",
      "ep 19: ep_len:590 episode reward: total was 6.260000. running mean: -22.895941\n",
      "ep 19: ep_len:875 episode reward: total was -23.270000. running mean: -22.899682\n",
      "ep 19: ep_len:500 episode reward: total was 4.700000. running mean: -22.623685\n",
      "ep 19: ep_len:500 episode reward: total was 7.390000. running mean: -22.323548\n",
      "ep 19: ep_len:500 episode reward: total was 15.040000. running mean: -21.949913\n",
      "ep 19: ep_len:970 episode reward: total was -50.600000. running mean: -22.236414\n",
      "ep 19: ep_len:625 episode reward: total was -37.180000. running mean: -22.385850\n",
      "ep 19: ep_len:500 episode reward: total was 15.380000. running mean: -22.008191\n",
      "ep 19: ep_len:442 episode reward: total was 13.660000. running mean: -21.651509\n",
      "ep 19: ep_len:1255 episode reward: total was -12.210000. running mean: -21.557094\n",
      "ep 19: ep_len:545 episode reward: total was -18.150000. running mean: -21.523023\n",
      "ep 19: ep_len:500 episode reward: total was -15.270000. running mean: -21.460493\n",
      "ep 19: ep_len:1025 episode reward: total was -114.640000. running mean: -22.392288\n",
      "ep 19: ep_len:715 episode reward: total was -1.020000. running mean: -22.178565\n",
      "ep 19: ep_len:645 episode reward: total was 8.050000. running mean: -21.876279\n",
      "ep 19: ep_len:2809 episode reward: total was -328.410000. running mean: -24.941617\n",
      "ep 19: ep_len:705 episode reward: total was -25.390000. running mean: -24.946100\n",
      "ep 19: ep_len:500 episode reward: total was 2.050000. running mean: -24.676139\n",
      "ep 19: ep_len:790 episode reward: total was -24.210000. running mean: -24.671478\n",
      "ep 19: ep_len:790 episode reward: total was -36.940000. running mean: -24.794163\n",
      "ep 19: ep_len:760 episode reward: total was -36.550000. running mean: -24.911722\n",
      "ep 19: ep_len:500 episode reward: total was 8.280000. running mean: -24.579804\n",
      "ep 19: ep_len:685 episode reward: total was -48.170000. running mean: -24.815706\n",
      "ep 19: ep_len:1095 episode reward: total was -12.230000. running mean: -24.689849\n",
      "ep 19: ep_len:890 episode reward: total was 2.470000. running mean: -24.418251\n",
      "ep 19: ep_len:505 episode reward: total was -13.210000. running mean: -24.306168\n",
      "ep 19: ep_len:1155 episode reward: total was -12.080000. running mean: -24.183907\n",
      "ep 19: ep_len:500 episode reward: total was -1.210000. running mean: -23.954168\n",
      "ep 19: ep_len:500 episode reward: total was -3.420000. running mean: -23.748826\n",
      "ep 19: ep_len:500 episode reward: total was 3.750000. running mean: -23.473838\n",
      "ep 19: ep_len:500 episode reward: total was -14.260000. running mean: -23.381699\n",
      "ep 19: ep_len:500 episode reward: total was 17.280000. running mean: -22.975082\n",
      "ep 19: ep_len:1035 episode reward: total was 10.210000. running mean: -22.643231\n",
      "ep 19: ep_len:615 episode reward: total was 1.320000. running mean: -22.403599\n",
      "ep 19: ep_len:500 episode reward: total was 1.700000. running mean: -22.162563\n",
      "ep 19: ep_len:625 episode reward: total was -27.960000. running mean: -22.220537\n",
      "ep 19: ep_len:500 episode reward: total was -12.790000. running mean: -22.126232\n",
      "ep 19: ep_len:740 episode reward: total was -12.250000. running mean: -22.027470\n",
      "ep 19: ep_len:1460 episode reward: total was -146.610000. running mean: -23.273295\n",
      "ep 19: ep_len:655 episode reward: total was -38.250000. running mean: -23.423062\n",
      "ep 19: ep_len:505 episode reward: total was 0.080000. running mean: -23.188032\n",
      "ep 19: ep_len:535 episode reward: total was -17.160000. running mean: -23.127751\n",
      "ep 19: ep_len:500 episode reward: total was -11.810000. running mean: -23.014574\n",
      "ep 19: ep_len:500 episode reward: total was 0.420000. running mean: -22.780228\n",
      "ep 19: ep_len:267 episode reward: total was 19.000000. running mean: -22.362426\n",
      "ep 19: ep_len:1800 episode reward: total was -185.570000. running mean: -23.994501\n",
      "ep 19: ep_len:1005 episode reward: total was -61.670000. running mean: -24.371256\n",
      "ep 19: ep_len:500 episode reward: total was 2.430000. running mean: -24.103244\n",
      "ep 19: ep_len:500 episode reward: total was -4.800000. running mean: -23.910211\n",
      "ep 19: ep_len:720 episode reward: total was -23.830000. running mean: -23.909409\n",
      "ep 19: ep_len:500 episode reward: total was -11.720000. running mean: -23.787515\n",
      "ep 19: ep_len:476 episode reward: total was -11.730000. running mean: -23.666940\n",
      "ep 19: ep_len:605 episode reward: total was -3.850000. running mean: -23.468771\n",
      "ep 19: ep_len:860 episode reward: total was -9.570000. running mean: -23.329783\n",
      "ep 19: ep_len:500 episode reward: total was -8.780000. running mean: -23.184285\n",
      "ep 19: ep_len:1150 episode reward: total was -47.280000. running mean: -23.425242\n",
      "ep 19: ep_len:845 episode reward: total was -16.370000. running mean: -23.354690\n",
      "ep 19: ep_len:570 episode reward: total was -24.160000. running mean: -23.362743\n",
      "ep 19: ep_len:500 episode reward: total was 7.640000. running mean: -23.052716\n",
      "ep 19: ep_len:630 episode reward: total was -14.950000. running mean: -22.971688\n",
      "ep 19: ep_len:880 episode reward: total was -21.690000. running mean: -22.958871\n",
      "ep 19: ep_len:700 episode reward: total was -51.170000. running mean: -23.240983\n",
      "ep 19: ep_len:147 episode reward: total was 8.500000. running mean: -22.923573\n",
      "ep 19: ep_len:1180 episode reward: total was -149.190000. running mean: -24.186237\n",
      "ep 19: ep_len:805 episode reward: total was -39.850000. running mean: -24.342875\n",
      "ep 19: ep_len:780 episode reward: total was -18.750000. running mean: -24.286946\n",
      "ep 19: ep_len:180 episode reward: total was 15.000000. running mean: -23.894077\n",
      "ep 19: ep_len:396 episode reward: total was 4.240000. running mean: -23.612736\n",
      "ep 19: ep_len:540 episode reward: total was -29.780000. running mean: -23.674408\n",
      "ep 19: ep_len:795 episode reward: total was -36.840000. running mean: -23.806064\n",
      "ep 19: ep_len:900 episode reward: total was 12.430000. running mean: -23.443704\n",
      "ep 19: ep_len:580 episode reward: total was -13.180000. running mean: -23.341067\n",
      "ep 19: ep_len:500 episode reward: total was 1.800000. running mean: -23.089656\n",
      "ep 19: ep_len:1590 episode reward: total was -132.210000. running mean: -24.180860\n",
      "ep 19: ep_len:177 episode reward: total was 8.500000. running mean: -23.854051\n",
      "ep 19: ep_len:500 episode reward: total was -7.490000. running mean: -23.690410\n",
      "ep 19: ep_len:221 episode reward: total was 14.500000. running mean: -23.308506\n",
      "ep 19: ep_len:500 episode reward: total was 6.930000. running mean: -23.006121\n",
      "ep 19: ep_len:500 episode reward: total was 8.710000. running mean: -22.688960\n",
      "ep 19: ep_len:116 episode reward: total was 10.000000. running mean: -22.362070\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 19: ep_len:500 episode reward: total was 10.760000. running mean: -22.030850\n",
      "ep 19: ep_len:500 episode reward: total was -13.760000. running mean: -21.948141\n",
      "ep 19: ep_len:165 episode reward: total was 13.500000. running mean: -21.593660\n",
      "ep 19: ep_len:92 episode reward: total was 6.000000. running mean: -21.317723\n",
      "ep 19: ep_len:785 episode reward: total was 15.130000. running mean: -20.953246\n",
      "ep 19: ep_len:1085 episode reward: total was 4.400000. running mean: -20.699714\n",
      "ep 19: ep_len:500 episode reward: total was 18.750000. running mean: -20.305216\n",
      "ep 19: ep_len:500 episode reward: total was 3.780000. running mean: -20.064364\n",
      "ep 19: ep_len:780 episode reward: total was 8.270000. running mean: -19.781021\n",
      "ep 19: ep_len:820 episode reward: total was -2.060000. running mean: -19.603810\n",
      "ep 19: ep_len:860 episode reward: total was -28.630000. running mean: -19.694072\n",
      "ep 19: ep_len:1085 episode reward: total was 3.330000. running mean: -19.463832\n",
      "ep 19: ep_len:500 episode reward: total was -3.510000. running mean: -19.304293\n",
      "ep 19: ep_len:525 episode reward: total was -19.690000. running mean: -19.308150\n",
      "ep 19: ep_len:500 episode reward: total was -6.290000. running mean: -19.177969\n",
      "ep 19: ep_len:585 episode reward: total was 17.790000. running mean: -18.808289\n",
      "ep 19: ep_len:685 episode reward: total was -35.790000. running mean: -18.978106\n",
      "ep 19: ep_len:500 episode reward: total was -3.050000. running mean: -18.818825\n",
      "ep 19: ep_len:1000 episode reward: total was -130.850000. running mean: -19.939137\n",
      "ep 19: ep_len:665 episode reward: total was -4.400000. running mean: -19.783746\n",
      "ep 19: ep_len:1475 episode reward: total was -265.760000. running mean: -22.243508\n",
      "ep 19: ep_len:890 episode reward: total was -59.210000. running mean: -22.613173\n",
      "ep 19: ep_len:747 episode reward: total was -88.450000. running mean: -23.271541\n",
      "ep 19: ep_len:225 episode reward: total was 10.500000. running mean: -22.933826\n",
      "ep 19: ep_len:500 episode reward: total was -40.980000. running mean: -23.114288\n",
      "ep 19: ep_len:785 episode reward: total was -16.410000. running mean: -23.047245\n",
      "ep 19: ep_len:500 episode reward: total was -19.460000. running mean: -23.011372\n",
      "ep 19: ep_len:505 episode reward: total was 2.320000. running mean: -22.758059\n",
      "ep 19: ep_len:500 episode reward: total was -16.220000. running mean: -22.692678\n",
      "ep 19: ep_len:500 episode reward: total was 1.080000. running mean: -22.454951\n",
      "ep 19: ep_len:535 episode reward: total was -20.980000. running mean: -22.440202\n",
      "ep 19: ep_len:540 episode reward: total was -61.070000. running mean: -22.826500\n",
      "ep 19: ep_len:675 episode reward: total was -35.550000. running mean: -22.953735\n",
      "ep 19: ep_len:550 episode reward: total was -22.180000. running mean: -22.945997\n",
      "ep 19: ep_len:500 episode reward: total was 14.710000. running mean: -22.569437\n",
      "ep 19: ep_len:790 episode reward: total was -74.190000. running mean: -23.085643\n",
      "ep 19: ep_len:975 episode reward: total was -62.220000. running mean: -23.476987\n",
      "ep 19: ep_len:800 episode reward: total was -33.830000. running mean: -23.580517\n",
      "ep 19: ep_len:140 episode reward: total was 8.000000. running mean: -23.264712\n",
      "ep 19: ep_len:500 episode reward: total was -7.580000. running mean: -23.107864\n",
      "ep 19: ep_len:283 episode reward: total was -0.800000. running mean: -22.884786\n",
      "ep 19: ep_len:873 episode reward: total was -95.250000. running mean: -23.608438\n",
      "ep 19: ep_len:500 episode reward: total was -9.420000. running mean: -23.466554\n",
      "ep 19: ep_len:585 episode reward: total was -14.050000. running mean: -23.372388\n",
      "ep 19: ep_len:252 episode reward: total was 16.500000. running mean: -22.973664\n",
      "ep 19: ep_len:500 episode reward: total was -8.230000. running mean: -22.826227\n",
      "ep 19: ep_len:500 episode reward: total was 9.780000. running mean: -22.500165\n",
      "ep 19: ep_len:500 episode reward: total was 40.000000. running mean: -21.875164\n",
      "ep 19: ep_len:650 episode reward: total was -6.830000. running mean: -21.724712\n",
      "ep 19: ep_len:850 episode reward: total was -4.190000. running mean: -21.549365\n",
      "ep 19: ep_len:175 episode reward: total was 10.000000. running mean: -21.233871\n",
      "ep 19: ep_len:500 episode reward: total was -1.830000. running mean: -21.039832\n",
      "ep 19: ep_len:500 episode reward: total was 3.260000. running mean: -20.796834\n",
      "ep 19: ep_len:795 episode reward: total was -22.700000. running mean: -20.815866\n",
      "ep 19: ep_len:685 episode reward: total was -39.080000. running mean: -20.998507\n",
      "ep 19: ep_len:745 episode reward: total was -73.990000. running mean: -21.528422\n",
      "ep 19: ep_len:575 episode reward: total was -1.160000. running mean: -21.324738\n",
      "ep 19: ep_len:1015 episode reward: total was -97.510000. running mean: -22.086590\n",
      "ep 19: ep_len:500 episode reward: total was -1.060000. running mean: -21.876325\n",
      "ep 19: ep_len:700 episode reward: total was -15.300000. running mean: -21.810561\n",
      "ep 19: ep_len:1320 episode reward: total was -108.080000. running mean: -22.673256\n",
      "ep 19: ep_len:1185 episode reward: total was -19.690000. running mean: -22.643423\n",
      "ep 19: ep_len:655 episode reward: total was 8.750000. running mean: -22.329489\n",
      "ep 19: ep_len:700 episode reward: total was -18.850000. running mean: -22.294694\n",
      "ep 19: ep_len:900 episode reward: total was 10.360000. running mean: -21.968147\n",
      "ep 19: ep_len:515 episode reward: total was -33.450000. running mean: -22.082966\n",
      "ep 19: ep_len:297 episode reward: total was 26.500000. running mean: -21.597136\n",
      "ep 19: ep_len:500 episode reward: total was 11.090000. running mean: -21.270265\n",
      "ep 19: ep_len:673 episode reward: total was -16.870000. running mean: -21.226262\n",
      "ep 19: ep_len:550 episode reward: total was -15.110000. running mean: -21.165099\n",
      "ep 19: ep_len:500 episode reward: total was -5.470000. running mean: -21.008148\n",
      "ep 19: ep_len:515 episode reward: total was -20.230000. running mean: -21.000367\n",
      "ep 19: ep_len:500 episode reward: total was -53.740000. running mean: -21.327763\n",
      "ep 19: ep_len:515 episode reward: total was -11.290000. running mean: -21.227386\n",
      "ep 19: ep_len:500 episode reward: total was -19.740000. running mean: -21.212512\n",
      "ep 19: ep_len:1410 episode reward: total was -118.390000. running mean: -22.184287\n",
      "ep 19: ep_len:1005 episode reward: total was -15.490000. running mean: -22.117344\n",
      "ep 19: ep_len:555 episode reward: total was -25.200000. running mean: -22.148170\n",
      "ep 19: ep_len:740 episode reward: total was -21.800000. running mean: -22.144689\n",
      "ep 19: ep_len:845 episode reward: total was -50.880000. running mean: -22.432042\n",
      "ep 19: ep_len:415 episode reward: total was 27.000000. running mean: -21.937721\n",
      "ep 19: ep_len:705 episode reward: total was -19.820000. running mean: -21.916544\n",
      "ep 19: ep_len:555 episode reward: total was -38.350000. running mean: -22.080879\n",
      "ep 19: ep_len:500 episode reward: total was -5.740000. running mean: -21.917470\n",
      "ep 19: ep_len:500 episode reward: total was -3.930000. running mean: -21.737595\n",
      "ep 19: ep_len:1030 episode reward: total was -24.790000. running mean: -21.768119\n",
      "ep 19: ep_len:920 episode reward: total was -4.450000. running mean: -21.594938\n",
      "ep 19: ep_len:650 episode reward: total was -37.130000. running mean: -21.750289\n",
      "ep 19: ep_len:660 episode reward: total was -14.890000. running mean: -21.681686\n",
      "ep 19: ep_len:500 episode reward: total was -23.010000. running mean: -21.694969\n",
      "ep 19: ep_len:500 episode reward: total was 12.750000. running mean: -21.350519\n",
      "ep 19: ep_len:500 episode reward: total was 18.320000. running mean: -20.953814\n",
      "ep 19: ep_len:500 episode reward: total was 10.970000. running mean: -20.634576\n",
      "ep 19: ep_len:1150 episode reward: total was -34.830000. running mean: -20.776530\n",
      "ep 19: ep_len:965 episode reward: total was -99.120000. running mean: -21.559965\n",
      "ep 19: ep_len:530 episode reward: total was -13.740000. running mean: -21.481765\n",
      "ep 19: ep_len:515 episode reward: total was -20.750000. running mean: -21.474447\n",
      "ep 19: ep_len:500 episode reward: total was -22.850000. running mean: -21.488203\n",
      "ep 19: ep_len:500 episode reward: total was -3.740000. running mean: -21.310721\n",
      "ep 19: ep_len:493 episode reward: total was 6.640000. running mean: -21.031214\n",
      "ep 19: ep_len:505 episode reward: total was 14.370000. running mean: -20.677202\n",
      "ep 19: ep_len:745 episode reward: total was -68.250000. running mean: -21.152930\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 19: ep_len:500 episode reward: total was -3.060000. running mean: -20.972000\n",
      "ep 19: ep_len:975 episode reward: total was -17.120000. running mean: -20.933480\n",
      "ep 19: ep_len:500 episode reward: total was -15.970000. running mean: -20.883845\n",
      "ep 19: ep_len:500 episode reward: total was 21.230000. running mean: -20.462707\n",
      "ep 19: ep_len:515 episode reward: total was -24.940000. running mean: -20.507480\n",
      "ep 19: ep_len:535 episode reward: total was -16.260000. running mean: -20.465005\n",
      "ep 19: ep_len:500 episode reward: total was -8.740000. running mean: -20.347755\n",
      "ep 19: ep_len:760 episode reward: total was -25.280000. running mean: -20.397078\n",
      "ep 19: ep_len:585 episode reward: total was -17.060000. running mean: -20.363707\n",
      "ep 19: ep_len:169 episode reward: total was 13.500000. running mean: -20.025070\n",
      "ep 19: ep_len:500 episode reward: total was -10.770000. running mean: -19.932519\n",
      "ep 19: ep_len:500 episode reward: total was 5.750000. running mean: -19.675694\n",
      "ep 19: ep_len:505 episode reward: total was -15.780000. running mean: -19.636737\n",
      "ep 19: ep_len:259 episode reward: total was 21.500000. running mean: -19.225370\n",
      "ep 19: ep_len:1345 episode reward: total was -135.730000. running mean: -20.390416\n",
      "ep 19: ep_len:500 episode reward: total was 4.790000. running mean: -20.138612\n",
      "ep 19: ep_len:730 episode reward: total was -11.780000. running mean: -20.055026\n",
      "ep 19: ep_len:500 episode reward: total was -27.970000. running mean: -20.134175\n",
      "ep 19: ep_len:500 episode reward: total was 4.790000. running mean: -19.884934\n",
      "ep 19: ep_len:1250 episode reward: total was -146.000000. running mean: -21.146084\n",
      "ep 19: ep_len:500 episode reward: total was -2.170000. running mean: -20.956323\n",
      "ep 19: ep_len:745 episode reward: total was -24.820000. running mean: -20.994960\n",
      "ep 19: ep_len:630 episode reward: total was -26.060000. running mean: -21.045611\n",
      "ep 19: ep_len:820 episode reward: total was -24.470000. running mean: -21.079854\n",
      "ep 19: ep_len:500 episode reward: total was -7.450000. running mean: -20.943556\n",
      "ep 19: ep_len:191 episode reward: total was 16.000000. running mean: -20.574120\n",
      "ep 19: ep_len:500 episode reward: total was -6.840000. running mean: -20.436779\n",
      "ep 19: ep_len:785 episode reward: total was -12.400000. running mean: -20.356411\n",
      "ep 19: ep_len:316 episode reward: total was 28.500000. running mean: -19.867847\n",
      "ep 19: ep_len:600 episode reward: total was 1.130000. running mean: -19.657869\n",
      "ep 19: ep_len:500 episode reward: total was 12.760000. running mean: -19.333690\n",
      "ep 19: ep_len:1515 episode reward: total was -243.460000. running mean: -21.574953\n",
      "ep 19: ep_len:840 episode reward: total was -16.690000. running mean: -21.526104\n",
      "ep 19: ep_len:505 episode reward: total was 41.500000. running mean: -20.895843\n",
      "ep 19: ep_len:525 episode reward: total was -11.610000. running mean: -20.802984\n",
      "ep 19: ep_len:855 episode reward: total was -1.360000. running mean: -20.608554\n",
      "ep 19: ep_len:500 episode reward: total was 20.830000. running mean: -20.194169\n",
      "ep 19: ep_len:500 episode reward: total was 2.420000. running mean: -19.968027\n",
      "ep 19: ep_len:505 episode reward: total was -15.720000. running mean: -19.925547\n",
      "ep 19: ep_len:500 episode reward: total was 16.610000. running mean: -19.560191\n",
      "ep 19: ep_len:705 episode reward: total was -3.800000. running mean: -19.402589\n",
      "ep 19: ep_len:500 episode reward: total was -2.160000. running mean: -19.230164\n",
      "ep 19: ep_len:4920 episode reward: total was -852.720000. running mean: -27.565062\n",
      "ep 19: ep_len:257 episode reward: total was 18.000000. running mean: -27.109411\n",
      "ep 19: ep_len:670 episode reward: total was -16.860000. running mean: -27.006917\n",
      "ep 19: ep_len:505 episode reward: total was -2.180000. running mean: -26.758648\n",
      "ep 19: ep_len:418 episode reward: total was 40.000000. running mean: -26.091062\n",
      "ep 19: ep_len:505 episode reward: total was 14.290000. running mean: -25.687251\n",
      "ep 19: ep_len:580 episode reward: total was -29.190000. running mean: -25.722278\n",
      "ep 19: ep_len:500 episode reward: total was 3.190000. running mean: -25.433156\n",
      "ep 19: ep_len:500 episode reward: total was 8.950000. running mean: -25.089324\n",
      "ep 19: ep_len:935 episode reward: total was -28.250000. running mean: -25.120931\n",
      "ep 19: ep_len:500 episode reward: total was -11.440000. running mean: -24.984122\n",
      "ep 19: ep_len:500 episode reward: total was 20.800000. running mean: -24.526280\n",
      "ep 19: ep_len:1025 episode reward: total was -61.780000. running mean: -24.898817\n",
      "ep 19: ep_len:500 episode reward: total was 4.300000. running mean: -24.606829\n",
      "ep 19: ep_len:890 episode reward: total was -12.770000. running mean: -24.488461\n",
      "ep 19: ep_len:500 episode reward: total was -7.830000. running mean: -24.321876\n",
      "ep 19: ep_len:1510 episode reward: total was -92.810000. running mean: -25.006758\n",
      "ep 19: ep_len:505 episode reward: total was 11.810000. running mean: -24.638590\n",
      "ep 19: ep_len:500 episode reward: total was -0.720000. running mean: -24.399404\n",
      "ep 19: ep_len:976 episode reward: total was -112.210000. running mean: -25.277510\n",
      "ep 19: ep_len:457 episode reward: total was 3.260000. running mean: -24.992135\n",
      "ep 19: ep_len:645 episode reward: total was -12.330000. running mean: -24.865514\n",
      "ep 19: ep_len:750 episode reward: total was -2.210000. running mean: -24.638959\n",
      "ep 19: ep_len:790 episode reward: total was 17.590000. running mean: -24.216669\n",
      "ep 19: ep_len:500 episode reward: total was 1.270000. running mean: -23.961802\n",
      "ep 19: ep_len:880 episode reward: total was -41.080000. running mean: -24.132984\n",
      "ep 19: ep_len:500 episode reward: total was -18.450000. running mean: -24.076154\n",
      "ep 19: ep_len:600 episode reward: total was 7.230000. running mean: -23.763093\n",
      "ep 19: ep_len:660 episode reward: total was -15.740000. running mean: -23.682862\n",
      "ep 19: ep_len:500 episode reward: total was 2.090000. running mean: -23.425133\n",
      "ep 19: ep_len:500 episode reward: total was -15.970000. running mean: -23.350582\n",
      "ep 19: ep_len:500 episode reward: total was -4.490000. running mean: -23.161976\n",
      "ep 19: ep_len:805 episode reward: total was -36.920000. running mean: -23.299556\n",
      "ep 19: ep_len:715 episode reward: total was -90.010000. running mean: -23.966661\n",
      "ep 19: ep_len:790 episode reward: total was -30.760000. running mean: -24.034594\n",
      "ep 19: ep_len:750 episode reward: total was -7.540000. running mean: -23.869648\n",
      "ep 19: ep_len:254 episode reward: total was 22.000000. running mean: -23.410952\n",
      "ep 19: ep_len:505 episode reward: total was -11.740000. running mean: -23.294242\n",
      "ep 19: ep_len:500 episode reward: total was -22.180000. running mean: -23.283100\n",
      "ep 19: ep_len:2647 episode reward: total was -420.630000. running mean: -27.256569\n",
      "ep 19: ep_len:500 episode reward: total was -2.000000. running mean: -27.004003\n",
      "ep 19: ep_len:500 episode reward: total was 16.240000. running mean: -26.571563\n",
      "ep 19: ep_len:785 episode reward: total was -44.910000. running mean: -26.754948\n",
      "ep 19: ep_len:650 episode reward: total was -31.560000. running mean: -26.802998\n",
      "ep 19: ep_len:680 episode reward: total was -16.620000. running mean: -26.701168\n",
      "ep 19: ep_len:535 episode reward: total was 10.830000. running mean: -26.325856\n",
      "ep 19: ep_len:740 episode reward: total was -20.270000. running mean: -26.265298\n",
      "ep 19: ep_len:790 episode reward: total was -68.160000. running mean: -26.684245\n",
      "ep 19: ep_len:660 episode reward: total was -31.540000. running mean: -26.732802\n",
      "ep 19: ep_len:540 episode reward: total was -0.940000. running mean: -26.474874\n",
      "ep 19: ep_len:720 episode reward: total was -9.030000. running mean: -26.300426\n",
      "ep 19: ep_len:705 episode reward: total was -25.910000. running mean: -26.296521\n",
      "ep 19: ep_len:119 episode reward: total was 9.000000. running mean: -25.943556\n",
      "ep 19: ep_len:142 episode reward: total was 12.500000. running mean: -25.559121\n",
      "ep 19: ep_len:565 episode reward: total was -31.730000. running mean: -25.620829\n",
      "ep 19: ep_len:700 episode reward: total was -17.810000. running mean: -25.542721\n",
      "ep 19: ep_len:500 episode reward: total was 9.690000. running mean: -25.190394\n",
      "ep 19: ep_len:775 episode reward: total was -25.770000. running mean: -25.196190\n",
      "ep 19: ep_len:500 episode reward: total was -6.940000. running mean: -25.013628\n",
      "ep 19: ep_len:500 episode reward: total was -11.350000. running mean: -24.876992\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 19: ep_len:130 episode reward: total was 11.500000. running mean: -24.513222\n",
      "ep 19: ep_len:500 episode reward: total was -86.490000. running mean: -25.132990\n",
      "ep 19: ep_len:525 episode reward: total was -13.140000. running mean: -25.013060\n",
      "ep 19: ep_len:505 episode reward: total was -12.170000. running mean: -24.884629\n",
      "ep 19: ep_len:164 episode reward: total was 13.000000. running mean: -24.505783\n",
      "ep 19: ep_len:500 episode reward: total was 24.290000. running mean: -24.017825\n",
      "ep 19: ep_len:468 episode reward: total was 7.810000. running mean: -23.699547\n",
      "ep 19: ep_len:520 episode reward: total was -72.740000. running mean: -24.189951\n",
      "ep 19: ep_len:280 episode reward: total was 17.500000. running mean: -23.773052\n",
      "ep 19: ep_len:520 episode reward: total was -15.170000. running mean: -23.687021\n",
      "ep 19: ep_len:181 episode reward: total was 13.500000. running mean: -23.315151\n",
      "ep 19: ep_len:565 episode reward: total was 17.310000. running mean: -22.908900\n",
      "ep 19: ep_len:500 episode reward: total was -0.820000. running mean: -22.688011\n",
      "ep 19: ep_len:500 episode reward: total was -3.470000. running mean: -22.495830\n",
      "ep 19: ep_len:2740 episode reward: total was -447.470000. running mean: -26.745572\n",
      "ep 19: ep_len:500 episode reward: total was 22.760000. running mean: -26.250516\n",
      "ep 19: ep_len:5540 episode reward: total was -869.510000. running mean: -34.683111\n",
      "ep 19: ep_len:1101 episode reward: total was -71.890000. running mean: -35.055180\n",
      "ep 19: ep_len:525 episode reward: total was -7.260000. running mean: -34.777228\n",
      "ep 19: ep_len:570 episode reward: total was -43.920000. running mean: -34.868656\n",
      "ep 19: ep_len:500 episode reward: total was 29.500000. running mean: -34.224969\n",
      "ep 19: ep_len:500 episode reward: total was -35.040000. running mean: -34.233120\n",
      "ep 19: ep_len:845 episode reward: total was -31.100000. running mean: -34.201789\n",
      "ep 19: ep_len:173 episode reward: total was -6.500000. running mean: -33.924771\n",
      "epsilon:0.092231 episode_count: 15783. steps_count: 11216457.000000\n",
      "ep 20: ep_len:505 episode reward: total was 6.730000. running mean: -33.518223\n",
      "ep 20: ep_len:1430 episode reward: total was -237.900000. running mean: -35.562041\n",
      "ep 20: ep_len:545 episode reward: total was -40.670000. running mean: -35.613120\n",
      "ep 20: ep_len:625 episode reward: total was -36.470000. running mean: -35.621689\n",
      "ep 20: ep_len:500 episode reward: total was 3.370000. running mean: -35.231772\n",
      "ep 20: ep_len:500 episode reward: total was -43.700000. running mean: -35.316455\n",
      "ep 20: ep_len:1080 episode reward: total was -33.550000. running mean: -35.298790\n",
      "ep 20: ep_len:500 episode reward: total was -24.300000. running mean: -35.188802\n",
      "ep 20: ep_len:890 episode reward: total was -45.880000. running mean: -35.295714\n",
      "ep 20: ep_len:530 episode reward: total was -7.070000. running mean: -35.013457\n",
      "ep 20: ep_len:525 episode reward: total was -0.310000. running mean: -34.666422\n",
      "ep 20: ep_len:500 episode reward: total was 7.800000. running mean: -34.241758\n",
      "ep 20: ep_len:540 episode reward: total was -4.810000. running mean: -33.947441\n",
      "ep 20: ep_len:212 episode reward: total was -37.000000. running mean: -33.977966\n",
      "ep 20: ep_len:890 episode reward: total was -51.800000. running mean: -34.156186\n",
      "ep 20: ep_len:855 episode reward: total was -55.910000. running mean: -34.373725\n",
      "ep 20: ep_len:500 episode reward: total was 17.220000. running mean: -33.857787\n",
      "ep 20: ep_len:500 episode reward: total was -2.640000. running mean: -33.545610\n",
      "ep 20: ep_len:500 episode reward: total was -27.630000. running mean: -33.486453\n",
      "ep 20: ep_len:580 episode reward: total was -27.170000. running mean: -33.423289\n",
      "ep 20: ep_len:500 episode reward: total was 15.210000. running mean: -32.936956\n",
      "ep 20: ep_len:1485 episode reward: total was -140.500000. running mean: -34.012586\n",
      "ep 20: ep_len:1245 episode reward: total was -68.800000. running mean: -34.360461\n",
      "ep 20: ep_len:1420 episode reward: total was -57.780000. running mean: -34.594656\n",
      "ep 20: ep_len:500 episode reward: total was -1.890000. running mean: -34.267609\n",
      "ep 20: ep_len:505 episode reward: total was -26.510000. running mean: -34.190033\n",
      "ep 20: ep_len:500 episode reward: total was 2.490000. running mean: -33.823233\n",
      "ep 20: ep_len:500 episode reward: total was -0.710000. running mean: -33.492101\n",
      "ep 20: ep_len:815 episode reward: total was -15.420000. running mean: -33.311380\n",
      "ep 20: ep_len:500 episode reward: total was -1.910000. running mean: -32.997366\n",
      "ep 20: ep_len:515 episode reward: total was 11.770000. running mean: -32.549692\n",
      "ep 20: ep_len:580 episode reward: total was -12.720000. running mean: -32.351395\n",
      "ep 20: ep_len:500 episode reward: total was 20.260000. running mean: -31.825281\n",
      "ep 20: ep_len:710 episode reward: total was -46.880000. running mean: -31.975828\n",
      "ep 20: ep_len:500 episode reward: total was -9.210000. running mean: -31.748170\n",
      "ep 20: ep_len:1000 episode reward: total was 3.220000. running mean: -31.398489\n",
      "ep 20: ep_len:585 episode reward: total was -24.130000. running mean: -31.325804\n",
      "ep 20: ep_len:493 episode reward: total was 11.750000. running mean: -30.895046\n",
      "ep 20: ep_len:816 episode reward: total was -20.590000. running mean: -30.791995\n",
      "ep 20: ep_len:500 episode reward: total was 14.220000. running mean: -30.341875\n",
      "ep 20: ep_len:269 episode reward: total was 25.000000. running mean: -29.788456\n",
      "ep 20: ep_len:525 episode reward: total was -7.600000. running mean: -29.566572\n",
      "ep 20: ep_len:990 episode reward: total was 7.680000. running mean: -29.194106\n",
      "ep 20: ep_len:560 episode reward: total was -50.930000. running mean: -29.411465\n",
      "ep 20: ep_len:680 episode reward: total was -9.800000. running mean: -29.215350\n",
      "ep 20: ep_len:500 episode reward: total was -0.170000. running mean: -28.924897\n",
      "ep 20: ep_len:790 episode reward: total was -14.690000. running mean: -28.782548\n",
      "ep 20: ep_len:1000 episode reward: total was -42.850000. running mean: -28.923222\n",
      "ep 20: ep_len:505 episode reward: total was -7.540000. running mean: -28.709390\n",
      "ep 20: ep_len:233 episode reward: total was 2.500000. running mean: -28.397296\n",
      "ep 20: ep_len:795 episode reward: total was -61.980000. running mean: -28.733123\n",
      "ep 20: ep_len:690 episode reward: total was -15.840000. running mean: -28.604192\n",
      "ep 20: ep_len:595 episode reward: total was 14.320000. running mean: -28.174950\n",
      "ep 20: ep_len:615 episode reward: total was -10.940000. running mean: -28.002601\n",
      "ep 20: ep_len:800 episode reward: total was -2.640000. running mean: -27.748975\n",
      "ep 20: ep_len:500 episode reward: total was -23.840000. running mean: -27.709885\n",
      "ep 20: ep_len:589 episode reward: total was -102.890000. running mean: -28.461686\n",
      "ep 20: ep_len:375 episode reward: total was 20.510000. running mean: -27.971969\n",
      "ep 20: ep_len:1240 episode reward: total was -188.430000. running mean: -29.576550\n",
      "ep 20: ep_len:500 episode reward: total was 14.830000. running mean: -29.132484\n",
      "ep 20: ep_len:525 episode reward: total was -18.680000. running mean: -29.027959\n",
      "ep 20: ep_len:505 episode reward: total was -33.580000. running mean: -29.073480\n",
      "ep 20: ep_len:505 episode reward: total was 12.680000. running mean: -28.655945\n",
      "ep 20: ep_len:1140 episode reward: total was -55.340000. running mean: -28.922785\n",
      "ep 20: ep_len:605 episode reward: total was -35.200000. running mean: -28.985558\n",
      "ep 20: ep_len:500 episode reward: total was 9.320000. running mean: -28.602502\n",
      "ep 20: ep_len:680 episode reward: total was -27.980000. running mean: -28.596277\n",
      "ep 20: ep_len:715 episode reward: total was -21.820000. running mean: -28.528514\n",
      "ep 20: ep_len:191 episode reward: total was 16.000000. running mean: -28.083229\n",
      "ep 20: ep_len:500 episode reward: total was -4.750000. running mean: -27.849897\n",
      "ep 20: ep_len:685 episode reward: total was -26.440000. running mean: -27.835798\n",
      "ep 20: ep_len:414 episode reward: total was -25.550000. running mean: -27.812940\n",
      "ep 20: ep_len:835 episode reward: total was -32.460000. running mean: -27.859410\n",
      "ep 20: ep_len:500 episode reward: total was -22.770000. running mean: -27.808516\n",
      "ep 20: ep_len:500 episode reward: total was -13.280000. running mean: -27.663231\n",
      "ep 20: ep_len:500 episode reward: total was -2.560000. running mean: -27.412199\n",
      "ep 20: ep_len:500 episode reward: total was -22.030000. running mean: -27.358377\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 20: ep_len:930 episode reward: total was 5.620000. running mean: -27.028593\n",
      "ep 20: ep_len:500 episode reward: total was -15.840000. running mean: -26.916707\n",
      "ep 20: ep_len:930 episode reward: total was 5.160000. running mean: -26.595940\n",
      "ep 20: ep_len:73 episode reward: total was 5.500000. running mean: -26.274981\n",
      "ep 20: ep_len:550 episode reward: total was -4.150000. running mean: -26.053731\n",
      "ep 20: ep_len:194 episode reward: total was -2.000000. running mean: -25.813194\n",
      "ep 20: ep_len:500 episode reward: total was -45.600000. running mean: -26.011062\n",
      "ep 20: ep_len:620 episode reward: total was -17.170000. running mean: -25.922651\n",
      "ep 20: ep_len:500 episode reward: total was -24.110000. running mean: -25.904524\n",
      "ep 20: ep_len:600 episode reward: total was -5.620000. running mean: -25.701679\n",
      "ep 20: ep_len:500 episode reward: total was 18.780000. running mean: -25.256862\n",
      "ep 20: ep_len:820 episode reward: total was -67.060000. running mean: -25.674894\n",
      "ep 20: ep_len:500 episode reward: total was 2.280000. running mean: -25.395345\n",
      "ep 20: ep_len:760 episode reward: total was -23.780000. running mean: -25.379191\n",
      "ep 20: ep_len:840 episode reward: total was -61.740000. running mean: -25.742800\n",
      "ep 20: ep_len:505 episode reward: total was 13.310000. running mean: -25.352272\n",
      "ep 20: ep_len:1040 episode reward: total was -62.280000. running mean: -25.721549\n",
      "ep 20: ep_len:880 episode reward: total was -13.110000. running mean: -25.595433\n",
      "ep 20: ep_len:500 episode reward: total was -24.330000. running mean: -25.582779\n",
      "ep 20: ep_len:500 episode reward: total was -20.400000. running mean: -25.530951\n",
      "ep 20: ep_len:675 episode reward: total was -10.820000. running mean: -25.383842\n",
      "ep 20: ep_len:500 episode reward: total was -19.770000. running mean: -25.327703\n",
      "ep 20: ep_len:785 episode reward: total was -62.010000. running mean: -25.694526\n",
      "ep 20: ep_len:500 episode reward: total was 14.160000. running mean: -25.295981\n",
      "ep 20: ep_len:755 episode reward: total was -53.770000. running mean: -25.580721\n",
      "ep 20: ep_len:1025 episode reward: total was -1.620000. running mean: -25.341114\n",
      "ep 20: ep_len:535 episode reward: total was -12.600000. running mean: -25.213703\n",
      "ep 20: ep_len:228 episode reward: total was 23.000000. running mean: -24.731566\n",
      "ep 20: ep_len:500 episode reward: total was -1.300000. running mean: -24.497250\n",
      "ep 20: ep_len:133 episode reward: total was 8.500000. running mean: -24.167278\n",
      "ep 20: ep_len:500 episode reward: total was 1.080000. running mean: -23.914805\n",
      "ep 20: ep_len:500 episode reward: total was -10.780000. running mean: -23.783457\n",
      "ep 20: ep_len:505 episode reward: total was 13.490000. running mean: -23.410722\n",
      "ep 20: ep_len:500 episode reward: total was -8.230000. running mean: -23.258915\n",
      "ep 20: ep_len:720 episode reward: total was -24.870000. running mean: -23.275026\n",
      "ep 20: ep_len:845 episode reward: total was -74.600000. running mean: -23.788276\n",
      "ep 20: ep_len:500 episode reward: total was -53.890000. running mean: -24.089293\n",
      "ep 20: ep_len:570 episode reward: total was -17.270000. running mean: -24.021100\n",
      "ep 20: ep_len:994 episode reward: total was -69.240000. running mean: -24.473289\n",
      "ep 20: ep_len:1118 episode reward: total was -153.360000. running mean: -25.762156\n",
      "ep 20: ep_len:555 episode reward: total was -32.290000. running mean: -25.827434\n",
      "ep 20: ep_len:870 episode reward: total was -33.300000. running mean: -25.902160\n",
      "ep 20: ep_len:500 episode reward: total was -87.500000. running mean: -26.518139\n",
      "ep 20: ep_len:1000 episode reward: total was 1.170000. running mean: -26.241257\n",
      "ep 20: ep_len:810 episode reward: total was -56.000000. running mean: -26.538845\n",
      "ep 20: ep_len:500 episode reward: total was -3.940000. running mean: -26.312856\n",
      "ep 20: ep_len:755 episode reward: total was -18.220000. running mean: -26.231928\n",
      "ep 20: ep_len:540 episode reward: total was -18.160000. running mean: -26.151208\n",
      "ep 20: ep_len:820 episode reward: total was -41.840000. running mean: -26.308096\n",
      "ep 20: ep_len:500 episode reward: total was 7.450000. running mean: -25.970515\n",
      "ep 20: ep_len:500 episode reward: total was 9.290000. running mean: -25.617910\n",
      "ep 20: ep_len:500 episode reward: total was 5.740000. running mean: -25.304331\n",
      "ep 20: ep_len:1450 episode reward: total was -46.300000. running mean: -25.514288\n",
      "ep 20: ep_len:1940 episode reward: total was -266.850000. running mean: -27.927645\n",
      "ep 20: ep_len:500 episode reward: total was 7.160000. running mean: -27.576768\n",
      "ep 20: ep_len:580 episode reward: total was -12.410000. running mean: -27.425101\n",
      "ep 20: ep_len:510 episode reward: total was 3.250000. running mean: -27.118350\n",
      "ep 20: ep_len:2815 episode reward: total was -356.460000. running mean: -30.411766\n",
      "ep 20: ep_len:500 episode reward: total was 15.770000. running mean: -29.949949\n",
      "ep 20: ep_len:500 episode reward: total was 8.740000. running mean: -29.563049\n",
      "ep 20: ep_len:1530 episode reward: total was -129.960000. running mean: -30.567019\n",
      "ep 20: ep_len:500 episode reward: total was 19.210000. running mean: -30.069248\n",
      "ep 20: ep_len:505 episode reward: total was 12.230000. running mean: -29.646256\n",
      "ep 20: ep_len:105 episode reward: total was 9.000000. running mean: -29.259793\n",
      "ep 20: ep_len:181 episode reward: total was 16.500000. running mean: -28.802195\n",
      "ep 20: ep_len:540 episode reward: total was -23.700000. running mean: -28.751173\n",
      "ep 20: ep_len:188 episode reward: total was 12.500000. running mean: -28.338662\n",
      "ep 20: ep_len:500 episode reward: total was 9.810000. running mean: -27.957175\n",
      "ep 20: ep_len:1030 episode reward: total was 4.180000. running mean: -27.635803\n",
      "ep 20: ep_len:500 episode reward: total was -52.610000. running mean: -27.885545\n",
      "ep 20: ep_len:250 episode reward: total was 16.000000. running mean: -27.446690\n",
      "ep 20: ep_len:535 episode reward: total was -15.260000. running mean: -27.324823\n",
      "ep 20: ep_len:650 episode reward: total was -97.270000. running mean: -28.024275\n",
      "ep 20: ep_len:500 episode reward: total was -41.470000. running mean: -28.158732\n",
      "ep 20: ep_len:500 episode reward: total was 20.310000. running mean: -27.674045\n",
      "ep 20: ep_len:175 episode reward: total was 11.500000. running mean: -27.282304\n",
      "ep 20: ep_len:595 episode reward: total was -15.020000. running mean: -27.159681\n",
      "ep 20: ep_len:860 episode reward: total was -17.250000. running mean: -27.060584\n",
      "ep 20: ep_len:500 episode reward: total was 5.580000. running mean: -26.734178\n",
      "ep 20: ep_len:925 episode reward: total was 1.570000. running mean: -26.451137\n",
      "ep 20: ep_len:815 episode reward: total was -8.360000. running mean: -26.270225\n",
      "ep 20: ep_len:735 episode reward: total was -6.430000. running mean: -26.071823\n",
      "ep 20: ep_len:540 episode reward: total was -2.300000. running mean: -25.834105\n",
      "ep 20: ep_len:500 episode reward: total was -6.760000. running mean: -25.643364\n",
      "ep 20: ep_len:500 episode reward: total was -17.060000. running mean: -25.557530\n",
      "ep 20: ep_len:920 episode reward: total was -31.200000. running mean: -25.613955\n",
      "ep 20: ep_len:192 episode reward: total was 17.500000. running mean: -25.182815\n",
      "ep 20: ep_len:690 episode reward: total was -19.880000. running mean: -25.129787\n",
      "ep 20: ep_len:500 episode reward: total was 16.730000. running mean: -24.711189\n",
      "ep 20: ep_len:500 episode reward: total was -10.800000. running mean: -24.572077\n",
      "ep 20: ep_len:530 episode reward: total was -14.630000. running mean: -24.472657\n",
      "ep 20: ep_len:640 episode reward: total was -9.360000. running mean: -24.321530\n",
      "ep 20: ep_len:510 episode reward: total was -18.280000. running mean: -24.261115\n",
      "ep 20: ep_len:520 episode reward: total was -36.380000. running mean: -24.382304\n",
      "ep 20: ep_len:500 episode reward: total was -0.420000. running mean: -24.142681\n",
      "ep 20: ep_len:500 episode reward: total was 1.760000. running mean: -23.883654\n",
      "ep 20: ep_len:790 episode reward: total was -15.300000. running mean: -23.797817\n",
      "ep 20: ep_len:860 episode reward: total was -38.730000. running mean: -23.947139\n",
      "ep 20: ep_len:680 episode reward: total was -25.930000. running mean: -23.966968\n",
      "ep 20: ep_len:168 episode reward: total was 12.000000. running mean: -23.607298\n",
      "ep 20: ep_len:960 episode reward: total was -42.810000. running mean: -23.799325\n",
      "ep 20: ep_len:500 episode reward: total was -11.350000. running mean: -23.674832\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 20: ep_len:510 episode reward: total was -29.330000. running mean: -23.731383\n",
      "ep 20: ep_len:640 episode reward: total was -25.110000. running mean: -23.745170\n",
      "ep 20: ep_len:550 episode reward: total was -28.730000. running mean: -23.795018\n",
      "ep 20: ep_len:555 episode reward: total was -16.580000. running mean: -23.722868\n",
      "ep 20: ep_len:960 episode reward: total was -55.290000. running mean: -24.038539\n",
      "ep 20: ep_len:520 episode reward: total was -1.330000. running mean: -23.811454\n",
      "ep 20: ep_len:540 episode reward: total was -25.230000. running mean: -23.825639\n",
      "ep 20: ep_len:500 episode reward: total was 24.230000. running mean: -23.345083\n",
      "ep 20: ep_len:505 episode reward: total was -26.800000. running mean: -23.379632\n",
      "ep 20: ep_len:500 episode reward: total was -16.310000. running mean: -23.308936\n",
      "ep 20: ep_len:585 episode reward: total was -38.270000. running mean: -23.458546\n",
      "ep 20: ep_len:690 episode reward: total was -16.850000. running mean: -23.392461\n",
      "ep 20: ep_len:900 episode reward: total was -24.260000. running mean: -23.401136\n",
      "ep 20: ep_len:650 episode reward: total was 0.480000. running mean: -23.162325\n",
      "ep 20: ep_len:1425 episode reward: total was -90.660000. running mean: -23.837302\n",
      "ep 20: ep_len:2000 episode reward: total was -264.750000. running mean: -26.246429\n",
      "ep 20: ep_len:500 episode reward: total was 6.750000. running mean: -25.916464\n",
      "ep 20: ep_len:500 episode reward: total was 3.810000. running mean: -25.619200\n",
      "ep 20: ep_len:780 episode reward: total was -11.860000. running mean: -25.481608\n",
      "ep 20: ep_len:850 episode reward: total was -12.870000. running mean: -25.355492\n",
      "ep 20: ep_len:505 episode reward: total was -12.720000. running mean: -25.229137\n",
      "ep 20: ep_len:178 episode reward: total was 14.500000. running mean: -24.831845\n",
      "ep 20: ep_len:655 episode reward: total was -29.620000. running mean: -24.879727\n",
      "ep 20: ep_len:695 episode reward: total was -8.080000. running mean: -24.711730\n",
      "ep 20: ep_len:530 episode reward: total was -7.740000. running mean: -24.542012\n",
      "ep 20: ep_len:600 episode reward: total was -21.070000. running mean: -24.507292\n",
      "ep 20: ep_len:500 episode reward: total was -0.450000. running mean: -24.266719\n",
      "ep 20: ep_len:5950 episode reward: total was -978.580000. running mean: -33.809852\n",
      "ep 20: ep_len:500 episode reward: total was -4.340000. running mean: -33.515153\n",
      "ep 20: ep_len:1070 episode reward: total was -17.820000. running mean: -33.358202\n",
      "ep 20: ep_len:500 episode reward: total was 9.360000. running mean: -32.931020\n",
      "ep 20: ep_len:830 episode reward: total was -33.110000. running mean: -32.932810\n",
      "ep 20: ep_len:625 episode reward: total was 9.080000. running mean: -32.512682\n",
      "ep 20: ep_len:325 episode reward: total was 21.510000. running mean: -31.972455\n",
      "ep 20: ep_len:670 episode reward: total was -18.910000. running mean: -31.841830\n",
      "ep 20: ep_len:535 episode reward: total was -47.050000. running mean: -31.993912\n",
      "ep 20: ep_len:500 episode reward: total was -38.680000. running mean: -32.060773\n",
      "ep 20: ep_len:500 episode reward: total was 6.290000. running mean: -31.677265\n",
      "ep 20: ep_len:660 episode reward: total was 3.670000. running mean: -31.323792\n",
      "ep 20: ep_len:540 episode reward: total was -29.270000. running mean: -31.303255\n",
      "ep 20: ep_len:208 episode reward: total was 15.000000. running mean: -30.840222\n",
      "ep 20: ep_len:740 episode reward: total was 5.920000. running mean: -30.472620\n",
      "ep 20: ep_len:730 episode reward: total was -25.920000. running mean: -30.427094\n",
      "ep 20: ep_len:510 episode reward: total was -38.040000. running mean: -30.503223\n",
      "ep 20: ep_len:615 episode reward: total was -10.940000. running mean: -30.307590\n",
      "ep 20: ep_len:795 episode reward: total was -2.050000. running mean: -30.025015\n",
      "ep 20: ep_len:413 episode reward: total was 6.230000. running mean: -29.662464\n",
      "ep 20: ep_len:670 episode reward: total was -49.210000. running mean: -29.857940\n",
      "ep 20: ep_len:500 episode reward: total was -3.700000. running mean: -29.596360\n",
      "ep 20: ep_len:500 episode reward: total was 10.740000. running mean: -29.192997\n",
      "ep 20: ep_len:500 episode reward: total was -13.830000. running mean: -29.039367\n",
      "ep 20: ep_len:675 episode reward: total was -21.930000. running mean: -28.968273\n",
      "ep 20: ep_len:500 episode reward: total was -6.270000. running mean: -28.741290\n",
      "ep 20: ep_len:855 episode reward: total was -38.740000. running mean: -28.841277\n",
      "ep 20: ep_len:500 episode reward: total was 22.240000. running mean: -28.330465\n",
      "ep 20: ep_len:555 episode reward: total was -55.500000. running mean: -28.602160\n",
      "ep 20: ep_len:500 episode reward: total was -17.410000. running mean: -28.490238\n",
      "ep 20: ep_len:1000 episode reward: total was -8.320000. running mean: -28.288536\n",
      "ep 20: ep_len:500 episode reward: total was 7.050000. running mean: -27.935151\n",
      "ep 20: ep_len:500 episode reward: total was 22.270000. running mean: -27.433099\n",
      "ep 20: ep_len:745 episode reward: total was -27.850000. running mean: -27.437268\n",
      "ep 20: ep_len:765 episode reward: total was -18.290000. running mean: -27.345796\n",
      "ep 20: ep_len:500 episode reward: total was 8.460000. running mean: -26.987738\n",
      "ep 20: ep_len:1563 episode reward: total was -209.030000. running mean: -28.808160\n",
      "ep 20: ep_len:500 episode reward: total was -11.230000. running mean: -28.632379\n",
      "ep 20: ep_len:500 episode reward: total was -7.260000. running mean: -28.418655\n",
      "ep 20: ep_len:525 episode reward: total was -29.300000. running mean: -28.427468\n",
      "ep 20: ep_len:500 episode reward: total was -22.300000. running mean: -28.366194\n",
      "ep 20: ep_len:735 episode reward: total was -5.650000. running mean: -28.139032\n",
      "ep 20: ep_len:650 episode reward: total was -103.490000. running mean: -28.892541\n",
      "ep 20: ep_len:500 episode reward: total was -19.280000. running mean: -28.796416\n",
      "ep 20: ep_len:71 episode reward: total was 7.000000. running mean: -28.438452\n",
      "ep 20: ep_len:500 episode reward: total was 5.800000. running mean: -28.096067\n",
      "ep 20: ep_len:500 episode reward: total was -0.270000. running mean: -27.817807\n",
      "ep 20: ep_len:500 episode reward: total was -19.280000. running mean: -27.732428\n",
      "ep 20: ep_len:1400 episode reward: total was -66.780000. running mean: -28.122904\n",
      "ep 20: ep_len:585 episode reward: total was -14.000000. running mean: -27.981675\n",
      "ep 20: ep_len:865 episode reward: total was -17.880000. running mean: -27.880658\n",
      "ep 20: ep_len:500 episode reward: total was -3.230000. running mean: -27.634152\n",
      "ep 20: ep_len:209 episode reward: total was 20.500000. running mean: -27.152810\n",
      "ep 20: ep_len:620 episode reward: total was -62.530000. running mean: -27.506582\n",
      "ep 20: ep_len:555 episode reward: total was -19.630000. running mean: -27.427816\n",
      "ep 20: ep_len:236 episode reward: total was 17.500000. running mean: -26.978538\n",
      "ep 20: ep_len:610 episode reward: total was -6.980000. running mean: -26.778553\n",
      "ep 20: ep_len:950 episode reward: total was -12.450000. running mean: -26.635267\n",
      "ep 20: ep_len:950 episode reward: total was -9.510000. running mean: -26.464015\n",
      "ep 20: ep_len:171 episode reward: total was 12.500000. running mean: -26.074374\n",
      "ep 20: ep_len:197 episode reward: total was 16.500000. running mean: -25.648631\n",
      "ep 20: ep_len:620 episode reward: total was -15.980000. running mean: -25.551944\n",
      "ep 20: ep_len:635 episode reward: total was -2.420000. running mean: -25.320625\n",
      "ep 20: ep_len:505 episode reward: total was -7.040000. running mean: -25.137819\n",
      "ep 20: ep_len:620 episode reward: total was -6.290000. running mean: -24.949341\n",
      "ep 20: ep_len:670 episode reward: total was -9.820000. running mean: -24.798047\n",
      "ep 20: ep_len:500 episode reward: total was 32.000000. running mean: -24.230067\n",
      "ep 20: ep_len:500 episode reward: total was -5.280000. running mean: -24.040566\n",
      "ep 20: ep_len:625 episode reward: total was -29.100000. running mean: -24.091160\n",
      "ep 20: ep_len:505 episode reward: total was 4.520000. running mean: -23.805049\n",
      "ep 20: ep_len:505 episode reward: total was 1.770000. running mean: -23.549298\n",
      "ep 20: ep_len:950 episode reward: total was -9.510000. running mean: -23.408905\n",
      "ep 20: ep_len:580 episode reward: total was -19.360000. running mean: -23.368416\n",
      "ep 20: ep_len:1235 episode reward: total was -178.340000. running mean: -24.918132\n",
      "ep 20: ep_len:500 episode reward: total was -7.190000. running mean: -24.740851\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 20: ep_len:500 episode reward: total was 17.250000. running mean: -24.320942\n",
      "ep 20: ep_len:545 episode reward: total was -21.670000. running mean: -24.294433\n",
      "ep 20: ep_len:374 episode reward: total was 0.050000. running mean: -24.050988\n",
      "ep 20: ep_len:630 episode reward: total was -46.260000. running mean: -24.273079\n",
      "ep 20: ep_len:1325 episode reward: total was -80.970000. running mean: -24.840048\n",
      "ep 20: ep_len:500 episode reward: total was 8.280000. running mean: -24.508847\n",
      "ep 20: ep_len:530 episode reward: total was 3.500000. running mean: -24.228759\n",
      "ep 20: ep_len:875 episode reward: total was -22.870000. running mean: -24.215171\n",
      "ep 20: ep_len:975 episode reward: total was -64.200000. running mean: -24.615020\n",
      "ep 20: ep_len:1470 episode reward: total was -136.490000. running mean: -25.733769\n",
      "ep 20: ep_len:685 episode reward: total was -27.970000. running mean: -25.756132\n",
      "ep 20: ep_len:500 episode reward: total was -12.360000. running mean: -25.622170\n",
      "ep 20: ep_len:500 episode reward: total was -3.790000. running mean: -25.403849\n",
      "ep 20: ep_len:580 episode reward: total was -20.100000. running mean: -25.350810\n",
      "ep 20: ep_len:349 episode reward: total was 29.000000. running mean: -24.807302\n",
      "ep 20: ep_len:985 episode reward: total was -46.560000. running mean: -25.024829\n",
      "ep 20: ep_len:535 episode reward: total was -21.200000. running mean: -24.986581\n",
      "ep 20: ep_len:540 episode reward: total was -26.910000. running mean: -25.005815\n",
      "ep 20: ep_len:595 episode reward: total was -26.130000. running mean: -25.017057\n",
      "ep 20: ep_len:2015 episode reward: total was -295.390000. running mean: -27.720786\n",
      "ep 20: ep_len:730 episode reward: total was -55.640000. running mean: -27.999978\n",
      "ep 20: ep_len:500 episode reward: total was 9.720000. running mean: -27.622779\n",
      "ep 20: ep_len:555 episode reward: total was 1.530000. running mean: -27.331251\n",
      "ep 20: ep_len:570 episode reward: total was -25.170000. running mean: -27.309638\n",
      "ep 20: ep_len:179 episode reward: total was 11.500000. running mean: -26.921542\n",
      "ep 20: ep_len:224 episode reward: total was 17.500000. running mean: -26.477326\n",
      "ep 20: ep_len:202 episode reward: total was 14.000000. running mean: -26.072553\n",
      "ep 20: ep_len:211 episode reward: total was 8.500000. running mean: -25.726828\n",
      "ep 20: ep_len:935 episode reward: total was -152.190000. running mean: -26.991459\n",
      "ep 20: ep_len:615 episode reward: total was -21.040000. running mean: -26.931945\n",
      "ep 20: ep_len:182 episode reward: total was 13.500000. running mean: -26.527625\n",
      "ep 20: ep_len:500 episode reward: total was 5.270000. running mean: -26.209649\n",
      "ep 20: ep_len:760 episode reward: total was -18.380000. running mean: -26.131353\n",
      "ep 20: ep_len:510 episode reward: total was 1.380000. running mean: -25.856239\n",
      "ep 20: ep_len:535 episode reward: total was -32.280000. running mean: -25.920477\n",
      "ep 20: ep_len:374 episode reward: total was -21.000000. running mean: -25.871272\n",
      "ep 20: ep_len:500 episode reward: total was 4.760000. running mean: -25.564959\n",
      "ep 20: ep_len:382 episode reward: total was -5.730000. running mean: -25.366610\n",
      "ep 20: ep_len:955 episode reward: total was -27.940000. running mean: -25.392344\n",
      "ep 20: ep_len:555 episode reward: total was -26.210000. running mean: -25.400520\n",
      "ep 20: ep_len:810 episode reward: total was -27.920000. running mean: -25.425715\n",
      "ep 20: ep_len:500 episode reward: total was -21.760000. running mean: -25.389058\n",
      "ep 20: ep_len:975 episode reward: total was -30.840000. running mean: -25.443567\n",
      "ep 20: ep_len:500 episode reward: total was 8.830000. running mean: -25.100831\n",
      "ep 20: ep_len:500 episode reward: total was 22.730000. running mean: -24.622523\n",
      "ep 20: ep_len:505 episode reward: total was 0.300000. running mean: -24.373298\n",
      "ep 20: ep_len:530 episode reward: total was -31.280000. running mean: -24.442365\n",
      "ep 20: ep_len:740 episode reward: total was -17.630000. running mean: -24.374241\n",
      "ep 20: ep_len:910 episode reward: total was -42.640000. running mean: -24.556899\n",
      "ep 20: ep_len:500 episode reward: total was -6.270000. running mean: -24.374030\n",
      "ep 20: ep_len:640 episode reward: total was -31.090000. running mean: -24.441190\n",
      "ep 20: ep_len:370 episode reward: total was 26.500000. running mean: -23.931778\n",
      "ep 20: ep_len:500 episode reward: total was -27.850000. running mean: -23.970960\n",
      "ep 20: ep_len:1333 episode reward: total was -174.120000. running mean: -25.472450\n",
      "ep 20: ep_len:720 episode reward: total was -15.750000. running mean: -25.375226\n",
      "ep 20: ep_len:500 episode reward: total was 27.760000. running mean: -24.843874\n",
      "ep 20: ep_len:152 episode reward: total was 15.000000. running mean: -24.445435\n",
      "ep 20: ep_len:500 episode reward: total was 16.790000. running mean: -24.033080\n",
      "ep 20: ep_len:500 episode reward: total was 12.720000. running mean: -23.665550\n",
      "ep 20: ep_len:2140 episode reward: total was -262.110000. running mean: -26.049994\n",
      "ep 20: ep_len:1120 episode reward: total was -122.040000. running mean: -27.009894\n",
      "ep 20: ep_len:905 episode reward: total was -51.740000. running mean: -27.257195\n",
      "ep 20: ep_len:500 episode reward: total was 35.000000. running mean: -26.634623\n",
      "ep 20: ep_len:500 episode reward: total was -6.840000. running mean: -26.436677\n",
      "ep 20: ep_len:700 episode reward: total was -15.790000. running mean: -26.330210\n",
      "ep 20: ep_len:925 episode reward: total was -54.690000. running mean: -26.613808\n",
      "ep 20: ep_len:720 episode reward: total was -47.580000. running mean: -26.823470\n",
      "ep 20: ep_len:540 episode reward: total was -75.730000. running mean: -27.312535\n",
      "ep 20: ep_len:575 episode reward: total was -34.740000. running mean: -27.386810\n",
      "ep 20: ep_len:585 episode reward: total was -11.000000. running mean: -27.222942\n",
      "ep 20: ep_len:500 episode reward: total was -53.500000. running mean: -27.485713\n",
      "ep 20: ep_len:140 episode reward: total was 12.500000. running mean: -27.085855\n",
      "ep 20: ep_len:1265 episode reward: total was -219.720000. running mean: -29.012197\n",
      "ep 20: ep_len:625 episode reward: total was -26.070000. running mean: -28.982775\n",
      "ep 20: ep_len:705 episode reward: total was -13.790000. running mean: -28.830847\n",
      "ep 20: ep_len:500 episode reward: total was -5.140000. running mean: -28.593939\n",
      "ep 20: ep_len:500 episode reward: total was -23.290000. running mean: -28.540899\n",
      "ep 20: ep_len:725 episode reward: total was 14.760000. running mean: -28.107890\n",
      "ep 20: ep_len:163 episode reward: total was 13.000000. running mean: -27.696811\n",
      "ep 20: ep_len:780 episode reward: total was -25.760000. running mean: -27.677443\n",
      "ep 20: ep_len:500 episode reward: total was 6.680000. running mean: -27.333869\n",
      "ep 20: ep_len:635 episode reward: total was -8.880000. running mean: -27.149330\n",
      "ep 20: ep_len:500 episode reward: total was 18.260000. running mean: -26.695237\n",
      "ep 20: ep_len:670 episode reward: total was -0.790000. running mean: -26.436185\n",
      "ep 20: ep_len:1100 episode reward: total was -17.760000. running mean: -26.349423\n",
      "ep 20: ep_len:500 episode reward: total was 2.670000. running mean: -26.059228\n",
      "ep 20: ep_len:510 episode reward: total was -5.300000. running mean: -25.851636\n",
      "ep 20: ep_len:500 episode reward: total was -24.220000. running mean: -25.835320\n",
      "ep 20: ep_len:500 episode reward: total was 15.110000. running mean: -25.425867\n",
      "ep 20: ep_len:500 episode reward: total was 15.750000. running mean: -25.014108\n",
      "ep 20: ep_len:675 episode reward: total was -17.890000. running mean: -24.942867\n",
      "ep 20: ep_len:500 episode reward: total was 0.200000. running mean: -24.691438\n",
      "ep 20: ep_len:620 episode reward: total was -56.380000. running mean: -25.008324\n",
      "ep 20: ep_len:192 episode reward: total was 13.500000. running mean: -24.623241\n",
      "ep 20: ep_len:670 episode reward: total was 2.160000. running mean: -24.355408\n",
      "ep 20: ep_len:500 episode reward: total was 4.200000. running mean: -24.069854\n",
      "ep 20: ep_len:575 episode reward: total was -22.130000. running mean: -24.050456\n",
      "ep 20: ep_len:1535 episode reward: total was -260.240000. running mean: -26.412351\n",
      "ep 20: ep_len:715 episode reward: total was -3.770000. running mean: -26.185927\n",
      "ep 20: ep_len:1627 episode reward: total was -292.760000. running mean: -28.851668\n",
      "ep 20: ep_len:640 episode reward: total was -31.850000. running mean: -28.881652\n",
      "ep 20: ep_len:900 episode reward: total was 23.170000. running mean: -28.361135\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 20: ep_len:500 episode reward: total was 17.800000. running mean: -27.899524\n",
      "ep 20: ep_len:1430 episode reward: total was -124.450000. running mean: -28.865028\n",
      "ep 20: ep_len:795 episode reward: total was -35.420000. running mean: -28.930578\n",
      "ep 20: ep_len:680 episode reward: total was -46.650000. running mean: -29.107772\n",
      "ep 20: ep_len:314 episode reward: total was 22.000000. running mean: -28.596695\n",
      "ep 20: ep_len:1075 episode reward: total was -102.910000. running mean: -29.339828\n",
      "ep 20: ep_len:560 episode reward: total was 1.630000. running mean: -29.030129\n",
      "ep 20: ep_len:1435 episode reward: total was -102.220000. running mean: -29.762028\n",
      "ep 20: ep_len:199 episode reward: total was 13.500000. running mean: -29.329408\n",
      "ep 20: ep_len:910 episode reward: total was -0.030000. running mean: -29.036414\n",
      "ep 20: ep_len:500 episode reward: total was 30.500000. running mean: -28.441050\n",
      "ep 20: ep_len:810 episode reward: total was -26.710000. running mean: -28.423739\n",
      "ep 20: ep_len:830 episode reward: total was -28.690000. running mean: -28.426402\n",
      "ep 20: ep_len:500 episode reward: total was 7.300000. running mean: -28.069138\n",
      "ep 20: ep_len:162 episode reward: total was 13.000000. running mean: -27.658446\n",
      "ep 20: ep_len:255 episode reward: total was 19.500000. running mean: -27.186862\n",
      "ep 20: ep_len:740 episode reward: total was -25.840000. running mean: -27.173393\n",
      "ep 20: ep_len:500 episode reward: total was -3.140000. running mean: -26.933059\n",
      "ep 20: ep_len:665 episode reward: total was -14.360000. running mean: -26.807329\n",
      "ep 20: ep_len:585 episode reward: total was -11.970000. running mean: -26.658955\n",
      "ep 20: ep_len:315 episode reward: total was 22.500000. running mean: -26.167366\n",
      "ep 20: ep_len:500 episode reward: total was 5.760000. running mean: -25.848092\n",
      "ep 20: ep_len:885 episode reward: total was -52.820000. running mean: -26.117811\n",
      "ep 20: ep_len:500 episode reward: total was 5.120000. running mean: -25.805433\n",
      "ep 20: ep_len:175 episode reward: total was 16.500000. running mean: -25.382379\n",
      "ep 20: ep_len:920 episode reward: total was -31.540000. running mean: -25.443955\n",
      "ep 20: ep_len:985 episode reward: total was -43.420000. running mean: -25.623716\n",
      "ep 20: ep_len:154 episode reward: total was 12.000000. running mean: -25.247478\n",
      "ep 20: ep_len:865 episode reward: total was -8.320000. running mean: -25.078204\n",
      "ep 20: ep_len:505 episode reward: total was -8.150000. running mean: -24.908922\n",
      "ep 20: ep_len:500 episode reward: total was -19.000000. running mean: -24.849832\n",
      "ep 20: ep_len:500 episode reward: total was -21.880000. running mean: -24.820134\n",
      "ep 20: ep_len:780 episode reward: total was 10.280000. running mean: -24.469133\n",
      "ep 20: ep_len:880 episode reward: total was -17.230000. running mean: -24.396741\n",
      "ep 20: ep_len:317 episode reward: total was 22.500000. running mean: -23.927774\n",
      "ep 20: ep_len:500 episode reward: total was 5.150000. running mean: -23.636996\n",
      "ep 20: ep_len:500 episode reward: total was 38.000000. running mean: -23.020626\n",
      "ep 20: ep_len:1535 episode reward: total was -212.110000. running mean: -24.911520\n",
      "ep 20: ep_len:500 episode reward: total was 9.230000. running mean: -24.570105\n",
      "ep 20: ep_len:705 episode reward: total was -28.720000. running mean: -24.611604\n",
      "ep 20: ep_len:665 episode reward: total was -30.700000. running mean: -24.672488\n",
      "ep 20: ep_len:535 episode reward: total was 24.800000. running mean: -24.177763\n",
      "ep 20: ep_len:1035 episode reward: total was -24.050000. running mean: -24.176485\n",
      "ep 20: ep_len:895 episode reward: total was -26.540000. running mean: -24.200120\n",
      "ep 20: ep_len:700 episode reward: total was -29.760000. running mean: -24.255719\n",
      "ep 20: ep_len:775 episode reward: total was -20.290000. running mean: -24.216062\n",
      "ep 20: ep_len:682 episode reward: total was -43.320000. running mean: -24.407101\n",
      "ep 20: ep_len:965 episode reward: total was -20.690000. running mean: -24.369930\n",
      "ep 20: ep_len:500 episode reward: total was -2.770000. running mean: -24.153931\n",
      "ep 20: ep_len:525 episode reward: total was -25.260000. running mean: -24.164992\n",
      "ep 20: ep_len:770 episode reward: total was 11.030000. running mean: -23.813042\n",
      "ep 20: ep_len:900 episode reward: total was -31.580000. running mean: -23.890711\n",
      "ep 20: ep_len:500 episode reward: total was -2.590000. running mean: -23.677704\n",
      "ep 20: ep_len:500 episode reward: total was -15.270000. running mean: -23.593627\n",
      "ep 20: ep_len:500 episode reward: total was -1.400000. running mean: -23.371691\n",
      "ep 20: ep_len:11145 episode reward: total was -2131.670000. running mean: -44.454674\n",
      "ep 20: ep_len:1065 episode reward: total was -17.890000. running mean: -44.189027\n",
      "ep 20: ep_len:735 episode reward: total was -57.550000. running mean: -44.322637\n",
      "ep 20: ep_len:530 episode reward: total was -41.900000. running mean: -44.298411\n",
      "ep 20: ep_len:10 episode reward: total was -0.500000. running mean: -43.860427\n",
      "ep 20: ep_len:500 episode reward: total was 19.210000. running mean: -43.229722\n",
      "ep 20: ep_len:500 episode reward: total was -55.330000. running mean: -43.350725\n",
      "ep 20: ep_len:725 episode reward: total was -13.720000. running mean: -43.054418\n",
      "ep 20: ep_len:500 episode reward: total was 17.160000. running mean: -42.452274\n",
      "ep 20: ep_len:500 episode reward: total was 24.290000. running mean: -41.784851\n",
      "ep 20: ep_len:905 episode reward: total was 0.050000. running mean: -41.366502\n",
      "ep 20: ep_len:500 episode reward: total was -0.710000. running mean: -40.959937\n",
      "ep 20: ep_len:590 episode reward: total was -43.310000. running mean: -40.983438\n",
      "ep 20: ep_len:650 episode reward: total was -13.900000. running mean: -40.712604\n",
      "ep 20: ep_len:500 episode reward: total was 3.780000. running mean: -40.267678\n",
      "ep 20: ep_len:770 episode reward: total was -24.770000. running mean: -40.112701\n",
      "ep 20: ep_len:500 episode reward: total was -3.210000. running mean: -39.743674\n",
      "ep 20: ep_len:645 episode reward: total was -37.630000. running mean: -39.722537\n",
      "ep 20: ep_len:635 episode reward: total was -7.910000. running mean: -39.404412\n",
      "ep 20: ep_len:500 episode reward: total was -6.400000. running mean: -39.074368\n",
      "ep 20: ep_len:505 episode reward: total was -5.240000. running mean: -38.736024\n",
      "ep 20: ep_len:1030 episode reward: total was -46.660000. running mean: -38.815264\n",
      "ep 20: ep_len:530 episode reward: total was 3.040000. running mean: -38.396711\n",
      "ep 20: ep_len:500 episode reward: total was 6.810000. running mean: -37.944644\n",
      "ep 20: ep_len:560 episode reward: total was -5.410000. running mean: -37.619297\n",
      "ep 20: ep_len:500 episode reward: total was 18.260000. running mean: -37.060504\n",
      "ep 20: ep_len:500 episode reward: total was -27.850000. running mean: -36.968399\n",
      "ep 20: ep_len:652 episode reward: total was -64.400000. running mean: -37.242715\n",
      "ep 20: ep_len:500 episode reward: total was -10.740000. running mean: -36.977688\n",
      "ep 20: ep_len:437 episode reward: total was 30.000000. running mean: -36.307911\n",
      "ep 20: ep_len:663 episode reward: total was -56.820000. running mean: -36.513032\n",
      "ep 20: ep_len:500 episode reward: total was 7.940000. running mean: -36.068502\n",
      "ep 20: ep_len:630 episode reward: total was -46.340000. running mean: -36.171217\n",
      "ep 20: ep_len:185 episode reward: total was 14.000000. running mean: -35.669505\n",
      "ep 20: ep_len:218 episode reward: total was -35.500000. running mean: -35.667810\n",
      "ep 20: ep_len:535 episode reward: total was -27.260000. running mean: -35.583732\n",
      "ep 20: ep_len:965 episode reward: total was -24.280000. running mean: -35.470694\n",
      "ep 20: ep_len:500 episode reward: total was -15.300000. running mean: -35.268987\n",
      "ep 20: ep_len:560 episode reward: total was -27.210000. running mean: -35.188397\n",
      "ep 20: ep_len:840 episode reward: total was -86.240000. running mean: -35.698914\n",
      "ep 20: ep_len:500 episode reward: total was 19.850000. running mean: -35.143424\n",
      "ep 20: ep_len:710 episode reward: total was -23.360000. running mean: -35.025590\n",
      "ep 20: ep_len:500 episode reward: total was -4.970000. running mean: -34.725034\n",
      "ep 20: ep_len:178 episode reward: total was 3.000000. running mean: -34.347784\n",
      "ep 20: ep_len:1045 episode reward: total was -119.160000. running mean: -35.195906\n",
      "ep 20: ep_len:500 episode reward: total was 6.040000. running mean: -34.783547\n",
      "ep 20: ep_len:1190 episode reward: total was -34.650000. running mean: -34.782212\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 20: ep_len:850 episode reward: total was -19.240000. running mean: -34.626789\n",
      "ep 20: ep_len:500 episode reward: total was -0.880000. running mean: -34.289322\n",
      "ep 20: ep_len:280 episode reward: total was 22.000000. running mean: -33.726428\n",
      "ep 20: ep_len:940 episode reward: total was -39.580000. running mean: -33.784964\n",
      "ep 20: ep_len:560 episode reward: total was 7.110000. running mean: -33.376014\n",
      "ep 20: ep_len:42290 episode reward: total was -8323.800000. running mean: -116.280254\n",
      "ep 20: ep_len:960 episode reward: total was -162.760000. running mean: -116.745052\n",
      "ep 20: ep_len:500 episode reward: total was 18.200000. running mean: -115.395601\n",
      "ep 20: ep_len:500 episode reward: total was -16.000000. running mean: -114.401645\n",
      "ep 20: ep_len:2210 episode reward: total was -363.850000. running mean: -116.896129\n",
      "ep 20: ep_len:740 episode reward: total was -43.890000. running mean: -116.166067\n",
      "ep 20: ep_len:500 episode reward: total was 16.480000. running mean: -114.839607\n",
      "ep 20: ep_len:820 episode reward: total was -85.760000. running mean: -114.548811\n",
      "ep 20: ep_len:453 episode reward: total was -8.540000. running mean: -113.488723\n",
      "ep 20: ep_len:665 episode reward: total was -12.560000. running mean: -112.479435\n",
      "ep 20: ep_len:805 episode reward: total was -118.630000. running mean: -112.540941\n",
      "ep 20: ep_len:1040 episode reward: total was -132.040000. running mean: -112.735932\n",
      "ep 20: ep_len:655 episode reward: total was 12.390000. running mean: -111.484672\n",
      "ep 20: ep_len:500 episode reward: total was 21.260000. running mean: -110.157226\n",
      "ep 20: ep_len:500 episode reward: total was 20.250000. running mean: -108.853153\n",
      "ep 20: ep_len:945 episode reward: total was -87.560000. running mean: -108.640222\n",
      "ep 20: ep_len:1708 episode reward: total was -268.760000. running mean: -110.241420\n",
      "ep 20: ep_len:600 episode reward: total was -76.100000. running mean: -109.900005\n",
      "ep 20: ep_len:500 episode reward: total was -17.340000. running mean: -108.974405\n",
      "ep 20: ep_len:500 episode reward: total was -57.170000. running mean: -108.456361\n",
      "ep 20: ep_len:590 episode reward: total was -75.630000. running mean: -108.128098\n",
      "ep 20: ep_len:500 episode reward: total was -15.360000. running mean: -107.200417\n",
      "ep 20: ep_len:520 episode reward: total was -30.320000. running mean: -106.431612\n",
      "ep 20: ep_len:580 episode reward: total was -44.830000. running mean: -105.815596\n",
      "ep 20: ep_len:635 episode reward: total was -39.080000. running mean: -105.148240\n",
      "ep 20: ep_len:500 episode reward: total was -4.300000. running mean: -104.139758\n",
      "ep 20: ep_len:710 episode reward: total was -103.670000. running mean: -104.135060\n",
      "ep 20: ep_len:600 episode reward: total was -5.620000. running mean: -103.149910\n",
      "ep 20: ep_len:565 episode reward: total was -41.340000. running mean: -102.531811\n",
      "ep 20: ep_len:500 episode reward: total was 10.710000. running mean: -101.399393\n",
      "ep 20: ep_len:575 episode reward: total was -21.760000. running mean: -100.602999\n",
      "ep 20: ep_len:2235 episode reward: total was -316.760000. running mean: -102.764569\n",
      "ep 20: ep_len:555 episode reward: total was 6.410000. running mean: -101.672823\n",
      "ep 20: ep_len:269 episode reward: total was 20.500000. running mean: -100.451095\n",
      "ep 20: ep_len:1450 episode reward: total was -181.980000. running mean: -101.266384\n",
      "ep 20: ep_len:1015 episode reward: total was -78.820000. running mean: -101.041920\n",
      "ep 20: ep_len:500 episode reward: total was -5.160000. running mean: -100.083101\n",
      "ep 20: ep_len:500 episode reward: total was -15.870000. running mean: -99.240970\n",
      "ep 20: ep_len:715 episode reward: total was -34.980000. running mean: -98.598360\n",
      "ep 20: ep_len:505 episode reward: total was 3.670000. running mean: -97.575676\n",
      "ep 20: ep_len:316 episode reward: total was -18.790000. running mean: -96.787820\n",
      "ep 20: ep_len:670 episode reward: total was 3.510000. running mean: -95.784842\n",
      "ep 20: ep_len:630 episode reward: total was -13.940000. running mean: -94.966393\n",
      "ep 20: ep_len:500 episode reward: total was -23.440000. running mean: -94.251129\n",
      "ep 20: ep_len:156 episode reward: total was 14.000000. running mean: -93.168618\n",
      "ep 20: ep_len:550 episode reward: total was -13.090000. running mean: -92.367832\n",
      "ep 20: ep_len:550 episode reward: total was -65.580000. running mean: -92.099953\n",
      "ep 20: ep_len:615 episode reward: total was -26.090000. running mean: -91.439854\n",
      "ep 20: ep_len:505 episode reward: total was -7.490000. running mean: -90.600355\n",
      "ep 20: ep_len:885 episode reward: total was -72.780000. running mean: -90.422152\n",
      "ep 20: ep_len:630 episode reward: total was -51.310000. running mean: -90.031030\n",
      "ep 20: ep_len:1165 episode reward: total was -164.840000. running mean: -90.779120\n",
      "ep 20: ep_len:168 episode reward: total was 10.500000. running mean: -89.766329\n",
      "ep 20: ep_len:500 episode reward: total was -14.470000. running mean: -89.013365\n",
      "ep 20: ep_len:500 episode reward: total was 10.790000. running mean: -88.015332\n",
      "ep 20: ep_len:710 episode reward: total was -18.830000. running mean: -87.323478\n",
      "ep 20: ep_len:174 episode reward: total was 14.000000. running mean: -86.310244\n",
      "ep 20: ep_len:415 episode reward: total was -50.760000. running mean: -85.954741\n",
      "ep 20: ep_len:500 episode reward: total was 22.240000. running mean: -84.872794\n",
      "ep 20: ep_len:795 episode reward: total was -38.860000. running mean: -84.412666\n",
      "ep 20: ep_len:630 episode reward: total was 7.190000. running mean: -83.496639\n",
      "ep 20: ep_len:500 episode reward: total was -28.370000. running mean: -82.945373\n",
      "ep 20: ep_len:500 episode reward: total was 24.690000. running mean: -81.869019\n",
      "ep 20: ep_len:218 episode reward: total was 15.500000. running mean: -80.895329\n",
      "ep 20: ep_len:750 episode reward: total was -114.700000. running mean: -81.233376\n",
      "ep 20: ep_len:140 episode reward: total was 9.500000. running mean: -80.326042\n",
      "ep 20: ep_len:210 episode reward: total was 19.500000. running mean: -79.327781\n",
      "ep 20: ep_len:500 episode reward: total was -18.570000. running mean: -78.720204\n",
      "ep 20: ep_len:232 episode reward: total was 20.000000. running mean: -77.733002\n",
      "ep 20: ep_len:500 episode reward: total was -15.480000. running mean: -77.110472\n",
      "ep 20: ep_len:258 episode reward: total was 22.500000. running mean: -76.114367\n",
      "ep 20: ep_len:500 episode reward: total was -11.840000. running mean: -75.471623\n",
      "ep 20: ep_len:625 episode reward: total was 16.920000. running mean: -74.547707\n",
      "ep 20: ep_len:500 episode reward: total was -10.180000. running mean: -73.904030\n",
      "ep 20: ep_len:52 episode reward: total was 3.500000. running mean: -73.129990\n",
      "ep 20: ep_len:500 episode reward: total was 17.800000. running mean: -72.220690\n",
      "ep 20: ep_len:750 episode reward: total was -28.850000. running mean: -71.786983\n",
      "ep 20: ep_len:500 episode reward: total was -8.260000. running mean: -71.151713\n",
      "ep 20: ep_len:640 episode reward: total was 16.740000. running mean: -70.272796\n",
      "ep 20: ep_len:500 episode reward: total was 0.040000. running mean: -69.569668\n",
      "ep 20: ep_len:775 episode reward: total was 8.960000. running mean: -68.784371\n",
      "ep 20: ep_len:850 episode reward: total was -34.710000. running mean: -68.443628\n",
      "ep 20: ep_len:805 episode reward: total was -24.670000. running mean: -68.005891\n",
      "ep 20: ep_len:500 episode reward: total was 10.400000. running mean: -67.221832\n",
      "ep 20: ep_len:565 episode reward: total was -15.230000. running mean: -66.701914\n",
      "ep 20: ep_len:525 episode reward: total was -31.320000. running mean: -66.348095\n",
      "ep 20: ep_len:500 episode reward: total was 5.770000. running mean: -65.626914\n",
      "ep 20: ep_len:370 episode reward: total was -3.420000. running mean: -65.004845\n",
      "ep 20: ep_len:500 episode reward: total was -21.940000. running mean: -64.574196\n",
      "ep 20: ep_len:500 episode reward: total was 1.270000. running mean: -63.915754\n",
      "ep 20: ep_len:500 episode reward: total was -5.490000. running mean: -63.331497\n",
      "ep 20: ep_len:500 episode reward: total was -24.970000. running mean: -62.947882\n",
      "ep 20: ep_len:555 episode reward: total was -80.750000. running mean: -63.125903\n",
      "ep 20: ep_len:1055 episode reward: total was -6.860000. running mean: -62.563244\n",
      "ep 20: ep_len:500 episode reward: total was -28.400000. running mean: -62.221612\n",
      "ep 20: ep_len:1250 episode reward: total was -212.680000. running mean: -63.726195\n",
      "ep 20: ep_len:600 episode reward: total was -15.440000. running mean: -63.243333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 20: ep_len:500 episode reward: total was -8.900000. running mean: -62.699900\n",
      "ep 20: ep_len:500 episode reward: total was -14.690000. running mean: -62.219801\n",
      "ep 20: ep_len:500 episode reward: total was 0.620000. running mean: -61.591403\n",
      "ep 20: ep_len:817 episode reward: total was -78.760000. running mean: -61.763089\n",
      "ep 20: ep_len:500 episode reward: total was 13.760000. running mean: -61.007858\n",
      "ep 20: ep_len:800 episode reward: total was -14.360000. running mean: -60.541380\n",
      "ep 20: ep_len:500 episode reward: total was 12.870000. running mean: -59.807266\n",
      "ep 20: ep_len:500 episode reward: total was 17.190000. running mean: -59.037293\n",
      "ep 20: ep_len:500 episode reward: total was 1.940000. running mean: -58.427520\n",
      "ep 20: ep_len:985 episode reward: total was -61.800000. running mean: -58.461245\n",
      "ep 20: ep_len:530 episode reward: total was -30.270000. running mean: -58.179333\n",
      "ep 20: ep_len:285 episode reward: total was 24.000000. running mean: -57.357539\n",
      "ep 20: ep_len:555 episode reward: total was -57.520000. running mean: -57.359164\n",
      "ep 20: ep_len:500 episode reward: total was 26.230000. running mean: -56.523272\n",
      "ep 20: ep_len:863 episode reward: total was -119.510000. running mean: -57.153140\n",
      "ep 20: ep_len:188 episode reward: total was 12.500000. running mean: -56.456608\n",
      "ep 20: ep_len:500 episode reward: total was 1.630000. running mean: -55.875742\n",
      "ep 20: ep_len:500 episode reward: total was 4.820000. running mean: -55.268785\n",
      "ep 20: ep_len:500 episode reward: total was 13.180000. running mean: -54.584297\n",
      "ep 20: ep_len:500 episode reward: total was 10.250000. running mean: -53.935954\n",
      "ep 20: ep_len:500 episode reward: total was 39.500000. running mean: -53.001594\n",
      "ep 20: ep_len:500 episode reward: total was -2.230000. running mean: -52.493878\n",
      "ep 20: ep_len:705 episode reward: total was -17.830000. running mean: -52.147240\n",
      "ep 20: ep_len:865 episode reward: total was -0.530000. running mean: -51.631067\n",
      "ep 20: ep_len:670 episode reward: total was -43.150000. running mean: -51.546256\n",
      "ep 20: ep_len:313 episode reward: total was -57.500000. running mean: -51.605794\n",
      "ep 20: ep_len:610 episode reward: total was -34.180000. running mean: -51.431536\n",
      "ep 20: ep_len:500 episode reward: total was 41.000000. running mean: -50.507221\n",
      "ep 20: ep_len:200 episode reward: total was 17.000000. running mean: -49.832148\n",
      "ep 20: ep_len:500 episode reward: total was 12.210000. running mean: -49.211727\n",
      "ep 20: ep_len:500 episode reward: total was -7.220000. running mean: -48.791810\n",
      "ep 20: ep_len:286 episode reward: total was 22.500000. running mean: -48.078892\n",
      "ep 20: ep_len:520 episode reward: total was 5.560000. running mean: -47.542503\n",
      "ep 20: ep_len:690 episode reward: total was -20.370000. running mean: -47.270778\n",
      "ep 20: ep_len:1835 episode reward: total was -207.470000. running mean: -48.872770\n",
      "ep 20: ep_len:840 episode reward: total was -28.150000. running mean: -48.665542\n",
      "ep 20: ep_len:545 episode reward: total was -2.220000. running mean: -48.201087\n",
      "ep 20: ep_len:895 episode reward: total was -6.790000. running mean: -47.786976\n",
      "ep 20: ep_len:500 episode reward: total was 19.670000. running mean: -47.112406\n",
      "ep 20: ep_len:255 episode reward: total was 15.500000. running mean: -46.486282\n",
      "ep 20: ep_len:274 episode reward: total was 18.500000. running mean: -45.836419\n",
      "ep 20: ep_len:555 episode reward: total was -24.190000. running mean: -45.619955\n",
      "ep 20: ep_len:500 episode reward: total was 32.000000. running mean: -44.843755\n",
      "ep 20: ep_len:500 episode reward: total was 9.080000. running mean: -44.304518\n",
      "ep 20: ep_len:500 episode reward: total was 8.860000. running mean: -43.772873\n",
      "ep 20: ep_len:500 episode reward: total was -15.850000. running mean: -43.493644\n",
      "ep 20: ep_len:500 episode reward: total was -26.740000. running mean: -43.326108\n",
      "ep 20: ep_len:494 episode reward: total was 6.590000. running mean: -42.826946\n",
      "ep 20: ep_len:710 episode reward: total was -10.750000. running mean: -42.506177\n",
      "ep 20: ep_len:1235 episode reward: total was -123.830000. running mean: -43.319415\n",
      "ep 20: ep_len:565 episode reward: total was -31.240000. running mean: -43.198621\n",
      "ep 20: ep_len:500 episode reward: total was 4.700000. running mean: -42.719635\n",
      "ep 20: ep_len:535 episode reward: total was 18.300000. running mean: -42.109439\n",
      "ep 20: ep_len:463 episode reward: total was 6.330000. running mean: -41.625044\n",
      "ep 20: ep_len:505 episode reward: total was 3.700000. running mean: -41.171794\n",
      "ep 20: ep_len:500 episode reward: total was 16.270000. running mean: -40.597376\n",
      "ep 20: ep_len:500 episode reward: total was -22.640000. running mean: -40.417802\n",
      "ep 20: ep_len:695 episode reward: total was -17.850000. running mean: -40.192124\n",
      "ep 20: ep_len:500 episode reward: total was -28.090000. running mean: -40.071103\n",
      "ep 20: ep_len:185 episode reward: total was 17.000000. running mean: -39.500392\n",
      "ep 20: ep_len:835 episode reward: total was -28.650000. running mean: -39.391888\n",
      "ep 20: ep_len:276 episode reward: total was 20.000000. running mean: -38.797969\n",
      "ep 20: ep_len:890 episode reward: total was -101.800000. running mean: -39.427989\n",
      "ep 20: ep_len:805 episode reward: total was -14.860000. running mean: -39.182309\n",
      "ep 20: ep_len:690 episode reward: total was -7.760000. running mean: -38.868086\n",
      "ep 20: ep_len:500 episode reward: total was -5.930000. running mean: -38.538705\n",
      "ep 20: ep_len:500 episode reward: total was 11.250000. running mean: -38.040818\n",
      "ep 20: ep_len:505 episode reward: total was -6.110000. running mean: -37.721510\n",
      "ep 20: ep_len:680 episode reward: total was -24.950000. running mean: -37.593795\n",
      "ep 20: ep_len:1025 episode reward: total was -38.600000. running mean: -37.603857\n",
      "ep 20: ep_len:550 episode reward: total was -61.100000. running mean: -37.838819\n",
      "ep 20: ep_len:500 episode reward: total was -37.430000. running mean: -37.834730\n",
      "ep 20: ep_len:570 episode reward: total was -22.350000. running mean: -37.679883\n",
      "ep 20: ep_len:585 episode reward: total was -12.830000. running mean: -37.431384\n",
      "ep 20: ep_len:525 episode reward: total was -39.400000. running mean: -37.451070\n",
      "ep 20: ep_len:227 episode reward: total was -6.850000. running mean: -37.145060\n",
      "ep 20: ep_len:835 episode reward: total was 26.100000. running mean: -36.512609\n",
      "ep 20: ep_len:800 episode reward: total was -74.350000. running mean: -36.890983\n",
      "ep 20: ep_len:785 episode reward: total was -26.240000. running mean: -36.784473\n",
      "ep 20: ep_len:500 episode reward: total was 3.200000. running mean: -36.384628\n",
      "ep 20: ep_len:610 episode reward: total was -18.510000. running mean: -36.205882\n",
      "ep 20: ep_len:830 episode reward: total was 6.010000. running mean: -35.783723\n",
      "ep 20: ep_len:665 episode reward: total was -2.900000. running mean: -35.454886\n",
      "ep 20: ep_len:510 episode reward: total was -17.210000. running mean: -35.272437\n",
      "ep 20: ep_len:500 episode reward: total was 20.260000. running mean: -34.717113\n",
      "ep 20: ep_len:760 episode reward: total was -14.690000. running mean: -34.516842\n",
      "ep 20: ep_len:535 episode reward: total was -17.160000. running mean: -34.343273\n",
      "ep 20: ep_len:515 episode reward: total was -12.150000. running mean: -34.121341\n",
      "ep 20: ep_len:100 episode reward: total was 5.500000. running mean: -33.725127\n",
      "ep 20: ep_len:500 episode reward: total was 9.260000. running mean: -33.295276\n",
      "ep 20: ep_len:500 episode reward: total was 13.790000. running mean: -32.824423\n",
      "ep 20: ep_len:500 episode reward: total was 8.640000. running mean: -32.409779\n",
      "ep 20: ep_len:570 episode reward: total was -28.200000. running mean: -32.367681\n",
      "ep 20: ep_len:500 episode reward: total was 21.440000. running mean: -31.829604\n",
      "ep 20: ep_len:830 episode reward: total was 3.160000. running mean: -31.479708\n",
      "ep 20: ep_len:500 episode reward: total was 9.750000. running mean: -31.067411\n",
      "ep 20: ep_len:500 episode reward: total was -65.740000. running mean: -31.414137\n",
      "ep 20: ep_len:500 episode reward: total was 31.270000. running mean: -30.787296\n",
      "ep 20: ep_len:685 episode reward: total was -12.820000. running mean: -30.607623\n",
      "ep 20: ep_len:184 episode reward: total was 13.500000. running mean: -30.166547\n",
      "ep 20: ep_len:595 episode reward: total was -25.090000. running mean: -30.115781\n",
      "ep 20: ep_len:500 episode reward: total was 0.320000. running mean: -29.811423\n",
      "ep 20: ep_len:930 episode reward: total was -155.770000. running mean: -31.071009\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 20: ep_len:282 episode reward: total was 22.000000. running mean: -30.540299\n",
      "ep 20: ep_len:805 episode reward: total was 8.620000. running mean: -30.148696\n",
      "ep 20: ep_len:216 episode reward: total was 19.000000. running mean: -29.657209\n",
      "ep 20: ep_len:382 episode reward: total was 31.000000. running mean: -29.050637\n",
      "ep 20: ep_len:320 episode reward: total was 23.500000. running mean: -28.525131\n",
      "ep 20: ep_len:178 episode reward: total was 8.500000. running mean: -28.154879\n",
      "ep 20: ep_len:500 episode reward: total was 14.250000. running mean: -27.730830\n",
      "ep 20: ep_len:500 episode reward: total was -15.270000. running mean: -27.606222\n",
      "ep 20: ep_len:1655 episode reward: total was -244.450000. running mean: -29.774660\n",
      "ep 20: ep_len:905 episode reward: total was -11.260000. running mean: -29.589513\n",
      "ep 20: ep_len:500 episode reward: total was 4.140000. running mean: -29.252218\n",
      "ep 20: ep_len:510 episode reward: total was 3.230000. running mean: -28.927396\n",
      "ep 20: ep_len:680 episode reward: total was -7.780000. running mean: -28.715922\n",
      "ep 20: ep_len:214 episode reward: total was 19.500000. running mean: -28.233763\n",
      "ep 20: ep_len:520 episode reward: total was -18.170000. running mean: -28.133125\n",
      "ep 20: ep_len:4890 episode reward: total was -656.450000. running mean: -34.416294\n",
      "ep 20: ep_len:500 episode reward: total was 12.720000. running mean: -33.944931\n",
      "ep 20: ep_len:550 episode reward: total was -79.770000. running mean: -34.403182\n",
      "ep 20: ep_len:675 episode reward: total was -9.810000. running mean: -34.157250\n",
      "ep 20: ep_len:191 episode reward: total was 11.500000. running mean: -33.700677\n",
      "ep 20: ep_len:500 episode reward: total was 2.310000. running mean: -33.340571\n",
      "ep 20: ep_len:500 episode reward: total was 38.000000. running mean: -32.627165\n",
      "ep 20: ep_len:287 episode reward: total was 24.000000. running mean: -32.060893\n",
      "ep 20: ep_len:895 episode reward: total was 1.660000. running mean: -31.723684\n",
      "ep 20: ep_len:483 episode reward: total was 33.000000. running mean: -31.076447\n",
      "ep 20: ep_len:324 episode reward: total was 30.500000. running mean: -30.460683\n",
      "ep 20: ep_len:505 episode reward: total was 12.270000. running mean: -30.033376\n",
      "ep 20: ep_len:740 episode reward: total was -12.150000. running mean: -29.854542\n",
      "ep 20: ep_len:500 episode reward: total was -0.390000. running mean: -29.559897\n",
      "ep 20: ep_len:500 episode reward: total was 0.500000. running mean: -29.259298\n",
      "ep 20: ep_len:555 episode reward: total was -34.780000. running mean: -29.314505\n",
      "ep 20: ep_len:505 episode reward: total was -30.350000. running mean: -29.324860\n",
      "ep 20: ep_len:840 episode reward: total was 6.650000. running mean: -28.965111\n",
      "ep 20: ep_len:2550 episode reward: total was -316.100000. running mean: -31.836460\n",
      "ep 20: ep_len:620 episode reward: total was -22.100000. running mean: -31.739096\n",
      "ep 20: ep_len:705 episode reward: total was -9.750000. running mean: -31.519205\n",
      "ep 20: ep_len:500 episode reward: total was -9.850000. running mean: -31.302513\n",
      "ep 20: ep_len:1200 episode reward: total was -65.320000. running mean: -31.642688\n",
      "ep 20: ep_len:500 episode reward: total was 20.800000. running mean: -31.118261\n",
      "ep 20: ep_len:500 episode reward: total was -5.710000. running mean: -30.864178\n",
      "ep 20: ep_len:486 episode reward: total was 41.000000. running mean: -30.145536\n",
      "ep 20: ep_len:790 episode reward: total was -23.720000. running mean: -30.081281\n",
      "ep 20: ep_len:500 episode reward: total was 6.750000. running mean: -29.712968\n",
      "ep 20: ep_len:500 episode reward: total was 15.260000. running mean: -29.263238\n",
      "ep 20: ep_len:845 episode reward: total was -99.340000. running mean: -29.964006\n",
      "ep 20: ep_len:500 episode reward: total was -4.920000. running mean: -29.713566\n",
      "ep 20: ep_len:780 episode reward: total was -10.770000. running mean: -29.524130\n",
      "ep 20: ep_len:570 episode reward: total was -35.760000. running mean: -29.586489\n",
      "ep 20: ep_len:500 episode reward: total was 3.810000. running mean: -29.252524\n",
      "ep 20: ep_len:500 episode reward: total was 12.260000. running mean: -28.837399\n",
      "ep 20: ep_len:1250 episode reward: total was -198.560000. running mean: -30.534625\n",
      "ep 20: ep_len:920 episode reward: total was -37.600000. running mean: -30.605279\n",
      "ep 20: ep_len:1265 episode reward: total was -109.630000. running mean: -31.395526\n",
      "ep 20: ep_len:830 episode reward: total was -4.120000. running mean: -31.122771\n",
      "ep 20: ep_len:720 episode reward: total was -18.500000. running mean: -30.996543\n",
      "ep 20: ep_len:815 episode reward: total was -16.600000. running mean: -30.852577\n",
      "ep 20: ep_len:640 episode reward: total was 0.470000. running mean: -30.539352\n",
      "ep 20: ep_len:850 episode reward: total was -3.370000. running mean: -30.267658\n",
      "ep 20: ep_len:500 episode reward: total was -44.860000. running mean: -30.413582\n",
      "ep 20: ep_len:500 episode reward: total was 0.780000. running mean: -30.101646\n",
      "ep 20: ep_len:510 episode reward: total was -18.080000. running mean: -29.981429\n",
      "ep 20: ep_len:500 episode reward: total was 27.750000. running mean: -29.404115\n",
      "ep 20: ep_len:720 episode reward: total was -22.850000. running mean: -29.338574\n",
      "ep 20: ep_len:670 episode reward: total was -28.000000. running mean: -29.325188\n",
      "ep 20: ep_len:525 episode reward: total was -12.130000. running mean: -29.153236\n",
      "ep 20: ep_len:500 episode reward: total was -11.750000. running mean: -28.979204\n",
      "ep 20: ep_len:900 episode reward: total was -19.420000. running mean: -28.883612\n",
      "ep 20: ep_len:1005 episode reward: total was -117.220000. running mean: -29.766976\n",
      "ep 20: ep_len:740 episode reward: total was -32.910000. running mean: -29.798406\n",
      "ep 20: ep_len:665 episode reward: total was 0.500000. running mean: -29.495422\n",
      "ep 20: ep_len:810 episode reward: total was 23.630000. running mean: -28.964168\n",
      "ep 20: ep_len:750 episode reward: total was -10.670000. running mean: -28.781226\n",
      "ep 20: ep_len:500 episode reward: total was 12.780000. running mean: -28.365614\n",
      "ep 20: ep_len:845 episode reward: total was -16.290000. running mean: -28.244858\n",
      "ep 20: ep_len:500 episode reward: total was -3.760000. running mean: -28.000009\n",
      "ep 20: ep_len:910 episode reward: total was -2.350000. running mean: -27.743509\n",
      "ep 20: ep_len:740 episode reward: total was 17.710000. running mean: -27.288974\n",
      "ep 20: ep_len:925 episode reward: total was -23.090000. running mean: -27.246984\n",
      "ep 20: ep_len:500 episode reward: total was 2.270000. running mean: -26.951814\n",
      "ep 20: ep_len:530 episode reward: total was -12.120000. running mean: -26.803496\n",
      "ep 20: ep_len:500 episode reward: total was 23.250000. running mean: -26.302961\n",
      "ep 20: ep_len:117 episode reward: total was 10.000000. running mean: -25.939932\n",
      "ep 20: ep_len:505 episode reward: total was -49.600000. running mean: -26.176532\n",
      "ep 20: ep_len:500 episode reward: total was 17.770000. running mean: -25.737067\n",
      "ep 20: ep_len:610 episode reward: total was -51.190000. running mean: -25.991596\n",
      "ep 20: ep_len:545 episode reward: total was -14.110000. running mean: -25.872780\n",
      "ep 20: ep_len:610 episode reward: total was 21.280000. running mean: -25.401252\n",
      "ep 20: ep_len:780 episode reward: total was 9.420000. running mean: -25.053040\n",
      "ep 20: ep_len:500 episode reward: total was -11.100000. running mean: -24.913510\n",
      "ep 20: ep_len:2725 episode reward: total was -457.910000. running mean: -29.243474\n",
      "ep 20: ep_len:500 episode reward: total was -0.370000. running mean: -28.954740\n",
      "ep 20: ep_len:5519 episode reward: total was -896.850000. running mean: -37.633692\n",
      "ep 20: ep_len:870 episode reward: total was -53.180000. running mean: -37.789155\n",
      "ep 20: ep_len:590 episode reward: total was -6.210000. running mean: -37.473364\n",
      "ep 20: ep_len:500 episode reward: total was 1.480000. running mean: -37.083830\n",
      "ep 20: ep_len:625 episode reward: total was -50.800000. running mean: -37.220992\n",
      "ep 20: ep_len:432 episode reward: total was -24.940000. running mean: -37.098182\n",
      "ep 20: ep_len:660 episode reward: total was -13.880000. running mean: -36.866000\n",
      "ep 20: ep_len:264 episode reward: total was -48.500000. running mean: -36.982340\n",
      "epsilon:0.076846 episode_count: 16572. steps_count: 11780758.000000\n",
      "ep 21: ep_len:500 episode reward: total was 12.750000. running mean: -36.485017\n",
      "ep 21: ep_len:780 episode reward: total was -33.810000. running mean: -36.458267\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 21: ep_len:500 episode reward: total was 8.490000. running mean: -36.008784\n",
      "ep 21: ep_len:500 episode reward: total was 2.140000. running mean: -35.627296\n",
      "ep 21: ep_len:500 episode reward: total was -4.770000. running mean: -35.318723\n",
      "ep 21: ep_len:500 episode reward: total was -24.360000. running mean: -35.209136\n",
      "ep 21: ep_len:750 episode reward: total was -68.730000. running mean: -35.544345\n",
      "ep 21: ep_len:510 episode reward: total was 2.760000. running mean: -35.161301\n",
      "ep 21: ep_len:785 episode reward: total was -25.750000. running mean: -35.067188\n",
      "ep 21: ep_len:520 episode reward: total was -14.160000. running mean: -34.858116\n",
      "ep 21: ep_len:500 episode reward: total was 1.140000. running mean: -34.498135\n",
      "ep 21: ep_len:1025 episode reward: total was -15.000000. running mean: -34.303154\n",
      "ep 21: ep_len:500 episode reward: total was -21.990000. running mean: -34.180022\n",
      "ep 21: ep_len:865 episode reward: total was -29.630000. running mean: -34.134522\n",
      "ep 21: ep_len:845 episode reward: total was -33.710000. running mean: -34.130277\n",
      "ep 21: ep_len:500 episode reward: total was 18.780000. running mean: -33.601174\n",
      "ep 21: ep_len:500 episode reward: total was -4.670000. running mean: -33.311862\n",
      "ep 21: ep_len:500 episode reward: total was -7.400000. running mean: -33.052744\n",
      "ep 21: ep_len:275 episode reward: total was 14.000000. running mean: -32.582216\n",
      "ep 21: ep_len:625 episode reward: total was -16.980000. running mean: -32.426194\n",
      "ep 21: ep_len:700 episode reward: total was -17.320000. running mean: -32.275132\n",
      "ep 21: ep_len:1819 episode reward: total was -146.890000. running mean: -33.421281\n",
      "ep 21: ep_len:1005 episode reward: total was -139.440000. running mean: -34.481468\n",
      "ep 21: ep_len:1550 episode reward: total was -263.590000. running mean: -36.772553\n",
      "ep 21: ep_len:471 episode reward: total was -13.910000. running mean: -36.543928\n",
      "ep 21: ep_len:545 episode reward: total was -61.550000. running mean: -36.793988\n",
      "ep 21: ep_len:500 episode reward: total was 1.180000. running mean: -36.414249\n",
      "ep 21: ep_len:500 episode reward: total was -16.890000. running mean: -36.219006\n",
      "ep 21: ep_len:625 episode reward: total was -12.940000. running mean: -35.986216\n",
      "ep 21: ep_len:505 episode reward: total was -18.230000. running mean: -35.808654\n",
      "ep 21: ep_len:505 episode reward: total was -6.930000. running mean: -35.519867\n",
      "ep 21: ep_len:165 episode reward: total was 5.000000. running mean: -35.114669\n",
      "ep 21: ep_len:500 episode reward: total was 21.810000. running mean: -34.545422\n",
      "ep 21: ep_len:805 episode reward: total was -4.860000. running mean: -34.248568\n",
      "ep 21: ep_len:794 episode reward: total was -137.830000. running mean: -35.284382\n",
      "ep 21: ep_len:500 episode reward: total was 21.780000. running mean: -34.713738\n",
      "ep 21: ep_len:890 episode reward: total was -5.130000. running mean: -34.417901\n",
      "ep 21: ep_len:735 episode reward: total was 0.480000. running mean: -34.068922\n",
      "ep 21: ep_len:485 episode reward: total was 16.760000. running mean: -33.560633\n",
      "ep 21: ep_len:778 episode reward: total was -12.620000. running mean: -33.351226\n",
      "ep 21: ep_len:510 episode reward: total was -21.250000. running mean: -33.230214\n",
      "ep 21: ep_len:570 episode reward: total was -25.170000. running mean: -33.149612\n",
      "ep 21: ep_len:540 episode reward: total was -11.090000. running mean: -32.929016\n",
      "ep 21: ep_len:500 episode reward: total was 17.770000. running mean: -32.422026\n",
      "ep 21: ep_len:690 episode reward: total was -12.810000. running mean: -32.225905\n",
      "ep 21: ep_len:19110 episode reward: total was -441.580000. running mean: -36.319446\n",
      "ep 21: ep_len:715 episode reward: total was -21.850000. running mean: -36.174752\n",
      "ep 21: ep_len:950 episode reward: total was -51.680000. running mean: -36.329804\n",
      "ep 21: ep_len:1402 episode reward: total was -189.970000. running mean: -37.866206\n",
      "ep 21: ep_len:164 episode reward: total was 8.500000. running mean: -37.402544\n",
      "ep 21: ep_len:138 episode reward: total was 10.500000. running mean: -36.923519\n",
      "ep 21: ep_len:825 episode reward: total was -60.480000. running mean: -37.159084\n",
      "ep 21: ep_len:500 episode reward: total was 12.070000. running mean: -36.666793\n",
      "ep 21: ep_len:715 episode reward: total was -33.740000. running mean: -36.637525\n",
      "ep 21: ep_len:675 episode reward: total was -15.840000. running mean: -36.429550\n",
      "ep 21: ep_len:78 episode reward: total was 5.000000. running mean: -36.015254\n",
      "ep 21: ep_len:500 episode reward: total was 20.220000. running mean: -35.452902\n",
      "ep 21: ep_len:500 episode reward: total was 7.210000. running mean: -35.026273\n",
      "ep 21: ep_len:830 episode reward: total was -24.230000. running mean: -34.918310\n",
      "ep 21: ep_len:17945 episode reward: total was -3295.810000. running mean: -67.527227\n",
      "ep 21: ep_len:600 episode reward: total was -7.020000. running mean: -66.922154\n",
      "ep 21: ep_len:630 episode reward: total was -14.550000. running mean: -66.398433\n",
      "ep 21: ep_len:183 episode reward: total was 16.500000. running mean: -65.569449\n",
      "ep 21: ep_len:550 episode reward: total was 15.210000. running mean: -64.761654\n",
      "ep 21: ep_len:500 episode reward: total was 16.680000. running mean: -63.947238\n",
      "ep 21: ep_len:1100 episode reward: total was -188.740000. running mean: -65.195165\n",
      "ep 21: ep_len:840 episode reward: total was -27.130000. running mean: -64.814514\n",
      "ep 21: ep_len:525 episode reward: total was -29.300000. running mean: -64.459368\n",
      "ep 21: ep_len:655 episode reward: total was -44.190000. running mean: -64.256675\n",
      "ep 21: ep_len:775 episode reward: total was -21.820000. running mean: -63.832308\n",
      "ep 21: ep_len:500 episode reward: total was -28.920000. running mean: -63.483185\n",
      "ep 21: ep_len:800 episode reward: total was -17.240000. running mean: -63.020753\n",
      "ep 21: ep_len:505 episode reward: total was -26.000000. running mean: -62.650545\n",
      "ep 21: ep_len:500 episode reward: total was -13.910000. running mean: -62.163140\n",
      "ep 21: ep_len:550 episode reward: total was -43.050000. running mean: -61.972009\n",
      "ep 21: ep_len:930 episode reward: total was -8.570000. running mean: -61.437989\n",
      "ep 21: ep_len:2310 episode reward: total was -293.760000. running mean: -63.761209\n",
      "ep 21: ep_len:500 episode reward: total was -65.950000. running mean: -63.783097\n",
      "ep 21: ep_len:665 episode reward: total was -29.020000. running mean: -63.435466\n",
      "ep 21: ep_len:505 episode reward: total was -6.830000. running mean: -62.869411\n",
      "ep 21: ep_len:860 episode reward: total was -40.220000. running mean: -62.642917\n",
      "ep 21: ep_len:70 episode reward: total was 5.500000. running mean: -61.961488\n",
      "ep 21: ep_len:515 episode reward: total was -10.100000. running mean: -61.442873\n",
      "ep 21: ep_len:500 episode reward: total was -44.100000. running mean: -61.269444\n",
      "ep 21: ep_len:715 episode reward: total was -11.990000. running mean: -60.776650\n",
      "ep 21: ep_len:515 episode reward: total was -32.860000. running mean: -60.497483\n",
      "ep 21: ep_len:595 episode reward: total was -32.190000. running mean: -60.214408\n",
      "ep 21: ep_len:830 episode reward: total was -5.100000. running mean: -59.663264\n",
      "ep 21: ep_len:500 episode reward: total was -31.850000. running mean: -59.385132\n",
      "ep 21: ep_len:1630 episode reward: total was -243.230000. running mean: -61.223580\n",
      "ep 21: ep_len:500 episode reward: total was 13.270000. running mean: -60.478644\n",
      "ep 21: ep_len:575 episode reward: total was -48.390000. running mean: -60.357758\n",
      "ep 21: ep_len:850 episode reward: total was -103.960000. running mean: -60.793780\n",
      "ep 21: ep_len:2187 episode reward: total was -305.300000. running mean: -63.238843\n",
      "ep 21: ep_len:500 episode reward: total was -28.520000. running mean: -62.891654\n",
      "ep 21: ep_len:505 episode reward: total was 7.070000. running mean: -62.192038\n",
      "ep 21: ep_len:500 episode reward: total was 6.750000. running mean: -61.502617\n",
      "ep 21: ep_len:640 episode reward: total was -14.930000. running mean: -61.036891\n",
      "ep 21: ep_len:500 episode reward: total was 4.200000. running mean: -60.384522\n",
      "ep 21: ep_len:211 episode reward: total was 18.000000. running mean: -59.600677\n",
      "ep 21: ep_len:1035 episode reward: total was -30.400000. running mean: -59.308670\n",
      "ep 21: ep_len:500 episode reward: total was 17.170000. running mean: -58.543883\n",
      "ep 21: ep_len:500 episode reward: total was -48.600000. running mean: -58.444445\n",
      "ep 21: ep_len:525 episode reward: total was -13.140000. running mean: -57.991400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 21: ep_len:760 episode reward: total was -12.680000. running mean: -57.538286\n",
      "ep 21: ep_len:500 episode reward: total was -0.840000. running mean: -56.971303\n",
      "ep 21: ep_len:201 episode reward: total was 18.500000. running mean: -56.216590\n",
      "ep 21: ep_len:640 episode reward: total was -11.870000. running mean: -55.773124\n",
      "ep 21: ep_len:940 episode reward: total was -152.230000. running mean: -56.737693\n",
      "ep 21: ep_len:770 episode reward: total was -56.080000. running mean: -56.731116\n",
      "ep 21: ep_len:500 episode reward: total was 22.250000. running mean: -55.941305\n",
      "ep 21: ep_len:500 episode reward: total was -19.800000. running mean: -55.579892\n",
      "ep 21: ep_len:243 episode reward: total was 16.500000. running mean: -54.859093\n",
      "ep 21: ep_len:1130 episode reward: total was -32.960000. running mean: -54.640102\n",
      "ep 21: ep_len:500 episode reward: total was 4.880000. running mean: -54.044901\n",
      "ep 21: ep_len:545 episode reward: total was -7.590000. running mean: -53.580352\n",
      "ep 21: ep_len:950 episode reward: total was -53.700000. running mean: -53.581549\n",
      "ep 21: ep_len:500 episode reward: total was -2.840000. running mean: -53.074133\n",
      "ep 21: ep_len:820 episode reward: total was 12.720000. running mean: -52.416192\n",
      "ep 21: ep_len:560 episode reward: total was -41.320000. running mean: -52.305230\n",
      "ep 21: ep_len:500 episode reward: total was -29.930000. running mean: -52.081478\n",
      "ep 21: ep_len:765 episode reward: total was -21.750000. running mean: -51.778163\n",
      "ep 21: ep_len:825 episode reward: total was -68.090000. running mean: -51.941281\n",
      "ep 21: ep_len:500 episode reward: total was -14.010000. running mean: -51.561968\n",
      "ep 21: ep_len:760 episode reward: total was -29.840000. running mean: -51.344749\n",
      "ep 21: ep_len:129 episode reward: total was 9.500000. running mean: -50.736301\n",
      "ep 21: ep_len:770 episode reward: total was -8.020000. running mean: -50.309138\n",
      "ep 21: ep_len:875 episode reward: total was -71.510000. running mean: -50.521147\n",
      "ep 21: ep_len:815 episode reward: total was -34.780000. running mean: -50.363735\n",
      "ep 21: ep_len:500 episode reward: total was -36.480000. running mean: -50.224898\n",
      "ep 21: ep_len:500 episode reward: total was 3.750000. running mean: -49.685149\n",
      "ep 21: ep_len:505 episode reward: total was 18.180000. running mean: -49.006498\n",
      "ep 21: ep_len:2145 episode reward: total was -252.220000. running mean: -51.038633\n",
      "ep 21: ep_len:735 episode reward: total was 7.320000. running mean: -50.455046\n",
      "ep 21: ep_len:500 episode reward: total was 5.150000. running mean: -49.898996\n",
      "ep 21: ep_len:500 episode reward: total was 9.750000. running mean: -49.302506\n",
      "ep 21: ep_len:2390 episode reward: total was -355.840000. running mean: -52.367881\n",
      "ep 21: ep_len:500 episode reward: total was 19.270000. running mean: -51.651502\n",
      "ep 21: ep_len:910 episode reward: total was -6.500000. running mean: -51.199987\n",
      "ep 21: ep_len:1465 episode reward: total was -120.340000. running mean: -51.891387\n",
      "ep 21: ep_len:510 episode reward: total was -59.630000. running mean: -51.968773\n",
      "ep 21: ep_len:500 episode reward: total was 23.190000. running mean: -51.217185\n",
      "ep 21: ep_len:268 episode reward: total was 22.000000. running mean: -50.485014\n",
      "ep 21: ep_len:615 episode reward: total was -23.060000. running mean: -50.210763\n",
      "ep 21: ep_len:710 episode reward: total was -34.990000. running mean: -50.058556\n",
      "ep 21: ep_len:665 episode reward: total was -8.820000. running mean: -49.646170\n",
      "ep 21: ep_len:555 episode reward: total was -44.480000. running mean: -49.594509\n",
      "ep 21: ep_len:505 episode reward: total was -37.420000. running mean: -49.472763\n",
      "ep 21: ep_len:1010 episode reward: total was 1.870000. running mean: -48.959336\n",
      "ep 21: ep_len:510 episode reward: total was -42.460000. running mean: -48.894342\n",
      "ep 21: ep_len:980 episode reward: total was -73.610000. running mean: -49.141499\n",
      "ep 21: ep_len:500 episode reward: total was 7.120000. running mean: -48.578884\n",
      "ep 21: ep_len:1102 episode reward: total was -105.200000. running mean: -49.145095\n",
      "ep 21: ep_len:500 episode reward: total was 0.040000. running mean: -48.653244\n",
      "ep 21: ep_len:700 episode reward: total was -17.840000. running mean: -48.345112\n",
      "ep 21: ep_len:920 episode reward: total was 2.000000. running mean: -47.841661\n",
      "ep 21: ep_len:310 episode reward: total was 12.760000. running mean: -47.235644\n",
      "ep 21: ep_len:625 episode reward: total was 8.250000. running mean: -46.680788\n",
      "ep 21: ep_len:500 episode reward: total was 17.260000. running mean: -46.041380\n",
      "ep 21: ep_len:665 episode reward: total was -53.370000. running mean: -46.114666\n",
      "ep 21: ep_len:1115 episode reward: total was -31.500000. running mean: -45.968519\n",
      "ep 21: ep_len:735 episode reward: total was -17.950000. running mean: -45.688334\n",
      "ep 21: ep_len:650 episode reward: total was -40.340000. running mean: -45.634851\n",
      "ep 21: ep_len:456 episode reward: total was 19.210000. running mean: -44.986402\n",
      "ep 21: ep_len:975 episode reward: total was -9.240000. running mean: -44.628938\n",
      "ep 21: ep_len:645 episode reward: total was -22.480000. running mean: -44.407449\n",
      "ep 21: ep_len:500 episode reward: total was 3.230000. running mean: -43.931074\n",
      "ep 21: ep_len:775 episode reward: total was -36.880000. running mean: -43.860564\n",
      "ep 21: ep_len:500 episode reward: total was -6.010000. running mean: -43.482058\n",
      "ep 21: ep_len:585 episode reward: total was 1.760000. running mean: -43.029637\n",
      "ep 21: ep_len:915 episode reward: total was 1.330000. running mean: -42.586041\n",
      "ep 21: ep_len:1350 episode reward: total was -152.890000. running mean: -43.689081\n",
      "ep 21: ep_len:855 episode reward: total was -6.980000. running mean: -43.321990\n",
      "ep 21: ep_len:500 episode reward: total was -55.660000. running mean: -43.445370\n",
      "ep 21: ep_len:500 episode reward: total was -5.780000. running mean: -43.068716\n",
      "ep 21: ep_len:505 episode reward: total was -35.400000. running mean: -42.992029\n",
      "ep 21: ep_len:500 episode reward: total was 3.680000. running mean: -42.525309\n",
      "ep 21: ep_len:600 episode reward: total was -38.210000. running mean: -42.482156\n",
      "ep 21: ep_len:825 episode reward: total was -40.190000. running mean: -42.459234\n",
      "ep 21: ep_len:720 episode reward: total was 2.200000. running mean: -42.012642\n",
      "ep 21: ep_len:500 episode reward: total was 10.240000. running mean: -41.490115\n",
      "ep 21: ep_len:565 episode reward: total was -12.540000. running mean: -41.200614\n",
      "ep 21: ep_len:500 episode reward: total was 25.760000. running mean: -40.531008\n",
      "ep 21: ep_len:520 episode reward: total was -24.260000. running mean: -40.368298\n",
      "ep 21: ep_len:500 episode reward: total was -12.700000. running mean: -40.091615\n",
      "ep 21: ep_len:500 episode reward: total was -4.760000. running mean: -39.738299\n",
      "ep 21: ep_len:795 episode reward: total was -12.900000. running mean: -39.469916\n",
      "ep 21: ep_len:161 episode reward: total was 9.000000. running mean: -38.985217\n",
      "ep 21: ep_len:151 episode reward: total was 12.000000. running mean: -38.475365\n",
      "ep 21: ep_len:805 episode reward: total was -33.270000. running mean: -38.423311\n",
      "ep 21: ep_len:1400 episode reward: total was -126.710000. running mean: -39.306178\n",
      "ep 21: ep_len:500 episode reward: total was -0.510000. running mean: -38.918216\n",
      "ep 21: ep_len:1715 episode reward: total was -222.270000. running mean: -40.751734\n",
      "ep 21: ep_len:500 episode reward: total was 13.760000. running mean: -40.206617\n",
      "ep 21: ep_len:720 episode reward: total was -28.720000. running mean: -40.091750\n",
      "ep 21: ep_len:705 episode reward: total was -18.840000. running mean: -39.879233\n",
      "ep 21: ep_len:765 episode reward: total was -27.810000. running mean: -39.758541\n",
      "ep 21: ep_len:955 episode reward: total was 7.320000. running mean: -39.287755\n",
      "ep 21: ep_len:655 episode reward: total was -21.970000. running mean: -39.114578\n",
      "ep 21: ep_len:585 episode reward: total was -11.000000. running mean: -38.833432\n",
      "ep 21: ep_len:500 episode reward: total was -11.170000. running mean: -38.556797\n",
      "ep 21: ep_len:620 episode reward: total was -13.960000. running mean: -38.310830\n",
      "ep 21: ep_len:840 episode reward: total was -38.770000. running mean: -38.315421\n",
      "ep 21: ep_len:515 episode reward: total was -34.340000. running mean: -38.275667\n",
      "ep 21: ep_len:525 episode reward: total was -0.740000. running mean: -37.900310\n",
      "ep 21: ep_len:875 episode reward: total was -22.840000. running mean: -37.749707\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 21: ep_len:500 episode reward: total was 10.550000. running mean: -37.266710\n",
      "ep 21: ep_len:805 episode reward: total was -42.220000. running mean: -37.316243\n",
      "ep 21: ep_len:570 episode reward: total was -17.090000. running mean: -37.113981\n",
      "ep 21: ep_len:505 episode reward: total was -12.780000. running mean: -36.870641\n",
      "ep 21: ep_len:670 episode reward: total was -10.830000. running mean: -36.610234\n",
      "ep 21: ep_len:2460 episode reward: total was -413.810000. running mean: -40.382232\n",
      "ep 21: ep_len:500 episode reward: total was 4.730000. running mean: -39.931110\n",
      "ep 21: ep_len:605 episode reward: total was -1.340000. running mean: -39.545199\n",
      "ep 21: ep_len:500 episode reward: total was 6.260000. running mean: -39.087147\n",
      "ep 21: ep_len:500 episode reward: total was -11.680000. running mean: -38.813075\n",
      "ep 21: ep_len:364 episode reward: total was -70.500000. running mean: -39.129944\n",
      "ep 21: ep_len:810 episode reward: total was -7.790000. running mean: -38.816545\n",
      "ep 21: ep_len:640 episode reward: total was -19.980000. running mean: -38.628180\n",
      "ep 21: ep_len:500 episode reward: total was -31.610000. running mean: -38.557998\n",
      "ep 21: ep_len:441 episode reward: total was 19.820000. running mean: -37.974218\n",
      "ep 21: ep_len:1230 episode reward: total was -129.950000. running mean: -38.893976\n",
      "ep 21: ep_len:479 episode reward: total was 23.200000. running mean: -38.273036\n",
      "ep 21: ep_len:496 episode reward: total was 29.760000. running mean: -37.592705\n",
      "ep 21: ep_len:500 episode reward: total was 15.720000. running mean: -37.059578\n",
      "ep 21: ep_len:500 episode reward: total was 15.260000. running mean: -36.536383\n",
      "ep 21: ep_len:535 episode reward: total was 23.750000. running mean: -35.933519\n",
      "ep 21: ep_len:863 episode reward: total was -93.050000. running mean: -36.504684\n",
      "ep 21: ep_len:500 episode reward: total was 10.250000. running mean: -36.037137\n",
      "ep 21: ep_len:875 episode reward: total was -25.430000. running mean: -35.931065\n",
      "ep 21: ep_len:1025 episode reward: total was -132.350000. running mean: -36.895255\n",
      "ep 21: ep_len:1334 episode reward: total was -204.770000. running mean: -38.574002\n",
      "ep 21: ep_len:500 episode reward: total was -7.550000. running mean: -38.263762\n",
      "ep 21: ep_len:630 episode reward: total was -35.170000. running mean: -38.232825\n",
      "ep 21: ep_len:730 episode reward: total was -15.730000. running mean: -38.007796\n",
      "ep 21: ep_len:745 episode reward: total was -15.730000. running mean: -37.785018\n",
      "ep 21: ep_len:500 episode reward: total was 14.930000. running mean: -37.257868\n",
      "ep 21: ep_len:670 episode reward: total was 7.300000. running mean: -36.812290\n",
      "ep 21: ep_len:700 episode reward: total was -15.820000. running mean: -36.602367\n",
      "ep 21: ep_len:500 episode reward: total was 13.970000. running mean: -36.096643\n",
      "ep 21: ep_len:186 episode reward: total was 14.000000. running mean: -35.595677\n",
      "ep 21: ep_len:500 episode reward: total was 10.300000. running mean: -35.136720\n",
      "ep 21: ep_len:500 episode reward: total was 6.930000. running mean: -34.716053\n",
      "ep 21: ep_len:555 episode reward: total was -20.800000. running mean: -34.576892\n",
      "ep 21: ep_len:349 episode reward: total was -4.460000. running mean: -34.275723\n",
      "ep 21: ep_len:482 episode reward: total was 20.730000. running mean: -33.725666\n",
      "ep 21: ep_len:925 episode reward: total was -58.800000. running mean: -33.976409\n",
      "ep 21: ep_len:880 episode reward: total was -22.510000. running mean: -33.861745\n",
      "ep 21: ep_len:575 episode reward: total was 18.690000. running mean: -33.336228\n",
      "ep 21: ep_len:1065 episode reward: total was -18.220000. running mean: -33.185065\n",
      "ep 21: ep_len:615 episode reward: total was -19.510000. running mean: -33.048315\n",
      "ep 21: ep_len:305 episode reward: total was 26.000000. running mean: -32.457832\n",
      "ep 21: ep_len:760 episode reward: total was 5.210000. running mean: -32.081153\n",
      "ep 21: ep_len:500 episode reward: total was -3.360000. running mean: -31.793942\n",
      "ep 21: ep_len:520 episode reward: total was -8.100000. running mean: -31.557002\n",
      "ep 21: ep_len:500 episode reward: total was -18.270000. running mean: -31.424132\n",
      "ep 21: ep_len:500 episode reward: total was 7.430000. running mean: -31.035591\n",
      "ep 21: ep_len:780 episode reward: total was -25.760000. running mean: -30.982835\n",
      "ep 21: ep_len:500 episode reward: total was 3.260000. running mean: -30.640407\n",
      "ep 21: ep_len:157 episode reward: total was 15.500000. running mean: -30.179003\n",
      "ep 21: ep_len:207 episode reward: total was 15.000000. running mean: -29.727213\n",
      "ep 21: ep_len:585 episode reward: total was -23.120000. running mean: -29.661140\n",
      "ep 21: ep_len:660 episode reward: total was -8.830000. running mean: -29.452829\n",
      "ep 21: ep_len:500 episode reward: total was -12.190000. running mean: -29.280201\n",
      "ep 21: ep_len:515 episode reward: total was -20.230000. running mean: -29.189699\n",
      "ep 21: ep_len:695 episode reward: total was -15.310000. running mean: -29.050902\n",
      "ep 21: ep_len:500 episode reward: total was 39.500000. running mean: -28.365393\n",
      "ep 21: ep_len:500 episode reward: total was 1.780000. running mean: -28.063939\n",
      "ep 21: ep_len:202 episode reward: total was 18.500000. running mean: -27.598299\n",
      "ep 21: ep_len:575 episode reward: total was -6.330000. running mean: -27.385616\n",
      "ep 21: ep_len:720 episode reward: total was -21.440000. running mean: -27.326160\n",
      "ep 21: ep_len:500 episode reward: total was 0.760000. running mean: -27.045299\n",
      "ep 21: ep_len:825 episode reward: total was -18.320000. running mean: -26.958046\n",
      "ep 21: ep_len:500 episode reward: total was -5.160000. running mean: -26.740065\n",
      "ep 21: ep_len:1575 episode reward: total was -114.160000. running mean: -27.614265\n",
      "ep 21: ep_len:849 episode reward: total was -90.300000. running mean: -28.241122\n",
      "ep 21: ep_len:555 episode reward: total was -14.090000. running mean: -28.099611\n",
      "ep 21: ep_len:885 episode reward: total was 11.870000. running mean: -27.699915\n",
      "ep 21: ep_len:180 episode reward: total was 15.000000. running mean: -27.272915\n",
      "ep 21: ep_len:940 episode reward: total was -13.150000. running mean: -27.131686\n",
      "ep 21: ep_len:1065 episode reward: total was -84.780000. running mean: -27.708169\n",
      "ep 21: ep_len:500 episode reward: total was -57.140000. running mean: -28.002488\n",
      "ep 21: ep_len:477 episode reward: total was 7.560000. running mean: -27.646863\n",
      "ep 21: ep_len:780 episode reward: total was -31.790000. running mean: -27.688294\n",
      "ep 21: ep_len:760 episode reward: total was -53.070000. running mean: -27.942111\n",
      "ep 21: ep_len:1635 episode reward: total was -96.150000. running mean: -28.624190\n",
      "ep 21: ep_len:715 episode reward: total was -17.810000. running mean: -28.516048\n",
      "ep 21: ep_len:500 episode reward: total was 39.500000. running mean: -27.835888\n",
      "ep 21: ep_len:570 episode reward: total was 14.970000. running mean: -27.407829\n",
      "ep 21: ep_len:500 episode reward: total was -38.460000. running mean: -27.518351\n",
      "ep 21: ep_len:590 episode reward: total was -22.100000. running mean: -27.464167\n",
      "ep 21: ep_len:755 episode reward: total was -14.700000. running mean: -27.336525\n",
      "ep 21: ep_len:1105 episode reward: total was -52.530000. running mean: -27.588460\n",
      "ep 21: ep_len:500 episode reward: total was 10.800000. running mean: -27.204576\n",
      "ep 21: ep_len:645 episode reward: total was -47.660000. running mean: -27.409130\n",
      "ep 21: ep_len:500 episode reward: total was 24.260000. running mean: -26.892439\n",
      "ep 21: ep_len:590 episode reward: total was -19.070000. running mean: -26.814214\n",
      "ep 21: ep_len:735 episode reward: total was -49.080000. running mean: -27.036872\n",
      "ep 21: ep_len:690 episode reward: total was -12.310000. running mean: -26.889603\n",
      "ep 21: ep_len:500 episode reward: total was 17.770000. running mean: -26.443007\n",
      "ep 21: ep_len:595 episode reward: total was -26.130000. running mean: -26.439877\n",
      "ep 21: ep_len:389 episode reward: total was 19.500000. running mean: -25.980478\n",
      "ep 21: ep_len:600 episode reward: total was -12.550000. running mean: -25.846174\n",
      "ep 21: ep_len:760 episode reward: total was -11.120000. running mean: -25.698912\n",
      "ep 21: ep_len:500 episode reward: total was 0.160000. running mean: -25.440323\n",
      "ep 21: ep_len:500 episode reward: total was 8.800000. running mean: -25.097920\n",
      "ep 21: ep_len:900 episode reward: total was 10.090000. running mean: -24.746040\n",
      "ep 21: ep_len:500 episode reward: total was 36.500000. running mean: -24.133580\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 21: ep_len:571 episode reward: total was -8.200000. running mean: -23.974244\n",
      "ep 21: ep_len:292 episode reward: total was 17.000000. running mean: -23.564502\n",
      "ep 21: ep_len:500 episode reward: total was -6.710000. running mean: -23.395957\n",
      "ep 21: ep_len:770 episode reward: total was -22.780000. running mean: -23.389797\n",
      "ep 21: ep_len:840 episode reward: total was -41.770000. running mean: -23.573599\n",
      "ep 21: ep_len:540 episode reward: total was -26.240000. running mean: -23.600263\n",
      "ep 21: ep_len:850 episode reward: total was 2.800000. running mean: -23.336261\n",
      "ep 21: ep_len:2240 episode reward: total was -229.630000. running mean: -25.399198\n",
      "ep 21: ep_len:775 episode reward: total was -30.820000. running mean: -25.453406\n",
      "ep 21: ep_len:515 episode reward: total was -12.150000. running mean: -25.320372\n",
      "ep 21: ep_len:505 episode reward: total was 25.280000. running mean: -24.814368\n",
      "ep 21: ep_len:500 episode reward: total was 15.750000. running mean: -24.408725\n",
      "ep 21: ep_len:985 episode reward: total was -103.120000. running mean: -25.195837\n",
      "ep 21: ep_len:358 episode reward: total was 8.230000. running mean: -24.861579\n",
      "ep 21: ep_len:950 episode reward: total was -29.950000. running mean: -24.912463\n",
      "ep 21: ep_len:500 episode reward: total was -4.710000. running mean: -24.710438\n",
      "ep 21: ep_len:895 episode reward: total was -26.030000. running mean: -24.723634\n",
      "ep 21: ep_len:253 episode reward: total was 14.500000. running mean: -24.331398\n",
      "ep 21: ep_len:935 episode reward: total was -24.630000. running mean: -24.334384\n",
      "ep 21: ep_len:875 episode reward: total was 1.340000. running mean: -24.077640\n",
      "ep 21: ep_len:950 episode reward: total was 0.740000. running mean: -23.829464\n",
      "ep 21: ep_len:505 episode reward: total was 10.170000. running mean: -23.489469\n",
      "ep 21: ep_len:115 episode reward: total was 4.000000. running mean: -23.214574\n",
      "ep 21: ep_len:500 episode reward: total was 11.310000. running mean: -22.869328\n",
      "ep 21: ep_len:500 episode reward: total was 24.690000. running mean: -22.393735\n",
      "ep 21: ep_len:347 episode reward: total was 31.500000. running mean: -21.854798\n",
      "ep 21: ep_len:1545 episode reward: total was -92.750000. running mean: -22.563750\n",
      "ep 21: ep_len:1030 episode reward: total was -111.110000. running mean: -23.449212\n",
      "ep 21: ep_len:590 episode reward: total was -32.200000. running mean: -23.536720\n",
      "ep 21: ep_len:500 episode reward: total was 34.500000. running mean: -22.956353\n",
      "ep 21: ep_len:500 episode reward: total was -0.720000. running mean: -22.733989\n",
      "ep 21: ep_len:930 episode reward: total was -2.480000. running mean: -22.531450\n",
      "ep 21: ep_len:520 episode reward: total was -24.770000. running mean: -22.553835\n",
      "ep 21: ep_len:675 episode reward: total was -39.100000. running mean: -22.719297\n",
      "ep 21: ep_len:535 episode reward: total was -72.190000. running mean: -23.214004\n",
      "ep 21: ep_len:167 episode reward: total was 16.500000. running mean: -22.816864\n",
      "ep 21: ep_len:500 episode reward: total was 9.750000. running mean: -22.491195\n",
      "ep 21: ep_len:1070 episode reward: total was 2.890000. running mean: -22.237383\n",
      "ep 21: ep_len:500 episode reward: total was -27.350000. running mean: -22.288509\n",
      "ep 21: ep_len:9990 episode reward: total was -1886.600000. running mean: -40.931624\n",
      "ep 21: ep_len:525 episode reward: total was -24.750000. running mean: -40.769808\n",
      "ep 21: ep_len:770 episode reward: total was -24.770000. running mean: -40.609810\n",
      "ep 21: ep_len:530 episode reward: total was -11.600000. running mean: -40.319712\n",
      "ep 21: ep_len:510 episode reward: total was -8.610000. running mean: -40.002615\n",
      "ep 21: ep_len:1000 episode reward: total was -38.480000. running mean: -39.987389\n",
      "ep 21: ep_len:500 episode reward: total was 0.880000. running mean: -39.578715\n",
      "ep 21: ep_len:535 episode reward: total was 2.740000. running mean: -39.155528\n",
      "ep 21: ep_len:500 episode reward: total was 9.750000. running mean: -38.666472\n",
      "ep 21: ep_len:500 episode reward: total was -1.280000. running mean: -38.292608\n",
      "ep 21: ep_len:750 episode reward: total was 24.890000. running mean: -37.660781\n",
      "ep 21: ep_len:1487 episode reward: total was -239.510000. running mean: -39.679274\n",
      "ep 21: ep_len:500 episode reward: total was 9.660000. running mean: -39.185881\n",
      "ep 21: ep_len:725 episode reward: total was -0.130000. running mean: -38.795322\n",
      "ep 21: ep_len:795 episode reward: total was -122.740000. running mean: -39.634769\n",
      "ep 21: ep_len:600 episode reward: total was 12.300000. running mean: -39.115421\n",
      "ep 21: ep_len:560 episode reward: total was -13.070000. running mean: -38.854967\n",
      "ep 21: ep_len:680 episode reward: total was -3.740000. running mean: -38.503817\n",
      "ep 21: ep_len:133 episode reward: total was 13.000000. running mean: -37.988779\n",
      "ep 21: ep_len:745 episode reward: total was -34.130000. running mean: -37.950191\n",
      "ep 21: ep_len:500 episode reward: total was -41.620000. running mean: -37.986889\n",
      "ep 21: ep_len:325 episode reward: total was 9.000000. running mean: -37.517021\n",
      "ep 21: ep_len:500 episode reward: total was 6.750000. running mean: -37.074350\n",
      "ep 21: ep_len:505 episode reward: total was 15.270000. running mean: -36.550907\n",
      "ep 21: ep_len:830 episode reward: total was 9.280000. running mean: -36.092598\n",
      "ep 21: ep_len:505 episode reward: total was 0.360000. running mean: -35.728072\n",
      "ep 21: ep_len:500 episode reward: total was -18.750000. running mean: -35.558291\n",
      "ep 21: ep_len:675 episode reward: total was -32.030000. running mean: -35.523008\n",
      "ep 21: ep_len:625 episode reward: total was -24.380000. running mean: -35.411578\n",
      "ep 21: ep_len:500 episode reward: total was 18.780000. running mean: -34.869662\n",
      "ep 21: ep_len:720 episode reward: total was -23.860000. running mean: -34.759566\n",
      "ep 21: ep_len:1395 episode reward: total was -109.370000. running mean: -35.505670\n",
      "ep 21: ep_len:500 episode reward: total was -5.660000. running mean: -35.207213\n",
      "ep 21: ep_len:705 episode reward: total was -42.560000. running mean: -35.280741\n",
      "ep 21: ep_len:695 episode reward: total was -14.820000. running mean: -35.076134\n",
      "ep 21: ep_len:1070 episode reward: total was -75.680000. running mean: -35.482172\n",
      "ep 21: ep_len:975 episode reward: total was 7.710000. running mean: -35.050251\n",
      "ep 21: ep_len:1400 episode reward: total was -62.870000. running mean: -35.328448\n",
      "ep 21: ep_len:184 episode reward: total was 13.500000. running mean: -34.840164\n",
      "ep 21: ep_len:500 episode reward: total was 20.340000. running mean: -34.288362\n",
      "ep 21: ep_len:500 episode reward: total was 38.000000. running mean: -33.565478\n",
      "ep 21: ep_len:915 episode reward: total was -5.040000. running mean: -33.280224\n",
      "ep 21: ep_len:1105 episode reward: total was -17.380000. running mean: -33.121221\n",
      "ep 21: ep_len:500 episode reward: total was 14.830000. running mean: -32.641709\n",
      "ep 21: ep_len:199 episode reward: total was 16.500000. running mean: -32.150292\n",
      "ep 21: ep_len:266 episode reward: total was 25.000000. running mean: -31.578789\n",
      "ep 21: ep_len:1015 episode reward: total was -0.750000. running mean: -31.270501\n",
      "ep 21: ep_len:500 episode reward: total was -4.570000. running mean: -31.003496\n",
      "ep 21: ep_len:665 episode reward: total was -7.810000. running mean: -30.771561\n",
      "ep 21: ep_len:1649 episode reward: total was -266.410000. running mean: -33.127946\n",
      "ep 21: ep_len:248 episode reward: total was 23.500000. running mean: -32.561666\n",
      "ep 21: ep_len:570 episode reward: total was -1.320000. running mean: -32.249250\n",
      "ep 21: ep_len:895 episode reward: total was -35.630000. running mean: -32.283057\n",
      "ep 21: ep_len:500 episode reward: total was 4.080000. running mean: -31.919427\n",
      "ep 21: ep_len:166 episode reward: total was 9.000000. running mean: -31.510232\n",
      "ep 21: ep_len:1055 episode reward: total was -30.260000. running mean: -31.497730\n",
      "ep 21: ep_len:605 episode reward: total was -48.330000. running mean: -31.666053\n",
      "ep 21: ep_len:215 episode reward: total was 19.000000. running mean: -31.159392\n",
      "ep 21: ep_len:500 episode reward: total was -4.000000. running mean: -30.887798\n",
      "ep 21: ep_len:500 episode reward: total was -11.620000. running mean: -30.695120\n",
      "ep 21: ep_len:1240 episode reward: total was -142.330000. running mean: -31.811469\n",
      "ep 21: ep_len:162 episode reward: total was 13.500000. running mean: -31.358354\n",
      "ep 21: ep_len:540 episode reward: total was -5.030000. running mean: -31.095071\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 21: ep_len:500 episode reward: total was -7.800000. running mean: -30.862120\n",
      "ep 21: ep_len:555 episode reward: total was 11.730000. running mean: -30.436199\n",
      "ep 21: ep_len:500 episode reward: total was -8.830000. running mean: -30.220137\n",
      "ep 21: ep_len:1000 episode reward: total was -116.220000. running mean: -31.080136\n",
      "ep 21: ep_len:1485 episode reward: total was -248.570000. running mean: -33.255034\n",
      "ep 21: ep_len:500 episode reward: total was 15.260000. running mean: -32.769884\n",
      "ep 21: ep_len:1142 episode reward: total was -88.460000. running mean: -33.326785\n",
      "ep 21: ep_len:545 episode reward: total was -41.380000. running mean: -33.407317\n",
      "ep 21: ep_len:1275 episode reward: total was -180.120000. running mean: -34.874444\n",
      "ep 21: ep_len:920 episode reward: total was -28.510000. running mean: -34.810800\n",
      "ep 21: ep_len:645 episode reward: total was -32.510000. running mean: -34.787792\n",
      "ep 21: ep_len:500 episode reward: total was -5.540000. running mean: -34.495314\n",
      "ep 21: ep_len:500 episode reward: total was 15.440000. running mean: -33.995960\n",
      "ep 21: ep_len:752 episode reward: total was -30.840000. running mean: -33.964401\n",
      "ep 21: ep_len:870 episode reward: total was -1.270000. running mean: -33.637457\n",
      "ep 21: ep_len:500 episode reward: total was -4.760000. running mean: -33.348682\n",
      "ep 21: ep_len:500 episode reward: total was -5.870000. running mean: -33.073895\n",
      "ep 21: ep_len:1271 episode reward: total was -193.970000. running mean: -34.682857\n",
      "ep 21: ep_len:1245 episode reward: total was 4.880000. running mean: -34.287228\n",
      "ep 21: ep_len:505 episode reward: total was -25.810000. running mean: -34.202456\n",
      "ep 21: ep_len:500 episode reward: total was 0.750000. running mean: -33.852931\n",
      "ep 21: ep_len:500 episode reward: total was 3.620000. running mean: -33.478202\n",
      "ep 21: ep_len:1130 episode reward: total was -115.200000. running mean: -34.295420\n",
      "ep 21: ep_len:760 episode reward: total was -23.750000. running mean: -34.189966\n",
      "ep 21: ep_len:500 episode reward: total was 0.710000. running mean: -33.840966\n",
      "ep 21: ep_len:615 episode reward: total was -46.290000. running mean: -33.965456\n",
      "ep 21: ep_len:720 episode reward: total was -33.490000. running mean: -33.960702\n",
      "ep 21: ep_len:500 episode reward: total was 16.270000. running mean: -33.458395\n",
      "ep 21: ep_len:1080 episode reward: total was -85.760000. running mean: -33.981411\n",
      "ep 21: ep_len:680 episode reward: total was -10.810000. running mean: -33.749697\n",
      "ep 21: ep_len:505 episode reward: total was 7.720000. running mean: -33.335000\n",
      "ep 21: ep_len:500 episode reward: total was 16.240000. running mean: -32.839250\n",
      "ep 21: ep_len:520 episode reward: total was 22.810000. running mean: -32.282757\n",
      "ep 21: ep_len:500 episode reward: total was 8.800000. running mean: -31.871930\n",
      "ep 21: ep_len:500 episode reward: total was 5.280000. running mean: -31.500410\n",
      "ep 21: ep_len:670 episode reward: total was -9.820000. running mean: -31.283606\n",
      "ep 21: ep_len:730 episode reward: total was 2.120000. running mean: -30.949570\n",
      "ep 21: ep_len:500 episode reward: total was 11.400000. running mean: -30.526074\n",
      "ep 21: ep_len:845 episode reward: total was -26.800000. running mean: -30.488814\n",
      "ep 21: ep_len:505 episode reward: total was 6.020000. running mean: -30.123726\n",
      "ep 21: ep_len:500 episode reward: total was 6.660000. running mean: -29.755888\n",
      "ep 21: ep_len:505 episode reward: total was 15.240000. running mean: -29.305929\n",
      "ep 21: ep_len:505 episode reward: total was -18.230000. running mean: -29.195170\n",
      "ep 21: ep_len:505 episode reward: total was 1.950000. running mean: -28.883718\n",
      "ep 21: ep_len:198 episode reward: total was 16.500000. running mean: -28.429881\n",
      "ep 21: ep_len:338 episode reward: total was -37.450000. running mean: -28.520082\n",
      "ep 21: ep_len:530 episode reward: total was 9.260000. running mean: -28.142282\n",
      "ep 21: ep_len:660 episode reward: total was -16.840000. running mean: -28.029259\n",
      "ep 21: ep_len:590 episode reward: total was -18.240000. running mean: -27.931366\n",
      "ep 21: ep_len:1180 episode reward: total was -224.420000. running mean: -29.896253\n",
      "ep 21: ep_len:1307 episode reward: total was -202.720000. running mean: -31.624490\n",
      "ep 21: ep_len:1135 episode reward: total was -176.550000. running mean: -33.073745\n",
      "ep 21: ep_len:500 episode reward: total was -17.380000. running mean: -32.916808\n",
      "ep 21: ep_len:500 episode reward: total was 22.300000. running mean: -32.364640\n",
      "ep 21: ep_len:500 episode reward: total was 17.430000. running mean: -31.866693\n",
      "ep 21: ep_len:500 episode reward: total was -18.970000. running mean: -31.737726\n",
      "ep 21: ep_len:201 episode reward: total was 17.500000. running mean: -31.245349\n",
      "ep 21: ep_len:535 episode reward: total was -13.120000. running mean: -31.064096\n",
      "ep 21: ep_len:840 episode reward: total was -26.000000. running mean: -31.013455\n",
      "ep 21: ep_len:885 episode reward: total was -38.290000. running mean: -31.086220\n",
      "ep 21: ep_len:835 episode reward: total was -11.280000. running mean: -30.888158\n",
      "ep 21: ep_len:500 episode reward: total was -20.440000. running mean: -30.783676\n",
      "ep 21: ep_len:500 episode reward: total was 12.290000. running mean: -30.352939\n",
      "ep 21: ep_len:745 episode reward: total was -14.690000. running mean: -30.196310\n",
      "ep 21: ep_len:500 episode reward: total was 20.280000. running mean: -29.691547\n",
      "ep 21: ep_len:1025 episode reward: total was -110.600000. running mean: -30.500631\n",
      "ep 21: ep_len:500 episode reward: total was 6.900000. running mean: -30.126625\n",
      "ep 21: ep_len:1040 episode reward: total was -37.080000. running mean: -30.196159\n",
      "ep 21: ep_len:715 episode reward: total was -44.220000. running mean: -30.336397\n",
      "ep 21: ep_len:885 episode reward: total was -12.900000. running mean: -30.162033\n",
      "ep 21: ep_len:500 episode reward: total was 28.760000. running mean: -29.572813\n",
      "ep 21: ep_len:595 episode reward: total was 16.490000. running mean: -29.112185\n",
      "ep 21: ep_len:500 episode reward: total was 16.760000. running mean: -28.653463\n",
      "ep 21: ep_len:755 episode reward: total was -11.670000. running mean: -28.483628\n",
      "ep 21: ep_len:775 episode reward: total was -67.670000. running mean: -28.875492\n",
      "ep 21: ep_len:645 episode reward: total was -51.250000. running mean: -29.099237\n",
      "ep 21: ep_len:505 episode reward: total was -5.980000. running mean: -28.868045\n",
      "ep 21: ep_len:1175 episode reward: total was -120.700000. running mean: -29.786364\n",
      "ep 21: ep_len:695 episode reward: total was -21.890000. running mean: -29.707401\n",
      "ep 21: ep_len:1000 episode reward: total was -31.910000. running mean: -29.729427\n",
      "ep 21: ep_len:790 episode reward: total was -31.280000. running mean: -29.744932\n",
      "ep 21: ep_len:640 episode reward: total was -42.890000. running mean: -29.876383\n",
      "ep 21: ep_len:1100 episode reward: total was -107.990000. running mean: -30.657519\n",
      "ep 21: ep_len:660 episode reward: total was -14.120000. running mean: -30.492144\n",
      "ep 21: ep_len:720 episode reward: total was -47.060000. running mean: -30.657823\n",
      "ep 21: ep_len:500 episode reward: total was -21.330000. running mean: -30.564544\n",
      "ep 21: ep_len:261 episode reward: total was 18.500000. running mean: -30.073899\n",
      "ep 21: ep_len:500 episode reward: total was 27.720000. running mean: -29.495960\n",
      "ep 21: ep_len:500 episode reward: total was -4.800000. running mean: -29.249000\n",
      "ep 21: ep_len:975 episode reward: total was -35.740000. running mean: -29.313910\n",
      "ep 21: ep_len:500 episode reward: total was 0.750000. running mean: -29.013271\n",
      "ep 21: ep_len:535 episode reward: total was -7.480000. running mean: -28.797939\n",
      "ep 21: ep_len:570 episode reward: total was -87.250000. running mean: -29.382459\n",
      "ep 21: ep_len:500 episode reward: total was -11.690000. running mean: -29.205535\n",
      "ep 21: ep_len:545 episode reward: total was -15.120000. running mean: -29.064679\n",
      "ep 21: ep_len:500 episode reward: total was 18.690000. running mean: -28.587132\n",
      "ep 21: ep_len:515 episode reward: total was -20.720000. running mean: -28.508461\n",
      "ep 21: ep_len:500 episode reward: total was 11.800000. running mean: -28.105377\n",
      "ep 21: ep_len:795 episode reward: total was -6.460000. running mean: -27.888923\n",
      "ep 21: ep_len:500 episode reward: total was -9.850000. running mean: -27.708534\n",
      "ep 21: ep_len:745 episode reward: total was -25.830000. running mean: -27.689748\n",
      "ep 21: ep_len:820 episode reward: total was -73.120000. running mean: -28.144051\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 21: ep_len:750 episode reward: total was -17.090000. running mean: -28.033510\n",
      "ep 21: ep_len:500 episode reward: total was 7.090000. running mean: -27.682275\n",
      "ep 21: ep_len:550 episode reward: total was -15.110000. running mean: -27.556552\n",
      "ep 21: ep_len:1570 episode reward: total was -119.090000. running mean: -28.471887\n",
      "ep 21: ep_len:725 episode reward: total was -39.000000. running mean: -28.577168\n",
      "ep 21: ep_len:291 episode reward: total was 27.500000. running mean: -28.016396\n",
      "ep 21: ep_len:1650 episode reward: total was -94.340000. running mean: -28.679632\n",
      "ep 21: ep_len:1005 episode reward: total was -63.690000. running mean: -29.029736\n",
      "ep 21: ep_len:500 episode reward: total was -3.040000. running mean: -28.769839\n",
      "ep 21: ep_len:805 episode reward: total was -19.910000. running mean: -28.681240\n",
      "ep 21: ep_len:720 episode reward: total was -17.800000. running mean: -28.572428\n",
      "ep 21: ep_len:500 episode reward: total was 15.750000. running mean: -28.129204\n",
      "ep 21: ep_len:371 episode reward: total was -0.740000. running mean: -27.855312\n",
      "ep 21: ep_len:605 episode reward: total was -26.110000. running mean: -27.837858\n",
      "ep 21: ep_len:850 episode reward: total was -34.010000. running mean: -27.899580\n",
      "ep 21: ep_len:595 episode reward: total was -13.270000. running mean: -27.753284\n",
      "ep 21: ep_len:560 episode reward: total was 19.400000. running mean: -27.281751\n",
      "ep 21: ep_len:505 episode reward: total was -11.650000. running mean: -27.125434\n",
      "ep 21: ep_len:575 episode reward: total was 8.830000. running mean: -26.765879\n",
      "ep 21: ep_len:500 episode reward: total was -8.200000. running mean: -26.580221\n",
      "ep 21: ep_len:500 episode reward: total was 18.230000. running mean: -26.132118\n",
      "ep 21: ep_len:670 episode reward: total was -37.120000. running mean: -26.241997\n",
      "ep 21: ep_len:705 episode reward: total was -35.490000. running mean: -26.334477\n",
      "ep 21: ep_len:615 episode reward: total was -49.440000. running mean: -26.565532\n",
      "ep 21: ep_len:500 episode reward: total was 0.880000. running mean: -26.291077\n",
      "ep 21: ep_len:690 episode reward: total was -13.300000. running mean: -26.161166\n",
      "ep 21: ep_len:1060 episode reward: total was -5.230000. running mean: -25.951855\n",
      "ep 21: ep_len:500 episode reward: total was 22.210000. running mean: -25.470236\n",
      "ep 21: ep_len:805 episode reward: total was -24.700000. running mean: -25.462534\n",
      "ep 21: ep_len:865 episode reward: total was 5.480000. running mean: -25.153108\n",
      "ep 21: ep_len:520 episode reward: total was -15.170000. running mean: -25.053277\n",
      "ep 21: ep_len:880 episode reward: total was -10.080000. running mean: -24.903545\n",
      "ep 21: ep_len:151 episode reward: total was 13.500000. running mean: -24.519509\n",
      "ep 21: ep_len:500 episode reward: total was -51.680000. running mean: -24.791114\n",
      "ep 21: ep_len:173 episode reward: total was 15.500000. running mean: -24.388203\n",
      "ep 21: ep_len:180 episode reward: total was 9.000000. running mean: -24.054321\n",
      "ep 21: ep_len:500 episode reward: total was 1.660000. running mean: -23.797178\n",
      "ep 21: ep_len:555 episode reward: total was 1.870000. running mean: -23.540506\n",
      "ep 21: ep_len:198 episode reward: total was 18.000000. running mean: -23.125101\n",
      "ep 21: ep_len:530 episode reward: total was 0.690000. running mean: -22.886950\n",
      "ep 21: ep_len:166 episode reward: total was 15.000000. running mean: -22.508080\n",
      "ep 21: ep_len:505 episode reward: total was -6.160000. running mean: -22.344600\n",
      "ep 21: ep_len:740 episode reward: total was -51.580000. running mean: -22.636954\n",
      "ep 21: ep_len:53 episode reward: total was 5.000000. running mean: -22.360584\n",
      "ep 21: ep_len:500 episode reward: total was -2.320000. running mean: -22.160178\n",
      "ep 21: ep_len:760 episode reward: total was -20.230000. running mean: -22.140876\n",
      "ep 21: ep_len:500 episode reward: total was 0.770000. running mean: -21.911768\n",
      "ep 21: ep_len:352 episode reward: total was 29.000000. running mean: -21.402650\n",
      "ep 21: ep_len:565 episode reward: total was -28.700000. running mean: -21.475623\n",
      "ep 21: ep_len:565 episode reward: total was 11.590000. running mean: -21.144967\n",
      "ep 21: ep_len:820 episode reward: total was 12.050000. running mean: -20.813018\n",
      "ep 21: ep_len:850 episode reward: total was -21.580000. running mean: -20.820687\n",
      "ep 21: ep_len:805 episode reward: total was -8.540000. running mean: -20.697880\n",
      "ep 21: ep_len:500 episode reward: total was 12.070000. running mean: -20.370202\n",
      "ep 21: ep_len:500 episode reward: total was 12.730000. running mean: -20.039200\n",
      "ep 21: ep_len:590 episode reward: total was -12.490000. running mean: -19.963708\n",
      "ep 21: ep_len:510 episode reward: total was -9.670000. running mean: -19.860771\n",
      "ep 21: ep_len:345 episode reward: total was 1.110000. running mean: -19.651063\n",
      "ep 21: ep_len:154 episode reward: total was 12.000000. running mean: -19.334552\n",
      "ep 21: ep_len:765 episode reward: total was -41.950000. running mean: -19.560707\n",
      "ep 21: ep_len:1425 episode reward: total was -122.960000. running mean: -20.594700\n",
      "ep 21: ep_len:103 episode reward: total was 8.500000. running mean: -20.303753\n",
      "ep 21: ep_len:610 episode reward: total was 16.700000. running mean: -19.933715\n",
      "ep 21: ep_len:615 episode reward: total was -22.310000. running mean: -19.957478\n",
      "ep 21: ep_len:525 episode reward: total was -72.730000. running mean: -20.485203\n",
      "ep 21: ep_len:500 episode reward: total was 7.080000. running mean: -20.209551\n",
      "ep 21: ep_len:745 episode reward: total was -7.390000. running mean: -20.081356\n",
      "ep 21: ep_len:500 episode reward: total was 24.270000. running mean: -19.637842\n",
      "ep 21: ep_len:500 episode reward: total was 9.220000. running mean: -19.349264\n",
      "ep 21: ep_len:500 episode reward: total was 1.700000. running mean: -19.138771\n",
      "ep 21: ep_len:446 episode reward: total was 28.000000. running mean: -18.667383\n",
      "ep 21: ep_len:500 episode reward: total was -12.210000. running mean: -18.602809\n",
      "ep 21: ep_len:510 episode reward: total was 1.630000. running mean: -18.400481\n",
      "ep 21: ep_len:620 episode reward: total was 4.240000. running mean: -18.174077\n",
      "ep 21: ep_len:500 episode reward: total was 18.240000. running mean: -17.809936\n",
      "ep 21: ep_len:360 episode reward: total was -69.490000. running mean: -18.326736\n",
      "ep 21: ep_len:520 episode reward: total was 8.590000. running mean: -18.057569\n",
      "ep 21: ep_len:755 episode reward: total was -21.270000. running mean: -18.089693\n",
      "ep 21: ep_len:500 episode reward: total was -1.610000. running mean: -17.924896\n",
      "ep 21: ep_len:910 episode reward: total was -85.090000. running mean: -18.596548\n",
      "ep 21: ep_len:825 episode reward: total was -51.960000. running mean: -18.930182\n",
      "ep 21: ep_len:216 episode reward: total was 20.500000. running mean: -18.535880\n",
      "ep 21: ep_len:735 episode reward: total was -16.760000. running mean: -18.518121\n",
      "ep 21: ep_len:359 episode reward: total was 12.710000. running mean: -18.205840\n",
      "ep 21: ep_len:730 episode reward: total was -27.170000. running mean: -18.295482\n",
      "ep 21: ep_len:505 episode reward: total was 0.430000. running mean: -18.108227\n",
      "ep 21: ep_len:500 episode reward: total was 9.780000. running mean: -17.829345\n",
      "ep 21: ep_len:880 episode reward: total was -2.970000. running mean: -17.680751\n",
      "ep 21: ep_len:500 episode reward: total was 13.790000. running mean: -17.366044\n",
      "ep 21: ep_len:500 episode reward: total was 13.000000. running mean: -17.062383\n",
      "ep 21: ep_len:500 episode reward: total was -1.400000. running mean: -16.905759\n",
      "ep 21: ep_len:885 episode reward: total was -0.170000. running mean: -16.738402\n",
      "ep 21: ep_len:107 episode reward: total was 9.500000. running mean: -16.476018\n",
      "ep 21: ep_len:500 episode reward: total was 11.740000. running mean: -16.193858\n",
      "ep 21: ep_len:500 episode reward: total was -17.830000. running mean: -16.210219\n",
      "ep 21: ep_len:935 episode reward: total was -8.610000. running mean: -16.134217\n",
      "ep 21: ep_len:845 episode reward: total was -21.090000. running mean: -16.183775\n",
      "ep 21: ep_len:500 episode reward: total was 39.500000. running mean: -15.626937\n",
      "ep 21: ep_len:565 episode reward: total was -1.700000. running mean: -15.487668\n",
      "ep 21: ep_len:500 episode reward: total was -5.630000. running mean: -15.389091\n",
      "ep 21: ep_len:500 episode reward: total was -2.380000. running mean: -15.259000\n",
      "ep 21: ep_len:500 episode reward: total was -41.100000. running mean: -15.517410\n",
      "ep 21: ep_len:500 episode reward: total was -0.900000. running mean: -15.371236\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 21: ep_len:865 episode reward: total was -22.040000. running mean: -15.437924\n",
      "ep 21: ep_len:635 episode reward: total was 14.340000. running mean: -15.140144\n",
      "ep 21: ep_len:705 episode reward: total was -13.270000. running mean: -15.121443\n",
      "ep 21: ep_len:840 episode reward: total was 1.410000. running mean: -14.956128\n",
      "ep 21: ep_len:510 episode reward: total was -7.110000. running mean: -14.877667\n",
      "ep 21: ep_len:500 episode reward: total was -9.810000. running mean: -14.826991\n",
      "ep 21: ep_len:723 episode reward: total was -22.830000. running mean: -14.907021\n",
      "ep 21: ep_len:500 episode reward: total was 4.910000. running mean: -14.708850\n",
      "ep 21: ep_len:500 episode reward: total was 8.210000. running mean: -14.479662\n",
      "ep 21: ep_len:500 episode reward: total was 8.770000. running mean: -14.247165\n",
      "ep 21: ep_len:559 episode reward: total was -71.750000. running mean: -14.822194\n",
      "ep 21: ep_len:500 episode reward: total was 23.130000. running mean: -14.442672\n",
      "ep 21: ep_len:925 episode reward: total was -9.040000. running mean: -14.388645\n",
      "ep 21: ep_len:1305 episode reward: total was -135.810000. running mean: -15.602859\n",
      "ep 21: ep_len:291 episode reward: total was 23.000000. running mean: -15.216830\n",
      "ep 21: ep_len:1040 episode reward: total was -16.980000. running mean: -15.234462\n",
      "ep 21: ep_len:560 episode reward: total was -20.140000. running mean: -15.283517\n",
      "ep 21: ep_len:920 episode reward: total was -26.160000. running mean: -15.392282\n",
      "ep 21: ep_len:860 episode reward: total was -7.390000. running mean: -15.312259\n",
      "ep 21: ep_len:500 episode reward: total was 5.830000. running mean: -15.100836\n",
      "ep 21: ep_len:940 episode reward: total was -7.540000. running mean: -15.025228\n",
      "ep 21: ep_len:500 episode reward: total was -20.490000. running mean: -15.079876\n",
      "ep 21: ep_len:695 episode reward: total was -27.920000. running mean: -15.208277\n",
      "ep 21: ep_len:925 episode reward: total was 1.400000. running mean: -15.042194\n",
      "ep 21: ep_len:148 episode reward: total was 10.000000. running mean: -14.791772\n",
      "ep 21: ep_len:835 episode reward: total was -23.600000. running mean: -14.879855\n",
      "ep 21: ep_len:500 episode reward: total was -10.800000. running mean: -14.839056\n",
      "ep 21: ep_len:595 episode reward: total was 16.950000. running mean: -14.521166\n",
      "ep 21: ep_len:343 episode reward: total was 25.500000. running mean: -14.120954\n",
      "ep 21: ep_len:500 episode reward: total was -37.120000. running mean: -14.350944\n",
      "ep 21: ep_len:500 episode reward: total was 18.290000. running mean: -14.024535\n",
      "ep 21: ep_len:1015 episode reward: total was 19.740000. running mean: -13.686890\n",
      "ep 21: ep_len:620 episode reward: total was -32.140000. running mean: -13.871421\n",
      "ep 21: ep_len:905 episode reward: total was -38.640000. running mean: -14.119106\n",
      "ep 21: ep_len:11950 episode reward: total was -2277.430000. running mean: -36.752215\n",
      "ep 21: ep_len:500 episode reward: total was 10.790000. running mean: -36.276793\n",
      "ep 21: ep_len:500 episode reward: total was -19.280000. running mean: -36.106825\n",
      "ep 21: ep_len:500 episode reward: total was -8.350000. running mean: -35.829257\n",
      "ep 21: ep_len:545 episode reward: total was -31.280000. running mean: -35.783764\n",
      "ep 21: ep_len:545 episode reward: total was -28.250000. running mean: -35.708427\n",
      "ep 21: ep_len:500 episode reward: total was 1.140000. running mean: -35.339943\n",
      "ep 21: ep_len:1215 episode reward: total was -48.280000. running mean: -35.469343\n",
      "ep 21: ep_len:800 episode reward: total was -29.270000. running mean: -35.407350\n",
      "ep 21: ep_len:830 episode reward: total was -17.970000. running mean: -35.232976\n",
      "ep 21: ep_len:1780 episode reward: total was -238.240000. running mean: -37.263046\n",
      "ep 21: ep_len:500 episode reward: total was 20.190000. running mean: -36.688516\n",
      "ep 21: ep_len:500 episode reward: total was -8.750000. running mean: -36.409131\n",
      "ep 21: ep_len:500 episode reward: total was 15.810000. running mean: -35.886939\n",
      "ep 21: ep_len:500 episode reward: total was 1.520000. running mean: -35.512870\n",
      "ep 21: ep_len:1070 episode reward: total was -17.940000. running mean: -35.337141\n",
      "ep 21: ep_len:310 episode reward: total was 24.000000. running mean: -34.743770\n",
      "ep 21: ep_len:840 episode reward: total was -3.500000. running mean: -34.431332\n",
      "ep 21: ep_len:735 episode reward: total was -19.270000. running mean: -34.279719\n",
      "ep 21: ep_len:655 episode reward: total was -43.180000. running mean: -34.368722\n",
      "ep 21: ep_len:730 episode reward: total was -70.300000. running mean: -34.728035\n",
      "ep 21: ep_len:154 episode reward: total was 13.500000. running mean: -34.245754\n",
      "ep 21: ep_len:1375 episode reward: total was -134.660000. running mean: -35.249897\n",
      "ep 21: ep_len:595 episode reward: total was -21.080000. running mean: -35.108198\n",
      "ep 21: ep_len:500 episode reward: total was 6.810000. running mean: -34.689016\n",
      "ep 21: ep_len:500 episode reward: total was -28.920000. running mean: -34.631326\n",
      "ep 21: ep_len:500 episode reward: total was 12.230000. running mean: -34.162712\n",
      "ep 21: ep_len:500 episode reward: total was 14.000000. running mean: -33.681085\n",
      "ep 21: ep_len:505 episode reward: total was -4.700000. running mean: -33.391274\n",
      "ep 21: ep_len:825 episode reward: total was -3.720000. running mean: -33.094562\n",
      "ep 21: ep_len:500 episode reward: total was 35.000000. running mean: -32.413616\n",
      "ep 21: ep_len:630 episode reward: total was -11.920000. running mean: -32.208680\n",
      "ep 21: ep_len:500 episode reward: total was 0.840000. running mean: -31.878193\n",
      "ep 21: ep_len:500 episode reward: total was 12.810000. running mean: -31.431311\n",
      "ep 21: ep_len:500 episode reward: total was -27.990000. running mean: -31.396898\n",
      "ep 21: ep_len:720 episode reward: total was -20.830000. running mean: -31.291229\n",
      "ep 21: ep_len:256 episode reward: total was 21.000000. running mean: -30.768317\n",
      "ep 21: ep_len:594 episode reward: total was -83.220000. running mean: -31.292834\n",
      "ep 21: ep_len:505 episode reward: total was -14.190000. running mean: -31.121805\n",
      "ep 21: ep_len:1505 episode reward: total was -226.310000. running mean: -33.073687\n",
      "ep 21: ep_len:1110 episode reward: total was -125.060000. running mean: -33.993550\n",
      "ep 21: ep_len:605 episode reward: total was -33.180000. running mean: -33.985415\n",
      "ep 21: ep_len:545 episode reward: total was -6.520000. running mean: -33.710761\n",
      "ep 21: ep_len:740 episode reward: total was -8.420000. running mean: -33.457853\n",
      "ep 21: ep_len:127 episode reward: total was 9.500000. running mean: -33.028274\n",
      "ep 21: ep_len:500 episode reward: total was 13.240000. running mean: -32.565592\n",
      "ep 21: ep_len:500 episode reward: total was -22.880000. running mean: -32.468736\n",
      "ep 21: ep_len:500 episode reward: total was 15.320000. running mean: -31.990848\n",
      "ep 21: ep_len:500 episode reward: total was 10.060000. running mean: -31.570340\n",
      "ep 21: ep_len:620 episode reward: total was -15.980000. running mean: -31.414437\n",
      "ep 21: ep_len:188 episode reward: total was 17.500000. running mean: -30.925292\n",
      "ep 21: ep_len:500 episode reward: total was 6.930000. running mean: -30.546739\n",
      "ep 21: ep_len:21190 episode reward: total was -4028.200000. running mean: -70.523272\n",
      "ep 21: ep_len:288 episode reward: total was 28.500000. running mean: -69.533039\n",
      "ep 21: ep_len:695 episode reward: total was -12.430000. running mean: -68.962009\n",
      "ep 21: ep_len:500 episode reward: total was 2.250000. running mean: -68.249889\n",
      "ep 21: ep_len:500 episode reward: total was 14.250000. running mean: -67.424890\n",
      "ep 21: ep_len:500 episode reward: total was -6.320000. running mean: -66.813841\n",
      "ep 21: ep_len:505 episode reward: total was -0.410000. running mean: -66.149803\n",
      "ep 21: ep_len:720 episode reward: total was -91.040000. running mean: -66.398704\n",
      "ep 21: ep_len:540 episode reward: total was -76.740000. running mean: -66.502117\n",
      "ep 21: ep_len:500 episode reward: total was -24.910000. running mean: -66.086196\n",
      "ep 21: ep_len:575 episode reward: total was -24.150000. running mean: -65.666834\n",
      "ep 21: ep_len:1070 episode reward: total was -90.490000. running mean: -65.915066\n",
      "ep 21: ep_len:525 episode reward: total was -29.270000. running mean: -65.548615\n",
      "ep 21: ep_len:855 episode reward: total was -58.870000. running mean: -65.481829\n",
      "ep 21: ep_len:480 episode reward: total was 10.750000. running mean: -64.719511\n",
      "ep 21: ep_len:1145 episode reward: total was -176.010000. running mean: -65.832416\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 21: ep_len:500 episode reward: total was 23.280000. running mean: -64.941292\n",
      "ep 21: ep_len:500 episode reward: total was -1.330000. running mean: -64.305179\n",
      "ep 21: ep_len:780 episode reward: total was -90.890000. running mean: -64.571027\n",
      "ep 21: ep_len:760 episode reward: total was -28.830000. running mean: -64.213617\n",
      "ep 21: ep_len:500 episode reward: total was 17.770000. running mean: -63.393780\n",
      "ep 21: ep_len:500 episode reward: total was 26.280000. running mean: -62.497043\n",
      "ep 21: ep_len:1180 episode reward: total was -74.800000. running mean: -62.620072\n",
      "ep 21: ep_len:830 episode reward: total was 1.100000. running mean: -61.982871\n",
      "ep 21: ep_len:890 episode reward: total was -10.290000. running mean: -61.465943\n",
      "ep 21: ep_len:235 episode reward: total was 22.000000. running mean: -60.631283\n",
      "ep 21: ep_len:49 episode reward: total was 4.500000. running mean: -59.979971\n",
      "ep 21: ep_len:775 episode reward: total was -4.820000. running mean: -59.428371\n",
      "ep 21: ep_len:500 episode reward: total was 9.260000. running mean: -58.741487\n",
      "ep 21: ep_len:500 episode reward: total was -27.230000. running mean: -58.426372\n",
      "ep 21: ep_len:500 episode reward: total was -10.730000. running mean: -57.949409\n",
      "ep 21: ep_len:1270 episode reward: total was -68.210000. running mean: -58.052014\n",
      "ep 21: ep_len:840 episode reward: total was -20.260000. running mean: -57.674094\n",
      "ep 21: ep_len:630 episode reward: total was -28.080000. running mean: -57.378153\n",
      "ep 21: ep_len:955 episode reward: total was -46.980000. running mean: -57.274172\n",
      "ep 21: ep_len:500 episode reward: total was -0.610000. running mean: -56.707530\n",
      "ep 21: ep_len:500 episode reward: total was 14.780000. running mean: -55.992655\n",
      "ep 21: ep_len:638 episode reward: total was -96.780000. running mean: -56.400528\n",
      "ep 21: ep_len:2356 episode reward: total was -325.260000. running mean: -59.089123\n",
      "ep 21: ep_len:580 episode reward: total was -83.760000. running mean: -59.335832\n",
      "ep 21: ep_len:500 episode reward: total was -1.280000. running mean: -58.755273\n",
      "ep 21: ep_len:780 episode reward: total was -42.930000. running mean: -58.597021\n",
      "ep 21: ep_len:670 episode reward: total was -34.060000. running mean: -58.351650\n",
      "ep 21: ep_len:670 episode reward: total was 10.880000. running mean: -57.659334\n",
      "ep 21: ep_len:500 episode reward: total was -9.730000. running mean: -57.180041\n",
      "ep 21: ep_len:690 episode reward: total was -25.940000. running mean: -56.867640\n",
      "ep 21: ep_len:775 episode reward: total was -85.360000. running mean: -57.152564\n",
      "ep 21: ep_len:790 episode reward: total was 19.540000. running mean: -56.385638\n",
      "ep 21: ep_len:500 episode reward: total was -0.680000. running mean: -55.828582\n",
      "ep 21: ep_len:665 episode reward: total was -11.220000. running mean: -55.382496\n",
      "ep 21: ep_len:950 episode reward: total was -4.770000. running mean: -54.876371\n",
      "ep 21: ep_len:184 episode reward: total was 13.500000. running mean: -54.192607\n",
      "ep 21: ep_len:665 episode reward: total was -50.040000. running mean: -54.151081\n",
      "ep 21: ep_len:705 episode reward: total was -10.760000. running mean: -53.717170\n",
      "ep 21: ep_len:500 episode reward: total was 28.790000. running mean: -52.892099\n",
      "ep 21: ep_len:247 episode reward: total was 20.000000. running mean: -52.163178\n",
      "ep 21: ep_len:1135 episode reward: total was 5.180000. running mean: -51.589746\n",
      "ep 21: ep_len:505 episode reward: total was 5.900000. running mean: -51.014848\n",
      "ep 21: ep_len:1049 episode reward: total was -90.710000. running mean: -51.411800\n",
      "ep 21: ep_len:500 episode reward: total was 17.290000. running mean: -50.724782\n",
      "ep 21: ep_len:505 episode reward: total was -31.390000. running mean: -50.531434\n",
      "ep 21: ep_len:500 episode reward: total was 19.210000. running mean: -49.834020\n",
      "ep 21: ep_len:500 episode reward: total was 13.760000. running mean: -49.198080\n",
      "ep 21: ep_len:500 episode reward: total was 19.790000. running mean: -48.508199\n",
      "ep 21: ep_len:500 episode reward: total was -35.930000. running mean: -48.382417\n",
      "ep 21: ep_len:705 episode reward: total was -5.150000. running mean: -47.950093\n",
      "ep 21: ep_len:690 episode reward: total was 3.300000. running mean: -47.437592\n",
      "ep 21: ep_len:500 episode reward: total was -3.300000. running mean: -46.996216\n",
      "ep 21: ep_len:500 episode reward: total was 4.050000. running mean: -46.485754\n",
      "ep 21: ep_len:2585 episode reward: total was -448.460000. running mean: -50.505496\n",
      "ep 21: ep_len:925 episode reward: total was -15.130000. running mean: -50.151741\n",
      "ep 21: ep_len:5533 episode reward: total was -857.420000. running mean: -58.224424\n",
      "ep 21: ep_len:904 episode reward: total was -75.480000. running mean: -58.396980\n",
      "ep 21: ep_len:515 episode reward: total was -12.670000. running mean: -57.939710\n",
      "ep 21: ep_len:505 episode reward: total was 0.570000. running mean: -57.354613\n",
      "ep 21: ep_len:752 episode reward: total was -76.840000. running mean: -57.549467\n",
      "ep 21: ep_len:500 episode reward: total was -20.900000. running mean: -57.182972\n",
      "ep 21: ep_len:670 episode reward: total was -26.990000. running mean: -56.881042\n",
      "epsilon:0.061655 episode_count: 17351. steps_count: 12374404.000000\n",
      "ep 22: ep_len:1535 episode reward: total was -123.230000. running mean: -57.544532\n",
      "ep 22: ep_len:900 episode reward: total was -35.120000. running mean: -57.320286\n",
      "ep 22: ep_len:500 episode reward: total was -9.970000. running mean: -56.846784\n",
      "ep 22: ep_len:1025 episode reward: total was -36.570000. running mean: -56.644016\n",
      "ep 22: ep_len:640 episode reward: total was 17.680000. running mean: -55.900776\n",
      "ep 22: ep_len:745 episode reward: total was 13.490000. running mean: -55.206868\n",
      "ep 22: ep_len:690 episode reward: total was -24.930000. running mean: -54.904099\n",
      "ep 22: ep_len:500 episode reward: total was 13.790000. running mean: -54.217158\n",
      "ep 22: ep_len:935 episode reward: total was -38.450000. running mean: -54.059487\n",
      "ep 22: ep_len:500 episode reward: total was 19.270000. running mean: -53.326192\n",
      "ep 22: ep_len:520 episode reward: total was -13.150000. running mean: -52.924430\n",
      "ep 22: ep_len:500 episode reward: total was 21.810000. running mean: -52.177085\n",
      "ep 22: ep_len:500 episode reward: total was 6.740000. running mean: -51.587915\n",
      "ep 22: ep_len:935 episode reward: total was -53.730000. running mean: -51.609335\n",
      "ep 22: ep_len:865 episode reward: total was -42.760000. running mean: -51.520842\n",
      "ep 22: ep_len:500 episode reward: total was 19.790000. running mean: -50.807734\n",
      "ep 22: ep_len:500 episode reward: total was 5.520000. running mean: -50.244456\n",
      "ep 22: ep_len:500 episode reward: total was 18.930000. running mean: -49.552712\n",
      "ep 22: ep_len:195 episode reward: total was 18.000000. running mean: -48.877185\n",
      "ep 22: ep_len:555 episode reward: total was -8.030000. running mean: -48.468713\n",
      "ep 22: ep_len:500 episode reward: total was 5.950000. running mean: -47.924526\n",
      "ep 22: ep_len:1866 episode reward: total was -165.460000. running mean: -49.099880\n",
      "ep 22: ep_len:180 episode reward: total was 3.000000. running mean: -48.578882\n",
      "ep 22: ep_len:965 episode reward: total was -46.570000. running mean: -48.558793\n",
      "ep 22: ep_len:2148 episode reward: total was -254.300000. running mean: -50.616205\n",
      "ep 22: ep_len:472 episode reward: total was 25.300000. running mean: -49.857043\n",
      "ep 22: ep_len:505 episode reward: total was -13.890000. running mean: -49.497372\n",
      "ep 22: ep_len:500 episode reward: total was 5.670000. running mean: -48.945699\n",
      "ep 22: ep_len:590 episode reward: total was 14.520000. running mean: -48.311042\n",
      "ep 22: ep_len:500 episode reward: total was 2.000000. running mean: -47.807931\n",
      "ep 22: ep_len:500 episode reward: total was 15.260000. running mean: -47.177252\n",
      "ep 22: ep_len:500 episode reward: total was -19.890000. running mean: -46.904379\n",
      "ep 22: ep_len:213 episode reward: total was -9.000000. running mean: -46.525336\n",
      "ep 22: ep_len:575 episode reward: total was -63.690000. running mean: -46.696982\n",
      "ep 22: ep_len:500 episode reward: total was 30.230000. running mean: -45.927712\n",
      "ep 22: ep_len:745 episode reward: total was -143.480000. running mean: -46.903235\n",
      "ep 22: ep_len:500 episode reward: total was 8.780000. running mean: -46.346403\n",
      "ep 22: ep_len:720 episode reward: total was -10.730000. running mean: -45.990239\n",
      "ep 22: ep_len:620 episode reward: total was -13.070000. running mean: -45.661037\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 22: ep_len:515 episode reward: total was -1.770000. running mean: -45.222126\n",
      "ep 22: ep_len:1258 episode reward: total was -165.200000. running mean: -46.421905\n",
      "ep 22: ep_len:505 episode reward: total was -8.790000. running mean: -46.045586\n",
      "ep 22: ep_len:329 episode reward: total was 20.500000. running mean: -45.380130\n",
      "ep 22: ep_len:680 episode reward: total was 9.860000. running mean: -44.827729\n",
      "ep 22: ep_len:550 episode reward: total was -9.050000. running mean: -44.469951\n",
      "ep 22: ep_len:500 episode reward: total was 7.250000. running mean: -43.952752\n",
      "ep 22: ep_len:815 episode reward: total was 5.200000. running mean: -43.461224\n",
      "ep 22: ep_len:20641 episode reward: total was -476.880000. running mean: -47.795412\n",
      "ep 22: ep_len:870 episode reward: total was -1.690000. running mean: -47.334358\n",
      "ep 22: ep_len:895 episode reward: total was -30.580000. running mean: -47.166814\n",
      "ep 22: ep_len:199 episode reward: total was 13.500000. running mean: -46.560146\n",
      "ep 22: ep_len:645 episode reward: total was 13.620000. running mean: -45.958345\n",
      "ep 22: ep_len:152 episode reward: total was 13.500000. running mean: -45.363761\n",
      "ep 22: ep_len:1395 episode reward: total was -97.220000. running mean: -45.882324\n",
      "ep 22: ep_len:670 episode reward: total was -22.950000. running mean: -45.653001\n",
      "ep 22: ep_len:500 episode reward: total was -28.920000. running mean: -45.485671\n",
      "ep 22: ep_len:890 episode reward: total was 3.090000. running mean: -44.999914\n",
      "ep 22: ep_len:575 episode reward: total was 17.130000. running mean: -44.378615\n",
      "ep 22: ep_len:935 episode reward: total was -29.110000. running mean: -44.225929\n",
      "ep 22: ep_len:510 episode reward: total was -24.110000. running mean: -44.024769\n",
      "ep 22: ep_len:1260 episode reward: total was -123.780000. running mean: -44.822322\n",
      "ep 22: ep_len:825 episode reward: total was 9.570000. running mean: -44.278398\n",
      "ep 22: ep_len:820 episode reward: total was 8.930000. running mean: -43.746314\n",
      "ep 22: ep_len:137 episode reward: total was 10.500000. running mean: -43.203851\n",
      "ep 22: ep_len:515 episode reward: total was 6.170000. running mean: -42.710113\n",
      "ep 22: ep_len:500 episode reward: total was -44.010000. running mean: -42.723112\n",
      "ep 22: ep_len:1080 episode reward: total was -147.370000. running mean: -43.769580\n",
      "ep 22: ep_len:590 episode reward: total was -19.070000. running mean: -43.522585\n",
      "ep 22: ep_len:510 episode reward: total was 3.130000. running mean: -43.056059\n",
      "ep 22: ep_len:750 episode reward: total was -55.110000. running mean: -43.176598\n",
      "ep 22: ep_len:780 episode reward: total was -7.730000. running mean: -42.822132\n",
      "ep 22: ep_len:500 episode reward: total was 6.110000. running mean: -42.332811\n",
      "ep 22: ep_len:785 episode reward: total was -13.750000. running mean: -42.046983\n",
      "ep 22: ep_len:575 episode reward: total was -56.470000. running mean: -42.191213\n",
      "ep 22: ep_len:530 episode reward: total was -34.340000. running mean: -42.112701\n",
      "ep 22: ep_len:500 episode reward: total was -5.490000. running mean: -41.746474\n",
      "ep 22: ep_len:500 episode reward: total was 17.220000. running mean: -41.156809\n",
      "ep 22: ep_len:500 episode reward: total was -16.290000. running mean: -40.908141\n",
      "ep 22: ep_len:815 episode reward: total was 1.190000. running mean: -40.487160\n",
      "ep 22: ep_len:1305 episode reward: total was -193.380000. running mean: -42.016088\n",
      "ep 22: ep_len:500 episode reward: total was -18.460000. running mean: -41.780527\n",
      "ep 22: ep_len:840 episode reward: total was 8.160000. running mean: -41.281122\n",
      "ep 22: ep_len:87 episode reward: total was 7.000000. running mean: -40.798311\n",
      "ep 22: ep_len:520 episode reward: total was -5.070000. running mean: -40.441028\n",
      "ep 22: ep_len:620 episode reward: total was -13.000000. running mean: -40.166617\n",
      "ep 22: ep_len:580 episode reward: total was -22.090000. running mean: -39.985851\n",
      "ep 22: ep_len:560 episode reward: total was 11.920000. running mean: -39.466793\n",
      "ep 22: ep_len:1325 episode reward: total was -146.360000. running mean: -40.535725\n",
      "ep 22: ep_len:500 episode reward: total was 1.320000. running mean: -40.117167\n",
      "ep 22: ep_len:500 episode reward: total was -38.280000. running mean: -40.098796\n",
      "ep 22: ep_len:1735 episode reward: total was -108.690000. running mean: -40.784708\n",
      "ep 22: ep_len:530 episode reward: total was 11.220000. running mean: -40.264661\n",
      "ep 22: ep_len:500 episode reward: total was -7.330000. running mean: -39.935314\n",
      "ep 22: ep_len:500 episode reward: total was 3.230000. running mean: -39.503661\n",
      "ep 22: ep_len:1025 episode reward: total was -32.550000. running mean: -39.434124\n",
      "ep 22: ep_len:910 episode reward: total was -0.620000. running mean: -39.045983\n",
      "ep 22: ep_len:500 episode reward: total was 17.190000. running mean: -38.483623\n",
      "ep 22: ep_len:500 episode reward: total was 10.180000. running mean: -37.996987\n",
      "ep 22: ep_len:660 episode reward: total was -16.910000. running mean: -37.786117\n",
      "ep 22: ep_len:675 episode reward: total was -18.800000. running mean: -37.596256\n",
      "ep 22: ep_len:680 episode reward: total was -49.190000. running mean: -37.712193\n",
      "ep 22: ep_len:500 episode reward: total was 14.740000. running mean: -37.187672\n",
      "ep 22: ep_len:890 episode reward: total was -38.300000. running mean: -37.198795\n",
      "ep 22: ep_len:1155 episode reward: total was -34.600000. running mean: -37.172807\n",
      "ep 22: ep_len:585 episode reward: total was -16.540000. running mean: -36.966479\n",
      "ep 22: ep_len:500 episode reward: total was 15.230000. running mean: -36.444514\n",
      "ep 22: ep_len:500 episode reward: total was 6.900000. running mean: -36.011069\n",
      "ep 22: ep_len:500 episode reward: total was 0.200000. running mean: -35.648958\n",
      "ep 22: ep_len:500 episode reward: total was -6.090000. running mean: -35.353369\n",
      "ep 22: ep_len:1119 episode reward: total was -134.170000. running mean: -36.341535\n",
      "ep 22: ep_len:770 episode reward: total was -23.760000. running mean: -36.215720\n",
      "ep 22: ep_len:865 episode reward: total was -26.080000. running mean: -36.114362\n",
      "ep 22: ep_len:500 episode reward: total was 1.050000. running mean: -35.742719\n",
      "ep 22: ep_len:790 episode reward: total was -2.920000. running mean: -35.414492\n",
      "ep 22: ep_len:895 episode reward: total was -39.150000. running mean: -35.451847\n",
      "ep 22: ep_len:640 episode reward: total was 5.650000. running mean: -35.040828\n",
      "ep 22: ep_len:500 episode reward: total was -16.860000. running mean: -34.859020\n",
      "ep 22: ep_len:1975 episode reward: total was -249.590000. running mean: -37.006330\n",
      "ep 22: ep_len:755 episode reward: total was -10.490000. running mean: -36.741166\n",
      "ep 22: ep_len:655 episode reward: total was -4.800000. running mean: -36.421755\n",
      "ep 22: ep_len:800 episode reward: total was -51.950000. running mean: -36.577037\n",
      "ep 22: ep_len:500 episode reward: total was 5.030000. running mean: -36.160967\n",
      "ep 22: ep_len:760 episode reward: total was -11.660000. running mean: -35.915957\n",
      "ep 22: ep_len:1040 episode reward: total was -11.990000. running mean: -35.676698\n",
      "ep 22: ep_len:900 episode reward: total was -15.420000. running mean: -35.474131\n",
      "ep 22: ep_len:500 episode reward: total was 7.970000. running mean: -35.039689\n",
      "ep 22: ep_len:500 episode reward: total was -10.730000. running mean: -34.796592\n",
      "ep 22: ep_len:500 episode reward: total was 10.300000. running mean: -34.345626\n",
      "ep 22: ep_len:1765 episode reward: total was -146.000000. running mean: -35.462170\n",
      "ep 22: ep_len:500 episode reward: total was -0.880000. running mean: -35.116348\n",
      "ep 22: ep_len:500 episode reward: total was 1.120000. running mean: -34.753985\n",
      "ep 22: ep_len:615 episode reward: total was -5.410000. running mean: -34.460545\n",
      "ep 22: ep_len:500 episode reward: total was 4.270000. running mean: -34.073240\n",
      "ep 22: ep_len:2305 episode reward: total was -293.390000. running mean: -36.666407\n",
      "ep 22: ep_len:500 episode reward: total was 24.230000. running mean: -36.057443\n",
      "ep 22: ep_len:627 episode reward: total was -50.830000. running mean: -36.205169\n",
      "ep 22: ep_len:2057 episode reward: total was -161.760000. running mean: -37.460717\n",
      "ep 22: ep_len:510 episode reward: total was -29.330000. running mean: -37.379410\n",
      "ep 22: ep_len:500 episode reward: total was 19.270000. running mean: -36.812916\n",
      "ep 22: ep_len:76 episode reward: total was 6.000000. running mean: -36.384787\n",
      "ep 22: ep_len:217 episode reward: total was 20.000000. running mean: -35.820939\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 22: ep_len:600 episode reward: total was -19.050000. running mean: -35.653229\n",
      "ep 22: ep_len:227 episode reward: total was 18.000000. running mean: -35.116697\n",
      "ep 22: ep_len:500 episode reward: total was 17.000000. running mean: -34.595530\n",
      "ep 22: ep_len:925 episode reward: total was 12.230000. running mean: -34.127275\n",
      "ep 22: ep_len:500 episode reward: total was 5.220000. running mean: -33.733802\n",
      "ep 22: ep_len:500 episode reward: total was 26.740000. running mean: -33.129064\n",
      "ep 22: ep_len:835 episode reward: total was -7.030000. running mean: -32.868073\n",
      "ep 22: ep_len:530 episode reward: total was -28.280000. running mean: -32.822193\n",
      "ep 22: ep_len:970 episode reward: total was 17.220000. running mean: -32.321771\n",
      "ep 22: ep_len:605 episode reward: total was -10.960000. running mean: -32.108153\n",
      "ep 22: ep_len:500 episode reward: total was 18.260000. running mean: -31.604472\n",
      "ep 22: ep_len:500 episode reward: total was 10.570000. running mean: -31.182727\n",
      "ep 22: ep_len:890 episode reward: total was -9.450000. running mean: -30.965400\n",
      "ep 22: ep_len:500 episode reward: total was 3.770000. running mean: -30.618046\n",
      "ep 22: ep_len:615 episode reward: total was -7.390000. running mean: -30.385765\n",
      "ep 22: ep_len:500 episode reward: total was 16.300000. running mean: -29.918907\n",
      "ep 22: ep_len:500 episode reward: total was 0.650000. running mean: -29.613218\n",
      "ep 22: ep_len:645 episode reward: total was -21.990000. running mean: -29.536986\n",
      "ep 22: ep_len:500 episode reward: total was 10.680000. running mean: -29.134816\n",
      "ep 22: ep_len:695 episode reward: total was -27.950000. running mean: -29.122968\n",
      "ep 22: ep_len:730 episode reward: total was -28.390000. running mean: -29.115639\n",
      "ep 22: ep_len:488 episode reward: total was 20.260000. running mean: -28.621882\n",
      "ep 22: ep_len:945 episode reward: total was -11.270000. running mean: -28.448363\n",
      "ep 22: ep_len:635 episode reward: total was -12.920000. running mean: -28.293080\n",
      "ep 22: ep_len:645 episode reward: total was 17.110000. running mean: -27.839049\n",
      "ep 22: ep_len:540 episode reward: total was -15.130000. running mean: -27.711958\n",
      "ep 22: ep_len:500 episode reward: total was 11.580000. running mean: -27.319039\n",
      "ep 22: ep_len:870 episode reward: total was -39.330000. running mean: -27.439148\n",
      "ep 22: ep_len:700 episode reward: total was -8.750000. running mean: -27.252257\n",
      "ep 22: ep_len:143 episode reward: total was 9.500000. running mean: -26.884734\n",
      "ep 22: ep_len:1135 episode reward: total was -38.290000. running mean: -26.998787\n",
      "ep 22: ep_len:500 episode reward: total was -8.690000. running mean: -26.815699\n",
      "ep 22: ep_len:530 episode reward: total was -56.730000. running mean: -27.114842\n",
      "ep 22: ep_len:740 episode reward: total was -36.950000. running mean: -27.213194\n",
      "ep 22: ep_len:520 episode reward: total was -19.210000. running mean: -27.133162\n",
      "ep 22: ep_len:805 episode reward: total was 11.990000. running mean: -26.741930\n",
      "ep 22: ep_len:500 episode reward: total was -18.260000. running mean: -26.657111\n",
      "ep 22: ep_len:500 episode reward: total was 43.000000. running mean: -25.960540\n",
      "ep 22: ep_len:1167 episode reward: total was -197.680000. running mean: -27.677734\n",
      "ep 22: ep_len:500 episode reward: total was -17.980000. running mean: -27.580757\n",
      "ep 22: ep_len:45 episode reward: total was 1.500000. running mean: -27.289949\n",
      "ep 22: ep_len:555 episode reward: total was -10.050000. running mean: -27.117550\n",
      "ep 22: ep_len:1294 episode reward: total was -174.200000. running mean: -28.588374\n",
      "ep 22: ep_len:500 episode reward: total was 16.790000. running mean: -28.134591\n",
      "ep 22: ep_len:500 episode reward: total was -4.680000. running mean: -27.900045\n",
      "ep 22: ep_len:1693 episode reward: total was -235.760000. running mean: -29.978644\n",
      "ep 22: ep_len:670 episode reward: total was -33.050000. running mean: -30.009358\n",
      "ep 22: ep_len:199 episode reward: total was 19.500000. running mean: -29.514264\n",
      "ep 22: ep_len:775 episode reward: total was -25.770000. running mean: -29.476822\n",
      "ep 22: ep_len:1345 episode reward: total was -23.170000. running mean: -29.413753\n",
      "ep 22: ep_len:500 episode reward: total was 2.090000. running mean: -29.098716\n",
      "ep 22: ep_len:2036 episode reward: total was -213.010000. running mean: -30.937829\n",
      "ep 22: ep_len:500 episode reward: total was -12.500000. running mean: -30.753450\n",
      "ep 22: ep_len:585 episode reward: total was -30.190000. running mean: -30.747816\n",
      "ep 22: ep_len:705 episode reward: total was -27.930000. running mean: -30.719638\n",
      "ep 22: ep_len:790 episode reward: total was -38.870000. running mean: -30.801141\n",
      "ep 22: ep_len:885 episode reward: total was 1.090000. running mean: -30.482230\n",
      "ep 22: ep_len:247 episode reward: total was 22.000000. running mean: -29.957408\n",
      "ep 22: ep_len:655 episode reward: total was -30.050000. running mean: -29.958334\n",
      "ep 22: ep_len:925 episode reward: total was 12.350000. running mean: -29.535250\n",
      "ep 22: ep_len:625 episode reward: total was 5.860000. running mean: -29.181298\n",
      "ep 22: ep_len:575 episode reward: total was -16.560000. running mean: -29.055085\n",
      "ep 22: ep_len:500 episode reward: total was 11.460000. running mean: -28.649934\n",
      "ep 22: ep_len:4180 episode reward: total was -707.780000. running mean: -35.441235\n",
      "ep 22: ep_len:500 episode reward: total was 31.700000. running mean: -34.769822\n",
      "ep 22: ep_len:1015 episode reward: total was -16.910000. running mean: -34.591224\n",
      "ep 22: ep_len:500 episode reward: total was 1.570000. running mean: -34.229612\n",
      "ep 22: ep_len:1135 episode reward: total was -65.650000. running mean: -34.543816\n",
      "ep 22: ep_len:186 episode reward: total was 15.500000. running mean: -34.043378\n",
      "ep 22: ep_len:625 episode reward: total was -17.960000. running mean: -33.882544\n",
      "ep 22: ep_len:500 episode reward: total was -4.160000. running mean: -33.585318\n",
      "ep 22: ep_len:500 episode reward: total was -1.950000. running mean: -33.268965\n",
      "ep 22: ep_len:640 episode reward: total was -25.030000. running mean: -33.186576\n",
      "ep 22: ep_len:500 episode reward: total was -13.710000. running mean: -32.991810\n",
      "ep 22: ep_len:580 episode reward: total was -13.520000. running mean: -32.797092\n",
      "ep 22: ep_len:795 episode reward: total was -80.480000. running mean: -33.273921\n",
      "ep 22: ep_len:200 episode reward: total was -31.490000. running mean: -33.256082\n",
      "ep 22: ep_len:585 episode reward: total was -2.600000. running mean: -32.949521\n",
      "ep 22: ep_len:710 episode reward: total was -21.830000. running mean: -32.838326\n",
      "ep 22: ep_len:715 episode reward: total was -18.300000. running mean: -32.692942\n",
      "ep 22: ep_len:585 episode reward: total was -3.410000. running mean: -32.400113\n",
      "ep 22: ep_len:815 episode reward: total was -64.070000. running mean: -32.716812\n",
      "ep 22: ep_len:500 episode reward: total was 22.270000. running mean: -32.166944\n",
      "ep 22: ep_len:725 episode reward: total was 6.690000. running mean: -31.778374\n",
      "ep 22: ep_len:500 episode reward: total was 4.200000. running mean: -31.418590\n",
      "ep 22: ep_len:565 episode reward: total was -5.680000. running mean: -31.161205\n",
      "ep 22: ep_len:500 episode reward: total was 26.740000. running mean: -30.582192\n",
      "ep 22: ep_len:900 episode reward: total was -1.460000. running mean: -30.290971\n",
      "ep 22: ep_len:500 episode reward: total was 13.250000. running mean: -29.855561\n",
      "ep 22: ep_len:905 episode reward: total was -35.240000. running mean: -29.909405\n",
      "ep 22: ep_len:645 episode reward: total was -17.860000. running mean: -29.788911\n",
      "ep 22: ep_len:1586 episode reward: total was -247.340000. running mean: -31.964422\n",
      "ep 22: ep_len:500 episode reward: total was -2.440000. running mean: -31.669178\n",
      "ep 22: ep_len:790 episode reward: total was -29.320000. running mean: -31.645686\n",
      "ep 22: ep_len:500 episode reward: total was 11.980000. running mean: -31.209429\n",
      "ep 22: ep_len:500 episode reward: total was 21.170000. running mean: -30.685635\n",
      "ep 22: ep_len:500 episode reward: total was 44.000000. running mean: -29.938779\n",
      "ep 22: ep_len:690 episode reward: total was -14.830000. running mean: -29.787691\n",
      "ep 22: ep_len:500 episode reward: total was -4.210000. running mean: -29.531914\n",
      "ep 22: ep_len:535 episode reward: total was -0.250000. running mean: -29.239095\n",
      "ep 22: ep_len:645 episode reward: total was -12.900000. running mean: -29.075704\n",
      "ep 22: ep_len:1195 episode reward: total was -66.380000. running mean: -29.448747\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 22: ep_len:825 episode reward: total was -36.780000. running mean: -29.522059\n",
      "ep 22: ep_len:500 episode reward: total was -6.200000. running mean: -29.288839\n",
      "ep 22: ep_len:600 episode reward: total was -12.370000. running mean: -29.119650\n",
      "ep 22: ep_len:362 episode reward: total was 3.590000. running mean: -28.792554\n",
      "ep 22: ep_len:540 episode reward: total was -13.200000. running mean: -28.636628\n",
      "ep 22: ep_len:500 episode reward: total was 5.280000. running mean: -28.297462\n",
      "ep 22: ep_len:500 episode reward: total was -7.250000. running mean: -28.086987\n",
      "ep 22: ep_len:505 episode reward: total was 5.230000. running mean: -27.753817\n",
      "ep 22: ep_len:1050 episode reward: total was -4.180000. running mean: -27.518079\n",
      "ep 22: ep_len:505 episode reward: total was -4.760000. running mean: -27.290499\n",
      "ep 22: ep_len:190 episode reward: total was 17.010000. running mean: -26.847494\n",
      "ep 22: ep_len:500 episode reward: total was -28.460000. running mean: -26.863619\n",
      "ep 22: ep_len:750 episode reward: total was 4.960000. running mean: -26.545382\n",
      "ep 22: ep_len:187 episode reward: total was 15.500000. running mean: -26.124929\n",
      "ep 22: ep_len:500 episode reward: total was 15.730000. running mean: -25.706379\n",
      "ep 22: ep_len:1145 episode reward: total was -8.700000. running mean: -25.536316\n",
      "ep 22: ep_len:520 episode reward: total was -11.130000. running mean: -25.392252\n",
      "ep 22: ep_len:980 episode reward: total was -6.910000. running mean: -25.207430\n",
      "ep 22: ep_len:500 episode reward: total was 20.800000. running mean: -24.747356\n",
      "ep 22: ep_len:217 episode reward: total was 17.000000. running mean: -24.329882\n",
      "ep 22: ep_len:770 episode reward: total was 5.970000. running mean: -24.026883\n",
      "ep 22: ep_len:595 episode reward: total was -6.940000. running mean: -23.856014\n",
      "ep 22: ep_len:500 episode reward: total was -12.390000. running mean: -23.741354\n",
      "ep 22: ep_len:500 episode reward: total was -7.230000. running mean: -23.576241\n",
      "ep 22: ep_len:500 episode reward: total was 31.790000. running mean: -23.022578\n",
      "ep 22: ep_len:500 episode reward: total was 44.000000. running mean: -22.352352\n",
      "ep 22: ep_len:620 episode reward: total was -25.560000. running mean: -22.384429\n",
      "ep 22: ep_len:178 episode reward: total was 13.000000. running mean: -22.030585\n",
      "ep 22: ep_len:500 episode reward: total was -9.760000. running mean: -21.907879\n",
      "ep 22: ep_len:500 episode reward: total was 17.490000. running mean: -21.513900\n",
      "ep 22: ep_len:500 episode reward: total was -18.270000. running mean: -21.481461\n",
      "ep 22: ep_len:500 episode reward: total was 19.330000. running mean: -21.073346\n",
      "ep 22: ep_len:560 episode reward: total was -26.200000. running mean: -21.124613\n",
      "ep 22: ep_len:1230 episode reward: total was -162.220000. running mean: -22.535567\n",
      "ep 22: ep_len:860 episode reward: total was 1.020000. running mean: -22.300011\n",
      "ep 22: ep_len:500 episode reward: total was -22.400000. running mean: -22.301011\n",
      "ep 22: ep_len:770 episode reward: total was 9.990000. running mean: -21.978101\n",
      "ep 22: ep_len:258 episode reward: total was 10.020000. running mean: -21.658120\n",
      "ep 22: ep_len:205 episode reward: total was 17.500000. running mean: -21.266539\n",
      "ep 22: ep_len:210 episode reward: total was 16.500000. running mean: -20.888873\n",
      "ep 22: ep_len:615 episode reward: total was -22.050000. running mean: -20.900485\n",
      "ep 22: ep_len:1630 episode reward: total was -159.200000. running mean: -22.283480\n",
      "ep 22: ep_len:505 episode reward: total was -21.000000. running mean: -22.270645\n",
      "ep 22: ep_len:436 episode reward: total was 2.880000. running mean: -22.019138\n",
      "ep 22: ep_len:725 episode reward: total was -22.840000. running mean: -22.027347\n",
      "ep 22: ep_len:725 episode reward: total was -59.200000. running mean: -22.399074\n",
      "ep 22: ep_len:1405 episode reward: total was -97.230000. running mean: -23.147383\n",
      "ep 22: ep_len:765 episode reward: total was -56.120000. running mean: -23.477109\n",
      "ep 22: ep_len:500 episode reward: total was -18.420000. running mean: -23.426538\n",
      "ep 22: ep_len:590 episode reward: total was -20.080000. running mean: -23.393073\n",
      "ep 22: ep_len:565 episode reward: total was -16.090000. running mean: -23.320042\n",
      "ep 22: ep_len:865 episode reward: total was -38.500000. running mean: -23.471841\n",
      "ep 22: ep_len:910 episode reward: total was -41.660000. running mean: -23.653723\n",
      "ep 22: ep_len:985 episode reward: total was -35.760000. running mean: -23.774786\n",
      "ep 22: ep_len:380 episode reward: total was 29.000000. running mean: -23.247038\n",
      "ep 22: ep_len:500 episode reward: total was 3.650000. running mean: -22.978068\n",
      "ep 22: ep_len:174 episode reward: total was 17.000000. running mean: -22.578287\n",
      "ep 22: ep_len:500 episode reward: total was 13.450000. running mean: -22.218004\n",
      "ep 22: ep_len:1060 episode reward: total was -19.490000. running mean: -22.190724\n",
      "ep 22: ep_len:500 episode reward: total was 19.220000. running mean: -21.776617\n",
      "ep 22: ep_len:500 episode reward: total was -28.340000. running mean: -21.842251\n",
      "ep 22: ep_len:500 episode reward: total was -2.660000. running mean: -21.650428\n",
      "ep 22: ep_len:198 episode reward: total was 15.000000. running mean: -21.283924\n",
      "ep 22: ep_len:261 episode reward: total was 19.000000. running mean: -20.881085\n",
      "ep 22: ep_len:860 episode reward: total was -29.480000. running mean: -20.967074\n",
      "ep 22: ep_len:715 episode reward: total was -1.110000. running mean: -20.768503\n",
      "ep 22: ep_len:254 episode reward: total was 19.000000. running mean: -20.370818\n",
      "ep 22: ep_len:540 episode reward: total was -14.120000. running mean: -20.308310\n",
      "ep 22: ep_len:505 episode reward: total was -6.720000. running mean: -20.172427\n",
      "ep 22: ep_len:1329 episode reward: total was -138.760000. running mean: -21.358302\n",
      "ep 22: ep_len:492 episode reward: total was 42.500000. running mean: -20.719719\n",
      "ep 22: ep_len:500 episode reward: total was 22.700000. running mean: -20.285522\n",
      "ep 22: ep_len:630 episode reward: total was -46.260000. running mean: -20.545267\n",
      "ep 22: ep_len:1040 episode reward: total was -1.690000. running mean: -20.356714\n",
      "ep 22: ep_len:820 episode reward: total was -26.690000. running mean: -20.420047\n",
      "ep 22: ep_len:550 episode reward: total was -22.670000. running mean: -20.442547\n",
      "ep 22: ep_len:750 episode reward: total was 16.830000. running mean: -20.069821\n",
      "ep 22: ep_len:545 episode reward: total was -17.140000. running mean: -20.040523\n",
      "ep 22: ep_len:825 episode reward: total was -30.720000. running mean: -20.147318\n",
      "ep 22: ep_len:500 episode reward: total was 6.790000. running mean: -19.877945\n",
      "ep 22: ep_len:700 episode reward: total was 1.340000. running mean: -19.665765\n",
      "ep 22: ep_len:500 episode reward: total was -5.770000. running mean: -19.526807\n",
      "ep 22: ep_len:1030 episode reward: total was -19.050000. running mean: -19.522039\n",
      "ep 22: ep_len:1580 episode reward: total was -184.590000. running mean: -21.172719\n",
      "ep 22: ep_len:1000 episode reward: total was -33.400000. running mean: -21.294992\n",
      "ep 22: ep_len:500 episode reward: total was 7.240000. running mean: -21.009642\n",
      "ep 22: ep_len:820 episode reward: total was -10.950000. running mean: -20.909045\n",
      "ep 22: ep_len:212 episode reward: total was 21.000000. running mean: -20.489955\n",
      "ep 22: ep_len:1345 episode reward: total was -135.290000. running mean: -21.637955\n",
      "ep 22: ep_len:855 episode reward: total was -5.220000. running mean: -21.473776\n",
      "ep 22: ep_len:895 episode reward: total was 8.880000. running mean: -21.170238\n",
      "ep 22: ep_len:500 episode reward: total was 19.730000. running mean: -20.761236\n",
      "ep 22: ep_len:153 episode reward: total was 13.500000. running mean: -20.418623\n",
      "ep 22: ep_len:525 episode reward: total was -5.060000. running mean: -20.265037\n",
      "ep 22: ep_len:505 episode reward: total was 25.190000. running mean: -19.810487\n",
      "ep 22: ep_len:324 episode reward: total was -30.720000. running mean: -19.919582\n",
      "ep 22: ep_len:271 episode reward: total was 27.000000. running mean: -19.450386\n",
      "ep 22: ep_len:1065 episode reward: total was -116.090000. running mean: -20.416782\n",
      "ep 22: ep_len:895 episode reward: total was -49.740000. running mean: -20.710014\n",
      "ep 22: ep_len:620 episode reward: total was -86.650000. running mean: -21.369414\n",
      "ep 22: ep_len:500 episode reward: total was -0.260000. running mean: -21.158320\n",
      "ep 22: ep_len:860 episode reward: total was 3.360000. running mean: -20.913137\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 22: ep_len:730 episode reward: total was -6.280000. running mean: -20.766806\n",
      "ep 22: ep_len:665 episode reward: total was -51.210000. running mean: -21.071238\n",
      "ep 22: ep_len:500 episode reward: total was -66.260000. running mean: -21.523125\n",
      "ep 22: ep_len:500 episode reward: total was 0.720000. running mean: -21.300694\n",
      "ep 22: ep_len:530 episode reward: total was -7.040000. running mean: -21.158087\n",
      "ep 22: ep_len:1230 episode reward: total was -164.840000. running mean: -22.594906\n",
      "ep 22: ep_len:232 episode reward: total was 15.500000. running mean: -22.213957\n",
      "ep 22: ep_len:565 episode reward: total was -62.610000. running mean: -22.617917\n",
      "ep 22: ep_len:500 episode reward: total was -3.210000. running mean: -22.423838\n",
      "ep 22: ep_len:700 episode reward: total was -11.780000. running mean: -22.317400\n",
      "ep 22: ep_len:555 episode reward: total was -10.050000. running mean: -22.194726\n",
      "ep 22: ep_len:520 episode reward: total was -11.130000. running mean: -22.084079\n",
      "ep 22: ep_len:500 episode reward: total was 18.350000. running mean: -21.679738\n",
      "ep 22: ep_len:1095 episode reward: total was 0.840000. running mean: -21.454540\n",
      "ep 22: ep_len:630 episode reward: total was 13.160000. running mean: -21.108395\n",
      "ep 22: ep_len:925 episode reward: total was 10.200000. running mean: -20.795311\n",
      "ep 22: ep_len:500 episode reward: total was -4.800000. running mean: -20.635358\n",
      "ep 22: ep_len:500 episode reward: total was 2.250000. running mean: -20.406504\n",
      "ep 22: ep_len:500 episode reward: total was -7.950000. running mean: -20.281939\n",
      "ep 22: ep_len:695 episode reward: total was 22.230000. running mean: -19.856820\n",
      "ep 22: ep_len:500 episode reward: total was 45.500000. running mean: -19.203252\n",
      "ep 22: ep_len:530 episode reward: total was 2.560000. running mean: -18.985619\n",
      "ep 22: ep_len:1565 episode reward: total was -87.850000. running mean: -19.674263\n",
      "ep 22: ep_len:459 episode reward: total was 23.750000. running mean: -19.240020\n",
      "ep 22: ep_len:565 episode reward: total was -14.070000. running mean: -19.188320\n",
      "ep 22: ep_len:755 episode reward: total was 3.210000. running mean: -18.964337\n",
      "ep 22: ep_len:810 episode reward: total was -30.750000. running mean: -19.082194\n",
      "ep 22: ep_len:585 episode reward: total was -106.950000. running mean: -19.960872\n",
      "ep 22: ep_len:207 episode reward: total was 14.500000. running mean: -19.616263\n",
      "ep 22: ep_len:845 episode reward: total was 33.280000. running mean: -19.087300\n",
      "ep 22: ep_len:500 episode reward: total was -2.810000. running mean: -18.924527\n",
      "ep 22: ep_len:343 episode reward: total was 28.000000. running mean: -18.455282\n",
      "ep 22: ep_len:640 episode reward: total was 2.260000. running mean: -18.248129\n",
      "ep 22: ep_len:500 episode reward: total was 8.490000. running mean: -17.980748\n",
      "ep 22: ep_len:500 episode reward: total was -20.340000. running mean: -18.004341\n",
      "ep 22: ep_len:695 episode reward: total was -31.470000. running mean: -18.138997\n",
      "ep 22: ep_len:2580 episode reward: total was -356.470000. running mean: -21.522307\n",
      "ep 22: ep_len:660 episode reward: total was 12.820000. running mean: -21.178884\n",
      "ep 22: ep_len:500 episode reward: total was 18.780000. running mean: -20.779295\n",
      "ep 22: ep_len:1760 episode reward: total was -82.170000. running mean: -21.393202\n",
      "ep 22: ep_len:500 episode reward: total was 19.740000. running mean: -20.981870\n",
      "ep 22: ep_len:910 episode reward: total was -17.590000. running mean: -20.947952\n",
      "ep 22: ep_len:825 episode reward: total was -33.500000. running mean: -21.073472\n",
      "ep 22: ep_len:1215 episode reward: total was -109.540000. running mean: -21.958137\n",
      "ep 22: ep_len:500 episode reward: total was -1.160000. running mean: -21.750156\n",
      "ep 22: ep_len:1540 episode reward: total was -85.110000. running mean: -22.383754\n",
      "ep 22: ep_len:258 episode reward: total was 21.000000. running mean: -21.949917\n",
      "ep 22: ep_len:505 episode reward: total was -10.210000. running mean: -21.832518\n",
      "ep 22: ep_len:900 episode reward: total was -31.580000. running mean: -21.929993\n",
      "ep 22: ep_len:780 episode reward: total was -20.710000. running mean: -21.917793\n",
      "ep 22: ep_len:805 episode reward: total was -25.710000. running mean: -21.955715\n",
      "ep 22: ep_len:500 episode reward: total was -5.630000. running mean: -21.792458\n",
      "ep 22: ep_len:168 episode reward: total was 13.500000. running mean: -21.439533\n",
      "ep 22: ep_len:790 episode reward: total was -26.750000. running mean: -21.492638\n",
      "ep 22: ep_len:1000 episode reward: total was 10.290000. running mean: -21.174811\n",
      "ep 22: ep_len:725 episode reward: total was -7.690000. running mean: -21.039963\n",
      "ep 22: ep_len:500 episode reward: total was -29.100000. running mean: -21.120563\n",
      "ep 22: ep_len:290 episode reward: total was 21.500000. running mean: -20.694358\n",
      "ep 22: ep_len:500 episode reward: total was 0.740000. running mean: -20.480014\n",
      "ep 22: ep_len:1195 episode reward: total was -6.640000. running mean: -20.341614\n",
      "ep 22: ep_len:915 episode reward: total was 8.110000. running mean: -20.057098\n",
      "ep 22: ep_len:231 episode reward: total was 20.000000. running mean: -19.656527\n",
      "ep 22: ep_len:1005 episode reward: total was -47.010000. running mean: -19.930062\n",
      "ep 22: ep_len:1184 episode reward: total was -66.850000. running mean: -20.399261\n",
      "ep 22: ep_len:181 episode reward: total was 13.500000. running mean: -20.060269\n",
      "ep 22: ep_len:970 episode reward: total was 5.700000. running mean: -19.802666\n",
      "ep 22: ep_len:870 episode reward: total was 7.850000. running mean: -19.526139\n",
      "ep 22: ep_len:500 episode reward: total was 3.680000. running mean: -19.294078\n",
      "ep 22: ep_len:535 episode reward: total was -10.700000. running mean: -19.208137\n",
      "ep 22: ep_len:540 episode reward: total was -25.230000. running mean: -19.268356\n",
      "ep 22: ep_len:1040 episode reward: total was 10.220000. running mean: -18.973472\n",
      "ep 22: ep_len:332 episode reward: total was 27.000000. running mean: -18.513737\n",
      "ep 22: ep_len:975 episode reward: total was 6.130000. running mean: -18.267300\n",
      "ep 22: ep_len:500 episode reward: total was 39.500000. running mean: -17.689627\n",
      "ep 22: ep_len:1455 episode reward: total was -187.020000. running mean: -19.382931\n",
      "ep 22: ep_len:505 episode reward: total was 16.260000. running mean: -19.026501\n",
      "ep 22: ep_len:372 episode reward: total was -37.670000. running mean: -19.212936\n",
      "ep 22: ep_len:1165 episode reward: total was -90.970000. running mean: -19.930507\n",
      "ep 22: ep_len:500 episode reward: total was -8.690000. running mean: -19.818102\n",
      "ep 22: ep_len:955 episode reward: total was -27.430000. running mean: -19.894221\n",
      "ep 22: ep_len:800 episode reward: total was -47.900000. running mean: -20.174279\n",
      "ep 22: ep_len:500 episode reward: total was -2.920000. running mean: -20.001736\n",
      "ep 22: ep_len:690 episode reward: total was -12.810000. running mean: -19.929819\n",
      "ep 22: ep_len:696 episode reward: total was -21.250000. running mean: -19.943020\n",
      "ep 22: ep_len:500 episode reward: total was 14.800000. running mean: -19.595590\n",
      "ep 22: ep_len:615 episode reward: total was 10.230000. running mean: -19.297334\n",
      "ep 22: ep_len:149 episode reward: total was 14.000000. running mean: -18.964361\n",
      "ep 22: ep_len:790 episode reward: total was 4.490000. running mean: -18.729817\n",
      "ep 22: ep_len:715 episode reward: total was -71.340000. running mean: -19.255919\n",
      "ep 22: ep_len:815 episode reward: total was -35.790000. running mean: -19.421260\n",
      "ep 22: ep_len:640 episode reward: total was -0.010000. running mean: -19.227147\n",
      "ep 22: ep_len:895 episode reward: total was 14.740000. running mean: -18.887476\n",
      "ep 22: ep_len:535 episode reward: total was -14.100000. running mean: -18.839601\n",
      "ep 22: ep_len:850 episode reward: total was -3.690000. running mean: -18.688105\n",
      "ep 22: ep_len:780 episode reward: total was -20.710000. running mean: -18.708324\n",
      "ep 22: ep_len:650 episode reward: total was -7.310000. running mean: -18.594341\n",
      "ep 22: ep_len:735 episode reward: total was -12.160000. running mean: -18.529997\n",
      "ep 22: ep_len:10 episode reward: total was -0.500000. running mean: -18.349697\n",
      "ep 22: ep_len:755 episode reward: total was -26.960000. running mean: -18.435800\n",
      "ep 22: ep_len:1130 episode reward: total was -126.060000. running mean: -19.512042\n",
      "ep 22: ep_len:685 episode reward: total was -6.760000. running mean: -19.384522\n",
      "ep 22: ep_len:505 episode reward: total was -3.290000. running mean: -19.223577\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 22: ep_len:500 episode reward: total was 16.240000. running mean: -18.868941\n",
      "ep 22: ep_len:870 episode reward: total was 9.560000. running mean: -18.584652\n",
      "ep 22: ep_len:500 episode reward: total was -29.240000. running mean: -18.691205\n",
      "ep 22: ep_len:500 episode reward: total was -0.750000. running mean: -18.511793\n",
      "ep 22: ep_len:695 episode reward: total was -7.750000. running mean: -18.404175\n",
      "ep 22: ep_len:585 episode reward: total was 14.790000. running mean: -18.072233\n",
      "ep 22: ep_len:740 episode reward: total was -17.760000. running mean: -18.069111\n",
      "ep 22: ep_len:875 episode reward: total was -0.020000. running mean: -17.888620\n",
      "ep 22: ep_len:500 episode reward: total was 5.800000. running mean: -17.651734\n",
      "ep 22: ep_len:935 episode reward: total was -42.620000. running mean: -17.901416\n",
      "ep 22: ep_len:540 episode reward: total was -36.340000. running mean: -18.085802\n",
      "ep 22: ep_len:510 episode reward: total was -20.730000. running mean: -18.112244\n",
      "ep 22: ep_len:1010 episode reward: total was -40.120000. running mean: -18.332322\n",
      "ep 22: ep_len:298 episode reward: total was 28.000000. running mean: -17.868999\n",
      "ep 22: ep_len:315 episode reward: total was -49.430000. running mean: -18.184609\n",
      "ep 22: ep_len:630 episode reward: total was -4.170000. running mean: -18.044462\n",
      "ep 22: ep_len:810 episode reward: total was 3.640000. running mean: -17.827618\n",
      "ep 22: ep_len:565 episode reward: total was -14.740000. running mean: -17.796742\n",
      "ep 22: ep_len:940 episode reward: total was -54.730000. running mean: -18.166074\n",
      "ep 22: ep_len:965 episode reward: total was -157.670000. running mean: -19.561114\n",
      "ep 22: ep_len:575 episode reward: total was -0.240000. running mean: -19.367902\n",
      "ep 22: ep_len:409 episode reward: total was 31.500000. running mean: -18.859223\n",
      "ep 22: ep_len:500 episode reward: total was 1.150000. running mean: -18.659131\n",
      "ep 22: ep_len:555 episode reward: total was -48.450000. running mean: -18.957040\n",
      "ep 22: ep_len:500 episode reward: total was 24.350000. running mean: -18.523969\n",
      "ep 22: ep_len:500 episode reward: total was 5.770000. running mean: -18.281030\n",
      "ep 22: ep_len:505 episode reward: total was -73.780000. running mean: -18.836019\n",
      "ep 22: ep_len:890 episode reward: total was 2.500000. running mean: -18.622659\n",
      "ep 22: ep_len:885 episode reward: total was 20.870000. running mean: -18.227733\n",
      "ep 22: ep_len:500 episode reward: total was -43.090000. running mean: -18.476355\n",
      "ep 22: ep_len:176 episode reward: total was 13.000000. running mean: -18.161592\n",
      "ep 22: ep_len:610 episode reward: total was 18.300000. running mean: -17.796976\n",
      "ep 22: ep_len:725 episode reward: total was -8.700000. running mean: -17.706006\n",
      "ep 22: ep_len:660 episode reward: total was -23.790000. running mean: -17.766846\n",
      "ep 22: ep_len:500 episode reward: total was -13.580000. running mean: -17.724978\n",
      "ep 22: ep_len:1525 episode reward: total was -253.290000. running mean: -20.080628\n",
      "ep 22: ep_len:900 episode reward: total was -16.430000. running mean: -20.044122\n",
      "ep 22: ep_len:630 episode reward: total was -33.130000. running mean: -20.174980\n",
      "ep 22: ep_len:1070 episode reward: total was -105.630000. running mean: -21.029531\n",
      "ep 22: ep_len:496 episode reward: total was 23.790000. running mean: -20.581335\n",
      "ep 22: ep_len:500 episode reward: total was -12.970000. running mean: -20.505222\n",
      "ep 22: ep_len:500 episode reward: total was -0.360000. running mean: -20.303770\n",
      "ep 22: ep_len:42965 episode reward: total was -8404.260000. running mean: -104.143332\n",
      "ep 22: ep_len:900 episode reward: total was -74.510000. running mean: -103.846999\n",
      "ep 22: ep_len:765 episode reward: total was 5.540000. running mean: -102.753129\n",
      "ep 22: ep_len:500 episode reward: total was -0.260000. running mean: -101.728197\n",
      "ep 22: ep_len:1945 episode reward: total was -322.390000. running mean: -103.934815\n",
      "ep 22: ep_len:590 episode reward: total was -110.980000. running mean: -104.005267\n",
      "ep 22: ep_len:505 episode reward: total was -4.720000. running mean: -103.012415\n",
      "ep 22: ep_len:940 episode reward: total was -179.970000. running mean: -103.781990\n",
      "ep 22: ep_len:595 episode reward: total was -80.980000. running mean: -103.553970\n",
      "ep 22: ep_len:570 episode reward: total was -38.950000. running mean: -102.907931\n",
      "ep 22: ep_len:530 episode reward: total was -5.980000. running mean: -101.938651\n",
      "ep 22: ep_len:500 episode reward: total was -23.710000. running mean: -101.156365\n",
      "ep 22: ep_len:500 episode reward: total was 1.360000. running mean: -100.131201\n",
      "ep 22: ep_len:246 episode reward: total was 21.500000. running mean: -98.914889\n",
      "ep 22: ep_len:500 episode reward: total was -13.920000. running mean: -98.064940\n",
      "ep 22: ep_len:500 episode reward: total was 8.160000. running mean: -97.002691\n",
      "ep 22: ep_len:950 episode reward: total was -63.800000. running mean: -96.670664\n",
      "ep 22: ep_len:1415 episode reward: total was -171.930000. running mean: -97.423257\n",
      "ep 22: ep_len:500 episode reward: total was -17.220000. running mean: -96.621225\n",
      "ep 22: ep_len:350 episode reward: total was 32.000000. running mean: -95.335013\n",
      "ep 22: ep_len:530 episode reward: total was -52.520000. running mean: -94.906863\n",
      "ep 22: ep_len:575 episode reward: total was -74.620000. running mean: -94.703994\n",
      "ep 22: ep_len:690 episode reward: total was -41.090000. running mean: -94.167854\n",
      "ep 22: ep_len:560 episode reward: total was -43.060000. running mean: -93.656775\n",
      "ep 22: ep_len:585 episode reward: total was -83.930000. running mean: -93.559508\n",
      "ep 22: ep_len:650 episode reward: total was -27.570000. running mean: -92.899613\n",
      "ep 22: ep_len:635 episode reward: total was -48.270000. running mean: -92.453316\n",
      "ep 22: ep_len:850 episode reward: total was -66.470000. running mean: -92.193483\n",
      "ep 22: ep_len:1900 episode reward: total was -164.580000. running mean: -92.917348\n",
      "ep 22: ep_len:580 episode reward: total was -41.310000. running mean: -92.401275\n",
      "ep 22: ep_len:500 episode reward: total was -17.930000. running mean: -91.656562\n",
      "ep 22: ep_len:535 episode reward: total was -26.740000. running mean: -91.007397\n",
      "ep 22: ep_len:500 episode reward: total was -19.940000. running mean: -90.296723\n",
      "ep 22: ep_len:500 episode reward: total was -17.990000. running mean: -89.573655\n",
      "ep 22: ep_len:258 episode reward: total was 19.500000. running mean: -88.482919\n",
      "ep 22: ep_len:1690 episode reward: total was -177.450000. running mean: -89.372590\n",
      "ep 22: ep_len:990 episode reward: total was -92.000000. running mean: -89.398864\n",
      "ep 22: ep_len:925 episode reward: total was -68.560000. running mean: -89.190475\n",
      "ep 22: ep_len:745 episode reward: total was 20.250000. running mean: -88.096070\n",
      "ep 22: ep_len:685 episode reward: total was -13.830000. running mean: -87.353410\n",
      "ep 22: ep_len:540 episode reward: total was -15.620000. running mean: -86.636076\n",
      "ep 22: ep_len:466 episode reward: total was -14.270000. running mean: -85.912415\n",
      "ep 22: ep_len:565 episode reward: total was -22.150000. running mean: -85.274791\n",
      "ep 22: ep_len:635 episode reward: total was -3.870000. running mean: -84.460743\n",
      "ep 22: ep_len:505 episode reward: total was -19.880000. running mean: -83.814935\n",
      "ep 22: ep_len:500 episode reward: total was 2.360000. running mean: -82.953186\n",
      "ep 22: ep_len:630 episode reward: total was 11.240000. running mean: -82.011254\n",
      "ep 22: ep_len:500 episode reward: total was 4.510000. running mean: -81.146042\n",
      "ep 22: ep_len:720 episode reward: total was -66.490000. running mean: -80.999481\n",
      "ep 22: ep_len:705 episode reward: total was -10.760000. running mean: -80.297086\n",
      "ep 22: ep_len:500 episode reward: total was 11.740000. running mean: -79.376715\n",
      "ep 22: ep_len:740 episode reward: total was -26.850000. running mean: -78.851448\n",
      "ep 22: ep_len:680 episode reward: total was -26.460000. running mean: -78.327534\n",
      "ep 22: ep_len:1190 episode reward: total was -21.820000. running mean: -77.762459\n",
      "ep 22: ep_len:500 episode reward: total was 12.380000. running mean: -76.861034\n",
      "ep 22: ep_len:186 episode reward: total was 16.000000. running mean: -75.932424\n",
      "ep 22: ep_len:1025 episode reward: total was -73.060000. running mean: -75.903699\n",
      "ep 22: ep_len:176 episode reward: total was 15.000000. running mean: -74.994662\n",
      "ep 22: ep_len:498 episode reward: total was 27.740000. running mean: -73.967316\n",
      "ep 22: ep_len:1120 episode reward: total was -34.890000. running mean: -73.576543\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 22: ep_len:855 episode reward: total was 6.430000. running mean: -72.776477\n",
      "ep 22: ep_len:525 episode reward: total was -3.130000. running mean: -72.080012\n",
      "ep 22: ep_len:500 episode reward: total was 15.260000. running mean: -71.206612\n",
      "ep 22: ep_len:255 episode reward: total was 19.500000. running mean: -70.299546\n",
      "ep 22: ep_len:1820 episode reward: total was -207.500000. running mean: -71.671551\n",
      "ep 22: ep_len:228 episode reward: total was 18.000000. running mean: -70.774835\n",
      "ep 22: ep_len:500 episode reward: total was -5.530000. running mean: -70.122387\n",
      "ep 22: ep_len:204 episode reward: total was 6.500000. running mean: -69.356163\n",
      "ep 22: ep_len:730 episode reward: total was -45.050000. running mean: -69.113101\n",
      "ep 22: ep_len:500 episode reward: total was -1.710000. running mean: -68.439070\n",
      "ep 22: ep_len:189 episode reward: total was 15.500000. running mean: -67.599680\n",
      "ep 22: ep_len:595 episode reward: total was -59.850000. running mean: -67.522183\n",
      "ep 22: ep_len:500 episode reward: total was -1.180000. running mean: -66.858761\n",
      "ep 22: ep_len:209 episode reward: total was 16.000000. running mean: -66.030173\n",
      "ep 22: ep_len:555 episode reward: total was -20.150000. running mean: -65.571372\n",
      "ep 22: ep_len:755 episode reward: total was -16.720000. running mean: -65.082858\n",
      "ep 22: ep_len:565 episode reward: total was 5.190000. running mean: -64.380129\n",
      "ep 22: ep_len:500 episode reward: total was -5.890000. running mean: -63.795228\n",
      "ep 22: ep_len:160 episode reward: total was 11.500000. running mean: -63.042276\n",
      "ep 22: ep_len:500 episode reward: total was 11.120000. running mean: -62.300653\n",
      "ep 22: ep_len:500 episode reward: total was -1.280000. running mean: -61.690446\n",
      "ep 22: ep_len:900 episode reward: total was -33.600000. running mean: -61.409542\n",
      "ep 22: ep_len:805 episode reward: total was -16.620000. running mean: -60.961647\n",
      "ep 22: ep_len:500 episode reward: total was 8.120000. running mean: -60.270830\n",
      "ep 22: ep_len:500 episode reward: total was 6.080000. running mean: -59.607322\n",
      "ep 22: ep_len:500 episode reward: total was -0.720000. running mean: -59.018449\n",
      "ep 22: ep_len:950 episode reward: total was -60.440000. running mean: -59.032664\n",
      "ep 22: ep_len:338 episode reward: total was -0.860000. running mean: -58.450937\n",
      "ep 22: ep_len:139 episode reward: total was 13.500000. running mean: -57.731428\n",
      "ep 22: ep_len:755 episode reward: total was -49.040000. running mean: -57.644514\n",
      "ep 22: ep_len:605 episode reward: total was 3.780000. running mean: -57.030269\n",
      "ep 22: ep_len:500 episode reward: total was 8.640000. running mean: -56.373566\n",
      "ep 22: ep_len:545 episode reward: total was -9.550000. running mean: -55.905330\n",
      "ep 22: ep_len:625 episode reward: total was -69.220000. running mean: -56.038477\n",
      "ep 22: ep_len:750 episode reward: total was -22.790000. running mean: -55.705992\n",
      "ep 22: ep_len:180 episode reward: total was 15.500000. running mean: -54.993932\n",
      "ep 22: ep_len:735 episode reward: total was -10.010000. running mean: -54.544093\n",
      "ep 22: ep_len:500 episode reward: total was -12.730000. running mean: -54.125952\n",
      "ep 22: ep_len:712 episode reward: total was -72.970000. running mean: -54.314393\n",
      "ep 22: ep_len:870 episode reward: total was 22.250000. running mean: -53.548749\n",
      "ep 22: ep_len:500 episode reward: total was -2.740000. running mean: -53.040661\n",
      "ep 22: ep_len:500 episode reward: total was -7.860000. running mean: -52.588855\n",
      "ep 22: ep_len:855 episode reward: total was 2.390000. running mean: -52.039066\n",
      "ep 22: ep_len:545 episode reward: total was -27.210000. running mean: -51.790775\n",
      "ep 22: ep_len:830 episode reward: total was 3.670000. running mean: -51.236168\n",
      "ep 22: ep_len:500 episode reward: total was 8.030000. running mean: -50.643506\n",
      "ep 22: ep_len:500 episode reward: total was 18.290000. running mean: -49.954171\n",
      "ep 22: ep_len:500 episode reward: total was -2.560000. running mean: -49.480229\n",
      "ep 22: ep_len:920 episode reward: total was -52.230000. running mean: -49.507727\n",
      "ep 22: ep_len:990 episode reward: total was -18.610000. running mean: -49.198750\n",
      "ep 22: ep_len:1030 episode reward: total was 16.180000. running mean: -48.544962\n",
      "ep 22: ep_len:318 episode reward: total was 8.760000. running mean: -47.971912\n",
      "ep 22: ep_len:907 episode reward: total was -83.060000. running mean: -48.322793\n",
      "ep 22: ep_len:640 episode reward: total was -39.170000. running mean: -48.231265\n",
      "ep 22: ep_len:2760 episode reward: total was -202.270000. running mean: -49.771653\n",
      "ep 22: ep_len:245 episode reward: total was 21.500000. running mean: -49.058936\n",
      "ep 22: ep_len:500 episode reward: total was -15.240000. running mean: -48.720747\n",
      "ep 22: ep_len:500 episode reward: total was 14.710000. running mean: -48.086439\n",
      "ep 22: ep_len:500 episode reward: total was 43.000000. running mean: -47.175575\n",
      "ep 22: ep_len:500 episode reward: total was -0.240000. running mean: -46.706219\n",
      "ep 22: ep_len:785 episode reward: total was -7.570000. running mean: -46.314857\n",
      "ep 22: ep_len:765 episode reward: total was 1.900000. running mean: -45.832708\n",
      "ep 22: ep_len:500 episode reward: total was 7.280000. running mean: -45.301581\n",
      "ep 22: ep_len:815 episode reward: total was -15.560000. running mean: -45.004166\n",
      "ep 22: ep_len:600 episode reward: total was -21.070000. running mean: -44.764824\n",
      "ep 22: ep_len:500 episode reward: total was -6.110000. running mean: -44.378276\n",
      "ep 22: ep_len:193 episode reward: total was 19.000000. running mean: -43.744493\n",
      "ep 22: ep_len:244 episode reward: total was 22.500000. running mean: -43.082048\n",
      "ep 22: ep_len:500 episode reward: total was -6.180000. running mean: -42.713028\n",
      "ep 22: ep_len:500 episode reward: total was 0.800000. running mean: -42.277897\n",
      "ep 22: ep_len:500 episode reward: total was 23.890000. running mean: -41.616218\n",
      "ep 22: ep_len:940 episode reward: total was 15.190000. running mean: -41.048156\n",
      "ep 22: ep_len:1770 episode reward: total was -89.610000. running mean: -41.533775\n",
      "ep 22: ep_len:855 episode reward: total was -11.470000. running mean: -41.233137\n",
      "ep 22: ep_len:555 episode reward: total was -16.110000. running mean: -40.981905\n",
      "ep 22: ep_len:680 episode reward: total was -6.800000. running mean: -40.640086\n",
      "ep 22: ep_len:830 episode reward: total was -31.820000. running mean: -40.551886\n",
      "ep 22: ep_len:500 episode reward: total was -44.100000. running mean: -40.587367\n",
      "ep 22: ep_len:219 episode reward: total was 20.000000. running mean: -39.981493\n",
      "ep 22: ep_len:500 episode reward: total was 7.970000. running mean: -39.501978\n",
      "ep 22: ep_len:691 episode reward: total was -8.750000. running mean: -39.194458\n",
      "ep 22: ep_len:575 episode reward: total was -1.930000. running mean: -38.821814\n",
      "ep 22: ep_len:500 episode reward: total was 7.910000. running mean: -38.354496\n",
      "ep 22: ep_len:1085 episode reward: total was -29.240000. running mean: -38.263351\n",
      "ep 22: ep_len:500 episode reward: total was -24.720000. running mean: -38.127917\n",
      "ep 22: ep_len:279 episode reward: total was 23.000000. running mean: -37.516638\n",
      "ep 22: ep_len:264 episode reward: total was 6.600000. running mean: -37.075472\n",
      "ep 22: ep_len:915 episode reward: total was -11.540000. running mean: -36.820117\n",
      "ep 22: ep_len:1255 episode reward: total was -106.620000. running mean: -37.518116\n",
      "ep 22: ep_len:200 episode reward: total was 12.500000. running mean: -37.017934\n",
      "ep 22: ep_len:530 episode reward: total was -27.270000. running mean: -36.920455\n",
      "ep 22: ep_len:500 episode reward: total was 24.290000. running mean: -36.308351\n",
      "ep 22: ep_len:770 episode reward: total was -8.610000. running mean: -36.031367\n",
      "ep 22: ep_len:1100 episode reward: total was 0.330000. running mean: -35.667753\n",
      "ep 22: ep_len:500 episode reward: total was 4.790000. running mean: -35.263176\n",
      "ep 22: ep_len:500 episode reward: total was -16.800000. running mean: -35.078544\n",
      "ep 22: ep_len:615 episode reward: total was -13.970000. running mean: -34.867459\n",
      "ep 22: ep_len:500 episode reward: total was 22.920000. running mean: -34.289584\n",
      "ep 22: ep_len:500 episode reward: total was -23.550000. running mean: -34.182188\n",
      "ep 22: ep_len:815 episode reward: total was -12.560000. running mean: -33.965966\n",
      "ep 22: ep_len:935 episode reward: total was 0.530000. running mean: -33.621007\n",
      "ep 22: ep_len:500 episode reward: total was 8.400000. running mean: -33.200797\n",
      "ep 22: ep_len:740 episode reward: total was -8.150000. running mean: -32.950289\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 22: ep_len:750 episode reward: total was -49.020000. running mean: -33.110986\n",
      "ep 22: ep_len:500 episode reward: total was 27.750000. running mean: -32.502376\n",
      "ep 22: ep_len:500 episode reward: total was 16.300000. running mean: -32.014352\n",
      "ep 22: ep_len:605 episode reward: total was 19.420000. running mean: -31.500009\n",
      "ep 22: ep_len:880 episode reward: total was -43.740000. running mean: -31.622409\n",
      "ep 22: ep_len:11380 episode reward: total was -2162.620000. running mean: -52.932384\n",
      "ep 22: ep_len:500 episode reward: total was 18.750000. running mean: -52.215561\n",
      "ep 22: ep_len:500 episode reward: total was -18.240000. running mean: -51.875805\n",
      "ep 22: ep_len:500 episode reward: total was -37.030000. running mean: -51.727347\n",
      "ep 22: ep_len:500 episode reward: total was 3.780000. running mean: -51.172274\n",
      "ep 22: ep_len:438 episode reward: total was 15.650000. running mean: -50.504051\n",
      "ep 22: ep_len:975 episode reward: total was -129.970000. running mean: -51.298710\n",
      "ep 22: ep_len:1260 episode reward: total was -75.150000. running mean: -51.537223\n",
      "ep 22: ep_len:755 episode reward: total was -18.740000. running mean: -51.209251\n",
      "ep 22: ep_len:935 episode reward: total was -5.960000. running mean: -50.756758\n",
      "ep 22: ep_len:615 episode reward: total was -2.860000. running mean: -50.277791\n",
      "ep 22: ep_len:500 episode reward: total was -7.190000. running mean: -49.846913\n",
      "ep 22: ep_len:505 episode reward: total was -19.420000. running mean: -49.542644\n",
      "ep 22: ep_len:515 episode reward: total was -17.200000. running mean: -49.219217\n",
      "ep 22: ep_len:500 episode reward: total was 28.280000. running mean: -48.444225\n",
      "ep 22: ep_len:715 episode reward: total was -17.290000. running mean: -48.132683\n",
      "ep 22: ep_len:645 episode reward: total was -8.860000. running mean: -47.739956\n",
      "ep 22: ep_len:680 episode reward: total was -14.330000. running mean: -47.405857\n",
      "ep 22: ep_len:625 episode reward: total was 33.730000. running mean: -46.594498\n",
      "ep 22: ep_len:505 episode reward: total was 12.270000. running mean: -46.005853\n",
      "ep 22: ep_len:1585 episode reward: total was -149.470000. running mean: -47.040494\n",
      "ep 22: ep_len:620 episode reward: total was -28.100000. running mean: -46.851090\n",
      "ep 22: ep_len:745 episode reward: total was -8.260000. running mean: -46.465179\n",
      "ep 22: ep_len:500 episode reward: total was -16.340000. running mean: -46.163927\n",
      "ep 22: ep_len:500 episode reward: total was 0.660000. running mean: -45.695688\n",
      "ep 22: ep_len:500 episode reward: total was -39.480000. running mean: -45.633531\n",
      "ep 22: ep_len:500 episode reward: total was -6.300000. running mean: -45.240195\n",
      "ep 22: ep_len:725 episode reward: total was -11.730000. running mean: -44.905093\n",
      "ep 22: ep_len:635 episode reward: total was -12.920000. running mean: -44.585243\n",
      "ep 22: ep_len:545 episode reward: total was -36.330000. running mean: -44.502690\n",
      "ep 22: ep_len:970 episode reward: total was -10.050000. running mean: -44.158163\n",
      "ep 22: ep_len:680 episode reward: total was -57.500000. running mean: -44.291582\n",
      "ep 22: ep_len:1060 episode reward: total was -65.250000. running mean: -44.501166\n",
      "ep 22: ep_len:304 episode reward: total was 30.000000. running mean: -43.756154\n",
      "ep 22: ep_len:500 episode reward: total was 21.290000. running mean: -43.105693\n",
      "ep 22: ep_len:865 episode reward: total was -12.460000. running mean: -42.799236\n",
      "ep 22: ep_len:500 episode reward: total was 8.370000. running mean: -42.287543\n",
      "ep 22: ep_len:755 episode reward: total was -7.110000. running mean: -41.935768\n",
      "ep 22: ep_len:885 episode reward: total was -67.940000. running mean: -42.195810\n",
      "ep 22: ep_len:500 episode reward: total was -18.820000. running mean: -41.962052\n",
      "ep 22: ep_len:745 episode reward: total was -12.700000. running mean: -41.669432\n",
      "ep 22: ep_len:500 episode reward: total was 17.740000. running mean: -41.075337\n",
      "ep 22: ep_len:500 episode reward: total was 32.000000. running mean: -40.344584\n",
      "ep 22: ep_len:500 episode reward: total was 19.300000. running mean: -39.748138\n",
      "ep 22: ep_len:156 episode reward: total was 14.000000. running mean: -39.210657\n",
      "ep 22: ep_len:500 episode reward: total was 6.510000. running mean: -38.753450\n",
      "ep 22: ep_len:690 episode reward: total was -7.240000. running mean: -38.438316\n",
      "ep 22: ep_len:500 episode reward: total was 10.420000. running mean: -37.949732\n",
      "ep 22: ep_len:1290 episode reward: total was -220.680000. running mean: -39.777035\n",
      "ep 22: ep_len:159 episode reward: total was 15.500000. running mean: -39.224265\n",
      "ep 22: ep_len:1005 episode reward: total was 17.310000. running mean: -38.658922\n",
      "ep 22: ep_len:500 episode reward: total was 10.300000. running mean: -38.169333\n",
      "ep 22: ep_len:280 episode reward: total was 16.000000. running mean: -37.627640\n",
      "ep 22: ep_len:610 episode reward: total was -29.130000. running mean: -37.542663\n",
      "ep 22: ep_len:405 episode reward: total was 34.500000. running mean: -36.822236\n",
      "ep 22: ep_len:580 episode reward: total was -25.150000. running mean: -36.705514\n",
      "ep 22: ep_len:500 episode reward: total was 3.710000. running mean: -36.301359\n",
      "ep 22: ep_len:500 episode reward: total was 12.590000. running mean: -35.812445\n",
      "ep 22: ep_len:966 episode reward: total was -73.130000. running mean: -36.185621\n",
      "ep 22: ep_len:500 episode reward: total was 2.640000. running mean: -35.797365\n",
      "ep 22: ep_len:500 episode reward: total was 25.850000. running mean: -35.180891\n",
      "ep 22: ep_len:1010 episode reward: total was -77.820000. running mean: -35.607282\n",
      "ep 22: ep_len:735 episode reward: total was -10.190000. running mean: -35.353109\n",
      "ep 22: ep_len:840 episode reward: total was 1.360000. running mean: -34.985978\n",
      "ep 22: ep_len:500 episode reward: total was 26.220000. running mean: -34.373918\n",
      "ep 22: ep_len:1365 episode reward: total was -119.530000. running mean: -35.225479\n",
      "ep 22: ep_len:500 episode reward: total was 19.790000. running mean: -34.675325\n",
      "ep 22: ep_len:500 episode reward: total was 9.750000. running mean: -34.231071\n",
      "ep 22: ep_len:1034 episode reward: total was -114.610000. running mean: -35.034861\n",
      "ep 22: ep_len:780 episode reward: total was -19.700000. running mean: -34.881512\n",
      "ep 22: ep_len:500 episode reward: total was 14.310000. running mean: -34.389597\n",
      "ep 22: ep_len:510 episode reward: total was -14.150000. running mean: -34.187201\n",
      "ep 22: ep_len:505 episode reward: total was -15.290000. running mean: -33.998229\n",
      "ep 22: ep_len:500 episode reward: total was 15.410000. running mean: -33.504147\n",
      "ep 22: ep_len:500 episode reward: total was 1.170000. running mean: -33.157405\n",
      "ep 22: ep_len:500 episode reward: total was 1.260000. running mean: -32.813231\n",
      "ep 22: ep_len:500 episode reward: total was 15.320000. running mean: -32.331899\n",
      "ep 22: ep_len:505 episode reward: total was -9.140000. running mean: -32.099980\n",
      "ep 22: ep_len:500 episode reward: total was 7.600000. running mean: -31.702980\n",
      "ep 22: ep_len:1403 episode reward: total was -198.820000. running mean: -33.374150\n",
      "ep 22: ep_len:1235 episode reward: total was -134.940000. running mean: -34.389809\n",
      "ep 22: ep_len:965 episode reward: total was 0.350000. running mean: -34.042411\n",
      "ep 22: ep_len:650 episode reward: total was -28.530000. running mean: -33.987286\n",
      "ep 22: ep_len:785 episode reward: total was -23.730000. running mean: -33.884714\n",
      "ep 22: ep_len:735 episode reward: total was 2.530000. running mean: -33.520566\n",
      "ep 22: ep_len:251 episode reward: total was 22.000000. running mean: -32.965361\n",
      "ep 22: ep_len:505 episode reward: total was 10.290000. running mean: -32.532807\n",
      "ep 22: ep_len:620 episode reward: total was -64.410000. running mean: -32.851579\n",
      "ep 22: ep_len:1460 episode reward: total was -157.720000. running mean: -34.100263\n",
      "ep 22: ep_len:570 episode reward: total was 9.530000. running mean: -33.663961\n",
      "ep 22: ep_len:500 episode reward: total was 19.270000. running mean: -33.134621\n",
      "ep 22: ep_len:785 episode reward: total was -14.760000. running mean: -32.950875\n",
      "ep 22: ep_len:855 episode reward: total was 19.310000. running mean: -32.428266\n",
      "ep 22: ep_len:505 episode reward: total was -6.600000. running mean: -32.169983\n",
      "ep 22: ep_len:245 episode reward: total was 21.500000. running mean: -31.633284\n",
      "ep 22: ep_len:500 episode reward: total was -13.800000. running mean: -31.454951\n",
      "ep 22: ep_len:740 episode reward: total was -24.830000. running mean: -31.388701\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 22: ep_len:1039 episode reward: total was -105.510000. running mean: -32.129914\n",
      "ep 22: ep_len:730 episode reward: total was 13.450000. running mean: -31.674115\n",
      "ep 22: ep_len:500 episode reward: total was 14.550000. running mean: -31.211874\n",
      "ep 22: ep_len:560 episode reward: total was -65.610000. running mean: -31.555855\n",
      "ep 22: ep_len:760 episode reward: total was -31.860000. running mean: -31.558897\n",
      "ep 22: ep_len:143 episode reward: total was 12.500000. running mean: -31.118308\n",
      "ep 22: ep_len:159 episode reward: total was 15.500000. running mean: -30.652125\n",
      "ep 22: ep_len:500 episode reward: total was 12.290000. running mean: -30.222703\n",
      "ep 22: ep_len:740 episode reward: total was -9.650000. running mean: -30.016976\n",
      "ep 22: ep_len:580 episode reward: total was 11.710000. running mean: -29.599707\n",
      "ep 22: ep_len:730 episode reward: total was -10.680000. running mean: -29.410510\n",
      "ep 22: ep_len:780 episode reward: total was -28.790000. running mean: -29.404304\n",
      "ep 22: ep_len:500 episode reward: total was 9.650000. running mean: -29.013761\n",
      "ep 22: ep_len:905 episode reward: total was 9.500000. running mean: -28.628624\n",
      "ep 22: ep_len:500 episode reward: total was 23.310000. running mean: -28.109238\n",
      "ep 22: ep_len:500 episode reward: total was 17.260000. running mean: -27.655545\n",
      "ep 22: ep_len:132 episode reward: total was 8.500000. running mean: -27.293990\n",
      "ep 22: ep_len:520 episode reward: total was -2.040000. running mean: -27.041450\n",
      "ep 22: ep_len:525 episode reward: total was 22.350000. running mean: -26.547535\n",
      "ep 22: ep_len:515 episode reward: total was -67.180000. running mean: -26.953860\n",
      "ep 22: ep_len:264 episode reward: total was 25.000000. running mean: -26.434321\n",
      "ep 22: ep_len:540 episode reward: total was -20.180000. running mean: -26.371778\n",
      "ep 22: ep_len:179 episode reward: total was 14.500000. running mean: -25.963060\n",
      "ep 22: ep_len:500 episode reward: total was 19.770000. running mean: -25.505730\n",
      "ep 22: ep_len:500 episode reward: total was -8.770000. running mean: -25.338372\n",
      "ep 22: ep_len:755 episode reward: total was -29.330000. running mean: -25.378289\n",
      "ep 22: ep_len:2847 episode reward: total was -516.510000. running mean: -30.289606\n",
      "ep 22: ep_len:865 episode reward: total was -28.290000. running mean: -30.269610\n",
      "ep 22: ep_len:500 episode reward: total was 40.000000. running mean: -29.566914\n",
      "ep 22: ep_len:1151 episode reward: total was -78.430000. running mean: -30.055545\n",
      "ep 22: ep_len:620 episode reward: total was -5.200000. running mean: -29.806989\n",
      "ep 22: ep_len:1690 episode reward: total was -154.840000. running mean: -31.057319\n",
      "ep 22: ep_len:1025 episode reward: total was -15.730000. running mean: -30.904046\n",
      "ep 22: ep_len:500 episode reward: total was 44.000000. running mean: -30.155006\n",
      "ep 22: ep_len:905 episode reward: total was 19.650000. running mean: -29.656956\n",
      "ep 22: ep_len:188 episode reward: total was 15.500000. running mean: -29.205386\n",
      "epsilon:0.046250 episode_count: 18141. steps_count: 12978647.000000\n",
      "ep 23: ep_len:1845 episode reward: total was -182.200000. running mean: -30.735332\n",
      "ep 23: ep_len:835 episode reward: total was -29.690000. running mean: -30.724879\n",
      "ep 23: ep_len:500 episode reward: total was 4.600000. running mean: -30.371630\n",
      "ep 23: ep_len:780 episode reward: total was -0.130000. running mean: -30.069214\n",
      "ep 23: ep_len:500 episode reward: total was 6.280000. running mean: -29.705722\n",
      "ep 23: ep_len:505 episode reward: total was -7.820000. running mean: -29.486864\n",
      "ep 23: ep_len:705 episode reward: total was -9.750000. running mean: -29.289496\n",
      "ep 23: ep_len:500 episode reward: total was 2.320000. running mean: -28.973401\n",
      "ep 23: ep_len:820 episode reward: total was -34.770000. running mean: -29.031367\n",
      "ep 23: ep_len:700 episode reward: total was 27.180000. running mean: -28.469253\n",
      "ep 23: ep_len:655 episode reward: total was 22.670000. running mean: -27.957861\n",
      "ep 23: ep_len:1025 episode reward: total was -7.010000. running mean: -27.748382\n",
      "ep 23: ep_len:500 episode reward: total was 4.230000. running mean: -27.428598\n",
      "ep 23: ep_len:960 episode reward: total was -37.520000. running mean: -27.529512\n",
      "ep 23: ep_len:895 episode reward: total was -24.520000. running mean: -27.499417\n",
      "ep 23: ep_len:500 episode reward: total was -0.930000. running mean: -27.233723\n",
      "ep 23: ep_len:760 episode reward: total was -16.220000. running mean: -27.123586\n",
      "ep 23: ep_len:500 episode reward: total was 15.900000. running mean: -26.693350\n",
      "ep 23: ep_len:585 episode reward: total was -4.540000. running mean: -26.471816\n",
      "ep 23: ep_len:605 episode reward: total was 8.800000. running mean: -26.119098\n",
      "ep 23: ep_len:1815 episode reward: total was -9.500000. running mean: -25.952907\n",
      "ep 23: ep_len:225 episode reward: total was 18.000000. running mean: -25.513378\n",
      "ep 23: ep_len:935 episode reward: total was -39.590000. running mean: -25.654144\n",
      "ep 23: ep_len:1840 episode reward: total was -225.640000. running mean: -27.654003\n",
      "ep 23: ep_len:500 episode reward: total was 11.150000. running mean: -27.265963\n",
      "ep 23: ep_len:560 episode reward: total was -16.100000. running mean: -27.154303\n",
      "ep 23: ep_len:725 episode reward: total was 25.660000. running mean: -26.626160\n",
      "ep 23: ep_len:500 episode reward: total was 12.530000. running mean: -26.234599\n",
      "ep 23: ep_len:720 episode reward: total was -5.680000. running mean: -26.029053\n",
      "ep 23: ep_len:585 episode reward: total was -4.570000. running mean: -25.814462\n",
      "ep 23: ep_len:535 episode reward: total was 23.810000. running mean: -25.318217\n",
      "ep 23: ep_len:665 episode reward: total was 2.390000. running mean: -25.041135\n",
      "ep 23: ep_len:920 episode reward: total was -30.460000. running mean: -25.095324\n",
      "ep 23: ep_len:500 episode reward: total was -7.360000. running mean: -24.917971\n",
      "ep 23: ep_len:500 episode reward: total was 16.180000. running mean: -24.506991\n",
      "ep 23: ep_len:500 episode reward: total was -8.000000. running mean: -24.341921\n",
      "ep 23: ep_len:570 episode reward: total was -10.020000. running mean: -24.198702\n",
      "ep 23: ep_len:500 episode reward: total was -11.780000. running mean: -24.074515\n",
      "ep 23: ep_len:500 episode reward: total was 14.530000. running mean: -23.688470\n",
      "ep 23: ep_len:935 episode reward: total was 6.100000. running mean: -23.390585\n",
      "ep 23: ep_len:600 episode reward: total was -17.520000. running mean: -23.331879\n",
      "ep 23: ep_len:975 episode reward: total was 17.550000. running mean: -22.923060\n",
      "ep 23: ep_len:530 episode reward: total was 14.830000. running mean: -22.545530\n",
      "ep 23: ep_len:500 episode reward: total was -7.650000. running mean: -22.396574\n",
      "ep 23: ep_len:204 episode reward: total was 20.000000. running mean: -21.972609\n",
      "ep 23: ep_len:505 episode reward: total was -22.990000. running mean: -21.982783\n",
      "ep 23: ep_len:1020 episode reward: total was 5.430000. running mean: -21.708655\n",
      "ep 23: ep_len:384 episode reward: total was -58.000000. running mean: -22.071568\n",
      "ep 23: ep_len:213 episode reward: total was 18.000000. running mean: -21.670853\n",
      "ep 23: ep_len:500 episode reward: total was -30.500000. running mean: -21.759144\n",
      "ep 23: ep_len:149 episode reward: total was 13.000000. running mean: -21.411553\n",
      "ep 23: ep_len:870 episode reward: total was 9.870000. running mean: -21.098737\n",
      "ep 23: ep_len:2604 episode reward: total was -448.150000. running mean: -25.369250\n",
      "ep 23: ep_len:500 episode reward: total was -12.790000. running mean: -25.243457\n",
      "ep 23: ep_len:930 episode reward: total was 16.270000. running mean: -24.828323\n",
      "ep 23: ep_len:875 episode reward: total was -9.600000. running mean: -24.676039\n",
      "ep 23: ep_len:950 episode reward: total was -15.600000. running mean: -24.585279\n",
      "ep 23: ep_len:500 episode reward: total was 2.090000. running mean: -24.318526\n",
      "ep 23: ep_len:885 episode reward: total was -20.470000. running mean: -24.280041\n",
      "ep 23: ep_len:780 episode reward: total was -5.950000. running mean: -24.096741\n",
      "ep 23: ep_len:575 episode reward: total was -7.990000. running mean: -23.935673\n",
      "ep 23: ep_len:234 episode reward: total was 18.500000. running mean: -23.511316\n",
      "ep 23: ep_len:139 episode reward: total was 9.000000. running mean: -23.186203\n",
      "ep 23: ep_len:500 episode reward: total was 20.310000. running mean: -22.751241\n",
      "ep 23: ep_len:680 episode reward: total was 6.370000. running mean: -22.460029\n",
      "ep 23: ep_len:1382 episode reward: total was -159.880000. running mean: -23.834228\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 23: ep_len:620 episode reward: total was -9.920000. running mean: -23.695086\n",
      "ep 23: ep_len:500 episode reward: total was -48.630000. running mean: -23.944435\n",
      "ep 23: ep_len:670 episode reward: total was -32.010000. running mean: -24.025091\n",
      "ep 23: ep_len:765 episode reward: total was -19.730000. running mean: -23.982140\n",
      "ep 23: ep_len:500 episode reward: total was 23.830000. running mean: -23.504019\n",
      "ep 23: ep_len:855 episode reward: total was 4.470000. running mean: -23.224278\n",
      "ep 23: ep_len:500 episode reward: total was -33.480000. running mean: -23.326836\n",
      "ep 23: ep_len:500 episode reward: total was 2.310000. running mean: -23.070467\n",
      "ep 23: ep_len:500 episode reward: total was 5.130000. running mean: -22.788463\n",
      "ep 23: ep_len:500 episode reward: total was 5.270000. running mean: -22.507878\n",
      "ep 23: ep_len:500 episode reward: total was -10.730000. running mean: -22.390099\n",
      "ep 23: ep_len:630 episode reward: total was -6.870000. running mean: -22.234898\n",
      "ep 23: ep_len:500 episode reward: total was 12.600000. running mean: -21.886549\n",
      "ep 23: ep_len:500 episode reward: total was -11.400000. running mean: -21.781684\n",
      "ep 23: ep_len:645 episode reward: total was -4.820000. running mean: -21.612067\n",
      "ep 23: ep_len:500 episode reward: total was -4.160000. running mean: -21.437546\n",
      "ep 23: ep_len:500 episode reward: total was -14.780000. running mean: -21.370971\n",
      "ep 23: ep_len:565 episode reward: total was -7.000000. running mean: -21.227261\n",
      "ep 23: ep_len:500 episode reward: total was -0.970000. running mean: -21.024688\n",
      "ep 23: ep_len:500 episode reward: total was 15.350000. running mean: -20.660942\n",
      "ep 23: ep_len:835 episode reward: total was 10.040000. running mean: -20.353932\n",
      "ep 23: ep_len:560 episode reward: total was 3.380000. running mean: -20.116593\n",
      "ep 23: ep_len:725 episode reward: total was 15.560000. running mean: -19.759827\n",
      "ep 23: ep_len:750 episode reward: total was -22.790000. running mean: -19.790129\n",
      "ep 23: ep_len:500 episode reward: total was 1.850000. running mean: -19.573727\n",
      "ep 23: ep_len:19785 episode reward: total was -2223.890000. running mean: -41.616890\n",
      "ep 23: ep_len:625 episode reward: total was -37.180000. running mean: -41.572521\n",
      "ep 23: ep_len:500 episode reward: total was 16.300000. running mean: -40.993796\n",
      "ep 23: ep_len:765 episode reward: total was 16.890000. running mean: -40.414958\n",
      "ep 23: ep_len:890 episode reward: total was 2.550000. running mean: -39.985308\n",
      "ep 23: ep_len:880 episode reward: total was 1.230000. running mean: -39.573155\n",
      "ep 23: ep_len:500 episode reward: total was 21.810000. running mean: -38.959324\n",
      "ep 23: ep_len:720 episode reward: total was -51.130000. running mean: -39.081031\n",
      "ep 23: ep_len:1333 episode reward: total was -263.000000. running mean: -41.320220\n",
      "ep 23: ep_len:775 episode reward: total was -42.610000. running mean: -41.333118\n",
      "ep 23: ep_len:856 episode reward: total was -71.040000. running mean: -41.630187\n",
      "ep 23: ep_len:625 episode reward: total was -51.290000. running mean: -41.726785\n",
      "ep 23: ep_len:267 episode reward: total was 23.500000. running mean: -41.074517\n",
      "ep 23: ep_len:580 episode reward: total was -24.140000. running mean: -40.905172\n",
      "ep 23: ep_len:500 episode reward: total was 16.300000. running mean: -40.333120\n",
      "ep 23: ep_len:500 episode reward: total was 16.330000. running mean: -39.766489\n",
      "ep 23: ep_len:5190 episode reward: total was -939.740000. running mean: -48.766224\n",
      "ep 23: ep_len:500 episode reward: total was 20.710000. running mean: -48.071462\n",
      "ep 23: ep_len:715 episode reward: total was -20.840000. running mean: -47.799147\n",
      "ep 23: ep_len:775 episode reward: total was -63.140000. running mean: -47.952556\n",
      "ep 23: ep_len:500 episode reward: total was 44.000000. running mean: -47.033030\n",
      "ep 23: ep_len:500 episode reward: total was -19.280000. running mean: -46.755500\n",
      "ep 23: ep_len:1134 episode reward: total was -112.290000. running mean: -47.410845\n",
      "ep 23: ep_len:880 episode reward: total was 5.010000. running mean: -46.886637\n",
      "ep 23: ep_len:595 episode reward: total was -18.410000. running mean: -46.601870\n",
      "ep 23: ep_len:615 episode reward: total was -6.760000. running mean: -46.203451\n",
      "ep 23: ep_len:615 episode reward: total was -23.510000. running mean: -45.976517\n",
      "ep 23: ep_len:685 episode reward: total was -13.830000. running mean: -45.655052\n",
      "ep 23: ep_len:500 episode reward: total was 47.000000. running mean: -44.728501\n",
      "ep 23: ep_len:780 episode reward: total was -16.020000. running mean: -44.441416\n",
      "ep 23: ep_len:750 episode reward: total was -20.770000. running mean: -44.204702\n",
      "ep 23: ep_len:114 episode reward: total was 9.500000. running mean: -43.667655\n",
      "ep 23: ep_len:715 episode reward: total was -10.120000. running mean: -43.332179\n",
      "ep 23: ep_len:980 episode reward: total was -32.760000. running mean: -43.226457\n",
      "ep 23: ep_len:500 episode reward: total was -4.690000. running mean: -42.841092\n",
      "ep 23: ep_len:175 episode reward: total was 14.500000. running mean: -42.267681\n",
      "ep 23: ep_len:505 episode reward: total was 0.760000. running mean: -41.837404\n",
      "ep 23: ep_len:530 episode reward: total was -22.220000. running mean: -41.641230\n",
      "ep 23: ep_len:1400 episode reward: total was -100.270000. running mean: -42.227518\n",
      "ep 23: ep_len:1390 episode reward: total was -132.610000. running mean: -43.131343\n",
      "ep 23: ep_len:500 episode reward: total was -5.710000. running mean: -42.757129\n",
      "ep 23: ep_len:370 episode reward: total was 29.500000. running mean: -42.034558\n",
      "ep 23: ep_len:500 episode reward: total was -25.950000. running mean: -41.873713\n",
      "ep 23: ep_len:500 episode reward: total was 41.000000. running mean: -41.044975\n",
      "ep 23: ep_len:430 episode reward: total was 38.500000. running mean: -40.249526\n",
      "ep 23: ep_len:880 episode reward: total was -10.050000. running mean: -39.947530\n",
      "ep 23: ep_len:1540 episode reward: total was -56.860000. running mean: -40.116655\n",
      "ep 23: ep_len:540 episode reward: total was -6.250000. running mean: -39.777989\n",
      "ep 23: ep_len:500 episode reward: total was 21.200000. running mean: -39.168209\n",
      "ep 23: ep_len:620 episode reward: total was -19.010000. running mean: -38.966627\n",
      "ep 23: ep_len:500 episode reward: total was 8.830000. running mean: -38.488660\n",
      "ep 23: ep_len:665 episode reward: total was -6.280000. running mean: -38.166574\n",
      "ep 23: ep_len:500 episode reward: total was 11.220000. running mean: -37.672708\n",
      "ep 23: ep_len:166 episode reward: total was 15.000000. running mean: -37.145981\n",
      "ep 23: ep_len:505 episode reward: total was 18.210000. running mean: -36.592421\n",
      "ep 23: ep_len:610 episode reward: total was -24.080000. running mean: -36.467297\n",
      "ep 23: ep_len:515 episode reward: total was -39.420000. running mean: -36.496824\n",
      "ep 23: ep_len:520 episode reward: total was 6.060000. running mean: -36.071256\n",
      "ep 23: ep_len:615 episode reward: total was 9.560000. running mean: -35.614943\n",
      "ep 23: ep_len:500 episode reward: total was 15.750000. running mean: -35.101294\n",
      "ep 23: ep_len:690 episode reward: total was -9.810000. running mean: -34.848381\n",
      "ep 23: ep_len:860 episode reward: total was 8.460000. running mean: -34.415297\n",
      "ep 23: ep_len:500 episode reward: total was 12.170000. running mean: -33.949444\n",
      "ep 23: ep_len:625 episode reward: total was -1.830000. running mean: -33.628250\n",
      "ep 23: ep_len:500 episode reward: total was 16.820000. running mean: -33.123767\n",
      "ep 23: ep_len:960 episode reward: total was 7.500000. running mean: -32.717529\n",
      "ep 23: ep_len:625 episode reward: total was 2.050000. running mean: -32.369854\n",
      "ep 23: ep_len:500 episode reward: total was 10.730000. running mean: -31.938856\n",
      "ep 23: ep_len:204 episode reward: total was 20.000000. running mean: -31.419467\n",
      "ep 23: ep_len:695 episode reward: total was -9.770000. running mean: -31.202972\n",
      "ep 23: ep_len:500 episode reward: total was 4.180000. running mean: -30.849143\n",
      "ep 23: ep_len:500 episode reward: total was 30.230000. running mean: -30.238351\n",
      "ep 23: ep_len:500 episode reward: total was 12.410000. running mean: -29.811868\n",
      "ep 23: ep_len:610 episode reward: total was -3.880000. running mean: -29.552549\n",
      "ep 23: ep_len:500 episode reward: total was -6.670000. running mean: -29.323724\n",
      "ep 23: ep_len:500 episode reward: total was 11.710000. running mean: -28.913386\n",
      "ep 23: ep_len:520 episode reward: total was 5.080000. running mean: -28.573452\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 23: ep_len:575 episode reward: total was 3.230000. running mean: -28.255418\n",
      "ep 23: ep_len:710 episode reward: total was -13.780000. running mean: -28.110664\n",
      "ep 23: ep_len:640 episode reward: total was -33.140000. running mean: -28.160957\n",
      "ep 23: ep_len:975 episode reward: total was 23.620000. running mean: -27.643148\n",
      "ep 23: ep_len:500 episode reward: total was 7.300000. running mean: -27.293716\n",
      "ep 23: ep_len:500 episode reward: total was -1.680000. running mean: -27.037579\n",
      "ep 23: ep_len:510 episode reward: total was -23.270000. running mean: -26.999903\n",
      "ep 23: ep_len:815 episode reward: total was 1.450000. running mean: -26.715404\n",
      "ep 23: ep_len:500 episode reward: total was -18.200000. running mean: -26.630250\n",
      "ep 23: ep_len:500 episode reward: total was 44.000000. running mean: -25.923948\n",
      "ep 23: ep_len:690 episode reward: total was -79.000000. running mean: -26.454708\n",
      "ep 23: ep_len:500 episode reward: total was 15.290000. running mean: -26.037261\n",
      "ep 23: ep_len:575 episode reward: total was -7.990000. running mean: -25.856788\n",
      "ep 23: ep_len:500 episode reward: total was 26.740000. running mean: -25.330820\n",
      "ep 23: ep_len:615 episode reward: total was -0.250000. running mean: -25.080012\n",
      "ep 23: ep_len:540 episode reward: total was -23.790000. running mean: -25.067112\n",
      "ep 23: ep_len:630 episode reward: total was -1.770000. running mean: -24.834141\n",
      "ep 23: ep_len:1000 episode reward: total was 22.720000. running mean: -24.358600\n",
      "ep 23: ep_len:176 episode reward: total was 16.000000. running mean: -23.955014\n",
      "ep 23: ep_len:790 episode reward: total was -20.690000. running mean: -23.922363\n",
      "ep 23: ep_len:590 episode reward: total was 11.280000. running mean: -23.570340\n",
      "ep 23: ep_len:500 episode reward: total was 21.870000. running mean: -23.115936\n",
      "ep 23: ep_len:1420 episode reward: total was -109.320000. running mean: -23.977977\n",
      "ep 23: ep_len:500 episode reward: total was 15.230000. running mean: -23.585897\n",
      "ep 23: ep_len:615 episode reward: total was -24.070000. running mean: -23.590738\n",
      "ep 23: ep_len:1010 episode reward: total was 16.830000. running mean: -23.186531\n",
      "ep 23: ep_len:765 episode reward: total was -16.700000. running mean: -23.121666\n",
      "ep 23: ep_len:855 episode reward: total was -6.490000. running mean: -22.955349\n",
      "ep 23: ep_len:885 episode reward: total was 11.590000. running mean: -22.609895\n",
      "ep 23: ep_len:595 episode reward: total was -8.960000. running mean: -22.473397\n",
      "ep 23: ep_len:570 episode reward: total was -0.630000. running mean: -22.254963\n",
      "ep 23: ep_len:500 episode reward: total was 1.080000. running mean: -22.021613\n",
      "ep 23: ep_len:500 episode reward: total was 8.920000. running mean: -21.712197\n",
      "ep 23: ep_len:505 episode reward: total was 14.260000. running mean: -21.352475\n",
      "ep 23: ep_len:500 episode reward: total was 24.260000. running mean: -20.896350\n",
      "ep 23: ep_len:500 episode reward: total was 11.090000. running mean: -20.576487\n",
      "ep 23: ep_len:740 episode reward: total was -10.690000. running mean: -20.477622\n",
      "ep 23: ep_len:860 episode reward: total was -72.060000. running mean: -20.993446\n",
      "ep 23: ep_len:635 episode reward: total was -8.880000. running mean: -20.872311\n",
      "ep 23: ep_len:600 episode reward: total was -0.870000. running mean: -20.672288\n",
      "ep 23: ep_len:500 episode reward: total was 7.940000. running mean: -20.386165\n",
      "ep 23: ep_len:725 episode reward: total was -36.980000. running mean: -20.552103\n",
      "ep 23: ep_len:860 episode reward: total was 15.590000. running mean: -20.190682\n",
      "ep 23: ep_len:685 episode reward: total was 9.230000. running mean: -19.896476\n",
      "ep 23: ep_len:1265 episode reward: total was -155.870000. running mean: -21.256211\n",
      "ep 23: ep_len:133 episode reward: total was 13.000000. running mean: -20.913649\n",
      "ep 23: ep_len:705 episode reward: total was 17.940000. running mean: -20.525112\n",
      "ep 23: ep_len:740 episode reward: total was -16.750000. running mean: -20.487361\n",
      "ep 23: ep_len:500 episode reward: total was 23.410000. running mean: -20.048387\n",
      "ep 23: ep_len:885 episode reward: total was 0.080000. running mean: -19.847104\n",
      "ep 23: ep_len:2455 episode reward: total was -380.460000. running mean: -23.453233\n",
      "ep 23: ep_len:570 episode reward: total was -24.230000. running mean: -23.461000\n",
      "ep 23: ep_len:630 episode reward: total was -24.040000. running mean: -23.466790\n",
      "ep 23: ep_len:525 episode reward: total was 1.740000. running mean: -23.214722\n",
      "ep 23: ep_len:550 episode reward: total was 2.800000. running mean: -22.954575\n",
      "ep 23: ep_len:500 episode reward: total was 23.220000. running mean: -22.492829\n",
      "ep 23: ep_len:920 episode reward: total was 13.140000. running mean: -22.136501\n",
      "ep 23: ep_len:575 episode reward: total was 29.310000. running mean: -21.622036\n",
      "ep 23: ep_len:980 episode reward: total was -7.200000. running mean: -21.477816\n",
      "ep 23: ep_len:840 episode reward: total was -111.120000. running mean: -22.374238\n",
      "ep 23: ep_len:970 episode reward: total was -17.790000. running mean: -22.328395\n",
      "ep 23: ep_len:500 episode reward: total was -12.420000. running mean: -22.229311\n",
      "ep 23: ep_len:510 episode reward: total was -19.230000. running mean: -22.199318\n",
      "ep 23: ep_len:1730 episode reward: total was -136.980000. running mean: -23.347125\n",
      "ep 23: ep_len:500 episode reward: total was 18.260000. running mean: -22.931054\n",
      "ep 23: ep_len:500 episode reward: total was 39.500000. running mean: -22.306743\n",
      "ep 23: ep_len:695 episode reward: total was -15.830000. running mean: -22.241976\n",
      "ep 23: ep_len:540 episode reward: total was 20.540000. running mean: -21.814156\n",
      "ep 23: ep_len:500 episode reward: total was -7.240000. running mean: -21.668414\n",
      "ep 23: ep_len:500 episode reward: total was 24.290000. running mean: -21.208830\n",
      "ep 23: ep_len:500 episode reward: total was 19.420000. running mean: -20.802542\n",
      "ep 23: ep_len:257 episode reward: total was 22.500000. running mean: -20.369517\n",
      "ep 23: ep_len:550 episode reward: total was -27.200000. running mean: -20.437821\n",
      "ep 23: ep_len:500 episode reward: total was 5.060000. running mean: -20.182843\n",
      "ep 23: ep_len:500 episode reward: total was -19.460000. running mean: -20.175615\n",
      "ep 23: ep_len:500 episode reward: total was 10.000000. running mean: -19.873859\n",
      "ep 23: ep_len:500 episode reward: total was 15.730000. running mean: -19.517820\n",
      "ep 23: ep_len:500 episode reward: total was 5.770000. running mean: -19.264942\n",
      "ep 23: ep_len:500 episode reward: total was 6.130000. running mean: -19.010992\n",
      "ep 23: ep_len:500 episode reward: total was -1.790000. running mean: -18.838782\n",
      "ep 23: ep_len:865 episode reward: total was -25.070000. running mean: -18.901095\n",
      "ep 23: ep_len:755 episode reward: total was 7.970000. running mean: -18.632384\n",
      "ep 23: ep_len:800 episode reward: total was -10.270000. running mean: -18.548760\n",
      "ep 23: ep_len:530 episode reward: total was -5.840000. running mean: -18.421672\n",
      "ep 23: ep_len:137 episode reward: total was 12.000000. running mean: -18.117456\n",
      "ep 23: ep_len:625 episode reward: total was 10.390000. running mean: -17.832381\n",
      "ep 23: ep_len:500 episode reward: total was 9.780000. running mean: -17.556257\n",
      "ep 23: ep_len:168 episode reward: total was 15.000000. running mean: -17.230695\n",
      "ep 23: ep_len:500 episode reward: total was 12.870000. running mean: -16.929688\n",
      "ep 23: ep_len:500 episode reward: total was 15.750000. running mean: -16.602891\n",
      "ep 23: ep_len:500 episode reward: total was 18.810000. running mean: -16.248762\n",
      "ep 23: ep_len:153 episode reward: total was 15.000000. running mean: -15.936274\n",
      "ep 23: ep_len:185 episode reward: total was 15.500000. running mean: -15.621911\n",
      "ep 23: ep_len:500 episode reward: total was 16.420000. running mean: -15.301492\n",
      "ep 23: ep_len:130 episode reward: total was 12.510000. running mean: -15.023377\n",
      "ep 23: ep_len:690 episode reward: total was -11.800000. running mean: -14.991144\n",
      "ep 23: ep_len:500 episode reward: total was 23.280000. running mean: -14.608432\n",
      "ep 23: ep_len:500 episode reward: total was 9.230000. running mean: -14.370048\n",
      "ep 23: ep_len:640 episode reward: total was -5.840000. running mean: -14.284747\n",
      "ep 23: ep_len:500 episode reward: total was 6.660000. running mean: -14.075300\n",
      "ep 23: ep_len:263 episode reward: total was 24.500000. running mean: -13.689547\n",
      "ep 23: ep_len:500 episode reward: total was -8.690000. running mean: -13.639551\n",
      "ep 23: ep_len:500 episode reward: total was 9.930000. running mean: -13.403856\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 23: ep_len:640 episode reward: total was 21.270000. running mean: -13.057117\n",
      "ep 23: ep_len:715 episode reward: total was 12.730000. running mean: -12.799246\n",
      "ep 23: ep_len:500 episode reward: total was -16.180000. running mean: -12.833054\n",
      "ep 23: ep_len:500 episode reward: total was 42.500000. running mean: -12.279723\n",
      "ep 23: ep_len:885 episode reward: total was 19.160000. running mean: -11.965326\n",
      "ep 23: ep_len:565 episode reward: total was -7.000000. running mean: -11.915673\n",
      "ep 23: ep_len:565 episode reward: total was -7.000000. running mean: -11.866516\n",
      "ep 23: ep_len:183 episode reward: total was -13.500000. running mean: -11.882851\n",
      "ep 23: ep_len:239 episode reward: total was 23.500000. running mean: -11.529022\n",
      "ep 23: ep_len:935 episode reward: total was 10.870000. running mean: -11.305032\n",
      "ep 23: ep_len:382 episode reward: total was 34.000000. running mean: -10.851982\n",
      "ep 23: ep_len:520 episode reward: total was -9.110000. running mean: -10.834562\n",
      "ep 23: ep_len:500 episode reward: total was 3.500000. running mean: -10.691216\n",
      "ep 23: ep_len:500 episode reward: total was 21.780000. running mean: -10.366504\n",
      "ep 23: ep_len:795 episode reward: total was -40.880000. running mean: -10.671639\n",
      "ep 23: ep_len:1510 episode reward: total was -55.580000. running mean: -11.120723\n",
      "ep 23: ep_len:1010 episode reward: total was 20.320000. running mean: -10.806316\n",
      "ep 23: ep_len:500 episode reward: total was 14.990000. running mean: -10.548352\n",
      "ep 23: ep_len:500 episode reward: total was 23.280000. running mean: -10.210069\n",
      "ep 23: ep_len:655 episode reward: total was -7.120000. running mean: -10.179168\n",
      "ep 23: ep_len:970 episode reward: total was 13.260000. running mean: -9.944776\n",
      "ep 23: ep_len:274 episode reward: total was 24.000000. running mean: -9.605329\n",
      "ep 23: ep_len:1330 episode reward: total was -107.480000. running mean: -10.584075\n",
      "ep 23: ep_len:955 episode reward: total was 11.200000. running mean: -10.366235\n",
      "ep 23: ep_len:500 episode reward: total was -79.850000. running mean: -11.061072\n",
      "ep 23: ep_len:500 episode reward: total was 24.300000. running mean: -10.707462\n",
      "ep 23: ep_len:169 episode reward: total was 16.500000. running mean: -10.435387\n",
      "ep 23: ep_len:525 episode reward: total was -19.950000. running mean: -10.530533\n",
      "ep 23: ep_len:500 episode reward: total was 44.000000. running mean: -9.985228\n",
      "ep 23: ep_len:500 episode reward: total was 18.290000. running mean: -9.702476\n",
      "ep 23: ep_len:845 episode reward: total was -16.610000. running mean: -9.771551\n",
      "ep 23: ep_len:595 episode reward: total was -26.130000. running mean: -9.935135\n",
      "ep 23: ep_len:162 episode reward: total was 13.000000. running mean: -9.705784\n",
      "ep 23: ep_len:198 episode reward: total was 18.000000. running mean: -9.428726\n",
      "ep 23: ep_len:134 episode reward: total was 13.000000. running mean: -9.204439\n",
      "ep 23: ep_len:339 episode reward: total was 19.000000. running mean: -8.922394\n",
      "ep 23: ep_len:500 episode reward: total was -4.890000. running mean: -8.882070\n",
      "ep 23: ep_len:745 episode reward: total was 4.370000. running mean: -8.749550\n",
      "ep 23: ep_len:605 episode reward: total was 0.070000. running mean: -8.661354\n",
      "ep 23: ep_len:530 episode reward: total was -9.090000. running mean: -8.665641\n",
      "ep 23: ep_len:680 episode reward: total was -7.780000. running mean: -8.656784\n",
      "ep 23: ep_len:525 episode reward: total was -3.530000. running mean: -8.605516\n",
      "ep 23: ep_len:384 episode reward: total was 36.500000. running mean: -8.154461\n",
      "ep 23: ep_len:590 episode reward: total was -25.100000. running mean: -8.323917\n",
      "ep 23: ep_len:520 episode reward: total was 4.600000. running mean: -8.194678\n",
      "ep 23: ep_len:785 episode reward: total was -14.640000. running mean: -8.259131\n",
      "ep 23: ep_len:705 episode reward: total was -38.030000. running mean: -8.556839\n",
      "ep 23: ep_len:500 episode reward: total was 6.780000. running mean: -8.403471\n",
      "ep 23: ep_len:980 episode reward: total was 13.570000. running mean: -8.183736\n",
      "ep 23: ep_len:780 episode reward: total was -19.700000. running mean: -8.298899\n",
      "ep 23: ep_len:700 episode reward: total was 1.820000. running mean: -8.197710\n",
      "ep 23: ep_len:500 episode reward: total was 32.250000. running mean: -7.793233\n",
      "ep 23: ep_len:600 episode reward: total was -60.460000. running mean: -8.319901\n",
      "ep 23: ep_len:1035 episode reward: total was -24.060000. running mean: -8.477302\n",
      "ep 23: ep_len:1525 episode reward: total was -173.470000. running mean: -10.127229\n",
      "ep 23: ep_len:1050 episode reward: total was -10.710000. running mean: -10.133056\n",
      "ep 23: ep_len:500 episode reward: total was 12.750000. running mean: -9.904226\n",
      "ep 23: ep_len:850 episode reward: total was -3.450000. running mean: -9.839683\n",
      "ep 23: ep_len:307 episode reward: total was 27.500000. running mean: -9.466287\n",
      "ep 23: ep_len:515 episode reward: total was -20.200000. running mean: -9.573624\n",
      "ep 23: ep_len:500 episode reward: total was -10.170000. running mean: -9.579587\n",
      "ep 23: ep_len:670 episode reward: total was -24.970000. running mean: -9.733492\n",
      "ep 23: ep_len:510 episode reward: total was -1.050000. running mean: -9.646657\n",
      "ep 23: ep_len:585 episode reward: total was 7.660000. running mean: -9.473590\n",
      "ep 23: ep_len:500 episode reward: total was 33.290000. running mean: -9.045954\n",
      "ep 23: ep_len:156 episode reward: total was 14.000000. running mean: -8.815495\n",
      "ep 23: ep_len:1380 episode reward: total was -29.580000. running mean: -9.023140\n",
      "ep 23: ep_len:1450 episode reward: total was -77.400000. running mean: -9.706908\n",
      "ep 23: ep_len:535 episode reward: total was -19.180000. running mean: -9.801639\n",
      "ep 23: ep_len:535 episode reward: total was -78.770000. running mean: -10.491323\n",
      "ep 23: ep_len:237 episode reward: total was 20.500000. running mean: -10.181410\n",
      "ep 23: ep_len:585 episode reward: total was 10.780000. running mean: -9.971796\n",
      "ep 23: ep_len:890 episode reward: total was 8.900000. running mean: -9.783078\n",
      "ep 23: ep_len:650 episode reward: total was -9.200000. running mean: -9.777247\n",
      "ep 23: ep_len:1000 episode reward: total was 24.320000. running mean: -9.436274\n",
      "ep 23: ep_len:746 episode reward: total was -79.830000. running mean: -10.140212\n",
      "ep 23: ep_len:500 episode reward: total was 4.760000. running mean: -9.991209\n",
      "ep 23: ep_len:500 episode reward: total was 22.970000. running mean: -9.661597\n",
      "ep 23: ep_len:510 episode reward: total was -16.200000. running mean: -9.726981\n",
      "ep 23: ep_len:200 episode reward: total was 15.500000. running mean: -9.474712\n",
      "ep 23: ep_len:570 episode reward: total was -72.640000. running mean: -10.106364\n",
      "ep 23: ep_len:500 episode reward: total was 22.330000. running mean: -9.782001\n",
      "ep 23: ep_len:860 episode reward: total was -0.740000. running mean: -9.691581\n",
      "ep 23: ep_len:705 episode reward: total was -2.060000. running mean: -9.615265\n",
      "ep 23: ep_len:500 episode reward: total was 25.820000. running mean: -9.260912\n",
      "ep 23: ep_len:500 episode reward: total was -4.800000. running mean: -9.216303\n",
      "ep 23: ep_len:500 episode reward: total was -27.420000. running mean: -9.398340\n",
      "ep 23: ep_len:409 episode reward: total was -7.580000. running mean: -9.380157\n",
      "ep 23: ep_len:870 episode reward: total was 6.290000. running mean: -9.223455\n",
      "ep 23: ep_len:970 episode reward: total was 25.700000. running mean: -8.874221\n",
      "ep 23: ep_len:700 episode reward: total was 20.290000. running mean: -8.582578\n",
      "ep 23: ep_len:1150 episode reward: total was -130.600000. running mean: -9.802753\n",
      "ep 23: ep_len:500 episode reward: total was 2.300000. running mean: -9.681725\n",
      "ep 23: ep_len:252 episode reward: total was 25.000000. running mean: -9.334908\n",
      "ep 23: ep_len:760 episode reward: total was 7.490000. running mean: -9.166659\n",
      "ep 23: ep_len:750 episode reward: total was -11.920000. running mean: -9.194192\n",
      "ep 23: ep_len:500 episode reward: total was 18.270000. running mean: -8.919550\n",
      "ep 23: ep_len:500 episode reward: total was 25.740000. running mean: -8.572955\n",
      "ep 23: ep_len:710 episode reward: total was -3.680000. running mean: -8.524025\n",
      "ep 23: ep_len:155 episode reward: total was 12.500000. running mean: -8.313785\n",
      "ep 23: ep_len:505 episode reward: total was 10.800000. running mean: -8.122647\n",
      "ep 23: ep_len:500 episode reward: total was -9.480000. running mean: -8.136221\n",
      "ep 23: ep_len:169 episode reward: total was 15.000000. running mean: -7.904859\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 23: ep_len:505 episode reward: total was -2.710000. running mean: -7.852910\n",
      "ep 23: ep_len:595 episode reward: total was -11.990000. running mean: -7.894281\n",
      "ep 23: ep_len:338 episode reward: total was 27.500000. running mean: -7.540338\n",
      "ep 23: ep_len:500 episode reward: total was 5.710000. running mean: -7.407835\n",
      "ep 23: ep_len:500 episode reward: total was -14.410000. running mean: -7.477856\n",
      "ep 23: ep_len:1095 episode reward: total was -139.000000. running mean: -8.793078\n",
      "ep 23: ep_len:625 episode reward: total was 14.440000. running mean: -8.560747\n",
      "ep 23: ep_len:628 episode reward: total was -50.290000. running mean: -8.978039\n",
      "ep 23: ep_len:500 episode reward: total was -10.310000. running mean: -8.991359\n",
      "ep 23: ep_len:500 episode reward: total was -15.210000. running mean: -9.053545\n",
      "ep 23: ep_len:1570 episode reward: total was -46.270000. running mean: -9.425710\n",
      "ep 23: ep_len:1447 episode reward: total was -198.670000. running mean: -11.318153\n",
      "ep 23: ep_len:675 episode reward: total was -31.020000. running mean: -11.515171\n",
      "ep 23: ep_len:730 episode reward: total was -39.260000. running mean: -11.792620\n",
      "ep 23: ep_len:500 episode reward: total was 47.000000. running mean: -11.204693\n",
      "ep 23: ep_len:1135 episode reward: total was -127.640000. running mean: -12.369047\n",
      "ep 23: ep_len:770 episode reward: total was 26.730000. running mean: -11.978056\n",
      "ep 23: ep_len:1740 episode reward: total was -42.460000. running mean: -12.282876\n",
      "ep 23: ep_len:275 episode reward: total was 23.000000. running mean: -11.930047\n",
      "ep 23: ep_len:500 episode reward: total was 18.750000. running mean: -11.623246\n",
      "ep 23: ep_len:895 episode reward: total was -45.730000. running mean: -11.964314\n",
      "ep 23: ep_len:500 episode reward: total was -15.210000. running mean: -11.996771\n",
      "ep 23: ep_len:540 episode reward: total was -22.200000. running mean: -12.098803\n",
      "ep 23: ep_len:500 episode reward: total was 8.770000. running mean: -11.890115\n",
      "ep 23: ep_len:129 episode reward: total was 11.000000. running mean: -11.661214\n",
      "ep 23: ep_len:1055 episode reward: total was 12.420000. running mean: -11.420402\n",
      "ep 23: ep_len:1045 episode reward: total was -116.760000. running mean: -12.473798\n",
      "ep 23: ep_len:730 episode reward: total was -12.730000. running mean: -12.476360\n",
      "ep 23: ep_len:1270 episode reward: total was -154.060000. running mean: -13.892196\n",
      "ep 23: ep_len:222 episode reward: total was 21.000000. running mean: -13.543274\n",
      "ep 23: ep_len:500 episode reward: total was 29.310000. running mean: -13.114741\n",
      "ep 23: ep_len:895 episode reward: total was -29.570000. running mean: -13.279294\n",
      "ep 23: ep_len:950 episode reward: total was 16.730000. running mean: -12.979201\n",
      "ep 23: ep_len:267 episode reward: total was 25.000000. running mean: -12.599409\n",
      "ep 23: ep_len:1180 episode reward: total was -9.400000. running mean: -12.567415\n",
      "ep 23: ep_len:500 episode reward: total was 7.950000. running mean: -12.362241\n",
      "ep 23: ep_len:127 episode reward: total was 13.000000. running mean: -12.108618\n",
      "ep 23: ep_len:1090 episode reward: total was 17.390000. running mean: -11.813632\n",
      "ep 23: ep_len:760 episode reward: total was -22.770000. running mean: -11.923196\n",
      "ep 23: ep_len:635 episode reward: total was -3.550000. running mean: -11.839464\n",
      "ep 23: ep_len:515 episode reward: total was -1.040000. running mean: -11.731469\n",
      "ep 23: ep_len:790 episode reward: total was -70.180000. running mean: -12.315955\n",
      "ep 23: ep_len:790 episode reward: total was -9.580000. running mean: -12.288595\n",
      "ep 23: ep_len:486 episode reward: total was 41.000000. running mean: -11.755709\n",
      "ep 23: ep_len:855 episode reward: total was 6.460000. running mean: -11.573552\n",
      "ep 23: ep_len:500 episode reward: total was 42.500000. running mean: -11.032816\n",
      "ep 23: ep_len:1690 episode reward: total was -168.540000. running mean: -12.607888\n",
      "ep 23: ep_len:500 episode reward: total was 21.810000. running mean: -12.263709\n",
      "ep 23: ep_len:625 episode reward: total was -47.020000. running mean: -12.611272\n",
      "ep 23: ep_len:920 episode reward: total was -97.190000. running mean: -13.457060\n",
      "ep 23: ep_len:500 episode reward: total was 13.800000. running mean: -13.184489\n",
      "ep 23: ep_len:1020 episode reward: total was -13.860000. running mean: -13.191244\n",
      "ep 23: ep_len:625 episode reward: total was -29.070000. running mean: -13.350032\n",
      "ep 23: ep_len:690 episode reward: total was -6.580000. running mean: -13.282331\n",
      "ep 23: ep_len:690 episode reward: total was -6.750000. running mean: -13.217008\n",
      "ep 23: ep_len:640 episode reward: total was -42.390000. running mean: -13.508738\n",
      "ep 23: ep_len:213 episode reward: total was 18.500000. running mean: -13.188651\n",
      "ep 23: ep_len:870 episode reward: total was 8.050000. running mean: -12.976264\n",
      "ep 23: ep_len:500 episode reward: total was 3.290000. running mean: -12.813601\n",
      "ep 23: ep_len:175 episode reward: total was 14.500000. running mean: -12.540465\n",
      "ep 23: ep_len:895 episode reward: total was -28.230000. running mean: -12.697361\n",
      "ep 23: ep_len:500 episode reward: total was -3.940000. running mean: -12.609787\n",
      "ep 23: ep_len:1055 episode reward: total was 2.360000. running mean: -12.460089\n",
      "ep 23: ep_len:500 episode reward: total was 3.470000. running mean: -12.300788\n",
      "ep 23: ep_len:500 episode reward: total was 7.810000. running mean: -12.099681\n",
      "ep 23: ep_len:575 episode reward: total was 11.030000. running mean: -11.868384\n",
      "ep 23: ep_len:880 episode reward: total was -70.000000. running mean: -12.449700\n",
      "ep 23: ep_len:805 episode reward: total was -23.840000. running mean: -12.563603\n",
      "ep 23: ep_len:492 episode reward: total was 30.270000. running mean: -12.135267\n",
      "ep 23: ep_len:630 episode reward: total was -8.150000. running mean: -12.095414\n",
      "ep 23: ep_len:500 episode reward: total was -37.520000. running mean: -12.349660\n",
      "ep 23: ep_len:690 episode reward: total was 3.280000. running mean: -12.193363\n",
      "ep 23: ep_len:500 episode reward: total was 6.560000. running mean: -12.005830\n",
      "ep 23: ep_len:569 episode reward: total was -60.560000. running mean: -12.491372\n",
      "ep 23: ep_len:500 episode reward: total was 18.290000. running mean: -12.183558\n",
      "ep 23: ep_len:500 episode reward: total was 21.810000. running mean: -11.843622\n",
      "ep 23: ep_len:630 episode reward: total was 17.230000. running mean: -11.552886\n",
      "ep 23: ep_len:500 episode reward: total was 14.770000. running mean: -11.289657\n",
      "ep 23: ep_len:770 episode reward: total was -0.490000. running mean: -11.181661\n",
      "ep 23: ep_len:675 episode reward: total was -0.720000. running mean: -11.077044\n",
      "ep 23: ep_len:990 episode reward: total was -10.990000. running mean: -11.076174\n",
      "ep 23: ep_len:236 episode reward: total was 20.500000. running mean: -10.760412\n",
      "ep 23: ep_len:920 episode reward: total was -0.160000. running mean: -10.654408\n",
      "ep 23: ep_len:845 episode reward: total was 10.110000. running mean: -10.446764\n",
      "ep 23: ep_len:500 episode reward: total was 21.880000. running mean: -10.123496\n",
      "ep 23: ep_len:500 episode reward: total was 21.330000. running mean: -9.808961\n",
      "ep 23: ep_len:500 episode reward: total was 29.340000. running mean: -9.417471\n",
      "ep 23: ep_len:545 episode reward: total was -12.060000. running mean: -9.443897\n",
      "ep 23: ep_len:980 episode reward: total was -56.310000. running mean: -9.912558\n",
      "ep 23: ep_len:314 episode reward: total was 31.000000. running mean: -9.503432\n",
      "ep 23: ep_len:600 episode reward: total was 14.970000. running mean: -9.258698\n",
      "ep 23: ep_len:500 episode reward: total was -2.140000. running mean: -9.187511\n",
      "ep 23: ep_len:500 episode reward: total was -21.820000. running mean: -9.313836\n",
      "ep 23: ep_len:500 episode reward: total was -0.120000. running mean: -9.221897\n",
      "ep 23: ep_len:730 episode reward: total was -1.090000. running mean: -9.140578\n",
      "ep 23: ep_len:500 episode reward: total was -6.260000. running mean: -9.111773\n",
      "ep 23: ep_len:565 episode reward: total was 11.740000. running mean: -8.903255\n",
      "ep 23: ep_len:410 episode reward: total was 38.000000. running mean: -8.434222\n",
      "ep 23: ep_len:500 episode reward: total was 22.820000. running mean: -8.121680\n",
      "ep 23: ep_len:500 episode reward: total was 17.460000. running mean: -7.865863\n",
      "ep 23: ep_len:500 episode reward: total was 4.260000. running mean: -7.744605\n",
      "ep 23: ep_len:273 episode reward: total was 25.500000. running mean: -7.412159\n",
      "ep 23: ep_len:278 episode reward: total was 23.000000. running mean: -7.108037\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 23: ep_len:525 episode reward: total was -11.090000. running mean: -7.147857\n",
      "ep 23: ep_len:730 episode reward: total was -21.370000. running mean: -7.290078\n",
      "ep 23: ep_len:910 episode reward: total was 13.580000. running mean: -7.081377\n",
      "ep 23: ep_len:595 episode reward: total was -26.130000. running mean: -7.271864\n",
      "ep 23: ep_len:825 episode reward: total was -75.160000. running mean: -7.950745\n",
      "ep 23: ep_len:500 episode reward: total was -3.670000. running mean: -7.907937\n",
      "ep 23: ep_len:745 episode reward: total was -10.680000. running mean: -7.935658\n",
      "ep 23: ep_len:500 episode reward: total was -3.640000. running mean: -7.892702\n",
      "ep 23: ep_len:10605 episode reward: total was -2028.920000. running mean: -28.102974\n",
      "ep 23: ep_len:500 episode reward: total was 14.460000. running mean: -27.677345\n",
      "ep 23: ep_len:1065 episode reward: total was -6.880000. running mean: -27.469371\n",
      "ep 23: ep_len:875 episode reward: total was -28.220000. running mean: -27.476878\n",
      "ep 23: ep_len:865 episode reward: total was -12.640000. running mean: -27.328509\n",
      "ep 23: ep_len:457 episode reward: total was 12.710000. running mean: -26.928124\n",
      "ep 23: ep_len:500 episode reward: total was -3.140000. running mean: -26.690242\n",
      "ep 23: ep_len:870 episode reward: total was -10.050000. running mean: -26.523840\n",
      "ep 23: ep_len:43475 episode reward: total was -8558.010000. running mean: -111.838702\n",
      "ep 23: ep_len:920 episode reward: total was -92.590000. running mean: -111.646215\n",
      "ep 23: ep_len:560 episode reward: total was -43.370000. running mean: -110.963452\n",
      "ep 23: ep_len:540 episode reward: total was 9.920000. running mean: -109.754618\n",
      "ep 23: ep_len:2260 episode reward: total was -353.700000. running mean: -112.194072\n",
      "ep 23: ep_len:615 episode reward: total was -31.140000. running mean: -111.383531\n",
      "ep 23: ep_len:500 episode reward: total was -35.490000. running mean: -110.624596\n",
      "ep 23: ep_len:805 episode reward: total was -109.540000. running mean: -110.613750\n",
      "ep 23: ep_len:500 episode reward: total was -17.260000. running mean: -109.680212\n",
      "ep 23: ep_len:675 episode reward: total was -28.760000. running mean: -108.871010\n",
      "ep 23: ep_len:775 episode reward: total was -37.450000. running mean: -108.156800\n",
      "ep 23: ep_len:500 episode reward: total was -45.930000. running mean: -107.534532\n",
      "ep 23: ep_len:840 episode reward: total was -65.030000. running mean: -107.109487\n",
      "ep 23: ep_len:500 episode reward: total was -23.870000. running mean: -106.277092\n",
      "ep 23: ep_len:550 episode reward: total was -17.020000. running mean: -105.384521\n",
      "ep 23: ep_len:945 episode reward: total was -86.030000. running mean: -105.190976\n",
      "ep 23: ep_len:500 episode reward: total was -11.370000. running mean: -104.252766\n",
      "ep 23: ep_len:500 episode reward: total was 2.870000. running mean: -103.181538\n",
      "ep 23: ep_len:345 episode reward: total was 26.000000. running mean: -101.889723\n",
      "ep 23: ep_len:545 episode reward: total was -88.450000. running mean: -101.755326\n",
      "ep 23: ep_len:500 episode reward: total was -5.000000. running mean: -100.787772\n",
      "ep 23: ep_len:850 episode reward: total was -48.950000. running mean: -100.269395\n",
      "ep 23: ep_len:723 episode reward: total was -65.740000. running mean: -99.924101\n",
      "ep 23: ep_len:605 episode reward: total was -11.870000. running mean: -99.043560\n",
      "ep 23: ep_len:1480 episode reward: total was -157.680000. running mean: -99.629924\n",
      "ep 23: ep_len:625 episode reward: total was -90.680000. running mean: -99.540425\n",
      "ep 23: ep_len:675 episode reward: total was -50.210000. running mean: -99.047121\n",
      "ep 23: ep_len:1985 episode reward: total was -297.040000. running mean: -101.027049\n",
      "ep 23: ep_len:870 episode reward: total was -49.510000. running mean: -100.511879\n",
      "ep 23: ep_len:500 episode reward: total was 15.720000. running mean: -99.349560\n",
      "ep 23: ep_len:535 episode reward: total was -12.110000. running mean: -98.477165\n",
      "ep 23: ep_len:500 episode reward: total was -9.270000. running mean: -97.585093\n",
      "ep 23: ep_len:510 episode reward: total was -11.940000. running mean: -96.728642\n",
      "ep 23: ep_len:1390 episode reward: total was -148.770000. running mean: -97.249056\n",
      "ep 23: ep_len:1255 episode reward: total was -42.350000. running mean: -96.700065\n",
      "ep 23: ep_len:505 episode reward: total was 9.140000. running mean: -95.641664\n",
      "ep 23: ep_len:804 episode reward: total was -48.640000. running mean: -95.171648\n",
      "ep 23: ep_len:905 episode reward: total was 14.780000. running mean: -94.072131\n",
      "ep 23: ep_len:570 episode reward: total was -17.120000. running mean: -93.302610\n",
      "ep 23: ep_len:547 episode reward: total was -6.760000. running mean: -92.437184\n",
      "ep 23: ep_len:565 episode reward: total was -28.210000. running mean: -91.794912\n",
      "ep 23: ep_len:935 episode reward: total was -3.400000. running mean: -90.910963\n",
      "ep 23: ep_len:500 episode reward: total was -19.340000. running mean: -90.195253\n",
      "ep 23: ep_len:510 episode reward: total was 10.500000. running mean: -89.188301\n",
      "ep 23: ep_len:500 episode reward: total was 9.810000. running mean: -88.198318\n",
      "ep 23: ep_len:500 episode reward: total was 10.050000. running mean: -87.215835\n",
      "ep 23: ep_len:740 episode reward: total was 8.400000. running mean: -86.259676\n",
      "ep 23: ep_len:925 episode reward: total was -50.450000. running mean: -85.901579\n",
      "ep 23: ep_len:685 episode reward: total was -27.140000. running mean: -85.313964\n",
      "ep 23: ep_len:725 episode reward: total was -97.580000. running mean: -85.436624\n",
      "ep 23: ep_len:750 episode reward: total was -78.340000. running mean: -85.365658\n",
      "ep 23: ep_len:500 episode reward: total was 3.320000. running mean: -84.478801\n",
      "ep 23: ep_len:500 episode reward: total was 7.850000. running mean: -83.555513\n",
      "ep 23: ep_len:1130 episode reward: total was 8.840000. running mean: -82.631558\n",
      "ep 23: ep_len:500 episode reward: total was 12.180000. running mean: -81.683442\n",
      "ep 23: ep_len:895 episode reward: total was -7.680000. running mean: -80.943408\n",
      "ep 23: ep_len:500 episode reward: total was -1.770000. running mean: -80.151674\n",
      "ep 23: ep_len:162 episode reward: total was 15.000000. running mean: -79.200157\n",
      "ep 23: ep_len:500 episode reward: total was 15.200000. running mean: -78.256156\n",
      "ep 23: ep_len:500 episode reward: total was 20.290000. running mean: -77.270694\n",
      "ep 23: ep_len:241 episode reward: total was 20.000000. running mean: -76.297987\n",
      "ep 23: ep_len:1340 episode reward: total was -118.170000. running mean: -76.716707\n",
      "ep 23: ep_len:278 episode reward: total was 27.500000. running mean: -75.674540\n",
      "ep 23: ep_len:500 episode reward: total was 3.190000. running mean: -74.885895\n",
      "ep 23: ep_len:645 episode reward: total was 13.660000. running mean: -74.000436\n",
      "ep 23: ep_len:500 episode reward: total was -7.280000. running mean: -73.333232\n",
      "ep 23: ep_len:500 episode reward: total was 17.770000. running mean: -72.422199\n",
      "ep 23: ep_len:500 episode reward: total was -5.310000. running mean: -71.751077\n",
      "ep 23: ep_len:61 episode reward: total was 6.000000. running mean: -70.973566\n",
      "ep 23: ep_len:1000 episode reward: total was -100.200000. running mean: -71.265831\n",
      "ep 23: ep_len:790 episode reward: total was -24.210000. running mean: -70.795272\n",
      "ep 23: ep_len:500 episode reward: total was 17.680000. running mean: -69.910520\n",
      "ep 23: ep_len:500 episode reward: total was 48.500000. running mean: -68.726415\n",
      "ep 23: ep_len:500 episode reward: total was 11.060000. running mean: -67.928550\n",
      "ep 23: ep_len:830 episode reward: total was 7.970000. running mean: -67.169565\n",
      "ep 23: ep_len:850 episode reward: total was -26.630000. running mean: -66.764169\n",
      "ep 23: ep_len:975 episode reward: total was 7.330000. running mean: -66.023228\n",
      "ep 23: ep_len:500 episode reward: total was 12.840000. running mean: -65.234595\n",
      "ep 23: ep_len:560 episode reward: total was -8.600000. running mean: -64.668249\n",
      "ep 23: ep_len:500 episode reward: total was 5.740000. running mean: -63.964167\n",
      "ep 23: ep_len:500 episode reward: total was 22.850000. running mean: -63.096025\n",
      "ep 23: ep_len:500 episode reward: total was -12.030000. running mean: -62.585365\n",
      "ep 23: ep_len:219 episode reward: total was 21.500000. running mean: -61.744511\n",
      "ep 23: ep_len:560 episode reward: total was 3.930000. running mean: -61.087766\n",
      "ep 23: ep_len:1630 episode reward: total was -38.820000. running mean: -60.865088\n",
      "ep 23: ep_len:500 episode reward: total was 28.270000. running mean: -59.973738\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 23: ep_len:715 episode reward: total was 4.880000. running mean: -59.325200\n",
      "ep 23: ep_len:505 episode reward: total was 8.480000. running mean: -58.647148\n",
      "ep 23: ep_len:500 episode reward: total was -2.240000. running mean: -58.083077\n",
      "ep 23: ep_len:535 episode reward: total was -18.470000. running mean: -57.686946\n",
      "ep 23: ep_len:955 episode reward: total was -5.180000. running mean: -57.161877\n",
      "ep 23: ep_len:500 episode reward: total was -8.030000. running mean: -56.670558\n",
      "ep 23: ep_len:252 episode reward: total was 22.000000. running mean: -55.883852\n",
      "ep 23: ep_len:855 episode reward: total was 11.600000. running mean: -55.209014\n",
      "ep 23: ep_len:369 episode reward: total was 35.000000. running mean: -54.306924\n",
      "ep 23: ep_len:710 episode reward: total was 7.930000. running mean: -53.684554\n",
      "ep 23: ep_len:500 episode reward: total was 6.190000. running mean: -53.085809\n",
      "ep 23: ep_len:500 episode reward: total was 2.270000. running mean: -52.532251\n",
      "ep 23: ep_len:500 episode reward: total was 21.780000. running mean: -51.789128\n",
      "ep 23: ep_len:695 episode reward: total was -14.820000. running mean: -51.419437\n",
      "ep 23: ep_len:500 episode reward: total was 7.660000. running mean: -50.828642\n",
      "ep 23: ep_len:500 episode reward: total was 20.800000. running mean: -50.112356\n",
      "ep 23: ep_len:580 episode reward: total was 13.950000. running mean: -49.471733\n",
      "ep 23: ep_len:950 episode reward: total was -31.480000. running mean: -49.291815\n",
      "ep 23: ep_len:525 episode reward: total was -20.210000. running mean: -49.000997\n",
      "ep 23: ep_len:505 episode reward: total was -28.330000. running mean: -48.794287\n",
      "ep 23: ep_len:285 episode reward: total was 7.730000. running mean: -48.229044\n",
      "ep 23: ep_len:926 episode reward: total was -69.030000. running mean: -48.437054\n",
      "ep 23: ep_len:645 episode reward: total was 23.170000. running mean: -47.720983\n",
      "ep 23: ep_len:515 episode reward: total was -4.890000. running mean: -47.292673\n",
      "ep 23: ep_len:193 episode reward: total was 17.500000. running mean: -46.644747\n",
      "ep 23: ep_len:500 episode reward: total was -3.790000. running mean: -46.216199\n",
      "ep 23: ep_len:510 episode reward: total was 18.310000. running mean: -45.570937\n",
      "ep 23: ep_len:500 episode reward: total was 44.000000. running mean: -44.675228\n",
      "ep 23: ep_len:685 episode reward: total was -7.770000. running mean: -44.306176\n",
      "ep 23: ep_len:720 episode reward: total was -11.740000. running mean: -43.980514\n",
      "ep 23: ep_len:600 episode reward: total was 13.340000. running mean: -43.407309\n",
      "ep 23: ep_len:500 episode reward: total was 16.790000. running mean: -42.805336\n",
      "ep 23: ep_len:835 episode reward: total was -10.500000. running mean: -42.482282\n",
      "ep 23: ep_len:785 episode reward: total was -42.150000. running mean: -42.478959\n",
      "ep 23: ep_len:500 episode reward: total was 1.370000. running mean: -42.040470\n",
      "ep 23: ep_len:235 episode reward: total was 22.000000. running mean: -41.400065\n",
      "ep 23: ep_len:500 episode reward: total was -6.180000. running mean: -41.047864\n",
      "ep 23: ep_len:500 episode reward: total was 24.290000. running mean: -40.394486\n",
      "ep 23: ep_len:280 episode reward: total was 24.510000. running mean: -39.745441\n",
      "ep 23: ep_len:1055 episode reward: total was 9.980000. running mean: -39.248187\n",
      "ep 23: ep_len:690 episode reward: total was -4.730000. running mean: -38.903005\n",
      "ep 23: ep_len:1285 episode reward: total was -12.630000. running mean: -38.640275\n",
      "ep 23: ep_len:855 episode reward: total was -9.450000. running mean: -38.348372\n",
      "ep 23: ep_len:505 episode reward: total was 12.330000. running mean: -37.841588\n",
      "ep 23: ep_len:835 episode reward: total was 1.380000. running mean: -37.449372\n",
      "ep 23: ep_len:840 episode reward: total was 18.090000. running mean: -36.893979\n",
      "ep 23: ep_len:500 episode reward: total was -12.730000. running mean: -36.652339\n",
      "ep 23: ep_len:203 episode reward: total was 17.000000. running mean: -36.115815\n",
      "ep 23: ep_len:500 episode reward: total was 4.080000. running mean: -35.713857\n",
      "ep 23: ep_len:686 episode reward: total was -7.750000. running mean: -35.434219\n",
      "ep 23: ep_len:500 episode reward: total was 10.940000. running mean: -34.970476\n",
      "ep 23: ep_len:500 episode reward: total was 8.610000. running mean: -34.534672\n",
      "ep 23: ep_len:910 episode reward: total was -21.580000. running mean: -34.405125\n",
      "ep 23: ep_len:515 episode reward: total was -28.210000. running mean: -34.343174\n",
      "ep 23: ep_len:500 episode reward: total was 15.600000. running mean: -33.843742\n",
      "ep 23: ep_len:975 episode reward: total was 22.330000. running mean: -33.282005\n",
      "ep 23: ep_len:1310 episode reward: total was -140.850000. running mean: -34.357685\n",
      "ep 23: ep_len:260 episode reward: total was 24.500000. running mean: -33.769108\n",
      "ep 23: ep_len:500 episode reward: total was 18.720000. running mean: -33.244217\n",
      "ep 23: ep_len:500 episode reward: total was 28.300000. running mean: -32.628774\n",
      "ep 23: ep_len:500 episode reward: total was -11.690000. running mean: -32.419387\n",
      "ep 23: ep_len:625 episode reward: total was 24.770000. running mean: -31.847493\n",
      "ep 23: ep_len:590 episode reward: total was 10.300000. running mean: -31.426018\n",
      "ep 23: ep_len:730 episode reward: total was -4.650000. running mean: -31.158258\n",
      "ep 23: ep_len:500 episode reward: total was 9.190000. running mean: -30.754775\n",
      "ep 23: ep_len:725 episode reward: total was -0.620000. running mean: -30.453427\n",
      "ep 23: ep_len:500 episode reward: total was 16.820000. running mean: -29.980693\n",
      "ep 23: ep_len:105 episode reward: total was 3.500000. running mean: -29.645886\n",
      "ep 23: ep_len:985 episode reward: total was -10.010000. running mean: -29.449527\n",
      "ep 23: ep_len:500 episode reward: total was -2.690000. running mean: -29.181932\n",
      "ep 23: ep_len:500 episode reward: total was 17.890000. running mean: -28.711213\n",
      "ep 23: ep_len:780 episode reward: total was -17.680000. running mean: -28.600901\n",
      "ep 23: ep_len:500 episode reward: total was -8.500000. running mean: -28.399892\n",
      "ep 23: ep_len:500 episode reward: total was 22.300000. running mean: -27.892893\n",
      "ep 23: ep_len:500 episode reward: total was 19.850000. running mean: -27.415464\n",
      "ep 23: ep_len:510 episode reward: total was 8.610000. running mean: -27.055209\n",
      "ep 23: ep_len:905 episode reward: total was -31.050000. running mean: -27.095157\n",
      "ep 23: ep_len:595 episode reward: total was 11.500000. running mean: -26.709205\n",
      "ep 23: ep_len:500 episode reward: total was 0.400000. running mean: -26.438113\n",
      "ep 23: ep_len:500 episode reward: total was -9.290000. running mean: -26.266632\n",
      "ep 23: ep_len:655 episode reward: total was 9.810000. running mean: -25.905866\n",
      "ep 23: ep_len:890 episode reward: total was 23.980000. running mean: -25.407007\n",
      "ep 23: ep_len:655 episode reward: total was -53.280000. running mean: -25.685737\n",
      "ep 23: ep_len:560 episode reward: total was -15.580000. running mean: -25.584680\n",
      "ep 23: ep_len:500 episode reward: total was 42.500000. running mean: -24.903833\n",
      "ep 23: ep_len:625 episode reward: total was 21.450000. running mean: -24.440295\n",
      "ep 23: ep_len:700 episode reward: total was -15.300000. running mean: -24.348892\n",
      "ep 23: ep_len:500 episode reward: total was -1.060000. running mean: -24.116003\n",
      "ep 23: ep_len:505 episode reward: total was 19.710000. running mean: -23.677743\n",
      "ep 23: ep_len:510 episode reward: total was -16.290000. running mean: -23.603865\n",
      "ep 23: ep_len:675 episode reward: total was 2.350000. running mean: -23.344327\n",
      "ep 23: ep_len:500 episode reward: total was 5.330000. running mean: -23.057583\n",
      "ep 23: ep_len:925 episode reward: total was 6.280000. running mean: -22.764208\n",
      "ep 23: ep_len:945 episode reward: total was 20.010000. running mean: -22.336466\n",
      "ep 23: ep_len:840 episode reward: total was 16.110000. running mean: -21.952001\n",
      "ep 23: ep_len:500 episode reward: total was 18.290000. running mean: -21.549581\n",
      "ep 23: ep_len:500 episode reward: total was -8.400000. running mean: -21.418085\n",
      "ep 23: ep_len:145 episode reward: total was 11.500000. running mean: -21.088904\n",
      "ep 23: ep_len:500 episode reward: total was 9.160000. running mean: -20.786415\n",
      "ep 23: ep_len:770 episode reward: total was 0.490000. running mean: -20.573651\n",
      "ep 23: ep_len:500 episode reward: total was -27.450000. running mean: -20.642415\n",
      "ep 23: ep_len:600 episode reward: total was -7.580000. running mean: -20.511790\n",
      "ep 23: ep_len:760 episode reward: total was -16.610000. running mean: -20.472772\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 23: ep_len:1400 episode reward: total was -192.500000. running mean: -22.193045\n",
      "ep 23: ep_len:500 episode reward: total was 0.890000. running mean: -21.962214\n",
      "ep 23: ep_len:890 episode reward: total was 11.320000. running mean: -21.629392\n",
      "ep 23: ep_len:208 episode reward: total was 20.500000. running mean: -21.208098\n",
      "ep 23: ep_len:635 episode reward: total was -14.940000. running mean: -21.145417\n",
      "ep 23: ep_len:530 episode reward: total was -8.080000. running mean: -21.014763\n",
      "ep 23: ep_len:500 episode reward: total was -9.270000. running mean: -20.897315\n",
      "ep 23: ep_len:630 episode reward: total was -28.050000. running mean: -20.968842\n",
      "ep 23: ep_len:720 episode reward: total was -10.730000. running mean: -20.866454\n",
      "ep 23: ep_len:500 episode reward: total was 21.780000. running mean: -20.439989\n",
      "ep 23: ep_len:500 episode reward: total was -13.710000. running mean: -20.372689\n",
      "ep 23: ep_len:690 episode reward: total was 5.850000. running mean: -20.110463\n",
      "ep 23: ep_len:500 episode reward: total was -6.040000. running mean: -19.969758\n",
      "ep 23: ep_len:500 episode reward: total was 41.000000. running mean: -19.360060\n",
      "ep 23: ep_len:207 episode reward: total was 17.500000. running mean: -18.991460\n",
      "ep 23: ep_len:570 episode reward: total was -15.070000. running mean: -18.952245\n",
      "ep 23: ep_len:665 episode reward: total was -34.040000. running mean: -19.103123\n",
      "ep 23: ep_len:500 episode reward: total was 23.290000. running mean: -18.679191\n",
      "ep 23: ep_len:1385 episode reward: total was -156.500000. running mean: -20.057400\n",
      "ep 23: ep_len:500 episode reward: total was -2.660000. running mean: -19.883426\n",
      "ep 23: ep_len:126 episode reward: total was 11.000000. running mean: -19.574591\n",
      "ep 23: ep_len:794 episode reward: total was -135.810000. running mean: -20.736945\n",
      "ep 23: ep_len:650 episode reward: total was -6.800000. running mean: -20.597576\n",
      "ep 23: ep_len:212 episode reward: total was 17.000000. running mean: -20.221600\n",
      "ep 23: ep_len:645 episode reward: total was 25.410000. running mean: -19.765284\n",
      "ep 23: ep_len:560 episode reward: total was -44.380000. running mean: -20.011431\n",
      "ep 23: ep_len:660 episode reward: total was -5.770000. running mean: -19.869017\n",
      "ep 23: ep_len:489 episode reward: total was 42.500000. running mean: -19.245327\n",
      "ep 23: ep_len:590 episode reward: total was -21.090000. running mean: -19.263774\n",
      "ep 23: ep_len:500 episode reward: total was 16.300000. running mean: -18.908136\n",
      "ep 23: ep_len:500 episode reward: total was 2.240000. running mean: -18.696654\n",
      "ep 23: ep_len:1030 episode reward: total was -92.500000. running mean: -19.434688\n",
      "ep 23: ep_len:505 episode reward: total was -22.270000. running mean: -19.463041\n",
      "ep 23: ep_len:500 episode reward: total was 5.790000. running mean: -19.210511\n",
      "ep 23: ep_len:600 episode reward: total was -16.020000. running mean: -19.178606\n",
      "ep 23: ep_len:2352 episode reward: total was -320.550000. running mean: -22.192319\n",
      "ep 23: ep_len:500 episode reward: total was 7.790000. running mean: -21.892496\n",
      "ep 23: ep_len:955 episode reward: total was -10.400000. running mean: -21.777571\n",
      "ep 23: ep_len:449 episode reward: total was 23.230000. running mean: -21.327496\n",
      "ep 23: ep_len:1335 episode reward: total was -73.050000. running mean: -21.844721\n",
      "ep 23: ep_len:500 episode reward: total was 22.270000. running mean: -21.403573\n",
      "ep 23: ep_len:665 episode reward: total was 17.800000. running mean: -21.011538\n",
      "ep 23: ep_len:913 episode reward: total was -102.240000. running mean: -21.823822\n",
      "ep 23: ep_len:395 episode reward: total was 3.320000. running mean: -21.572384\n",
      "ep 23: ep_len:500 episode reward: total was -10.650000. running mean: -21.463160\n",
      "ep 23: ep_len:748 episode reward: total was -34.170000. running mean: -21.590229\n",
      "ep 23: ep_len:500 episode reward: total was -21.300000. running mean: -21.587326\n",
      "ep 23: ep_len:500 episode reward: total was 9.590000. running mean: -21.275553\n",
      "ep 23: ep_len:795 episode reward: total was 23.480000. running mean: -20.827998\n",
      "ep 23: ep_len:615 episode reward: total was -2.700000. running mean: -20.646718\n",
      "ep 23: ep_len:500 episode reward: total was -10.190000. running mean: -20.542150\n",
      "ep 23: ep_len:645 episode reward: total was 3.460000. running mean: -20.302129\n",
      "ep 23: ep_len:500 episode reward: total was 16.050000. running mean: -19.938608\n",
      "ep 23: ep_len:500 episode reward: total was -3.980000. running mean: -19.779022\n",
      "ep 23: ep_len:201 episode reward: total was 16.000000. running mean: -19.421231\n",
      "ep 23: ep_len:500 episode reward: total was 11.640000. running mean: -19.110619\n",
      "ep 23: ep_len:500 episode reward: total was -2.170000. running mean: -18.941213\n",
      "ep 23: ep_len:685 episode reward: total was -44.130000. running mean: -19.193101\n",
      "ep 23: ep_len:780 episode reward: total was -17.680000. running mean: -19.177970\n",
      "ep 23: ep_len:570 episode reward: total was -10.020000. running mean: -19.086390\n",
      "ep 23: ep_len:500 episode reward: total was 11.350000. running mean: -18.782026\n",
      "ep 23: ep_len:850 episode reward: total was -59.790000. running mean: -19.192106\n",
      "ep 23: ep_len:200 episode reward: total was 17.500000. running mean: -18.825185\n",
      "ep 23: ep_len:2035 episode reward: total was -197.960000. running mean: -20.616533\n",
      "ep 23: ep_len:500 episode reward: total was 5.040000. running mean: -20.359968\n",
      "ep 23: ep_len:467 episode reward: total was 14.760000. running mean: -20.008768\n",
      "ep 23: ep_len:1060 episode reward: total was 9.680000. running mean: -19.711880\n",
      "ep 23: ep_len:620 episode reward: total was -35.170000. running mean: -19.866461\n",
      "ep 23: ep_len:600 episode reward: total was 11.810000. running mean: -19.549697\n",
      "ep 23: ep_len:218 episode reward: total was 21.500000. running mean: -19.139200\n",
      "ep 23: ep_len:500 episode reward: total was 19.300000. running mean: -18.754808\n",
      "ep 23: ep_len:700 episode reward: total was -11.780000. running mean: -18.685060\n",
      "ep 23: ep_len:780 episode reward: total was -72.220000. running mean: -19.220409\n",
      "ep 23: ep_len:675 episode reward: total was -15.930000. running mean: -19.187505\n",
      "ep 23: ep_len:500 episode reward: total was 5.610000. running mean: -18.939530\n",
      "ep 23: ep_len:670 episode reward: total was -28.000000. running mean: -19.030135\n",
      "ep 23: ep_len:765 episode reward: total was -12.660000. running mean: -18.966433\n",
      "ep 23: ep_len:555 episode reward: total was -8.030000. running mean: -18.857069\n",
      "ep 23: ep_len:700 episode reward: total was -6.730000. running mean: -18.735798\n",
      "ep 23: ep_len:500 episode reward: total was 28.300000. running mean: -18.265440\n",
      "ep 23: ep_len:1055 episode reward: total was 17.230000. running mean: -17.910486\n",
      "ep 23: ep_len:505 episode reward: total was 15.510000. running mean: -17.576281\n",
      "ep 23: ep_len:845 episode reward: total was 4.420000. running mean: -17.356318\n",
      "ep 23: ep_len:500 episode reward: total was 19.790000. running mean: -16.984855\n",
      "ep 23: ep_len:500 episode reward: total was -14.230000. running mean: -16.957307\n",
      "ep 23: ep_len:515 episode reward: total was -13.220000. running mean: -16.919934\n",
      "ep 23: ep_len:500 episode reward: total was 26.830000. running mean: -16.482434\n",
      "ep 23: ep_len:469 episode reward: total was 17.330000. running mean: -16.144310\n",
      "ep 23: ep_len:617 episode reward: total was -84.670000. running mean: -16.829567\n",
      "ep 23: ep_len:535 episode reward: total was -31.330000. running mean: -16.974571\n",
      "ep 23: ep_len:850 episode reward: total was -1.260000. running mean: -16.817425\n",
      "ep 23: ep_len:500 episode reward: total was 1.840000. running mean: -16.630851\n",
      "ep 23: ep_len:500 episode reward: total was -23.860000. running mean: -16.703143\n",
      "ep 23: ep_len:2800 episode reward: total was -447.500000. running mean: -21.011111\n",
      "ep 23: ep_len:500 episode reward: total was -8.170000. running mean: -20.882700\n",
      "ep 23: ep_len:500 episode reward: total was 48.500000. running mean: -20.188873\n",
      "ep 23: ep_len:645 episode reward: total was -25.020000. running mean: -20.237184\n",
      "ep 23: ep_len:515 episode reward: total was -10.130000. running mean: -20.136112\n",
      "ep 23: ep_len:1330 episode reward: total was -57.990000. running mean: -20.514651\n",
      "ep 23: ep_len:500 episode reward: total was 9.530000. running mean: -20.214205\n",
      "ep 23: ep_len:500 episode reward: total was -18.910000. running mean: -20.201163\n",
      "ep 23: ep_len:500 episode reward: total was 11.090000. running mean: -19.888251\n",
      "epsilon:0.030962 episode_count: 18925. steps_count: 13560452.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 24: ep_len:500 episode reward: total was 3.110000. running mean: -19.658269\n",
      "ep 24: ep_len:805 episode reward: total was -17.630000. running mean: -19.637986\n",
      "ep 24: ep_len:545 episode reward: total was 11.980000. running mean: -19.321806\n",
      "ep 24: ep_len:945 episode reward: total was -61.610000. running mean: -19.744688\n",
      "ep 24: ep_len:500 episode reward: total was -1.770000. running mean: -19.564941\n",
      "ep 24: ep_len:500 episode reward: total was -6.330000. running mean: -19.432592\n",
      "ep 24: ep_len:750 episode reward: total was -143.990000. running mean: -20.678166\n",
      "ep 24: ep_len:505 episode reward: total was -16.700000. running mean: -20.638384\n",
      "ep 24: ep_len:800 episode reward: total was -30.770000. running mean: -20.739700\n",
      "ep 24: ep_len:1060 episode reward: total was -110.550000. running mean: -21.637803\n",
      "ep 24: ep_len:560 episode reward: total was 2.700000. running mean: -21.394425\n",
      "ep 24: ep_len:700 episode reward: total was -50.160000. running mean: -21.682081\n",
      "ep 24: ep_len:545 episode reward: total was -8.840000. running mean: -21.553660\n",
      "ep 24: ep_len:875 episode reward: total was -30.710000. running mean: -21.645224\n",
      "ep 24: ep_len:1065 episode reward: total was -16.640000. running mean: -21.595171\n",
      "ep 24: ep_len:641 episode reward: total was -90.190000. running mean: -22.281120\n",
      "ep 24: ep_len:669 episode reward: total was -64.060000. running mean: -22.698908\n",
      "ep 24: ep_len:550 episode reward: total was 4.580000. running mean: -22.426119\n",
      "ep 24: ep_len:830 episode reward: total was 8.360000. running mean: -22.118258\n",
      "ep 24: ep_len:500 episode reward: total was 15.500000. running mean: -21.742076\n",
      "ep 24: ep_len:1460 episode reward: total was -110.250000. running mean: -22.627155\n",
      "ep 24: ep_len:1245 episode reward: total was -12.450000. running mean: -22.525383\n",
      "ep 24: ep_len:1420 episode reward: total was -50.740000. running mean: -22.807529\n",
      "ep 24: ep_len:565 episode reward: total was 11.680000. running mean: -22.462654\n",
      "ep 24: ep_len:885 episode reward: total was -32.690000. running mean: -22.564928\n",
      "ep 24: ep_len:525 episode reward: total was -13.630000. running mean: -22.475578\n",
      "ep 24: ep_len:900 episode reward: total was 2.780000. running mean: -22.223023\n",
      "ep 24: ep_len:500 episode reward: total was 10.490000. running mean: -21.895892\n",
      "ep 24: ep_len:500 episode reward: total was 26.810000. running mean: -21.408833\n",
      "ep 24: ep_len:500 episode reward: total was -0.380000. running mean: -21.198545\n",
      "ep 24: ep_len:260 episode reward: total was 24.500000. running mean: -20.741560\n",
      "ep 24: ep_len:500 episode reward: total was 25.330000. running mean: -20.280844\n",
      "ep 24: ep_len:778 episode reward: total was -67.180000. running mean: -20.749836\n",
      "ep 24: ep_len:500 episode reward: total was -6.670000. running mean: -20.609037\n",
      "ep 24: ep_len:500 episode reward: total was -12.210000. running mean: -20.525047\n",
      "ep 24: ep_len:725 episode reward: total was -15.770000. running mean: -20.477496\n",
      "ep 24: ep_len:580 episode reward: total was -20.100000. running mean: -20.473721\n",
      "ep 24: ep_len:451 episode reward: total was 23.180000. running mean: -20.037184\n",
      "ep 24: ep_len:500 episode reward: total was 8.090000. running mean: -19.755912\n",
      "ep 24: ep_len:500 episode reward: total was 26.310000. running mean: -19.295253\n",
      "ep 24: ep_len:324 episode reward: total was 27.500000. running mean: -18.827301\n",
      "ep 24: ep_len:505 episode reward: total was -10.150000. running mean: -18.740528\n",
      "ep 24: ep_len:500 episode reward: total was 22.280000. running mean: -18.330322\n",
      "ep 24: ep_len:500 episode reward: total was 10.330000. running mean: -18.043719\n",
      "ep 24: ep_len:675 episode reward: total was -1.730000. running mean: -17.880582\n",
      "ep 24: ep_len:500 episode reward: total was 6.260000. running mean: -17.639176\n",
      "ep 24: ep_len:785 episode reward: total was -1.720000. running mean: -17.479984\n",
      "ep 24: ep_len:785 episode reward: total was -20.700000. running mean: -17.512185\n",
      "ep 24: ep_len:845 episode reward: total was 9.730000. running mean: -17.239763\n",
      "ep 24: ep_len:327 episode reward: total was 31.500000. running mean: -16.752365\n",
      "ep 24: ep_len:525 episode reward: total was -30.310000. running mean: -16.887941\n",
      "ep 24: ep_len:1260 episode reward: total was -215.710000. running mean: -18.876162\n",
      "ep 24: ep_len:765 episode reward: total was -0.310000. running mean: -18.690500\n",
      "ep 24: ep_len:695 episode reward: total was -13.810000. running mean: -18.641695\n",
      "ep 24: ep_len:127 episode reward: total was 10.000000. running mean: -18.355279\n",
      "ep 24: ep_len:805 episode reward: total was -8.630000. running mean: -18.258026\n",
      "ep 24: ep_len:925 episode reward: total was 15.660000. running mean: -17.918845\n",
      "ep 24: ep_len:500 episode reward: total was 6.600000. running mean: -17.673657\n",
      "ep 24: ep_len:1115 episode reward: total was -8.670000. running mean: -17.583620\n",
      "ep 24: ep_len:950 episode reward: total was 23.120000. running mean: -17.176584\n",
      "ep 24: ep_len:550 episode reward: total was -8.040000. running mean: -17.085218\n",
      "ep 24: ep_len:170 episode reward: total was 14.000000. running mean: -16.774366\n",
      "ep 24: ep_len:855 episode reward: total was -2.110000. running mean: -16.627723\n",
      "ep 24: ep_len:469 episode reward: total was -53.780000. running mean: -16.999245\n",
      "ep 24: ep_len:1280 episode reward: total was -55.050000. running mean: -17.379753\n",
      "ep 24: ep_len:605 episode reward: total was -20.540000. running mean: -17.411355\n",
      "ep 24: ep_len:500 episode reward: total was -14.290000. running mean: -17.380142\n",
      "ep 24: ep_len:895 episode reward: total was -0.390000. running mean: -17.210240\n",
      "ep 24: ep_len:710 episode reward: total was -3.680000. running mean: -17.074938\n",
      "ep 24: ep_len:750 episode reward: total was 6.270000. running mean: -16.841489\n",
      "ep 24: ep_len:635 episode reward: total was -8.880000. running mean: -16.761874\n",
      "ep 24: ep_len:500 episode reward: total was -3.570000. running mean: -16.629955\n",
      "ep 24: ep_len:535 episode reward: total was -28.270000. running mean: -16.746355\n",
      "ep 24: ep_len:515 episode reward: total was -8.110000. running mean: -16.659992\n",
      "ep 24: ep_len:585 episode reward: total was 38.820000. running mean: -16.105192\n",
      "ep 24: ep_len:500 episode reward: total was 14.550000. running mean: -15.798640\n",
      "ep 24: ep_len:670 episode reward: total was -10.830000. running mean: -15.748954\n",
      "ep 24: ep_len:1803 episode reward: total was -243.900000. running mean: -18.030464\n",
      "ep 24: ep_len:1068 episode reward: total was -198.890000. running mean: -19.839059\n",
      "ep 24: ep_len:840 episode reward: total was 14.650000. running mean: -19.494169\n",
      "ep 24: ep_len:108 episode reward: total was 10.500000. running mean: -19.194227\n",
      "ep 24: ep_len:500 episode reward: total was -1.160000. running mean: -19.013885\n",
      "ep 24: ep_len:960 episode reward: total was -23.110000. running mean: -19.054846\n",
      "ep 24: ep_len:715 episode reward: total was 2.000000. running mean: -18.844298\n",
      "ep 24: ep_len:500 episode reward: total was 10.450000. running mean: -18.551355\n",
      "ep 24: ep_len:1320 episode reward: total was -104.200000. running mean: -19.407841\n",
      "ep 24: ep_len:500 episode reward: total was 5.010000. running mean: -19.163663\n",
      "ep 24: ep_len:500 episode reward: total was -3.390000. running mean: -19.005926\n",
      "ep 24: ep_len:2020 episode reward: total was -278.790000. running mean: -21.603767\n",
      "ep 24: ep_len:530 episode reward: total was -22.220000. running mean: -21.609929\n",
      "ep 24: ep_len:530 episode reward: total was -104.000000. running mean: -22.433830\n",
      "ep 24: ep_len:575 episode reward: total was -75.660000. running mean: -22.966092\n",
      "ep 24: ep_len:885 episode reward: total was -65.490000. running mean: -23.391331\n",
      "ep 24: ep_len:500 episode reward: total was 3.710000. running mean: -23.120317\n",
      "ep 24: ep_len:500 episode reward: total was 19.730000. running mean: -22.691814\n",
      "ep 24: ep_len:895 episode reward: total was 5.630000. running mean: -22.408596\n",
      "ep 24: ep_len:675 episode reward: total was -8.800000. running mean: -22.272510\n",
      "ep 24: ep_len:555 episode reward: total was -8.700000. running mean: -22.136785\n",
      "ep 24: ep_len:140 episode reward: total was 12.500000. running mean: -21.790417\n",
      "ep 24: ep_len:655 episode reward: total was -98.730000. running mean: -22.559813\n",
      "ep 24: ep_len:555 episode reward: total was -60.080000. running mean: -22.935015\n",
      "ep 24: ep_len:505 episode reward: total was -43.970000. running mean: -23.145365\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 24: ep_len:299 episode reward: total was 28.000000. running mean: -22.633911\n",
      "ep 24: ep_len:940 episode reward: total was -1.580000. running mean: -22.423372\n",
      "ep 24: ep_len:655 episode reward: total was -6.820000. running mean: -22.267338\n",
      "ep 24: ep_len:500 episode reward: total was 10.210000. running mean: -21.942565\n",
      "ep 24: ep_len:500 episode reward: total was -19.640000. running mean: -21.919539\n",
      "ep 24: ep_len:500 episode reward: total was 20.310000. running mean: -21.497244\n",
      "ep 24: ep_len:5250 episode reward: total was -984.580000. running mean: -31.128071\n",
      "ep 24: ep_len:500 episode reward: total was 27.690000. running mean: -30.539891\n",
      "ep 24: ep_len:730 episode reward: total was -22.830000. running mean: -30.462792\n",
      "ep 24: ep_len:231 episode reward: total was 23.500000. running mean: -29.923164\n",
      "ep 24: ep_len:1040 episode reward: total was 1.980000. running mean: -29.604132\n",
      "ep 24: ep_len:735 episode reward: total was -30.900000. running mean: -29.617091\n",
      "ep 24: ep_len:500 episode reward: total was 13.450000. running mean: -29.186420\n",
      "ep 24: ep_len:910 episode reward: total was -95.190000. running mean: -29.846456\n",
      "ep 24: ep_len:500 episode reward: total was 26.830000. running mean: -29.279691\n",
      "ep 24: ep_len:500 episode reward: total was -19.310000. running mean: -29.179994\n",
      "ep 24: ep_len:1300 episode reward: total was -187.330000. running mean: -30.761494\n",
      "ep 24: ep_len:500 episode reward: total was -25.460000. running mean: -30.708479\n",
      "ep 24: ep_len:910 episode reward: total was 4.720000. running mean: -30.354195\n",
      "ep 24: ep_len:830 episode reward: total was -62.020000. running mean: -30.670853\n",
      "ep 24: ep_len:500 episode reward: total was 13.510000. running mean: -30.229044\n",
      "ep 24: ep_len:765 episode reward: total was -16.700000. running mean: -30.093754\n",
      "ep 24: ep_len:500 episode reward: total was 15.700000. running mean: -29.635816\n",
      "ep 24: ep_len:895 episode reward: total was -35.630000. running mean: -29.695758\n",
      "ep 24: ep_len:820 episode reward: total was -29.290000. running mean: -29.691700\n",
      "ep 24: ep_len:500 episode reward: total was 3.230000. running mean: -29.362483\n",
      "ep 24: ep_len:500 episode reward: total was 18.320000. running mean: -28.885659\n",
      "ep 24: ep_len:2140 episode reward: total was -260.390000. running mean: -31.200702\n",
      "ep 24: ep_len:2524 episode reward: total was -323.290000. running mean: -34.121595\n",
      "ep 24: ep_len:860 episode reward: total was -49.320000. running mean: -34.273579\n",
      "ep 24: ep_len:610 episode reward: total was -17.610000. running mean: -34.106943\n",
      "ep 24: ep_len:510 episode reward: total was -13.170000. running mean: -33.897574\n",
      "ep 24: ep_len:500 episode reward: total was 44.000000. running mean: -33.118598\n",
      "ep 24: ep_len:500 episode reward: total was 12.170000. running mean: -32.665712\n",
      "ep 24: ep_len:505 episode reward: total was 13.710000. running mean: -32.201955\n",
      "ep 24: ep_len:1700 episode reward: total was -154.350000. running mean: -33.423435\n",
      "ep 24: ep_len:505 episode reward: total was -25.300000. running mean: -33.342201\n",
      "ep 24: ep_len:500 episode reward: total was 22.150000. running mean: -32.787279\n",
      "ep 24: ep_len:525 episode reward: total was -28.260000. running mean: -32.742006\n",
      "ep 24: ep_len:685 episode reward: total was -40.090000. running mean: -32.815486\n",
      "ep 24: ep_len:1015 episode reward: total was -2.010000. running mean: -32.507431\n",
      "ep 24: ep_len:500 episode reward: total was -1.350000. running mean: -32.195857\n",
      "ep 24: ep_len:500 episode reward: total was -20.780000. running mean: -32.081698\n",
      "ep 24: ep_len:820 episode reward: total was -19.580000. running mean: -31.956681\n",
      "ep 24: ep_len:500 episode reward: total was -49.550000. running mean: -32.132615\n",
      "ep 24: ep_len:500 episode reward: total was 4.660000. running mean: -31.764688\n",
      "ep 24: ep_len:500 episode reward: total was 4.540000. running mean: -31.401642\n",
      "ep 24: ep_len:500 episode reward: total was 20.800000. running mean: -30.879625\n",
      "ep 24: ep_len:500 episode reward: total was 23.960000. running mean: -30.331229\n",
      "ep 24: ep_len:500 episode reward: total was -8.750000. running mean: -30.115417\n",
      "ep 24: ep_len:735 episode reward: total was -14.280000. running mean: -29.957062\n",
      "ep 24: ep_len:675 episode reward: total was -8.520000. running mean: -29.742692\n",
      "ep 24: ep_len:1514 episode reward: total was -237.770000. running mean: -31.822965\n",
      "ep 24: ep_len:920 episode reward: total was 11.530000. running mean: -31.389435\n",
      "ep 24: ep_len:500 episode reward: total was 11.950000. running mean: -30.956041\n",
      "ep 24: ep_len:615 episode reward: total was -30.130000. running mean: -30.947780\n",
      "ep 24: ep_len:695 episode reward: total was -30.980000. running mean: -30.948103\n",
      "ep 24: ep_len:550 episode reward: total was -44.400000. running mean: -31.082622\n",
      "ep 24: ep_len:497 episode reward: total was 20.150000. running mean: -30.570295\n",
      "ep 24: ep_len:725 episode reward: total was -50.170000. running mean: -30.766292\n",
      "ep 24: ep_len:650 episode reward: total was -13.900000. running mean: -30.597630\n",
      "ep 24: ep_len:733 episode reward: total was -57.690000. running mean: -30.868553\n",
      "ep 24: ep_len:750 episode reward: total was -32.890000. running mean: -30.888768\n",
      "ep 24: ep_len:500 episode reward: total was 7.520000. running mean: -30.504680\n",
      "ep 24: ep_len:540 episode reward: total was 3.710000. running mean: -30.162533\n",
      "ep 24: ep_len:745 episode reward: total was -36.510000. running mean: -30.226008\n",
      "ep 24: ep_len:191 episode reward: total was 16.000000. running mean: -29.763748\n",
      "ep 24: ep_len:1085 episode reward: total was -24.220000. running mean: -29.708310\n",
      "ep 24: ep_len:570 episode reward: total was 30.800000. running mean: -29.103227\n",
      "ep 24: ep_len:130 episode reward: total was 10.000000. running mean: -28.712195\n",
      "ep 24: ep_len:665 episode reward: total was -4.980000. running mean: -28.474873\n",
      "ep 24: ep_len:500 episode reward: total was 27.810000. running mean: -27.912024\n",
      "ep 24: ep_len:500 episode reward: total was 50.000000. running mean: -27.132904\n",
      "ep 24: ep_len:525 episode reward: total was -34.350000. running mean: -27.205075\n",
      "ep 24: ep_len:500 episode reward: total was 0.310000. running mean: -26.929924\n",
      "ep 24: ep_len:850 episode reward: total was -27.440000. running mean: -26.935025\n",
      "ep 24: ep_len:540 episode reward: total was -37.300000. running mean: -27.038675\n",
      "ep 24: ep_len:505 episode reward: total was -20.830000. running mean: -26.976588\n",
      "ep 24: ep_len:500 episode reward: total was 24.760000. running mean: -26.459222\n",
      "ep 24: ep_len:605 episode reward: total was -9.920000. running mean: -26.293830\n",
      "ep 24: ep_len:545 episode reward: total was -18.760000. running mean: -26.218492\n",
      "ep 24: ep_len:600 episode reward: total was -13.200000. running mean: -26.088307\n",
      "ep 24: ep_len:500 episode reward: total was -1.160000. running mean: -25.839024\n",
      "ep 24: ep_len:580 episode reward: total was -31.210000. running mean: -25.892733\n",
      "ep 24: ep_len:700 episode reward: total was -7.740000. running mean: -25.711206\n",
      "ep 24: ep_len:830 episode reward: total was -20.910000. running mean: -25.663194\n",
      "ep 24: ep_len:1374 episode reward: total was -182.120000. running mean: -27.227762\n",
      "ep 24: ep_len:500 episode reward: total was 21.500000. running mean: -26.740484\n",
      "ep 24: ep_len:1765 episode reward: total was -271.240000. running mean: -29.185480\n",
      "ep 24: ep_len:500 episode reward: total was 13.730000. running mean: -28.756325\n",
      "ep 24: ep_len:500 episode reward: total was 13.670000. running mean: -28.332062\n",
      "ep 24: ep_len:775 episode reward: total was -6.270000. running mean: -28.111441\n",
      "ep 24: ep_len:925 episode reward: total was -7.310000. running mean: -27.903427\n",
      "ep 24: ep_len:870 episode reward: total was 11.600000. running mean: -27.508392\n",
      "ep 24: ep_len:850 episode reward: total was -11.640000. running mean: -27.349708\n",
      "ep 24: ep_len:650 episode reward: total was -15.240000. running mean: -27.228611\n",
      "ep 24: ep_len:595 episode reward: total was 11.220000. running mean: -26.844125\n",
      "ep 24: ep_len:720 episode reward: total was -9.180000. running mean: -26.667484\n",
      "ep 24: ep_len:780 episode reward: total was -26.770000. running mean: -26.668509\n",
      "ep 24: ep_len:980 episode reward: total was -23.560000. running mean: -26.637424\n",
      "ep 24: ep_len:822 episode reward: total was -98.710000. running mean: -27.358150\n",
      "ep 24: ep_len:500 episode reward: total was 18.390000. running mean: -26.900668\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 24: ep_len:500 episode reward: total was 15.140000. running mean: -26.480262\n",
      "ep 24: ep_len:865 episode reward: total was -81.140000. running mean: -27.026859\n",
      "ep 24: ep_len:500 episode reward: total was 16.970000. running mean: -26.586890\n",
      "ep 24: ep_len:680 episode reward: total was -10.810000. running mean: -26.429121\n",
      "ep 24: ep_len:780 episode reward: total was -4.300000. running mean: -26.207830\n",
      "ep 24: ep_len:500 episode reward: total was 4.450000. running mean: -25.901252\n",
      "ep 24: ep_len:695 episode reward: total was -33.000000. running mean: -25.972239\n",
      "ep 24: ep_len:535 episode reward: total was -45.440000. running mean: -26.166917\n",
      "ep 24: ep_len:560 episode reward: total was -10.040000. running mean: -26.005648\n",
      "ep 24: ep_len:765 episode reward: total was -30.840000. running mean: -26.053991\n",
      "ep 24: ep_len:730 episode reward: total was -12.730000. running mean: -25.920751\n",
      "ep 24: ep_len:500 episode reward: total was 17.900000. running mean: -25.482544\n",
      "ep 24: ep_len:910 episode reward: total was 2.120000. running mean: -25.206518\n",
      "ep 24: ep_len:500 episode reward: total was -19.000000. running mean: -25.144453\n",
      "ep 24: ep_len:500 episode reward: total was 20.680000. running mean: -24.686209\n",
      "ep 24: ep_len:650 episode reward: total was -32.080000. running mean: -24.760147\n",
      "ep 24: ep_len:500 episode reward: total was 2.220000. running mean: -24.490345\n",
      "ep 24: ep_len:489 episode reward: total was 25.760000. running mean: -23.987842\n",
      "ep 24: ep_len:500 episode reward: total was 22.760000. running mean: -23.520363\n",
      "ep 24: ep_len:500 episode reward: total was -6.180000. running mean: -23.346960\n",
      "ep 24: ep_len:555 episode reward: total was 9.160000. running mean: -23.021890\n",
      "ep 24: ep_len:1005 episode reward: total was -18.780000. running mean: -22.979471\n",
      "ep 24: ep_len:500 episode reward: total was 26.710000. running mean: -22.482577\n",
      "ep 24: ep_len:590 episode reward: total was -53.410000. running mean: -22.791851\n",
      "ep 24: ep_len:535 episode reward: total was -8.460000. running mean: -22.648532\n",
      "ep 24: ep_len:525 episode reward: total was -13.140000. running mean: -22.553447\n",
      "ep 24: ep_len:1280 episode reward: total was -103.540000. running mean: -23.363312\n",
      "ep 24: ep_len:500 episode reward: total was 19.730000. running mean: -22.932379\n",
      "ep 24: ep_len:675 episode reward: total was -11.830000. running mean: -22.821356\n",
      "ep 24: ep_len:720 episode reward: total was -9.720000. running mean: -22.690342\n",
      "ep 24: ep_len:500 episode reward: total was 8.030000. running mean: -22.383139\n",
      "ep 24: ep_len:500 episode reward: total was -0.250000. running mean: -22.161807\n",
      "ep 24: ep_len:695 episode reward: total was -7.750000. running mean: -22.017689\n",
      "ep 24: ep_len:500 episode reward: total was 15.910000. running mean: -21.638412\n",
      "ep 24: ep_len:188 episode reward: total was 17.500000. running mean: -21.247028\n",
      "ep 24: ep_len:164 episode reward: total was 15.000000. running mean: -20.884558\n",
      "ep 24: ep_len:500 episode reward: total was 14.800000. running mean: -20.527712\n",
      "ep 24: ep_len:545 episode reward: total was -6.030000. running mean: -20.382735\n",
      "ep 24: ep_len:500 episode reward: total was 16.280000. running mean: -20.016108\n",
      "ep 24: ep_len:376 episode reward: total was 13.170000. running mean: -19.684247\n",
      "ep 24: ep_len:500 episode reward: total was 30.260000. running mean: -19.184804\n",
      "ep 24: ep_len:33 episode reward: total was 1.500000. running mean: -18.977956\n",
      "ep 24: ep_len:500 episode reward: total was 14.280000. running mean: -18.645377\n",
      "ep 24: ep_len:1345 episode reward: total was -180.630000. running mean: -20.265223\n",
      "ep 24: ep_len:500 episode reward: total was -0.240000. running mean: -20.064971\n",
      "ep 24: ep_len:1405 episode reward: total was -33.640000. running mean: -20.200721\n",
      "ep 24: ep_len:600 episode reward: total was -5.920000. running mean: -20.057914\n",
      "ep 24: ep_len:277 episode reward: total was 27.500000. running mean: -19.582335\n",
      "ep 24: ep_len:825 episode reward: total was -25.860000. running mean: -19.645111\n",
      "ep 24: ep_len:695 episode reward: total was -29.970000. running mean: -19.748360\n",
      "ep 24: ep_len:990 episode reward: total was 26.750000. running mean: -19.283376\n",
      "ep 24: ep_len:825 episode reward: total was -26.770000. running mean: -19.358243\n",
      "ep 24: ep_len:500 episode reward: total was -2.470000. running mean: -19.189360\n",
      "ep 24: ep_len:525 episode reward: total was -16.170000. running mean: -19.159167\n",
      "ep 24: ep_len:500 episode reward: total was 7.210000. running mean: -18.895475\n",
      "ep 24: ep_len:164 episode reward: total was 16.500000. running mean: -18.541520\n",
      "ep 24: ep_len:565 episode reward: total was -1.950000. running mean: -18.375605\n",
      "ep 24: ep_len:600 episode reward: total was -1.880000. running mean: -18.210649\n",
      "ep 24: ep_len:630 episode reward: total was -20.440000. running mean: -18.232943\n",
      "ep 24: ep_len:500 episode reward: total was -0.170000. running mean: -18.052313\n",
      "ep 24: ep_len:835 episode reward: total was 7.000000. running mean: -17.801790\n",
      "ep 24: ep_len:500 episode reward: total was 45.500000. running mean: -17.168772\n",
      "ep 24: ep_len:500 episode reward: total was -4.310000. running mean: -17.040184\n",
      "ep 24: ep_len:166 episode reward: total was 15.000000. running mean: -16.719783\n",
      "ep 24: ep_len:605 episode reward: total was -21.060000. running mean: -16.763185\n",
      "ep 24: ep_len:500 episode reward: total was 25.390000. running mean: -16.341653\n",
      "ep 24: ep_len:500 episode reward: total was 10.760000. running mean: -16.070636\n",
      "ep 24: ep_len:965 episode reward: total was 12.790000. running mean: -15.782030\n",
      "ep 24: ep_len:500 episode reward: total was -10.670000. running mean: -15.730910\n",
      "ep 24: ep_len:1195 episode reward: total was -140.070000. running mean: -16.974301\n",
      "ep 24: ep_len:500 episode reward: total was 30.840000. running mean: -16.496158\n",
      "ep 24: ep_len:705 episode reward: total was 14.630000. running mean: -16.184896\n",
      "ep 24: ep_len:500 episode reward: total was 7.300000. running mean: -15.950047\n",
      "ep 24: ep_len:275 episode reward: total was 16.550000. running mean: -15.625047\n",
      "ep 24: ep_len:219 episode reward: total was 18.500000. running mean: -15.283796\n",
      "ep 24: ep_len:625 episode reward: total was -21.020000. running mean: -15.341158\n",
      "ep 24: ep_len:1065 episode reward: total was -77.680000. running mean: -15.964547\n",
      "ep 24: ep_len:515 episode reward: total was -17.200000. running mean: -15.976901\n",
      "ep 24: ep_len:447 episode reward: total was 8.990000. running mean: -15.727232\n",
      "ep 24: ep_len:530 episode reward: total was -21.180000. running mean: -15.781760\n",
      "ep 24: ep_len:915 episode reward: total was -22.270000. running mean: -15.846642\n",
      "ep 24: ep_len:1630 episode reward: total was -57.530000. running mean: -16.263476\n",
      "ep 24: ep_len:690 episode reward: total was -12.290000. running mean: -16.223741\n",
      "ep 24: ep_len:500 episode reward: total was 47.000000. running mean: -15.591504\n",
      "ep 24: ep_len:500 episode reward: total was 15.960000. running mean: -15.275989\n",
      "ep 24: ep_len:600 episode reward: total was 7.800000. running mean: -15.045229\n",
      "ep 24: ep_len:695 episode reward: total was -13.040000. running mean: -15.025176\n",
      "ep 24: ep_len:955 episode reward: total was 12.340000. running mean: -14.751525\n",
      "ep 24: ep_len:304 episode reward: total was 27.000000. running mean: -14.334009\n",
      "ep 24: ep_len:985 episode reward: total was -29.390000. running mean: -14.484569\n",
      "ep 24: ep_len:515 episode reward: total was -18.180000. running mean: -14.521524\n",
      "ep 24: ep_len:500 episode reward: total was -21.330000. running mean: -14.589608\n",
      "ep 24: ep_len:500 episode reward: total was 27.810000. running mean: -14.165612\n",
      "ep 24: ep_len:500 episode reward: total was 12.560000. running mean: -13.898356\n",
      "ep 24: ep_len:875 episode reward: total was -27.430000. running mean: -14.033673\n",
      "ep 24: ep_len:500 episode reward: total was 24.750000. running mean: -13.645836\n",
      "ep 24: ep_len:500 episode reward: total was 3.130000. running mean: -13.478077\n",
      "ep 24: ep_len:635 episode reward: total was -24.030000. running mean: -13.583597\n",
      "ep 24: ep_len:268 episode reward: total was 22.500000. running mean: -13.222761\n",
      "ep 24: ep_len:257 episode reward: total was 17.000000. running mean: -12.920533\n",
      "ep 24: ep_len:500 episode reward: total was -1.370000. running mean: -12.805028\n",
      "ep 24: ep_len:1085 episode reward: total was -113.570000. running mean: -13.812678\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 24: ep_len:555 episode reward: total was -7.020000. running mean: -13.744751\n",
      "ep 24: ep_len:515 episode reward: total was -10.130000. running mean: -13.708603\n",
      "ep 24: ep_len:800 episode reward: total was 9.670000. running mean: -13.474817\n",
      "ep 24: ep_len:500 episode reward: total was 47.000000. running mean: -12.870069\n",
      "ep 24: ep_len:500 episode reward: total was 24.290000. running mean: -12.498468\n",
      "ep 24: ep_len:255 episode reward: total was 21.000000. running mean: -12.163484\n",
      "ep 24: ep_len:700 episode reward: total was -21.750000. running mean: -12.259349\n",
      "ep 24: ep_len:435 episode reward: total was 12.280000. running mean: -12.013955\n",
      "ep 24: ep_len:775 episode reward: total was -26.780000. running mean: -12.161616\n",
      "ep 24: ep_len:720 episode reward: total was -1.140000. running mean: -12.051400\n",
      "ep 24: ep_len:505 episode reward: total was 2.720000. running mean: -11.903686\n",
      "ep 24: ep_len:525 episode reward: total was -12.130000. running mean: -11.905949\n",
      "ep 24: ep_len:950 episode reward: total was -22.750000. running mean: -12.014389\n",
      "ep 24: ep_len:500 episode reward: total was 18.230000. running mean: -11.711945\n",
      "ep 24: ep_len:545 episode reward: total was -9.060000. running mean: -11.685426\n",
      "ep 24: ep_len:570 episode reward: total was -24.160000. running mean: -11.810172\n",
      "ep 24: ep_len:960 episode reward: total was -98.120000. running mean: -12.673270\n",
      "ep 24: ep_len:615 episode reward: total was -39.210000. running mean: -12.938637\n",
      "ep 24: ep_len:980 episode reward: total was -21.320000. running mean: -13.022451\n",
      "ep 24: ep_len:675 episode reward: total was 8.320000. running mean: -12.809026\n",
      "ep 24: ep_len:655 episode reward: total was -16.920000. running mean: -12.850136\n",
      "ep 24: ep_len:540 episode reward: total was -14.120000. running mean: -12.862835\n",
      "ep 24: ep_len:685 episode reward: total was -4.710000. running mean: -12.781306\n",
      "ep 24: ep_len:730 episode reward: total was -8.690000. running mean: -12.740393\n",
      "ep 24: ep_len:500 episode reward: total was 29.280000. running mean: -12.320189\n",
      "ep 24: ep_len:520 episode reward: total was -3.050000. running mean: -12.227488\n",
      "ep 24: ep_len:500 episode reward: total was 3.340000. running mean: -12.071813\n",
      "ep 24: ep_len:317 episode reward: total was 9.770000. running mean: -11.853395\n",
      "ep 24: ep_len:163 episode reward: total was 15.000000. running mean: -11.584861\n",
      "ep 24: ep_len:1020 episode reward: total was -105.070000. running mean: -12.519712\n",
      "ep 24: ep_len:910 episode reward: total was -38.630000. running mean: -12.780815\n",
      "ep 24: ep_len:9978 episode reward: total was -1850.620000. running mean: -31.159207\n",
      "ep 24: ep_len:213 episode reward: total was 21.500000. running mean: -30.632615\n",
      "ep 24: ep_len:500 episode reward: total was -2.740000. running mean: -30.353688\n",
      "ep 24: ep_len:710 episode reward: total was -20.850000. running mean: -30.258652\n",
      "ep 24: ep_len:790 episode reward: total was -56.040000. running mean: -30.516465\n",
      "ep 24: ep_len:970 episode reward: total was -25.880000. running mean: -30.470100\n",
      "ep 24: ep_len:805 episode reward: total was -47.730000. running mean: -30.642699\n",
      "ep 24: ep_len:224 episode reward: total was 18.000000. running mean: -30.156272\n",
      "ep 24: ep_len:500 episode reward: total was 6.290000. running mean: -29.791810\n",
      "ep 24: ep_len:590 episode reward: total was -18.100000. running mean: -29.674892\n",
      "ep 24: ep_len:500 episode reward: total was -9.120000. running mean: -29.469343\n",
      "ep 24: ep_len:18145 episode reward: total was -3433.410000. running mean: -63.508749\n",
      "ep 24: ep_len:965 episode reward: total was -11.080000. running mean: -62.984462\n",
      "ep 24: ep_len:675 episode reward: total was -9.810000. running mean: -62.452717\n",
      "ep 24: ep_len:510 episode reward: total was -14.180000. running mean: -61.969990\n",
      "ep 24: ep_len:620 episode reward: total was -27.090000. running mean: -61.621190\n",
      "ep 24: ep_len:500 episode reward: total was -8.320000. running mean: -61.088178\n",
      "ep 24: ep_len:2650 episode reward: total was -443.480000. running mean: -64.912096\n",
      "ep 24: ep_len:580 episode reward: total was 4.640000. running mean: -64.216575\n",
      "ep 24: ep_len:645 episode reward: total was -42.190000. running mean: -63.996310\n",
      "ep 24: ep_len:500 episode reward: total was 23.740000. running mean: -63.118947\n",
      "ep 24: ep_len:500 episode reward: total was -3.260000. running mean: -62.520357\n",
      "ep 24: ep_len:505 episode reward: total was -7.480000. running mean: -61.969954\n",
      "ep 24: ep_len:680 episode reward: total was 13.600000. running mean: -61.214254\n",
      "ep 24: ep_len:205 episode reward: total was 19.000000. running mean: -60.412111\n",
      "ep 24: ep_len:775 episode reward: total was -29.360000. running mean: -60.101590\n",
      "ep 24: ep_len:500 episode reward: total was -55.150000. running mean: -60.052074\n",
      "ep 24: ep_len:500 episode reward: total was 11.620000. running mean: -59.335354\n",
      "ep 24: ep_len:1040 episode reward: total was -71.090000. running mean: -59.452900\n",
      "ep 24: ep_len:675 episode reward: total was -72.430000. running mean: -59.582671\n",
      "ep 24: ep_len:860 episode reward: total was -93.270000. running mean: -59.919544\n",
      "ep 24: ep_len:585 episode reward: total was -55.440000. running mean: -59.874749\n",
      "ep 24: ep_len:500 episode reward: total was -6.380000. running mean: -59.339802\n",
      "ep 24: ep_len:530 episode reward: total was -67.640000. running mean: -59.422804\n",
      "ep 24: ep_len:327 episode reward: total was 31.000000. running mean: -58.518575\n",
      "ep 24: ep_len:500 episode reward: total was 6.200000. running mean: -57.871390\n",
      "ep 24: ep_len:755 episode reward: total was -76.310000. running mean: -58.055776\n",
      "ep 24: ep_len:500 episode reward: total was 50.000000. running mean: -56.975218\n",
      "ep 24: ep_len:500 episode reward: total was -12.020000. running mean: -56.525666\n",
      "ep 24: ep_len:505 episode reward: total was -19.300000. running mean: -56.153409\n",
      "ep 24: ep_len:500 episode reward: total was 15.230000. running mean: -55.439575\n",
      "ep 24: ep_len:500 episode reward: total was 17.280000. running mean: -54.712379\n",
      "ep 24: ep_len:1450 episode reward: total was -125.420000. running mean: -55.419456\n",
      "ep 24: ep_len:500 episode reward: total was 14.110000. running mean: -54.724161\n",
      "ep 24: ep_len:960 episode reward: total was -32.640000. running mean: -54.503319\n",
      "ep 24: ep_len:855 episode reward: total was -17.090000. running mean: -54.129186\n",
      "ep 24: ep_len:500 episode reward: total was 47.000000. running mean: -53.117894\n",
      "ep 24: ep_len:1145 episode reward: total was -111.430000. running mean: -53.701015\n",
      "ep 24: ep_len:500 episode reward: total was 15.720000. running mean: -53.006805\n",
      "ep 24: ep_len:1460 episode reward: total was -93.570000. running mean: -53.412437\n",
      "ep 24: ep_len:250 episode reward: total was 21.000000. running mean: -52.668313\n",
      "ep 24: ep_len:915 episode reward: total was -23.270000. running mean: -52.374330\n",
      "ep 24: ep_len:925 episode reward: total was -52.740000. running mean: -52.377986\n",
      "ep 24: ep_len:500 episode reward: total was 19.300000. running mean: -51.661207\n",
      "ep 24: ep_len:565 episode reward: total was 24.270000. running mean: -50.901894\n",
      "ep 24: ep_len:985 episode reward: total was -19.110000. running mean: -50.583976\n",
      "ep 24: ep_len:228 episode reward: total was 21.000000. running mean: -49.868136\n",
      "ep 24: ep_len:730 episode reward: total was -18.790000. running mean: -49.557354\n",
      "ep 24: ep_len:765 episode reward: total was -20.740000. running mean: -49.269181\n",
      "ep 24: ep_len:1030 episode reward: total was 17.730000. running mean: -48.599189\n",
      "ep 24: ep_len:645 episode reward: total was -7.500000. running mean: -48.188197\n",
      "ep 24: ep_len:500 episode reward: total was -0.240000. running mean: -47.708715\n",
      "ep 24: ep_len:1030 episode reward: total was -27.730000. running mean: -47.508928\n",
      "ep 24: ep_len:500 episode reward: total was 24.780000. running mean: -46.786039\n",
      "ep 24: ep_len:2113 episode reward: total was -195.330000. running mean: -48.271478\n",
      "ep 24: ep_len:1000 episode reward: total was -39.460000. running mean: -48.183364\n",
      "ep 24: ep_len:540 episode reward: total was 21.530000. running mean: -47.486230\n",
      "ep 24: ep_len:277 episode reward: total was 27.500000. running mean: -46.736368\n",
      "ep 24: ep_len:810 episode reward: total was -19.640000. running mean: -46.465404\n",
      "ep 24: ep_len:680 episode reward: total was -3.740000. running mean: -46.038150\n",
      "ep 24: ep_len:500 episode reward: total was 2.120000. running mean: -45.556568\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 24: ep_len:192 episode reward: total was 16.000000. running mean: -44.941003\n",
      "ep 24: ep_len:600 episode reward: total was -6.190000. running mean: -44.553493\n",
      "ep 24: ep_len:500 episode reward: total was -3.670000. running mean: -44.144658\n",
      "ep 24: ep_len:430 episode reward: total was -44.150000. running mean: -44.144711\n",
      "ep 24: ep_len:241 episode reward: total was 23.000000. running mean: -43.473264\n",
      "ep 24: ep_len:500 episode reward: total was 3.740000. running mean: -43.001131\n",
      "ep 24: ep_len:980 episode reward: total was -108.180000. running mean: -43.652920\n",
      "ep 24: ep_len:1515 episode reward: total was -229.320000. running mean: -45.509591\n",
      "ep 24: ep_len:500 episode reward: total was 8.190000. running mean: -44.972595\n",
      "ep 24: ep_len:1021 episode reward: total was -103.030000. running mean: -45.553169\n",
      "ep 24: ep_len:1065 episode reward: total was -31.930000. running mean: -45.416937\n",
      "ep 24: ep_len:500 episode reward: total was 20.830000. running mean: -44.754468\n",
      "ep 24: ep_len:1210 episode reward: total was 1.070000. running mean: -44.296223\n",
      "ep 24: ep_len:1095 episode reward: total was 5.410000. running mean: -43.799161\n",
      "ep 24: ep_len:505 episode reward: total was -10.150000. running mean: -43.462670\n",
      "ep 24: ep_len:630 episode reward: total was 24.980000. running mean: -42.778243\n",
      "ep 24: ep_len:662 episode reward: total was -32.740000. running mean: -42.677860\n",
      "ep 24: ep_len:209 episode reward: total was 19.000000. running mean: -42.061082\n",
      "ep 24: ep_len:885 episode reward: total was 6.750000. running mean: -41.572971\n",
      "ep 24: ep_len:830 episode reward: total was -20.140000. running mean: -41.358641\n",
      "ep 24: ep_len:219 episode reward: total was 22.500000. running mean: -40.720055\n",
      "ep 24: ep_len:720 episode reward: total was 14.080000. running mean: -40.172054\n",
      "ep 24: ep_len:1062 episode reward: total was -88.810000. running mean: -40.658434\n",
      "ep 24: ep_len:840 episode reward: total was -23.620000. running mean: -40.488049\n",
      "ep 24: ep_len:570 episode reward: total was 12.490000. running mean: -39.958269\n",
      "ep 24: ep_len:815 episode reward: total was -3.910000. running mean: -39.597786\n",
      "ep 24: ep_len:950 episode reward: total was 11.210000. running mean: -39.089708\n",
      "ep 24: ep_len:955 episode reward: total was -8.160000. running mean: -38.780411\n",
      "ep 24: ep_len:760 episode reward: total was -5.600000. running mean: -38.448607\n",
      "ep 24: ep_len:500 episode reward: total was 19.130000. running mean: -37.872821\n",
      "ep 24: ep_len:615 episode reward: total was -25.710000. running mean: -37.751193\n",
      "ep 24: ep_len:520 episode reward: total was -99.980000. running mean: -38.373481\n",
      "ep 24: ep_len:500 episode reward: total was 16.210000. running mean: -37.827646\n",
      "ep 24: ep_len:500 episode reward: total was 6.620000. running mean: -37.383170\n",
      "ep 24: ep_len:680 episode reward: total was -2.730000. running mean: -37.036638\n",
      "ep 24: ep_len:500 episode reward: total was 4.640000. running mean: -36.619872\n",
      "ep 24: ep_len:500 episode reward: total was 17.740000. running mean: -36.076273\n",
      "ep 24: ep_len:500 episode reward: total was 10.730000. running mean: -35.608210\n",
      "ep 24: ep_len:550 episode reward: total was -23.190000. running mean: -35.484028\n",
      "ep 24: ep_len:500 episode reward: total was 4.180000. running mean: -35.087388\n",
      "ep 24: ep_len:670 episode reward: total was -1.740000. running mean: -34.753914\n",
      "ep 24: ep_len:640 episode reward: total was 24.790000. running mean: -34.158475\n",
      "ep 24: ep_len:220 episode reward: total was 20.500000. running mean: -33.611890\n",
      "ep 24: ep_len:500 episode reward: total was 8.490000. running mean: -33.190871\n",
      "ep 24: ep_len:685 episode reward: total was -3.730000. running mean: -32.896262\n",
      "ep 24: ep_len:500 episode reward: total was 16.630000. running mean: -32.401000\n",
      "ep 24: ep_len:920 episode reward: total was -18.410000. running mean: -32.261090\n",
      "ep 24: ep_len:530 episode reward: total was -14.140000. running mean: -32.079879\n",
      "ep 24: ep_len:675 episode reward: total was 2.900000. running mean: -31.730080\n",
      "ep 24: ep_len:900 episode reward: total was -128.230000. running mean: -32.695079\n",
      "ep 24: ep_len:213 episode reward: total was 19.500000. running mean: -32.173129\n",
      "ep 24: ep_len:605 episode reward: total was 20.580000. running mean: -31.645597\n",
      "ep 24: ep_len:500 episode reward: total was -7.220000. running mean: -31.401341\n",
      "ep 24: ep_len:660 episode reward: total was -4.900000. running mean: -31.136328\n",
      "ep 24: ep_len:500 episode reward: total was 25.300000. running mean: -30.571965\n",
      "ep 24: ep_len:960 episode reward: total was -41.040000. running mean: -30.676645\n",
      "ep 24: ep_len:1090 episode reward: total was -151.810000. running mean: -31.887978\n",
      "ep 24: ep_len:1458 episode reward: total was -205.450000. running mean: -33.623599\n",
      "ep 24: ep_len:500 episode reward: total was -17.780000. running mean: -33.465163\n",
      "ep 24: ep_len:955 episode reward: total was 5.620000. running mean: -33.074311\n",
      "ep 24: ep_len:500 episode reward: total was 11.090000. running mean: -32.632668\n",
      "ep 24: ep_len:515 episode reward: total was -13.160000. running mean: -32.437941\n",
      "ep 24: ep_len:123 episode reward: total was 11.000000. running mean: -32.003562\n",
      "ep 24: ep_len:210 episode reward: total was 20.000000. running mean: -31.483526\n",
      "ep 24: ep_len:500 episode reward: total was 1.270000. running mean: -31.155991\n",
      "ep 24: ep_len:500 episode reward: total was 13.690000. running mean: -30.707531\n",
      "ep 24: ep_len:850 episode reward: total was 21.170000. running mean: -30.188756\n",
      "ep 24: ep_len:555 episode reward: total was -17.120000. running mean: -30.058068\n",
      "ep 24: ep_len:595 episode reward: total was -16.940000. running mean: -29.926888\n",
      "ep 24: ep_len:500 episode reward: total was 19.820000. running mean: -29.429419\n",
      "ep 24: ep_len:710 episode reward: total was -9.740000. running mean: -29.232524\n",
      "ep 24: ep_len:500 episode reward: total was 25.270000. running mean: -28.687499\n",
      "ep 24: ep_len:500 episode reward: total was 0.040000. running mean: -28.400224\n",
      "ep 24: ep_len:530 episode reward: total was 18.070000. running mean: -27.935522\n",
      "ep 24: ep_len:1070 episode reward: total was -35.280000. running mean: -28.008967\n",
      "ep 24: ep_len:630 episode reward: total was -26.640000. running mean: -27.995277\n",
      "ep 24: ep_len:850 episode reward: total was -40.800000. running mean: -28.123324\n",
      "ep 24: ep_len:482 episode reward: total was 16.260000. running mean: -27.679491\n",
      "ep 24: ep_len:1205 episode reward: total was -22.370000. running mean: -27.626396\n",
      "ep 24: ep_len:500 episode reward: total was 11.120000. running mean: -27.238932\n",
      "ep 24: ep_len:735 episode reward: total was -4.120000. running mean: -27.007743\n",
      "ep 24: ep_len:705 episode reward: total was -13.790000. running mean: -26.875565\n",
      "ep 24: ep_len:500 episode reward: total was 19.760000. running mean: -26.409210\n",
      "ep 24: ep_len:500 episode reward: total was 23.490000. running mean: -25.910218\n",
      "ep 24: ep_len:2495 episode reward: total was -242.890000. running mean: -28.080016\n",
      "ep 24: ep_len:585 episode reward: total was -9.960000. running mean: -27.898815\n",
      "ep 24: ep_len:555 episode reward: total was 17.570000. running mean: -27.444127\n",
      "ep 24: ep_len:940 episode reward: total was 8.940000. running mean: -27.080286\n",
      "ep 24: ep_len:860 episode reward: total was -34.380000. running mean: -27.153283\n",
      "ep 24: ep_len:810 episode reward: total was -133.750000. running mean: -28.219250\n",
      "ep 24: ep_len:500 episode reward: total was -31.450000. running mean: -28.251558\n",
      "ep 24: ep_len:685 episode reward: total was -43.040000. running mean: -28.399442\n",
      "ep 24: ep_len:865 episode reward: total was -20.540000. running mean: -28.320848\n",
      "ep 24: ep_len:895 episode reward: total was 27.080000. running mean: -27.766839\n",
      "ep 24: ep_len:500 episode reward: total was -14.720000. running mean: -27.636371\n",
      "ep 24: ep_len:1025 episode reward: total was -24.260000. running mean: -27.602607\n",
      "ep 24: ep_len:1455 episode reward: total was -50.140000. running mean: -27.827981\n",
      "ep 24: ep_len:500 episode reward: total was 25.450000. running mean: -27.295201\n",
      "ep 24: ep_len:598 episode reward: total was -88.730000. running mean: -27.909549\n",
      "ep 24: ep_len:500 episode reward: total was -6.670000. running mean: -27.697154\n",
      "ep 24: ep_len:500 episode reward: total was 0.220000. running mean: -27.417982\n",
      "ep 24: ep_len:860 episode reward: total was 17.580000. running mean: -26.968002\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 24: ep_len:515 episode reward: total was -4.070000. running mean: -26.739022\n",
      "ep 24: ep_len:500 episode reward: total was 15.240000. running mean: -26.319232\n",
      "ep 24: ep_len:560 episode reward: total was -16.860000. running mean: -26.224640\n",
      "ep 24: ep_len:655 episode reward: total was -22.980000. running mean: -26.192193\n",
      "ep 24: ep_len:680 episode reward: total was -1.720000. running mean: -25.947472\n",
      "ep 24: ep_len:1869 episode reward: total was -164.970000. running mean: -27.337697\n",
      "ep 24: ep_len:615 episode reward: total was -26.090000. running mean: -27.325220\n",
      "ep 24: ep_len:530 episode reward: total was -6.060000. running mean: -27.112568\n",
      "ep 24: ep_len:500 episode reward: total was 0.400000. running mean: -26.837442\n",
      "ep 24: ep_len:600 episode reward: total was -0.220000. running mean: -26.571268\n",
      "ep 24: ep_len:580 episode reward: total was 5.620000. running mean: -26.249355\n",
      "ep 24: ep_len:1420 episode reward: total was -28.520000. running mean: -26.272061\n",
      "ep 24: ep_len:1140 episode reward: total was -31.920000. running mean: -26.328541\n",
      "ep 24: ep_len:500 episode reward: total was 12.440000. running mean: -25.940855\n",
      "ep 24: ep_len:845 episode reward: total was -15.330000. running mean: -25.834747\n",
      "ep 24: ep_len:665 episode reward: total was -6.280000. running mean: -25.639199\n",
      "ep 24: ep_len:500 episode reward: total was 23.790000. running mean: -25.144907\n",
      "ep 24: ep_len:446 episode reward: total was -14.220000. running mean: -25.035658\n",
      "ep 24: ep_len:500 episode reward: total was 3.650000. running mean: -24.748802\n",
      "ep 24: ep_len:860 episode reward: total was 18.590000. running mean: -24.315414\n",
      "ep 24: ep_len:500 episode reward: total was -8.810000. running mean: -24.160359\n",
      "ep 24: ep_len:575 episode reward: total was -13.530000. running mean: -24.054056\n",
      "ep 24: ep_len:500 episode reward: total was 7.360000. running mean: -23.739915\n",
      "ep 24: ep_len:545 episode reward: total was 27.960000. running mean: -23.222916\n",
      "ep 24: ep_len:500 episode reward: total was 30.290000. running mean: -22.687787\n",
      "ep 24: ep_len:915 episode reward: total was 19.800000. running mean: -22.262909\n",
      "ep 24: ep_len:715 episode reward: total was -14.010000. running mean: -22.180380\n",
      "ep 24: ep_len:2363 episode reward: total was -314.470000. running mean: -25.103276\n",
      "ep 24: ep_len:396 episode reward: total was -30.550000. running mean: -25.157743\n",
      "ep 24: ep_len:500 episode reward: total was 9.160000. running mean: -24.814566\n",
      "ep 24: ep_len:500 episode reward: total was 19.970000. running mean: -24.366720\n",
      "ep 24: ep_len:288 episode reward: total was 28.500000. running mean: -23.838053\n",
      "ep 24: ep_len:437 episode reward: total was 8.300000. running mean: -23.516673\n",
      "ep 24: ep_len:106 episode reward: total was 10.500000. running mean: -23.176506\n",
      "ep 24: ep_len:500 episode reward: total was 32.280000. running mean: -22.621941\n",
      "ep 24: ep_len:810 episode reward: total was -16.610000. running mean: -22.561821\n",
      "ep 24: ep_len:2125 episode reward: total was -196.730000. running mean: -24.303503\n",
      "ep 24: ep_len:163 episode reward: total was 11.500000. running mean: -23.945468\n",
      "ep 24: ep_len:500 episode reward: total was 28.270000. running mean: -23.423314\n",
      "ep 24: ep_len:665 episode reward: total was 12.650000. running mean: -23.062580\n",
      "ep 24: ep_len:171 episode reward: total was 17.000000. running mean: -22.661955\n",
      "ep 24: ep_len:500 episode reward: total was -24.010000. running mean: -22.675435\n",
      "ep 24: ep_len:233 episode reward: total was 20.000000. running mean: -22.248681\n",
      "ep 24: ep_len:93 episode reward: total was 9.000000. running mean: -21.936194\n",
      "ep 24: ep_len:232 episode reward: total was 23.000000. running mean: -21.486832\n",
      "ep 24: ep_len:740 episode reward: total was 23.180000. running mean: -21.040164\n",
      "ep 24: ep_len:500 episode reward: total was 16.510000. running mean: -20.664662\n",
      "ep 24: ep_len:179 episode reward: total was 17.500000. running mean: -20.283015\n",
      "ep 24: ep_len:500 episode reward: total was 1.750000. running mean: -20.062685\n",
      "ep 24: ep_len:145 episode reward: total was 13.000000. running mean: -19.732058\n",
      "ep 24: ep_len:635 episode reward: total was 21.500000. running mean: -19.319738\n",
      "ep 24: ep_len:735 episode reward: total was -43.020000. running mean: -19.556740\n",
      "ep 24: ep_len:64 episode reward: total was 4.500000. running mean: -19.316173\n",
      "ep 24: ep_len:575 episode reward: total was -16.070000. running mean: -19.283711\n",
      "ep 24: ep_len:800 episode reward: total was -6.530000. running mean: -19.156174\n",
      "ep 24: ep_len:500 episode reward: total was 0.280000. running mean: -18.961812\n",
      "ep 24: ep_len:190 episode reward: total was 17.500000. running mean: -18.597194\n",
      "ep 24: ep_len:500 episode reward: total was 10.830000. running mean: -18.302922\n",
      "ep 24: ep_len:205 episode reward: total was 17.500000. running mean: -17.944893\n",
      "ep 24: ep_len:540 episode reward: total was 14.600000. running mean: -17.619444\n",
      "ep 24: ep_len:825 episode reward: total was 1.730000. running mean: -17.425950\n",
      "ep 24: ep_len:840 episode reward: total was -4.430000. running mean: -17.295990\n",
      "ep 24: ep_len:810 episode reward: total was -2.470000. running mean: -17.147730\n",
      "ep 24: ep_len:500 episode reward: total was 19.570000. running mean: -16.780553\n",
      "ep 24: ep_len:500 episode reward: total was 27.790000. running mean: -16.334848\n",
      "ep 24: ep_len:755 episode reward: total was -54.540000. running mean: -16.716899\n",
      "ep 24: ep_len:505 episode reward: total was -4.090000. running mean: -16.590630\n",
      "ep 24: ep_len:500 episode reward: total was -5.000000. running mean: -16.474724\n",
      "ep 24: ep_len:161 episode reward: total was 16.000000. running mean: -16.149977\n",
      "ep 24: ep_len:500 episode reward: total was 12.530000. running mean: -15.863177\n",
      "ep 24: ep_len:965 episode reward: total was -142.520000. running mean: -17.129745\n",
      "ep 24: ep_len:500 episode reward: total was 12.160000. running mean: -16.836848\n",
      "ep 24: ep_len:1595 episode reward: total was -248.770000. running mean: -19.156179\n",
      "ep 24: ep_len:555 episode reward: total was -75.700000. running mean: -19.721617\n",
      "ep 24: ep_len:500 episode reward: total was 4.730000. running mean: -19.477101\n",
      "ep 24: ep_len:500 episode reward: total was -16.860000. running mean: -19.450930\n",
      "ep 24: ep_len:500 episode reward: total was -16.800000. running mean: -19.424421\n",
      "ep 24: ep_len:925 episode reward: total was -32.320000. running mean: -19.553377\n",
      "ep 24: ep_len:273 episode reward: total was 27.000000. running mean: -19.087843\n",
      "ep 24: ep_len:500 episode reward: total was 16.820000. running mean: -18.728764\n",
      "ep 24: ep_len:371 episode reward: total was 37.500000. running mean: -18.166477\n",
      "ep 24: ep_len:500 episode reward: total was 1.710000. running mean: -17.967712\n",
      "ep 24: ep_len:500 episode reward: total was 25.240000. running mean: -17.535635\n",
      "ep 24: ep_len:500 episode reward: total was 8.300000. running mean: -17.277279\n",
      "ep 24: ep_len:500 episode reward: total was 27.290000. running mean: -16.831606\n",
      "ep 24: ep_len:785 episode reward: total was -1.200000. running mean: -16.675290\n",
      "ep 24: ep_len:530 episode reward: total was -7.070000. running mean: -16.579237\n",
      "ep 24: ep_len:725 episode reward: total was -4.650000. running mean: -16.459944\n",
      "ep 24: ep_len:785 episode reward: total was -59.080000. running mean: -16.886145\n",
      "ep 24: ep_len:1055 episode reward: total was -45.220000. running mean: -17.169484\n",
      "ep 24: ep_len:500 episode reward: total was 5.070000. running mean: -16.947089\n",
      "ep 24: ep_len:725 episode reward: total was -6.680000. running mean: -16.844418\n",
      "ep 24: ep_len:500 episode reward: total was 11.070000. running mean: -16.565274\n",
      "ep 24: ep_len:878 episode reward: total was -89.180000. running mean: -17.291421\n",
      "ep 24: ep_len:750 episode reward: total was -44.000000. running mean: -17.558507\n",
      "ep 24: ep_len:615 episode reward: total was -28.110000. running mean: -17.664022\n",
      "ep 24: ep_len:297 episode reward: total was 23.500000. running mean: -17.252381\n",
      "ep 24: ep_len:850 episode reward: total was -5.090000. running mean: -17.130758\n",
      "ep 24: ep_len:500 episode reward: total was 14.250000. running mean: -16.816950\n",
      "ep 24: ep_len:500 episode reward: total was 48.500000. running mean: -16.163780\n",
      "ep 24: ep_len:500 episode reward: total was 29.710000. running mean: -15.705043\n",
      "ep 24: ep_len:760 episode reward: total was -8.630000. running mean: -15.634292\n",
      "ep 24: ep_len:207 episode reward: total was 20.500000. running mean: -15.272949\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 24: ep_len:825 episode reward: total was -0.000000. running mean: -15.120220\n",
      "ep 24: ep_len:500 episode reward: total was 2.770000. running mean: -14.941318\n",
      "ep 24: ep_len:815 episode reward: total was -3.470000. running mean: -14.826604\n",
      "ep 24: ep_len:610 episode reward: total was -23.070000. running mean: -14.909038\n",
      "ep 24: ep_len:500 episode reward: total was -7.210000. running mean: -14.832048\n",
      "ep 24: ep_len:258 episode reward: total was 24.000000. running mean: -14.443728\n",
      "ep 24: ep_len:500 episode reward: total was -18.820000. running mean: -14.487490\n",
      "ep 24: ep_len:500 episode reward: total was -24.420000. running mean: -14.586815\n",
      "ep 24: ep_len:161 episode reward: total was 13.000000. running mean: -14.310947\n",
      "ep 24: ep_len:500 episode reward: total was 8.580000. running mean: -14.082038\n",
      "ep 24: ep_len:880 episode reward: total was 5.730000. running mean: -13.883917\n",
      "ep 24: ep_len:2189 episode reward: total was -244.120000. running mean: -16.186278\n",
      "ep 24: ep_len:790 episode reward: total was -4.530000. running mean: -16.069715\n",
      "ep 24: ep_len:630 episode reward: total was 9.800000. running mean: -15.811018\n",
      "ep 24: ep_len:730 episode reward: total was -4.650000. running mean: -15.699408\n",
      "ep 24: ep_len:500 episode reward: total was -5.320000. running mean: -15.595614\n",
      "ep 24: ep_len:530 episode reward: total was -8.230000. running mean: -15.521958\n",
      "ep 24: ep_len:247 episode reward: total was 21.500000. running mean: -15.151738\n",
      "ep 24: ep_len:500 episode reward: total was -5.770000. running mean: -15.057921\n",
      "ep 24: ep_len:683 episode reward: total was -7.760000. running mean: -14.984942\n",
      "ep 24: ep_len:500 episode reward: total was -38.830000. running mean: -15.223392\n",
      "ep 24: ep_len:1170 episode reward: total was -174.480000. running mean: -16.815958\n",
      "ep 24: ep_len:920 episode reward: total was -60.830000. running mean: -17.256099\n",
      "ep 24: ep_len:500 episode reward: total was -17.710000. running mean: -17.260638\n",
      "ep 24: ep_len:279 episode reward: total was 16.670000. running mean: -16.921331\n",
      "ep 24: ep_len:500 episode reward: total was -24.360000. running mean: -16.995718\n",
      "ep 24: ep_len:1804 episode reward: total was -196.670000. running mean: -18.792461\n",
      "ep 24: ep_len:510 episode reward: total was -36.400000. running mean: -18.968536\n",
      "ep 24: ep_len:500 episode reward: total was 26.310000. running mean: -18.515751\n",
      "ep 24: ep_len:720 episode reward: total was -7.700000. running mean: -18.407593\n",
      "ep 24: ep_len:850 episode reward: total was -41.780000. running mean: -18.641317\n",
      "ep 24: ep_len:500 episode reward: total was 4.300000. running mean: -18.411904\n",
      "ep 24: ep_len:500 episode reward: total was 23.280000. running mean: -17.994985\n",
      "ep 24: ep_len:500 episode reward: total was 4.660000. running mean: -17.768435\n",
      "ep 24: ep_len:500 episode reward: total was 15.040000. running mean: -17.440351\n",
      "ep 24: ep_len:585 episode reward: total was -7.970000. running mean: -17.345648\n",
      "ep 24: ep_len:121 episode reward: total was 10.500000. running mean: -17.067191\n",
      "ep 24: ep_len:815 episode reward: total was -20.640000. running mean: -17.102919\n",
      "ep 24: ep_len:880 episode reward: total was -2.580000. running mean: -16.957690\n",
      "ep 24: ep_len:855 episode reward: total was 4.130000. running mean: -16.746813\n",
      "ep 24: ep_len:670 episode reward: total was -5.780000. running mean: -16.637145\n",
      "ep 24: ep_len:500 episode reward: total was -7.520000. running mean: -16.545973\n",
      "ep 24: ep_len:500 episode reward: total was -8.810000. running mean: -16.468614\n",
      "ep 24: ep_len:500 episode reward: total was 0.430000. running mean: -16.299628\n",
      "ep 24: ep_len:765 episode reward: total was 29.600000. running mean: -15.840631\n",
      "ep 24: ep_len:880 episode reward: total was -33.640000. running mean: -16.018625\n",
      "ep 24: ep_len:12725 episode reward: total was -2403.820000. running mean: -39.896639\n",
      "ep 24: ep_len:500 episode reward: total was -6.150000. running mean: -39.559172\n",
      "ep 24: ep_len:510 episode reward: total was -7.860000. running mean: -39.242181\n",
      "ep 24: ep_len:313 episode reward: total was 31.000000. running mean: -38.539759\n",
      "ep 24: ep_len:510 episode reward: total was -0.040000. running mean: -38.154761\n",
      "ep 24: ep_len:665 episode reward: total was 22.760000. running mean: -37.545614\n",
      "ep 24: ep_len:710 episode reward: total was -59.720000. running mean: -37.767358\n",
      "ep 24: ep_len:535 episode reward: total was -2.010000. running mean: -37.409784\n",
      "ep 24: ep_len:1720 episode reward: total was -269.310000. running mean: -39.728786\n",
      "ep 24: ep_len:500 episode reward: total was 6.140000. running mean: -39.270098\n",
      "ep 24: ep_len:500 episode reward: total was 13.730000. running mean: -38.740097\n",
      "ep 24: ep_len:500 episode reward: total was -0.510000. running mean: -38.357796\n",
      "ep 24: ep_len:945 episode reward: total was 14.540000. running mean: -37.828818\n",
      "ep 24: ep_len:740 episode reward: total was 5.180000. running mean: -37.398730\n",
      "ep 24: ep_len:500 episode reward: total was 14.710000. running mean: -36.877643\n",
      "ep 24: ep_len:500 episode reward: total was 31.210000. running mean: -36.196766\n",
      "ep 24: ep_len:960 episode reward: total was 6.790000. running mean: -35.766899\n",
      "ep 24: ep_len:920 episode reward: total was 4.350000. running mean: -35.365730\n",
      "ep 24: ep_len:500 episode reward: total was 26.310000. running mean: -34.748972\n",
      "ep 24: ep_len:655 episode reward: total was -34.090000. running mean: -34.742383\n",
      "ep 24: ep_len:500 episode reward: total was -3.090000. running mean: -34.425859\n",
      "ep 24: ep_len:244 episode reward: total was 21.000000. running mean: -33.871600\n",
      "ep 24: ep_len:2086 episode reward: total was -336.800000. running mean: -36.900884\n",
      "ep 24: ep_len:570 episode reward: total was -27.160000. running mean: -36.803475\n",
      "ep 24: ep_len:500 episode reward: total was 16.880000. running mean: -36.266641\n",
      "ep 24: ep_len:505 episode reward: total was -11.520000. running mean: -36.019174\n",
      "ep 24: ep_len:615 episode reward: total was -37.200000. running mean: -36.030983\n",
      "ep 24: ep_len:500 episode reward: total was 48.500000. running mean: -35.185673\n",
      "ep 24: ep_len:500 episode reward: total was 0.830000. running mean: -34.825516\n",
      "ep 24: ep_len:339 episode reward: total was 33.500000. running mean: -34.142261\n",
      "ep 24: ep_len:945 episode reward: total was -4.680000. running mean: -33.847638\n",
      "ep 24: ep_len:510 episode reward: total was -41.450000. running mean: -33.923662\n",
      "ep 24: ep_len:500 episode reward: total was 21.840000. running mean: -33.366025\n",
      "ep 24: ep_len:224 episode reward: total was 17.500000. running mean: -32.857365\n",
      "ep 24: ep_len:510 episode reward: total was -97.000000. running mean: -33.498791\n",
      "ep 24: ep_len:358 episode reward: total was 32.500000. running mean: -32.838803\n",
      "ep 24: ep_len:329 episode reward: total was 31.000000. running mean: -32.200415\n",
      "ep 24: ep_len:500 episode reward: total was 3.860000. running mean: -31.839811\n",
      "ep 24: ep_len:500 episode reward: total was 21.290000. running mean: -31.308513\n",
      "ep 24: ep_len:500 episode reward: total was 15.470000. running mean: -30.840728\n",
      "ep 24: ep_len:1495 episode reward: total was -209.140000. running mean: -32.623721\n",
      "ep 24: ep_len:750 episode reward: total was -61.070000. running mean: -32.908184\n",
      "ep 24: ep_len:500 episode reward: total was -13.800000. running mean: -32.717102\n",
      "ep 24: ep_len:705 episode reward: total was 4.270000. running mean: -32.347231\n",
      "ep 24: ep_len:500 episode reward: total was -11.170000. running mean: -32.135458\n",
      "ep 24: ep_len:500 episode reward: total was 50.000000. running mean: -31.314104\n",
      "ep 24: ep_len:610 episode reward: total was 3.380000. running mean: -30.967163\n",
      "ep 24: ep_len:354 episode reward: total was 7.640000. running mean: -30.581091\n",
      "ep 24: ep_len:635 episode reward: total was -4.900000. running mean: -30.324280\n",
      "ep 24: ep_len:280 episode reward: total was 23.500000. running mean: -29.786037\n",
      "ep 24: ep_len:500 episode reward: total was -10.760000. running mean: -29.595777\n",
      "ep 24: ep_len:2055 episode reward: total was -313.840000. running mean: -32.438219\n",
      "ep 24: ep_len:715 episode reward: total was -10.740000. running mean: -32.221237\n",
      "ep 24: ep_len:500 episode reward: total was 9.290000. running mean: -31.806125\n",
      "ep 24: ep_len:279 episode reward: total was 26.000000. running mean: -31.228063\n",
      "ep 24: ep_len:500 episode reward: total was 15.780000. running mean: -30.757983\n",
      "ep 24: ep_len:830 episode reward: total was 3.370000. running mean: -30.416703\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 24: ep_len:535 episode reward: total was 5.740000. running mean: -30.055136\n",
      "ep 24: ep_len:500 episode reward: total was 10.050000. running mean: -29.654085\n",
      "ep 24: ep_len:590 episode reward: total was -85.210000. running mean: -30.209644\n",
      "ep 24: ep_len:595 episode reward: total was 10.330000. running mean: -29.804247\n",
      "ep 24: ep_len:500 episode reward: total was 21.290000. running mean: -29.293305\n",
      "ep 24: ep_len:1025 episode reward: total was -73.840000. running mean: -29.738772\n",
      "ep 24: ep_len:500 episode reward: total was 10.770000. running mean: -29.333684\n",
      "ep 24: ep_len:720 episode reward: total was -20.830000. running mean: -29.248647\n",
      "ep 24: ep_len:525 episode reward: total was -3.370000. running mean: -28.989861\n",
      "ep 24: ep_len:1175 episode reward: total was -106.780000. running mean: -29.767762\n",
      "ep 24: ep_len:620 episode reward: total was -21.030000. running mean: -29.680385\n",
      "ep 24: ep_len:500 episode reward: total was 4.730000. running mean: -29.336281\n",
      "ep 24: ep_len:1001 episode reward: total was -105.090000. running mean: -30.093818\n",
      "ep 24: ep_len:840 episode reward: total was -2.710000. running mean: -29.819980\n",
      "ep 24: ep_len:925 episode reward: total was 19.670000. running mean: -29.325080\n",
      "ep 24: ep_len:500 episode reward: total was 23.800000. running mean: -28.793829\n",
      "ep 24: ep_len:840 episode reward: total was -100.360000. running mean: -29.509491\n",
      "ep 24: ep_len:500 episode reward: total was -13.170000. running mean: -29.346096\n",
      "ep 24: ep_len:500 episode reward: total was 8.210000. running mean: -28.970535\n",
      "ep 24: ep_len:500 episode reward: total was -3.180000. running mean: -28.712630\n",
      "ep 24: ep_len:500 episode reward: total was -2.720000. running mean: -28.452703\n",
      "ep 24: ep_len:500 episode reward: total was 20.810000. running mean: -27.960076\n",
      "ep 24: ep_len:555 episode reward: total was -66.450000. running mean: -28.344976\n",
      "ep 24: ep_len:1383 episode reward: total was -207.400000. running mean: -30.135526\n",
      "ep 24: ep_len:645 episode reward: total was 22.050000. running mean: -29.613670\n",
      "ep 24: ep_len:500 episode reward: total was -15.850000. running mean: -29.476034\n",
      "ep 24: ep_len:695 episode reward: total was -19.070000. running mean: -29.371973\n",
      "ep 24: ep_len:1075 episode reward: total was -50.130000. running mean: -29.579554\n",
      "ep 24: ep_len:525 episode reward: total was -10.110000. running mean: -29.384858\n",
      "ep 24: ep_len:500 episode reward: total was 19.330000. running mean: -28.897710\n",
      "ep 24: ep_len:628 episode reward: total was -70.490000. running mean: -29.313632\n",
      "ep 24: ep_len:2045 episode reward: total was -313.100000. running mean: -32.151496\n",
      "ep 24: ep_len:1221 episode reward: total was -135.420000. running mean: -33.184181\n",
      "ep 24: ep_len:500 episode reward: total was 32.800000. running mean: -32.524339\n",
      "ep 24: ep_len:1040 episode reward: total was 2.290000. running mean: -32.176196\n",
      "ep 24: ep_len:500 episode reward: total was -9.330000. running mean: -31.947734\n",
      "ep 24: ep_len:500 episode reward: total was 2.910000. running mean: -31.599157\n",
      "ep 24: ep_len:278 episode reward: total was 24.500000. running mean: -31.038165\n",
      "ep 24: ep_len:1000 episode reward: total was -10.970000. running mean: -30.837483\n",
      "ep 24: ep_len:750 episode reward: total was -37.940000. running mean: -30.908509\n",
      "ep 24: ep_len:765 episode reward: total was -49.020000. running mean: -31.089624\n",
      "ep 24: ep_len:585 episode reward: total was -13.510000. running mean: -30.913827\n",
      "ep 24: ep_len:500 episode reward: total was 13.910000. running mean: -30.465589\n",
      "ep 24: ep_len:1982 episode reward: total was -330.130000. running mean: -33.462233\n",
      "ep 24: ep_len:775 episode reward: total was -25.770000. running mean: -33.385311\n",
      "ep 24: ep_len:160 episode reward: total was 14.500000. running mean: -32.906458\n",
      "ep 24: ep_len:705 episode reward: total was -7.090000. running mean: -32.648293\n",
      "ep 24: ep_len:660 episode reward: total was -5.800000. running mean: -32.379810\n",
      "ep 24: ep_len:486 episode reward: total was 28.790000. running mean: -31.768112\n",
      "ep 24: ep_len:281 episode reward: total was 25.000000. running mean: -31.200431\n",
      "ep 24: ep_len:750 episode reward: total was -12.690000. running mean: -31.015327\n",
      "ep 24: ep_len:500 episode reward: total was 20.950000. running mean: -30.495673\n",
      "ep 24: ep_len:500 episode reward: total was 6.770000. running mean: -30.123017\n",
      "ep 24: ep_len:240 episode reward: total was 22.500000. running mean: -29.596787\n",
      "ep 24: ep_len:1190 episode reward: total was -103.720000. running mean: -30.338019\n",
      "ep 24: ep_len:500 episode reward: total was 30.270000. running mean: -29.731938\n",
      "ep 24: ep_len:605 episode reward: total was 9.340000. running mean: -29.341219\n",
      "ep 24: ep_len:500 episode reward: total was 26.830000. running mean: -28.779507\n",
      "ep 24: ep_len:467 episode reward: total was 19.840000. running mean: -28.293312\n",
      "ep 24: ep_len:505 episode reward: total was -49.140000. running mean: -28.501779\n",
      "ep 24: ep_len:505 episode reward: total was -15.200000. running mean: -28.368761\n",
      "ep 24: ep_len:500 episode reward: total was -13.190000. running mean: -28.216973\n",
      "ep 24: ep_len:505 episode reward: total was -5.100000. running mean: -27.985804\n",
      "ep 24: ep_len:760 episode reward: total was -40.950000. running mean: -28.115446\n",
      "ep 24: ep_len:2410 episode reward: total was -414.500000. running mean: -31.979291\n",
      "ep 24: ep_len:500 episode reward: total was -18.330000. running mean: -31.842798\n",
      "ep 24: ep_len:500 episode reward: total was 48.500000. running mean: -31.039370\n",
      "ep 24: ep_len:835 episode reward: total was -70.090000. running mean: -31.429876\n",
      "ep 24: ep_len:505 episode reward: total was -9.140000. running mean: -31.206978\n",
      "ep 24: ep_len:500 episode reward: total was -2.560000. running mean: -30.920508\n",
      "ep 24: ep_len:500 episode reward: total was -10.580000. running mean: -30.717103\n",
      "ep 24: ep_len:500 episode reward: total was 50.000000. running mean: -29.909932\n",
      "ep 24: ep_len:675 episode reward: total was -3.750000. running mean: -29.648333\n",
      "ep 24: ep_len:265 episode reward: total was -10.500000. running mean: -29.456849\n",
      "epsilon:0.015557 episode_count: 19715. steps_count: 14126111.000000\n",
      "ep 25: ep_len:2375 episode reward: total was -147.810000. running mean: -30.640381\n",
      "ep 25: ep_len:815 episode reward: total was -7.510000. running mean: -30.409077\n",
      "ep 25: ep_len:500 episode reward: total was 2.490000. running mean: -30.080086\n",
      "ep 25: ep_len:1055 episode reward: total was -105.550000. running mean: -30.834785\n",
      "ep 25: ep_len:880 episode reward: total was 11.570000. running mean: -30.410737\n",
      "ep 25: ep_len:970 episode reward: total was -55.680000. running mean: -30.663430\n",
      "ep 25: ep_len:1087 episode reward: total was -148.430000. running mean: -31.841096\n",
      "ep 25: ep_len:500 episode reward: total was 16.850000. running mean: -31.354185\n",
      "ep 25: ep_len:1015 episode reward: total was -10.790000. running mean: -31.148543\n",
      "ep 25: ep_len:545 episode reward: total was -1.990000. running mean: -30.856958\n",
      "ep 25: ep_len:695 episode reward: total was 21.190000. running mean: -30.336488\n",
      "ep 25: ep_len:500 episode reward: total was 19.280000. running mean: -29.840323\n",
      "ep 25: ep_len:1916 episode reward: total was -261.450000. running mean: -32.156420\n",
      "ep 25: ep_len:840 episode reward: total was -22.610000. running mean: -32.060956\n",
      "ep 25: ep_len:830 episode reward: total was -29.700000. running mean: -32.037346\n",
      "ep 25: ep_len:500 episode reward: total was 24.260000. running mean: -31.474373\n",
      "ep 25: ep_len:500 episode reward: total was 8.960000. running mean: -31.070029\n",
      "ep 25: ep_len:500 episode reward: total was 6.160000. running mean: -30.697729\n",
      "ep 25: ep_len:267 episode reward: total was 26.500000. running mean: -30.125751\n",
      "ep 25: ep_len:745 episode reward: total was 8.000000. running mean: -29.744494\n",
      "ep 25: ep_len:500 episode reward: total was 6.010000. running mean: -29.386949\n",
      "ep 25: ep_len:1585 episode reward: total was -74.520000. running mean: -29.838279\n",
      "ep 25: ep_len:267 episode reward: total was 26.500000. running mean: -29.274897\n",
      "ep 25: ep_len:960 episode reward: total was -46.610000. running mean: -29.448248\n",
      "ep 25: ep_len:500 episode reward: total was 1.300000. running mean: -29.140765\n",
      "ep 25: ep_len:500 episode reward: total was 6.190000. running mean: -28.787457\n",
      "ep 25: ep_len:126 episode reward: total was 12.500000. running mean: -28.374583\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 25: ep_len:565 episode reward: total was -35.830000. running mean: -28.449137\n",
      "ep 25: ep_len:570 episode reward: total was 16.160000. running mean: -28.003046\n",
      "ep 25: ep_len:15928 episode reward: total was -2927.460000. running mean: -56.997615\n",
      "ep 25: ep_len:500 episode reward: total was 24.420000. running mean: -56.183439\n",
      "ep 25: ep_len:500 episode reward: total was 21.260000. running mean: -55.409005\n",
      "ep 25: ep_len:850 episode reward: total was 0.970000. running mean: -54.845215\n",
      "ep 25: ep_len:565 episode reward: total was 2.890000. running mean: -54.267863\n",
      "ep 25: ep_len:890 episode reward: total was 5.630000. running mean: -53.668884\n",
      "ep 25: ep_len:500 episode reward: total was 17.600000. running mean: -52.956195\n",
      "ep 25: ep_len:500 episode reward: total was 20.680000. running mean: -52.219833\n",
      "ep 25: ep_len:1497 episode reward: total was -214.230000. running mean: -53.839935\n",
      "ep 25: ep_len:765 episode reward: total was -13.230000. running mean: -53.433835\n",
      "ep 25: ep_len:500 episode reward: total was -27.080000. running mean: -53.170297\n",
      "ep 25: ep_len:510 episode reward: total was -18.120000. running mean: -52.819794\n",
      "ep 25: ep_len:500 episode reward: total was -32.500000. running mean: -52.616596\n",
      "ep 25: ep_len:254 episode reward: total was 22.000000. running mean: -51.870430\n",
      "ep 25: ep_len:830 episode reward: total was 27.960000. running mean: -51.072126\n",
      "ep 25: ep_len:500 episode reward: total was 33.350000. running mean: -50.227905\n",
      "ep 25: ep_len:500 episode reward: total was 18.380000. running mean: -49.541826\n",
      "ep 25: ep_len:670 episode reward: total was -17.900000. running mean: -49.225407\n",
      "ep 25: ep_len:21850 episode reward: total was -4324.660000. running mean: -91.979753\n",
      "ep 25: ep_len:765 episode reward: total was -10.640000. running mean: -91.166356\n",
      "ep 25: ep_len:1230 episode reward: total was -9.190000. running mean: -90.346592\n",
      "ep 25: ep_len:795 episode reward: total was -7.330000. running mean: -89.516426\n",
      "ep 25: ep_len:107 episode reward: total was 9.000000. running mean: -88.531262\n",
      "ep 25: ep_len:555 episode reward: total was -72.670000. running mean: -88.372649\n",
      "ep 25: ep_len:705 episode reward: total was -16.600000. running mean: -87.654923\n",
      "ep 25: ep_len:500 episode reward: total was 14.800000. running mean: -86.630374\n",
      "ep 25: ep_len:920 episode reward: total was -31.250000. running mean: -86.076570\n",
      "ep 25: ep_len:128 episode reward: total was 9.500000. running mean: -85.120804\n",
      "ep 25: ep_len:805 episode reward: total was 2.840000. running mean: -84.241196\n",
      "ep 25: ep_len:775 episode reward: total was -28.800000. running mean: -83.686784\n",
      "ep 25: ep_len:615 episode reward: total was 10.540000. running mean: -82.744516\n",
      "ep 25: ep_len:915 episode reward: total was -50.580000. running mean: -82.422871\n",
      "ep 25: ep_len:500 episode reward: total was -13.310000. running mean: -81.731742\n",
      "ep 25: ep_len:515 episode reward: total was -23.260000. running mean: -81.147025\n",
      "ep 25: ep_len:221 episode reward: total was 22.000000. running mean: -80.115555\n",
      "ep 25: ep_len:236 episode reward: total was 23.500000. running mean: -79.079399\n",
      "ep 25: ep_len:1188 episode reward: total was -176.630000. running mean: -80.054905\n",
      "ep 25: ep_len:480 episode reward: total was 20.700000. running mean: -79.047356\n",
      "ep 25: ep_len:1622 episode reward: total was -171.720000. running mean: -79.974083\n",
      "ep 25: ep_len:550 episode reward: total was -36.320000. running mean: -79.537542\n",
      "ep 25: ep_len:945 episode reward: total was -63.340000. running mean: -79.375566\n",
      "ep 25: ep_len:650 episode reward: total was -13.900000. running mean: -78.720811\n",
      "ep 25: ep_len:730 episode reward: total was -3.640000. running mean: -77.970003\n",
      "ep 25: ep_len:500 episode reward: total was -41.560000. running mean: -77.605903\n",
      "ep 25: ep_len:955 episode reward: total was -65.260000. running mean: -77.482444\n",
      "ep 25: ep_len:425 episode reward: total was -19.520000. running mean: -76.902819\n",
      "ep 25: ep_len:820 episode reward: total was -31.450000. running mean: -76.448291\n",
      "ep 25: ep_len:1482 episode reward: total was -207.880000. running mean: -77.762608\n",
      "ep 25: ep_len:920 episode reward: total was -1.000000. running mean: -76.994982\n",
      "ep 25: ep_len:500 episode reward: total was -14.190000. running mean: -76.366932\n",
      "ep 25: ep_len:720 episode reward: total was -5.680000. running mean: -75.660063\n",
      "ep 25: ep_len:870 episode reward: total was -5.400000. running mean: -74.957462\n",
      "ep 25: ep_len:500 episode reward: total was 7.240000. running mean: -74.135488\n",
      "ep 25: ep_len:730 episode reward: total was 13.200000. running mean: -73.262133\n",
      "ep 25: ep_len:500 episode reward: total was -12.700000. running mean: -72.656511\n",
      "ep 25: ep_len:500 episode reward: total was 13.310000. running mean: -71.796846\n",
      "ep 25: ep_len:570 episode reward: total was -24.160000. running mean: -71.320478\n",
      "ep 25: ep_len:635 episode reward: total was -38.170000. running mean: -70.988973\n",
      "ep 25: ep_len:615 episode reward: total was -31.140000. running mean: -70.590483\n",
      "ep 25: ep_len:875 episode reward: total was 2.950000. running mean: -69.855078\n",
      "ep 25: ep_len:770 episode reward: total was -63.150000. running mean: -69.788028\n",
      "ep 25: ep_len:1610 episode reward: total was -222.060000. running mean: -71.310747\n",
      "ep 25: ep_len:500 episode reward: total was 20.280000. running mean: -70.394840\n",
      "ep 25: ep_len:575 episode reward: total was -36.270000. running mean: -70.053592\n",
      "ep 25: ep_len:20429 episode reward: total was -408.630000. running mean: -73.439356\n",
      "ep 25: ep_len:500 episode reward: total was -56.740000. running mean: -73.272362\n",
      "ep 25: ep_len:252 episode reward: total was 25.000000. running mean: -72.289638\n",
      "ep 25: ep_len:520 episode reward: total was 30.330000. running mean: -71.263442\n",
      "ep 25: ep_len:500 episode reward: total was 13.240000. running mean: -70.418408\n",
      "ep 25: ep_len:500 episode reward: total was 24.320000. running mean: -69.471024\n",
      "ep 25: ep_len:695 episode reward: total was -6.740000. running mean: -68.843713\n",
      "ep 25: ep_len:500 episode reward: total was -21.270000. running mean: -68.367976\n",
      "ep 25: ep_len:840 episode reward: total was -42.250000. running mean: -68.106796\n",
      "ep 25: ep_len:1273 episode reward: total was -214.640000. running mean: -69.572128\n",
      "ep 25: ep_len:500 episode reward: total was -27.540000. running mean: -69.151807\n",
      "ep 25: ep_len:1190 episode reward: total was -32.030000. running mean: -68.780589\n",
      "ep 25: ep_len:550 episode reward: total was -25.210000. running mean: -68.344883\n",
      "ep 25: ep_len:775 episode reward: total was -12.230000. running mean: -67.783734\n",
      "ep 25: ep_len:245 episode reward: total was 20.000000. running mean: -66.905897\n",
      "ep 25: ep_len:500 episode reward: total was 16.390000. running mean: -66.072938\n",
      "ep 25: ep_len:500 episode reward: total was -4.250000. running mean: -65.454709\n",
      "ep 25: ep_len:20415 episode reward: total was -3648.620000. running mean: -101.286362\n",
      "ep 25: ep_len:500 episode reward: total was 6.250000. running mean: -100.210998\n",
      "ep 25: ep_len:1030 episode reward: total was -2.780000. running mean: -99.236688\n",
      "ep 25: ep_len:165 episode reward: total was 15.500000. running mean: -98.089321\n",
      "ep 25: ep_len:870 episode reward: total was -59.920000. running mean: -97.707628\n",
      "ep 25: ep_len:1025 episode reward: total was -2.880000. running mean: -96.759352\n",
      "ep 25: ep_len:715 episode reward: total was -32.330000. running mean: -96.115058\n",
      "ep 25: ep_len:1031 episode reward: total was -57.710000. running mean: -95.731008\n",
      "ep 25: ep_len:500 episode reward: total was -46.120000. running mean: -95.234897\n",
      "ep 25: ep_len:500 episode reward: total was -4.250000. running mean: -94.325048\n",
      "ep 25: ep_len:1995 episode reward: total was -299.010000. running mean: -96.371898\n",
      "ep 25: ep_len:800 episode reward: total was -87.440000. running mean: -96.282579\n",
      "ep 25: ep_len:750 episode reward: total was -26.830000. running mean: -95.588053\n",
      "ep 25: ep_len:500 episode reward: total was 49.000000. running mean: -94.142173\n",
      "ep 25: ep_len:500 episode reward: total was -4.670000. running mean: -93.247451\n",
      "ep 25: ep_len:1120 episode reward: total was 3.190000. running mean: -92.283076\n",
      "ep 25: ep_len:500 episode reward: total was 24.720000. running mean: -91.113046\n",
      "ep 25: ep_len:1130 episode reward: total was -26.820000. running mean: -90.470115\n",
      "ep 25: ep_len:500 episode reward: total was -16.060000. running mean: -89.726014\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 25: ep_len:218 episode reward: total was 22.000000. running mean: -88.608754\n",
      "ep 25: ep_len:775 episode reward: total was -68.160000. running mean: -88.404266\n",
      "ep 25: ep_len:500 episode reward: total was 21.320000. running mean: -87.307024\n",
      "ep 25: ep_len:1905 episode reward: total was -198.330000. running mean: -88.417253\n",
      "ep 25: ep_len:2224 episode reward: total was -328.890000. running mean: -90.821981\n",
      "ep 25: ep_len:537 episode reward: total was -90.870000. running mean: -90.822461\n",
      "ep 25: ep_len:500 episode reward: total was -21.020000. running mean: -90.124437\n",
      "ep 25: ep_len:515 episode reward: total was -38.410000. running mean: -89.607292\n",
      "ep 25: ep_len:500 episode reward: total was 48.500000. running mean: -88.226219\n",
      "ep 25: ep_len:500 episode reward: total was 18.660000. running mean: -87.157357\n",
      "ep 25: ep_len:945 episode reward: total was 16.190000. running mean: -86.123883\n",
      "ep 25: ep_len:1560 episode reward: total was -132.140000. running mean: -86.584045\n",
      "ep 25: ep_len:500 episode reward: total was -25.310000. running mean: -85.971304\n",
      "ep 25: ep_len:590 episode reward: total was -4.800000. running mean: -85.159591\n",
      "ep 25: ep_len:620 episode reward: total was -38.200000. running mean: -84.689995\n",
      "ep 25: ep_len:505 episode reward: total was 2.350000. running mean: -83.819595\n",
      "ep 25: ep_len:665 episode reward: total was -2.760000. running mean: -83.008999\n",
      "ep 25: ep_len:500 episode reward: total was 5.740000. running mean: -82.121509\n",
      "ep 25: ep_len:500 episode reward: total was 24.240000. running mean: -81.057894\n",
      "ep 25: ep_len:680 episode reward: total was -44.140000. running mean: -80.688715\n",
      "ep 25: ep_len:500 episode reward: total was -41.470000. running mean: -80.296528\n",
      "ep 25: ep_len:545 episode reward: total was 4.230000. running mean: -79.451263\n",
      "ep 25: ep_len:238 episode reward: total was 23.500000. running mean: -78.421750\n",
      "ep 25: ep_len:500 episode reward: total was 10.120000. running mean: -77.536333\n",
      "ep 25: ep_len:870 episode reward: total was 2.450000. running mean: -76.736469\n",
      "ep 25: ep_len:720 episode reward: total was -0.780000. running mean: -75.976905\n",
      "ep 25: ep_len:870 episode reward: total was 6.170000. running mean: -75.155436\n",
      "ep 25: ep_len:500 episode reward: total was -14.350000. running mean: -74.547381\n",
      "ep 25: ep_len:600 episode reward: total was -1.880000. running mean: -73.820708\n",
      "ep 25: ep_len:550 episode reward: total was -16.120000. running mean: -73.243700\n",
      "ep 25: ep_len:500 episode reward: total was 12.290000. running mean: -72.388363\n",
      "ep 25: ep_len:500 episode reward: total was 7.360000. running mean: -71.590880\n",
      "ep 25: ep_len:765 episode reward: total was -15.690000. running mean: -71.031871\n",
      "ep 25: ep_len:755 episode reward: total was -4.260000. running mean: -70.364152\n",
      "ep 25: ep_len:525 episode reward: total was -29.300000. running mean: -69.953511\n",
      "ep 25: ep_len:500 episode reward: total was 6.250000. running mean: -69.191476\n",
      "ep 25: ep_len:500 episode reward: total was 16.540000. running mean: -68.334161\n",
      "ep 25: ep_len:875 episode reward: total was 19.650000. running mean: -67.454319\n",
      "ep 25: ep_len:500 episode reward: total was 3.890000. running mean: -66.740876\n",
      "ep 25: ep_len:1000 episode reward: total was -24.590000. running mean: -66.319367\n",
      "ep 25: ep_len:500 episode reward: total was 9.560000. running mean: -65.560574\n",
      "ep 25: ep_len:625 episode reward: total was -45.260000. running mean: -65.357568\n",
      "ep 25: ep_len:725 episode reward: total was -6.680000. running mean: -64.770792\n",
      "ep 25: ep_len:147 episode reward: total was 10.500000. running mean: -64.018084\n",
      "ep 25: ep_len:690 episode reward: total was -18.430000. running mean: -63.562203\n",
      "ep 25: ep_len:955 episode reward: total was -7.510000. running mean: -63.001681\n",
      "ep 25: ep_len:216 episode reward: total was 20.000000. running mean: -62.171665\n",
      "ep 25: ep_len:500 episode reward: total was 10.820000. running mean: -61.441748\n",
      "ep 25: ep_len:236 episode reward: total was 22.000000. running mean: -60.607331\n",
      "ep 25: ep_len:880 episode reward: total was -7.770000. running mean: -60.078957\n",
      "ep 25: ep_len:520 episode reward: total was -26.280000. running mean: -59.740968\n",
      "ep 25: ep_len:660 episode reward: total was -42.680000. running mean: -59.570358\n",
      "ep 25: ep_len:595 episode reward: total was -35.220000. running mean: -59.326854\n",
      "ep 25: ep_len:500 episode reward: total was 19.300000. running mean: -58.540586\n",
      "ep 25: ep_len:675 episode reward: total was 5.750000. running mean: -57.897680\n",
      "ep 25: ep_len:500 episode reward: total was 11.240000. running mean: -57.206303\n",
      "ep 25: ep_len:500 episode reward: total was 45.500000. running mean: -56.179240\n",
      "ep 25: ep_len:1260 episode reward: total was -97.690000. running mean: -56.594348\n",
      "ep 25: ep_len:720 episode reward: total was 6.790000. running mean: -55.960504\n",
      "ep 25: ep_len:500 episode reward: total was -3.120000. running mean: -55.432099\n",
      "ep 25: ep_len:595 episode reward: total was -31.180000. running mean: -55.189578\n",
      "ep 25: ep_len:655 episode reward: total was -4.800000. running mean: -54.685682\n",
      "ep 25: ep_len:805 episode reward: total was -8.540000. running mean: -54.224226\n",
      "ep 25: ep_len:180 episode reward: total was 16.500000. running mean: -53.516983\n",
      "ep 25: ep_len:2655 episode reward: total was -352.900000. running mean: -56.510814\n",
      "ep 25: ep_len:565 episode reward: total was -13.060000. running mean: -56.076305\n",
      "ep 25: ep_len:2001 episode reward: total was -202.070000. running mean: -57.536242\n",
      "ep 25: ep_len:500 episode reward: total was 21.750000. running mean: -56.743380\n",
      "ep 25: ep_len:575 episode reward: total was -37.280000. running mean: -56.548746\n",
      "ep 25: ep_len:670 episode reward: total was -6.790000. running mean: -56.051159\n",
      "ep 25: ep_len:765 episode reward: total was -16.700000. running mean: -55.657647\n",
      "ep 25: ep_len:865 episode reward: total was 13.550000. running mean: -54.965571\n",
      "ep 25: ep_len:257 episode reward: total was 22.500000. running mean: -54.190915\n",
      "ep 25: ep_len:985 episode reward: total was 2.920000. running mean: -53.619806\n",
      "ep 25: ep_len:590 episode reward: total was -16.040000. running mean: -53.244008\n",
      "ep 25: ep_len:725 episode reward: total was 27.340000. running mean: -52.438168\n",
      "ep 25: ep_len:500 episode reward: total was -0.970000. running mean: -51.923486\n",
      "ep 25: ep_len:1466 episode reward: total was -196.540000. running mean: -53.369651\n",
      "ep 25: ep_len:1000 episode reward: total was -6.470000. running mean: -52.900655\n",
      "ep 25: ep_len:575 episode reward: total was 9.770000. running mean: -52.273948\n",
      "ep 25: ep_len:1656 episode reward: total was -286.680000. running mean: -54.618009\n",
      "ep 25: ep_len:730 episode reward: total was -15.270000. running mean: -54.224528\n",
      "ep 25: ep_len:545 episode reward: total was -23.200000. running mean: -53.914283\n",
      "ep 25: ep_len:605 episode reward: total was -12.980000. running mean: -53.504940\n",
      "ep 25: ep_len:675 episode reward: total was -4.760000. running mean: -53.017491\n",
      "ep 25: ep_len:995 episode reward: total was 25.830000. running mean: -52.229016\n",
      "ep 25: ep_len:500 episode reward: total was -15.200000. running mean: -51.858726\n",
      "ep 25: ep_len:2379 episode reward: total was -241.250000. running mean: -53.752639\n",
      "ep 25: ep_len:715 episode reward: total was 16.270000. running mean: -53.052412\n",
      "ep 25: ep_len:595 episode reward: total was -13.150000. running mean: -52.653388\n",
      "ep 25: ep_len:645 episode reward: total was 3.920000. running mean: -52.087654\n",
      "ep 25: ep_len:870 episode reward: total was 2.280000. running mean: -51.543978\n",
      "ep 25: ep_len:500 episode reward: total was 13.360000. running mean: -50.894938\n",
      "ep 25: ep_len:855 episode reward: total was 29.100000. running mean: -50.094989\n",
      "ep 25: ep_len:500 episode reward: total was -27.020000. running mean: -49.864239\n",
      "ep 25: ep_len:500 episode reward: total was 24.760000. running mean: -49.117996\n",
      "ep 25: ep_len:570 episode reward: total was 10.710000. running mean: -48.519716\n",
      "ep 25: ep_len:500 episode reward: total was 8.820000. running mean: -47.946319\n",
      "ep 25: ep_len:500 episode reward: total was 32.310000. running mean: -47.143756\n",
      "ep 25: ep_len:500 episode reward: total was 34.270000. running mean: -46.329618\n",
      "ep 25: ep_len:500 episode reward: total was 22.760000. running mean: -45.638722\n",
      "ep 25: ep_len:525 episode reward: total was 19.260000. running mean: -44.989735\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 25: ep_len:500 episode reward: total was -3.420000. running mean: -44.574038\n",
      "ep 25: ep_len:675 episode reward: total was -100.710000. running mean: -45.135397\n",
      "ep 25: ep_len:1827 episode reward: total was -240.420000. running mean: -47.088243\n",
      "ep 25: ep_len:695 episode reward: total was -27.950000. running mean: -46.896861\n",
      "ep 25: ep_len:790 episode reward: total was -11.750000. running mean: -46.545392\n",
      "ep 25: ep_len:1720 episode reward: total was -95.590000. running mean: -47.035838\n",
      "ep 25: ep_len:540 episode reward: total was -16.140000. running mean: -46.726880\n",
      "ep 25: ep_len:700 episode reward: total was -14.810000. running mean: -46.407711\n",
      "ep 25: ep_len:745 episode reward: total was -4.620000. running mean: -45.989834\n",
      "ep 25: ep_len:500 episode reward: total was 19.420000. running mean: -45.335736\n",
      "ep 25: ep_len:510 episode reward: total was -16.200000. running mean: -45.044378\n",
      "ep 25: ep_len:710 episode reward: total was -5.700000. running mean: -44.650935\n",
      "ep 25: ep_len:570 episode reward: total was 23.050000. running mean: -43.973925\n",
      "ep 25: ep_len:182 episode reward: total was 16.500000. running mean: -43.369186\n",
      "ep 25: ep_len:980 episode reward: total was 4.110000. running mean: -42.894394\n",
      "ep 25: ep_len:500 episode reward: total was 7.540000. running mean: -42.390050\n",
      "ep 25: ep_len:500 episode reward: total was 19.790000. running mean: -41.768250\n",
      "ep 25: ep_len:505 episode reward: total was 7.580000. running mean: -41.274767\n",
      "ep 25: ep_len:500 episode reward: total was 36.750000. running mean: -40.494519\n",
      "ep 25: ep_len:80 episode reward: total was 6.500000. running mean: -40.024574\n",
      "ep 25: ep_len:885 episode reward: total was -28.580000. running mean: -39.910129\n",
      "ep 25: ep_len:595 episode reward: total was 3.720000. running mean: -39.473827\n",
      "ep 25: ep_len:615 episode reward: total was 22.720000. running mean: -38.851889\n",
      "ep 25: ep_len:1149 episode reward: total was -60.630000. running mean: -39.069670\n",
      "ep 25: ep_len:735 episode reward: total was 14.450000. running mean: -38.534473\n",
      "ep 25: ep_len:685 episode reward: total was -75.440000. running mean: -38.903529\n",
      "ep 25: ep_len:500 episode reward: total was -6.930000. running mean: -38.583793\n",
      "ep 25: ep_len:500 episode reward: total was 23.800000. running mean: -37.959955\n",
      "ep 25: ep_len:900 episode reward: total was -7.520000. running mean: -37.655556\n",
      "ep 25: ep_len:500 episode reward: total was -1.970000. running mean: -37.298700\n",
      "ep 25: ep_len:1005 episode reward: total was 7.190000. running mean: -36.853813\n",
      "ep 25: ep_len:500 episode reward: total was 15.750000. running mean: -36.327775\n",
      "ep 25: ep_len:1030 episode reward: total was 20.940000. running mean: -35.755097\n",
      "ep 25: ep_len:127 episode reward: total was 11.000000. running mean: -35.287546\n",
      "ep 25: ep_len:690 episode reward: total was 10.610000. running mean: -34.828571\n",
      "ep 25: ep_len:655 episode reward: total was 5.620000. running mean: -34.424085\n",
      "ep 25: ep_len:500 episode reward: total was 0.810000. running mean: -34.071744\n",
      "ep 25: ep_len:500 episode reward: total was 8.360000. running mean: -33.647427\n",
      "ep 25: ep_len:500 episode reward: total was 3.740000. running mean: -33.273553\n",
      "ep 25: ep_len:206 episode reward: total was 20.500000. running mean: -32.735817\n",
      "ep 25: ep_len:500 episode reward: total was -5.690000. running mean: -32.465359\n",
      "ep 25: ep_len:745 episode reward: total was -8.810000. running mean: -32.228805\n",
      "ep 25: ep_len:500 episode reward: total was -0.220000. running mean: -31.908717\n",
      "ep 25: ep_len:990 episode reward: total was 10.820000. running mean: -31.481430\n",
      "ep 25: ep_len:500 episode reward: total was -9.760000. running mean: -31.264216\n",
      "ep 25: ep_len:500 episode reward: total was 48.500000. running mean: -30.466574\n",
      "ep 25: ep_len:500 episode reward: total was 27.290000. running mean: -29.889008\n",
      "ep 25: ep_len:500 episode reward: total was 20.280000. running mean: -29.387318\n",
      "ep 25: ep_len:905 episode reward: total was 23.020000. running mean: -28.863245\n",
      "ep 25: ep_len:337 episode reward: total was -54.910000. running mean: -29.123712\n",
      "ep 25: ep_len:186 episode reward: total was 19.000000. running mean: -28.642475\n",
      "ep 25: ep_len:208 episode reward: total was 20.500000. running mean: -28.151050\n",
      "ep 25: ep_len:228 episode reward: total was 22.500000. running mean: -27.644540\n",
      "ep 25: ep_len:635 episode reward: total was -27.060000. running mean: -27.638695\n",
      "ep 25: ep_len:1666 episode reward: total was -273.490000. running mean: -30.097208\n",
      "ep 25: ep_len:500 episode reward: total was 22.820000. running mean: -29.568035\n",
      "ep 25: ep_len:500 episode reward: total was 19.060000. running mean: -29.081755\n",
      "ep 25: ep_len:715 episode reward: total was -8.200000. running mean: -28.872938\n",
      "ep 25: ep_len:790 episode reward: total was -52.000000. running mean: -29.104208\n",
      "ep 25: ep_len:1710 episode reward: total was 17.340000. running mean: -28.639766\n",
      "ep 25: ep_len:700 episode reward: total was -71.370000. running mean: -29.067068\n",
      "ep 25: ep_len:500 episode reward: total was 47.000000. running mean: -28.306398\n",
      "ep 25: ep_len:500 episode reward: total was 12.960000. running mean: -27.893734\n",
      "ep 25: ep_len:500 episode reward: total was 4.320000. running mean: -27.571596\n",
      "ep 25: ep_len:610 episode reward: total was -10.950000. running mean: -27.405380\n",
      "ep 25: ep_len:391 episode reward: total was 36.000000. running mean: -26.771327\n",
      "ep 25: ep_len:1360 episode reward: total was -88.750000. running mean: -27.391113\n",
      "ep 25: ep_len:960 episode reward: total was 15.700000. running mean: -26.960202\n",
      "ep 25: ep_len:625 episode reward: total was -14.390000. running mean: -26.834500\n",
      "ep 25: ep_len:500 episode reward: total was 2.240000. running mean: -26.543755\n",
      "ep 25: ep_len:500 episode reward: total was 16.940000. running mean: -26.108918\n",
      "ep 25: ep_len:715 episode reward: total was -40.030000. running mean: -26.248129\n",
      "ep 25: ep_len:500 episode reward: total was 18.780000. running mean: -25.797847\n",
      "ep 25: ep_len:500 episode reward: total was -15.330000. running mean: -25.693169\n",
      "ep 25: ep_len:575 episode reward: total was -10.100000. running mean: -25.537237\n",
      "ep 25: ep_len:193 episode reward: total was 19.000000. running mean: -25.091865\n",
      "ep 25: ep_len:177 episode reward: total was 16.000000. running mean: -24.680946\n",
      "ep 25: ep_len:364 episode reward: total was 27.000000. running mean: -24.164137\n",
      "ep 25: ep_len:500 episode reward: total was 0.160000. running mean: -23.920895\n",
      "ep 25: ep_len:750 episode reward: total was -1.560000. running mean: -23.697286\n",
      "ep 25: ep_len:685 episode reward: total was 27.260000. running mean: -23.187713\n",
      "ep 25: ep_len:500 episode reward: total was 21.320000. running mean: -22.742636\n",
      "ep 25: ep_len:750 episode reward: total was 9.230000. running mean: -22.422910\n",
      "ep 25: ep_len:500 episode reward: total was 50.000000. running mean: -21.698681\n",
      "ep 25: ep_len:500 episode reward: total was 29.310000. running mean: -21.188594\n",
      "ep 25: ep_len:500 episode reward: total was 5.800000. running mean: -20.918708\n",
      "ep 25: ep_len:421 episode reward: total was 16.780000. running mean: -20.541721\n",
      "ep 25: ep_len:1100 episode reward: total was 19.370000. running mean: -20.142604\n",
      "ep 25: ep_len:505 episode reward: total was 10.250000. running mean: -19.838678\n",
      "ep 25: ep_len:500 episode reward: total was 13.330000. running mean: -19.506991\n",
      "ep 25: ep_len:3756 episode reward: total was -429.720000. running mean: -23.609121\n",
      "ep 25: ep_len:830 episode reward: total was -13.540000. running mean: -23.508430\n",
      "ep 25: ep_len:505 episode reward: total was -6.110000. running mean: -23.334446\n",
      "ep 25: ep_len:735 episode reward: total was 5.930000. running mean: -23.041801\n",
      "ep 25: ep_len:1130 episode reward: total was -189.690000. running mean: -24.708283\n",
      "ep 25: ep_len:1075 episode reward: total was -109.730000. running mean: -25.558500\n",
      "ep 25: ep_len:595 episode reward: total was -35.720000. running mean: -25.660115\n",
      "ep 25: ep_len:1240 episode reward: total was -56.150000. running mean: -25.965014\n",
      "ep 25: ep_len:500 episode reward: total was 4.760000. running mean: -25.657764\n",
      "ep 25: ep_len:640 episode reward: total was -19.980000. running mean: -25.600986\n",
      "ep 25: ep_len:193 episode reward: total was 17.500000. running mean: -25.169976\n",
      "ep 25: ep_len:500 episode reward: total was -15.990000. running mean: -25.078177\n",
      "ep 25: ep_len:620 episode reward: total was -32.140000. running mean: -25.148795\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 25: ep_len:735 episode reward: total was -2.620000. running mean: -24.923507\n",
      "ep 25: ep_len:510 episode reward: total was -8.180000. running mean: -24.756072\n",
      "ep 25: ep_len:500 episode reward: total was 6.250000. running mean: -24.446011\n",
      "ep 25: ep_len:500 episode reward: total was 4.810000. running mean: -24.153451\n",
      "ep 25: ep_len:2096 episode reward: total was -138.640000. running mean: -25.298317\n",
      "ep 25: ep_len:251 episode reward: total was 25.000000. running mean: -24.795333\n",
      "ep 25: ep_len:1025 episode reward: total was -97.990000. running mean: -25.527280\n",
      "ep 25: ep_len:865 episode reward: total was -96.290000. running mean: -26.234907\n",
      "ep 25: ep_len:4595 episode reward: total was -794.040000. running mean: -33.912958\n",
      "ep 25: ep_len:500 episode reward: total was 12.320000. running mean: -33.450629\n",
      "ep 25: ep_len:680 episode reward: total was -2.210000. running mean: -33.138222\n",
      "ep 25: ep_len:500 episode reward: total was -9.260000. running mean: -32.899440\n",
      "ep 25: ep_len:710 episode reward: total was -62.260000. running mean: -33.193046\n",
      "ep 25: ep_len:175 episode reward: total was 16.500000. running mean: -32.696115\n",
      "ep 25: ep_len:662 episode reward: total was -57.290000. running mean: -32.942054\n",
      "ep 25: ep_len:500 episode reward: total was 4.270000. running mean: -32.569934\n",
      "ep 25: ep_len:615 episode reward: total was -3.870000. running mean: -32.282934\n",
      "ep 25: ep_len:530 episode reward: total was 26.340000. running mean: -31.696705\n",
      "ep 25: ep_len:119 episode reward: total was 11.500000. running mean: -31.264738\n",
      "ep 25: ep_len:500 episode reward: total was 18.260000. running mean: -30.769490\n",
      "ep 25: ep_len:635 episode reward: total was -9.890000. running mean: -30.560696\n",
      "ep 25: ep_len:660 episode reward: total was 3.290000. running mean: -30.222189\n",
      "ep 25: ep_len:535 episode reward: total was -5.040000. running mean: -29.970367\n",
      "ep 25: ep_len:505 episode reward: total was -12.170000. running mean: -29.792363\n",
      "ep 25: ep_len:500 episode reward: total was 19.760000. running mean: -29.296839\n",
      "ep 25: ep_len:500 episode reward: total was 20.860000. running mean: -28.795271\n",
      "ep 25: ep_len:525 episode reward: total was -70.680000. running mean: -29.214118\n",
      "ep 25: ep_len:670 episode reward: total was 0.280000. running mean: -28.919177\n",
      "ep 25: ep_len:555 episode reward: total was -10.020000. running mean: -28.730185\n",
      "ep 25: ep_len:500 episode reward: total was 15.410000. running mean: -28.288783\n",
      "ep 25: ep_len:500 episode reward: total was -3.360000. running mean: -28.039496\n",
      "ep 25: ep_len:660 episode reward: total was 19.770000. running mean: -27.561401\n",
      "ep 25: ep_len:500 episode reward: total was 8.100000. running mean: -27.204787\n",
      "ep 25: ep_len:500 episode reward: total was -24.200000. running mean: -27.174739\n",
      "ep 25: ep_len:500 episode reward: total was 1.320000. running mean: -26.889791\n",
      "ep 25: ep_len:535 episode reward: total was -12.600000. running mean: -26.746894\n",
      "ep 25: ep_len:715 episode reward: total was -3.670000. running mean: -26.516125\n",
      "ep 25: ep_len:249 episode reward: total was 23.000000. running mean: -26.020963\n",
      "ep 25: ep_len:2600 episode reward: total was -149.710000. running mean: -27.257854\n",
      "ep 25: ep_len:960 episode reward: total was -17.320000. running mean: -27.158475\n",
      "ep 25: ep_len:136 episode reward: total was 13.500000. running mean: -26.751890\n",
      "ep 25: ep_len:610 episode reward: total was -16.000000. running mean: -26.644372\n",
      "ep 25: ep_len:600 episode reward: total was 9.700000. running mean: -26.280928\n",
      "ep 25: ep_len:379 episode reward: total was 37.500000. running mean: -25.643119\n",
      "ep 25: ep_len:500 episode reward: total was 0.740000. running mean: -25.379287\n",
      "ep 25: ep_len:500 episode reward: total was -14.430000. running mean: -25.269794\n",
      "ep 25: ep_len:500 episode reward: total was 50.000000. running mean: -24.517097\n",
      "ep 25: ep_len:720 episode reward: total was -27.900000. running mean: -24.550926\n",
      "ep 25: ep_len:2480 episode reward: total was -69.720000. running mean: -25.002616\n",
      "ep 25: ep_len:500 episode reward: total was 6.710000. running mean: -24.685490\n",
      "ep 25: ep_len:865 episode reward: total was 4.930000. running mean: -24.389335\n",
      "ep 25: ep_len:1735 episode reward: total was 8.670000. running mean: -24.058742\n",
      "ep 25: ep_len:525 episode reward: total was -6.070000. running mean: -23.878854\n",
      "ep 25: ep_len:1000 episode reward: total was -24.690000. running mean: -23.886966\n",
      "ep 25: ep_len:860 episode reward: total was -12.430000. running mean: -23.772396\n",
      "ep 25: ep_len:500 episode reward: total was 50.000000. running mean: -23.034672\n",
      "ep 25: ep_len:1130 episode reward: total was -97.260000. running mean: -23.776926\n",
      "ep 25: ep_len:500 episode reward: total was 29.280000. running mean: -23.246356\n",
      "ep 25: ep_len:1805 episode reward: total was 34.740000. running mean: -22.666493\n",
      "ep 25: ep_len:165 episode reward: total was 15.000000. running mean: -22.289828\n",
      "ep 25: ep_len:500 episode reward: total was 4.800000. running mean: -22.018930\n",
      "ep 25: ep_len:500 episode reward: total was -2.140000. running mean: -21.820140\n",
      "ep 25: ep_len:500 episode reward: total was 22.300000. running mean: -21.378939\n",
      "ep 25: ep_len:1050 episode reward: total was -12.490000. running mean: -21.290049\n",
      "ep 25: ep_len:500 episode reward: total was 22.390000. running mean: -20.853249\n",
      "ep 25: ep_len:775 episode reward: total was -6.580000. running mean: -20.710516\n",
      "ep 25: ep_len:200 episode reward: total was 18.500000. running mean: -20.318411\n",
      "ep 25: ep_len:500 episode reward: total was 14.890000. running mean: -19.966327\n",
      "ep 25: ep_len:685 episode reward: total was 1.320000. running mean: -19.753464\n",
      "ep 25: ep_len:1260 episode reward: total was -157.110000. running mean: -21.127029\n",
      "ep 25: ep_len:500 episode reward: total was 30.810000. running mean: -20.607659\n",
      "ep 25: ep_len:955 episode reward: total was 4.500000. running mean: -20.356582\n",
      "ep 25: ep_len:500 episode reward: total was 30.820000. running mean: -19.844817\n",
      "ep 25: ep_len:268 episode reward: total was 26.500000. running mean: -19.381368\n",
      "ep 25: ep_len:995 episode reward: total was -14.190000. running mean: -19.329455\n",
      "ep 25: ep_len:500 episode reward: total was -39.750000. running mean: -19.533660\n",
      "ep 25: ep_len:850 episode reward: total was 0.430000. running mean: -19.334024\n",
      "ep 25: ep_len:802 episode reward: total was -69.850000. running mean: -19.839183\n",
      "ep 25: ep_len:1235 episode reward: total was 24.690000. running mean: -19.393892\n",
      "ep 25: ep_len:221 episode reward: total was 22.000000. running mean: -18.979953\n",
      "ep 25: ep_len:615 episode reward: total was 3.420000. running mean: -18.755953\n",
      "ep 25: ep_len:752 episode reward: total was -62.160000. running mean: -19.189994\n",
      "ep 25: ep_len:785 episode reward: total was -6.560000. running mean: -19.063694\n",
      "ep 25: ep_len:995 episode reward: total was 19.260000. running mean: -18.680457\n",
      "ep 25: ep_len:1360 episode reward: total was -46.370000. running mean: -18.957352\n",
      "ep 25: ep_len:1495 episode reward: total was -94.020000. running mean: -19.707979\n",
      "ep 25: ep_len:500 episode reward: total was 22.820000. running mean: -19.282699\n",
      "ep 25: ep_len:372 episode reward: total was -29.120000. running mean: -19.381072\n",
      "ep 25: ep_len:605 episode reward: total was -29.140000. running mean: -19.478661\n",
      "ep 25: ep_len:500 episode reward: total was 28.330000. running mean: -19.000574\n",
      "ep 25: ep_len:1385 episode reward: total was 32.280000. running mean: -18.487769\n",
      "ep 25: ep_len:645 episode reward: total was -56.330000. running mean: -18.866191\n",
      "ep 25: ep_len:500 episode reward: total was -6.180000. running mean: -18.739329\n",
      "ep 25: ep_len:535 episode reward: total was 17.930000. running mean: -18.372636\n",
      "ep 25: ep_len:690 episode reward: total was -15.710000. running mean: -18.346009\n",
      "ep 25: ep_len:725 episode reward: total was -6.680000. running mean: -18.229349\n",
      "ep 25: ep_len:500 episode reward: total was 45.500000. running mean: -17.592056\n",
      "ep 25: ep_len:203 episode reward: total was 20.000000. running mean: -17.216135\n",
      "ep 25: ep_len:620 episode reward: total was 3.590000. running mean: -17.008074\n",
      "ep 25: ep_len:1115 episode reward: total was -151.340000. running mean: -18.351393\n",
      "ep 25: ep_len:865 episode reward: total was -31.650000. running mean: -18.484379\n",
      "ep 25: ep_len:500 episode reward: total was -1.890000. running mean: -18.318436\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 25: ep_len:605 episode reward: total was 0.220000. running mean: -18.133051\n",
      "ep 25: ep_len:500 episode reward: total was 4.020000. running mean: -17.911521\n",
      "ep 25: ep_len:8345 episode reward: total was -1450.410000. running mean: -32.236505\n",
      "ep 25: ep_len:755 episode reward: total was -7.630000. running mean: -31.990440\n",
      "ep 25: ep_len:473 episode reward: total was 31.270000. running mean: -31.357836\n",
      "ep 25: ep_len:288 episode reward: total was 28.500000. running mean: -30.759258\n",
      "ep 25: ep_len:500 episode reward: total was -30.390000. running mean: -30.755565\n",
      "ep 25: ep_len:500 episode reward: total was 28.790000. running mean: -30.160109\n",
      "ep 25: ep_len:500 episode reward: total was 5.550000. running mean: -29.803008\n",
      "ep 25: ep_len:545 episode reward: total was -64.610000. running mean: -30.151078\n",
      "ep 25: ep_len:1253 episode reward: total was -118.900000. running mean: -31.038567\n",
      "ep 25: ep_len:500 episode reward: total was 26.340000. running mean: -30.464782\n",
      "ep 25: ep_len:500 episode reward: total was 28.360000. running mean: -29.876534\n",
      "ep 25: ep_len:580 episode reward: total was -13.030000. running mean: -29.708069\n",
      "ep 25: ep_len:500 episode reward: total was 20.800000. running mean: -29.202988\n",
      "ep 25: ep_len:695 episode reward: total was -0.680000. running mean: -28.917758\n",
      "ep 25: ep_len:500 episode reward: total was 23.860000. running mean: -28.389980\n",
      "ep 25: ep_len:800 episode reward: total was -10.570000. running mean: -28.211781\n",
      "ep 25: ep_len:500 episode reward: total was 2.850000. running mean: -27.901163\n",
      "ep 25: ep_len:500 episode reward: total was 14.120000. running mean: -27.480951\n",
      "ep 25: ep_len:650 episode reward: total was -38.140000. running mean: -27.587542\n",
      "ep 25: ep_len:500 episode reward: total was 21.870000. running mean: -27.092966\n",
      "ep 25: ep_len:500 episode reward: total was 15.870000. running mean: -26.663337\n",
      "ep 25: ep_len:575 episode reward: total was -32.520000. running mean: -26.721903\n",
      "ep 25: ep_len:535 episode reward: total was 15.630000. running mean: -26.298384\n",
      "ep 25: ep_len:540 episode reward: total was 0.910000. running mean: -26.026300\n",
      "ep 25: ep_len:505 episode reward: total was -22.270000. running mean: -25.988737\n",
      "ep 25: ep_len:500 episode reward: total was 30.260000. running mean: -25.426250\n",
      "ep 25: ep_len:960 episode reward: total was -32.470000. running mean: -25.496688\n",
      "ep 25: ep_len:965 episode reward: total was -170.830000. running mean: -26.950021\n",
      "ep 25: ep_len:500 episode reward: total was 8.330000. running mean: -26.597220\n",
      "ep 25: ep_len:500 episode reward: total was -23.810000. running mean: -26.569348\n",
      "ep 25: ep_len:950 episode reward: total was 24.680000. running mean: -26.056855\n",
      "ep 25: ep_len:500 episode reward: total was 13.540000. running mean: -25.660886\n",
      "ep 25: ep_len:500 episode reward: total was 26.280000. running mean: -25.141477\n",
      "ep 25: ep_len:540 episode reward: total was -8.060000. running mean: -24.970663\n",
      "ep 25: ep_len:500 episode reward: total was -38.960000. running mean: -25.110556\n",
      "ep 25: ep_len:920 episode reward: total was 1.720000. running mean: -24.842250\n",
      "ep 25: ep_len:825 episode reward: total was 6.480000. running mean: -24.529028\n",
      "ep 25: ep_len:500 episode reward: total was 50.000000. running mean: -23.783738\n",
      "ep 25: ep_len:500 episode reward: total was 24.380000. running mean: -23.302100\n",
      "ep 25: ep_len:1035 episode reward: total was 28.420000. running mean: -22.784879\n",
      "ep 25: ep_len:535 episode reward: total was -14.130000. running mean: -22.698330\n",
      "ep 25: ep_len:770 episode reward: total was -3.560000. running mean: -22.506947\n",
      "ep 25: ep_len:500 episode reward: total was 8.860000. running mean: -22.193278\n",
      "ep 25: ep_len:925 episode reward: total was -8.300000. running mean: -22.054345\n",
      "ep 25: ep_len:780 episode reward: total was -25.600000. running mean: -22.089801\n",
      "ep 25: ep_len:820 episode reward: total was 21.060000. running mean: -21.658303\n",
      "ep 25: ep_len:500 episode reward: total was 29.770000. running mean: -21.144020\n",
      "ep 25: ep_len:555 episode reward: total was 10.440000. running mean: -20.828180\n",
      "ep 25: ep_len:655 episode reward: total was 22.180000. running mean: -20.398098\n",
      "ep 25: ep_len:730 episode reward: total was -4.650000. running mean: -20.240617\n",
      "ep 25: ep_len:745 episode reward: total was -73.300000. running mean: -20.771211\n",
      "ep 25: ep_len:2270 episode reward: total was -328.790000. running mean: -23.851399\n",
      "ep 25: ep_len:620 episode reward: total was -23.050000. running mean: -23.843385\n",
      "ep 25: ep_len:2240 episode reward: total was -293.520000. running mean: -26.540151\n",
      "ep 25: ep_len:750 episode reward: total was -21.780000. running mean: -26.492550\n",
      "ep 25: ep_len:500 episode reward: total was 21.040000. running mean: -26.017224\n",
      "ep 25: ep_len:780 episode reward: total was -8.590000. running mean: -25.842952\n",
      "ep 25: ep_len:720 episode reward: total was -26.890000. running mean: -25.853422\n",
      "ep 25: ep_len:1197 episode reward: total was -95.370000. running mean: -26.548588\n",
      "ep 25: ep_len:505 episode reward: total was -7.120000. running mean: -26.354302\n",
      "ep 25: ep_len:500 episode reward: total was 9.380000. running mean: -25.996959\n",
      "ep 25: ep_len:525 episode reward: total was 12.000000. running mean: -25.616990\n",
      "ep 25: ep_len:208 episode reward: total was 20.500000. running mean: -25.155820\n",
      "ep 25: ep_len:500 episode reward: total was 4.870000. running mean: -24.855562\n",
      "ep 25: ep_len:500 episode reward: total was 29.280000. running mean: -24.314206\n",
      "ep 25: ep_len:870 episode reward: total was -12.450000. running mean: -24.195564\n",
      "ep 25: ep_len:1105 episode reward: total was -87.730000. running mean: -24.830908\n",
      "ep 25: ep_len:525 episode reward: total was -13.990000. running mean: -24.722499\n",
      "ep 25: ep_len:624 episode reward: total was -90.700000. running mean: -25.382274\n",
      "ep 25: ep_len:515 episode reward: total was -6.090000. running mean: -25.189352\n",
      "ep 25: ep_len:1637 episode reward: total was -228.660000. running mean: -27.224058\n",
      "ep 25: ep_len:500 episode reward: total was -8.140000. running mean: -27.033217\n",
      "ep 25: ep_len:525 episode reward: total was -16.200000. running mean: -26.924885\n",
      "ep 25: ep_len:500 episode reward: total was -7.340000. running mean: -26.729036\n",
      "ep 25: ep_len:500 episode reward: total was -30.940000. running mean: -26.771146\n",
      "ep 25: ep_len:2317 episode reward: total was -281.920000. running mean: -29.322635\n",
      "ep 25: ep_len:725 episode reward: total was -11.790000. running mean: -29.147308\n",
      "ep 25: ep_len:1645 episode reward: total was -153.310000. running mean: -30.388935\n",
      "ep 25: ep_len:665 episode reward: total was -27.150000. running mean: -30.356546\n",
      "ep 25: ep_len:500 episode reward: total was 16.240000. running mean: -29.890580\n",
      "ep 25: ep_len:500 episode reward: total was 25.270000. running mean: -29.338975\n",
      "ep 25: ep_len:2245 episode reward: total was -269.240000. running mean: -31.737985\n",
      "ep 25: ep_len:500 episode reward: total was -4.890000. running mean: -31.469505\n",
      "ep 25: ep_len:1465 episode reward: total was -145.560000. running mean: -32.610410\n",
      "ep 25: ep_len:955 episode reward: total was -96.110000. running mean: -33.245406\n",
      "ep 25: ep_len:800 episode reward: total was -14.610000. running mean: -33.059052\n",
      "ep 25: ep_len:482 episode reward: total was -17.250000. running mean: -32.900961\n",
      "ep 25: ep_len:735 episode reward: total was -0.600000. running mean: -32.577952\n",
      "ep 25: ep_len:500 episode reward: total was 26.280000. running mean: -31.989372\n",
      "ep 25: ep_len:443 episode reward: total was -5.220000. running mean: -31.721678\n",
      "ep 25: ep_len:2239 episode reward: total was -206.850000. running mean: -33.472962\n",
      "ep 25: ep_len:500 episode reward: total was 2.240000. running mean: -33.115832\n",
      "ep 25: ep_len:500 episode reward: total was -8.260000. running mean: -32.867274\n",
      "ep 25: ep_len:510 episode reward: total was -11.150000. running mean: -32.650101\n",
      "ep 25: ep_len:500 episode reward: total was 7.270000. running mean: -32.250900\n",
      "ep 25: ep_len:565 episode reward: total was -16.060000. running mean: -32.088991\n",
      "ep 25: ep_len:500 episode reward: total was -4.650000. running mean: -31.814601\n",
      "ep 25: ep_len:960 episode reward: total was 11.630000. running mean: -31.380155\n",
      "ep 25: ep_len:1873 episode reward: total was -243.640000. running mean: -33.502753\n",
      "ep 25: ep_len:765 episode reward: total was -32.860000. running mean: -33.496326\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 25: ep_len:244 episode reward: total was 24.000000. running mean: -32.921363\n",
      "ep 25: ep_len:1290 episode reward: total was -132.540000. running mean: -33.917549\n",
      "ep 25: ep_len:1287 episode reward: total was -178.820000. running mean: -35.366574\n",
      "ep 25: ep_len:750 episode reward: total was -5.280000. running mean: -35.065708\n",
      "ep 25: ep_len:560 episode reward: total was 32.840000. running mean: -34.386651\n",
      "ep 25: ep_len:500 episode reward: total was 31.790000. running mean: -33.724884\n",
      "ep 25: ep_len:1060 episode reward: total was -4.800000. running mean: -33.435635\n",
      "ep 25: ep_len:810 episode reward: total was 8.510000. running mean: -33.016179\n",
      "ep 25: ep_len:520 episode reward: total was -5.070000. running mean: -32.736717\n",
      "ep 25: ep_len:950 episode reward: total was 7.110000. running mean: -32.338250\n",
      "ep 25: ep_len:505 episode reward: total was 21.820000. running mean: -31.796668\n",
      "ep 25: ep_len:178 episode reward: total was 16.000000. running mean: -31.318701\n",
      "ep 25: ep_len:640 episode reward: total was -41.790000. running mean: -31.423414\n",
      "ep 25: ep_len:700 episode reward: total was -50.130000. running mean: -31.610480\n",
      "ep 25: ep_len:500 episode reward: total was -4.250000. running mean: -31.336875\n",
      "ep 25: ep_len:500 episode reward: total was -41.710000. running mean: -31.440606\n",
      "ep 25: ep_len:670 episode reward: total was -37.090000. running mean: -31.497100\n",
      "ep 25: ep_len:59 episode reward: total was 5.500000. running mean: -31.127129\n",
      "ep 25: ep_len:500 episode reward: total was 17.770000. running mean: -30.638158\n",
      "ep 25: ep_len:875 episode reward: total was -4.140000. running mean: -30.373176\n",
      "ep 25: ep_len:500 episode reward: total was 8.820000. running mean: -29.981244\n",
      "ep 25: ep_len:202 episode reward: total was 20.000000. running mean: -29.481432\n",
      "ep 25: ep_len:675 episode reward: total was 33.340000. running mean: -28.853218\n",
      "ep 25: ep_len:740 episode reward: total was -93.510000. running mean: -29.499786\n",
      "ep 25: ep_len:830 episode reward: total was 6.530000. running mean: -29.139488\n",
      "ep 25: ep_len:785 episode reward: total was -17.670000. running mean: -29.024793\n",
      "ep 25: ep_len:810 episode reward: total was -14.070000. running mean: -28.875245\n",
      "ep 25: ep_len:500 episode reward: total was 15.410000. running mean: -28.432392\n",
      "ep 25: ep_len:500 episode reward: total was 25.300000. running mean: -27.895069\n",
      "ep 25: ep_len:500 episode reward: total was 4.300000. running mean: -27.573118\n",
      "ep 25: ep_len:500 episode reward: total was 21.870000. running mean: -27.078687\n",
      "ep 25: ep_len:500 episode reward: total was -8.920000. running mean: -26.897100\n",
      "ep 25: ep_len:505 episode reward: total was -23.400000. running mean: -26.862129\n",
      "ep 25: ep_len:1275 episode reward: total was -74.260000. running mean: -27.336107\n",
      "ep 25: ep_len:218 episode reward: total was 21.500000. running mean: -26.847746\n",
      "ep 25: ep_len:550 episode reward: total was 14.160000. running mean: -26.437669\n",
      "ep 25: ep_len:535 episode reward: total was -11.100000. running mean: -26.284292\n",
      "ep 25: ep_len:910 episode reward: total was -34.140000. running mean: -26.362849\n",
      "ep 25: ep_len:500 episode reward: total was 6.680000. running mean: -26.032421\n",
      "ep 25: ep_len:188 episode reward: total was 18.500000. running mean: -25.587097\n",
      "ep 25: ep_len:790 episode reward: total was 14.220000. running mean: -25.189026\n",
      "ep 25: ep_len:670 episode reward: total was -14.870000. running mean: -25.085835\n",
      "ep 25: ep_len:630 episode reward: total was -3.240000. running mean: -24.867377\n",
      "ep 25: ep_len:221 episode reward: total was 20.500000. running mean: -24.413703\n",
      "ep 25: ep_len:505 episode reward: total was 17.810000. running mean: -23.991466\n",
      "ep 25: ep_len:500 episode reward: total was 3.290000. running mean: -23.718652\n",
      "ep 25: ep_len:850 episode reward: total was 14.530000. running mean: -23.336165\n",
      "ep 25: ep_len:795 episode reward: total was 15.500000. running mean: -22.947803\n",
      "ep 25: ep_len:500 episode reward: total was 23.830000. running mean: -22.480025\n",
      "ep 25: ep_len:835 episode reward: total was 13.210000. running mean: -22.123125\n",
      "ep 25: ep_len:1015 episode reward: total was 15.330000. running mean: -21.748594\n",
      "ep 25: ep_len:500 episode reward: total was 28.300000. running mean: -21.248108\n",
      "ep 25: ep_len:500 episode reward: total was -2.640000. running mean: -21.062027\n",
      "ep 25: ep_len:920 episode reward: total was -43.660000. running mean: -21.288007\n",
      "ep 25: ep_len:875 episode reward: total was -11.790000. running mean: -21.193027\n",
      "ep 25: ep_len:670 episode reward: total was -1.710000. running mean: -20.998196\n",
      "ep 25: ep_len:299 episode reward: total was 11.290000. running mean: -20.675314\n",
      "ep 25: ep_len:1104 episode reward: total was -65.090000. running mean: -21.119461\n",
      "ep 25: ep_len:735 episode reward: total was -41.000000. running mean: -21.318267\n",
      "ep 25: ep_len:615 episode reward: total was -18.010000. running mean: -21.285184\n",
      "ep 25: ep_len:257 episode reward: total was 25.500000. running mean: -20.817332\n",
      "ep 25: ep_len:920 episode reward: total was 19.770000. running mean: -20.411459\n",
      "ep 25: ep_len:2495 episode reward: total was -463.720000. running mean: -24.844544\n",
      "ep 25: ep_len:500 episode reward: total was 48.500000. running mean: -24.111099\n",
      "ep 25: ep_len:790 episode reward: total was 6.970000. running mean: -23.800288\n",
      "ep 25: ep_len:925 episode reward: total was 12.890000. running mean: -23.433385\n",
      "ep 25: ep_len:500 episode reward: total was 31.300000. running mean: -22.886051\n",
      "ep 25: ep_len:500 episode reward: total was -10.770000. running mean: -22.764890\n",
      "ep 25: ep_len:830 episode reward: total was -22.720000. running mean: -22.764442\n",
      "ep 25: ep_len:585 episode reward: total was -19.570000. running mean: -22.732497\n",
      "ep 25: ep_len:500 episode reward: total was 10.970000. running mean: -22.395472\n",
      "ep 25: ep_len:144 episode reward: total was 14.000000. running mean: -22.031517\n",
      "ep 25: ep_len:500 episode reward: total was -2.140000. running mean: -21.832602\n",
      "ep 25: ep_len:505 episode reward: total was -12.170000. running mean: -21.735976\n",
      "ep 25: ep_len:585 episode reward: total was -9.990000. running mean: -21.618517\n",
      "ep 25: ep_len:500 episode reward: total was 31.270000. running mean: -21.089631\n",
      "ep 25: ep_len:1855 episode reward: total was -290.250000. running mean: -23.781235\n",
      "ep 25: ep_len:810 episode reward: total was -21.660000. running mean: -23.760023\n",
      "ep 25: ep_len:1149 episode reward: total was -224.500000. running mean: -25.767422\n",
      "ep 25: ep_len:975 episode reward: total was 7.760000. running mean: -25.432148\n",
      "ep 25: ep_len:705 episode reward: total was -9.810000. running mean: -25.275927\n",
      "ep 25: ep_len:500 episode reward: total was -50.620000. running mean: -25.529367\n",
      "ep 25: ep_len:625 episode reward: total was 26.040000. running mean: -25.013674\n",
      "ep 25: ep_len:702 episode reward: total was -4.690000. running mean: -24.810437\n",
      "ep 25: ep_len:500 episode reward: total was 11.090000. running mean: -24.451433\n",
      "ep 25: ep_len:600 episode reward: total was -12.990000. running mean: -24.336818\n",
      "ep 25: ep_len:500 episode reward: total was 19.820000. running mean: -23.895250\n",
      "ep 25: ep_len:500 episode reward: total was -22.240000. running mean: -23.878698\n",
      "ep 25: ep_len:187 episode reward: total was 18.500000. running mean: -23.454911\n",
      "ep 25: ep_len:480 episode reward: total was 27.110000. running mean: -22.949262\n",
      "ep 25: ep_len:715 episode reward: total was -3.670000. running mean: -22.756469\n",
      "ep 25: ep_len:1560 episode reward: total was -72.330000. running mean: -23.252204\n",
      "ep 25: ep_len:268 episode reward: total was 26.500000. running mean: -22.754682\n",
      "ep 25: ep_len:1115 episode reward: total was 17.810000. running mean: -22.349035\n",
      "ep 25: ep_len:500 episode reward: total was 20.800000. running mean: -21.917545\n",
      "ep 25: ep_len:500 episode reward: total was -29.350000. running mean: -21.991870\n",
      "ep 25: ep_len:1170 episode reward: total was -7.740000. running mean: -21.849351\n",
      "ep 25: ep_len:500 episode reward: total was 5.250000. running mean: -21.578357\n",
      "ep 25: ep_len:710 episode reward: total was -6.190000. running mean: -21.424474\n",
      "ep 25: ep_len:580 episode reward: total was -29.160000. running mean: -21.501829\n",
      "ep 25: ep_len:535 episode reward: total was -45.460000. running mean: -21.741411\n",
      "ep 25: ep_len:630 episode reward: total was 4.190000. running mean: -21.482097\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 25: ep_len:177 episode reward: total was 17.500000. running mean: -21.092276\n",
      "ep 25: ep_len:840 episode reward: total was -17.560000. running mean: -21.056953\n",
      "ep 25: ep_len:500 episode reward: total was -25.340000. running mean: -21.099783\n",
      "ep 25: ep_len:500 episode reward: total was -17.310000. running mean: -21.061886\n",
      "ep 25: ep_len:725 episode reward: total was -3.650000. running mean: -20.887767\n",
      "ep 25: ep_len:545 episode reward: total was -25.270000. running mean: -20.931589\n",
      "ep 25: ep_len:515 episode reward: total was -23.260000. running mean: -20.954873\n",
      "ep 25: ep_len:550 episode reward: total was -26.190000. running mean: -21.007224\n",
      "ep 25: ep_len:680 episode reward: total was -34.010000. running mean: -21.137252\n",
      "ep 25: ep_len:885 episode reward: total was -25.550000. running mean: -21.181380\n",
      "ep 25: ep_len:985 episode reward: total was -77.870000. running mean: -21.748266\n",
      "ep 25: ep_len:500 episode reward: total was -10.340000. running mean: -21.634183\n",
      "ep 25: ep_len:835 episode reward: total was -84.860000. running mean: -22.266441\n",
      "ep 25: ep_len:510 episode reward: total was -2.060000. running mean: -22.064377\n",
      "ep 25: ep_len:875 episode reward: total was -7.920000. running mean: -21.922933\n",
      "ep 25: ep_len:755 episode reward: total was -53.170000. running mean: -22.235404\n",
      "ep 25: ep_len:500 episode reward: total was 5.730000. running mean: -21.955750\n",
      "ep 25: ep_len:805 episode reward: total was -80.250000. running mean: -22.538692\n",
      "ep 25: ep_len:500 episode reward: total was 9.900000. running mean: -22.214305\n",
      "ep 25: ep_len:950 episode reward: total was 0.490000. running mean: -21.987262\n",
      "ep 25: ep_len:615 episode reward: total was -1.850000. running mean: -21.785890\n",
      "ep 25: ep_len:765 episode reward: total was 8.220000. running mean: -21.485831\n",
      "ep 25: ep_len:500 episode reward: total was 10.800000. running mean: -21.162973\n",
      "ep 25: ep_len:500 episode reward: total was 21.230000. running mean: -20.739043\n",
      "ep 25: ep_len:595 episode reward: total was 8.830000. running mean: -20.443352\n",
      "ep 25: ep_len:770 episode reward: total was -9.620000. running mean: -20.335119\n",
      "ep 25: ep_len:284 episode reward: total was 28.500000. running mean: -19.846768\n",
      "ep 25: ep_len:555 episode reward: total was -8.030000. running mean: -19.728600\n",
      "ep 25: ep_len:500 episode reward: total was -20.320000. running mean: -19.734514\n",
      "ep 25: ep_len:500 episode reward: total was 16.300000. running mean: -19.374169\n",
      "ep 25: ep_len:500 episode reward: total was 24.780000. running mean: -18.932627\n",
      "ep 25: ep_len:1510 episode reward: total was -133.250000. running mean: -20.075801\n",
      "ep 25: ep_len:500 episode reward: total was 13.270000. running mean: -19.742343\n",
      "ep 25: ep_len:720 episode reward: total was -5.680000. running mean: -19.601719\n",
      "ep 25: ep_len:500 episode reward: total was -11.040000. running mean: -19.516102\n",
      "ep 25: ep_len:640 episode reward: total was -36.140000. running mean: -19.682341\n",
      "ep 25: ep_len:535 episode reward: total was -39.000000. running mean: -19.875518\n",
      "ep 25: ep_len:483 episode reward: total was 31.750000. running mean: -19.359263\n",
      "ep 25: ep_len:685 episode reward: total was -16.860000. running mean: -19.334270\n",
      "ep 25: ep_len:307 episode reward: total was 30.500000. running mean: -18.835927\n",
      "ep 25: ep_len:118 episode reward: total was 11.500000. running mean: -18.532568\n",
      "ep 25: ep_len:615 episode reward: total was -15.990000. running mean: -18.507142\n",
      "ep 25: ep_len:630 episode reward: total was 20.270000. running mean: -18.119371\n",
      "ep 25: ep_len:500 episode reward: total was 0.280000. running mean: -17.935377\n",
      "ep 25: ep_len:500 episode reward: total was 17.770000. running mean: -17.578323\n",
      "ep 25: ep_len:895 episode reward: total was 5.240000. running mean: -17.350140\n",
      "ep 25: ep_len:500 episode reward: total was 23.770000. running mean: -16.938939\n",
      "ep 25: ep_len:500 episode reward: total was 3.750000. running mean: -16.732049\n",
      "ep 25: ep_len:500 episode reward: total was 8.400000. running mean: -16.480729\n",
      "ep 25: ep_len:535 episode reward: total was -4.000000. running mean: -16.355922\n",
      "ep 25: ep_len:500 episode reward: total was -36.170000. running mean: -16.554062\n",
      "ep 25: ep_len:500 episode reward: total was -11.290000. running mean: -16.501422\n",
      "ep 25: ep_len:770 episode reward: total was 8.230000. running mean: -16.254108\n",
      "ep 25: ep_len:520 episode reward: total was -8.100000. running mean: -16.172567\n",
      "ep 25: ep_len:673 episode reward: total was -76.020000. running mean: -16.771041\n",
      "ep 25: ep_len:590 episode reward: total was 1.840000. running mean: -16.584930\n",
      "ep 25: ep_len:100 episode reward: total was 8.500000. running mean: -16.334081\n",
      "ep 25: ep_len:560 episode reward: total was -21.830000. running mean: -16.389040\n",
      "ep 25: ep_len:630 episode reward: total was -5.860000. running mean: -16.283750\n",
      "ep 25: ep_len:685 episode reward: total was 23.960000. running mean: -15.881312\n",
      "ep 25: ep_len:500 episode reward: total was 47.000000. running mean: -15.252499\n",
      "ep 25: ep_len:150 episode reward: total was 13.500000. running mean: -14.964974\n",
      "ep 25: ep_len:730 episode reward: total was -2.630000. running mean: -14.841625\n",
      "ep 25: ep_len:500 episode reward: total was 3.780000. running mean: -14.655408\n",
      "ep 25: ep_len:237 episode reward: total was 23.500000. running mean: -14.273854\n",
      "ep 25: ep_len:1195 episode reward: total was -110.260000. running mean: -15.233716\n",
      "ep 25: ep_len:302 episode reward: total was 30.000000. running mean: -14.781379\n",
      "ep 25: ep_len:635 episode reward: total was -13.620000. running mean: -14.769765\n",
      "ep 25: ep_len:500 episode reward: total was 5.240000. running mean: -14.569667\n",
      "ep 25: ep_len:500 episode reward: total was 18.380000. running mean: -14.240170\n",
      "ep 25: ep_len:500 episode reward: total was 0.250000. running mean: -14.095269\n",
      "ep 25: ep_len:611 episode reward: total was -96.830000. running mean: -14.922616\n",
      "ep 25: ep_len:500 episode reward: total was 0.770000. running mean: -14.765690\n",
      "ep 25: ep_len:2195 episode reward: total was -235.290000. running mean: -16.970933\n",
      "ep 25: ep_len:500 episode reward: total was 9.290000. running mean: -16.708324\n",
      "ep 25: ep_len:500 episode reward: total was -16.220000. running mean: -16.703440\n",
      "ep 25: ep_len:454 episode reward: total was 27.770000. running mean: -16.258706\n",
      "ep 25: ep_len:1140 episode reward: total was -100.790000. running mean: -17.104019\n",
      "ep 25: ep_len:1667 episode reward: total was -204.760000. running mean: -18.980579\n",
      "ep 25: ep_len:500 episode reward: total was 5.770000. running mean: -18.733073\n",
      "ep 25: ep_len:435 episode reward: total was 42.000000. running mean: -18.125742\n",
      "ep 25: ep_len:407 episode reward: total was 15.310000. running mean: -17.791385\n",
      "ep 25: ep_len:500 episode reward: total was 25.880000. running mean: -17.354671\n",
      "ep 25: ep_len:500 episode reward: total was 26.740000. running mean: -16.913724\n",
      "ep 25: ep_len:620 episode reward: total was 25.170000. running mean: -16.492887\n",
      "ep 25: ep_len:500 episode reward: total was 25.450000. running mean: -16.073458\n",
      "ep 25: ep_len:500 episode reward: total was 21.810000. running mean: -15.694624\n",
      "ep 25: ep_len:500 episode reward: total was -27.530000. running mean: -15.812977\n",
      "ep 25: ep_len:995 episode reward: total was -50.280000. running mean: -16.157648\n",
      "ep 25: ep_len:500 episode reward: total was -0.900000. running mean: -16.005071\n",
      "ep 25: ep_len:655 episode reward: total was 30.080000. running mean: -15.544220\n",
      "ep 25: ep_len:500 episode reward: total was 0.680000. running mean: -15.381978\n",
      "ep 25: ep_len:1255 episode reward: total was -82.380000. running mean: -16.051958\n",
      "ep 25: ep_len:500 episode reward: total was -12.820000. running mean: -16.019639\n",
      "ep 25: ep_len:695 episode reward: total was -27.030000. running mean: -16.129742\n",
      "ep 25: ep_len:800 episode reward: total was -15.620000. running mean: -16.124645\n",
      "ep 25: ep_len:600 episode reward: total was -1.480000. running mean: -15.978199\n",
      "ep 25: ep_len:500 episode reward: total was 17.340000. running mean: -15.645017\n",
      "ep 25: ep_len:670 episode reward: total was -85.500000. running mean: -16.343566\n",
      "ep 25: ep_len:141 episode reward: total was 14.000000. running mean: -16.040131\n",
      "ep 25: ep_len:1495 episode reward: total was -145.530000. running mean: -17.335029\n",
      "ep 25: ep_len:500 episode reward: total was 3.990000. running mean: -17.121779\n",
      "ep 25: ep_len:500 episode reward: total was -1.650000. running mean: -16.967061\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 25: ep_len:740 episode reward: total was -19.810000. running mean: -16.995491\n",
      "ep 25: ep_len:675 episode reward: total was -45.160000. running mean: -17.277136\n",
      "ep 25: ep_len:500 episode reward: total was -4.650000. running mean: -17.150864\n",
      "ep 25: ep_len:500 episode reward: total was 18.810000. running mean: -16.791256\n",
      "ep 25: ep_len:755 episode reward: total was -11.150000. running mean: -16.734843\n",
      "ep 25: ep_len:775 episode reward: total was -62.130000. running mean: -17.188795\n",
      "ep 25: ep_len:635 episode reward: total was -17.970000. running mean: -17.196607\n",
      "ep 25: ep_len:560 episode reward: total was -4.990000. running mean: -17.074541\n",
      "ep 25: ep_len:770 episode reward: total was 14.060000. running mean: -16.763195\n",
      "ep 25: ep_len:815 episode reward: total was 0.340000. running mean: -16.592163\n",
      "ep 25: ep_len:134 episode reward: total was 13.000000. running mean: -16.296242\n",
      "ep 25: ep_len:121 episode reward: total was 12.000000. running mean: -16.013279\n",
      "ep 25: ep_len:555 episode reward: total was -20.150000. running mean: -16.054647\n",
      "ep 25: ep_len:695 episode reward: total was -11.790000. running mean: -16.012000\n",
      "ep 25: ep_len:500 episode reward: total was 29.800000. running mean: -15.553880\n",
      "ep 25: ep_len:296 episode reward: total was 28.000000. running mean: -15.118341\n",
      "ep 25: ep_len:1090 episode reward: total was 10.260000. running mean: -14.864558\n",
      "ep 25: ep_len:500 episode reward: total was -4.460000. running mean: -14.760512\n",
      "ep 25: ep_len:830 episode reward: total was 15.530000. running mean: -14.457607\n",
      "ep 25: ep_len:264 episode reward: total was 24.500000. running mean: -14.068031\n",
      "ep 25: ep_len:500 episode reward: total was -5.720000. running mean: -13.984551\n",
      "ep 25: ep_len:500 episode reward: total was 24.200000. running mean: -13.602705\n",
      "ep 25: ep_len:580 episode reward: total was 5.400000. running mean: -13.412678\n",
      "ep 25: ep_len:159 episode reward: total was 12.500000. running mean: -13.153551\n",
      "ep 25: ep_len:540 episode reward: total was -5.030000. running mean: -13.072316\n",
      "ep 25: ep_len:628 episode reward: total was -35.180000. running mean: -13.293393\n",
      "ep 25: ep_len:500 episode reward: total was -57.690000. running mean: -13.737359\n",
      "ep 25: ep_len:565 episode reward: total was -23.800000. running mean: -13.837985\n",
      "ep 25: ep_len:167 episode reward: total was 16.500000. running mean: -13.534605\n",
      "ep 25: ep_len:500 episode reward: total was 25.240000. running mean: -13.146859\n",
      "ep 25: ep_len:540 episode reward: total was -11.120000. running mean: -13.126591\n",
      "ep 25: ep_len:500 episode reward: total was -38.370000. running mean: -13.379025\n",
      "ep 25: ep_len:2585 episode reward: total was -442.490000. running mean: -17.670135\n",
      "ep 25: ep_len:610 episode reward: total was 42.330000. running mean: -17.070133\n",
      "ep 25: ep_len:5453 episode reward: total was -903.990000. running mean: -25.939332\n",
      "ep 25: ep_len:924 episode reward: total was -56.770000. running mean: -26.247639\n",
      "ep 25: ep_len:585 episode reward: total was 0.360000. running mean: -25.981562\n",
      "ep 25: ep_len:1725 episode reward: total was -140.020000. running mean: -27.121947\n",
      "ep 25: ep_len:650 episode reward: total was -34.070000. running mean: -27.191427\n",
      "ep 25: ep_len:409 episode reward: total was -1.950000. running mean: -26.939013\n",
      "ep 25: ep_len:500 episode reward: total was 11.640000. running mean: -26.553223\n",
      "epsilon:0.010000 episode_count: 20499. steps_count: 14758120.000000\n",
      "ep 26: ep_len:500 episode reward: total was 12.780000. running mean: -26.159891\n",
      "ep 26: ep_len:810 episode reward: total was -27.200000. running mean: -26.170292\n",
      "ep 26: ep_len:500 episode reward: total was -3.900000. running mean: -25.947589\n",
      "ep 26: ep_len:985 episode reward: total was -10.540000. running mean: -25.793513\n",
      "ep 26: ep_len:505 episode reward: total was -10.150000. running mean: -25.637078\n",
      "ep 26: ep_len:635 episode reward: total was 19.510000. running mean: -25.185607\n",
      "ep 26: ep_len:750 episode reward: total was -11.680000. running mean: -25.050551\n",
      "ep 26: ep_len:500 episode reward: total was 12.780000. running mean: -24.672245\n",
      "ep 26: ep_len:795 episode reward: total was -31.790000. running mean: -24.743423\n",
      "ep 26: ep_len:935 episode reward: total was 16.570000. running mean: -24.330289\n",
      "ep 26: ep_len:500 episode reward: total was -2.810000. running mean: -24.115086\n",
      "ep 26: ep_len:500 episode reward: total was 15.840000. running mean: -23.715535\n",
      "ep 26: ep_len:500 episode reward: total was 24.850000. running mean: -23.229880\n",
      "ep 26: ep_len:149 episode reward: total was 14.500000. running mean: -22.852581\n",
      "ep 26: ep_len:1175 episode reward: total was -11.730000. running mean: -22.741355\n",
      "ep 26: ep_len:780 episode reward: total was -29.800000. running mean: -22.811941\n",
      "ep 26: ep_len:500 episode reward: total was 24.750000. running mean: -22.336322\n",
      "ep 26: ep_len:890 episode reward: total was 14.690000. running mean: -21.966059\n",
      "ep 26: ep_len:500 episode reward: total was 7.600000. running mean: -21.670398\n",
      "ep 26: ep_len:715 episode reward: total was -16.150000. running mean: -21.615194\n",
      "ep 26: ep_len:500 episode reward: total was 5.950000. running mean: -21.339542\n",
      "ep 26: ep_len:1777 episode reward: total was -117.680000. running mean: -22.302947\n",
      "ep 26: ep_len:1165 episode reward: total was -56.260000. running mean: -22.642517\n",
      "ep 26: ep_len:1590 episode reward: total was -94.460000. running mean: -23.360692\n",
      "ep 26: ep_len:500 episode reward: total was -2.810000. running mean: -23.155185\n",
      "ep 26: ep_len:144 episode reward: total was 14.000000. running mean: -22.783633\n",
      "ep 26: ep_len:615 episode reward: total was -8.210000. running mean: -22.637897\n",
      "ep 26: ep_len:500 episode reward: total was 1.690000. running mean: -22.394618\n",
      "ep 26: ep_len:16093 episode reward: total was -2916.050000. running mean: -51.331172\n",
      "ep 26: ep_len:500 episode reward: total was 9.650000. running mean: -50.721360\n",
      "ep 26: ep_len:520 episode reward: total was -11.130000. running mean: -50.325447\n",
      "ep 26: ep_len:780 episode reward: total was -5.200000. running mean: -49.874192\n",
      "ep 26: ep_len:600 episode reward: total was -2.730000. running mean: -49.402750\n",
      "ep 26: ep_len:830 episode reward: total was 17.580000. running mean: -48.732923\n",
      "ep 26: ep_len:330 episode reward: total was -0.450000. running mean: -48.250094\n",
      "ep 26: ep_len:500 episode reward: total was 21.660000. running mean: -47.550993\n",
      "ep 26: ep_len:715 episode reward: total was -15.790000. running mean: -47.233383\n",
      "ep 26: ep_len:605 episode reward: total was -58.430000. running mean: -47.345349\n",
      "ep 26: ep_len:500 episode reward: total was 32.690000. running mean: -46.544995\n",
      "ep 26: ep_len:500 episode reward: total was 9.530000. running mean: -45.984245\n",
      "ep 26: ep_len:500 episode reward: total was 7.730000. running mean: -45.447103\n",
      "ep 26: ep_len:272 episode reward: total was 25.500000. running mean: -44.737632\n",
      "ep 26: ep_len:770 episode reward: total was 8.820000. running mean: -44.202056\n",
      "ep 26: ep_len:1005 episode reward: total was 17.170000. running mean: -43.588335\n",
      "ep 26: ep_len:565 episode reward: total was -67.600000. running mean: -43.828452\n",
      "ep 26: ep_len:925 episode reward: total was 21.170000. running mean: -43.178467\n",
      "ep 26: ep_len:500 episode reward: total was 13.730000. running mean: -42.609382\n",
      "ep 26: ep_len:1070 episode reward: total was -4.410000. running mean: -42.227389\n",
      "ep 26: ep_len:910 episode reward: total was -81.020000. running mean: -42.615315\n",
      "ep 26: ep_len:165 episode reward: total was 15.000000. running mean: -42.039162\n",
      "ep 26: ep_len:500 episode reward: total was 17.920000. running mean: -41.439570\n",
      "ep 26: ep_len:271 episode reward: total was 24.000000. running mean: -40.785174\n",
      "ep 26: ep_len:685 episode reward: total was -25.480000. running mean: -40.632123\n",
      "ep 26: ep_len:500 episode reward: total was 22.020000. running mean: -40.005601\n",
      "ep 26: ep_len:500 episode reward: total was -20.990000. running mean: -39.815445\n",
      "ep 26: ep_len:615 episode reward: total was -3.870000. running mean: -39.455991\n",
      "ep 26: ep_len:500 episode reward: total was 25.760000. running mean: -38.803831\n",
      "ep 26: ep_len:980 episode reward: total was 19.280000. running mean: -38.222993\n",
      "ep 26: ep_len:500 episode reward: total was -67.330000. running mean: -38.514063\n",
      "ep 26: ep_len:446 episode reward: total was -86.000000. running mean: -38.988922\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 26: ep_len:890 episode reward: total was -39.680000. running mean: -38.995833\n",
      "ep 26: ep_len:500 episode reward: total was 21.810000. running mean: -38.387775\n",
      "ep 26: ep_len:555 episode reward: total was -17.120000. running mean: -38.175097\n",
      "ep 26: ep_len:154 episode reward: total was 15.500000. running mean: -37.638346\n",
      "ep 26: ep_len:500 episode reward: total was 18.230000. running mean: -37.079662\n",
      "ep 26: ep_len:451 episode reward: total was 19.140000. running mean: -36.517466\n",
      "ep 26: ep_len:1130 episode reward: total was -132.120000. running mean: -37.473491\n",
      "ep 26: ep_len:615 episode reward: total was -25.080000. running mean: -37.349556\n",
      "ep 26: ep_len:510 episode reward: total was -34.380000. running mean: -37.319861\n",
      "ep 26: ep_len:625 episode reward: total was -7.890000. running mean: -37.025562\n",
      "ep 26: ep_len:745 episode reward: total was -2.600000. running mean: -36.681306\n",
      "ep 26: ep_len:166 episode reward: total was 16.500000. running mean: -36.149493\n",
      "ep 26: ep_len:955 episode reward: total was -3.040000. running mean: -35.818398\n",
      "ep 26: ep_len:945 episode reward: total was 6.720000. running mean: -35.393014\n",
      "ep 26: ep_len:540 episode reward: total was -48.480000. running mean: -35.523884\n",
      "ep 26: ep_len:500 episode reward: total was -0.200000. running mean: -35.170645\n",
      "ep 26: ep_len:500 episode reward: total was 22.700000. running mean: -34.591939\n",
      "ep 26: ep_len:500 episode reward: total was -2.720000. running mean: -34.273220\n",
      "ep 26: ep_len:1935 episode reward: total was -228.480000. running mean: -36.215287\n",
      "ep 26: ep_len:635 episode reward: total was -6.860000. running mean: -35.921735\n",
      "ep 26: ep_len:840 episode reward: total was 15.150000. running mean: -35.411017\n",
      "ep 26: ep_len:472 episode reward: total was 47.000000. running mean: -34.586907\n",
      "ep 26: ep_len:650 episode reward: total was -10.350000. running mean: -34.344538\n",
      "ep 26: ep_len:79 episode reward: total was 7.500000. running mean: -33.926093\n",
      "ep 26: ep_len:500 episode reward: total was -6.700000. running mean: -33.653832\n",
      "ep 26: ep_len:500 episode reward: total was 6.750000. running mean: -33.249793\n",
      "ep 26: ep_len:560 episode reward: total was -20.140000. running mean: -33.118695\n",
      "ep 26: ep_len:630 episode reward: total was -31.110000. running mean: -33.098608\n",
      "ep 26: ep_len:500 episode reward: total was 0.690000. running mean: -32.760722\n",
      "ep 26: ep_len:500 episode reward: total was -0.670000. running mean: -32.439815\n",
      "ep 26: ep_len:500 episode reward: total was -9.540000. running mean: -32.210817\n",
      "ep 26: ep_len:500 episode reward: total was -0.330000. running mean: -31.892009\n",
      "ep 26: ep_len:1005 episode reward: total was -35.130000. running mean: -31.924389\n",
      "ep 26: ep_len:500 episode reward: total was 4.760000. running mean: -31.557545\n",
      "ep 26: ep_len:585 episode reward: total was 18.740000. running mean: -31.054569\n",
      "ep 26: ep_len:735 episode reward: total was -47.060000. running mean: -31.214624\n",
      "ep 26: ep_len:128 episode reward: total was 12.500000. running mean: -30.777477\n",
      "ep 26: ep_len:500 episode reward: total was -5.320000. running mean: -30.522903\n",
      "ep 26: ep_len:510 episode reward: total was -13.170000. running mean: -30.349374\n",
      "ep 26: ep_len:905 episode reward: total was 5.490000. running mean: -29.990980\n",
      "ep 26: ep_len:705 episode reward: total was -12.780000. running mean: -29.818870\n",
      "ep 26: ep_len:545 episode reward: total was 0.220000. running mean: -29.518481\n",
      "ep 26: ep_len:635 episode reward: total was -65.440000. running mean: -29.877697\n",
      "ep 26: ep_len:500 episode reward: total was 19.760000. running mean: -29.381320\n",
      "ep 26: ep_len:525 episode reward: total was -44.450000. running mean: -29.532006\n",
      "ep 26: ep_len:1095 episode reward: total was -41.500000. running mean: -29.651686\n",
      "ep 26: ep_len:710 episode reward: total was -12.030000. running mean: -29.475469\n",
      "ep 26: ep_len:260 episode reward: total was 24.500000. running mean: -28.935715\n",
      "ep 26: ep_len:500 episode reward: total was 19.270000. running mean: -28.453658\n",
      "ep 26: ep_len:289 episode reward: total was 27.000000. running mean: -27.899121\n",
      "ep 26: ep_len:162 episode reward: total was 14.500000. running mean: -27.475130\n",
      "ep 26: ep_len:500 episode reward: total was 9.170000. running mean: -27.108679\n",
      "ep 26: ep_len:500 episode reward: total was 19.270000. running mean: -26.644892\n",
      "ep 26: ep_len:500 episode reward: total was -3.100000. running mean: -26.409443\n",
      "ep 26: ep_len:500 episode reward: total was 4.840000. running mean: -26.096948\n",
      "ep 26: ep_len:735 episode reward: total was -24.410000. running mean: -26.080079\n",
      "ep 26: ep_len:810 episode reward: total was -22.670000. running mean: -26.045978\n",
      "ep 26: ep_len:730 episode reward: total was -20.810000. running mean: -25.993618\n",
      "ep 26: ep_len:500 episode reward: total was -20.260000. running mean: -25.936282\n",
      "ep 26: ep_len:755 episode reward: total was -26.300000. running mean: -25.939919\n",
      "ep 26: ep_len:500 episode reward: total was -0.790000. running mean: -25.688420\n",
      "ep 26: ep_len:500 episode reward: total was -18.790000. running mean: -25.619436\n",
      "ep 26: ep_len:8990 episode reward: total was -1664.980000. running mean: -42.013042\n",
      "ep 26: ep_len:750 episode reward: total was 1.560000. running mean: -41.577311\n",
      "ep 26: ep_len:790 episode reward: total was 2.820000. running mean: -41.133338\n",
      "ep 26: ep_len:1530 episode reward: total was -251.510000. running mean: -43.237105\n",
      "ep 26: ep_len:500 episode reward: total was 4.690000. running mean: -42.757834\n",
      "ep 26: ep_len:805 episode reward: total was -8.140000. running mean: -42.411655\n",
      "ep 26: ep_len:92 episode reward: total was 9.000000. running mean: -41.897539\n",
      "ep 26: ep_len:550 episode reward: total was -9.050000. running mean: -41.569063\n",
      "ep 26: ep_len:835 episode reward: total was -34.740000. running mean: -41.500773\n",
      "ep 26: ep_len:500 episode reward: total was 7.850000. running mean: -41.007265\n",
      "ep 26: ep_len:1200 episode reward: total was -208.280000. running mean: -42.679992\n",
      "ep 26: ep_len:795 episode reward: total was -6.920000. running mean: -42.322392\n",
      "ep 26: ep_len:1975 episode reward: total was -206.660000. running mean: -43.965769\n",
      "ep 26: ep_len:500 episode reward: total was 10.570000. running mean: -43.420411\n",
      "ep 26: ep_len:870 episode reward: total was -41.220000. running mean: -43.398407\n",
      "ep 26: ep_len:500 episode reward: total was -1.890000. running mean: -42.983323\n",
      "ep 26: ep_len:500 episode reward: total was -16.800000. running mean: -42.721489\n",
      "ep 26: ep_len:2620 episode reward: total was -377.650000. running mean: -46.070775\n",
      "ep 26: ep_len:500 episode reward: total was 23.800000. running mean: -45.372067\n",
      "ep 26: ep_len:650 episode reward: total was -53.290000. running mean: -45.451246\n",
      "ep 26: ep_len:1730 episode reward: total was -78.140000. running mean: -45.778134\n",
      "ep 26: ep_len:500 episode reward: total was 19.240000. running mean: -45.127952\n",
      "ep 26: ep_len:500 episode reward: total was 25.730000. running mean: -44.419373\n",
      "ep 26: ep_len:81 episode reward: total was 8.000000. running mean: -43.895179\n",
      "ep 26: ep_len:500 episode reward: total was 50.000000. running mean: -42.956227\n",
      "ep 26: ep_len:500 episode reward: total was 2.220000. running mean: -42.504465\n",
      "ep 26: ep_len:970 episode reward: total was 9.770000. running mean: -41.981720\n",
      "ep 26: ep_len:690 episode reward: total was 4.810000. running mean: -41.513803\n",
      "ep 26: ep_len:500 episode reward: total was 34.270000. running mean: -40.755965\n",
      "ep 26: ep_len:655 episode reward: total was -19.950000. running mean: -40.547905\n",
      "ep 26: ep_len:500 episode reward: total was -28.370000. running mean: -40.426126\n",
      "ep 26: ep_len:500 episode reward: total was 14.700000. running mean: -39.874865\n",
      "ep 26: ep_len:510 episode reward: total was 4.560000. running mean: -39.430517\n",
      "ep 26: ep_len:835 episode reward: total was 14.930000. running mean: -38.886911\n",
      "ep 26: ep_len:990 episode reward: total was 21.320000. running mean: -38.284842\n",
      "ep 26: ep_len:500 episode reward: total was 1.660000. running mean: -37.885394\n",
      "ep 26: ep_len:820 episode reward: total was -0.080000. running mean: -37.507340\n",
      "ep 26: ep_len:665 episode reward: total was -2.760000. running mean: -37.159866\n",
      "ep 26: ep_len:730 episode reward: total was 28.240000. running mean: -36.505868\n",
      "ep 26: ep_len:500 episode reward: total was 25.820000. running mean: -35.882609\n",
      "ep 26: ep_len:505 episode reward: total was 10.380000. running mean: -35.419983\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 26: ep_len:500 episode reward: total was 23.770000. running mean: -34.828083\n",
      "ep 26: ep_len:655 episode reward: total was -15.390000. running mean: -34.633702\n",
      "ep 26: ep_len:500 episode reward: total was 19.760000. running mean: -34.089765\n",
      "ep 26: ep_len:500 episode reward: total was -5.260000. running mean: -33.801468\n",
      "ep 26: ep_len:930 episode reward: total was -3.160000. running mean: -33.495053\n",
      "ep 26: ep_len:695 episode reward: total was 3.700000. running mean: -33.123102\n",
      "ep 26: ep_len:500 episode reward: total was 13.660000. running mean: -32.655271\n",
      "ep 26: ep_len:1125 episode reward: total was 6.870000. running mean: -32.260019\n",
      "ep 26: ep_len:500 episode reward: total was 9.100000. running mean: -31.846419\n",
      "ep 26: ep_len:670 episode reward: total was -35.070000. running mean: -31.878654\n",
      "ep 26: ep_len:710 episode reward: total was -5.700000. running mean: -31.616868\n",
      "ep 26: ep_len:610 episode reward: total was -27.110000. running mean: -31.571799\n",
      "ep 26: ep_len:500 episode reward: total was -3.760000. running mean: -31.293681\n",
      "ep 26: ep_len:505 episode reward: total was 16.280000. running mean: -30.817944\n",
      "ep 26: ep_len:855 episode reward: total was 6.050000. running mean: -30.449265\n",
      "ep 26: ep_len:500 episode reward: total was 17.310000. running mean: -29.971672\n",
      "ep 26: ep_len:500 episode reward: total was -18.130000. running mean: -29.853256\n",
      "ep 26: ep_len:720 episode reward: total was 10.350000. running mean: -29.451223\n",
      "ep 26: ep_len:500 episode reward: total was 20.770000. running mean: -28.949011\n",
      "ep 26: ep_len:745 episode reward: total was 24.320000. running mean: -28.416321\n",
      "ep 26: ep_len:705 episode reward: total was 29.230000. running mean: -27.839857\n",
      "ep 26: ep_len:48 episode reward: total was 4.500000. running mean: -27.516459\n",
      "ep 26: ep_len:510 episode reward: total was -6.100000. running mean: -27.302294\n",
      "ep 26: ep_len:500 episode reward: total was 25.790000. running mean: -26.771371\n",
      "ep 26: ep_len:500 episode reward: total was -7.160000. running mean: -26.575258\n",
      "ep 26: ep_len:500 episode reward: total was -0.610000. running mean: -26.315605\n",
      "ep 26: ep_len:565 episode reward: total was -30.720000. running mean: -26.359649\n",
      "ep 26: ep_len:705 episode reward: total was -9.260000. running mean: -26.188653\n",
      "ep 26: ep_len:284 episode reward: total was 26.500000. running mean: -25.661766\n",
      "ep 26: ep_len:750 episode reward: total was -16.730000. running mean: -25.572448\n",
      "ep 26: ep_len:565 episode reward: total was 22.320000. running mean: -25.093524\n",
      "ep 26: ep_len:500 episode reward: total was 21.530000. running mean: -24.627289\n",
      "ep 26: ep_len:1500 episode reward: total was -152.590000. running mean: -25.906916\n",
      "ep 26: ep_len:500 episode reward: total was 19.270000. running mean: -25.455147\n",
      "ep 26: ep_len:500 episode reward: total was 17.280000. running mean: -25.027795\n",
      "ep 26: ep_len:690 episode reward: total was -10.790000. running mean: -24.885417\n",
      "ep 26: ep_len:1045 episode reward: total was 16.170000. running mean: -24.474863\n",
      "ep 26: ep_len:710 episode reward: total was -10.750000. running mean: -24.337614\n",
      "ep 26: ep_len:810 episode reward: total was -6.470000. running mean: -24.158938\n",
      "ep 26: ep_len:755 episode reward: total was 12.060000. running mean: -23.796749\n",
      "ep 26: ep_len:555 episode reward: total was 2.290000. running mean: -23.535881\n",
      "ep 26: ep_len:690 episode reward: total was 31.630000. running mean: -22.984223\n",
      "ep 26: ep_len:1005 episode reward: total was -8.280000. running mean: -22.837180\n",
      "ep 26: ep_len:525 episode reward: total was -17.180000. running mean: -22.780608\n",
      "ep 26: ep_len:500 episode reward: total was 2.420000. running mean: -22.528602\n",
      "ep 26: ep_len:745 episode reward: total was -17.750000. running mean: -22.480816\n",
      "ep 26: ep_len:600 episode reward: total was 15.580000. running mean: -22.100208\n",
      "ep 26: ep_len:805 episode reward: total was -31.600000. running mean: -22.195206\n",
      "ep 26: ep_len:195 episode reward: total was 18.000000. running mean: -21.793254\n",
      "ep 26: ep_len:525 episode reward: total was 15.100000. running mean: -21.424322\n",
      "ep 26: ep_len:850 episode reward: total was 9.630000. running mean: -21.113778\n",
      "ep 26: ep_len:500 episode reward: total was 10.420000. running mean: -20.798441\n",
      "ep 26: ep_len:500 episode reward: total was 4.420000. running mean: -20.546256\n",
      "ep 26: ep_len:650 episode reward: total was -7.800000. running mean: -20.418794\n",
      "ep 26: ep_len:755 episode reward: total was 8.700000. running mean: -20.127606\n",
      "ep 26: ep_len:500 episode reward: total was 23.310000. running mean: -19.693230\n",
      "ep 26: ep_len:500 episode reward: total was 7.600000. running mean: -19.420297\n",
      "ep 26: ep_len:985 episode reward: total was 12.770000. running mean: -19.098394\n",
      "ep 26: ep_len:500 episode reward: total was 0.190000. running mean: -18.905510\n",
      "ep 26: ep_len:665 episode reward: total was -18.920000. running mean: -18.905655\n",
      "ep 26: ep_len:1995 episode reward: total was -142.980000. running mean: -20.146399\n",
      "ep 26: ep_len:417 episode reward: total was 24.330000. running mean: -19.701635\n",
      "ep 26: ep_len:660 episode reward: total was 9.240000. running mean: -19.412218\n",
      "ep 26: ep_len:473 episode reward: total was 24.780000. running mean: -18.970296\n",
      "ep 26: ep_len:580 episode reward: total was 11.400000. running mean: -18.666593\n",
      "ep 26: ep_len:570 episode reward: total was 8.900000. running mean: -18.390927\n",
      "ep 26: ep_len:920 episode reward: total was 15.310000. running mean: -18.053918\n",
      "ep 26: ep_len:500 episode reward: total was 7.780000. running mean: -17.795579\n",
      "ep 26: ep_len:820 episode reward: total was -25.680000. running mean: -17.874423\n",
      "ep 26: ep_len:434 episode reward: total was 41.500000. running mean: -17.280679\n",
      "ep 26: ep_len:910 episode reward: total was -13.880000. running mean: -17.246672\n",
      "ep 26: ep_len:810 episode reward: total was 27.670000. running mean: -16.797505\n",
      "ep 26: ep_len:935 episode reward: total was 9.070000. running mean: -16.538830\n",
      "ep 26: ep_len:1745 episode reward: total was -102.610000. running mean: -17.399542\n",
      "ep 26: ep_len:500 episode reward: total was 32.280000. running mean: -16.902747\n",
      "ep 26: ep_len:730 episode reward: total was -2.630000. running mean: -16.760019\n",
      "ep 26: ep_len:820 episode reward: total was 2.850000. running mean: -16.563919\n",
      "ep 26: ep_len:520 episode reward: total was 18.020000. running mean: -16.218080\n",
      "ep 26: ep_len:500 episode reward: total was 1.760000. running mean: -16.038299\n",
      "ep 26: ep_len:875 episode reward: total was 16.110000. running mean: -15.716816\n",
      "ep 26: ep_len:500 episode reward: total was 17.090000. running mean: -15.388748\n",
      "ep 26: ep_len:219 episode reward: total was 20.000000. running mean: -15.034860\n",
      "ep 26: ep_len:500 episode reward: total was 18.290000. running mean: -14.701612\n",
      "ep 26: ep_len:520 episode reward: total was 12.110000. running mean: -14.433496\n",
      "ep 26: ep_len:565 episode reward: total was -26.140000. running mean: -14.550561\n",
      "ep 26: ep_len:371 episode reward: total was 1.560000. running mean: -14.389455\n",
      "ep 26: ep_len:500 episode reward: total was -2.720000. running mean: -14.272760\n",
      "ep 26: ep_len:545 episode reward: total was -21.670000. running mean: -14.346733\n",
      "ep 26: ep_len:835 episode reward: total was -10.970000. running mean: -14.312966\n",
      "ep 26: ep_len:500 episode reward: total was 13.830000. running mean: -14.031536\n",
      "ep 26: ep_len:810 episode reward: total was -11.560000. running mean: -14.006820\n",
      "ep 26: ep_len:500 episode reward: total was 32.770000. running mean: -13.539052\n",
      "ep 26: ep_len:500 episode reward: total was -23.040000. running mean: -13.634062\n",
      "ep 26: ep_len:590 episode reward: total was 1.660000. running mean: -13.481121\n",
      "ep 26: ep_len:500 episode reward: total was 21.320000. running mean: -13.133110\n",
      "ep 26: ep_len:500 episode reward: total was -8.200000. running mean: -13.083779\n",
      "ep 26: ep_len:730 episode reward: total was 36.660000. running mean: -12.586341\n",
      "ep 26: ep_len:780 episode reward: total was -12.630000. running mean: -12.586778\n",
      "ep 26: ep_len:500 episode reward: total was 22.760000. running mean: -12.233310\n",
      "ep 26: ep_len:500 episode reward: total was 19.890000. running mean: -11.912077\n",
      "ep 26: ep_len:122 episode reward: total was 12.000000. running mean: -11.672956\n",
      "ep 26: ep_len:655 episode reward: total was -3.790000. running mean: -11.594126\n",
      "ep 26: ep_len:500 episode reward: total was 2.710000. running mean: -11.451085\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 26: ep_len:500 episode reward: total was 8.340000. running mean: -11.253174\n",
      "ep 26: ep_len:500 episode reward: total was 5.820000. running mean: -11.082443\n",
      "ep 26: ep_len:500 episode reward: total was 48.500000. running mean: -10.486618\n",
      "ep 26: ep_len:760 episode reward: total was 25.270000. running mean: -10.129052\n",
      "ep 26: ep_len:610 episode reward: total was -9.940000. running mean: -10.127161\n",
      "ep 26: ep_len:500 episode reward: total was 15.160000. running mean: -9.874290\n",
      "ep 26: ep_len:510 episode reward: total was -9.130000. running mean: -9.866847\n",
      "ep 26: ep_len:500 episode reward: total was 2.730000. running mean: -9.740878\n",
      "ep 26: ep_len:700 episode reward: total was -34.000000. running mean: -9.983470\n",
      "ep 26: ep_len:1205 episode reward: total was -146.110000. running mean: -11.344735\n",
      "ep 26: ep_len:500 episode reward: total was 0.830000. running mean: -11.222988\n",
      "ep 26: ep_len:540 episode reward: total was -0.990000. running mean: -11.120658\n",
      "ep 26: ep_len:580 episode reward: total was -3.940000. running mean: -11.048851\n",
      "ep 26: ep_len:260 episode reward: total was -41.470000. running mean: -11.353063\n",
      "ep 26: ep_len:630 episode reward: total was -12.930000. running mean: -11.368832\n",
      "ep 26: ep_len:1065 episode reward: total was -50.440000. running mean: -11.759544\n",
      "ep 26: ep_len:500 episode reward: total was 16.300000. running mean: -11.478948\n",
      "ep 26: ep_len:481 episode reward: total was 8.570000. running mean: -11.278459\n",
      "ep 26: ep_len:550 episode reward: total was -13.090000. running mean: -11.296574\n",
      "ep 26: ep_len:750 episode reward: total was -47.030000. running mean: -11.653908\n",
      "ep 26: ep_len:2079 episode reward: total was -103.570000. running mean: -12.573069\n",
      "ep 26: ep_len:1015 episode reward: total was 24.890000. running mean: -12.198439\n",
      "ep 26: ep_len:500 episode reward: total was 47.000000. running mean: -11.606454\n",
      "ep 26: ep_len:500 episode reward: total was -25.030000. running mean: -11.740690\n",
      "ep 26: ep_len:500 episode reward: total was 26.770000. running mean: -11.355583\n",
      "ep 26: ep_len:835 episode reward: total was 18.530000. running mean: -11.056727\n",
      "ep 26: ep_len:765 episode reward: total was -5.590000. running mean: -11.002060\n",
      "ep 26: ep_len:268 episode reward: total was 26.500000. running mean: -10.627039\n",
      "ep 26: ep_len:1020 episode reward: total was -26.290000. running mean: -10.783669\n",
      "ep 26: ep_len:500 episode reward: total was 22.790000. running mean: -10.447932\n",
      "ep 26: ep_len:565 episode reward: total was -15.320000. running mean: -10.496653\n",
      "ep 26: ep_len:500 episode reward: total was 8.670000. running mean: -10.304986\n",
      "ep 26: ep_len:230 episode reward: total was 21.500000. running mean: -9.986936\n",
      "ep 26: ep_len:243 episode reward: total was 24.000000. running mean: -9.647067\n",
      "ep 26: ep_len:500 episode reward: total was 15.100000. running mean: -9.399596\n",
      "ep 26: ep_len:715 episode reward: total was -36.970000. running mean: -9.675300\n",
      "ep 26: ep_len:500 episode reward: total was -14.720000. running mean: -9.725747\n",
      "ep 26: ep_len:535 episode reward: total was 0.080000. running mean: -9.627690\n",
      "ep 26: ep_len:925 episode reward: total was -15.110000. running mean: -9.682513\n",
      "ep 26: ep_len:202 episode reward: total was 20.000000. running mean: -9.385688\n",
      "ep 26: ep_len:295 episode reward: total was 26.500000. running mean: -9.026831\n",
      "ep 26: ep_len:422 episode reward: total was 34.000000. running mean: -8.596563\n",
      "ep 26: ep_len:500 episode reward: total was 7.170000. running mean: -8.438897\n",
      "ep 26: ep_len:610 episode reward: total was -1.860000. running mean: -8.373108\n",
      "ep 26: ep_len:178 episode reward: total was 16.000000. running mean: -8.129377\n",
      "ep 26: ep_len:500 episode reward: total was 25.820000. running mean: -7.789883\n",
      "ep 26: ep_len:895 episode reward: total was -26.540000. running mean: -7.977384\n",
      "ep 26: ep_len:128 episode reward: total was 11.500000. running mean: -7.782611\n",
      "ep 26: ep_len:500 episode reward: total was 16.450000. running mean: -7.540284\n",
      "ep 26: ep_len:277 episode reward: total was 23.000000. running mean: -7.234882\n",
      "ep 26: ep_len:505 episode reward: total was -11.160000. running mean: -7.274133\n",
      "ep 26: ep_len:500 episode reward: total was 12.750000. running mean: -7.073891\n",
      "ep 26: ep_len:960 episode reward: total was 10.300000. running mean: -6.900153\n",
      "ep 26: ep_len:810 episode reward: total was -16.610000. running mean: -6.997251\n",
      "ep 26: ep_len:705 episode reward: total was -15.780000. running mean: -7.085079\n",
      "ep 26: ep_len:510 episode reward: total was -10.140000. running mean: -7.115628\n",
      "ep 26: ep_len:1880 episode reward: total was -130.620000. running mean: -8.350671\n",
      "ep 26: ep_len:835 episode reward: total was -29.690000. running mean: -8.564065\n",
      "ep 26: ep_len:515 episode reward: total was -15.180000. running mean: -8.630224\n",
      "ep 26: ep_len:500 episode reward: total was 37.280000. running mean: -8.171122\n",
      "ep 26: ep_len:1300 episode reward: total was -165.710000. running mean: -9.746511\n",
      "ep 26: ep_len:1503 episode reward: total was -276.850000. running mean: -12.417546\n",
      "ep 26: ep_len:361 episode reward: total was 8.730000. running mean: -12.206070\n",
      "ep 26: ep_len:1040 episode reward: total was -3.290000. running mean: -12.116909\n",
      "ep 26: ep_len:500 episode reward: total was 14.280000. running mean: -11.852940\n",
      "ep 26: ep_len:975 episode reward: total was 27.080000. running mean: -11.463611\n",
      "ep 26: ep_len:384 episode reward: total was 35.000000. running mean: -10.998975\n",
      "ep 26: ep_len:510 episode reward: total was -25.460000. running mean: -11.143585\n",
      "ep 26: ep_len:500 episode reward: total was 17.580000. running mean: -10.856349\n",
      "ep 26: ep_len:835 episode reward: total was 5.850000. running mean: -10.689286\n",
      "ep 26: ep_len:505 episode reward: total was -4.090000. running mean: -10.623293\n",
      "ep 26: ep_len:224 episode reward: total was 19.000000. running mean: -10.327060\n",
      "ep 26: ep_len:500 episode reward: total was 25.300000. running mean: -9.970789\n",
      "ep 26: ep_len:500 episode reward: total was 9.280000. running mean: -9.778281\n",
      "ep 26: ep_len:178 episode reward: total was 16.000000. running mean: -9.520499\n",
      "ep 26: ep_len:294 episode reward: total was 6.230000. running mean: -9.362994\n",
      "ep 26: ep_len:1045 episode reward: total was -92.900000. running mean: -10.198364\n",
      "ep 26: ep_len:835 episode reward: total was -21.580000. running mean: -10.312180\n",
      "ep 26: ep_len:590 episode reward: total was -79.670000. running mean: -11.005758\n",
      "ep 26: ep_len:550 episode reward: total was 0.040000. running mean: -10.895301\n",
      "ep 26: ep_len:500 episode reward: total was 25.820000. running mean: -10.528148\n",
      "ep 26: ep_len:885 episode reward: total was -48.650000. running mean: -10.909366\n",
      "ep 26: ep_len:1020 episode reward: total was 25.280000. running mean: -10.547472\n",
      "ep 26: ep_len:164 episode reward: total was 16.000000. running mean: -10.281998\n",
      "ep 26: ep_len:683 episode reward: total was -21.900000. running mean: -10.398178\n",
      "ep 26: ep_len:500 episode reward: total was 10.820000. running mean: -10.185996\n",
      "ep 26: ep_len:580 episode reward: total was -1.920000. running mean: -10.103336\n",
      "ep 26: ep_len:1080 episode reward: total was -183.300000. running mean: -11.835303\n",
      "ep 26: ep_len:178 episode reward: total was 17.500000. running mean: -11.541950\n",
      "ep 26: ep_len:720 episode reward: total was -108.700000. running mean: -12.513530\n",
      "ep 26: ep_len:500 episode reward: total was 11.700000. running mean: -12.271395\n",
      "ep 26: ep_len:855 episode reward: total was 17.190000. running mean: -11.976781\n",
      "ep 26: ep_len:740 episode reward: total was 22.960000. running mean: -11.627413\n",
      "ep 26: ep_len:860 episode reward: total was 17.940000. running mean: -11.331739\n",
      "ep 26: ep_len:640 episode reward: total was 18.810000. running mean: -11.030322\n",
      "ep 26: ep_len:175 episode reward: total was 16.000000. running mean: -10.760018\n",
      "ep 26: ep_len:500 episode reward: total was 12.010000. running mean: -10.532318\n",
      "ep 26: ep_len:525 episode reward: total was 2.200000. running mean: -10.404995\n",
      "ep 26: ep_len:272 episode reward: total was 16.200000. running mean: -10.138945\n",
      "ep 26: ep_len:500 episode reward: total was 9.250000. running mean: -9.945056\n",
      "ep 26: ep_len:500 episode reward: total was 7.880000. running mean: -9.766805\n",
      "ep 26: ep_len:500 episode reward: total was 6.470000. running mean: -9.604437\n",
      "ep 26: ep_len:472 episode reward: total was -37.470000. running mean: -9.883093\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 26: ep_len:123 episode reward: total was 12.000000. running mean: -9.664262\n",
      "ep 26: ep_len:500 episode reward: total was -2.810000. running mean: -9.595719\n",
      "ep 26: ep_len:500 episode reward: total was -22.700000. running mean: -9.726762\n",
      "ep 26: ep_len:500 episode reward: total was 1.900000. running mean: -9.610494\n",
      "ep 26: ep_len:620 episode reward: total was 18.190000. running mean: -9.332489\n",
      "ep 26: ep_len:705 episode reward: total was -1.670000. running mean: -9.255864\n",
      "ep 26: ep_len:178 episode reward: total was 17.500000. running mean: -8.988306\n",
      "ep 26: ep_len:1665 episode reward: total was -36.110000. running mean: -9.259523\n",
      "ep 26: ep_len:500 episode reward: total was -6.510000. running mean: -9.232028\n",
      "ep 26: ep_len:194 episode reward: total was 19.000000. running mean: -8.949707\n",
      "ep 26: ep_len:715 episode reward: total was 14.200000. running mean: -8.718210\n",
      "ep 26: ep_len:500 episode reward: total was 10.660000. running mean: -8.524428\n",
      "ep 26: ep_len:500 episode reward: total was -15.210000. running mean: -8.591284\n",
      "ep 26: ep_len:500 episode reward: total was 4.450000. running mean: -8.460871\n",
      "ep 26: ep_len:500 episode reward: total was -8.650000. running mean: -8.462762\n",
      "ep 26: ep_len:670 episode reward: total was -13.860000. running mean: -8.516735\n",
      "ep 26: ep_len:2105 episode reward: total was -118.050000. running mean: -9.612067\n",
      "ep 26: ep_len:500 episode reward: total was 2.730000. running mean: -9.488647\n",
      "ep 26: ep_len:750 episode reward: total was -4.610000. running mean: -9.439860\n",
      "ep 26: ep_len:1843 episode reward: total was -98.360000. running mean: -10.329062\n",
      "ep 26: ep_len:735 episode reward: total was -101.600000. running mean: -11.241771\n",
      "ep 26: ep_len:715 episode reward: total was -28.920000. running mean: -11.418553\n",
      "ep 26: ep_len:341 episode reward: total was 34.500000. running mean: -10.959368\n",
      "ep 26: ep_len:500 episode reward: total was 48.500000. running mean: -10.364774\n",
      "ep 26: ep_len:1055 episode reward: total was -71.670000. running mean: -10.977826\n",
      "ep 26: ep_len:500 episode reward: total was 13.170000. running mean: -10.736348\n",
      "ep 26: ep_len:2051 episode reward: total was -74.730000. running mean: -11.376285\n",
      "ep 26: ep_len:500 episode reward: total was -9.700000. running mean: -11.359522\n",
      "ep 26: ep_len:500 episode reward: total was 48.500000. running mean: -10.760926\n",
      "ep 26: ep_len:500 episode reward: total was 13.800000. running mean: -10.515317\n",
      "ep 26: ep_len:545 episode reward: total was 27.290000. running mean: -10.137264\n",
      "ep 26: ep_len:500 episode reward: total was 20.340000. running mean: -9.832491\n",
      "ep 26: ep_len:101 episode reward: total was -12.500000. running mean: -9.859166\n",
      "ep 26: ep_len:217 episode reward: total was 21.500000. running mean: -9.545575\n",
      "ep 26: ep_len:770 episode reward: total was -6.590000. running mean: -9.516019\n",
      "ep 26: ep_len:935 episode reward: total was 16.430000. running mean: -9.256559\n",
      "ep 26: ep_len:685 episode reward: total was 1.320000. running mean: -9.150793\n",
      "ep 26: ep_len:770 episode reward: total was 20.090000. running mean: -8.858385\n",
      "ep 26: ep_len:158 episode reward: total was 16.000000. running mean: -8.609801\n",
      "ep 26: ep_len:500 episode reward: total was 27.290000. running mean: -8.250803\n",
      "ep 26: ep_len:895 episode reward: total was -20.480000. running mean: -8.373095\n",
      "ep 26: ep_len:500 episode reward: total was 27.820000. running mean: -8.011164\n",
      "ep 26: ep_len:271 episode reward: total was 27.000000. running mean: -7.661053\n",
      "ep 26: ep_len:1040 episode reward: total was -17.160000. running mean: -7.756042\n",
      "ep 26: ep_len:1119 episode reward: total was -138.210000. running mean: -9.060582\n",
      "ep 26: ep_len:500 episode reward: total was 18.040000. running mean: -8.789576\n",
      "ep 26: ep_len:500 episode reward: total was 3.010000. running mean: -8.671580\n",
      "ep 26: ep_len:910 episode reward: total was -20.450000. running mean: -8.789365\n",
      "ep 26: ep_len:610 episode reward: total was 4.940000. running mean: -8.652071\n",
      "ep 26: ep_len:500 episode reward: total was -7.160000. running mean: -8.637150\n",
      "ep 26: ep_len:422 episode reward: total was 5.820000. running mean: -8.492579\n",
      "ep 26: ep_len:500 episode reward: total was 6.770000. running mean: -8.339953\n",
      "ep 26: ep_len:500 episode reward: total was 48.500000. running mean: -7.771553\n",
      "ep 26: ep_len:1600 episode reward: total was -130.530000. running mean: -8.999138\n",
      "ep 26: ep_len:500 episode reward: total was 29.310000. running mean: -8.616046\n",
      "ep 26: ep_len:572 episode reward: total was -53.480000. running mean: -9.064686\n",
      "ep 26: ep_len:545 episode reward: total was -27.240000. running mean: -9.246439\n",
      "ep 26: ep_len:540 episode reward: total was 24.340000. running mean: -8.910575\n",
      "ep 26: ep_len:915 episode reward: total was -10.340000. running mean: -8.924869\n",
      "ep 26: ep_len:1990 episode reward: total was -58.030000. running mean: -9.415920\n",
      "ep 26: ep_len:625 episode reward: total was 16.220000. running mean: -9.159561\n",
      "ep 26: ep_len:500 episode reward: total was 22.540000. running mean: -8.842565\n",
      "ep 26: ep_len:831 episode reward: total was -11.270000. running mean: -8.866840\n",
      "ep 26: ep_len:715 episode reward: total was -2.660000. running mean: -8.804771\n",
      "ep 26: ep_len:675 episode reward: total was -46.170000. running mean: -9.178424\n",
      "ep 26: ep_len:755 episode reward: total was -28.030000. running mean: -9.366939\n",
      "ep 26: ep_len:500 episode reward: total was -33.480000. running mean: -9.608070\n",
      "ep 26: ep_len:835 episode reward: total was -15.550000. running mean: -9.667489\n",
      "ep 26: ep_len:500 episode reward: total was 7.170000. running mean: -9.499114\n",
      "ep 26: ep_len:730 episode reward: total was 1.800000. running mean: -9.386123\n",
      "ep 26: ep_len:500 episode reward: total was 13.170000. running mean: -9.160562\n",
      "ep 26: ep_len:1155 episode reward: total was 11.950000. running mean: -8.949456\n",
      "ep 26: ep_len:770 episode reward: total was -4.570000. running mean: -8.905662\n",
      "ep 26: ep_len:489 episode reward: total was 25.300000. running mean: -8.563605\n",
      "ep 26: ep_len:635 episode reward: total was -14.570000. running mean: -8.623669\n",
      "ep 26: ep_len:500 episode reward: total was -26.320000. running mean: -8.800633\n",
      "ep 26: ep_len:500 episode reward: total was 30.840000. running mean: -8.404226\n",
      "ep 26: ep_len:500 episode reward: total was 13.170000. running mean: -8.188484\n",
      "ep 26: ep_len:525 episode reward: total was 17.950000. running mean: -7.927099\n",
      "ep 26: ep_len:500 episode reward: total was -0.610000. running mean: -7.853928\n",
      "ep 26: ep_len:500 episode reward: total was 29.770000. running mean: -7.477689\n",
      "ep 26: ep_len:895 episode reward: total was -27.830000. running mean: -7.681212\n",
      "ep 26: ep_len:500 episode reward: total was 17.890000. running mean: -7.425500\n",
      "ep 26: ep_len:635 episode reward: total was -39.180000. running mean: -7.743045\n",
      "ep 26: ep_len:860 episode reward: total was 12.730000. running mean: -7.538314\n",
      "ep 26: ep_len:1346 episode reward: total was -174.590000. running mean: -9.208831\n",
      "ep 26: ep_len:500 episode reward: total was 16.510000. running mean: -8.951643\n",
      "ep 26: ep_len:855 episode reward: total was 16.620000. running mean: -8.695926\n",
      "ep 26: ep_len:500 episode reward: total was 11.610000. running mean: -8.492867\n",
      "ep 26: ep_len:3133 episode reward: total was -430.270000. running mean: -12.710639\n",
      "ep 26: ep_len:815 episode reward: total was -12.560000. running mean: -12.709132\n",
      "ep 26: ep_len:775 episode reward: total was 13.360000. running mean: -12.448441\n",
      "ep 26: ep_len:500 episode reward: total was 8.520000. running mean: -12.238756\n",
      "ep 26: ep_len:500 episode reward: total was 15.560000. running mean: -11.960769\n",
      "ep 26: ep_len:575 episode reward: total was 21.350000. running mean: -11.627661\n",
      "ep 26: ep_len:560 episode reward: total was -36.300000. running mean: -11.874385\n",
      "ep 26: ep_len:500 episode reward: total was 32.780000. running mean: -11.427841\n",
      "ep 26: ep_len:500 episode reward: total was 24.380000. running mean: -11.069762\n",
      "ep 26: ep_len:500 episode reward: total was -0.090000. running mean: -10.959965\n",
      "ep 26: ep_len:1875 episode reward: total was -247.250000. running mean: -13.322865\n",
      "ep 26: ep_len:500 episode reward: total was -17.290000. running mean: -13.362536\n",
      "ep 26: ep_len:500 episode reward: total was 26.830000. running mean: -12.960611\n",
      "ep 26: ep_len:500 episode reward: total was 10.410000. running mean: -12.726905\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 26: ep_len:625 episode reward: total was -56.940000. running mean: -13.169036\n",
      "ep 26: ep_len:219 episode reward: total was 22.000000. running mean: -12.817346\n",
      "ep 26: ep_len:243 episode reward: total was 21.000000. running mean: -12.479172\n",
      "ep 26: ep_len:500 episode reward: total was 11.860000. running mean: -12.235780\n",
      "ep 26: ep_len:1010 episode reward: total was 6.970000. running mean: -12.043723\n",
      "ep 26: ep_len:860 episode reward: total was -4.340000. running mean: -11.966685\n",
      "ep 26: ep_len:550 episode reward: total was -17.130000. running mean: -12.018318\n",
      "ep 26: ep_len:805 episode reward: total was -50.960000. running mean: -12.407735\n",
      "ep 26: ep_len:160 episode reward: total was 13.000000. running mean: -12.153658\n",
      "ep 26: ep_len:500 episode reward: total was 19.820000. running mean: -11.833921\n",
      "ep 26: ep_len:690 episode reward: total was -4.730000. running mean: -11.762882\n",
      "ep 26: ep_len:500 episode reward: total was 19.670000. running mean: -11.448553\n",
      "ep 26: ep_len:875 episode reward: total was -4.690000. running mean: -11.380968\n",
      "ep 26: ep_len:760 episode reward: total was -55.090000. running mean: -11.818058\n",
      "ep 26: ep_len:1430 episode reward: total was 30.290000. running mean: -11.396978\n",
      "ep 26: ep_len:630 episode reward: total was -33.130000. running mean: -11.614308\n",
      "ep 26: ep_len:865 episode reward: total was -9.880000. running mean: -11.596965\n",
      "ep 26: ep_len:450 episode reward: total was 19.200000. running mean: -11.288995\n",
      "ep 26: ep_len:505 episode reward: total was -23.670000. running mean: -11.412805\n",
      "ep 26: ep_len:500 episode reward: total was 10.630000. running mean: -11.192377\n",
      "ep 26: ep_len:900 episode reward: total was 7.820000. running mean: -11.002253\n",
      "ep 26: ep_len:695 episode reward: total was -79.460000. running mean: -11.686831\n",
      "ep 26: ep_len:500 episode reward: total was 48.500000. running mean: -11.084962\n",
      "ep 26: ep_len:500 episode reward: total was 15.930000. running mean: -10.814813\n",
      "ep 26: ep_len:2255 episode reward: total was -319.750000. running mean: -13.904165\n",
      "ep 26: ep_len:670 episode reward: total was -6.790000. running mean: -13.833023\n",
      "ep 26: ep_len:565 episode reward: total was -7.000000. running mean: -13.764693\n",
      "ep 26: ep_len:760 episode reward: total was -70.240000. running mean: -14.329446\n",
      "ep 26: ep_len:500 episode reward: total was -30.770000. running mean: -14.493851\n",
      "ep 26: ep_len:500 episode reward: total was 24.780000. running mean: -14.101113\n",
      "ep 26: ep_len:545 episode reward: total was -15.120000. running mean: -14.111302\n",
      "ep 26: ep_len:590 episode reward: total was 19.940000. running mean: -13.770789\n",
      "ep 26: ep_len:880 episode reward: total was -14.450000. running mean: -13.777581\n",
      "ep 26: ep_len:500 episode reward: total was 29.800000. running mean: -13.341805\n",
      "ep 26: ep_len:500 episode reward: total was 31.270000. running mean: -12.895687\n",
      "ep 26: ep_len:870 episode reward: total was -9.420000. running mean: -12.860930\n",
      "ep 26: ep_len:1160 episode reward: total was -63.380000. running mean: -13.366121\n",
      "ep 26: ep_len:535 episode reward: total was 17.440000. running mean: -13.058060\n",
      "ep 26: ep_len:593 episode reward: total was -92.260000. running mean: -13.850079\n",
      "ep 26: ep_len:520 episode reward: total was -5.070000. running mean: -13.762278\n",
      "ep 26: ep_len:695 episode reward: total was 17.700000. running mean: -13.447655\n",
      "ep 26: ep_len:505 episode reward: total was 28.770000. running mean: -13.025479\n",
      "ep 26: ep_len:680 episode reward: total was -2.260000. running mean: -12.917824\n",
      "ep 26: ep_len:600 episode reward: total was -15.010000. running mean: -12.938746\n",
      "ep 26: ep_len:500 episode reward: total was -29.470000. running mean: -13.104058\n",
      "ep 26: ep_len:500 episode reward: total was -0.330000. running mean: -12.976318\n",
      "ep 26: ep_len:720 episode reward: total was -2.650000. running mean: -12.873055\n",
      "ep 26: ep_len:500 episode reward: total was 19.300000. running mean: -12.551324\n",
      "ep 26: ep_len:630 episode reward: total was -21.010000. running mean: -12.635911\n",
      "ep 26: ep_len:525 episode reward: total was -11.120000. running mean: -12.620752\n",
      "ep 26: ep_len:500 episode reward: total was 17.680000. running mean: -12.317744\n",
      "ep 26: ep_len:500 episode reward: total was -3.670000. running mean: -12.231267\n",
      "ep 26: ep_len:500 episode reward: total was -4.430000. running mean: -12.153254\n",
      "ep 26: ep_len:1420 episode reward: total was -58.820000. running mean: -12.619922\n",
      "ep 26: ep_len:1030 episode reward: total was -36.370000. running mean: -12.857422\n",
      "ep 26: ep_len:500 episode reward: total was 8.980000. running mean: -12.639048\n",
      "ep 26: ep_len:505 episode reward: total was 7.180000. running mean: -12.440858\n",
      "ep 26: ep_len:685 episode reward: total was -4.740000. running mean: -12.363849\n",
      "ep 26: ep_len:500 episode reward: total was -16.770000. running mean: -12.407911\n",
      "ep 26: ep_len:481 episode reward: total was -5.240000. running mean: -12.336231\n",
      "ep 26: ep_len:585 episode reward: total was 14.780000. running mean: -12.065069\n",
      "ep 26: ep_len:715 episode reward: total was -21.850000. running mean: -12.162918\n",
      "ep 26: ep_len:466 episode reward: total was 46.500000. running mean: -11.576289\n",
      "ep 26: ep_len:209 episode reward: total was 20.500000. running mean: -11.255526\n",
      "ep 26: ep_len:500 episode reward: total was 15.070000. running mean: -10.992271\n",
      "ep 26: ep_len:635 episode reward: total was 26.860000. running mean: -10.613748\n",
      "ep 26: ep_len:500 episode reward: total was 11.060000. running mean: -10.397011\n",
      "ep 26: ep_len:630 episode reward: total was 1.290000. running mean: -10.280141\n",
      "ep 26: ep_len:735 episode reward: total was 4.330000. running mean: -10.134039\n",
      "ep 26: ep_len:605 episode reward: total was -35.200000. running mean: -10.384699\n",
      "ep 26: ep_len:2271 episode reward: total was -290.380000. running mean: -13.184652\n",
      "ep 26: ep_len:172 episode reward: total was 15.500000. running mean: -12.897806\n",
      "ep 26: ep_len:424 episode reward: total was 12.400000. running mean: -12.644827\n",
      "ep 26: ep_len:500 episode reward: total was 8.670000. running mean: -12.431679\n",
      "ep 26: ep_len:695 episode reward: total was -1.690000. running mean: -12.324262\n",
      "ep 26: ep_len:261 episode reward: total was 26.000000. running mean: -11.941020\n",
      "ep 26: ep_len:585 episode reward: total was 20.790000. running mean: -11.613710\n",
      "ep 26: ep_len:146 episode reward: total was 14.500000. running mean: -11.352572\n",
      "ep 26: ep_len:500 episode reward: total was 24.140000. running mean: -10.997647\n",
      "ep 26: ep_len:815 episode reward: total was -11.550000. running mean: -11.003170\n",
      "ep 26: ep_len:500 episode reward: total was -36.110000. running mean: -11.254239\n",
      "ep 26: ep_len:500 episode reward: total was -8.630000. running mean: -11.227996\n",
      "ep 26: ep_len:655 episode reward: total was 9.180000. running mean: -11.023916\n",
      "ep 26: ep_len:1560 episode reward: total was -242.140000. running mean: -13.335077\n",
      "ep 26: ep_len:178 episode reward: total was 17.500000. running mean: -13.026726\n",
      "ep 26: ep_len:520 episode reward: total was 0.600000. running mean: -12.890459\n",
      "ep 26: ep_len:500 episode reward: total was 7.090000. running mean: -12.690654\n",
      "ep 26: ep_len:171 episode reward: total was 17.000000. running mean: -12.393748\n",
      "ep 26: ep_len:500 episode reward: total was 13.210000. running mean: -12.137710\n",
      "ep 26: ep_len:151 episode reward: total was 15.000000. running mean: -11.866333\n",
      "ep 26: ep_len:632 episode reward: total was -88.190000. running mean: -12.629570\n",
      "ep 26: ep_len:1080 episode reward: total was -18.070000. running mean: -12.683974\n",
      "ep 26: ep_len:39 episode reward: total was 3.500000. running mean: -12.522135\n",
      "ep 26: ep_len:500 episode reward: total was 18.260000. running mean: -12.214313\n",
      "ep 26: ep_len:910 episode reward: total was -5.570000. running mean: -12.147870\n",
      "ep 26: ep_len:500 episode reward: total was 2.770000. running mean: -11.998691\n",
      "ep 26: ep_len:1412 episode reward: total was -189.860000. running mean: -13.777304\n",
      "ep 26: ep_len:273 episode reward: total was 27.000000. running mean: -13.369531\n",
      "ep 26: ep_len:500 episode reward: total was -14.440000. running mean: -13.380236\n",
      "ep 26: ep_len:680 episode reward: total was -2.730000. running mean: -13.273734\n",
      "ep 26: ep_len:985 episode reward: total was -1.160000. running mean: -13.152596\n",
      "ep 26: ep_len:770 episode reward: total was -7.600000. running mean: -13.097070\n",
      "ep 26: ep_len:560 episode reward: total was -15.090000. running mean: -13.117000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 26: ep_len:500 episode reward: total was 24.780000. running mean: -12.738030\n",
      "ep 26: ep_len:500 episode reward: total was 6.810000. running mean: -12.542549\n",
      "ep 26: ep_len:520 episode reward: total was 21.360000. running mean: -12.203524\n",
      "ep 26: ep_len:344 episode reward: total was 3.060000. running mean: -12.050889\n",
      "ep 26: ep_len:185 episode reward: total was 17.000000. running mean: -11.760380\n",
      "ep 26: ep_len:500 episode reward: total was 1.390000. running mean: -11.628876\n",
      "ep 26: ep_len:500 episode reward: total was -8.340000. running mean: -11.595987\n",
      "ep 26: ep_len:170 episode reward: total was 14.000000. running mean: -11.340027\n",
      "ep 26: ep_len:500 episode reward: total was 13.610000. running mean: -11.090527\n",
      "ep 26: ep_len:1395 episode reward: total was -190.170000. running mean: -12.881322\n",
      "ep 26: ep_len:500 episode reward: total was 1.940000. running mean: -12.733109\n",
      "ep 26: ep_len:775 episode reward: total was -44.250000. running mean: -13.048278\n",
      "ep 26: ep_len:815 episode reward: total was 18.650000. running mean: -12.731295\n",
      "ep 26: ep_len:600 episode reward: total was -5.920000. running mean: -12.663182\n",
      "ep 26: ep_len:670 episode reward: total was -15.860000. running mean: -12.695150\n",
      "ep 26: ep_len:232 episode reward: total was 23.000000. running mean: -12.338198\n",
      "ep 26: ep_len:500 episode reward: total was -7.460000. running mean: -12.289417\n",
      "ep 26: ep_len:500 episode reward: total was -0.260000. running mean: -12.169122\n",
      "ep 26: ep_len:500 episode reward: total was 22.740000. running mean: -11.820031\n",
      "ep 26: ep_len:500 episode reward: total was -18.970000. running mean: -11.891531\n",
      "ep 26: ep_len:500 episode reward: total was 17.280000. running mean: -11.599815\n",
      "ep 26: ep_len:610 episode reward: total was -3.360000. running mean: -11.517417\n",
      "ep 26: ep_len:555 episode reward: total was -42.340000. running mean: -11.825643\n",
      "ep 26: ep_len:540 episode reward: total was -11.090000. running mean: -11.818287\n",
      "ep 26: ep_len:500 episode reward: total was 0.870000. running mean: -11.691404\n",
      "ep 26: ep_len:2227 episode reward: total was -318.780000. running mean: -14.762290\n",
      "ep 26: ep_len:1165 episode reward: total was 13.780000. running mean: -14.476867\n",
      "ep 26: ep_len:935 episode reward: total was 13.830000. running mean: -14.193798\n",
      "ep 26: ep_len:297 episode reward: total was 8.780000. running mean: -13.964060\n",
      "ep 26: ep_len:1101 episode reward: total was -59.700000. running mean: -14.421420\n",
      "ep 26: ep_len:500 episode reward: total was 10.050000. running mean: -14.176705\n",
      "ep 26: ep_len:550 episode reward: total was 18.300000. running mean: -13.851938\n",
      "ep 26: ep_len:500 episode reward: total was -25.000000. running mean: -13.963419\n",
      "ep 26: ep_len:500 episode reward: total was 22.890000. running mean: -13.594885\n",
      "ep 26: ep_len:500 episode reward: total was 47.000000. running mean: -12.988936\n",
      "ep 26: ep_len:500 episode reward: total was 31.270000. running mean: -12.546347\n",
      "ep 26: ep_len:775 episode reward: total was -25.770000. running mean: -12.678583\n",
      "ep 26: ep_len:180 episode reward: total was 15.000000. running mean: -12.401797\n",
      "ep 26: ep_len:500 episode reward: total was 23.680000. running mean: -12.040979\n",
      "ep 26: ep_len:840 episode reward: total was 29.230000. running mean: -11.628270\n",
      "ep 26: ep_len:820 episode reward: total was -64.060000. running mean: -12.152587\n",
      "ep 26: ep_len:500 episode reward: total was -0.580000. running mean: -12.036861\n",
      "ep 26: ep_len:500 episode reward: total was 10.880000. running mean: -11.807692\n",
      "ep 26: ep_len:146 episode reward: total was 14.500000. running mean: -11.544615\n",
      "ep 26: ep_len:211 episode reward: total was 19.500000. running mean: -11.234169\n",
      "ep 26: ep_len:500 episode reward: total was 1.750000. running mean: -11.104328\n",
      "ep 26: ep_len:530 episode reward: total was -14.140000. running mean: -11.134684\n",
      "ep 26: ep_len:500 episode reward: total was 15.100000. running mean: -10.872338\n",
      "ep 26: ep_len:500 episode reward: total was -37.090000. running mean: -11.134514\n",
      "ep 26: ep_len:1825 episode reward: total was -293.340000. running mean: -13.956569\n",
      "ep 26: ep_len:825 episode reward: total was -8.500000. running mean: -13.902003\n",
      "ep 26: ep_len:580 episode reward: total was -23.130000. running mean: -13.994283\n",
      "ep 26: ep_len:850 episode reward: total was 1.900000. running mean: -13.835340\n",
      "ep 26: ep_len:785 episode reward: total was 5.660000. running mean: -13.640387\n",
      "ep 26: ep_len:722 episode reward: total was -62.240000. running mean: -14.126383\n",
      "ep 26: ep_len:640 episode reward: total was -20.990000. running mean: -14.195019\n",
      "ep 26: ep_len:675 episode reward: total was -0.700000. running mean: -14.060069\n",
      "ep 26: ep_len:500 episode reward: total was -3.680000. running mean: -13.956268\n",
      "ep 26: ep_len:600 episode reward: total was -7.940000. running mean: -13.896106\n",
      "ep 26: ep_len:2964 episode reward: total was -394.950000. running mean: -17.706645\n",
      "ep 26: ep_len:500 episode reward: total was -16.240000. running mean: -17.691978\n",
      "ep 26: ep_len:650 episode reward: total was -112.340000. running mean: -18.638458\n",
      "ep 26: ep_len:500 episode reward: total was -29.900000. running mean: -18.751074\n",
      "ep 26: ep_len:1640 episode reward: total was -138.660000. running mean: -19.950163\n",
      "ep 26: ep_len:810 episode reward: total was -19.640000. running mean: -19.947062\n",
      "ep 26: ep_len:500 episode reward: total was 19.240000. running mean: -19.555191\n",
      "ep 26: ep_len:860 episode reward: total was 1.310000. running mean: -19.346539\n",
      "ep 26: ep_len:645 episode reward: total was 28.720000. running mean: -18.865874\n",
      "ep 26: ep_len:500 episode reward: total was 10.790000. running mean: -18.569315\n",
      "ep 26: ep_len:500 episode reward: total was -27.450000. running mean: -18.658122\n",
      "ep 26: ep_len:500 episode reward: total was 23.800000. running mean: -18.233541\n",
      "ep 26: ep_len:500 episode reward: total was 19.910000. running mean: -17.852105\n",
      "ep 26: ep_len:500 episode reward: total was 7.200000. running mean: -17.601584\n",
      "ep 26: ep_len:840 episode reward: total was -41.800000. running mean: -17.843568\n",
      "ep 26: ep_len:755 episode reward: total was -16.720000. running mean: -17.832333\n",
      "ep 26: ep_len:500 episode reward: total was 17.030000. running mean: -17.483709\n",
      "ep 26: ep_len:705 episode reward: total was -20.860000. running mean: -17.517472\n",
      "ep 26: ep_len:500 episode reward: total was -6.910000. running mean: -17.411397\n",
      "ep 26: ep_len:500 episode reward: total was 24.270000. running mean: -16.994583\n",
      "ep 26: ep_len:500 episode reward: total was 21.780000. running mean: -16.606838\n",
      "ep 26: ep_len:575 episode reward: total was -8.990000. running mean: -16.530669\n",
      "ep 26: ep_len:1285 episode reward: total was 2.450000. running mean: -16.340863\n",
      "ep 26: ep_len:1035 episode reward: total was 15.200000. running mean: -16.025454\n",
      "ep 26: ep_len:560 episode reward: total was -0.700000. running mean: -15.872199\n",
      "ep 26: ep_len:500 episode reward: total was -26.430000. running mean: -15.977777\n",
      "ep 26: ep_len:462 episode reward: total was 44.500000. running mean: -15.373000\n",
      "ep 26: ep_len:500 episode reward: total was -7.270000. running mean: -15.291970\n",
      "ep 26: ep_len:530 episode reward: total was -27.270000. running mean: -15.411750\n",
      "ep 26: ep_len:237 episode reward: total was 10.680000. running mean: -15.150832\n",
      "ep 26: ep_len:500 episode reward: total was 15.810000. running mean: -14.841224\n",
      "ep 26: ep_len:1275 episode reward: total was -26.640000. running mean: -14.959212\n",
      "ep 26: ep_len:620 episode reward: total was 17.890000. running mean: -14.630720\n",
      "ep 26: ep_len:770 episode reward: total was -10.440000. running mean: -14.588813\n",
      "ep 26: ep_len:655 episode reward: total was -8.840000. running mean: -14.531324\n",
      "ep 26: ep_len:500 episode reward: total was 28.700000. running mean: -14.099011\n",
      "ep 26: ep_len:500 episode reward: total was 16.790000. running mean: -13.790121\n",
      "ep 26: ep_len:500 episode reward: total was 18.750000. running mean: -13.464720\n",
      "ep 26: ep_len:500 episode reward: total was 0.220000. running mean: -13.327873\n",
      "ep 26: ep_len:770 episode reward: total was -12.650000. running mean: -13.321094\n",
      "ep 26: ep_len:248 episode reward: total was 24.500000. running mean: -12.942883\n",
      "ep 26: ep_len:590 episode reward: total was -5.940000. running mean: -12.872854\n",
      "ep 26: ep_len:650 episode reward: total was -2.790000. running mean: -12.772026\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 26: ep_len:103 episode reward: total was 10.000000. running mean: -12.544305\n",
      "ep 26: ep_len:970 episode reward: total was -12.170000. running mean: -12.540562\n",
      "ep 26: ep_len:500 episode reward: total was 18.750000. running mean: -12.227657\n",
      "ep 26: ep_len:1330 episode reward: total was -144.850000. running mean: -13.553880\n",
      "ep 26: ep_len:660 episode reward: total was -21.160000. running mean: -13.629941\n",
      "ep 26: ep_len:500 episode reward: total was 14.810000. running mean: -13.345542\n",
      "ep 26: ep_len:590 episode reward: total was 5.000000. running mean: -13.162086\n",
      "ep 26: ep_len:500 episode reward: total was 22.300000. running mean: -12.807466\n",
      "ep 26: ep_len:3170 episode reward: total was -483.500000. running mean: -17.514391\n",
      "ep 26: ep_len:485 episode reward: total was 30.760000. running mean: -17.031647\n",
      "ep 26: ep_len:730 episode reward: total was -16.250000. running mean: -17.023831\n",
      "ep 26: ep_len:645 episode reward: total was -8.860000. running mean: -16.942192\n",
      "ep 26: ep_len:500 episode reward: total was 14.400000. running mean: -16.628770\n",
      "ep 26: ep_len:500 episode reward: total was -3.270000. running mean: -16.495183\n",
      "ep 26: ep_len:193 episode reward: total was 19.000000. running mean: -16.140231\n",
      "ep 26: ep_len:625 episode reward: total was -21.020000. running mean: -16.189028\n",
      "ep 26: ep_len:174 episode reward: total was 17.000000. running mean: -15.857138\n",
      "ep 26: ep_len:715 episode reward: total was -6.700000. running mean: -15.765567\n",
      "ep 26: ep_len:307 episode reward: total was 28.000000. running mean: -15.327911\n",
      "ep 26: ep_len:500 episode reward: total was 30.290000. running mean: -14.871732\n",
      "ep 26: ep_len:500 episode reward: total was 24.380000. running mean: -14.479215\n",
      "ep 26: ep_len:675 episode reward: total was -31.020000. running mean: -14.644623\n",
      "ep 26: ep_len:950 episode reward: total was 7.950000. running mean: -14.418676\n",
      "ep 26: ep_len:500 episode reward: total was 48.500000. running mean: -13.789490\n",
      "ep 26: ep_len:304 episode reward: total was 30.000000. running mean: -13.351595\n",
      "ep 26: ep_len:500 episode reward: total was -4.770000. running mean: -13.265779\n",
      "ep 26: ep_len:735 episode reward: total was -15.260000. running mean: -13.285721\n",
      "ep 26: ep_len:535 episode reward: total was -4.030000. running mean: -13.193164\n",
      "ep 26: ep_len:4290 episode reward: total was -653.020000. running mean: -19.591432\n",
      "ep 26: ep_len:510 episode reward: total was -3.070000. running mean: -19.426218\n",
      "ep 26: ep_len:168 episode reward: total was 15.000000. running mean: -19.081956\n",
      "ep 26: ep_len:500 episode reward: total was 15.020000. running mean: -18.740936\n",
      "ep 26: ep_len:720 episode reward: total was -18.900000. running mean: -18.742527\n",
      "ep 26: ep_len:334 episode reward: total was -64.500000. running mean: -19.200101\n",
      "ep 26: ep_len:645 episode reward: total was 7.830000. running mean: -18.929800\n",
      "ep 26: ep_len:1400 episode reward: total was -120.090000. running mean: -19.941402\n",
      "ep 26: ep_len:690 episode reward: total was -9.780000. running mean: -19.839788\n",
      "ep 26: ep_len:500 episode reward: total was 11.310000. running mean: -19.528290\n",
      "ep 26: ep_len:605 episode reward: total was -20.050000. running mean: -19.533508\n",
      "ep 26: ep_len:515 episode reward: total was -11.140000. running mean: -19.449573\n",
      "ep 26: ep_len:690 episode reward: total was 31.280000. running mean: -18.942277\n",
      "ep 26: ep_len:500 episode reward: total was 11.370000. running mean: -18.639154\n",
      "ep 26: ep_len:500 episode reward: total was 4.290000. running mean: -18.409862\n",
      "ep 26: ep_len:500 episode reward: total was -6.760000. running mean: -18.293364\n",
      "ep 26: ep_len:620 episode reward: total was -7.900000. running mean: -18.189430\n",
      "ep 26: ep_len:1920 episode reward: total was -238.610000. running mean: -20.393636\n",
      "ep 26: ep_len:585 episode reward: total was -13.020000. running mean: -20.319900\n",
      "ep 26: ep_len:500 episode reward: total was -21.790000. running mean: -20.334601\n",
      "ep 26: ep_len:447 episode reward: total was 26.240000. running mean: -19.868855\n",
      "ep 26: ep_len:1952 episode reward: total was -189.330000. running mean: -21.563466\n",
      "ep 26: ep_len:500 episode reward: total was 29.770000. running mean: -21.050131\n",
      "ep 26: ep_len:535 episode reward: total was 8.320000. running mean: -20.756430\n",
      "ep 26: ep_len:975 episode reward: total was -109.670000. running mean: -21.645566\n",
      "ep 26: ep_len:433 episode reward: total was 0.240000. running mean: -21.426710\n",
      "ep 26: ep_len:500 episode reward: total was 21.320000. running mean: -20.999243\n",
      "ep 26: ep_len:500 episode reward: total was 34.790000. running mean: -20.441351\n",
      "ep 26: ep_len:500 episode reward: total was -29.350000. running mean: -20.530437\n",
      "ep 26: ep_len:790 episode reward: total was 17.240000. running mean: -20.152733\n",
      "ep 26: ep_len:500 episode reward: total was 23.190000. running mean: -19.719305\n",
      "ep 26: ep_len:500 episode reward: total was -18.300000. running mean: -19.705112\n",
      "ep 26: ep_len:980 episode reward: total was -69.330000. running mean: -20.201361\n",
      "ep 26: ep_len:750 episode reward: total was 9.970000. running mean: -19.899648\n",
      "ep 26: ep_len:500 episode reward: total was 19.540000. running mean: -19.505251\n",
      "ep 26: ep_len:500 episode reward: total was 7.720000. running mean: -19.232999\n",
      "ep 26: ep_len:705 episode reward: total was 31.620000. running mean: -18.724469\n",
      "ep 26: ep_len:800 episode reward: total was 0.960000. running mean: -18.527624\n",
      "ep 26: ep_len:810 episode reward: total was -6.440000. running mean: -18.406748\n",
      "ep 26: ep_len:810 episode reward: total was -23.680000. running mean: -18.459480\n",
      "ep 26: ep_len:660 episode reward: total was 12.020000. running mean: -18.154685\n",
      "ep 26: ep_len:174 episode reward: total was 15.500000. running mean: -17.818139\n",
      "ep 26: ep_len:620 episode reward: total was 1.840000. running mean: -17.621557\n",
      "ep 26: ep_len:705 episode reward: total was 23.000000. running mean: -17.215342\n",
      "ep 26: ep_len:159 episode reward: total was 15.500000. running mean: -16.888188\n",
      "ep 26: ep_len:635 episode reward: total was 29.340000. running mean: -16.425906\n",
      "ep 26: ep_len:945 episode reward: total was -102.080000. running mean: -17.282447\n",
      "ep 26: ep_len:500 episode reward: total was 29.770000. running mean: -16.811923\n",
      "ep 26: ep_len:965 episode reward: total was 12.880000. running mean: -16.515004\n",
      "ep 26: ep_len:825 episode reward: total was -16.870000. running mean: -16.518553\n",
      "ep 26: ep_len:555 episode reward: total was -7.020000. running mean: -16.423568\n",
      "ep 26: ep_len:500 episode reward: total was 27.350000. running mean: -15.985832\n",
      "ep 26: ep_len:1000 episode reward: total was -25.740000. running mean: -16.083374\n",
      "ep 26: ep_len:865 episode reward: total was -61.920000. running mean: -16.541740\n",
      "ep 26: ep_len:690 episode reward: total was -21.900000. running mean: -16.595323\n",
      "ep 26: ep_len:500 episode reward: total was 12.070000. running mean: -16.308670\n",
      "ep 26: ep_len:500 episode reward: total was -3.420000. running mean: -16.179783\n",
      "ep 26: ep_len:340 episode reward: total was -66.990000. running mean: -16.687885\n",
      "ep 26: ep_len:500 episode reward: total was 19.760000. running mean: -16.323406\n",
      "ep 26: ep_len:745 episode reward: total was -4.620000. running mean: -16.206372\n",
      "ep 26: ep_len:500 episode reward: total was 31.330000. running mean: -15.731008\n",
      "ep 26: ep_len:740 episode reward: total was -10.690000. running mean: -15.680598\n",
      "ep 26: ep_len:740 episode reward: total was -42.000000. running mean: -15.943792\n",
      "ep 26: ep_len:500 episode reward: total was 19.790000. running mean: -15.586454\n",
      "ep 26: ep_len:250 episode reward: total was 23.500000. running mean: -15.195590\n",
      "ep 26: ep_len:525 episode reward: total was 26.850000. running mean: -14.775134\n",
      "ep 26: ep_len:520 episode reward: total was -8.100000. running mean: -14.708383\n",
      "ep 26: ep_len:525 episode reward: total was -10.110000. running mean: -14.662399\n",
      "ep 26: ep_len:135 episode reward: total was 1.500000. running mean: -14.500775\n",
      "ep 26: ep_len:550 episode reward: total was -8.040000. running mean: -14.436167\n",
      "ep 26: ep_len:500 episode reward: total was 24.380000. running mean: -14.048005\n",
      "ep 26: ep_len:525 episode reward: total was -53.140000. running mean: -14.438925\n",
      "ep 26: ep_len:530 episode reward: total was -55.550000. running mean: -14.850036\n",
      "ep 26: ep_len:500 episode reward: total was 21.720000. running mean: -14.484336\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 26: ep_len:500 episode reward: total was -12.300000. running mean: -14.462492\n",
      "ep 26: ep_len:720 episode reward: total was -38.000000. running mean: -14.697867\n",
      "ep 26: ep_len:2550 episode reward: total was -424.500000. running mean: -18.795889\n",
      "ep 26: ep_len:500 episode reward: total was -5.720000. running mean: -18.665130\n",
      "ep 26: ep_len:500 episode reward: total was 50.500000. running mean: -17.973479\n",
      "ep 26: ep_len:870 episode reward: total was -55.860000. running mean: -18.352344\n",
      "ep 26: ep_len:550 episode reward: total was -14.280000. running mean: -18.311620\n",
      "ep 26: ep_len:1355 episode reward: total was -141.490000. running mean: -19.543404\n",
      "ep 26: ep_len:500 episode reward: total was 50.000000. running mean: -18.847970\n",
      "ep 26: ep_len:500 episode reward: total was 50.000000. running mean: -18.159490\n",
      "ep 26: ep_len:500 episode reward: total was 19.450000. running mean: -17.783396\n",
      "ep 26: ep_len:215 episode reward: total was 15.510000. running mean: -17.450462\n",
      "epsilon:0.010000 episode_count: 21290. steps_count: 15300569.000000\n",
      "ep 27: ep_len:700 episode reward: total was 0.960000. running mean: -17.266357\n",
      "ep 27: ep_len:800 episode reward: total was -10.570000. running mean: -17.199393\n",
      "ep 27: ep_len:2112 episode reward: total was -405.500000. running mean: -21.082399\n",
      "ep 27: ep_len:975 episode reward: total was -13.590000. running mean: -21.007475\n",
      "ep 27: ep_len:500 episode reward: total was 4.840000. running mean: -20.749001\n",
      "ep 27: ep_len:500 episode reward: total was -2.960000. running mean: -20.571111\n",
      "ep 27: ep_len:800 episode reward: total was 10.940000. running mean: -20.256000\n",
      "ep 27: ep_len:505 episode reward: total was -17.250000. running mean: -20.225940\n",
      "ep 27: ep_len:790 episode reward: total was -23.720000. running mean: -20.260880\n",
      "ep 27: ep_len:500 episode reward: total was 23.290000. running mean: -19.825371\n",
      "ep 27: ep_len:500 episode reward: total was 19.850000. running mean: -19.428618\n",
      "ep 27: ep_len:500 episode reward: total was 26.830000. running mean: -18.966031\n",
      "ep 27: ep_len:745 episode reward: total was 32.310000. running mean: -18.453271\n",
      "ep 27: ep_len:239 episode reward: total was 19.000000. running mean: -18.078738\n",
      "ep 27: ep_len:995 episode reward: total was -50.580000. running mean: -18.403751\n",
      "ep 27: ep_len:930 episode reward: total was -32.800000. running mean: -18.547714\n",
      "ep 27: ep_len:500 episode reward: total was 19.730000. running mean: -18.164936\n",
      "ep 27: ep_len:500 episode reward: total was 20.370000. running mean: -17.779587\n",
      "ep 27: ep_len:655 episode reward: total was -18.940000. running mean: -17.791191\n",
      "ep 27: ep_len:181 episode reward: total was 18.000000. running mean: -17.433279\n",
      "ep 27: ep_len:550 episode reward: total was -17.130000. running mean: -17.430247\n",
      "ep 27: ep_len:590 episode reward: total was 15.350000. running mean: -17.102444\n",
      "ep 27: ep_len:1970 episode reward: total was -145.300000. running mean: -18.384420\n",
      "ep 27: ep_len:1010 episode reward: total was -48.530000. running mean: -18.685875\n",
      "ep 27: ep_len:500 episode reward: total was 9.810000. running mean: -18.400917\n",
      "ep 27: ep_len:500 episode reward: total was 2.640000. running mean: -18.190507\n",
      "ep 27: ep_len:161 episode reward: total was 11.500000. running mean: -17.893602\n",
      "ep 27: ep_len:545 episode reward: total was -12.320000. running mean: -17.837866\n",
      "ep 27: ep_len:555 episode reward: total was -16.110000. running mean: -17.820588\n",
      "ep 27: ep_len:865 episode reward: total was 1.580000. running mean: -17.626582\n",
      "ep 27: ep_len:520 episode reward: total was 26.440000. running mean: -17.185916\n",
      "ep 27: ep_len:500 episode reward: total was 16.240000. running mean: -16.851657\n",
      "ep 27: ep_len:890 episode reward: total was 17.060000. running mean: -16.512540\n",
      "ep 27: ep_len:281 episode reward: total was 17.500000. running mean: -16.172415\n",
      "ep 27: ep_len:500 episode reward: total was 28.730000. running mean: -15.723391\n",
      "ep 27: ep_len:500 episode reward: total was -2.690000. running mean: -15.593057\n",
      "ep 27: ep_len:1603 episode reward: total was -318.500000. running mean: -18.622126\n",
      "ep 27: ep_len:515 episode reward: total was -101.000000. running mean: -19.445905\n",
      "ep 27: ep_len:915 episode reward: total was 19.140000. running mean: -19.060046\n",
      "ep 27: ep_len:620 episode reward: total was -8.910000. running mean: -18.958545\n",
      "ep 27: ep_len:500 episode reward: total was -66.500000. running mean: -19.433960\n",
      "ep 27: ep_len:500 episode reward: total was 4.570000. running mean: -19.193920\n",
      "ep 27: ep_len:550 episode reward: total was 28.400000. running mean: -18.717981\n",
      "ep 27: ep_len:273 episode reward: total was 25.500000. running mean: -18.275801\n",
      "ep 27: ep_len:575 episode reward: total was -2.110000. running mean: -18.114143\n",
      "ep 27: ep_len:800 episode reward: total was 22.990000. running mean: -17.703102\n",
      "ep 27: ep_len:550 episode reward: total was -25.210000. running mean: -17.778171\n",
      "ep 27: ep_len:800 episode reward: total was 15.820000. running mean: -17.442189\n",
      "ep 27: ep_len:500 episode reward: total was -0.290000. running mean: -17.270667\n",
      "ep 27: ep_len:955 episode reward: total was 16.870000. running mean: -16.929261\n",
      "ep 27: ep_len:885 episode reward: total was -16.460000. running mean: -16.924568\n",
      "ep 27: ep_len:500 episode reward: total was 16.630000. running mean: -16.589022\n",
      "ep 27: ep_len:259 episode reward: total was 16.500000. running mean: -16.258132\n",
      "ep 27: ep_len:156 episode reward: total was 11.000000. running mean: -15.985551\n",
      "ep 27: ep_len:740 episode reward: total was -16.980000. running mean: -15.995495\n",
      "ep 27: ep_len:500 episode reward: total was 15.410000. running mean: -15.681440\n",
      "ep 27: ep_len:500 episode reward: total was -4.770000. running mean: -15.572326\n",
      "ep 27: ep_len:352 episode reward: total was 33.500000. running mean: -15.081603\n",
      "ep 27: ep_len:95 episode reward: total was 8.000000. running mean: -14.850787\n",
      "ep 27: ep_len:500 episode reward: total was 25.850000. running mean: -14.443779\n",
      "ep 27: ep_len:960 episode reward: total was 1.170000. running mean: -14.287641\n",
      "ep 27: ep_len:740 episode reward: total was -78.750000. running mean: -14.932265\n",
      "ep 27: ep_len:260 episode reward: total was 23.000000. running mean: -14.552942\n",
      "ep 27: ep_len:665 episode reward: total was 9.940000. running mean: -14.308013\n",
      "ep 27: ep_len:500 episode reward: total was 22.300000. running mean: -13.941932\n",
      "ep 27: ep_len:550 episode reward: total was -15.080000. running mean: -13.953313\n",
      "ep 27: ep_len:134 episode reward: total was 13.000000. running mean: -13.683780\n",
      "ep 27: ep_len:875 episode reward: total was 11.120000. running mean: -13.435742\n",
      "ep 27: ep_len:510 episode reward: total was -14.180000. running mean: -13.443185\n",
      "ep 27: ep_len:1270 episode reward: total was -56.110000. running mean: -13.869853\n",
      "ep 27: ep_len:615 episode reward: total was -20.520000. running mean: -13.936354\n",
      "ep 27: ep_len:1015 episode reward: total was 12.290000. running mean: -13.674091\n",
      "ep 27: ep_len:765 episode reward: total was -5.920000. running mean: -13.596550\n",
      "ep 27: ep_len:398 episode reward: total was 39.500000. running mean: -13.065584\n",
      "ep 27: ep_len:500 episode reward: total was 29.840000. running mean: -12.636529\n",
      "ep 27: ep_len:975 episode reward: total was 20.310000. running mean: -12.307063\n",
      "ep 27: ep_len:379 episode reward: total was -28.570000. running mean: -12.469693\n",
      "ep 27: ep_len:795 episode reward: total was 7.310000. running mean: -12.271896\n",
      "ep 27: ep_len:600 episode reward: total was -5.610000. running mean: -12.205277\n",
      "ep 27: ep_len:860 episode reward: total was 10.510000. running mean: -11.978124\n",
      "ep 27: ep_len:2740 episode reward: total was -420.790000. running mean: -16.066243\n",
      "ep 27: ep_len:500 episode reward: total was -8.320000. running mean: -15.988780\n",
      "ep 27: ep_len:990 episode reward: total was 21.780000. running mean: -15.611093\n",
      "ep 27: ep_len:500 episode reward: total was 12.290000. running mean: -15.332082\n",
      "ep 27: ep_len:640 episode reward: total was 2.240000. running mean: -15.156361\n",
      "ep 27: ep_len:720 episode reward: total was -45.040000. running mean: -15.455197\n",
      "ep 27: ep_len:500 episode reward: total was 19.360000. running mean: -15.107045\n",
      "ep 27: ep_len:580 episode reward: total was -16.550000. running mean: -15.121475\n",
      "ep 27: ep_len:500 episode reward: total was 10.910000. running mean: -14.861160\n",
      "ep 27: ep_len:515 episode reward: total was -48.510000. running mean: -15.197648\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 27: ep_len:895 episode reward: total was 19.150000. running mean: -14.854172\n",
      "ep 27: ep_len:500 episode reward: total was -0.360000. running mean: -14.709230\n",
      "ep 27: ep_len:780 episode reward: total was 29.230000. running mean: -14.269838\n",
      "ep 27: ep_len:500 episode reward: total was 23.310000. running mean: -13.894040\n",
      "ep 27: ep_len:500 episode reward: total was 9.870000. running mean: -13.656399\n",
      "ep 27: ep_len:500 episode reward: total was 23.340000. running mean: -13.286435\n",
      "ep 27: ep_len:710 episode reward: total was -2.640000. running mean: -13.179971\n",
      "ep 27: ep_len:500 episode reward: total was 4.900000. running mean: -12.999171\n",
      "ep 27: ep_len:500 episode reward: total was 26.770000. running mean: -12.601479\n",
      "ep 27: ep_len:500 episode reward: total was 24.350000. running mean: -12.231965\n",
      "ep 27: ep_len:735 episode reward: total was 1.420000. running mean: -12.095445\n",
      "ep 27: ep_len:515 episode reward: total was -2.170000. running mean: -11.996190\n",
      "ep 27: ep_len:675 episode reward: total was -40.080000. running mean: -12.277029\n",
      "ep 27: ep_len:536 episode reward: total was -56.700000. running mean: -12.721258\n",
      "ep 27: ep_len:500 episode reward: total was -24.300000. running mean: -12.837046\n",
      "ep 27: ep_len:242 episode reward: total was -48.000000. running mean: -13.188675\n",
      "ep 27: ep_len:985 episode reward: total was 49.450000. running mean: -12.562289\n",
      "ep 27: ep_len:655 episode reward: total was -7.580000. running mean: -12.512466\n",
      "ep 27: ep_len:656 episode reward: total was -80.180000. running mean: -13.189141\n",
      "ep 27: ep_len:500 episode reward: total was 22.940000. running mean: -12.827850\n",
      "ep 27: ep_len:500 episode reward: total was 18.380000. running mean: -12.515771\n",
      "ep 27: ep_len:5725 episode reward: total was -1088.020000. running mean: -23.270813\n",
      "ep 27: ep_len:500 episode reward: total was -2.200000. running mean: -23.060105\n",
      "ep 27: ep_len:645 episode reward: total was -114.910000. running mean: -23.978604\n",
      "ep 27: ep_len:166 episode reward: total was 16.500000. running mean: -23.573818\n",
      "ep 27: ep_len:1105 episode reward: total was -5.660000. running mean: -23.394680\n",
      "ep 27: ep_len:500 episode reward: total was 48.500000. running mean: -22.675733\n",
      "ep 27: ep_len:760 episode reward: total was -7.020000. running mean: -22.519176\n",
      "ep 27: ep_len:835 episode reward: total was -54.940000. running mean: -22.843384\n",
      "ep 27: ep_len:820 episode reward: total was 17.530000. running mean: -22.439650\n",
      "ep 27: ep_len:760 episode reward: total was 22.210000. running mean: -21.993154\n",
      "ep 27: ep_len:645 episode reward: total was 8.820000. running mean: -21.685022\n",
      "ep 27: ep_len:500 episode reward: total was -11.960000. running mean: -21.587772\n",
      "ep 27: ep_len:720 episode reward: total was -9.720000. running mean: -21.469094\n",
      "ep 27: ep_len:1510 episode reward: total was -247.510000. running mean: -23.729503\n",
      "ep 27: ep_len:500 episode reward: total was 0.100000. running mean: -23.491208\n",
      "ep 27: ep_len:348 episode reward: total was 34.000000. running mean: -22.916296\n",
      "ep 27: ep_len:565 episode reward: total was -20.130000. running mean: -22.888433\n",
      "ep 27: ep_len:1095 episode reward: total was -20.130000. running mean: -22.860849\n",
      "ep 27: ep_len:1015 episode reward: total was 2.420000. running mean: -22.608040\n",
      "ep 27: ep_len:189 episode reward: total was 18.500000. running mean: -22.196960\n",
      "ep 27: ep_len:1610 episode reward: total was -284.730000. running mean: -24.822290\n",
      "ep 27: ep_len:785 episode reward: total was 8.300000. running mean: -24.491067\n",
      "ep 27: ep_len:2207 episode reward: total was -285.490000. running mean: -27.101057\n",
      "ep 27: ep_len:734 episode reward: total was -56.860000. running mean: -27.398646\n",
      "ep 27: ep_len:950 episode reward: total was -34.230000. running mean: -27.466960\n",
      "ep 27: ep_len:500 episode reward: total was -17.530000. running mean: -27.367590\n",
      "ep 27: ep_len:500 episode reward: total was 19.820000. running mean: -26.895714\n",
      "ep 27: ep_len:3005 episode reward: total was -537.370000. running mean: -32.000457\n",
      "ep 27: ep_len:500 episode reward: total was 29.800000. running mean: -31.382453\n",
      "ep 27: ep_len:905 episode reward: total was 7.540000. running mean: -30.993228\n",
      "ep 27: ep_len:1635 episode reward: total was -86.050000. running mean: -31.543796\n",
      "ep 27: ep_len:500 episode reward: total was 19.270000. running mean: -31.035658\n",
      "ep 27: ep_len:500 episode reward: total was 34.800000. running mean: -30.377301\n",
      "ep 27: ep_len:233 episode reward: total was 23.000000. running mean: -29.843528\n",
      "ep 27: ep_len:500 episode reward: total was 50.000000. running mean: -29.045093\n",
      "ep 27: ep_len:500 episode reward: total was -4.490000. running mean: -28.799542\n",
      "ep 27: ep_len:740 episode reward: total was -9.680000. running mean: -28.608347\n",
      "ep 27: ep_len:550 episode reward: total was -32.770000. running mean: -28.649963\n",
      "ep 27: ep_len:237 episode reward: total was 23.500000. running mean: -28.128463\n",
      "ep 27: ep_len:500 episode reward: total was 34.270000. running mean: -27.504479\n",
      "ep 27: ep_len:740 episode reward: total was -22.590000. running mean: -27.455334\n",
      "ep 27: ep_len:500 episode reward: total was 50.000000. running mean: -26.680781\n",
      "ep 27: ep_len:990 episode reward: total was 26.260000. running mean: -26.151373\n",
      "ep 27: ep_len:1480 episode reward: total was -236.480000. running mean: -28.254659\n",
      "ep 27: ep_len:500 episode reward: total was -4.280000. running mean: -28.014913\n",
      "ep 27: ep_len:720 episode reward: total was -8.710000. running mean: -27.821863\n",
      "ep 27: ep_len:675 episode reward: total was -10.820000. running mean: -27.651845\n",
      "ep 27: ep_len:765 episode reward: total was -12.690000. running mean: -27.502226\n",
      "ep 27: ep_len:605 episode reward: total was -5.910000. running mean: -27.286304\n",
      "ep 27: ep_len:685 episode reward: total was 25.700000. running mean: -26.756441\n",
      "ep 27: ep_len:500 episode reward: total was -0.300000. running mean: -26.491877\n",
      "ep 27: ep_len:2424 episode reward: total was -384.940000. running mean: -30.076358\n",
      "ep 27: ep_len:625 episode reward: total was -34.120000. running mean: -30.116794\n",
      "ep 27: ep_len:670 episode reward: total was -5.780000. running mean: -29.873426\n",
      "ep 27: ep_len:500 episode reward: total was 19.270000. running mean: -29.381992\n",
      "ep 27: ep_len:500 episode reward: total was 32.230000. running mean: -28.765872\n",
      "ep 27: ep_len:500 episode reward: total was -1.590000. running mean: -28.494113\n",
      "ep 27: ep_len:630 episode reward: total was -0.810000. running mean: -28.217272\n",
      "ep 27: ep_len:925 episode reward: total was 20.710000. running mean: -27.728000\n",
      "ep 27: ep_len:1000 episode reward: total was -24.670000. running mean: -27.697420\n",
      "ep 27: ep_len:500 episode reward: total was 13.110000. running mean: -27.289345\n",
      "ep 27: ep_len:590 episode reward: total was 11.320000. running mean: -26.903252\n",
      "ep 27: ep_len:925 episode reward: total was 5.850000. running mean: -26.575719\n",
      "ep 27: ep_len:975 episode reward: total was -14.560000. running mean: -26.455562\n",
      "ep 27: ep_len:925 episode reward: total was -12.060000. running mean: -26.311607\n",
      "ep 27: ep_len:925 episode reward: total was 1.460000. running mean: -26.033891\n",
      "ep 27: ep_len:500 episode reward: total was 29.250000. running mean: -25.481052\n",
      "ep 27: ep_len:500 episode reward: total was 50.000000. running mean: -24.726241\n",
      "ep 27: ep_len:500 episode reward: total was 13.300000. running mean: -24.345979\n",
      "ep 27: ep_len:500 episode reward: total was -9.960000. running mean: -24.202119\n",
      "ep 27: ep_len:565 episode reward: total was -33.260000. running mean: -24.292698\n",
      "ep 27: ep_len:600 episode reward: total was -48.610000. running mean: -24.535871\n",
      "ep 27: ep_len:1148 episode reward: total was -161.360000. running mean: -25.904112\n",
      "ep 27: ep_len:1120 episode reward: total was -142.820000. running mean: -27.073271\n",
      "ep 27: ep_len:500 episode reward: total was 48.500000. running mean: -26.317538\n",
      "ep 27: ep_len:500 episode reward: total was -33.450000. running mean: -26.388863\n",
      "ep 27: ep_len:500 episode reward: total was -9.730000. running mean: -26.222274\n",
      "ep 27: ep_len:500 episode reward: total was 2.360000. running mean: -25.936451\n",
      "ep 27: ep_len:500 episode reward: total was -11.700000. running mean: -25.794087\n",
      "ep 27: ep_len:720 episode reward: total was -8.710000. running mean: -25.623246\n",
      "ep 27: ep_len:735 episode reward: total was -18.780000. running mean: -25.554814\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 27: ep_len:2175 episode reward: total was -316.880000. running mean: -28.468066\n",
      "ep 27: ep_len:500 episode reward: total was 14.520000. running mean: -28.038185\n",
      "ep 27: ep_len:1901 episode reward: total was -291.150000. running mean: -30.669303\n",
      "ep 27: ep_len:500 episode reward: total was 23.190000. running mean: -30.130710\n",
      "ep 27: ep_len:595 episode reward: total was -36.720000. running mean: -30.196603\n",
      "ep 27: ep_len:710 episode reward: total was -5.700000. running mean: -29.951637\n",
      "ep 27: ep_len:1000 episode reward: total was 8.300000. running mean: -29.569120\n",
      "ep 27: ep_len:500 episode reward: total was 29.310000. running mean: -28.980329\n",
      "ep 27: ep_len:615 episode reward: total was -28.110000. running mean: -28.971626\n",
      "ep 27: ep_len:570 episode reward: total was -17.090000. running mean: -28.852810\n",
      "ep 27: ep_len:560 episode reward: total was -16.590000. running mean: -28.730182\n",
      "ep 27: ep_len:500 episode reward: total was 1.510000. running mean: -28.427780\n",
      "ep 27: ep_len:785 episode reward: total was -17.670000. running mean: -28.320202\n",
      "ep 27: ep_len:500 episode reward: total was 20.770000. running mean: -27.829300\n",
      "ep 27: ep_len:500 episode reward: total was 30.810000. running mean: -27.242907\n",
      "ep 27: ep_len:610 episode reward: total was 21.390000. running mean: -26.756578\n",
      "ep 27: ep_len:730 episode reward: total was -13.740000. running mean: -26.626412\n",
      "ep 27: ep_len:820 episode reward: total was -39.680000. running mean: -26.756948\n",
      "ep 27: ep_len:500 episode reward: total was -5.040000. running mean: -26.539779\n",
      "ep 27: ep_len:500 episode reward: total was 31.760000. running mean: -25.956781\n",
      "ep 27: ep_len:500 episode reward: total was 7.850000. running mean: -25.618713\n",
      "ep 27: ep_len:500 episode reward: total was 9.930000. running mean: -25.263226\n",
      "ep 27: ep_len:2401 episode reward: total was -411.350000. running mean: -29.124094\n",
      "ep 27: ep_len:500 episode reward: total was -9.790000. running mean: -28.930753\n",
      "ep 27: ep_len:500 episode reward: total was 12.260000. running mean: -28.518845\n",
      "ep 27: ep_len:890 episode reward: total was -8.030000. running mean: -28.313957\n",
      "ep 27: ep_len:705 episode reward: total was -3.290000. running mean: -28.063717\n",
      "ep 27: ep_len:675 episode reward: total was -3.750000. running mean: -27.820580\n",
      "ep 27: ep_len:570 episode reward: total was 0.080000. running mean: -27.541574\n",
      "ep 27: ep_len:800 episode reward: total was -69.120000. running mean: -27.957358\n",
      "ep 27: ep_len:500 episode reward: total was 29.370000. running mean: -27.384085\n",
      "ep 27: ep_len:765 episode reward: total was 14.660000. running mean: -26.963644\n",
      "ep 27: ep_len:492 episode reward: total was 30.760000. running mean: -26.386407\n",
      "ep 27: ep_len:485 episode reward: total was 34.240000. running mean: -25.780143\n",
      "ep 27: ep_len:500 episode reward: total was 33.320000. running mean: -25.189142\n",
      "ep 27: ep_len:955 episode reward: total was 9.020000. running mean: -24.847051\n",
      "ep 27: ep_len:790 episode reward: total was 25.330000. running mean: -24.345280\n",
      "ep 27: ep_len:775 episode reward: total was -23.230000. running mean: -24.334127\n",
      "ep 27: ep_len:500 episode reward: total was 5.190000. running mean: -24.038886\n",
      "ep 27: ep_len:775 episode reward: total was -40.510000. running mean: -24.203597\n",
      "ep 27: ep_len:680 episode reward: total was -61.760000. running mean: -24.579161\n",
      "ep 27: ep_len:1040 episode reward: total was 10.220000. running mean: -24.231170\n",
      "ep 27: ep_len:500 episode reward: total was 5.560000. running mean: -23.933258\n",
      "ep 27: ep_len:500 episode reward: total was 30.780000. running mean: -23.386125\n",
      "ep 27: ep_len:770 episode reward: total was -40.410000. running mean: -23.556364\n",
      "ep 27: ep_len:850 episode reward: total was 9.280000. running mean: -23.228000\n",
      "ep 27: ep_len:580 episode reward: total was -21.110000. running mean: -23.206820\n",
      "ep 27: ep_len:500 episode reward: total was -2.250000. running mean: -22.997252\n",
      "ep 27: ep_len:500 episode reward: total was -5.720000. running mean: -22.824480\n",
      "ep 27: ep_len:500 episode reward: total was 23.920000. running mean: -22.357035\n",
      "ep 27: ep_len:206 episode reward: total was 19.000000. running mean: -21.943465\n",
      "ep 27: ep_len:865 episode reward: total was -32.660000. running mean: -22.050630\n",
      "ep 27: ep_len:500 episode reward: total was 20.460000. running mean: -21.625524\n",
      "ep 27: ep_len:655 episode reward: total was -46.870000. running mean: -21.877968\n",
      "ep 27: ep_len:500 episode reward: total was -1.980000. running mean: -21.678989\n",
      "ep 27: ep_len:515 episode reward: total was -55.210000. running mean: -22.014299\n",
      "ep 27: ep_len:920 episode reward: total was -41.640000. running mean: -22.210556\n",
      "ep 27: ep_len:805 episode reward: total was -1.450000. running mean: -22.002950\n",
      "ep 27: ep_len:500 episode reward: total was -8.170000. running mean: -21.864621\n",
      "ep 27: ep_len:1000 episode reward: total was -55.590000. running mean: -22.201874\n",
      "ep 27: ep_len:750 episode reward: total was 16.560000. running mean: -21.814256\n",
      "ep 27: ep_len:1551 episode reward: total was -216.100000. running mean: -23.757113\n",
      "ep 27: ep_len:500 episode reward: total was 4.970000. running mean: -23.469842\n",
      "ep 27: ep_len:120 episode reward: total was 10.500000. running mean: -23.130144\n",
      "ep 27: ep_len:630 episode reward: total was 11.870000. running mean: -22.780142\n",
      "ep 27: ep_len:500 episode reward: total was 13.770000. running mean: -22.414641\n",
      "ep 27: ep_len:245 episode reward: total was 23.000000. running mean: -21.960494\n",
      "ep 27: ep_len:590 episode reward: total was 25.480000. running mean: -21.486089\n",
      "ep 27: ep_len:520 episode reward: total was -19.210000. running mean: -21.463329\n",
      "ep 27: ep_len:500 episode reward: total was 23.380000. running mean: -21.014895\n",
      "ep 27: ep_len:224 episode reward: total was 22.000000. running mean: -20.584746\n",
      "ep 27: ep_len:177 episode reward: total was 18.000000. running mean: -20.198899\n",
      "ep 27: ep_len:219 episode reward: total was 20.000000. running mean: -19.796910\n",
      "ep 27: ep_len:575 episode reward: total was -7.990000. running mean: -19.678841\n",
      "ep 27: ep_len:815 episode reward: total was 20.170000. running mean: -19.280352\n",
      "ep 27: ep_len:640 episode reward: total was -18.550000. running mean: -19.273049\n",
      "ep 27: ep_len:212 episode reward: total was 21.000000. running mean: -18.870318\n",
      "ep 27: ep_len:5332 episode reward: total was -969.070000. running mean: -28.372315\n",
      "ep 27: ep_len:500 episode reward: total was 32.720000. running mean: -27.761392\n",
      "ep 27: ep_len:500 episode reward: total was 12.630000. running mean: -27.357478\n",
      "ep 27: ep_len:226 episode reward: total was 21.000000. running mean: -26.873903\n",
      "ep 27: ep_len:2364 episode reward: total was -388.220000. running mean: -30.487364\n",
      "ep 27: ep_len:725 episode reward: total was -27.890000. running mean: -30.461391\n",
      "ep 27: ep_len:500 episode reward: total was 8.780000. running mean: -30.068977\n",
      "ep 27: ep_len:930 episode reward: total was 1.970000. running mean: -29.748587\n",
      "ep 27: ep_len:500 episode reward: total was -22.850000. running mean: -29.679601\n",
      "ep 27: ep_len:1215 episode reward: total was -157.200000. running mean: -30.954805\n",
      "ep 27: ep_len:830 episode reward: total was 7.980000. running mean: -30.565457\n",
      "ep 27: ep_len:580 episode reward: total was -111.000000. running mean: -31.369802\n",
      "ep 27: ep_len:595 episode reward: total was -15.020000. running mean: -31.206304\n",
      "ep 27: ep_len:258 episode reward: total was 16.000000. running mean: -30.734241\n",
      "ep 27: ep_len:193 episode reward: total was 19.000000. running mean: -30.236899\n",
      "ep 27: ep_len:625 episode reward: total was -26.070000. running mean: -30.195230\n",
      "ep 27: ep_len:1060 episode reward: total was -73.680000. running mean: -30.630078\n",
      "ep 27: ep_len:500 episode reward: total was 18.230000. running mean: -30.141477\n",
      "ep 27: ep_len:535 episode reward: total was 28.460000. running mean: -29.555462\n",
      "ep 27: ep_len:500 episode reward: total was -19.800000. running mean: -29.457908\n",
      "ep 27: ep_len:800 episode reward: total was -49.960000. running mean: -29.662928\n",
      "ep 27: ep_len:1435 episode reward: total was -280.990000. running mean: -32.176199\n",
      "ep 27: ep_len:790 episode reward: total was -7.310000. running mean: -31.927537\n",
      "ep 27: ep_len:500 episode reward: total was 20.950000. running mean: -31.398762\n",
      "ep 27: ep_len:600 episode reward: total was -14.000000. running mean: -31.224774\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 27: ep_len:595 episode reward: total was -18.050000. running mean: -31.093026\n",
      "ep 27: ep_len:700 episode reward: total was -10.770000. running mean: -30.889796\n",
      "ep 27: ep_len:312 episode reward: total was 31.000000. running mean: -30.270898\n",
      "ep 27: ep_len:935 episode reward: total was -32.520000. running mean: -30.293389\n",
      "ep 27: ep_len:500 episode reward: total was 22.270000. running mean: -29.767755\n",
      "ep 27: ep_len:500 episode reward: total was -32.500000. running mean: -29.795078\n",
      "ep 27: ep_len:660 episode reward: total was 23.260000. running mean: -29.264527\n",
      "ep 27: ep_len:500 episode reward: total was 21.990000. running mean: -28.751982\n",
      "ep 27: ep_len:725 episode reward: total was -44.050000. running mean: -28.904962\n",
      "ep 27: ep_len:500 episode reward: total was 26.220000. running mean: -28.353712\n",
      "ep 27: ep_len:810 episode reward: total was 6.490000. running mean: -28.005275\n",
      "ep 27: ep_len:545 episode reward: total was -5.020000. running mean: -27.775422\n",
      "ep 27: ep_len:155 episode reward: total was 14.000000. running mean: -27.357668\n",
      "ep 27: ep_len:169 episode reward: total was 16.500000. running mean: -26.919092\n",
      "ep 27: ep_len:333 episode reward: total was 26.000000. running mean: -26.389901\n",
      "ep 27: ep_len:1740 episode reward: total was -262.180000. running mean: -28.747802\n",
      "ep 27: ep_len:885 episode reward: total was 2.650000. running mean: -28.433824\n",
      "ep 27: ep_len:177 episode reward: total was 17.500000. running mean: -27.974485\n",
      "ep 27: ep_len:605 episode reward: total was 21.220000. running mean: -27.482540\n",
      "ep 27: ep_len:500 episode reward: total was 18.320000. running mean: -27.024515\n",
      "ep 27: ep_len:151 episode reward: total was 15.000000. running mean: -26.604270\n",
      "ep 27: ep_len:500 episode reward: total was 17.890000. running mean: -26.159327\n",
      "ep 27: ep_len:500 episode reward: total was 48.500000. running mean: -25.412734\n",
      "ep 27: ep_len:595 episode reward: total was 5.800000. running mean: -25.100607\n",
      "ep 27: ep_len:500 episode reward: total was 3.720000. running mean: -24.812401\n",
      "ep 27: ep_len:935 episode reward: total was 8.350000. running mean: -24.480777\n",
      "ep 27: ep_len:1110 episode reward: total was 13.300000. running mean: -24.102969\n",
      "ep 27: ep_len:685 episode reward: total was -34.030000. running mean: -24.202239\n",
      "ep 27: ep_len:500 episode reward: total was -27.500000. running mean: -24.235217\n",
      "ep 27: ep_len:2025 episode reward: total was -194.970000. running mean: -25.942565\n",
      "ep 27: ep_len:825 episode reward: total was -21.110000. running mean: -25.894239\n",
      "ep 27: ep_len:510 episode reward: total was -30.310000. running mean: -25.938396\n",
      "ep 27: ep_len:505 episode reward: total was -14.190000. running mean: -25.820913\n",
      "ep 27: ep_len:965 episode reward: total was -15.390000. running mean: -25.716603\n",
      "ep 27: ep_len:815 episode reward: total was -1.250000. running mean: -25.471937\n",
      "ep 27: ep_len:635 episode reward: total was -34.240000. running mean: -25.559618\n",
      "ep 27: ep_len:970 episode reward: total was -34.470000. running mean: -25.648722\n",
      "ep 27: ep_len:1521 episode reward: total was -180.920000. running mean: -27.201435\n",
      "ep 27: ep_len:710 episode reward: total was -14.990000. running mean: -27.079320\n",
      "ep 27: ep_len:430 episode reward: total was 41.500000. running mean: -26.393527\n",
      "ep 27: ep_len:965 episode reward: total was -21.110000. running mean: -26.340692\n",
      "ep 27: ep_len:500 episode reward: total was 8.610000. running mean: -25.991185\n",
      "ep 27: ep_len:710 episode reward: total was 2.810000. running mean: -25.703173\n",
      "ep 27: ep_len:500 episode reward: total was 28.730000. running mean: -25.158841\n",
      "ep 27: ep_len:279 episode reward: total was 24.500000. running mean: -24.662253\n",
      "ep 27: ep_len:730 episode reward: total was 32.710000. running mean: -24.088530\n",
      "ep 27: ep_len:500 episode reward: total was 6.370000. running mean: -23.783945\n",
      "ep 27: ep_len:500 episode reward: total was 28.300000. running mean: -23.263106\n",
      "ep 27: ep_len:212 episode reward: total was 20.000000. running mean: -22.830475\n",
      "ep 27: ep_len:1075 episode reward: total was -99.910000. running mean: -23.601270\n",
      "ep 27: ep_len:550 episode reward: total was -26.220000. running mean: -23.627457\n",
      "ep 27: ep_len:500 episode reward: total was -9.960000. running mean: -23.490783\n",
      "ep 27: ep_len:276 episode reward: total was 27.500000. running mean: -22.980875\n",
      "ep 27: ep_len:500 episode reward: total was 9.780000. running mean: -22.653266\n",
      "ep 27: ep_len:965 episode reward: total was 1.510000. running mean: -22.411633\n",
      "ep 27: ep_len:765 episode reward: total was -54.070000. running mean: -22.728217\n",
      "ep 27: ep_len:500 episode reward: total was 25.300000. running mean: -22.247935\n",
      "ep 27: ep_len:272 episode reward: total was 25.500000. running mean: -21.770455\n",
      "ep 27: ep_len:805 episode reward: total was 3.690000. running mean: -21.515851\n",
      "ep 27: ep_len:635 episode reward: total was -20.110000. running mean: -21.501792\n",
      "ep 27: ep_len:500 episode reward: total was 3.990000. running mean: -21.246874\n",
      "ep 27: ep_len:535 episode reward: total was -21.200000. running mean: -21.246406\n",
      "ep 27: ep_len:500 episode reward: total was 21.720000. running mean: -20.816742\n",
      "ep 27: ep_len:500 episode reward: total was 15.260000. running mean: -20.455974\n",
      "ep 27: ep_len:640 episode reward: total was -8.840000. running mean: -20.339814\n",
      "ep 27: ep_len:545 episode reward: total was -0.980000. running mean: -20.146216\n",
      "ep 27: ep_len:500 episode reward: total was 29.280000. running mean: -19.651954\n",
      "ep 27: ep_len:500 episode reward: total was -5.720000. running mean: -19.512635\n",
      "ep 27: ep_len:785 episode reward: total was -15.650000. running mean: -19.474008\n",
      "ep 27: ep_len:343 episode reward: total was -19.110000. running mean: -19.470368\n",
      "ep 27: ep_len:860 episode reward: total was 12.240000. running mean: -19.153265\n",
      "ep 27: ep_len:1455 episode reward: total was -201.230000. running mean: -20.974032\n",
      "ep 27: ep_len:565 episode reward: total was -31.240000. running mean: -21.076692\n",
      "ep 27: ep_len:500 episode reward: total was 0.440000. running mean: -20.861525\n",
      "ep 27: ep_len:520 episode reward: total was 12.140000. running mean: -20.531509\n",
      "ep 27: ep_len:500 episode reward: total was 4.580000. running mean: -20.280394\n",
      "ep 27: ep_len:1570 episode reward: total was -77.990000. running mean: -20.857490\n",
      "ep 27: ep_len:630 episode reward: total was 9.940000. running mean: -20.549515\n",
      "ep 27: ep_len:580 episode reward: total was -15.050000. running mean: -20.494520\n",
      "ep 27: ep_len:735 episode reward: total was -0.750000. running mean: -20.297075\n",
      "ep 27: ep_len:500 episode reward: total was 4.580000. running mean: -20.048304\n",
      "ep 27: ep_len:1025 episode reward: total was -57.590000. running mean: -20.423721\n",
      "ep 27: ep_len:500 episode reward: total was -0.670000. running mean: -20.226184\n",
      "ep 27: ep_len:715 episode reward: total was 35.710000. running mean: -19.666822\n",
      "ep 27: ep_len:1006 episode reward: total was -195.950000. running mean: -21.429654\n",
      "ep 27: ep_len:500 episode reward: total was -16.850000. running mean: -21.383857\n",
      "ep 27: ep_len:500 episode reward: total was -18.720000. running mean: -21.357219\n",
      "ep 27: ep_len:675 episode reward: total was -35.550000. running mean: -21.499147\n",
      "ep 27: ep_len:2325 episode reward: total was -195.140000. running mean: -23.235555\n",
      "ep 27: ep_len:930 episode reward: total was 33.820000. running mean: -22.665000\n",
      "ep 27: ep_len:680 episode reward: total was -13.810000. running mean: -22.576450\n",
      "ep 27: ep_len:1435 episode reward: total was -69.900000. running mean: -23.049685\n",
      "ep 27: ep_len:500 episode reward: total was 32.770000. running mean: -22.491488\n",
      "ep 27: ep_len:695 episode reward: total was -32.970000. running mean: -22.596273\n",
      "ep 27: ep_len:690 episode reward: total was -0.690000. running mean: -22.377211\n",
      "ep 27: ep_len:1110 episode reward: total was -67.520000. running mean: -22.828639\n",
      "ep 27: ep_len:580 episode reward: total was 8.770000. running mean: -22.512652\n",
      "ep 27: ep_len:1485 episode reward: total was -68.790000. running mean: -22.975426\n",
      "ep 27: ep_len:197 episode reward: total was 18.000000. running mean: -22.565671\n",
      "ep 27: ep_len:685 episode reward: total was 23.340000. running mean: -22.106615\n",
      "ep 27: ep_len:500 episode reward: total was 48.500000. running mean: -21.400549\n",
      "ep 27: ep_len:885 episode reward: total was -23.650000. running mean: -21.423043\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 27: ep_len:500 episode reward: total was 22.330000. running mean: -20.985513\n",
      "ep 27: ep_len:500 episode reward: total was 16.880000. running mean: -20.606858\n",
      "ep 27: ep_len:140 episode reward: total was 12.500000. running mean: -20.275789\n",
      "ep 27: ep_len:780 episode reward: total was -82.290000. running mean: -20.895931\n",
      "ep 27: ep_len:610 episode reward: total was 16.370000. running mean: -20.523272\n",
      "ep 27: ep_len:925 episode reward: total was 20.270000. running mean: -20.115339\n",
      "ep 27: ep_len:770 episode reward: total was -1.000000. running mean: -19.924186\n",
      "ep 27: ep_len:500 episode reward: total was 25.300000. running mean: -19.471944\n",
      "ep 27: ep_len:1170 episode reward: total was -5.760000. running mean: -19.334824\n",
      "ep 27: ep_len:1025 episode reward: total was -1.990000. running mean: -19.161376\n",
      "ep 27: ep_len:2131 episode reward: total was -144.330000. running mean: -20.413062\n",
      "ep 27: ep_len:975 episode reward: total was -26.870000. running mean: -20.477632\n",
      "ep 27: ep_len:705 episode reward: total was -40.030000. running mean: -20.673155\n",
      "ep 27: ep_len:1075 episode reward: total was -27.450000. running mean: -20.740924\n",
      "ep 27: ep_len:500 episode reward: total was 2.640000. running mean: -20.507115\n",
      "ep 27: ep_len:625 episode reward: total was -14.960000. running mean: -20.451643\n",
      "ep 27: ep_len:615 episode reward: total was 10.340000. running mean: -20.143727\n",
      "ep 27: ep_len:741 episode reward: total was -61.170000. running mean: -20.553990\n",
      "ep 27: ep_len:1030 episode reward: total was 12.920000. running mean: -20.219250\n",
      "ep 27: ep_len:303 episode reward: total was 30.000000. running mean: -19.717057\n",
      "ep 27: ep_len:500 episode reward: total was 16.240000. running mean: -19.357487\n",
      "ep 27: ep_len:500 episode reward: total was 50.000000. running mean: -18.663912\n",
      "ep 27: ep_len:1520 episode reward: total was -78.820000. running mean: -19.265473\n",
      "ep 27: ep_len:500 episode reward: total was 14.280000. running mean: -18.930018\n",
      "ep 27: ep_len:342 episode reward: total was -23.590000. running mean: -18.976618\n",
      "ep 27: ep_len:575 episode reward: total was -22.620000. running mean: -19.013052\n",
      "ep 27: ep_len:770 episode reward: total was 23.820000. running mean: -18.584721\n",
      "ep 27: ep_len:925 episode reward: total was -23.940000. running mean: -18.638274\n",
      "ep 27: ep_len:500 episode reward: total was -22.830000. running mean: -18.680191\n",
      "ep 27: ep_len:760 episode reward: total was 3.540000. running mean: -18.457989\n",
      "ep 27: ep_len:770 episode reward: total was 2.320000. running mean: -18.250209\n",
      "ep 27: ep_len:684 episode reward: total was -22.720000. running mean: -18.294907\n",
      "ep 27: ep_len:900 episode reward: total was 21.580000. running mean: -17.896158\n",
      "ep 27: ep_len:500 episode reward: total was 9.290000. running mean: -17.624297\n",
      "ep 27: ep_len:505 episode reward: total was -7.120000. running mean: -17.519254\n",
      "ep 27: ep_len:500 episode reward: total was -6.450000. running mean: -17.408561\n",
      "ep 27: ep_len:1160 episode reward: total was 17.500000. running mean: -17.059476\n",
      "ep 27: ep_len:500 episode reward: total was 2.950000. running mean: -16.859381\n",
      "ep 27: ep_len:500 episode reward: total was -3.210000. running mean: -16.722887\n",
      "ep 27: ep_len:1340 episode reward: total was -218.560000. running mean: -18.741258\n",
      "ep 27: ep_len:1175 episode reward: total was -67.640000. running mean: -19.230246\n",
      "ep 27: ep_len:760 episode reward: total was -2.570000. running mean: -19.063643\n",
      "ep 27: ep_len:480 episode reward: total was 30.800000. running mean: -18.565007\n",
      "ep 27: ep_len:570 episode reward: total was -20.610000. running mean: -18.585457\n",
      "ep 27: ep_len:362 episode reward: total was 35.000000. running mean: -18.049602\n",
      "ep 27: ep_len:500 episode reward: total was 28.730000. running mean: -17.581806\n",
      "ep 27: ep_len:500 episode reward: total was 0.530000. running mean: -17.400688\n",
      "ep 27: ep_len:500 episode reward: total was 13.940000. running mean: -17.087281\n",
      "ep 27: ep_len:486 episode reward: total was 27.750000. running mean: -16.638908\n",
      "ep 27: ep_len:630 episode reward: total was -22.020000. running mean: -16.692719\n",
      "ep 27: ep_len:500 episode reward: total was 0.810000. running mean: -16.517692\n",
      "ep 27: ep_len:1615 episode reward: total was -209.100000. running mean: -18.443515\n",
      "ep 27: ep_len:725 episode reward: total was -32.050000. running mean: -18.579580\n",
      "ep 27: ep_len:660 episode reward: total was 0.260000. running mean: -18.391184\n",
      "ep 27: ep_len:1207 episode reward: total was -194.570000. running mean: -20.152972\n",
      "ep 27: ep_len:500 episode reward: total was -6.730000. running mean: -20.018743\n",
      "ep 27: ep_len:880 episode reward: total was 7.780000. running mean: -19.740755\n",
      "ep 27: ep_len:500 episode reward: total was 14.950000. running mean: -19.393848\n",
      "ep 27: ep_len:500 episode reward: total was 18.240000. running mean: -19.017509\n",
      "ep 27: ep_len:500 episode reward: total was 25.300000. running mean: -18.574334\n",
      "ep 27: ep_len:955 episode reward: total was -14.270000. running mean: -18.531291\n",
      "ep 27: ep_len:585 episode reward: total was -25.140000. running mean: -18.597378\n",
      "ep 27: ep_len:207 episode reward: total was 20.500000. running mean: -18.206404\n",
      "ep 27: ep_len:1034 episode reward: total was -132.870000. running mean: -19.353040\n",
      "ep 27: ep_len:965 episode reward: total was -16.300000. running mean: -19.322510\n",
      "ep 27: ep_len:500 episode reward: total was -9.270000. running mean: -19.221984\n",
      "ep 27: ep_len:655 episode reward: total was 5.930000. running mean: -18.970465\n",
      "ep 27: ep_len:975 episode reward: total was -13.220000. running mean: -18.912960\n",
      "ep 27: ep_len:500 episode reward: total was -6.210000. running mean: -18.785930\n",
      "ep 27: ep_len:1125 episode reward: total was -152.080000. running mean: -20.118871\n",
      "ep 27: ep_len:505 episode reward: total was -4.760000. running mean: -19.965282\n",
      "ep 27: ep_len:500 episode reward: total was 19.830000. running mean: -19.567330\n",
      "ep 27: ep_len:560 episode reward: total was 13.020000. running mean: -19.241456\n",
      "ep 27: ep_len:500 episode reward: total was -7.620000. running mean: -19.125242\n",
      "ep 27: ep_len:205 episode reward: total was 17.500000. running mean: -18.758989\n",
      "ep 27: ep_len:500 episode reward: total was 50.000000. running mean: -18.071399\n",
      "ep 27: ep_len:500 episode reward: total was 14.620000. running mean: -17.744485\n",
      "ep 27: ep_len:505 episode reward: total was 27.730000. running mean: -17.289741\n",
      "ep 27: ep_len:545 episode reward: total was -12.090000. running mean: -17.237743\n",
      "ep 27: ep_len:500 episode reward: total was -25.550000. running mean: -17.320866\n",
      "ep 27: ep_len:137 episode reward: total was 13.500000. running mean: -17.012657\n",
      "ep 27: ep_len:500 episode reward: total was 25.910000. running mean: -16.583430\n",
      "ep 27: ep_len:710 episode reward: total was -20.820000. running mean: -16.625796\n",
      "ep 27: ep_len:515 episode reward: total was -5.080000. running mean: -16.510338\n",
      "ep 27: ep_len:149 episode reward: total was 13.500000. running mean: -16.210235\n",
      "ep 27: ep_len:11285 episode reward: total was -2080.470000. running mean: -36.852832\n",
      "ep 27: ep_len:750 episode reward: total was -53.090000. running mean: -37.015204\n",
      "ep 27: ep_len:1345 episode reward: total was 17.290000. running mean: -36.472152\n",
      "ep 27: ep_len:965 episode reward: total was -13.090000. running mean: -36.238331\n",
      "ep 27: ep_len:700 episode reward: total was -3.730000. running mean: -35.913247\n",
      "ep 27: ep_len:500 episode reward: total was 27.750000. running mean: -35.276615\n",
      "ep 27: ep_len:900 episode reward: total was -36.630000. running mean: -35.290149\n",
      "ep 27: ep_len:500 episode reward: total was -45.020000. running mean: -35.387447\n",
      "ep 27: ep_len:500 episode reward: total was -1.130000. running mean: -35.044873\n",
      "ep 27: ep_len:1553 episode reward: total was -310.000000. running mean: -37.794424\n",
      "ep 27: ep_len:720 episode reward: total was 8.970000. running mean: -37.326780\n",
      "ep 27: ep_len:605 episode reward: total was -11.970000. running mean: -37.073212\n",
      "ep 27: ep_len:975 episode reward: total was -65.950000. running mean: -37.361980\n",
      "ep 27: ep_len:825 episode reward: total was 12.660000. running mean: -36.861760\n",
      "ep 27: ep_len:1055 episode reward: total was -5.120000. running mean: -36.544342\n",
      "ep 27: ep_len:1115 episode reward: total was -5.230000. running mean: -36.231199\n",
      "ep 27: ep_len:895 episode reward: total was -20.360000. running mean: -36.072487\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 27: ep_len:500 episode reward: total was 13.210000. running mean: -35.579662\n",
      "ep 27: ep_len:1130 episode reward: total was -201.810000. running mean: -37.241966\n",
      "ep 27: ep_len:500 episode reward: total was 11.380000. running mean: -36.755746\n",
      "ep 27: ep_len:500 episode reward: total was -0.630000. running mean: -36.394488\n",
      "ep 27: ep_len:700 episode reward: total was 4.120000. running mean: -35.989344\n",
      "ep 27: ep_len:500 episode reward: total was -6.670000. running mean: -35.696150\n",
      "ep 27: ep_len:950 episode reward: total was -23.640000. running mean: -35.575589\n",
      "ep 27: ep_len:1454 episode reward: total was -159.740000. running mean: -36.817233\n",
      "ep 27: ep_len:500 episode reward: total was -7.550000. running mean: -36.524560\n",
      "ep 27: ep_len:597 episode reward: total was -93.780000. running mean: -37.097115\n",
      "ep 27: ep_len:515 episode reward: total was -11.140000. running mean: -36.837544\n",
      "ep 27: ep_len:515 episode reward: total was -20.230000. running mean: -36.671468\n",
      "ep 27: ep_len:695 episode reward: total was -19.870000. running mean: -36.503453\n",
      "ep 27: ep_len:735 episode reward: total was -1.570000. running mean: -36.154119\n",
      "ep 27: ep_len:500 episode reward: total was 17.740000. running mean: -35.615178\n",
      "ep 27: ep_len:500 episode reward: total was -38.010000. running mean: -35.639126\n",
      "ep 27: ep_len:500 episode reward: total was -7.280000. running mean: -35.355535\n",
      "ep 27: ep_len:730 episode reward: total was -7.680000. running mean: -35.078779\n",
      "ep 27: ep_len:2205 episode reward: total was -325.480000. running mean: -37.982792\n",
      "ep 27: ep_len:625 episode reward: total was -34.150000. running mean: -37.944464\n",
      "ep 27: ep_len:605 episode reward: total was 19.690000. running mean: -37.368119\n",
      "ep 27: ep_len:515 episode reward: total was -5.080000. running mean: -37.045238\n",
      "ep 27: ep_len:2501 episode reward: total was -378.310000. running mean: -40.457885\n",
      "ep 27: ep_len:550 episode reward: total was -0.470000. running mean: -40.058007\n",
      "ep 27: ep_len:1575 episode reward: total was -137.250000. running mean: -41.029927\n",
      "ep 27: ep_len:995 episode reward: total was -57.650000. running mean: -41.196127\n",
      "ep 27: ep_len:785 episode reward: total was -16.660000. running mean: -40.950766\n",
      "ep 27: ep_len:500 episode reward: total was -52.760000. running mean: -41.068858\n",
      "ep 27: ep_len:685 episode reward: total was -7.770000. running mean: -40.735870\n",
      "ep 27: ep_len:500 episode reward: total was 22.240000. running mean: -40.106111\n",
      "ep 27: ep_len:506 episode reward: total was -5.220000. running mean: -39.757250\n",
      "ep 27: ep_len:500 episode reward: total was 23.250000. running mean: -39.127177\n",
      "ep 27: ep_len:905 episode reward: total was 4.490000. running mean: -38.691006\n",
      "ep 27: ep_len:500 episode reward: total was -33.020000. running mean: -38.634296\n",
      "ep 27: ep_len:615 episode reward: total was 26.050000. running mean: -37.987453\n",
      "ep 27: ep_len:530 episode reward: total was -23.230000. running mean: -37.839878\n",
      "ep 27: ep_len:500 episode reward: total was 13.120000. running mean: -37.330279\n",
      "ep 27: ep_len:500 episode reward: total was 27.750000. running mean: -36.679477\n",
      "ep 27: ep_len:690 episode reward: total was -3.720000. running mean: -36.349882\n",
      "ep 27: ep_len:610 episode reward: total was -32.160000. running mean: -36.307983\n",
      "ep 27: ep_len:1226 episode reward: total was -113.450000. running mean: -37.079403\n",
      "ep 27: ep_len:505 episode reward: total was 4.530000. running mean: -36.663309\n",
      "ep 27: ep_len:1060 episode reward: total was -13.770000. running mean: -36.434376\n",
      "ep 27: ep_len:500 episode reward: total was 10.600000. running mean: -35.964032\n",
      "ep 27: ep_len:226 episode reward: total was 19.500000. running mean: -35.409392\n",
      "ep 27: ep_len:1040 episode reward: total was -18.680000. running mean: -35.242098\n",
      "ep 27: ep_len:67 episode reward: total was 6.500000. running mean: -34.824677\n",
      "ep 27: ep_len:500 episode reward: total was 24.260000. running mean: -34.233830\n",
      "ep 27: ep_len:805 episode reward: total was -17.630000. running mean: -34.067792\n",
      "ep 27: ep_len:680 episode reward: total was -22.930000. running mean: -33.956414\n",
      "ep 27: ep_len:227 episode reward: total was 22.500000. running mean: -33.391850\n",
      "ep 27: ep_len:500 episode reward: total was 26.770000. running mean: -32.790231\n",
      "ep 27: ep_len:500 episode reward: total was 4.290000. running mean: -32.419429\n",
      "ep 27: ep_len:535 episode reward: total was -48.670000. running mean: -32.581935\n",
      "ep 27: ep_len:179 episode reward: total was 16.000000. running mean: -32.096115\n",
      "ep 27: ep_len:695 episode reward: total was 0.530000. running mean: -31.769854\n",
      "ep 27: ep_len:650 episode reward: total was -46.220000. running mean: -31.914356\n",
      "ep 27: ep_len:500 episode reward: total was 20.810000. running mean: -31.387112\n",
      "ep 27: ep_len:95 episode reward: total was 8.000000. running mean: -30.993241\n",
      "ep 27: ep_len:570 episode reward: total was 5.910000. running mean: -30.624209\n",
      "ep 27: ep_len:700 episode reward: total was -52.180000. running mean: -30.839767\n",
      "ep 27: ep_len:500 episode reward: total was 24.810000. running mean: -30.283269\n",
      "ep 27: ep_len:830 episode reward: total was -9.500000. running mean: -30.075436\n",
      "ep 27: ep_len:500 episode reward: total was 6.310000. running mean: -29.711582\n",
      "ep 27: ep_len:565 episode reward: total was -33.260000. running mean: -29.747066\n",
      "ep 27: ep_len:245 episode reward: total was 21.500000. running mean: -29.234595\n",
      "ep 27: ep_len:500 episode reward: total was 14.610000. running mean: -28.796149\n",
      "ep 27: ep_len:795 episode reward: total was -3.150000. running mean: -28.539688\n",
      "ep 27: ep_len:845 episode reward: total was -17.550000. running mean: -28.429791\n",
      "ep 27: ep_len:750 episode reward: total was -9.660000. running mean: -28.242093\n",
      "ep 27: ep_len:565 episode reward: total was -18.110000. running mean: -28.140772\n",
      "ep 27: ep_len:515 episode reward: total was -14.660000. running mean: -28.005965\n",
      "ep 27: ep_len:685 episode reward: total was -13.670000. running mean: -27.862605\n",
      "ep 27: ep_len:535 episode reward: total was 23.350000. running mean: -27.350479\n",
      "ep 27: ep_len:500 episode reward: total was -31.630000. running mean: -27.393274\n",
      "ep 27: ep_len:500 episode reward: total was -5.560000. running mean: -27.174941\n",
      "ep 27: ep_len:1215 episode reward: total was -100.640000. running mean: -27.909592\n",
      "ep 27: ep_len:500 episode reward: total was 10.630000. running mean: -27.524196\n",
      "ep 27: ep_len:1675 episode reward: total was -222.410000. running mean: -29.473054\n",
      "ep 27: ep_len:2000 episode reward: total was -229.900000. running mean: -31.477323\n",
      "ep 27: ep_len:715 episode reward: total was -10.740000. running mean: -31.269950\n",
      "ep 27: ep_len:305 episode reward: total was 26.000000. running mean: -30.697251\n",
      "ep 27: ep_len:500 episode reward: total was -19.520000. running mean: -30.585478\n",
      "ep 27: ep_len:685 episode reward: total was -19.890000. running mean: -30.478523\n",
      "ep 27: ep_len:615 episode reward: total was -6.300000. running mean: -30.236738\n",
      "ep 27: ep_len:260 episode reward: total was 24.500000. running mean: -29.689371\n",
      "ep 27: ep_len:500 episode reward: total was 26.400000. running mean: -29.128477\n",
      "ep 27: ep_len:500 episode reward: total was 4.270000. running mean: -28.794492\n",
      "ep 27: ep_len:500 episode reward: total was 26.800000. running mean: -28.238547\n",
      "ep 27: ep_len:500 episode reward: total was -9.420000. running mean: -28.050362\n",
      "ep 27: ep_len:830 episode reward: total was 9.460000. running mean: -27.675258\n",
      "ep 27: ep_len:355 episode reward: total was 34.500000. running mean: -27.053506\n",
      "ep 27: ep_len:2029 episode reward: total was -330.310000. running mean: -30.086071\n",
      "ep 27: ep_len:500 episode reward: total was 30.290000. running mean: -29.482310\n",
      "ep 27: ep_len:1130 episode reward: total was -103.850000. running mean: -30.225987\n",
      "ep 27: ep_len:995 episode reward: total was -49.570000. running mean: -30.419427\n",
      "ep 27: ep_len:500 episode reward: total was -25.860000. running mean: -30.373833\n",
      "ep 27: ep_len:500 episode reward: total was 15.120000. running mean: -29.918894\n",
      "ep 27: ep_len:300 episode reward: total was 14.240000. running mean: -29.477305\n",
      "ep 27: ep_len:795 episode reward: total was -86.330000. running mean: -30.045832\n",
      "ep 27: ep_len:500 episode reward: total was -4.430000. running mean: -29.789674\n",
      "ep 27: ep_len:2375 episode reward: total was -305.820000. running mean: -32.549977\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 27: ep_len:275 episode reward: total was 26.000000. running mean: -31.964478\n",
      "ep 27: ep_len:890 episode reward: total was -6.540000. running mean: -31.710233\n",
      "ep 27: ep_len:1800 episode reward: total was -161.080000. running mean: -33.003930\n",
      "ep 27: ep_len:500 episode reward: total was 47.000000. running mean: -32.203891\n",
      "ep 27: ep_len:500 episode reward: total was 30.670000. running mean: -31.575152\n",
      "ep 27: ep_len:900 episode reward: total was -4.580000. running mean: -31.305201\n",
      "ep 27: ep_len:820 episode reward: total was 2.380000. running mean: -30.968349\n",
      "ep 27: ep_len:500 episode reward: total was 13.790000. running mean: -30.520765\n",
      "ep 27: ep_len:960 episode reward: total was -13.630000. running mean: -30.351858\n",
      "ep 27: ep_len:620 episode reward: total was -23.050000. running mean: -30.278839\n",
      "ep 27: ep_len:500 episode reward: total was -6.880000. running mean: -30.044851\n",
      "ep 27: ep_len:500 episode reward: total was 30.750000. running mean: -29.436902\n",
      "ep 27: ep_len:500 episode reward: total was 31.300000. running mean: -28.829533\n",
      "ep 27: ep_len:565 episode reward: total was -20.130000. running mean: -28.742538\n",
      "ep 27: ep_len:500 episode reward: total was -17.810000. running mean: -28.633212\n",
      "ep 27: ep_len:500 episode reward: total was -53.970000. running mean: -28.886580\n",
      "ep 27: ep_len:830 episode reward: total was -10.510000. running mean: -28.702814\n",
      "ep 27: ep_len:500 episode reward: total was 13.390000. running mean: -28.281886\n",
      "ep 27: ep_len:765 episode reward: total was -11.130000. running mean: -28.110367\n",
      "ep 27: ep_len:500 episode reward: total was -0.820000. running mean: -27.837464\n",
      "ep 27: ep_len:510 episode reward: total was 2.840000. running mean: -27.530689\n",
      "ep 27: ep_len:203 episode reward: total was 20.000000. running mean: -27.055382\n",
      "ep 27: ep_len:500 episode reward: total was 14.120000. running mean: -26.643628\n",
      "ep 27: ep_len:500 episode reward: total was 50.000000. running mean: -25.877192\n",
      "ep 27: ep_len:580 episode reward: total was -13.030000. running mean: -25.748720\n",
      "ep 27: ep_len:500 episode reward: total was 8.150000. running mean: -25.409733\n",
      "ep 27: ep_len:980 episode reward: total was -33.220000. running mean: -25.487836\n",
      "ep 27: ep_len:500 episode reward: total was -18.170000. running mean: -25.414657\n",
      "ep 27: ep_len:290 episode reward: total was 4.120000. running mean: -25.119311\n",
      "ep 27: ep_len:875 episode reward: total was -17.160000. running mean: -25.039718\n",
      "ep 27: ep_len:1295 episode reward: total was -124.840000. running mean: -26.037720\n",
      "ep 27: ep_len:500 episode reward: total was 23.740000. running mean: -25.539943\n",
      "ep 27: ep_len:500 episode reward: total was 26.800000. running mean: -25.016544\n",
      "ep 27: ep_len:930 episode reward: total was -5.540000. running mean: -24.821778\n",
      "ep 27: ep_len:855 episode reward: total was -27.630000. running mean: -24.849861\n",
      "ep 27: ep_len:500 episode reward: total was 14.710000. running mean: -24.454262\n",
      "ep 27: ep_len:805 episode reward: total was -1.650000. running mean: -24.226219\n",
      "ep 27: ep_len:500 episode reward: total was 26.280000. running mean: -23.721157\n",
      "ep 27: ep_len:655 episode reward: total was -42.440000. running mean: -23.908346\n",
      "ep 27: ep_len:500 episode reward: total was 7.660000. running mean: -23.592662\n",
      "ep 27: ep_len:214 episode reward: total was 18.000000. running mean: -23.176736\n",
      "ep 27: ep_len:1190 episode reward: total was 21.970000. running mean: -22.725268\n",
      "ep 27: ep_len:292 episode reward: total was 29.500000. running mean: -22.203015\n",
      "ep 27: ep_len:915 episode reward: total was 0.520000. running mean: -21.975785\n",
      "ep 27: ep_len:500 episode reward: total was -24.880000. running mean: -22.004827\n",
      "ep 27: ep_len:725 episode reward: total was -2.640000. running mean: -21.811179\n",
      "ep 27: ep_len:815 episode reward: total was -59.510000. running mean: -22.188167\n",
      "ep 27: ep_len:520 episode reward: total was -2.560000. running mean: -21.991886\n",
      "ep 27: ep_len:500 episode reward: total was 24.290000. running mean: -21.529067\n",
      "ep 27: ep_len:500 episode reward: total was 4.630000. running mean: -21.267476\n",
      "ep 27: ep_len:850 episode reward: total was -21.580000. running mean: -21.270601\n",
      "ep 27: ep_len:500 episode reward: total was -10.180000. running mean: -21.159695\n",
      "ep 27: ep_len:500 episode reward: total was 27.810000. running mean: -20.669998\n",
      "ep 27: ep_len:500 episode reward: total was -19.770000. running mean: -20.660999\n",
      "ep 27: ep_len:251 episode reward: total was 25.000000. running mean: -20.204389\n",
      "ep 27: ep_len:575 episode reward: total was -4.830000. running mean: -20.050645\n",
      "ep 27: ep_len:500 episode reward: total was 10.330000. running mean: -19.746838\n",
      "ep 27: ep_len:770 episode reward: total was -57.180000. running mean: -20.121170\n",
      "ep 27: ep_len:1603 episode reward: total was -236.700000. running mean: -22.286958\n",
      "ep 27: ep_len:775 episode reward: total was -63.140000. running mean: -22.695489\n",
      "ep 27: ep_len:720 episode reward: total was -3.660000. running mean: -22.505134\n",
      "ep 27: ep_len:500 episode reward: total was 17.840000. running mean: -22.101682\n",
      "ep 27: ep_len:680 episode reward: total was 8.610000. running mean: -21.794565\n",
      "ep 27: ep_len:500 episode reward: total was -0.240000. running mean: -21.579020\n",
      "ep 27: ep_len:500 episode reward: total was 16.820000. running mean: -21.195030\n",
      "ep 27: ep_len:500 episode reward: total was 23.830000. running mean: -20.744779\n",
      "ep 27: ep_len:500 episode reward: total was 3.430000. running mean: -20.503032\n",
      "ep 27: ep_len:785 episode reward: total was -3.530000. running mean: -20.333301\n",
      "ep 27: ep_len:590 episode reward: total was -10.990000. running mean: -20.239868\n",
      "ep 27: ep_len:500 episode reward: total was 19.760000. running mean: -19.839870\n",
      "ep 27: ep_len:770 episode reward: total was -22.590000. running mean: -19.867371\n",
      "ep 27: ep_len:520 episode reward: total was -8.100000. running mean: -19.749697\n",
      "ep 27: ep_len:500 episode reward: total was 19.020000. running mean: -19.362000\n",
      "ep 27: ep_len:500 episode reward: total was 14.810000. running mean: -19.020280\n",
      "ep 27: ep_len:500 episode reward: total was -29.010000. running mean: -19.120177\n",
      "ep 27: ep_len:500 episode reward: total was -19.490000. running mean: -19.123876\n",
      "ep 27: ep_len:500 episode reward: total was 16.310000. running mean: -18.769537\n",
      "ep 27: ep_len:500 episode reward: total was -41.500000. running mean: -18.996841\n",
      "ep 27: ep_len:500 episode reward: total was 28.300000. running mean: -18.523873\n",
      "ep 27: ep_len:725 episode reward: total was -0.620000. running mean: -18.344834\n",
      "ep 27: ep_len:910 episode reward: total was 8.920000. running mean: -18.072186\n",
      "ep 27: ep_len:550 episode reward: total was 18.360000. running mean: -17.707864\n",
      "ep 27: ep_len:500 episode reward: total was 23.340000. running mean: -17.297385\n",
      "ep 27: ep_len:500 episode reward: total was 16.850000. running mean: -16.955912\n",
      "ep 27: ep_len:945 episode reward: total was 14.860000. running mean: -16.637752\n",
      "ep 27: ep_len:500 episode reward: total was 26.280000. running mean: -16.208575\n",
      "ep 27: ep_len:500 episode reward: total was -6.150000. running mean: -16.107989\n",
      "ep 27: ep_len:815 episode reward: total was -44.880000. running mean: -16.395709\n",
      "ep 27: ep_len:775 episode reward: total was -3.550000. running mean: -16.267252\n",
      "ep 27: ep_len:610 episode reward: total was -80.640000. running mean: -16.910980\n",
      "ep 27: ep_len:500 episode reward: total was -5.690000. running mean: -16.798770\n",
      "ep 27: ep_len:700 episode reward: total was -2.690000. running mean: -16.657682\n",
      "ep 27: ep_len:500 episode reward: total was 26.830000. running mean: -16.222805\n",
      "ep 27: ep_len:500 episode reward: total was -3.600000. running mean: -16.096577\n",
      "ep 27: ep_len:575 episode reward: total was 6.000000. running mean: -15.875612\n",
      "ep 27: ep_len:107 episode reward: total was 10.500000. running mean: -15.611855\n",
      "ep 27: ep_len:811 episode reward: total was -131.730000. running mean: -16.773037\n",
      "ep 27: ep_len:695 episode reward: total was -4.720000. running mean: -16.652507\n",
      "ep 27: ep_len:880 episode reward: total was -26.570000. running mean: -16.751681\n",
      "ep 27: ep_len:1895 episode reward: total was -269.970000. running mean: -19.283865\n",
      "ep 27: ep_len:735 episode reward: total was 1.420000. running mean: -19.076826\n",
      "ep 27: ep_len:500 episode reward: total was 18.720000. running mean: -18.698858\n",
      "ep 27: ep_len:341 episode reward: total was 32.500000. running mean: -18.186869\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 27: ep_len:570 episode reward: total was -21.130000. running mean: -18.216300\n",
      "ep 27: ep_len:500 episode reward: total was 19.330000. running mean: -17.840837\n",
      "ep 27: ep_len:500 episode reward: total was 6.770000. running mean: -17.594729\n",
      "ep 27: ep_len:680 episode reward: total was -7.780000. running mean: -17.496582\n",
      "ep 27: ep_len:560 episode reward: total was 6.800000. running mean: -17.253616\n",
      "ep 27: ep_len:500 episode reward: total was 8.760000. running mean: -16.993480\n",
      "ep 27: ep_len:500 episode reward: total was 27.330000. running mean: -16.550245\n",
      "ep 27: ep_len:1055 episode reward: total was -92.970000. running mean: -17.314443\n",
      "ep 27: ep_len:580 episode reward: total was 14.350000. running mean: -16.997798\n",
      "ep 27: ep_len:500 episode reward: total was 25.790000. running mean: -16.569920\n",
      "ep 27: ep_len:515 episode reward: total was -22.250000. running mean: -16.626721\n",
      "ep 27: ep_len:1170 episode reward: total was -92.620000. running mean: -17.386654\n",
      "ep 27: ep_len:610 episode reward: total was -16.000000. running mean: -17.372787\n",
      "ep 27: ep_len:555 episode reward: total was 8.300000. running mean: -17.116059\n",
      "ep 27: ep_len:991 episode reward: total was -100.610000. running mean: -17.950999\n",
      "ep 27: ep_len:995 episode reward: total was 15.330000. running mean: -17.618189\n",
      "ep 27: ep_len:500 episode reward: total was 26.400000. running mean: -17.178007\n",
      "ep 27: ep_len:540 episode reward: total was -2.000000. running mean: -17.026227\n",
      "ep 27: ep_len:860 episode reward: total was -87.300000. running mean: -17.728965\n",
      "ep 27: ep_len:500 episode reward: total was 11.890000. running mean: -17.432775\n",
      "ep 27: ep_len:500 episode reward: total was 9.280000. running mean: -17.165647\n",
      "ep 27: ep_len:610 episode reward: total was 9.840000. running mean: -16.895591\n",
      "ep 27: ep_len:500 episode reward: total was 20.370000. running mean: -16.522935\n",
      "ep 27: ep_len:540 episode reward: total was 0.050000. running mean: -16.357205\n",
      "ep 27: ep_len:500 episode reward: total was 24.010000. running mean: -15.953533\n",
      "ep 27: ep_len:605 episode reward: total was 4.420000. running mean: -15.749798\n",
      "ep 27: ep_len:2170 episode reward: total was -281.070000. running mean: -18.403000\n",
      "ep 27: ep_len:500 episode reward: total was -6.670000. running mean: -18.285670\n",
      "ep 27: ep_len:700 episode reward: total was -15.820000. running mean: -18.261013\n",
      "ep 27: ep_len:815 episode reward: total was -17.610000. running mean: -18.254503\n",
      "ep 27: ep_len:760 episode reward: total was 22.060000. running mean: -17.851358\n",
      "ep 27: ep_len:244 episode reward: total was 24.000000. running mean: -17.432845\n",
      "ep 27: ep_len:500 episode reward: total was 24.350000. running mean: -17.015016\n",
      "ep 27: ep_len:625 episode reward: total was -74.530000. running mean: -17.590166\n",
      "ep 27: ep_len:665 episode reward: total was 34.880000. running mean: -17.065464\n",
      "ep 27: ep_len:540 episode reward: total was -12.930000. running mean: -17.024110\n",
      "ep 27: ep_len:600 episode reward: total was 12.850000. running mean: -16.725369\n",
      "ep 27: ep_len:720 episode reward: total was -15.780000. running mean: -16.715915\n",
      "ep 27: ep_len:500 episode reward: total was 13.330000. running mean: -16.415456\n",
      "ep 27: ep_len:515 episode reward: total was -5.080000. running mean: -16.302101\n",
      "ep 27: ep_len:500 episode reward: total was 25.920000. running mean: -15.879880\n",
      "ep 27: ep_len:750 episode reward: total was -12.690000. running mean: -15.847981\n",
      "ep 27: ep_len:1047 episode reward: total was -83.790000. running mean: -16.527402\n",
      "ep 27: ep_len:705 episode reward: total was -30.440000. running mean: -16.666528\n",
      "ep 27: ep_len:500 episode reward: total was -0.450000. running mean: -16.504362\n",
      "ep 27: ep_len:500 episode reward: total was 17.520000. running mean: -16.164119\n",
      "ep 27: ep_len:730 episode reward: total was -11.200000. running mean: -16.114477\n",
      "ep 27: ep_len:500 episode reward: total was 14.260000. running mean: -15.810733\n",
      "ep 27: ep_len:900 episode reward: total was 0.780000. running mean: -15.644825\n",
      "ep 27: ep_len:500 episode reward: total was 29.830000. running mean: -15.190077\n",
      "ep 27: ep_len:795 episode reward: total was -11.220000. running mean: -15.150376\n",
      "ep 27: ep_len:535 episode reward: total was 22.040000. running mean: -14.778473\n",
      "ep 27: ep_len:500 episode reward: total was 3.130000. running mean: -14.599388\n",
      "ep 27: ep_len:500 episode reward: total was 28.270000. running mean: -14.170694\n",
      "ep 27: ep_len:700 episode reward: total was 17.920000. running mean: -13.849787\n",
      "ep 27: ep_len:500 episode reward: total was 28.330000. running mean: -13.427989\n",
      "ep 27: ep_len:102 episode reward: total was 10.000000. running mean: -13.193709\n",
      "ep 27: ep_len:500 episode reward: total was 1.900000. running mean: -13.042772\n",
      "ep 27: ep_len:461 episode reward: total was 24.300000. running mean: -12.669344\n",
      "ep 27: ep_len:500 episode reward: total was -59.680000. running mean: -13.139451\n",
      "ep 27: ep_len:286 episode reward: total was 28.500000. running mean: -12.723057\n",
      "ep 27: ep_len:520 episode reward: total was -29.310000. running mean: -12.888926\n",
      "ep 27: ep_len:500 episode reward: total was 18.820000. running mean: -12.571837\n",
      "ep 27: ep_len:515 episode reward: total was -2.200000. running mean: -12.468118\n",
      "ep 27: ep_len:695 episode reward: total was -25.930000. running mean: -12.602737\n",
      "ep 27: ep_len:2760 episode reward: total was -439.990000. running mean: -16.876610\n",
      "ep 27: ep_len:500 episode reward: total was -0.210000. running mean: -16.709944\n",
      "ep 27: ep_len:5465 episode reward: total was -887.850000. running mean: -25.421344\n",
      "ep 27: ep_len:902 episode reward: total was -72.940000. running mean: -25.896531\n",
      "ep 27: ep_len:680 episode reward: total was -64.340000. running mean: -26.280965\n",
      "ep 27: ep_len:500 episode reward: total was 1.940000. running mean: -25.998756\n",
      "ep 27: ep_len:500 episode reward: total was 50.000000. running mean: -25.238768\n",
      "ep 27: ep_len:500 episode reward: total was 48.500000. running mean: -24.501381\n",
      "ep 27: ep_len:500 episode reward: total was -7.610000. running mean: -24.332467\n",
      "ep 27: ep_len:284 episode reward: total was -18.000000. running mean: -24.269142\n",
      "epsilon:0.010000 episode_count: 22068. steps_count: 15857298.000000\n",
      "ep 28: ep_len:500 episode reward: total was 21.320000. running mean: -23.813251\n",
      "ep 28: ep_len:780 episode reward: total was -47.460000. running mean: -24.049718\n",
      "ep 28: ep_len:800 episode reward: total was 11.060000. running mean: -23.698621\n",
      "ep 28: ep_len:2644 episode reward: total was -453.260000. running mean: -27.994235\n",
      "ep 28: ep_len:500 episode reward: total was 3.770000. running mean: -27.676592\n",
      "ep 28: ep_len:560 episode reward: total was 6.990000. running mean: -27.329927\n",
      "ep 28: ep_len:725 episode reward: total was -22.840000. running mean: -27.285027\n",
      "ep 28: ep_len:500 episode reward: total was 23.370000. running mean: -26.778477\n",
      "ep 28: ep_len:985 episode reward: total was -10.800000. running mean: -26.618692\n",
      "ep 28: ep_len:500 episode reward: total was 14.090000. running mean: -26.211605\n",
      "ep 28: ep_len:520 episode reward: total was 7.760000. running mean: -25.871889\n",
      "ep 28: ep_len:660 episode reward: total was -18.930000. running mean: -25.802470\n",
      "ep 28: ep_len:500 episode reward: total was 3.250000. running mean: -25.511946\n",
      "ep 28: ep_len:910 episode reward: total was -46.710000. running mean: -25.723926\n",
      "ep 28: ep_len:815 episode reward: total was -33.770000. running mean: -25.804387\n",
      "ep 28: ep_len:500 episode reward: total was 29.340000. running mean: -25.252943\n",
      "ep 28: ep_len:820 episode reward: total was 15.220000. running mean: -24.848214\n",
      "ep 28: ep_len:500 episode reward: total was 16.430000. running mean: -24.435431\n",
      "ep 28: ep_len:570 episode reward: total was -2.950000. running mean: -24.220577\n",
      "ep 28: ep_len:500 episode reward: total was 10.820000. running mean: -23.870171\n",
      "ep 28: ep_len:1425 episode reward: total was -121.920000. running mean: -24.850670\n",
      "ep 28: ep_len:251 episode reward: total was -50.000000. running mean: -25.102163\n",
      "ep 28: ep_len:930 episode reward: total was -48.660000. running mean: -25.337741\n",
      "ep 28: ep_len:2092 episode reward: total was -341.270000. running mean: -28.497064\n",
      "ep 28: ep_len:500 episode reward: total was 11.700000. running mean: -28.095093\n",
      "ep 28: ep_len:153 episode reward: total was 13.500000. running mean: -27.679142\n",
      "ep 28: ep_len:500 episode reward: total was -13.390000. running mean: -27.536251\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 28: ep_len:500 episode reward: total was 25.790000. running mean: -27.002988\n",
      "ep 28: ep_len:15534 episode reward: total was -2936.350000. running mean: -56.096459\n",
      "ep 28: ep_len:500 episode reward: total was 6.040000. running mean: -55.475094\n",
      "ep 28: ep_len:500 episode reward: total was 23.830000. running mean: -54.682043\n",
      "ep 28: ep_len:745 episode reward: total was 9.390000. running mean: -54.041323\n",
      "ep 28: ep_len:500 episode reward: total was -11.260000. running mean: -53.613509\n",
      "ep 28: ep_len:625 episode reward: total was -9.480000. running mean: -53.172174\n",
      "ep 28: ep_len:695 episode reward: total was -14.430000. running mean: -52.784753\n",
      "ep 28: ep_len:500 episode reward: total was 28.790000. running mean: -51.969005\n",
      "ep 28: ep_len:500 episode reward: total was -3.760000. running mean: -51.486915\n",
      "ep 28: ep_len:875 episode reward: total was 4.320000. running mean: -50.928846\n",
      "ep 28: ep_len:500 episode reward: total was 5.500000. running mean: -50.364557\n",
      "ep 28: ep_len:730 episode reward: total was 11.470000. running mean: -49.746212\n",
      "ep 28: ep_len:1349 episode reward: total was -99.990000. running mean: -50.248650\n",
      "ep 28: ep_len:650 episode reward: total was 5.910000. running mean: -49.687063\n",
      "ep 28: ep_len:530 episode reward: total was -8.050000. running mean: -49.270693\n",
      "ep 28: ep_len:560 episode reward: total was -34.280000. running mean: -49.120786\n",
      "ep 28: ep_len:675 episode reward: total was -3.230000. running mean: -48.661878\n",
      "ep 28: ep_len:206 episode reward: total was 14.500000. running mean: -48.030259\n",
      "ep 28: ep_len:500 episode reward: total was 2.800000. running mean: -47.521956\n",
      "ep 28: ep_len:735 episode reward: total was -11.710000. running mean: -47.163837\n",
      "ep 28: ep_len:840 episode reward: total was -38.770000. running mean: -47.079898\n",
      "ep 28: ep_len:203 episode reward: total was 18.500000. running mean: -46.424099\n",
      "ep 28: ep_len:810 episode reward: total was 11.770000. running mean: -45.842158\n",
      "ep 28: ep_len:1135 episode reward: total was -105.040000. running mean: -46.434137\n",
      "ep 28: ep_len:500 episode reward: total was 8.070000. running mean: -45.889096\n",
      "ep 28: ep_len:500 episode reward: total was 16.270000. running mean: -45.267505\n",
      "ep 28: ep_len:680 episode reward: total was 3.270000. running mean: -44.782130\n",
      "ep 28: ep_len:176 episode reward: total was 17.500000. running mean: -44.159308\n",
      "ep 28: ep_len:790 episode reward: total was -0.220000. running mean: -43.719915\n",
      "ep 28: ep_len:920 episode reward: total was -8.560000. running mean: -43.368316\n",
      "ep 28: ep_len:500 episode reward: total was -3.570000. running mean: -42.970333\n",
      "ep 28: ep_len:478 episode reward: total was 46.500000. running mean: -42.075630\n",
      "ep 28: ep_len:1030 episode reward: total was -29.600000. running mean: -41.950873\n",
      "ep 28: ep_len:500 episode reward: total was -17.290000. running mean: -41.704264\n",
      "ep 28: ep_len:515 episode reward: total was -6.090000. running mean: -41.348122\n",
      "ep 28: ep_len:840 episode reward: total was -8.230000. running mean: -41.016941\n",
      "ep 28: ep_len:500 episode reward: total was -9.790000. running mean: -40.704671\n",
      "ep 28: ep_len:1120 episode reward: total was -54.370000. running mean: -40.841324\n",
      "ep 28: ep_len:620 episode reward: total was -19.010000. running mean: -40.623011\n",
      "ep 28: ep_len:500 episode reward: total was 24.380000. running mean: -39.972981\n",
      "ep 28: ep_len:565 episode reward: total was -8.010000. running mean: -39.653351\n",
      "ep 28: ep_len:755 episode reward: total was -11.670000. running mean: -39.373518\n",
      "ep 28: ep_len:166 episode reward: total was 17.000000. running mean: -38.809783\n",
      "ep 28: ep_len:500 episode reward: total was -27.880000. running mean: -38.700485\n",
      "ep 28: ep_len:1000 episode reward: total was 22.690000. running mean: -38.086580\n",
      "ep 28: ep_len:705 episode reward: total was -38.470000. running mean: -38.090414\n",
      "ep 28: ep_len:500 episode reward: total was -49.550000. running mean: -38.205010\n",
      "ep 28: ep_len:500 episode reward: total was -22.310000. running mean: -38.046060\n",
      "ep 28: ep_len:500 episode reward: total was 30.260000. running mean: -37.362999\n",
      "ep 28: ep_len:1935 episode reward: total was -247.670000. running mean: -39.466069\n",
      "ep 28: ep_len:805 episode reward: total was 14.730000. running mean: -38.924109\n",
      "ep 28: ep_len:500 episode reward: total was 17.740000. running mean: -38.357468\n",
      "ep 28: ep_len:500 episode reward: total was 10.120000. running mean: -37.872693\n",
      "ep 28: ep_len:655 episode reward: total was -6.820000. running mean: -37.562166\n",
      "ep 28: ep_len:69 episode reward: total was 6.500000. running mean: -37.121544\n",
      "ep 28: ep_len:500 episode reward: total was -1.100000. running mean: -36.761329\n",
      "ep 28: ep_len:500 episode reward: total was -20.960000. running mean: -36.603316\n",
      "ep 28: ep_len:575 episode reward: total was -1.900000. running mean: -36.256282\n",
      "ep 28: ep_len:630 episode reward: total was -23.030000. running mean: -36.124020\n",
      "ep 28: ep_len:595 episode reward: total was 25.010000. running mean: -35.512679\n",
      "ep 28: ep_len:890 episode reward: total was 5.170000. running mean: -35.105853\n",
      "ep 28: ep_len:500 episode reward: total was -17.990000. running mean: -34.934694\n",
      "ep 28: ep_len:500 episode reward: total was -2.840000. running mean: -34.613747\n",
      "ep 28: ep_len:990 episode reward: total was -3.460000. running mean: -34.302210\n",
      "ep 28: ep_len:500 episode reward: total was 11.860000. running mean: -33.840588\n",
      "ep 28: ep_len:500 episode reward: total was 21.840000. running mean: -33.283782\n",
      "ep 28: ep_len:500 episode reward: total was 14.340000. running mean: -32.807544\n",
      "ep 28: ep_len:140 episode reward: total was 11.500000. running mean: -32.364468\n",
      "ep 28: ep_len:500 episode reward: total was 25.790000. running mean: -31.782924\n",
      "ep 28: ep_len:500 episode reward: total was 23.770000. running mean: -31.227394\n",
      "ep 28: ep_len:850 episode reward: total was -3.100000. running mean: -30.946121\n",
      "ep 28: ep_len:840 episode reward: total was -3.870000. running mean: -30.675359\n",
      "ep 28: ep_len:505 episode reward: total was -11.160000. running mean: -30.480206\n",
      "ep 28: ep_len:950 episode reward: total was -44.310000. running mean: -30.618504\n",
      "ep 28: ep_len:500 episode reward: total was 28.210000. running mean: -30.030219\n",
      "ep 28: ep_len:500 episode reward: total was -37.950000. running mean: -30.109416\n",
      "ep 28: ep_len:355 episode reward: total was 34.000000. running mean: -29.468322\n",
      "ep 28: ep_len:837 episode reward: total was -63.000000. running mean: -29.803639\n",
      "ep 28: ep_len:570 episode reward: total was -11.030000. running mean: -29.615903\n",
      "ep 28: ep_len:720 episode reward: total was -9.680000. running mean: -29.416544\n",
      "ep 28: ep_len:500 episode reward: total was 16.890000. running mean: -28.953478\n",
      "ep 28: ep_len:500 episode reward: total was 24.320000. running mean: -28.420743\n",
      "ep 28: ep_len:5425 episode reward: total was -862.130000. running mean: -36.757836\n",
      "ep 28: ep_len:500 episode reward: total was 0.740000. running mean: -36.382858\n",
      "ep 28: ep_len:950 episode reward: total was 17.210000. running mean: -35.846929\n",
      "ep 28: ep_len:271 episode reward: total was 25.500000. running mean: -35.233460\n",
      "ep 28: ep_len:820 episode reward: total was -32.720000. running mean: -35.208325\n",
      "ep 28: ep_len:700 episode reward: total was -20.870000. running mean: -35.064942\n",
      "ep 28: ep_len:500 episode reward: total was -6.960000. running mean: -34.783893\n",
      "ep 28: ep_len:1050 episode reward: total was -6.810000. running mean: -34.504154\n",
      "ep 28: ep_len:500 episode reward: total was 34.770000. running mean: -33.811412\n",
      "ep 28: ep_len:500 episode reward: total was -13.250000. running mean: -33.605798\n",
      "ep 28: ep_len:1685 episode reward: total was -293.620000. running mean: -36.205940\n",
      "ep 28: ep_len:500 episode reward: total was -21.450000. running mean: -36.058381\n",
      "ep 28: ep_len:795 episode reward: total was 1.760000. running mean: -35.680197\n",
      "ep 28: ep_len:500 episode reward: total was 48.500000. running mean: -34.838395\n",
      "ep 28: ep_len:745 episode reward: total was -27.850000. running mean: -34.768511\n",
      "ep 28: ep_len:790 episode reward: total was -7.650000. running mean: -34.497326\n",
      "ep 28: ep_len:500 episode reward: total was 32.860000. running mean: -33.823752\n",
      "ep 28: ep_len:880 episode reward: total was -26.570000. running mean: -33.751215\n",
      "ep 28: ep_len:1419 episode reward: total was -169.530000. running mean: -35.109003\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 28: ep_len:500 episode reward: total was 25.880000. running mean: -34.499113\n",
      "ep 28: ep_len:500 episode reward: total was 20.380000. running mean: -33.950322\n",
      "ep 28: ep_len:2152 episode reward: total was -194.700000. running mean: -35.557818\n",
      "ep 28: ep_len:1540 episode reward: total was -144.920000. running mean: -36.651440\n",
      "ep 28: ep_len:1045 episode reward: total was -33.320000. running mean: -36.618126\n",
      "ep 28: ep_len:500 episode reward: total was -8.900000. running mean: -36.340945\n",
      "ep 28: ep_len:720 episode reward: total was -2.360000. running mean: -36.001135\n",
      "ep 28: ep_len:500 episode reward: total was 48.500000. running mean: -35.156124\n",
      "ep 28: ep_len:500 episode reward: total was 17.230000. running mean: -34.632263\n",
      "ep 28: ep_len:875 episode reward: total was 4.080000. running mean: -34.245140\n",
      "ep 28: ep_len:1510 episode reward: total was -54.600000. running mean: -34.448689\n",
      "ep 28: ep_len:500 episode reward: total was 21.780000. running mean: -33.886402\n",
      "ep 28: ep_len:500 episode reward: total was 6.370000. running mean: -33.483838\n",
      "ep 28: ep_len:575 episode reward: total was -10.010000. running mean: -33.249099\n",
      "ep 28: ep_len:304 episode reward: total was 28.500000. running mean: -32.631608\n",
      "ep 28: ep_len:500 episode reward: total was 3.070000. running mean: -32.274592\n",
      "ep 28: ep_len:660 episode reward: total was -1.760000. running mean: -31.969446\n",
      "ep 28: ep_len:500 episode reward: total was 6.690000. running mean: -31.582852\n",
      "ep 28: ep_len:500 episode reward: total was 24.690000. running mean: -31.020123\n",
      "ep 28: ep_len:605 episode reward: total was -14.970000. running mean: -30.859622\n",
      "ep 28: ep_len:525 episode reward: total was -48.490000. running mean: -31.035926\n",
      "ep 28: ep_len:1005 episode reward: total was 15.850000. running mean: -30.567067\n",
      "ep 28: ep_len:500 episode reward: total was 15.500000. running mean: -30.106396\n",
      "ep 28: ep_len:500 episode reward: total was -7.370000. running mean: -29.879032\n",
      "ep 28: ep_len:515 episode reward: total was 11.860000. running mean: -29.461642\n",
      "ep 28: ep_len:970 episode reward: total was 17.210000. running mean: -28.994925\n",
      "ep 28: ep_len:900 episode reward: total was 15.130000. running mean: -28.553676\n",
      "ep 28: ep_len:467 episode reward: total was 31.820000. running mean: -27.949939\n",
      "ep 28: ep_len:500 episode reward: total was 24.840000. running mean: -27.422040\n",
      "ep 28: ep_len:650 episode reward: total was 12.290000. running mean: -27.024919\n",
      "ep 28: ep_len:500 episode reward: total was -4.430000. running mean: -26.798970\n",
      "ep 28: ep_len:605 episode reward: total was -11.700000. running mean: -26.647980\n",
      "ep 28: ep_len:308 episode reward: total was 30.500000. running mean: -26.076501\n",
      "ep 28: ep_len:765 episode reward: total was 9.630000. running mean: -25.719436\n",
      "ep 28: ep_len:500 episode reward: total was 21.780000. running mean: -25.244441\n",
      "ep 28: ep_len:484 episode reward: total was 34.750000. running mean: -24.644497\n",
      "ep 28: ep_len:810 episode reward: total was -25.710000. running mean: -24.655152\n",
      "ep 28: ep_len:660 episode reward: total was -0.750000. running mean: -24.416100\n",
      "ep 28: ep_len:500 episode reward: total was 6.650000. running mean: -24.105439\n",
      "ep 28: ep_len:1035 episode reward: total was -3.340000. running mean: -23.897785\n",
      "ep 28: ep_len:500 episode reward: total was 16.120000. running mean: -23.497607\n",
      "ep 28: ep_len:930 episode reward: total was -26.240000. running mean: -23.525031\n",
      "ep 28: ep_len:760 episode reward: total was 4.410000. running mean: -23.245681\n",
      "ep 28: ep_len:1125 episode reward: total was -8.060000. running mean: -23.093824\n",
      "ep 28: ep_len:865 episode reward: total was 13.690000. running mean: -22.725986\n",
      "ep 28: ep_len:500 episode reward: total was 21.380000. running mean: -22.284926\n",
      "ep 28: ep_len:745 episode reward: total was -13.710000. running mean: -22.199177\n",
      "ep 28: ep_len:500 episode reward: total was 50.000000. running mean: -21.477185\n",
      "ep 28: ep_len:500 episode reward: total was -24.820000. running mean: -21.510613\n",
      "ep 28: ep_len:735 episode reward: total was 3.970000. running mean: -21.255807\n",
      "ep 28: ep_len:500 episode reward: total was -4.640000. running mean: -21.089649\n",
      "ep 28: ep_len:590 episode reward: total was -49.090000. running mean: -21.369652\n",
      "ep 28: ep_len:955 episode reward: total was 9.140000. running mean: -21.064556\n",
      "ep 28: ep_len:1183 episode reward: total was -116.380000. running mean: -22.017710\n",
      "ep 28: ep_len:500 episode reward: total was 50.000000. running mean: -21.297533\n",
      "ep 28: ep_len:500 episode reward: total was 28.790000. running mean: -20.796658\n",
      "ep 28: ep_len:505 episode reward: total was -8.130000. running mean: -20.669991\n",
      "ep 28: ep_len:500 episode reward: total was 1.870000. running mean: -20.444591\n",
      "ep 28: ep_len:500 episode reward: total was -6.130000. running mean: -20.301445\n",
      "ep 28: ep_len:830 episode reward: total was 7.650000. running mean: -20.021931\n",
      "ep 28: ep_len:196 episode reward: total was 19.500000. running mean: -19.626712\n",
      "ep 28: ep_len:810 episode reward: total was -5.990000. running mean: -19.490345\n",
      "ep 28: ep_len:212 episode reward: total was 21.000000. running mean: -19.085441\n",
      "ep 28: ep_len:2482 episode reward: total was -346.550000. running mean: -22.360087\n",
      "ep 28: ep_len:500 episode reward: total was 16.390000. running mean: -21.972586\n",
      "ep 28: ep_len:2118 episode reward: total was -304.330000. running mean: -24.796160\n",
      "ep 28: ep_len:500 episode reward: total was 17.310000. running mean: -24.375098\n",
      "ep 28: ep_len:670 episode reward: total was -21.630000. running mean: -24.347647\n",
      "ep 28: ep_len:675 episode reward: total was -5.770000. running mean: -24.161871\n",
      "ep 28: ep_len:730 episode reward: total was -12.730000. running mean: -24.047552\n",
      "ep 28: ep_len:895 episode reward: total was 18.630000. running mean: -23.620777\n",
      "ep 28: ep_len:615 episode reward: total was -13.970000. running mean: -23.524269\n",
      "ep 28: ep_len:600 episode reward: total was -5.920000. running mean: -23.348226\n",
      "ep 28: ep_len:520 episode reward: total was -8.100000. running mean: -23.195744\n",
      "ep 28: ep_len:605 episode reward: total was -5.880000. running mean: -23.022587\n",
      "ep 28: ep_len:975 episode reward: total was 4.820000. running mean: -22.744161\n",
      "ep 28: ep_len:1508 episode reward: total was -268.730000. running mean: -25.204019\n",
      "ep 28: ep_len:500 episode reward: total was 30.320000. running mean: -24.648779\n",
      "ep 28: ep_len:775 episode reward: total was -5.570000. running mean: -24.457991\n",
      "ep 28: ep_len:875 episode reward: total was 8.810000. running mean: -24.125311\n",
      "ep 28: ep_len:860 episode reward: total was -78.120000. running mean: -24.665258\n",
      "ep 28: ep_len:620 episode reward: total was -2.850000. running mean: -24.447105\n",
      "ep 28: ep_len:292 episode reward: total was 27.500000. running mean: -23.927634\n",
      "ep 28: ep_len:840 episode reward: total was 13.590000. running mean: -23.552458\n",
      "ep 28: ep_len:700 episode reward: total was -7.220000. running mean: -23.389133\n",
      "ep 28: ep_len:605 episode reward: total was 20.060000. running mean: -22.954642\n",
      "ep 28: ep_len:500 episode reward: total was 16.850000. running mean: -22.556596\n",
      "ep 28: ep_len:542 episode reward: total was -19.150000. running mean: -22.522530\n",
      "ep 28: ep_len:745 episode reward: total was 6.960000. running mean: -22.227704\n",
      "ep 28: ep_len:169 episode reward: total was 16.500000. running mean: -21.840427\n",
      "ep 28: ep_len:500 episode reward: total was 11.670000. running mean: -21.505323\n",
      "ep 28: ep_len:885 episode reward: total was 7.300000. running mean: -21.217270\n",
      "ep 28: ep_len:1340 episode reward: total was -178.740000. running mean: -22.792497\n",
      "ep 28: ep_len:810 episode reward: total was -25.880000. running mean: -22.823372\n",
      "ep 28: ep_len:500 episode reward: total was -9.880000. running mean: -22.693939\n",
      "ep 28: ep_len:427 episode reward: total was 20.370000. running mean: -22.263299\n",
      "ep 28: ep_len:1632 episode reward: total was -275.090000. running mean: -24.791566\n",
      "ep 28: ep_len:500 episode reward: total was 9.250000. running mean: -24.451150\n",
      "ep 28: ep_len:500 episode reward: total was 31.820000. running mean: -23.888439\n",
      "ep 28: ep_len:500 episode reward: total was 9.740000. running mean: -23.552155\n",
      "ep 28: ep_len:680 episode reward: total was -6.770000. running mean: -23.384333\n",
      "ep 28: ep_len:550 episode reward: total was 28.770000. running mean: -22.862790\n",
      "ep 28: ep_len:580 episode reward: total was -17.070000. running mean: -22.804862\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 28: ep_len:500 episode reward: total was 25.820000. running mean: -22.318613\n",
      "ep 28: ep_len:500 episode reward: total was 29.310000. running mean: -21.802327\n",
      "ep 28: ep_len:715 episode reward: total was -25.890000. running mean: -21.843204\n",
      "ep 28: ep_len:505 episode reward: total was -14.190000. running mean: -21.766672\n",
      "ep 28: ep_len:500 episode reward: total was 14.010000. running mean: -21.408905\n",
      "ep 28: ep_len:510 episode reward: total was -8.120000. running mean: -21.276016\n",
      "ep 28: ep_len:705 episode reward: total was -2.680000. running mean: -21.090056\n",
      "ep 28: ep_len:760 episode reward: total was -8.630000. running mean: -20.965455\n",
      "ep 28: ep_len:600 episode reward: total was -7.940000. running mean: -20.835201\n",
      "ep 28: ep_len:500 episode reward: total was 2.800000. running mean: -20.598849\n",
      "ep 28: ep_len:975 episode reward: total was 11.690000. running mean: -20.275960\n",
      "ep 28: ep_len:500 episode reward: total was 16.970000. running mean: -19.903501\n",
      "ep 28: ep_len:540 episode reward: total was -19.170000. running mean: -19.896166\n",
      "ep 28: ep_len:590 episode reward: total was -6.950000. running mean: -19.766704\n",
      "ep 28: ep_len:500 episode reward: total was -18.240000. running mean: -19.751437\n",
      "ep 28: ep_len:354 episode reward: total was -6.500000. running mean: -19.618923\n",
      "ep 28: ep_len:500 episode reward: total was 31.790000. running mean: -19.104833\n",
      "ep 28: ep_len:950 episode reward: total was -40.570000. running mean: -19.319485\n",
      "ep 28: ep_len:500 episode reward: total was 7.850000. running mean: -19.047790\n",
      "ep 28: ep_len:500 episode reward: total was 20.830000. running mean: -18.649012\n",
      "ep 28: ep_len:1000 episode reward: total was -17.630000. running mean: -18.638822\n",
      "ep 28: ep_len:500 episode reward: total was -3.230000. running mean: -18.484734\n",
      "ep 28: ep_len:278 episode reward: total was 26.000000. running mean: -18.039887\n",
      "ep 28: ep_len:770 episode reward: total was -20.770000. running mean: -18.067188\n",
      "ep 28: ep_len:500 episode reward: total was 9.500000. running mean: -17.791516\n",
      "ep 28: ep_len:132 episode reward: total was 13.000000. running mean: -17.483601\n",
      "ep 28: ep_len:960 episode reward: total was 28.300000. running mean: -17.025765\n",
      "ep 28: ep_len:530 episode reward: total was -16.160000. running mean: -17.017107\n",
      "ep 28: ep_len:510 episode reward: total was -3.070000. running mean: -16.877636\n",
      "ep 28: ep_len:965 episode reward: total was -14.460000. running mean: -16.853460\n",
      "ep 28: ep_len:500 episode reward: total was 29.340000. running mean: -16.391525\n",
      "ep 28: ep_len:181 episode reward: total was 16.500000. running mean: -16.062610\n",
      "ep 28: ep_len:500 episode reward: total was 23.460000. running mean: -15.667384\n",
      "ep 28: ep_len:660 episode reward: total was -7.820000. running mean: -15.588910\n",
      "ep 28: ep_len:500 episode reward: total was 28.820000. running mean: -15.144821\n",
      "ep 28: ep_len:500 episode reward: total was 50.000000. running mean: -14.493372\n",
      "ep 28: ep_len:775 episode reward: total was 8.850000. running mean: -14.259939\n",
      "ep 28: ep_len:500 episode reward: total was 45.500000. running mean: -13.662339\n",
      "ep 28: ep_len:500 episode reward: total was 6.830000. running mean: -13.457416\n",
      "ep 28: ep_len:500 episode reward: total was -2.200000. running mean: -13.344842\n",
      "ep 28: ep_len:660 episode reward: total was -12.900000. running mean: -13.340393\n",
      "ep 28: ep_len:500 episode reward: total was 7.330000. running mean: -13.133689\n",
      "ep 28: ep_len:985 episode reward: total was 10.870000. running mean: -12.893653\n",
      "ep 28: ep_len:710 episode reward: total was -45.060000. running mean: -13.215316\n",
      "ep 28: ep_len:1285 episode reward: total was -162.110000. running mean: -14.704263\n",
      "ep 28: ep_len:735 episode reward: total was 5.310000. running mean: -14.504120\n",
      "ep 28: ep_len:825 episode reward: total was 39.240000. running mean: -13.966679\n",
      "ep 28: ep_len:500 episode reward: total was 5.250000. running mean: -13.774512\n",
      "ep 28: ep_len:330 episode reward: total was 20.000000. running mean: -13.436767\n",
      "ep 28: ep_len:610 episode reward: total was -22.060000. running mean: -13.522999\n",
      "ep 28: ep_len:1070 episode reward: total was -57.500000. running mean: -13.962769\n",
      "ep 28: ep_len:500 episode reward: total was 19.790000. running mean: -13.625242\n",
      "ep 28: ep_len:500 episode reward: total was 19.480000. running mean: -13.294189\n",
      "ep 28: ep_len:945 episode reward: total was 7.820000. running mean: -13.083047\n",
      "ep 28: ep_len:955 episode reward: total was -40.550000. running mean: -13.357717\n",
      "ep 28: ep_len:1400 episode reward: total was -70.980000. running mean: -13.933940\n",
      "ep 28: ep_len:700 episode reward: total was -5.720000. running mean: -13.851800\n",
      "ep 28: ep_len:800 episode reward: total was -21.680000. running mean: -13.930082\n",
      "ep 28: ep_len:585 episode reward: total was -13.020000. running mean: -13.920982\n",
      "ep 28: ep_len:655 episode reward: total was -0.140000. running mean: -13.783172\n",
      "ep 28: ep_len:730 episode reward: total was -11.720000. running mean: -13.762540\n",
      "ep 28: ep_len:980 episode reward: total was -32.430000. running mean: -13.949215\n",
      "ep 28: ep_len:500 episode reward: total was 27.900000. running mean: -13.530723\n",
      "ep 28: ep_len:500 episode reward: total was -29.870000. running mean: -13.694115\n",
      "ep 28: ep_len:585 episode reward: total was -9.990000. running mean: -13.657074\n",
      "ep 28: ep_len:140 episode reward: total was 12.500000. running mean: -13.395503\n",
      "ep 28: ep_len:233 episode reward: total was 23.000000. running mean: -13.031548\n",
      "ep 28: ep_len:545 episode reward: total was 9.040000. running mean: -12.810833\n",
      "ep 28: ep_len:1000 episode reward: total was -11.470000. running mean: -12.797425\n",
      "ep 28: ep_len:500 episode reward: total was 19.790000. running mean: -12.471550\n",
      "ep 28: ep_len:775 episode reward: total was -2.060000. running mean: -12.367435\n",
      "ep 28: ep_len:790 episode reward: total was -46.880000. running mean: -12.712560\n",
      "ep 28: ep_len:132 episode reward: total was 13.000000. running mean: -12.455435\n",
      "ep 28: ep_len:225 episode reward: total was 19.500000. running mean: -12.135881\n",
      "ep 28: ep_len:384 episode reward: total was 31.500000. running mean: -11.699522\n",
      "ep 28: ep_len:500 episode reward: total was -0.880000. running mean: -11.591326\n",
      "ep 28: ep_len:690 episode reward: total was -9.350000. running mean: -11.568913\n",
      "ep 28: ep_len:500 episode reward: total was 11.760000. running mean: -11.335624\n",
      "ep 28: ep_len:965 episode reward: total was 7.570000. running mean: -11.146568\n",
      "ep 28: ep_len:845 episode reward: total was -36.960000. running mean: -11.404702\n",
      "ep 28: ep_len:471 episode reward: total was 45.500000. running mean: -10.835655\n",
      "ep 28: ep_len:500 episode reward: total was -3.610000. running mean: -10.763399\n",
      "ep 28: ep_len:650 episode reward: total was -32.080000. running mean: -10.976565\n",
      "ep 28: ep_len:1080 episode reward: total was 18.780000. running mean: -10.678999\n",
      "ep 28: ep_len:885 episode reward: total was -13.030000. running mean: -10.702509\n",
      "ep 28: ep_len:710 episode reward: total was -31.960000. running mean: -10.915084\n",
      "ep 28: ep_len:570 episode reward: total was 16.810000. running mean: -10.637833\n",
      "ep 28: ep_len:725 episode reward: total was 9.250000. running mean: -10.438955\n",
      "ep 28: ep_len:895 episode reward: total was -11.140000. running mean: -10.445965\n",
      "ep 28: ep_len:500 episode reward: total was 6.790000. running mean: -10.273606\n",
      "ep 28: ep_len:500 episode reward: total was -2.630000. running mean: -10.197169\n",
      "ep 28: ep_len:540 episode reward: total was -44.420000. running mean: -10.539398\n",
      "ep 28: ep_len:535 episode reward: total was -28.270000. running mean: -10.716704\n",
      "ep 28: ep_len:364 episode reward: total was 11.210000. running mean: -10.497437\n",
      "ep 28: ep_len:990 episode reward: total was -13.220000. running mean: -10.524662\n",
      "ep 28: ep_len:500 episode reward: total was 8.770000. running mean: -10.331716\n",
      "ep 28: ep_len:735 episode reward: total was -7.540000. running mean: -10.303799\n",
      "ep 28: ep_len:214 episode reward: total was 18.500000. running mean: -10.015761\n",
      "ep 28: ep_len:945 episode reward: total was -16.620000. running mean: -10.081803\n",
      "ep 28: ep_len:1045 episode reward: total was 26.770000. running mean: -9.713285\n",
      "ep 28: ep_len:670 episode reward: total was -9.820000. running mean: -9.714352\n",
      "ep 28: ep_len:520 episode reward: total was -3.110000. running mean: -9.648309\n",
      "ep 28: ep_len:230 episode reward: total was 22.000000. running mean: -9.331826\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 28: ep_len:680 episode reward: total was 21.230000. running mean: -9.026207\n",
      "ep 28: ep_len:500 episode reward: total was 1.290000. running mean: -8.923045\n",
      "ep 28: ep_len:289 episode reward: total was 10.240000. running mean: -8.731415\n",
      "ep 28: ep_len:205 episode reward: total was 19.000000. running mean: -8.454101\n",
      "ep 28: ep_len:1075 episode reward: total was -104.440000. running mean: -9.413960\n",
      "ep 28: ep_len:680 episode reward: total was -9.720000. running mean: -9.417020\n",
      "ep 28: ep_len:500 episode reward: total was 15.380000. running mean: -9.169050\n",
      "ep 28: ep_len:545 episode reward: total was -22.190000. running mean: -9.299259\n",
      "ep 28: ep_len:715 episode reward: total was -4.190000. running mean: -9.248167\n",
      "ep 28: ep_len:500 episode reward: total was -5.680000. running mean: -9.212485\n",
      "ep 28: ep_len:2613 episode reward: total was -308.590000. running mean: -12.206260\n",
      "ep 28: ep_len:250 episode reward: total was 22.000000. running mean: -11.864198\n",
      "ep 28: ep_len:705 episode reward: total was -55.100000. running mean: -12.296556\n",
      "ep 28: ep_len:196 episode reward: total was 19.500000. running mean: -11.978590\n",
      "ep 28: ep_len:500 episode reward: total was 14.800000. running mean: -11.710804\n",
      "ep 28: ep_len:500 episode reward: total was 24.810000. running mean: -11.345596\n",
      "ep 28: ep_len:625 episode reward: total was -48.490000. running mean: -11.717040\n",
      "ep 28: ep_len:38775 episode reward: total was -7547.790000. running mean: -87.077770\n",
      "ep 28: ep_len:500 episode reward: total was 18.290000. running mean: -86.024092\n",
      "ep 28: ep_len:750 episode reward: total was -1.580000. running mean: -85.179651\n",
      "ep 28: ep_len:685 episode reward: total was 16.850000. running mean: -84.159355\n",
      "ep 28: ep_len:570 episode reward: total was -8.000000. running mean: -83.397761\n",
      "ep 28: ep_len:776 episode reward: total was -144.930000. running mean: -84.013083\n",
      "ep 28: ep_len:990 episode reward: total was -27.010000. running mean: -83.443053\n",
      "ep 28: ep_len:390 episode reward: total was -39.450000. running mean: -83.003122\n",
      "ep 28: ep_len:700 episode reward: total was -70.360000. running mean: -82.876691\n",
      "ep 28: ep_len:500 episode reward: total was -19.000000. running mean: -82.237924\n",
      "ep 28: ep_len:500 episode reward: total was -5.280000. running mean: -81.468345\n",
      "ep 28: ep_len:2856 episode reward: total was -470.030000. running mean: -85.353961\n",
      "ep 28: ep_len:695 episode reward: total was 21.220000. running mean: -84.288222\n",
      "ep 28: ep_len:500 episode reward: total was -10.600000. running mean: -83.551339\n",
      "ep 28: ep_len:28469 episode reward: total was -5534.050000. running mean: -138.056326\n",
      "ep 28: ep_len:500 episode reward: total was 16.210000. running mean: -136.513663\n",
      "ep 28: ep_len:550 episode reward: total was 17.680000. running mean: -134.971726\n",
      "ep 28: ep_len:735 episode reward: total was -9.690000. running mean: -133.718909\n",
      "ep 28: ep_len:205 episode reward: total was 18.000000. running mean: -132.201720\n",
      "ep 28: ep_len:1565 episode reward: total was -236.290000. running mean: -133.242603\n",
      "ep 28: ep_len:1125 episode reward: total was -75.260000. running mean: -132.662777\n",
      "ep 28: ep_len:218 episode reward: total was 21.500000. running mean: -131.121149\n",
      "ep 28: ep_len:500 episode reward: total was -12.000000. running mean: -129.929937\n",
      "ep 28: ep_len:1010 episode reward: total was -63.550000. running mean: -129.266138\n",
      "ep 28: ep_len:302 episode reward: total was 28.500000. running mean: -127.688477\n",
      "ep 28: ep_len:500 episode reward: total was -17.000000. running mean: -126.581592\n",
      "ep 28: ep_len:500 episode reward: total was -30.960000. running mean: -125.625376\n",
      "ep 28: ep_len:500 episode reward: total was -46.970000. running mean: -124.838822\n",
      "ep 28: ep_len:750 episode reward: total was -75.310000. running mean: -124.343534\n",
      "ep 28: ep_len:568 episode reward: total was -54.450000. running mean: -123.644599\n",
      "ep 28: ep_len:500 episode reward: total was 2.170000. running mean: -122.386453\n",
      "ep 28: ep_len:500 episode reward: total was -89.450000. running mean: -122.057088\n",
      "ep 28: ep_len:1405 episode reward: total was -120.460000. running mean: -122.041117\n",
      "ep 28: ep_len:499 episode reward: total was 31.300000. running mean: -120.507706\n",
      "ep 28: ep_len:670 episode reward: total was -35.070000. running mean: -119.653329\n",
      "ep 28: ep_len:710 episode reward: total was -20.850000. running mean: -118.665296\n",
      "ep 28: ep_len:1035 episode reward: total was -77.770000. running mean: -118.256343\n",
      "ep 28: ep_len:500 episode reward: total was 21.270000. running mean: -116.861079\n",
      "ep 28: ep_len:1575 episode reward: total was -85.880000. running mean: -116.551268\n",
      "ep 28: ep_len:500 episode reward: total was -17.350000. running mean: -115.559256\n",
      "ep 28: ep_len:10395 episode reward: total was -1950.090000. running mean: -133.904563\n",
      "ep 28: ep_len:500 episode reward: total was 13.670000. running mean: -132.428818\n",
      "ep 28: ep_len:500 episode reward: total was 15.760000. running mean: -130.946929\n",
      "ep 28: ep_len:510 episode reward: total was -22.260000. running mean: -129.860060\n",
      "ep 28: ep_len:123 episode reward: total was 12.000000. running mean: -128.441460\n",
      "ep 28: ep_len:960 episode reward: total was 7.820000. running mean: -127.078845\n",
      "ep 28: ep_len:500 episode reward: total was -12.200000. running mean: -125.930056\n",
      "ep 28: ep_len:930 episode reward: total was 20.750000. running mean: -124.463256\n",
      "ep 28: ep_len:500 episode reward: total was -26.220000. running mean: -123.480823\n",
      "ep 28: ep_len:500 episode reward: total was 35.320000. running mean: -121.892815\n",
      "ep 28: ep_len:900 episode reward: total was -34.610000. running mean: -121.019987\n",
      "ep 28: ep_len:680 episode reward: total was 1.940000. running mean: -119.790387\n",
      "ep 28: ep_len:206 episode reward: total was 20.500000. running mean: -118.387483\n",
      "ep 28: ep_len:1180 episode reward: total was -33.920000. running mean: -117.542808\n",
      "ep 28: ep_len:500 episode reward: total was 6.470000. running mean: -116.302680\n",
      "ep 28: ep_len:605 episode reward: total was -5.830000. running mean: -115.197954\n",
      "ep 28: ep_len:500 episode reward: total was -32.710000. running mean: -114.373074\n",
      "ep 28: ep_len:500 episode reward: total was -36.230000. running mean: -113.591643\n",
      "ep 28: ep_len:128 episode reward: total was 12.500000. running mean: -112.330727\n",
      "ep 28: ep_len:500 episode reward: total was -4.220000. running mean: -111.249620\n",
      "ep 28: ep_len:590 episode reward: total was -47.350000. running mean: -110.610623\n",
      "ep 28: ep_len:388 episode reward: total was -0.760000. running mean: -109.512117\n",
      "ep 28: ep_len:1754 episode reward: total was -239.530000. running mean: -110.812296\n",
      "ep 28: ep_len:500 episode reward: total was 45.500000. running mean: -109.249173\n",
      "ep 28: ep_len:1805 episode reward: total was -151.350000. running mean: -109.670181\n",
      "ep 28: ep_len:500 episode reward: total was 19.820000. running mean: -108.375279\n",
      "ep 28: ep_len:396 episode reward: total was -32.570000. running mean: -107.617227\n",
      "ep 28: ep_len:570 episode reward: total was -27.190000. running mean: -106.812954\n",
      "ep 28: ep_len:500 episode reward: total was 20.370000. running mean: -105.541125\n",
      "ep 28: ep_len:1095 episode reward: total was -56.440000. running mean: -105.050114\n",
      "ep 28: ep_len:635 episode reward: total was -15.950000. running mean: -104.159112\n",
      "ep 28: ep_len:725 episode reward: total was -22.210000. running mean: -103.339621\n",
      "ep 28: ep_len:500 episode reward: total was 7.170000. running mean: -102.234525\n",
      "ep 28: ep_len:647 episode reward: total was -23.770000. running mean: -101.449880\n",
      "ep 28: ep_len:1563 episode reward: total was -177.890000. running mean: -102.214281\n",
      "ep 28: ep_len:660 episode reward: total was -35.090000. running mean: -101.543038\n",
      "ep 28: ep_len:211 episode reward: total was 21.000000. running mean: -100.317608\n",
      "ep 28: ep_len:510 episode reward: total was -16.200000. running mean: -99.476432\n",
      "ep 28: ep_len:1116 episode reward: total was -150.310000. running mean: -99.984767\n",
      "ep 28: ep_len:1115 episode reward: total was 8.810000. running mean: -98.896820\n",
      "ep 28: ep_len:500 episode reward: total was -23.770000. running mean: -98.145552\n",
      "ep 28: ep_len:505 episode reward: total was 15.300000. running mean: -97.011096\n",
      "ep 28: ep_len:500 episode reward: total was 2.550000. running mean: -96.015485\n",
      "ep 28: ep_len:10884 episode reward: total was -2035.220000. running mean: -115.407530\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 28: ep_len:990 episode reward: total was 10.820000. running mean: -114.145255\n",
      "ep 28: ep_len:500 episode reward: total was -5.810000. running mean: -113.061902\n",
      "ep 28: ep_len:585 episode reward: total was -31.720000. running mean: -112.248483\n",
      "ep 28: ep_len:10 episode reward: total was -0.500000. running mean: -111.130999\n",
      "ep 28: ep_len:500 episode reward: total was 24.720000. running mean: -109.772489\n",
      "ep 28: ep_len:500 episode reward: total was 1.540000. running mean: -108.659364\n",
      "ep 28: ep_len:685 episode reward: total was -2.720000. running mean: -107.599970\n",
      "ep 28: ep_len:500 episode reward: total was 24.750000. running mean: -106.276470\n",
      "ep 28: ep_len:615 episode reward: total was -9.930000. running mean: -105.313006\n",
      "ep 28: ep_len:500 episode reward: total was 2.820000. running mean: -104.231676\n",
      "ep 28: ep_len:500 episode reward: total was 16.850000. running mean: -103.020859\n",
      "ep 28: ep_len:705 episode reward: total was -16.940000. running mean: -102.160050\n",
      "ep 28: ep_len:675 episode reward: total was -1.700000. running mean: -101.155450\n",
      "ep 28: ep_len:500 episode reward: total was 4.340000. running mean: -100.100495\n",
      "ep 28: ep_len:500 episode reward: total was 9.380000. running mean: -99.005690\n",
      "ep 28: ep_len:670 episode reward: total was -4.250000. running mean: -98.058133\n",
      "ep 28: ep_len:1065 episode reward: total was -18.420000. running mean: -97.261752\n",
      "ep 28: ep_len:500 episode reward: total was 9.240000. running mean: -96.196735\n",
      "ep 28: ep_len:500 episode reward: total was 16.770000. running mean: -95.067067\n",
      "ep 28: ep_len:810 episode reward: total was 12.390000. running mean: -93.992497\n",
      "ep 28: ep_len:600 episode reward: total was -28.140000. running mean: -93.333972\n",
      "ep 28: ep_len:500 episode reward: total was 6.470000. running mean: -92.335932\n",
      "ep 28: ep_len:500 episode reward: total was -8.140000. running mean: -91.493973\n",
      "ep 28: ep_len:500 episode reward: total was -20.780000. running mean: -90.786833\n",
      "ep 28: ep_len:500 episode reward: total was 27.790000. running mean: -89.601064\n",
      "ep 28: ep_len:500 episode reward: total was -6.150000. running mean: -88.766554\n",
      "ep 28: ep_len:500 episode reward: total was -1.620000. running mean: -87.895088\n",
      "ep 28: ep_len:1899 episode reward: total was -267.930000. running mean: -89.695437\n",
      "ep 28: ep_len:630 episode reward: total was -14.820000. running mean: -88.946683\n",
      "ep 28: ep_len:500 episode reward: total was -0.670000. running mean: -88.063916\n",
      "ep 28: ep_len:500 episode reward: total was 9.500000. running mean: -87.088277\n",
      "ep 28: ep_len:500 episode reward: total was -9.700000. running mean: -86.314394\n",
      "ep 28: ep_len:248 episode reward: total was 23.000000. running mean: -85.221250\n",
      "ep 28: ep_len:185 episode reward: total was 17.500000. running mean: -84.194038\n",
      "ep 28: ep_len:500 episode reward: total was 3.350000. running mean: -83.318597\n",
      "ep 28: ep_len:500 episode reward: total was 3.070000. running mean: -82.454711\n",
      "ep 28: ep_len:990 episode reward: total was 16.790000. running mean: -81.462264\n",
      "ep 28: ep_len:575 episode reward: total was -20.110000. running mean: -80.848742\n",
      "ep 28: ep_len:795 episode reward: total was -68.150000. running mean: -80.721754\n",
      "ep 28: ep_len:690 episode reward: total was -37.050000. running mean: -80.285037\n",
      "ep 28: ep_len:660 episode reward: total was -7.820000. running mean: -79.560386\n",
      "ep 28: ep_len:665 episode reward: total was 15.890000. running mean: -78.605883\n",
      "ep 28: ep_len:500 episode reward: total was 20.460000. running mean: -77.615224\n",
      "ep 28: ep_len:500 episode reward: total was 10.360000. running mean: -76.735471\n",
      "ep 28: ep_len:945 episode reward: total was -12.300000. running mean: -76.091117\n",
      "ep 28: ep_len:675 episode reward: total was -30.010000. running mean: -75.630306\n",
      "ep 28: ep_len:500 episode reward: total was 22.940000. running mean: -74.644603\n",
      "ep 28: ep_len:500 episode reward: total was 24.260000. running mean: -73.655556\n",
      "ep 28: ep_len:840 episode reward: total was -22.610000. running mean: -73.145101\n",
      "ep 28: ep_len:935 episode reward: total was 22.170000. running mean: -72.191950\n",
      "ep 28: ep_len:43290 episode reward: total was -8478.890000. running mean: -156.258930\n",
      "ep 28: ep_len:1152 episode reward: total was -122.970000. running mean: -155.926041\n",
      "ep 28: ep_len:500 episode reward: total was 4.320000. running mean: -154.323581\n",
      "ep 28: ep_len:710 episode reward: total was 24.590000. running mean: -152.534445\n",
      "ep 28: ep_len:2638 episode reward: total was -451.280000. running mean: -155.521900\n",
      "ep 28: ep_len:800 episode reward: total was 5.630000. running mean: -153.910381\n",
      "ep 28: ep_len:610 episode reward: total was -13.980000. running mean: -152.511078\n",
      "ep 28: ep_len:780 episode reward: total was -23.740000. running mean: -151.223367\n",
      "ep 28: ep_len:855 episode reward: total was 8.040000. running mean: -149.630733\n",
      "ep 28: ep_len:350 episode reward: total was -4.940000. running mean: -148.183826\n",
      "ep 28: ep_len:590 episode reward: total was -29.170000. running mean: -146.993688\n",
      "ep 28: ep_len:500 episode reward: total was 4.790000. running mean: -145.475851\n",
      "ep 28: ep_len:500 episode reward: total was 4.820000. running mean: -143.972892\n",
      "ep 28: ep_len:212 episode reward: total was 21.000000. running mean: -142.323163\n",
      "ep 28: ep_len:500 episode reward: total was -7.340000. running mean: -140.973332\n",
      "ep 28: ep_len:500 episode reward: total was 6.800000. running mean: -139.495598\n",
      "ep 28: ep_len:800 episode reward: total was -52.990000. running mean: -138.630542\n",
      "ep 28: ep_len:500 episode reward: total was 7.800000. running mean: -137.166237\n",
      "ep 28: ep_len:640 episode reward: total was -40.180000. running mean: -136.196375\n",
      "ep 28: ep_len:500 episode reward: total was -43.990000. running mean: -135.274311\n",
      "ep 28: ep_len:500 episode reward: total was -19.220000. running mean: -134.113768\n",
      "ep 28: ep_len:510 episode reward: total was -28.040000. running mean: -133.053030\n",
      "ep 28: ep_len:770 episode reward: total was -27.950000. running mean: -132.002000\n",
      "ep 28: ep_len:740 episode reward: total was 14.420000. running mean: -130.537780\n",
      "ep 28: ep_len:695 episode reward: total was 13.080000. running mean: -129.101602\n",
      "ep 28: ep_len:500 episode reward: total was -10.860000. running mean: -127.919186\n",
      "ep 28: ep_len:500 episode reward: total was -1.870000. running mean: -126.658694\n",
      "ep 28: ep_len:715 episode reward: total was -31.950000. running mean: -125.711607\n",
      "ep 28: ep_len:2219 episode reward: total was -219.990000. running mean: -126.654391\n",
      "ep 28: ep_len:620 episode reward: total was -34.160000. running mean: -125.729447\n",
      "ep 28: ep_len:515 episode reward: total was -13.160000. running mean: -124.603753\n",
      "ep 28: ep_len:500 episode reward: total was 31.800000. running mean: -123.039715\n",
      "ep 28: ep_len:2597 episode reward: total was -360.460000. running mean: -125.413918\n",
      "ep 28: ep_len:600 episode reward: total was -83.410000. running mean: -124.993879\n",
      "ep 28: ep_len:1480 episode reward: total was -126.370000. running mean: -125.007640\n",
      "ep 28: ep_len:1275 episode reward: total was -52.850000. running mean: -124.286064\n",
      "ep 28: ep_len:500 episode reward: total was 1.080000. running mean: -123.032403\n",
      "ep 28: ep_len:540 episode reward: total was 9.730000. running mean: -121.704779\n",
      "ep 28: ep_len:695 episode reward: total was -2.700000. running mean: -120.514731\n",
      "ep 28: ep_len:500 episode reward: total was 25.240000. running mean: -119.057184\n",
      "ep 28: ep_len:490 episode reward: total was -9.710000. running mean: -117.963712\n",
      "ep 28: ep_len:500 episode reward: total was 0.130000. running mean: -116.782775\n",
      "ep 28: ep_len:875 episode reward: total was 8.460000. running mean: -115.530347\n",
      "ep 28: ep_len:500 episode reward: total was -24.360000. running mean: -114.618644\n",
      "ep 28: ep_len:500 episode reward: total was 14.550000. running mean: -113.326957\n",
      "ep 28: ep_len:545 episode reward: total was 1.860000. running mean: -112.175088\n",
      "ep 28: ep_len:500 episode reward: total was 16.430000. running mean: -110.889037\n",
      "ep 28: ep_len:500 episode reward: total was 20.220000. running mean: -109.577946\n",
      "ep 28: ep_len:860 episode reward: total was 8.520000. running mean: -108.396967\n",
      "ep 28: ep_len:500 episode reward: total was 15.230000. running mean: -107.160697\n",
      "ep 28: ep_len:1130 episode reward: total was -33.770000. running mean: -106.426790\n",
      "ep 28: ep_len:187 episode reward: total was 17.000000. running mean: -105.192522\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 28: ep_len:1198 episode reward: total was -125.910000. running mean: -105.399697\n",
      "ep 28: ep_len:850 episode reward: total was -7.500000. running mean: -104.420700\n",
      "ep 28: ep_len:705 episode reward: total was 1.360000. running mean: -103.362893\n",
      "ep 28: ep_len:815 episode reward: total was -6.500000. running mean: -102.394264\n",
      "ep 28: ep_len:105 episode reward: total was 9.000000. running mean: -101.280322\n",
      "ep 28: ep_len:220 episode reward: total was 20.500000. running mean: -100.062518\n",
      "ep 28: ep_len:500 episode reward: total was 24.170000. running mean: -98.820193\n",
      "ep 28: ep_len:1045 episode reward: total was 14.490000. running mean: -97.687091\n",
      "ep 28: ep_len:1945 episode reward: total was -237.010000. running mean: -99.080320\n",
      "ep 28: ep_len:500 episode reward: total was 17.190000. running mean: -97.917617\n",
      "ep 28: ep_len:865 episode reward: total was 19.090000. running mean: -96.747541\n",
      "ep 28: ep_len:188 episode reward: total was 18.500000. running mean: -95.595066\n",
      "ep 28: ep_len:2518 episode reward: total was -181.740000. running mean: -96.456515\n",
      "ep 28: ep_len:775 episode reward: total was 24.140000. running mean: -95.250550\n",
      "ep 28: ep_len:500 episode reward: total was 0.190000. running mean: -94.296144\n",
      "ep 28: ep_len:500 episode reward: total was 13.210000. running mean: -93.221083\n",
      "ep 28: ep_len:500 episode reward: total was -1.550000. running mean: -92.304372\n",
      "ep 28: ep_len:705 episode reward: total was -45.590000. running mean: -91.837228\n",
      "ep 28: ep_len:142 episode reward: total was 14.000000. running mean: -90.778856\n",
      "ep 28: ep_len:760 episode reward: total was 34.790000. running mean: -89.523167\n",
      "ep 28: ep_len:855 episode reward: total was -11.220000. running mean: -88.740136\n",
      "ep 28: ep_len:520 episode reward: total was 1.390000. running mean: -87.838834\n",
      "ep 28: ep_len:500 episode reward: total was 13.370000. running mean: -86.826746\n",
      "ep 28: ep_len:500 episode reward: total was -34.240000. running mean: -86.300879\n",
      "ep 28: ep_len:800 episode reward: total was 15.300000. running mean: -85.284870\n",
      "ep 28: ep_len:1020 episode reward: total was -15.630000. running mean: -84.588321\n",
      "ep 28: ep_len:820 episode reward: total was -12.550000. running mean: -83.867938\n",
      "ep 28: ep_len:500 episode reward: total was 15.930000. running mean: -82.869959\n",
      "ep 28: ep_len:540 episode reward: total was -17.150000. running mean: -82.212759\n",
      "ep 28: ep_len:710 episode reward: total was -9.640000. running mean: -81.487031\n",
      "ep 28: ep_len:500 episode reward: total was 24.870000. running mean: -80.423461\n",
      "ep 28: ep_len:565 episode reward: total was 4.500000. running mean: -79.574226\n",
      "ep 28: ep_len:250 episode reward: total was 22.000000. running mean: -78.558484\n",
      "ep 28: ep_len:500 episode reward: total was 7.910000. running mean: -77.693799\n",
      "ep 28: ep_len:750 episode reward: total was 30.800000. running mean: -76.608861\n",
      "ep 28: ep_len:226 episode reward: total was 21.000000. running mean: -75.632773\n",
      "ep 28: ep_len:500 episode reward: total was 14.060000. running mean: -74.735845\n",
      "ep 28: ep_len:1425 episode reward: total was -239.230000. running mean: -76.380787\n",
      "ep 28: ep_len:765 episode reward: total was -37.650000. running mean: -75.993479\n",
      "ep 28: ep_len:500 episode reward: total was 13.690000. running mean: -75.096644\n",
      "ep 28: ep_len:500 episode reward: total was -13.370000. running mean: -74.479377\n",
      "ep 28: ep_len:500 episode reward: total was 28.270000. running mean: -73.451884\n",
      "ep 28: ep_len:500 episode reward: total was 4.580000. running mean: -72.671565\n",
      "ep 28: ep_len:222 episode reward: total was 22.000000. running mean: -71.724849\n",
      "ep 28: ep_len:500 episode reward: total was -1.220000. running mean: -71.019801\n",
      "ep 28: ep_len:343 episode reward: total was 34.000000. running mean: -69.969603\n",
      "ep 28: ep_len:500 episode reward: total was -2.630000. running mean: -69.296207\n",
      "ep 28: ep_len:500 episode reward: total was -17.810000. running mean: -68.781345\n",
      "ep 28: ep_len:500 episode reward: total was 11.240000. running mean: -67.981131\n",
      "ep 28: ep_len:500 episode reward: total was 18.750000. running mean: -67.113820\n",
      "ep 28: ep_len:700 episode reward: total was 7.600000. running mean: -66.366682\n",
      "ep 28: ep_len:500 episode reward: total was 23.920000. running mean: -65.463815\n",
      "ep 28: ep_len:500 episode reward: total was 24.760000. running mean: -64.561577\n",
      "ep 28: ep_len:500 episode reward: total was -3.850000. running mean: -63.954461\n",
      "ep 28: ep_len:960 episode reward: total was -31.460000. running mean: -63.629516\n",
      "ep 28: ep_len:1025 episode reward: total was -1.920000. running mean: -63.012421\n",
      "ep 28: ep_len:710 episode reward: total was -0.650000. running mean: -62.388797\n",
      "ep 28: ep_len:310 episode reward: total was -0.730000. running mean: -61.772209\n",
      "ep 28: ep_len:950 episode reward: total was -1.560000. running mean: -61.170087\n",
      "ep 28: ep_len:172 episode reward: total was 15.500000. running mean: -60.403386\n",
      "ep 28: ep_len:500 episode reward: total was 10.140000. running mean: -59.697952\n",
      "ep 28: ep_len:500 episode reward: total was 14.370000. running mean: -58.957273\n",
      "ep 28: ep_len:690 episode reward: total was 0.320000. running mean: -58.364500\n",
      "ep 28: ep_len:2135 episode reward: total was -259.370000. running mean: -60.374555\n",
      "ep 28: ep_len:500 episode reward: total was 50.000000. running mean: -59.270809\n",
      "ep 28: ep_len:500 episode reward: total was 30.810000. running mean: -58.370001\n",
      "ep 28: ep_len:785 episode reward: total was -13.110000. running mean: -57.917401\n",
      "ep 28: ep_len:815 episode reward: total was 15.560000. running mean: -57.182627\n",
      "ep 28: ep_len:610 episode reward: total was -21.050000. running mean: -56.821301\n",
      "ep 28: ep_len:835 episode reward: total was -14.540000. running mean: -56.398488\n",
      "ep 28: ep_len:600 episode reward: total was -24.100000. running mean: -56.075503\n",
      "ep 28: ep_len:540 episode reward: total was 1.380000. running mean: -55.500948\n",
      "ep 28: ep_len:500 episode reward: total was 4.260000. running mean: -54.903339\n",
      "ep 28: ep_len:680 episode reward: total was 17.880000. running mean: -54.175505\n",
      "ep 28: ep_len:286 episode reward: total was 28.500000. running mean: -53.348750\n",
      "ep 28: ep_len:500 episode reward: total was 8.640000. running mean: -52.728863\n",
      "ep 28: ep_len:500 episode reward: total was -8.170000. running mean: -52.283274\n",
      "ep 28: ep_len:2291 episode reward: total was -136.380000. running mean: -53.124241\n",
      "ep 28: ep_len:865 episode reward: total was -9.430000. running mean: -52.687299\n",
      "ep 28: ep_len:540 episode reward: total was 14.910000. running mean: -52.011326\n",
      "ep 28: ep_len:1075 episode reward: total was 33.340000. running mean: -51.157813\n",
      "ep 28: ep_len:820 episode reward: total was 16.980000. running mean: -50.476434\n",
      "ep 28: ep_len:500 episode reward: total was -1.740000. running mean: -49.989070\n",
      "ep 28: ep_len:500 episode reward: total was 20.460000. running mean: -49.284579\n",
      "ep 28: ep_len:709 episode reward: total was -6.700000. running mean: -48.858734\n",
      "ep 28: ep_len:500 episode reward: total was 16.110000. running mean: -48.209046\n",
      "ep 28: ep_len:500 episode reward: total was 18.510000. running mean: -47.541856\n",
      "ep 28: ep_len:905 episode reward: total was -35.610000. running mean: -47.422537\n",
      "ep 28: ep_len:500 episode reward: total was -44.430000. running mean: -47.392612\n",
      "ep 28: ep_len:258 episode reward: total was 25.500000. running mean: -46.663686\n",
      "ep 28: ep_len:661 episode reward: total was -102.740000. running mean: -47.224449\n",
      "ep 28: ep_len:855 episode reward: total was 2.520000. running mean: -46.727004\n",
      "ep 28: ep_len:1305 episode reward: total was -93.390000. running mean: -47.193634\n",
      "ep 28: ep_len:255 episode reward: total was 24.500000. running mean: -46.476698\n",
      "ep 28: ep_len:500 episode reward: total was 23.770000. running mean: -45.774231\n",
      "ep 28: ep_len:500 episode reward: total was 19.790000. running mean: -45.118589\n",
      "ep 28: ep_len:935 episode reward: total was -0.940000. running mean: -44.676803\n",
      "ep 28: ep_len:439 episode reward: total was 9.740000. running mean: -44.132635\n",
      "ep 28: ep_len:500 episode reward: total was 4.300000. running mean: -43.648308\n",
      "ep 28: ep_len:720 episode reward: total was 2.680000. running mean: -43.185025\n",
      "ep 28: ep_len:765 episode reward: total was 18.640000. running mean: -42.566775\n",
      "ep 28: ep_len:810 episode reward: total was 11.430000. running mean: -42.026807\n",
      "ep 28: ep_len:500 episode reward: total was 12.260000. running mean: -41.483939\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 28: ep_len:855 episode reward: total was -15.510000. running mean: -41.224200\n",
      "ep 28: ep_len:242 episode reward: total was 21.000000. running mean: -40.601958\n",
      "ep 28: ep_len:895 episode reward: total was 8.560000. running mean: -40.110338\n",
      "ep 28: ep_len:760 episode reward: total was 1.700000. running mean: -39.692235\n",
      "ep 28: ep_len:1005 episode reward: total was 23.310000. running mean: -39.062213\n",
      "ep 28: ep_len:500 episode reward: total was -2.960000. running mean: -38.701191\n",
      "ep 28: ep_len:500 episode reward: total was 22.800000. running mean: -38.086179\n",
      "ep 28: ep_len:1000 episode reward: total was 11.660000. running mean: -37.588717\n",
      "ep 28: ep_len:2301 episode reward: total was -377.290000. running mean: -40.985730\n",
      "ep 28: ep_len:945 episode reward: total was -22.400000. running mean: -40.799872\n",
      "ep 28: ep_len:500 episode reward: total was -4.180000. running mean: -40.433674\n",
      "ep 28: ep_len:510 episode reward: total was -1.050000. running mean: -40.039837\n",
      "ep 28: ep_len:860 episode reward: total was 3.990000. running mean: -39.599539\n",
      "ep 28: ep_len:271 episode reward: total was 25.500000. running mean: -38.948543\n",
      "ep 28: ep_len:500 episode reward: total was -7.190000. running mean: -38.630958\n",
      "ep 28: ep_len:915 episode reward: total was 9.890000. running mean: -38.145748\n",
      "ep 28: ep_len:196 episode reward: total was -3.850000. running mean: -37.802791\n",
      "ep 28: ep_len:500 episode reward: total was 8.210000. running mean: -37.342663\n",
      "ep 28: ep_len:2105 episode reward: total was -333.160000. running mean: -40.300836\n",
      "ep 28: ep_len:810 episode reward: total was -13.180000. running mean: -40.029628\n",
      "ep 28: ep_len:500 episode reward: total was 1.150000. running mean: -39.617831\n",
      "ep 28: ep_len:650 episode reward: total was -8.850000. running mean: -39.310153\n",
      "ep 28: ep_len:835 episode reward: total was 14.600000. running mean: -38.771052\n",
      "ep 28: ep_len:815 episode reward: total was 14.790000. running mean: -38.235441\n",
      "ep 28: ep_len:500 episode reward: total was 27.840000. running mean: -37.574687\n",
      "ep 28: ep_len:500 episode reward: total was 30.780000. running mean: -36.891140\n",
      "ep 28: ep_len:780 episode reward: total was -9.630000. running mean: -36.618528\n",
      "ep 28: ep_len:590 episode reward: total was -5.940000. running mean: -36.311743\n",
      "ep 28: ep_len:815 episode reward: total was 5.290000. running mean: -35.895726\n",
      "ep 28: ep_len:685 episode reward: total was -40.090000. running mean: -35.937668\n",
      "ep 28: ep_len:500 episode reward: total was 21.780000. running mean: -35.360492\n",
      "ep 28: ep_len:500 episode reward: total was 17.580000. running mean: -34.831087\n",
      "ep 28: ep_len:555 episode reward: total was -17.120000. running mean: -34.653976\n",
      "ep 28: ep_len:810 episode reward: total was -3.600000. running mean: -34.343436\n",
      "ep 28: ep_len:500 episode reward: total was -16.310000. running mean: -34.163102\n",
      "ep 28: ep_len:500 episode reward: total was 21.350000. running mean: -33.607971\n",
      "ep 28: ep_len:595 episode reward: total was -17.040000. running mean: -33.442291\n",
      "ep 28: ep_len:500 episode reward: total was 6.310000. running mean: -33.044768\n",
      "ep 28: ep_len:855 episode reward: total was 6.200000. running mean: -32.652321\n",
      "ep 28: ep_len:670 episode reward: total was -5.900000. running mean: -32.384797\n",
      "ep 28: ep_len:1115 episode reward: total was -181.690000. running mean: -33.877849\n",
      "ep 28: ep_len:500 episode reward: total was -0.230000. running mean: -33.541371\n",
      "ep 28: ep_len:226 episode reward: total was 21.000000. running mean: -32.995957\n",
      "ep 28: ep_len:500 episode reward: total was 4.260000. running mean: -32.623398\n",
      "ep 28: ep_len:850 episode reward: total was 14.730000. running mean: -32.149864\n",
      "ep 28: ep_len:500 episode reward: total was -4.220000. running mean: -31.870565\n",
      "ep 28: ep_len:500 episode reward: total was 21.350000. running mean: -31.338359\n",
      "ep 28: ep_len:500 episode reward: total was 14.470000. running mean: -30.880276\n",
      "ep 28: ep_len:805 episode reward: total was -4.590000. running mean: -30.617373\n",
      "ep 28: ep_len:580 episode reward: total was -14.040000. running mean: -30.451599\n",
      "ep 28: ep_len:184 episode reward: total was 16.500000. running mean: -29.982083\n",
      "ep 28: ep_len:500 episode reward: total was -15.730000. running mean: -29.839562\n",
      "ep 28: ep_len:905 episode reward: total was 15.820000. running mean: -29.382967\n",
      "ep 28: ep_len:134 episode reward: total was 13.000000. running mean: -28.959137\n",
      "ep 28: ep_len:605 episode reward: total was -3.240000. running mean: -28.701946\n",
      "ep 28: ep_len:4300 episode reward: total was -651.990000. running mean: -34.934826\n",
      "ep 28: ep_len:505 episode reward: total was -12.170000. running mean: -34.707178\n",
      "ep 28: ep_len:911 episode reward: total was -123.350000. running mean: -35.593606\n",
      "ep 28: ep_len:605 episode reward: total was -0.860000. running mean: -35.246270\n",
      "ep 28: ep_len:316 episode reward: total was 30.000000. running mean: -34.593807\n",
      "ep 28: ep_len:866 episode reward: total was -92.770000. running mean: -35.175569\n",
      "ep 28: ep_len:8950 episode reward: total was -1703.700000. running mean: -51.860814\n",
      "ep 28: ep_len:725 episode reward: total was -4.660000. running mean: -51.388806\n",
      "ep 28: ep_len:500 episode reward: total was 12.780000. running mean: -50.747118\n",
      "ep 28: ep_len:343 episode reward: total was 33.000000. running mean: -49.909646\n",
      "ep 28: ep_len:575 episode reward: total was -17.080000. running mean: -49.581350\n",
      "ep 28: ep_len:540 episode reward: total was -6.040000. running mean: -49.145936\n",
      "ep 28: ep_len:630 episode reward: total was 19.740000. running mean: -48.457077\n",
      "ep 28: ep_len:1194 episode reward: total was -153.270000. running mean: -49.505206\n",
      "ep 28: ep_len:555 episode reward: total was -8.810000. running mean: -49.098254\n",
      "ep 28: ep_len:500 episode reward: total was -2.810000. running mean: -48.635372\n",
      "ep 28: ep_len:500 episode reward: total was 3.800000. running mean: -48.111018\n",
      "ep 28: ep_len:2261 episode reward: total was -284.370000. running mean: -50.473608\n",
      "ep 28: ep_len:845 episode reward: total was -2.080000. running mean: -49.989672\n",
      "ep 28: ep_len:685 episode reward: total was -11.810000. running mean: -49.607875\n",
      "ep 28: ep_len:500 episode reward: total was -13.800000. running mean: -49.249796\n",
      "ep 28: ep_len:500 episode reward: total was 47.000000. running mean: -48.287298\n",
      "ep 28: ep_len:500 episode reward: total was 27.260000. running mean: -47.531825\n",
      "ep 28: ep_len:500 episode reward: total was -19.480000. running mean: -47.251307\n",
      "ep 28: ep_len:760 episode reward: total was -41.710000. running mean: -47.195894\n",
      "ep 28: ep_len:740 episode reward: total was -25.840000. running mean: -46.982335\n",
      "ep 28: ep_len:500 episode reward: total was -9.300000. running mean: -46.605512\n",
      "ep 28: ep_len:500 episode reward: total was 31.820000. running mean: -45.821257\n",
      "ep 28: ep_len:862 episode reward: total was -106.380000. running mean: -46.426844\n",
      "ep 28: ep_len:715 episode reward: total was -4.680000. running mean: -46.009376\n",
      "ep 28: ep_len:835 episode reward: total was 19.980000. running mean: -45.349482\n",
      "ep 28: ep_len:500 episode reward: total was -13.770000. running mean: -45.033687\n",
      "ep 28: ep_len:49 episode reward: total was 4.500000. running mean: -44.538350\n",
      "ep 28: ep_len:700 episode reward: total was 1.700000. running mean: -44.075967\n",
      "ep 28: ep_len:550 episode reward: total was -10.060000. running mean: -43.735807\n",
      "ep 28: ep_len:500 episode reward: total was 2.520000. running mean: -43.273249\n",
      "ep 28: ep_len:500 episode reward: total was 2.520000. running mean: -42.815316\n",
      "ep 28: ep_len:1385 episode reward: total was -47.780000. running mean: -42.864963\n",
      "ep 28: ep_len:500 episode reward: total was -13.190000. running mean: -42.568214\n",
      "ep 28: ep_len:680 episode reward: total was -34.040000. running mean: -42.482931\n",
      "ep 28: ep_len:805 episode reward: total was -26.720000. running mean: -42.325302\n",
      "ep 28: ep_len:550 episode reward: total was -4.580000. running mean: -41.947849\n",
      "ep 28: ep_len:214 episode reward: total was 21.500000. running mean: -41.313371\n",
      "ep 28: ep_len:740 episode reward: total was 14.820000. running mean: -40.752037\n",
      "ep 28: ep_len:500 episode reward: total was -62.370000. running mean: -40.968217\n",
      "ep 28: ep_len:218 episode reward: total was 21.500000. running mean: -40.343534\n",
      "ep 28: ep_len:2222 episode reward: total was -146.250000. running mean: -41.402599\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 28: ep_len:510 episode reward: total was -10.090000. running mean: -41.089473\n",
      "ep 28: ep_len:630 episode reward: total was 5.930000. running mean: -40.619278\n",
      "ep 28: ep_len:715 episode reward: total was -13.770000. running mean: -40.350786\n",
      "ep 28: ep_len:690 episode reward: total was -35.030000. running mean: -40.297578\n",
      "ep 28: ep_len:615 episode reward: total was 9.910000. running mean: -39.795502\n",
      "ep 28: ep_len:500 episode reward: total was -20.440000. running mean: -39.601947\n",
      "ep 28: ep_len:720 episode reward: total was -49.110000. running mean: -39.697027\n",
      "ep 28: ep_len:1105 episode reward: total was 1.720000. running mean: -39.282857\n",
      "ep 28: ep_len:680 episode reward: total was -0.950000. running mean: -38.899529\n",
      "ep 28: ep_len:575 episode reward: total was -9.000000. running mean: -38.600533\n",
      "ep 28: ep_len:500 episode reward: total was -40.240000. running mean: -38.616928\n",
      "ep 28: ep_len:870 episode reward: total was -9.410000. running mean: -38.324859\n",
      "ep 28: ep_len:500 episode reward: total was 16.850000. running mean: -37.773110\n",
      "ep 28: ep_len:725 episode reward: total was -3.650000. running mean: -37.431879\n",
      "ep 28: ep_len:492 episode reward: total was 31.800000. running mean: -36.739560\n",
      "ep 28: ep_len:302 episode reward: total was 29.000000. running mean: -36.082165\n",
      "ep 28: ep_len:705 episode reward: total was -11.250000. running mean: -35.833843\n",
      "ep 28: ep_len:500 episode reward: total was 17.460000. running mean: -35.300905\n",
      "ep 28: ep_len:500 episode reward: total was -9.940000. running mean: -35.047295\n",
      "ep 28: ep_len:500 episode reward: total was -0.870000. running mean: -34.705523\n",
      "ep 28: ep_len:500 episode reward: total was 33.320000. running mean: -34.025267\n",
      "ep 28: ep_len:510 episode reward: total was 0.970000. running mean: -33.675315\n",
      "ep 28: ep_len:500 episode reward: total was 36.260000. running mean: -32.975961\n",
      "ep 28: ep_len:456 episode reward: total was 8.250000. running mean: -32.563702\n",
      "ep 28: ep_len:525 episode reward: total was -68.170000. running mean: -32.919765\n",
      "ep 28: ep_len:204 episode reward: total was 20.000000. running mean: -32.390567\n",
      "ep 28: ep_len:500 episode reward: total was -29.410000. running mean: -32.360762\n",
      "ep 28: ep_len:505 episode reward: total was 20.300000. running mean: -31.834154\n",
      "ep 28: ep_len:500 episode reward: total was 21.200000. running mean: -31.303812\n",
      "ep 28: ep_len:500 episode reward: total was 8.000000. running mean: -30.910774\n",
      "ep 28: ep_len:2495 episode reward: total was -445.490000. running mean: -35.056566\n",
      "ep 28: ep_len:960 episode reward: total was -2.020000. running mean: -34.726201\n",
      "ep 28: ep_len:5465 episode reward: total was -875.970000. running mean: -43.138639\n",
      "ep 28: ep_len:850 episode reward: total was -62.970000. running mean: -43.336952\n",
      "ep 28: ep_len:620 episode reward: total was 4.300000. running mean: -42.860583\n",
      "ep 28: ep_len:500 episode reward: total was 13.110000. running mean: -42.300877\n",
      "ep 28: ep_len:500 episode reward: total was 48.500000. running mean: -41.392868\n",
      "ep 28: ep_len:500 episode reward: total was 47.500000. running mean: -40.503940\n",
      "ep 28: ep_len:670 episode reward: total was -27.110000. running mean: -40.370000\n",
      "epsilon:0.010000 episode_count: 22850. steps_count: 16548471.000000\n",
      "ep 29: ep_len:1080 episode reward: total was -171.090000. running mean: -41.677200\n",
      "ep 29: ep_len:805 episode reward: total was -39.850000. running mean: -41.658928\n",
      "ep 29: ep_len:500 episode reward: total was 6.930000. running mean: -41.173039\n",
      "ep 29: ep_len:525 episode reward: total was -29.790000. running mean: -41.059209\n",
      "ep 29: ep_len:500 episode reward: total was 1.810000. running mean: -40.630516\n",
      "ep 29: ep_len:500 episode reward: total was 2.000000. running mean: -40.204211\n",
      "ep 29: ep_len:830 episode reward: total was 2.890000. running mean: -39.773269\n",
      "ep 29: ep_len:505 episode reward: total was 12.300000. running mean: -39.252536\n",
      "ep 29: ep_len:810 episode reward: total was -54.990000. running mean: -39.409911\n",
      "ep 29: ep_len:1920 episode reward: total was -279.530000. running mean: -41.811112\n",
      "ep 29: ep_len:500 episode reward: total was 23.770000. running mean: -41.155301\n",
      "ep 29: ep_len:1745 episode reward: total was -285.260000. running mean: -43.596348\n",
      "ep 29: ep_len:500 episode reward: total was 21.810000. running mean: -42.942284\n",
      "ep 29: ep_len:1155 episode reward: total was -103.790000. running mean: -43.550762\n",
      "ep 29: ep_len:1220 episode reward: total was -5.850000. running mean: -43.173754\n",
      "ep 29: ep_len:500 episode reward: total was 29.800000. running mean: -42.444016\n",
      "ep 29: ep_len:720 episode reward: total was -2.280000. running mean: -42.042376\n",
      "ep 29: ep_len:500 episode reward: total was -10.790000. running mean: -41.729852\n",
      "ep 29: ep_len:630 episode reward: total was -1.540000. running mean: -41.327954\n",
      "ep 29: ep_len:765 episode reward: total was -2.900000. running mean: -40.943674\n",
      "ep 29: ep_len:1765 episode reward: total was -105.610000. running mean: -41.590338\n",
      "ep 29: ep_len:1175 episode reward: total was -41.180000. running mean: -41.586234\n",
      "ep 29: ep_len:500 episode reward: total was 0.730000. running mean: -41.163072\n",
      "ep 29: ep_len:655 episode reward: total was 24.690000. running mean: -40.504541\n",
      "ep 29: ep_len:137 episode reward: total was 12.000000. running mean: -39.979496\n",
      "ep 29: ep_len:890 episode reward: total was -4.520000. running mean: -39.624901\n",
      "ep 29: ep_len:530 episode reward: total was -5.050000. running mean: -39.279152\n",
      "ep 29: ep_len:16172 episode reward: total was -2971.890000. running mean: -68.605260\n",
      "ep 29: ep_len:680 episode reward: total was -14.850000. running mean: -68.067708\n",
      "ep 29: ep_len:535 episode reward: total was -11.100000. running mean: -67.498031\n",
      "ep 29: ep_len:500 episode reward: total was -7.030000. running mean: -66.893350\n",
      "ep 29: ep_len:500 episode reward: total was -10.280000. running mean: -66.327217\n",
      "ep 29: ep_len:690 episode reward: total was -24.930000. running mean: -65.913245\n",
      "ep 29: ep_len:500 episode reward: total was -47.620000. running mean: -65.730312\n",
      "ep 29: ep_len:500 episode reward: total was 21.750000. running mean: -64.855509\n",
      "ep 29: ep_len:980 episode reward: total was -16.470000. running mean: -64.371654\n",
      "ep 29: ep_len:560 episode reward: total was -10.040000. running mean: -63.828337\n",
      "ep 29: ep_len:500 episode reward: total was -45.750000. running mean: -63.647554\n",
      "ep 29: ep_len:500 episode reward: total was -24.720000. running mean: -63.258279\n",
      "ep 29: ep_len:520 episode reward: total was 21.770000. running mean: -62.407996\n",
      "ep 29: ep_len:645 episode reward: total was 6.970000. running mean: -61.714216\n",
      "ep 29: ep_len:500 episode reward: total was 24.290000. running mean: -60.854174\n",
      "ep 29: ep_len:500 episode reward: total was 12.320000. running mean: -60.122432\n",
      "ep 29: ep_len:1596 episode reward: total was -195.530000. running mean: -61.476508\n",
      "ep 29: ep_len:169 episode reward: total was 16.500000. running mean: -60.696743\n",
      "ep 29: ep_len:21225 episode reward: total was -4080.470000. running mean: -100.894475\n",
      "ep 29: ep_len:710 episode reward: total was -10.750000. running mean: -99.993030\n",
      "ep 29: ep_len:900 episode reward: total was -36.630000. running mean: -99.359400\n",
      "ep 29: ep_len:148 episode reward: total was 14.500000. running mean: -98.220806\n",
      "ep 29: ep_len:535 episode reward: total was -3.220000. running mean: -97.270798\n",
      "ep 29: ep_len:183 episode reward: total was 18.000000. running mean: -96.118090\n",
      "ep 29: ep_len:123 episode reward: total was 9.500000. running mean: -95.061909\n",
      "ep 29: ep_len:745 episode reward: total was -52.090000. running mean: -94.632190\n",
      "ep 29: ep_len:705 episode reward: total was 5.000000. running mean: -93.635868\n",
      "ep 29: ep_len:500 episode reward: total was 11.250000. running mean: -92.587009\n",
      "ep 29: ep_len:845 episode reward: total was -17.200000. running mean: -91.833139\n",
      "ep 29: ep_len:127 episode reward: total was 12.500000. running mean: -90.789808\n",
      "ep 29: ep_len:840 episode reward: total was -58.210000. running mean: -90.464010\n",
      "ep 29: ep_len:500 episode reward: total was 17.190000. running mean: -89.387470\n",
      "ep 29: ep_len:500 episode reward: total was -36.290000. running mean: -88.856495\n",
      "ep 29: ep_len:487 episode reward: total was 46.000000. running mean: -87.507930\n",
      "ep 29: ep_len:500 episode reward: total was -18.230000. running mean: -86.815151\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 29: ep_len:500 episode reward: total was -17.350000. running mean: -86.120499\n",
      "ep 29: ep_len:530 episode reward: total was -12.610000. running mean: -85.385394\n",
      "ep 29: ep_len:280 episode reward: total was 26.500000. running mean: -84.266540\n",
      "ep 29: ep_len:198 episode reward: total was 19.500000. running mean: -83.228875\n",
      "ep 29: ep_len:500 episode reward: total was -23.040000. running mean: -82.626986\n",
      "ep 29: ep_len:500 episode reward: total was -19.250000. running mean: -81.993216\n",
      "ep 29: ep_len:1385 episode reward: total was -131.230000. running mean: -82.485584\n",
      "ep 29: ep_len:575 episode reward: total was -35.750000. running mean: -82.018228\n",
      "ep 29: ep_len:525 episode reward: total was -41.420000. running mean: -81.612246\n",
      "ep 29: ep_len:580 episode reward: total was -20.100000. running mean: -80.997124\n",
      "ep 29: ep_len:715 episode reward: total was -42.540000. running mean: -80.612552\n",
      "ep 29: ep_len:500 episode reward: total was 26.250000. running mean: -79.543927\n",
      "ep 29: ep_len:500 episode reward: total was -18.820000. running mean: -78.936688\n",
      "ep 29: ep_len:545 episode reward: total was -48.450000. running mean: -78.631821\n",
      "ep 29: ep_len:500 episode reward: total was 3.230000. running mean: -77.813202\n",
      "ep 29: ep_len:500 episode reward: total was 2.100000. running mean: -77.014070\n",
      "ep 29: ep_len:845 episode reward: total was 8.400000. running mean: -76.159930\n",
      "ep 29: ep_len:2255 episode reward: total was -331.870000. running mean: -78.717030\n",
      "ep 29: ep_len:665 episode reward: total was -17.910000. running mean: -78.108960\n",
      "ep 29: ep_len:670 episode reward: total was -21.940000. running mean: -77.547271\n",
      "ep 29: ep_len:500 episode reward: total was -26.000000. running mean: -77.031798\n",
      "ep 29: ep_len:690 episode reward: total was -23.460000. running mean: -76.496080\n",
      "ep 29: ep_len:500 episode reward: total was -1.100000. running mean: -75.742119\n",
      "ep 29: ep_len:500 episode reward: total was 8.280000. running mean: -74.901898\n",
      "ep 29: ep_len:810 episode reward: total was 8.350000. running mean: -74.069379\n",
      "ep 29: ep_len:500 episode reward: total was 12.860000. running mean: -73.200085\n",
      "ep 29: ep_len:570 episode reward: total was 16.260000. running mean: -72.305484\n",
      "ep 29: ep_len:695 episode reward: total was -17.850000. running mean: -71.760929\n",
      "ep 29: ep_len:795 episode reward: total was -47.950000. running mean: -71.522820\n",
      "ep 29: ep_len:500 episode reward: total was -8.840000. running mean: -70.895992\n",
      "ep 29: ep_len:805 episode reward: total was -39.880000. running mean: -70.585832\n",
      "ep 29: ep_len:500 episode reward: total was -2.250000. running mean: -69.902474\n",
      "ep 29: ep_len:20370 episode reward: total was -4022.560000. running mean: -109.429049\n",
      "ep 29: ep_len:500 episode reward: total was 7.700000. running mean: -108.257758\n",
      "ep 29: ep_len:500 episode reward: total was -28.210000. running mean: -107.457281\n",
      "ep 29: ep_len:500 episode reward: total was -28.400000. running mean: -106.666708\n",
      "ep 29: ep_len:945 episode reward: total was -49.980000. running mean: -106.099841\n",
      "ep 29: ep_len:680 episode reward: total was -25.960000. running mean: -105.298443\n",
      "ep 29: ep_len:635 episode reward: total was -18.850000. running mean: -104.433958\n",
      "ep 29: ep_len:192 episode reward: total was 19.500000. running mean: -103.194619\n",
      "ep 29: ep_len:695 episode reward: total was -73.400000. running mean: -102.896672\n",
      "ep 29: ep_len:500 episode reward: total was -13.860000. running mean: -102.006306\n",
      "ep 29: ep_len:1096 episode reward: total was -82.800000. running mean: -101.814243\n",
      "ep 29: ep_len:334 episode reward: total was -63.000000. running mean: -101.426100\n",
      "ep 29: ep_len:843 episode reward: total was -76.120000. running mean: -101.173039\n",
      "ep 29: ep_len:720 episode reward: total was -17.150000. running mean: -100.332809\n",
      "ep 29: ep_len:168 episode reward: total was 17.000000. running mean: -99.159481\n",
      "ep 29: ep_len:770 episode reward: total was -29.260000. running mean: -98.460486\n",
      "ep 29: ep_len:157 episode reward: total was 14.000000. running mean: -97.335881\n",
      "ep 29: ep_len:500 episode reward: total was 13.880000. running mean: -96.223722\n",
      "ep 29: ep_len:500 episode reward: total was 12.230000. running mean: -95.139185\n",
      "ep 29: ep_len:505 episode reward: total was 4.340000. running mean: -94.144393\n",
      "ep 29: ep_len:515 episode reward: total was -63.500000. running mean: -93.837949\n",
      "ep 29: ep_len:500 episode reward: total was -13.740000. running mean: -93.036970\n",
      "ep 29: ep_len:855 episode reward: total was -56.920000. running mean: -92.675800\n",
      "ep 29: ep_len:725 episode reward: total was -48.090000. running mean: -92.229942\n",
      "ep 29: ep_len:500 episode reward: total was -15.010000. running mean: -91.457743\n",
      "ep 29: ep_len:1014 episode reward: total was -173.750000. running mean: -92.280665\n",
      "ep 29: ep_len:500 episode reward: total was 18.750000. running mean: -91.170359\n",
      "ep 29: ep_len:790 episode reward: total was 11.250000. running mean: -90.146155\n",
      "ep 29: ep_len:1370 episode reward: total was -225.570000. running mean: -91.500393\n",
      "ep 29: ep_len:500 episode reward: total was -48.720000. running mean: -91.072589\n",
      "ep 29: ep_len:1005 episode reward: total was -8.860000. running mean: -90.250464\n",
      "ep 29: ep_len:500 episode reward: total was 47.000000. running mean: -88.877959\n",
      "ep 29: ep_len:820 episode reward: total was -32.960000. running mean: -88.318779\n",
      "ep 29: ep_len:865 episode reward: total was -15.760000. running mean: -87.593192\n",
      "ep 29: ep_len:98 episode reward: total was 9.500000. running mean: -86.622260\n",
      "ep 29: ep_len:500 episode reward: total was 22.760000. running mean: -85.528437\n",
      "ep 29: ep_len:885 episode reward: total was -48.780000. running mean: -85.160953\n",
      "ep 29: ep_len:500 episode reward: total was -3.660000. running mean: -84.345943\n",
      "ep 29: ep_len:500 episode reward: total was 9.780000. running mean: -83.404684\n",
      "ep 29: ep_len:500 episode reward: total was 13.270000. running mean: -82.437937\n",
      "ep 29: ep_len:500 episode reward: total was 13.670000. running mean: -81.476858\n",
      "ep 29: ep_len:2257 episode reward: total was -345.990000. running mean: -84.121989\n",
      "ep 29: ep_len:500 episode reward: total was 4.300000. running mean: -83.237769\n",
      "ep 29: ep_len:500 episode reward: total was -3.910000. running mean: -82.444491\n",
      "ep 29: ep_len:662 episode reward: total was -61.380000. running mean: -82.233846\n",
      "ep 29: ep_len:500 episode reward: total was 50.000000. running mean: -80.911508\n",
      "ep 29: ep_len:372 episode reward: total was 37.000000. running mean: -79.732393\n",
      "ep 29: ep_len:915 episode reward: total was -7.010000. running mean: -79.005169\n",
      "ep 29: ep_len:1715 episode reward: total was -138.310000. running mean: -79.598217\n",
      "ep 29: ep_len:530 episode reward: total was -8.080000. running mean: -78.883035\n",
      "ep 29: ep_len:500 episode reward: total was -0.640000. running mean: -78.100605\n",
      "ep 29: ep_len:80 episode reward: total was 6.500000. running mean: -77.254599\n",
      "ep 29: ep_len:154 episode reward: total was 15.000000. running mean: -76.332053\n",
      "ep 29: ep_len:500 episode reward: total was 48.500000. running mean: -75.083732\n",
      "ep 29: ep_len:500 episode reward: total was -4.020000. running mean: -74.373095\n",
      "ep 29: ep_len:695 episode reward: total was -4.720000. running mean: -73.676564\n",
      "ep 29: ep_len:500 episode reward: total was 8.250000. running mean: -72.857298\n",
      "ep 29: ep_len:515 episode reward: total was -5.080000. running mean: -72.179525\n",
      "ep 29: ep_len:620 episode reward: total was -28.100000. running mean: -71.738730\n",
      "ep 29: ep_len:540 episode reward: total was -31.290000. running mean: -71.334243\n",
      "ep 29: ep_len:500 episode reward: total was 16.170000. running mean: -70.459200\n",
      "ep 29: ep_len:500 episode reward: total was -2.990000. running mean: -69.784508\n",
      "ep 29: ep_len:500 episode reward: total was -2.230000. running mean: -69.108963\n",
      "ep 29: ep_len:775 episode reward: total was -3.760000. running mean: -68.455474\n",
      "ep 29: ep_len:500 episode reward: total was -9.730000. running mean: -67.868219\n",
      "ep 29: ep_len:500 episode reward: total was -7.770000. running mean: -67.267237\n",
      "ep 29: ep_len:303 episode reward: total was 14.760000. running mean: -66.446964\n",
      "ep 29: ep_len:650 episode reward: total was 20.270000. running mean: -65.579795\n",
      "ep 29: ep_len:500 episode reward: total was 1.290000. running mean: -64.911097\n",
      "ep 29: ep_len:1065 episode reward: total was 2.410000. running mean: -64.237886\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 29: ep_len:855 episode reward: total was -35.710000. running mean: -63.952607\n",
      "ep 29: ep_len:251 episode reward: total was 23.500000. running mean: -63.078081\n",
      "ep 29: ep_len:825 episode reward: total was -9.260000. running mean: -62.539900\n",
      "ep 29: ep_len:500 episode reward: total was 16.240000. running mean: -61.752101\n",
      "ep 29: ep_len:500 episode reward: total was 27.230000. running mean: -60.862280\n",
      "ep 29: ep_len:500 episode reward: total was 20.980000. running mean: -60.043857\n",
      "ep 29: ep_len:645 episode reward: total was -10.360000. running mean: -59.547019\n",
      "ep 29: ep_len:505 episode reward: total was -5.100000. running mean: -59.002548\n",
      "ep 29: ep_len:525 episode reward: total was 20.210000. running mean: -58.210423\n",
      "ep 29: ep_len:500 episode reward: total was 3.620000. running mean: -57.592119\n",
      "ep 29: ep_len:630 episode reward: total was -38.180000. running mean: -57.397998\n",
      "ep 29: ep_len:705 episode reward: total was -0.660000. running mean: -56.830618\n",
      "ep 29: ep_len:149 episode reward: total was 14.500000. running mean: -56.117311\n",
      "ep 29: ep_len:890 episode reward: total was -41.700000. running mean: -55.973138\n",
      "ep 29: ep_len:725 episode reward: total was -23.820000. running mean: -55.651607\n",
      "ep 29: ep_len:500 episode reward: total was 3.310000. running mean: -55.061991\n",
      "ep 29: ep_len:178 episode reward: total was 18.000000. running mean: -54.331371\n",
      "ep 29: ep_len:500 episode reward: total was -3.240000. running mean: -53.820457\n",
      "ep 29: ep_len:500 episode reward: total was 11.800000. running mean: -53.164253\n",
      "ep 29: ep_len:500 episode reward: total was 5.300000. running mean: -52.579610\n",
      "ep 29: ep_len:500 episode reward: total was -3.200000. running mean: -52.085814\n",
      "ep 29: ep_len:500 episode reward: total was 24.320000. running mean: -51.321756\n",
      "ep 29: ep_len:500 episode reward: total was 16.790000. running mean: -50.640638\n",
      "ep 29: ep_len:194 episode reward: total was 19.000000. running mean: -49.944232\n",
      "ep 29: ep_len:800 episode reward: total was 38.760000. running mean: -49.057190\n",
      "ep 29: ep_len:550 episode reward: total was -9.050000. running mean: -48.657118\n",
      "ep 29: ep_len:500 episode reward: total was 31.850000. running mean: -47.852047\n",
      "ep 29: ep_len:500 episode reward: total was 30.760000. running mean: -47.065926\n",
      "ep 29: ep_len:580 episode reward: total was 11.280000. running mean: -46.482467\n",
      "ep 29: ep_len:500 episode reward: total was -12.260000. running mean: -46.140242\n",
      "ep 29: ep_len:830 episode reward: total was 4.680000. running mean: -45.632040\n",
      "ep 29: ep_len:177 episode reward: total was 17.500000. running mean: -45.000719\n",
      "ep 29: ep_len:830 episode reward: total was -10.510000. running mean: -44.655812\n",
      "ep 29: ep_len:159 episode reward: total was 15.500000. running mean: -44.054254\n",
      "ep 29: ep_len:570 episode reward: total was 19.320000. running mean: -43.420511\n",
      "ep 29: ep_len:500 episode reward: total was 14.560000. running mean: -42.840706\n",
      "ep 29: ep_len:1946 episode reward: total was -243.590000. running mean: -44.848199\n",
      "ep 29: ep_len:500 episode reward: total was 23.280000. running mean: -44.166917\n",
      "ep 29: ep_len:500 episode reward: total was 20.770000. running mean: -43.517548\n",
      "ep 29: ep_len:715 episode reward: total was -15.270000. running mean: -43.235073\n",
      "ep 29: ep_len:720 episode reward: total was -16.790000. running mean: -42.970622\n",
      "ep 29: ep_len:1300 episode reward: total was -193.390000. running mean: -44.474816\n",
      "ep 29: ep_len:249 episode reward: total was 25.000000. running mean: -43.780068\n",
      "ep 29: ep_len:680 episode reward: total was -3.120000. running mean: -43.373467\n",
      "ep 29: ep_len:610 episode reward: total was -12.970000. running mean: -43.069432\n",
      "ep 29: ep_len:575 episode reward: total was -64.550000. running mean: -43.284238\n",
      "ep 29: ep_len:500 episode reward: total was -0.940000. running mean: -42.860795\n",
      "ep 29: ep_len:500 episode reward: total was 6.720000. running mean: -42.364988\n",
      "ep 29: ep_len:4350 episode reward: total was -626.390000. running mean: -48.205238\n",
      "ep 29: ep_len:1274 episode reward: total was -154.060000. running mean: -49.263785\n",
      "ep 29: ep_len:520 episode reward: total was 12.400000. running mean: -48.647147\n",
      "ep 29: ep_len:500 episode reward: total was 20.370000. running mean: -47.956976\n",
      "ep 29: ep_len:1010 episode reward: total was -58.500000. running mean: -48.062406\n",
      "ep 29: ep_len:500 episode reward: total was 10.490000. running mean: -47.476882\n",
      "ep 29: ep_len:345 episode reward: total was 31.500000. running mean: -46.687113\n",
      "ep 29: ep_len:820 episode reward: total was 15.940000. running mean: -46.060842\n",
      "ep 29: ep_len:500 episode reward: total was 10.420000. running mean: -45.496034\n",
      "ep 29: ep_len:500 episode reward: total was 16.020000. running mean: -44.880873\n",
      "ep 29: ep_len:500 episode reward: total was 8.240000. running mean: -44.349665\n",
      "ep 29: ep_len:800 episode reward: total was 21.250000. running mean: -43.693668\n",
      "ep 29: ep_len:690 episode reward: total was 4.430000. running mean: -43.212431\n",
      "ep 29: ep_len:785 episode reward: total was -26.760000. running mean: -43.047907\n",
      "ep 29: ep_len:1025 episode reward: total was 14.790000. running mean: -42.469528\n",
      "ep 29: ep_len:500 episode reward: total was 18.960000. running mean: -41.855233\n",
      "ep 29: ep_len:815 episode reward: total was -4.530000. running mean: -41.481980\n",
      "ep 29: ep_len:815 episode reward: total was -54.980000. running mean: -41.616961\n",
      "ep 29: ep_len:386 episode reward: total was 21.300000. running mean: -40.987791\n",
      "ep 29: ep_len:500 episode reward: total was 16.180000. running mean: -40.416113\n",
      "ep 29: ep_len:505 episode reward: total was 1.330000. running mean: -39.998652\n",
      "ep 29: ep_len:580 episode reward: total was 5.320000. running mean: -39.545465\n",
      "ep 29: ep_len:500 episode reward: total was 32.310000. running mean: -38.826911\n",
      "ep 29: ep_len:755 episode reward: total was -8.640000. running mean: -38.525042\n",
      "ep 29: ep_len:500 episode reward: total was 1.350000. running mean: -38.126291\n",
      "ep 29: ep_len:885 episode reward: total was -23.370000. running mean: -37.978728\n",
      "ep 29: ep_len:815 episode reward: total was -109.490000. running mean: -38.693841\n",
      "ep 29: ep_len:530 episode reward: total was -33.330000. running mean: -38.640203\n",
      "ep 29: ep_len:720 episode reward: total was -26.890000. running mean: -38.522701\n",
      "ep 29: ep_len:870 episode reward: total was -11.310000. running mean: -38.250574\n",
      "ep 29: ep_len:2415 episode reward: total was -124.440000. running mean: -39.112468\n",
      "ep 29: ep_len:575 episode reward: total was -5.450000. running mean: -38.775843\n",
      "ep 29: ep_len:500 episode reward: total was 47.000000. running mean: -37.918085\n",
      "ep 29: ep_len:690 episode reward: total was -8.770000. running mean: -37.626604\n",
      "ep 29: ep_len:500 episode reward: total was 5.250000. running mean: -37.197838\n",
      "ep 29: ep_len:500 episode reward: total was -0.210000. running mean: -36.827959\n",
      "ep 29: ep_len:690 episode reward: total was -3.720000. running mean: -36.496880\n",
      "ep 29: ep_len:500 episode reward: total was 8.550000. running mean: -36.046411\n",
      "ep 29: ep_len:1235 episode reward: total was 3.880000. running mean: -35.647147\n",
      "ep 29: ep_len:500 episode reward: total was 1.480000. running mean: -35.275876\n",
      "ep 29: ep_len:605 episode reward: total was -66.690000. running mean: -35.590017\n",
      "ep 29: ep_len:387 episode reward: total was 10.130000. running mean: -35.132817\n",
      "ep 29: ep_len:510 episode reward: total was -1.050000. running mean: -34.791988\n",
      "ep 29: ep_len:58 episode reward: total was 5.500000. running mean: -34.389069\n",
      "ep 29: ep_len:950 episode reward: total was -45.680000. running mean: -34.501978\n",
      "ep 29: ep_len:500 episode reward: total was 11.730000. running mean: -34.039658\n",
      "ep 29: ep_len:630 episode reward: total was 27.860000. running mean: -33.420661\n",
      "ep 29: ep_len:1090 episode reward: total was -78.670000. running mean: -33.873155\n",
      "ep 29: ep_len:660 episode reward: total was -4.360000. running mean: -33.578023\n",
      "ep 29: ep_len:277 episode reward: total was 27.500000. running mean: -32.967243\n",
      "ep 29: ep_len:1579 episode reward: total was -206.960000. running mean: -34.707171\n",
      "ep 29: ep_len:770 episode reward: total was -33.860000. running mean: -34.698699\n",
      "ep 29: ep_len:229 episode reward: total was 21.000000. running mean: -34.141712\n",
      "ep 29: ep_len:500 episode reward: total was 22.800000. running mean: -33.572295\n",
      "ep 29: ep_len:960 episode reward: total was -12.020000. running mean: -33.356772\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 29: ep_len:550 episode reward: total was -4.000000. running mean: -33.063204\n",
      "ep 29: ep_len:1100 episode reward: total was 16.290000. running mean: -32.569672\n",
      "ep 29: ep_len:500 episode reward: total was 3.310000. running mean: -32.210875\n",
      "ep 29: ep_len:227 episode reward: total was 22.500000. running mean: -31.663767\n",
      "ep 29: ep_len:575 episode reward: total was -0.890000. running mean: -31.356029\n",
      "ep 29: ep_len:705 episode reward: total was 6.140000. running mean: -30.981069\n",
      "ep 29: ep_len:500 episode reward: total was 30.260000. running mean: -30.368658\n",
      "ep 29: ep_len:500 episode reward: total was 10.300000. running mean: -29.961971\n",
      "ep 29: ep_len:670 episode reward: total was 0.280000. running mean: -29.659552\n",
      "ep 29: ep_len:500 episode reward: total was 50.000000. running mean: -28.862956\n",
      "ep 29: ep_len:765 episode reward: total was 29.790000. running mean: -28.276427\n",
      "ep 29: ep_len:258 episode reward: total was 25.500000. running mean: -27.738662\n",
      "ep 29: ep_len:500 episode reward: total was 18.260000. running mean: -27.278676\n",
      "ep 29: ep_len:815 episode reward: total was 18.070000. running mean: -26.825189\n",
      "ep 29: ep_len:535 episode reward: total was -21.200000. running mean: -26.768937\n",
      "ep 29: ep_len:915 episode reward: total was 5.320000. running mean: -26.448048\n",
      "ep 29: ep_len:505 episode reward: total was -17.220000. running mean: -26.355767\n",
      "ep 29: ep_len:1205 episode reward: total was -76.910000. running mean: -26.861310\n",
      "ep 29: ep_len:815 episode reward: total was -69.880000. running mean: -27.291496\n",
      "ep 29: ep_len:500 episode reward: total was 18.780000. running mean: -26.830782\n",
      "ep 29: ep_len:575 episode reward: total was -1.930000. running mean: -26.581774\n",
      "ep 29: ep_len:219 episode reward: total was 14.500000. running mean: -26.170956\n",
      "ep 29: ep_len:156 episode reward: total was 15.500000. running mean: -25.754246\n",
      "ep 29: ep_len:625 episode reward: total was -11.930000. running mean: -25.616004\n",
      "ep 29: ep_len:1045 episode reward: total was -48.460000. running mean: -25.844444\n",
      "ep 29: ep_len:500 episode reward: total was -15.270000. running mean: -25.738699\n",
      "ep 29: ep_len:402 episode reward: total was 6.420000. running mean: -25.417112\n",
      "ep 29: ep_len:975 episode reward: total was 0.000000. running mean: -25.162941\n",
      "ep 29: ep_len:750 episode reward: total was -28.850000. running mean: -25.199812\n",
      "ep 29: ep_len:1425 episode reward: total was -37.570000. running mean: -25.323514\n",
      "ep 29: ep_len:765 episode reward: total was -10.180000. running mean: -25.172079\n",
      "ep 29: ep_len:720 episode reward: total was -12.750000. running mean: -25.047858\n",
      "ep 29: ep_len:670 episode reward: total was 19.210000. running mean: -24.605279\n",
      "ep 29: ep_len:560 episode reward: total was -1.960000. running mean: -24.378827\n",
      "ep 29: ep_len:810 episode reward: total was 6.810000. running mean: -24.066938\n",
      "ep 29: ep_len:310 episode reward: total was 29.500000. running mean: -23.531269\n",
      "ep 29: ep_len:985 episode reward: total was -24.340000. running mean: -23.539356\n",
      "ep 29: ep_len:530 episode reward: total was 21.780000. running mean: -23.086163\n",
      "ep 29: ep_len:500 episode reward: total was -16.800000. running mean: -23.023301\n",
      "ep 29: ep_len:500 episode reward: total was 21.760000. running mean: -22.575468\n",
      "ep 29: ep_len:595 episode reward: total was 12.510000. running mean: -22.224613\n",
      "ep 29: ep_len:785 episode reward: total was -34.840000. running mean: -22.350767\n",
      "ep 29: ep_len:500 episode reward: total was 22.820000. running mean: -21.899059\n",
      "ep 29: ep_len:500 episode reward: total was -0.910000. running mean: -21.689169\n",
      "ep 29: ep_len:710 episode reward: total was -34.990000. running mean: -21.822177\n",
      "ep 29: ep_len:222 episode reward: total was 20.500000. running mean: -21.398955\n",
      "ep 29: ep_len:432 episode reward: total was 36.000000. running mean: -20.824966\n",
      "ep 29: ep_len:500 episode reward: total was 10.580000. running mean: -20.510916\n",
      "ep 29: ep_len:675 episode reward: total was -4.760000. running mean: -20.353407\n",
      "ep 29: ep_len:585 episode reward: total was -2.920000. running mean: -20.179073\n",
      "ep 29: ep_len:595 episode reward: total was 31.890000. running mean: -19.658382\n",
      "ep 29: ep_len:500 episode reward: total was -15.110000. running mean: -19.612898\n",
      "ep 29: ep_len:500 episode reward: total was 27.320000. running mean: -19.143569\n",
      "ep 29: ep_len:410 episode reward: total was 36.500000. running mean: -18.587134\n",
      "ep 29: ep_len:520 episode reward: total was 12.830000. running mean: -18.272962\n",
      "ep 29: ep_len:990 episode reward: total was 20.860000. running mean: -17.881633\n",
      "ep 29: ep_len:830 episode reward: total was -13.540000. running mean: -17.838216\n",
      "ep 29: ep_len:860 episode reward: total was 20.360000. running mean: -17.456234\n",
      "ep 29: ep_len:500 episode reward: total was 11.800000. running mean: -17.163672\n",
      "ep 29: ep_len:920 episode reward: total was 9.050000. running mean: -16.901535\n",
      "ep 29: ep_len:885 episode reward: total was -11.560000. running mean: -16.848120\n",
      "ep 29: ep_len:500 episode reward: total was -3.210000. running mean: -16.711739\n",
      "ep 29: ep_len:500 episode reward: total was 31.310000. running mean: -16.231521\n",
      "ep 29: ep_len:500 episode reward: total was 28.760000. running mean: -15.781606\n",
      "ep 29: ep_len:730 episode reward: total was -7.670000. running mean: -15.700490\n",
      "ep 29: ep_len:720 episode reward: total was -19.280000. running mean: -15.736285\n",
      "ep 29: ep_len:975 episode reward: total was -10.770000. running mean: -15.686622\n",
      "ep 29: ep_len:500 episode reward: total was 15.810000. running mean: -15.371656\n",
      "ep 29: ep_len:650 episode reward: total was -11.880000. running mean: -15.336740\n",
      "ep 29: ep_len:217 episode reward: total was 18.500000. running mean: -14.998372\n",
      "ep 29: ep_len:462 episode reward: total was 46.000000. running mean: -14.388388\n",
      "ep 29: ep_len:520 episode reward: total was -10.610000. running mean: -14.350605\n",
      "ep 29: ep_len:705 episode reward: total was -0.690000. running mean: -14.213998\n",
      "ep 29: ep_len:765 episode reward: total was -2.560000. running mean: -14.097458\n",
      "ep 29: ep_len:500 episode reward: total was 29.310000. running mean: -13.663384\n",
      "ep 29: ep_len:343 episode reward: total was 34.000000. running mean: -13.186750\n",
      "ep 29: ep_len:84 episode reward: total was 6.500000. running mean: -12.989883\n",
      "ep 29: ep_len:500 episode reward: total was 4.640000. running mean: -12.813584\n",
      "ep 29: ep_len:500 episode reward: total was 28.240000. running mean: -12.403048\n",
      "ep 29: ep_len:203 episode reward: total was 18.500000. running mean: -12.094017\n",
      "ep 29: ep_len:332 episode reward: total was 11.790000. running mean: -11.855177\n",
      "ep 29: ep_len:1090 episode reward: total was -95.840000. running mean: -12.695025\n",
      "ep 29: ep_len:550 episode reward: total was -5.010000. running mean: -12.618175\n",
      "ep 29: ep_len:3875 episode reward: total was -518.640000. running mean: -17.678393\n",
      "ep 29: ep_len:154 episode reward: total was 14.000000. running mean: -17.361610\n",
      "ep 29: ep_len:500 episode reward: total was 12.880000. running mean: -17.059193\n",
      "ep 29: ep_len:675 episode reward: total was -1.730000. running mean: -16.905901\n",
      "ep 29: ep_len:500 episode reward: total was -6.140000. running mean: -16.798242\n",
      "ep 29: ep_len:2250 episode reward: total was -272.270000. running mean: -19.352960\n",
      "ep 29: ep_len:920 episode reward: total was -16.150000. running mean: -19.320930\n",
      "ep 29: ep_len:810 episode reward: total was -58.740000. running mean: -19.715121\n",
      "ep 29: ep_len:500 episode reward: total was 9.040000. running mean: -19.427570\n",
      "ep 29: ep_len:580 episode reward: total was -13.030000. running mean: -19.363594\n",
      "ep 29: ep_len:198 episode reward: total was 18.000000. running mean: -18.989958\n",
      "ep 29: ep_len:500 episode reward: total was 18.330000. running mean: -18.616759\n",
      "ep 29: ep_len:610 episode reward: total was -8.930000. running mean: -18.519891\n",
      "ep 29: ep_len:705 episode reward: total was -7.730000. running mean: -18.411992\n",
      "ep 29: ep_len:630 episode reward: total was -2.520000. running mean: -18.253072\n",
      "ep 29: ep_len:500 episode reward: total was 31.790000. running mean: -17.752642\n",
      "ep 29: ep_len:500 episode reward: total was 10.170000. running mean: -17.473415\n",
      "ep 29: ep_len:196 episode reward: total was 18.000000. running mean: -17.118681\n",
      "ep 29: ep_len:500 episode reward: total was 13.450000. running mean: -16.812994\n",
      "ep 29: ep_len:649 episode reward: total was -86.610000. running mean: -17.510964\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 29: ep_len:780 episode reward: total was 11.310000. running mean: -17.222755\n",
      "ep 29: ep_len:1010 episode reward: total was 15.710000. running mean: -16.893427\n",
      "ep 29: ep_len:500 episode reward: total was 5.370000. running mean: -16.670793\n",
      "ep 29: ep_len:885 episode reward: total was -28.150000. running mean: -16.785585\n",
      "ep 29: ep_len:453 episode reward: total was -64.780000. running mean: -17.265529\n",
      "ep 29: ep_len:580 episode reward: total was 8.830000. running mean: -17.004574\n",
      "ep 29: ep_len:590 episode reward: total was -22.300000. running mean: -17.057528\n",
      "ep 29: ep_len:500 episode reward: total was -39.020000. running mean: -17.277153\n",
      "ep 29: ep_len:1005 episode reward: total was -0.360000. running mean: -17.107981\n",
      "ep 29: ep_len:1010 episode reward: total was 23.810000. running mean: -16.698801\n",
      "ep 29: ep_len:500 episode reward: total was 18.290000. running mean: -16.348913\n",
      "ep 29: ep_len:590 episode reward: total was -32.200000. running mean: -16.507424\n",
      "ep 29: ep_len:500 episode reward: total was 8.190000. running mean: -16.260450\n",
      "ep 29: ep_len:545 episode reward: total was -4.010000. running mean: -16.137945\n",
      "ep 29: ep_len:358 episode reward: total was 34.000000. running mean: -15.636566\n",
      "ep 29: ep_len:645 episode reward: total was -17.950000. running mean: -15.659700\n",
      "ep 29: ep_len:500 episode reward: total was -8.250000. running mean: -15.585603\n",
      "ep 29: ep_len:500 episode reward: total was -14.220000. running mean: -15.571947\n",
      "ep 29: ep_len:500 episode reward: total was 1.600000. running mean: -15.400228\n",
      "ep 29: ep_len:2145 episode reward: total was -257.350000. running mean: -17.819726\n",
      "ep 29: ep_len:500 episode reward: total was -3.270000. running mean: -17.674228\n",
      "ep 29: ep_len:710 episode reward: total was -5.700000. running mean: -17.554486\n",
      "ep 29: ep_len:1415 episode reward: total was -115.390000. running mean: -18.532841\n",
      "ep 29: ep_len:1412 episode reward: total was -238.500000. running mean: -20.732513\n",
      "ep 29: ep_len:680 episode reward: total was -23.940000. running mean: -20.764588\n",
      "ep 29: ep_len:345 episode reward: total was 33.000000. running mean: -20.226942\n",
      "ep 29: ep_len:1290 episode reward: total was -64.670000. running mean: -20.671372\n",
      "ep 29: ep_len:500 episode reward: total was 13.720000. running mean: -20.327459\n",
      "ep 29: ep_len:1780 episode reward: total was -46.390000. running mean: -20.588084\n",
      "ep 29: ep_len:500 episode reward: total was 20.280000. running mean: -20.179403\n",
      "ep 29: ep_len:500 episode reward: total was 50.000000. running mean: -19.477609\n",
      "ep 29: ep_len:500 episode reward: total was 16.790000. running mean: -19.114933\n",
      "ep 29: ep_len:500 episode reward: total was 19.790000. running mean: -18.725884\n",
      "ep 29: ep_len:500 episode reward: total was 13.240000. running mean: -18.406225\n",
      "ep 29: ep_len:221 episode reward: total was 5.500000. running mean: -18.167163\n",
      "ep 29: ep_len:835 episode reward: total was -4.620000. running mean: -18.031691\n",
      "ep 29: ep_len:500 episode reward: total was 5.270000. running mean: -17.798674\n",
      "ep 29: ep_len:710 episode reward: total was -2.670000. running mean: -17.647387\n",
      "ep 29: ep_len:500 episode reward: total was -6.880000. running mean: -17.539713\n",
      "ep 29: ep_len:500 episode reward: total was 31.300000. running mean: -17.051316\n",
      "ep 29: ep_len:825 episode reward: total was -22.640000. running mean: -17.107203\n",
      "ep 29: ep_len:525 episode reward: total was 9.610000. running mean: -16.840031\n",
      "ep 29: ep_len:2126 episode reward: total was -200.350000. running mean: -18.675131\n",
      "ep 29: ep_len:960 episode reward: total was -22.370000. running mean: -18.712080\n",
      "ep 29: ep_len:724 episode reward: total was -48.080000. running mean: -19.005759\n",
      "ep 29: ep_len:785 episode reward: total was -6.620000. running mean: -18.881901\n",
      "ep 29: ep_len:1095 episode reward: total was -93.120000. running mean: -19.624282\n",
      "ep 29: ep_len:1005 episode reward: total was -14.550000. running mean: -19.573539\n",
      "ep 29: ep_len:135 episode reward: total was 12.000000. running mean: -19.257804\n",
      "ep 29: ep_len:620 episode reward: total was 10.900000. running mean: -18.956226\n",
      "ep 29: ep_len:500 episode reward: total was 50.500000. running mean: -18.261664\n",
      "ep 29: ep_len:780 episode reward: total was -3.540000. running mean: -18.114447\n",
      "ep 29: ep_len:500 episode reward: total was 25.210000. running mean: -17.681203\n",
      "ep 29: ep_len:1035 episode reward: total was -71.710000. running mean: -18.221491\n",
      "ep 29: ep_len:1550 episode reward: total was -82.800000. running mean: -18.867276\n",
      "ep 29: ep_len:452 episode reward: total was 40.500000. running mean: -18.273603\n",
      "ep 29: ep_len:645 episode reward: total was -46.230000. running mean: -18.553167\n",
      "ep 29: ep_len:500 episode reward: total was 8.220000. running mean: -18.285435\n",
      "ep 29: ep_len:500 episode reward: total was 26.870000. running mean: -17.833881\n",
      "ep 29: ep_len:935 episode reward: total was -15.350000. running mean: -17.809042\n",
      "ep 29: ep_len:1415 episode reward: total was -141.650000. running mean: -19.047452\n",
      "ep 29: ep_len:670 episode reward: total was -1.600000. running mean: -18.872977\n",
      "ep 29: ep_len:665 episode reward: total was 0.270000. running mean: -18.681547\n",
      "ep 29: ep_len:812 episode reward: total was -43.240000. running mean: -18.927132\n",
      "ep 29: ep_len:269 episode reward: total was 1.000000. running mean: -18.727860\n",
      "ep 29: ep_len:930 episode reward: total was 15.150000. running mean: -18.389082\n",
      "ep 29: ep_len:500 episode reward: total was 7.270000. running mean: -18.132491\n",
      "ep 29: ep_len:845 episode reward: total was 1.910000. running mean: -17.932066\n",
      "ep 29: ep_len:695 episode reward: total was -68.350000. running mean: -18.436245\n",
      "ep 29: ep_len:845 episode reward: total was -23.610000. running mean: -18.487983\n",
      "ep 29: ep_len:825 episode reward: total was 29.140000. running mean: -18.011703\n",
      "ep 29: ep_len:1040 episode reward: total was -71.700000. running mean: -18.548586\n",
      "ep 29: ep_len:575 episode reward: total was 20.610000. running mean: -18.157000\n",
      "ep 29: ep_len:8495 episode reward: total was -1617.260000. running mean: -34.148030\n",
      "ep 29: ep_len:735 episode reward: total was -5.650000. running mean: -33.863050\n",
      "ep 29: ep_len:500 episode reward: total was 10.720000. running mean: -33.417220\n",
      "ep 29: ep_len:570 episode reward: total was -21.130000. running mean: -33.294347\n",
      "ep 29: ep_len:520 episode reward: total was -17.190000. running mean: -33.133304\n",
      "ep 29: ep_len:500 episode reward: total was -17.780000. running mean: -32.979771\n",
      "ep 29: ep_len:710 episode reward: total was 27.560000. running mean: -32.374373\n",
      "ep 29: ep_len:500 episode reward: total was 24.010000. running mean: -31.810529\n",
      "ep 29: ep_len:481 episode reward: total was 28.720000. running mean: -31.205224\n",
      "ep 29: ep_len:685 episode reward: total was -23.130000. running mean: -31.124472\n",
      "ep 29: ep_len:505 episode reward: total was -9.260000. running mean: -30.905827\n",
      "ep 29: ep_len:500 episode reward: total was 12.840000. running mean: -30.468369\n",
      "ep 29: ep_len:930 episode reward: total was -38.030000. running mean: -30.543985\n",
      "ep 29: ep_len:710 episode reward: total was -20.850000. running mean: -30.447045\n",
      "ep 29: ep_len:500 episode reward: total was 20.840000. running mean: -29.934175\n",
      "ep 29: ep_len:500 episode reward: total was 20.920000. running mean: -29.425633\n",
      "ep 29: ep_len:505 episode reward: total was 1.820000. running mean: -29.113177\n",
      "ep 29: ep_len:500 episode reward: total was 17.580000. running mean: -28.646245\n",
      "ep 29: ep_len:825 episode reward: total was -51.930000. running mean: -28.879083\n",
      "ep 29: ep_len:500 episode reward: total was 20.250000. running mean: -28.387792\n",
      "ep 29: ep_len:510 episode reward: total was -7.110000. running mean: -28.175014\n",
      "ep 29: ep_len:585 episode reward: total was -16.370000. running mean: -28.056964\n",
      "ep 29: ep_len:326 episode reward: total was 11.570000. running mean: -27.660694\n",
      "ep 29: ep_len:625 episode reward: total was 26.870000. running mean: -27.115387\n",
      "ep 29: ep_len:550 episode reward: total was -32.280000. running mean: -27.167033\n",
      "ep 29: ep_len:735 episode reward: total was -6.280000. running mean: -26.958163\n",
      "ep 29: ep_len:500 episode reward: total was 19.360000. running mean: -26.494981\n",
      "ep 29: ep_len:1236 episode reward: total was -215.810000. running mean: -28.388131\n",
      "ep 29: ep_len:500 episode reward: total was 3.310000. running mean: -28.071150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 29: ep_len:464 episode reward: total was 43.500000. running mean: -27.355439\n",
      "ep 29: ep_len:920 episode reward: total was 24.140000. running mean: -26.840484\n",
      "ep 29: ep_len:550 episode reward: total was -4.000000. running mean: -26.612079\n",
      "ep 29: ep_len:500 episode reward: total was -10.830000. running mean: -26.454259\n",
      "ep 29: ep_len:229 episode reward: total was 21.000000. running mean: -25.979716\n",
      "ep 29: ep_len:500 episode reward: total was 13.280000. running mean: -25.587119\n",
      "ep 29: ep_len:500 episode reward: total was 1.750000. running mean: -25.313748\n",
      "ep 29: ep_len:500 episode reward: total was 3.220000. running mean: -25.028410\n",
      "ep 29: ep_len:885 episode reward: total was 30.970000. running mean: -24.468426\n",
      "ep 29: ep_len:500 episode reward: total was 50.000000. running mean: -23.723742\n",
      "ep 29: ep_len:500 episode reward: total was 22.880000. running mean: -23.257704\n",
      "ep 29: ep_len:735 episode reward: total was -2.620000. running mean: -23.051327\n",
      "ep 29: ep_len:500 episode reward: total was 24.810000. running mean: -22.572714\n",
      "ep 29: ep_len:13033 episode reward: total was -2415.460000. running mean: -46.501587\n",
      "ep 29: ep_len:500 episode reward: total was 9.350000. running mean: -45.943071\n",
      "ep 29: ep_len:1060 episode reward: total was -41.850000. running mean: -45.902140\n",
      "ep 29: ep_len:645 episode reward: total was -21.560000. running mean: -45.658719\n",
      "ep 29: ep_len:690 episode reward: total was -53.390000. running mean: -45.736032\n",
      "ep 29: ep_len:500 episode reward: total was 28.730000. running mean: -44.991371\n",
      "ep 29: ep_len:920 episode reward: total was -40.110000. running mean: -44.942558\n",
      "ep 29: ep_len:920 episode reward: total was 12.100000. running mean: -44.372132\n",
      "ep 29: ep_len:735 episode reward: total was -52.110000. running mean: -44.449511\n",
      "ep 29: ep_len:960 episode reward: total was -28.050000. running mean: -44.285516\n",
      "ep 29: ep_len:585 episode reward: total was 38.760000. running mean: -43.455061\n",
      "ep 29: ep_len:500 episode reward: total was -7.490000. running mean: -43.095410\n",
      "ep 29: ep_len:925 episode reward: total was -88.090000. running mean: -43.545356\n",
      "ep 29: ep_len:565 episode reward: total was -20.130000. running mean: -43.311202\n",
      "ep 29: ep_len:500 episode reward: total was 17.950000. running mean: -42.698590\n",
      "ep 29: ep_len:805 episode reward: total was -48.940000. running mean: -42.761004\n",
      "ep 29: ep_len:449 episode reward: total was -19.510000. running mean: -42.528494\n",
      "ep 29: ep_len:540 episode reward: total was 21.830000. running mean: -41.884909\n",
      "ep 29: ep_len:745 episode reward: total was -30.880000. running mean: -41.774860\n",
      "ep 29: ep_len:690 episode reward: total was 16.040000. running mean: -41.196712\n",
      "ep 29: ep_len:850 episode reward: total was -35.720000. running mean: -41.141945\n",
      "ep 29: ep_len:161 episode reward: total was 16.000000. running mean: -40.570525\n",
      "ep 29: ep_len:960 episode reward: total was 7.040000. running mean: -40.094420\n",
      "ep 29: ep_len:500 episode reward: total was 20.160000. running mean: -39.491876\n",
      "ep 29: ep_len:1170 episode reward: total was -26.740000. running mean: -39.364357\n",
      "ep 29: ep_len:1365 episode reward: total was -185.840000. running mean: -40.829113\n",
      "ep 29: ep_len:605 episode reward: total was -26.110000. running mean: -40.681922\n",
      "ep 29: ep_len:659 episode reward: total was -82.270000. running mean: -41.097803\n",
      "ep 29: ep_len:500 episode reward: total was -7.130000. running mean: -40.758125\n",
      "ep 29: ep_len:500 episode reward: total was -3.820000. running mean: -40.388744\n",
      "ep 29: ep_len:500 episode reward: total was -9.270000. running mean: -40.077556\n",
      "ep 29: ep_len:665 episode reward: total was -6.210000. running mean: -39.738881\n",
      "ep 29: ep_len:500 episode reward: total was 12.720000. running mean: -39.214292\n",
      "ep 29: ep_len:1695 episode reward: total was -224.970000. running mean: -41.071849\n",
      "ep 29: ep_len:620 episode reward: total was -26.080000. running mean: -40.921931\n",
      "ep 29: ep_len:725 episode reward: total was -20.820000. running mean: -40.720911\n",
      "ep 29: ep_len:1395 episode reward: total was -202.290000. running mean: -42.336602\n",
      "ep 29: ep_len:630 episode reward: total was -17.980000. running mean: -42.093036\n",
      "ep 29: ep_len:535 episode reward: total was -2.010000. running mean: -41.692206\n",
      "ep 29: ep_len:520 episode reward: total was -16.180000. running mean: -41.437084\n",
      "ep 29: ep_len:620 episode reward: total was 8.250000. running mean: -40.940213\n",
      "ep 29: ep_len:715 episode reward: total was 2.010000. running mean: -40.510711\n",
      "ep 29: ep_len:273 episode reward: total was 26.000000. running mean: -39.845604\n",
      "ep 29: ep_len:1400 episode reward: total was -181.040000. running mean: -41.257548\n",
      "ep 29: ep_len:965 episode reward: total was -65.790000. running mean: -41.502872\n",
      "ep 29: ep_len:500 episode reward: total was 11.180000. running mean: -40.976043\n",
      "ep 29: ep_len:500 episode reward: total was -0.820000. running mean: -40.574483\n",
      "ep 29: ep_len:800 episode reward: total was -0.740000. running mean: -40.176138\n",
      "ep 29: ep_len:500 episode reward: total was 12.690000. running mean: -39.647477\n",
      "ep 29: ep_len:358 episode reward: total was -22.270000. running mean: -39.473702\n",
      "ep 29: ep_len:705 episode reward: total was 16.650000. running mean: -38.912465\n",
      "ep 29: ep_len:755 episode reward: total was 5.920000. running mean: -38.464140\n",
      "ep 29: ep_len:500 episode reward: total was -0.450000. running mean: -38.083999\n",
      "ep 29: ep_len:260 episode reward: total was 24.500000. running mean: -37.458159\n",
      "ep 29: ep_len:500 episode reward: total was 7.910000. running mean: -37.004477\n",
      "ep 29: ep_len:560 episode reward: total was -43.370000. running mean: -37.068133\n",
      "ep 29: ep_len:500 episode reward: total was -21.870000. running mean: -36.916151\n",
      "ep 29: ep_len:505 episode reward: total was -38.430000. running mean: -36.931290\n",
      "ep 29: ep_len:910 episode reward: total was 6.050000. running mean: -36.501477\n",
      "ep 29: ep_len:885 episode reward: total was -39.430000. running mean: -36.530762\n",
      "ep 29: ep_len:860 episode reward: total was -33.680000. running mean: -36.502254\n",
      "ep 29: ep_len:267 episode reward: total was 25.000000. running mean: -35.887232\n",
      "ep 29: ep_len:1205 episode reward: total was -177.400000. running mean: -37.302360\n",
      "ep 29: ep_len:1138 episode reward: total was -196.790000. running mean: -38.897236\n",
      "ep 29: ep_len:505 episode reward: total was 6.630000. running mean: -38.441964\n",
      "ep 29: ep_len:645 episode reward: total was 33.770000. running mean: -37.719844\n",
      "ep 29: ep_len:500 episode reward: total was 28.240000. running mean: -37.060246\n",
      "ep 29: ep_len:445 episode reward: total was 43.000000. running mean: -36.259643\n",
      "ep 29: ep_len:705 episode reward: total was 13.410000. running mean: -35.762947\n",
      "ep 29: ep_len:185 episode reward: total was 14.000000. running mean: -35.265317\n",
      "ep 29: ep_len:500 episode reward: total was 21.780000. running mean: -34.694864\n",
      "ep 29: ep_len:500 episode reward: total was 1.350000. running mean: -34.334415\n",
      "ep 29: ep_len:2338 episode reward: total was -281.150000. running mean: -36.802571\n",
      "ep 29: ep_len:252 episode reward: total was 23.500000. running mean: -36.199545\n",
      "ep 29: ep_len:500 episode reward: total was -37.270000. running mean: -36.210250\n",
      "ep 29: ep_len:250 episode reward: total was 23.500000. running mean: -35.613148\n",
      "ep 29: ep_len:635 episode reward: total was 17.950000. running mean: -35.077516\n",
      "ep 29: ep_len:500 episode reward: total was 0.220000. running mean: -34.724541\n",
      "ep 29: ep_len:545 episode reward: total was 15.040000. running mean: -34.226895\n",
      "ep 29: ep_len:500 episode reward: total was -1.230000. running mean: -33.896927\n",
      "ep 29: ep_len:58 episode reward: total was 5.500000. running mean: -33.502957\n",
      "ep 29: ep_len:695 episode reward: total was 25.750000. running mean: -32.910428\n",
      "ep 29: ep_len:775 episode reward: total was -9.610000. running mean: -32.677423\n",
      "ep 29: ep_len:525 episode reward: total was 1.250000. running mean: -32.338149\n",
      "ep 29: ep_len:670 episode reward: total was 33.790000. running mean: -31.676868\n",
      "ep 29: ep_len:197 episode reward: total was 19.500000. running mean: -31.165099\n",
      "ep 29: ep_len:540 episode reward: total was 10.040000. running mean: -30.753048\n",
      "ep 29: ep_len:840 episode reward: total was 11.710000. running mean: -30.328418\n",
      "ep 29: ep_len:875 episode reward: total was -22.540000. running mean: -30.250533\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 29: ep_len:835 episode reward: total was -8.660000. running mean: -30.034628\n",
      "ep 29: ep_len:560 episode reward: total was -0.720000. running mean: -29.741482\n",
      "ep 29: ep_len:500 episode reward: total was 27.780000. running mean: -29.166267\n",
      "ep 29: ep_len:500 episode reward: total was 7.270000. running mean: -28.801904\n",
      "ep 29: ep_len:500 episode reward: total was -4.680000. running mean: -28.560685\n",
      "ep 29: ep_len:510 episode reward: total was -15.510000. running mean: -28.430178\n",
      "ep 29: ep_len:500 episode reward: total was 10.050000. running mean: -28.045377\n",
      "ep 29: ep_len:500 episode reward: total was 2.250000. running mean: -27.742423\n",
      "ep 29: ep_len:237 episode reward: total was 23.500000. running mean: -27.229999\n",
      "ep 29: ep_len:500 episode reward: total was -3.990000. running mean: -26.997599\n",
      "ep 29: ep_len:1435 episode reward: total was -253.720000. running mean: -29.264823\n",
      "ep 29: ep_len:500 episode reward: total was 15.500000. running mean: -28.817174\n",
      "ep 29: ep_len:500 episode reward: total was 7.830000. running mean: -28.450703\n",
      "ep 29: ep_len:840 episode reward: total was 1.930000. running mean: -28.146896\n",
      "ep 29: ep_len:500 episode reward: total was -17.290000. running mean: -28.038327\n",
      "ep 29: ep_len:640 episode reward: total was 9.390000. running mean: -27.664043\n",
      "ep 29: ep_len:500 episode reward: total was 15.240000. running mean: -27.235003\n",
      "ep 29: ep_len:500 episode reward: total was 0.780000. running mean: -26.954853\n",
      "ep 29: ep_len:500 episode reward: total was 11.120000. running mean: -26.574104\n",
      "ep 29: ep_len:570 episode reward: total was 9.270000. running mean: -26.215663\n",
      "ep 29: ep_len:825 episode reward: total was -5.180000. running mean: -26.005307\n",
      "ep 29: ep_len:620 episode reward: total was 1.190000. running mean: -25.733354\n",
      "ep 29: ep_len:500 episode reward: total was 16.970000. running mean: -25.306320\n",
      "ep 29: ep_len:555 episode reward: total was -19.140000. running mean: -25.244657\n",
      "ep 29: ep_len:500 episode reward: total was 20.490000. running mean: -24.787310\n",
      "ep 29: ep_len:935 episode reward: total was -47.670000. running mean: -25.016137\n",
      "ep 29: ep_len:500 episode reward: total was 26.800000. running mean: -24.497976\n",
      "ep 29: ep_len:270 episode reward: total was 25.500000. running mean: -23.997996\n",
      "ep 29: ep_len:645 episode reward: total was 1.240000. running mean: -23.745616\n",
      "ep 29: ep_len:303 episode reward: total was 13.810000. running mean: -23.370060\n",
      "ep 29: ep_len:767 episode reward: total was -59.100000. running mean: -23.727359\n",
      "ep 29: ep_len:500 episode reward: total was -10.000000. running mean: -23.590086\n",
      "ep 29: ep_len:1580 episode reward: total was -225.150000. running mean: -25.605685\n",
      "ep 29: ep_len:500 episode reward: total was 33.260000. running mean: -25.017028\n",
      "ep 29: ep_len:1960 episode reward: total was -238.530000. running mean: -27.152158\n",
      "ep 29: ep_len:500 episode reward: total was 50.000000. running mean: -26.380636\n",
      "ep 29: ep_len:500 episode reward: total was 32.280000. running mean: -25.794030\n",
      "ep 29: ep_len:955 episode reward: total was 16.360000. running mean: -25.372490\n",
      "ep 29: ep_len:226 episode reward: total was 22.500000. running mean: -24.893765\n",
      "ep 29: ep_len:500 episode reward: total was 27.750000. running mean: -24.367327\n",
      "ep 29: ep_len:500 episode reward: total was 12.260000. running mean: -24.001054\n",
      "ep 29: ep_len:1035 episode reward: total was 4.420000. running mean: -23.716843\n",
      "ep 29: ep_len:910 episode reward: total was -2.100000. running mean: -23.500675\n",
      "ep 29: ep_len:785 episode reward: total was 13.310000. running mean: -23.132568\n",
      "ep 29: ep_len:500 episode reward: total was 33.260000. running mean: -22.568642\n",
      "ep 29: ep_len:500 episode reward: total was 33.690000. running mean: -22.006056\n",
      "ep 29: ep_len:500 episode reward: total was 9.040000. running mean: -21.695595\n",
      "ep 29: ep_len:500 episode reward: total was 31.670000. running mean: -21.161939\n",
      "ep 29: ep_len:500 episode reward: total was 12.100000. running mean: -20.829320\n",
      "ep 29: ep_len:805 episode reward: total was -6.520000. running mean: -20.686227\n",
      "ep 29: ep_len:585 episode reward: total was -23.610000. running mean: -20.715465\n",
      "ep 29: ep_len:750 episode reward: total was -3.600000. running mean: -20.544310\n",
      "ep 29: ep_len:620 episode reward: total was -8.910000. running mean: -20.427967\n",
      "ep 29: ep_len:540 episode reward: total was 6.910000. running mean: -20.154587\n",
      "ep 29: ep_len:500 episode reward: total was 13.020000. running mean: -19.822841\n",
      "ep 29: ep_len:500 episode reward: total was 50.000000. running mean: -19.124613\n",
      "ep 29: ep_len:1454 episode reward: total was -237.530000. running mean: -21.308667\n",
      "ep 29: ep_len:620 episode reward: total was -5.880000. running mean: -21.154380\n",
      "ep 29: ep_len:550 episode reward: total was -25.210000. running mean: -21.194936\n",
      "ep 29: ep_len:500 episode reward: total was -35.190000. running mean: -21.334887\n",
      "ep 29: ep_len:249 episode reward: total was 24.500000. running mean: -20.876538\n",
      "ep 29: ep_len:510 episode reward: total was 2.190000. running mean: -20.645873\n",
      "ep 29: ep_len:500 episode reward: total was 0.660000. running mean: -20.432814\n",
      "ep 29: ep_len:1290 episode reward: total was -141.900000. running mean: -21.647486\n",
      "ep 29: ep_len:500 episode reward: total was 17.770000. running mean: -21.253311\n",
      "ep 29: ep_len:555 episode reward: total was -21.160000. running mean: -21.252378\n",
      "ep 29: ep_len:500 episode reward: total was 22.270000. running mean: -20.817154\n",
      "ep 29: ep_len:1190 episode reward: total was 12.880000. running mean: -20.480183\n",
      "ep 29: ep_len:500 episode reward: total was 8.250000. running mean: -20.192881\n",
      "ep 29: ep_len:700 episode reward: total was -6.210000. running mean: -20.053052\n",
      "ep 29: ep_len:500 episode reward: total was 20.770000. running mean: -19.644821\n",
      "ep 29: ep_len:795 episode reward: total was 5.850000. running mean: -19.389873\n",
      "ep 29: ep_len:500 episode reward: total was 14.780000. running mean: -19.048174\n",
      "ep 29: ep_len:148 episode reward: total was 13.000000. running mean: -18.727693\n",
      "ep 29: ep_len:910 episode reward: total was -15.400000. running mean: -18.694416\n",
      "ep 29: ep_len:750 episode reward: total was -9.660000. running mean: -18.604072\n",
      "ep 29: ep_len:505 episode reward: total was 23.440000. running mean: -18.183631\n",
      "ep 29: ep_len:755 episode reward: total was -2.580000. running mean: -18.027595\n",
      "ep 29: ep_len:500 episode reward: total was -3.390000. running mean: -17.881219\n",
      "ep 29: ep_len:500 episode reward: total was 24.810000. running mean: -17.454306\n",
      "ep 29: ep_len:640 episode reward: total was 8.710000. running mean: -17.192663\n",
      "ep 29: ep_len:500 episode reward: total was -0.420000. running mean: -17.024937\n",
      "ep 29: ep_len:945 episode reward: total was -29.470000. running mean: -17.149387\n",
      "ep 29: ep_len:730 episode reward: total was -9.700000. running mean: -17.074893\n",
      "ep 29: ep_len:605 episode reward: total was 6.340000. running mean: -16.840745\n",
      "ep 29: ep_len:850 episode reward: total was -4.050000. running mean: -16.712837\n",
      "ep 29: ep_len:243 episode reward: total was 24.000000. running mean: -16.305709\n",
      "ep 29: ep_len:525 episode reward: total was -2.030000. running mean: -16.162952\n",
      "ep 29: ep_len:500 episode reward: total was 15.350000. running mean: -15.847822\n",
      "ep 29: ep_len:625 episode reward: total was -39.200000. running mean: -16.081344\n",
      "ep 29: ep_len:500 episode reward: total was 21.780000. running mean: -15.702730\n",
      "ep 29: ep_len:500 episode reward: total was 47.000000. running mean: -15.075703\n",
      "ep 29: ep_len:500 episode reward: total was -5.680000. running mean: -14.981746\n",
      "ep 29: ep_len:680 episode reward: total was -18.890000. running mean: -15.020829\n",
      "ep 29: ep_len:2865 episode reward: total was -303.690000. running mean: -17.907520\n",
      "ep 29: ep_len:895 episode reward: total was 11.470000. running mean: -17.613745\n",
      "ep 29: ep_len:500 episode reward: total was 10.250000. running mean: -17.335108\n",
      "ep 29: ep_len:500 episode reward: total was 24.780000. running mean: -16.913957\n",
      "ep 29: ep_len:500 episode reward: total was 2.330000. running mean: -16.721517\n",
      "ep 29: ep_len:905 episode reward: total was -1.200000. running mean: -16.566302\n",
      "ep 29: ep_len:620 episode reward: total was -2.480000. running mean: -16.425439\n",
      "ep 29: ep_len:160 episode reward: total was 15.000000. running mean: -16.111185\n",
      "ep 29: ep_len:500 episode reward: total was 24.790000. running mean: -15.702173\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 29: ep_len:500 episode reward: total was 14.280000. running mean: -15.402351\n",
      "ep 29: ep_len:500 episode reward: total was 18.780000. running mean: -15.060527\n",
      "ep 29: ep_len:1315 episode reward: total was -56.490000. running mean: -15.474822\n",
      "ep 29: ep_len:500 episode reward: total was 19.790000. running mean: -15.122174\n",
      "ep 29: ep_len:500 episode reward: total was 15.350000. running mean: -14.817452\n",
      "ep 29: ep_len:595 episode reward: total was -53.330000. running mean: -15.202578\n",
      "ep 29: ep_len:500 episode reward: total was 12.320000. running mean: -14.927352\n",
      "ep 29: ep_len:500 episode reward: total was 48.500000. running mean: -14.293078\n",
      "ep 29: ep_len:500 episode reward: total was 32.280000. running mean: -13.827348\n",
      "ep 29: ep_len:695 episode reward: total was -7.750000. running mean: -13.766574\n",
      "ep 29: ep_len:820 episode reward: total was -4.490000. running mean: -13.673808\n",
      "ep 29: ep_len:1310 episode reward: total was -153.220000. running mean: -15.069270\n",
      "ep 29: ep_len:950 episode reward: total was 18.190000. running mean: -14.736678\n",
      "ep 29: ep_len:290 episode reward: total was 26.000000. running mean: -14.329311\n",
      "ep 29: ep_len:500 episode reward: total was 15.320000. running mean: -14.032818\n",
      "ep 29: ep_len:227 episode reward: total was 22.500000. running mean: -13.667490\n",
      "ep 29: ep_len:670 episode reward: total was -9.820000. running mean: -13.629015\n",
      "ep 29: ep_len:324 episode reward: total was 30.500000. running mean: -13.187724\n",
      "ep 29: ep_len:213 episode reward: total was 19.500000. running mean: -12.860847\n",
      "ep 29: ep_len:500 episode reward: total was -4.680000. running mean: -12.779039\n",
      "ep 29: ep_len:510 episode reward: total was -6.100000. running mean: -12.712248\n",
      "ep 29: ep_len:500 episode reward: total was 16.390000. running mean: -12.421226\n",
      "ep 29: ep_len:980 episode reward: total was 11.390000. running mean: -12.183114\n",
      "ep 29: ep_len:500 episode reward: total was 49.000000. running mean: -11.571283\n",
      "ep 29: ep_len:500 episode reward: total was 15.840000. running mean: -11.297170\n",
      "ep 29: ep_len:665 episode reward: total was -5.790000. running mean: -11.242098\n",
      "ep 29: ep_len:500 episode reward: total was 30.290000. running mean: -10.826777\n",
      "ep 29: ep_len:500 episode reward: total was 50.000000. running mean: -10.218509\n",
      "ep 29: ep_len:520 episode reward: total was -10.120000. running mean: -10.217524\n",
      "ep 29: ep_len:378 episode reward: total was -0.970000. running mean: -10.125049\n",
      "ep 29: ep_len:660 episode reward: total was -5.800000. running mean: -10.081798\n",
      "ep 29: ep_len:242 episode reward: total was 23.000000. running mean: -9.750980\n",
      "ep 29: ep_len:500 episode reward: total was -0.270000. running mean: -9.656171\n",
      "ep 29: ep_len:6385 episode reward: total was -1130.730000. running mean: -20.866909\n",
      "ep 29: ep_len:740 episode reward: total was -5.640000. running mean: -20.714640\n",
      "ep 29: ep_len:500 episode reward: total was 9.320000. running mean: -20.414293\n",
      "ep 29: ep_len:500 episode reward: total was 27.810000. running mean: -19.932050\n",
      "ep 29: ep_len:500 episode reward: total was 18.320000. running mean: -19.549530\n",
      "ep 29: ep_len:500 episode reward: total was 7.230000. running mean: -19.281735\n",
      "ep 29: ep_len:525 episode reward: total was 16.350000. running mean: -18.925417\n",
      "ep 29: ep_len:825 episode reward: total was 33.270000. running mean: -18.403463\n",
      "ep 29: ep_len:500 episode reward: total was -0.240000. running mean: -18.221829\n",
      "ep 29: ep_len:580 episode reward: total was -14.040000. running mean: -18.180010\n",
      "ep 29: ep_len:2165 episode reward: total was -322.960000. running mean: -21.227810\n",
      "ep 29: ep_len:545 episode reward: total was -56.180000. running mean: -21.577332\n",
      "ep 29: ep_len:960 episode reward: total was 3.580000. running mean: -21.325759\n",
      "ep 29: ep_len:458 episode reward: total was 24.750000. running mean: -20.865001\n",
      "ep 29: ep_len:1110 episode reward: total was -76.610000. running mean: -21.422451\n",
      "ep 29: ep_len:500 episode reward: total was 30.810000. running mean: -20.900127\n",
      "ep 29: ep_len:500 episode reward: total was 4.790000. running mean: -20.643225\n",
      "ep 29: ep_len:952 episode reward: total was -105.190000. running mean: -21.488693\n",
      "ep 29: ep_len:414 episode reward: total was 9.780000. running mean: -21.176006\n",
      "ep 29: ep_len:500 episode reward: total was 29.840000. running mean: -20.665846\n",
      "ep 29: ep_len:500 episode reward: total was 28.330000. running mean: -20.175888\n",
      "ep 29: ep_len:862 episode reward: total was -97.290000. running mean: -20.947029\n",
      "ep 29: ep_len:620 episode reward: total was -5.880000. running mean: -20.796358\n",
      "ep 29: ep_len:500 episode reward: total was 8.790000. running mean: -20.500495\n",
      "ep 29: ep_len:515 episode reward: total was 1.350000. running mean: -20.281990\n",
      "ep 29: ep_len:46 episode reward: total was 4.500000. running mean: -20.034170\n",
      "ep 29: ep_len:500 episode reward: total was 26.860000. running mean: -19.565228\n",
      "ep 29: ep_len:500 episode reward: total was 25.770000. running mean: -19.111876\n",
      "ep 29: ep_len:500 episode reward: total was 14.580000. running mean: -18.774957\n",
      "ep 29: ep_len:920 episode reward: total was -38.610000. running mean: -18.973308\n",
      "ep 29: ep_len:1195 episode reward: total was -75.430000. running mean: -19.537875\n",
      "ep 29: ep_len:810 episode reward: total was -9.210000. running mean: -19.434596\n",
      "ep 29: ep_len:840 episode reward: total was -16.480000. running mean: -19.405050\n",
      "ep 29: ep_len:830 episode reward: total was -26.240000. running mean: -19.473399\n",
      "ep 29: ep_len:590 episode reward: total was -5.540000. running mean: -19.334065\n",
      "ep 29: ep_len:510 episode reward: total was -23.270000. running mean: -19.373425\n",
      "ep 29: ep_len:510 episode reward: total was -94.980000. running mean: -20.129491\n",
      "ep 29: ep_len:150 episode reward: total was 13.500000. running mean: -19.793196\n",
      "ep 29: ep_len:500 episode reward: total was 20.340000. running mean: -19.391864\n",
      "ep 29: ep_len:505 episode reward: total was 7.070000. running mean: -19.127245\n",
      "ep 29: ep_len:416 episode reward: total was 22.280000. running mean: -18.713173\n",
      "ep 29: ep_len:1105 episode reward: total was 6.680000. running mean: -18.459241\n",
      "ep 29: ep_len:500 episode reward: total was -18.300000. running mean: -18.457648\n",
      "ep 29: ep_len:500 episode reward: total was -1.130000. running mean: -18.284372\n",
      "ep 29: ep_len:690 episode reward: total was 11.380000. running mean: -17.987728\n",
      "ep 29: ep_len:710 episode reward: total was -13.780000. running mean: -17.945651\n",
      "ep 29: ep_len:1434 episode reward: total was -90.250000. running mean: -18.668694\n",
      "ep 29: ep_len:630 episode reward: total was -26.060000. running mean: -18.742608\n",
      "ep 29: ep_len:650 episode reward: total was 27.650000. running mean: -18.278681\n",
      "ep 29: ep_len:500 episode reward: total was -10.860000. running mean: -18.204495\n",
      "ep 29: ep_len:750 episode reward: total was -9.660000. running mean: -18.119050\n",
      "ep 29: ep_len:144 episode reward: total was 12.500000. running mean: -17.812859\n",
      "ep 29: ep_len:730 episode reward: total was -14.190000. running mean: -17.776631\n",
      "ep 29: ep_len:750 episode reward: total was -4.610000. running mean: -17.644964\n",
      "ep 29: ep_len:500 episode reward: total was 36.750000. running mean: -17.101015\n",
      "ep 29: ep_len:240 episode reward: total was 22.500000. running mean: -16.705005\n",
      "ep 29: ep_len:915 episode reward: total was 7.700000. running mean: -16.460954\n",
      "ep 29: ep_len:500 episode reward: total was 24.970000. running mean: -16.046645\n",
      "ep 29: ep_len:805 episode reward: total was -93.890000. running mean: -16.825078\n",
      "ep 29: ep_len:500 episode reward: total was -3.150000. running mean: -16.688328\n",
      "ep 29: ep_len:530 episode reward: total was -4.620000. running mean: -16.567644\n",
      "ep 29: ep_len:505 episode reward: total was -10.670000. running mean: -16.508668\n",
      "ep 29: ep_len:214 episode reward: total was 21.000000. running mean: -16.133581\n",
      "ep 29: ep_len:500 episode reward: total was 35.280000. running mean: -15.619445\n",
      "ep 29: ep_len:420 episode reward: total was 18.290000. running mean: -15.280351\n",
      "ep 29: ep_len:620 episode reward: total was -49.180000. running mean: -15.619348\n",
      "ep 29: ep_len:158 episode reward: total was 15.500000. running mean: -15.308154\n",
      "ep 29: ep_len:510 episode reward: total was -20.240000. running mean: -15.357472\n",
      "ep 29: ep_len:500 episode reward: total was 24.320000. running mean: -14.960698\n",
      "ep 29: ep_len:500 episode reward: total was 23.860000. running mean: -14.572491\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 29: ep_len:500 episode reward: total was 12.560000. running mean: -14.301166\n",
      "ep 29: ep_len:2710 episode reward: total was -440.000000. running mean: -18.558154\n",
      "ep 29: ep_len:885 episode reward: total was 11.080000. running mean: -18.261773\n",
      "ep 29: ep_len:5422 episode reward: total was -844.330000. running mean: -26.522455\n",
      "ep 29: ep_len:1073 episode reward: total was -44.920000. running mean: -26.706430\n",
      "ep 29: ep_len:500 episode reward: total was -15.780000. running mean: -26.597166\n",
      "ep 29: ep_len:500 episode reward: total was 11.120000. running mean: -26.219994\n",
      "ep 29: ep_len:1405 episode reward: total was -193.150000. running mean: -27.889294\n",
      "ep 29: ep_len:500 episode reward: total was 50.000000. running mean: -27.110402\n",
      "ep 29: ep_len:500 episode reward: total was 9.620000. running mean: -26.743098\n",
      "ep 29: ep_len:221 episode reward: total was -9.500000. running mean: -26.570667\n",
      "epsilon:0.010000 episode_count: 23641. steps_count: 17154349.000000\n",
      "ep 30: ep_len:500 episode reward: total was 28.310000. running mean: -26.021860\n",
      "ep 30: ep_len:835 episode reward: total was -27.150000. running mean: -26.033141\n",
      "ep 30: ep_len:520 episode reward: total was 5.040000. running mean: -25.722410\n",
      "ep 30: ep_len:2566 episode reward: total was -453.930000. running mean: -30.004486\n",
      "ep 30: ep_len:500 episode reward: total was 17.230000. running mean: -29.532141\n",
      "ep 30: ep_len:980 episode reward: total was -52.630000. running mean: -29.763120\n",
      "ep 30: ep_len:725 episode reward: total was -20.820000. running mean: -29.673688\n",
      "ep 30: ep_len:550 episode reward: total was 19.260000. running mean: -29.184351\n",
      "ep 30: ep_len:468 episode reward: total was 43.500000. running mean: -28.457508\n",
      "ep 30: ep_len:500 episode reward: total was 32.220000. running mean: -27.850733\n",
      "ep 30: ep_len:500 episode reward: total was 15.220000. running mean: -27.420026\n",
      "ep 30: ep_len:500 episode reward: total was 6.260000. running mean: -27.083225\n",
      "ep 30: ep_len:500 episode reward: total was 19.790000. running mean: -26.614493\n",
      "ep 30: ep_len:263 episode reward: total was 0.500000. running mean: -26.343348\n",
      "ep 30: ep_len:875 episode reward: total was -23.550000. running mean: -26.315415\n",
      "ep 30: ep_len:830 episode reward: total was -32.730000. running mean: -26.379560\n",
      "ep 30: ep_len:500 episode reward: total was 33.780000. running mean: -25.777965\n",
      "ep 30: ep_len:600 episode reward: total was -16.610000. running mean: -25.686285\n",
      "ep 30: ep_len:665 episode reward: total was -131.500000. running mean: -26.744422\n",
      "ep 30: ep_len:660 episode reward: total was -1.480000. running mean: -26.491778\n",
      "ep 30: ep_len:685 episode reward: total was 16.800000. running mean: -26.058860\n",
      "ep 30: ep_len:1505 episode reward: total was -82.890000. running mean: -26.627172\n",
      "ep 30: ep_len:1185 episode reward: total was -42.570000. running mean: -26.786600\n",
      "ep 30: ep_len:1450 episode reward: total was -107.240000. running mean: -27.591134\n",
      "ep 30: ep_len:478 episode reward: total was 26.320000. running mean: -27.052023\n",
      "ep 30: ep_len:570 episode reward: total was -20.120000. running mean: -26.982702\n",
      "ep 30: ep_len:500 episode reward: total was 26.770000. running mean: -26.445175\n",
      "ep 30: ep_len:16230 episode reward: total was -2978.810000. running mean: -55.968824\n",
      "ep 30: ep_len:990 episode reward: total was -111.020000. running mean: -56.519335\n",
      "ep 30: ep_len:500 episode reward: total was 25.790000. running mean: -55.696242\n",
      "ep 30: ep_len:575 episode reward: total was 12.200000. running mean: -55.017280\n",
      "ep 30: ep_len:500 episode reward: total was 27.230000. running mean: -54.194807\n",
      "ep 30: ep_len:830 episode reward: total was 14.060000. running mean: -53.512259\n",
      "ep 30: ep_len:890 episode reward: total was -120.900000. running mean: -54.186136\n",
      "ep 30: ep_len:500 episode reward: total was 24.240000. running mean: -53.401875\n",
      "ep 30: ep_len:860 episode reward: total was 8.980000. running mean: -52.778056\n",
      "ep 30: ep_len:595 episode reward: total was -22.580000. running mean: -52.476076\n",
      "ep 30: ep_len:500 episode reward: total was 6.250000. running mean: -51.888815\n",
      "ep 30: ep_len:825 episode reward: total was -32.720000. running mean: -51.697127\n",
      "ep 30: ep_len:500 episode reward: total was -32.490000. running mean: -51.505055\n",
      "ep 30: ep_len:525 episode reward: total was -9.070000. running mean: -51.080705\n",
      "ep 30: ep_len:970 episode reward: total was 6.600000. running mean: -50.503898\n",
      "ep 30: ep_len:585 episode reward: total was -34.230000. running mean: -50.341159\n",
      "ep 30: ep_len:540 episode reward: total was 5.240000. running mean: -49.785347\n",
      "ep 30: ep_len:133 episode reward: total was 13.500000. running mean: -49.152494\n",
      "ep 30: ep_len:500 episode reward: total was 5.290000. running mean: -48.608069\n",
      "ep 30: ep_len:750 episode reward: total was -11.680000. running mean: -48.238788\n",
      "ep 30: ep_len:439 episode reward: total was 43.500000. running mean: -47.321400\n",
      "ep 30: ep_len:500 episode reward: total was 19.420000. running mean: -46.653986\n",
      "ep 30: ep_len:525 episode reward: total was -17.730000. running mean: -46.364746\n",
      "ep 30: ep_len:755 episode reward: total was 24.230000. running mean: -45.658799\n",
      "ep 30: ep_len:500 episode reward: total was 16.820000. running mean: -45.034011\n",
      "ep 30: ep_len:665 episode reward: total was -14.970000. running mean: -44.733371\n",
      "ep 30: ep_len:124 episode reward: total was 12.000000. running mean: -44.166037\n",
      "ep 30: ep_len:500 episode reward: total was 19.800000. running mean: -43.526377\n",
      "ep 30: ep_len:940 episode reward: total was -27.150000. running mean: -43.362613\n",
      "ep 30: ep_len:621 episode reward: total was -39.540000. running mean: -43.324387\n",
      "ep 30: ep_len:322 episode reward: total was 26.000000. running mean: -42.631143\n",
      "ep 30: ep_len:845 episode reward: total was -55.930000. running mean: -42.764132\n",
      "ep 30: ep_len:500 episode reward: total was -15.230000. running mean: -42.488790\n",
      "ep 30: ep_len:580 episode reward: total was -10.980000. running mean: -42.173702\n",
      "ep 30: ep_len:209 episode reward: total was 16.000000. running mean: -41.591965\n",
      "ep 30: ep_len:930 episode reward: total was 19.080000. running mean: -40.985246\n",
      "ep 30: ep_len:500 episode reward: total was -24.850000. running mean: -40.823893\n",
      "ep 30: ep_len:1225 episode reward: total was -115.610000. running mean: -41.571754\n",
      "ep 30: ep_len:725 episode reward: total was -8.480000. running mean: -41.240837\n",
      "ep 30: ep_len:970 episode reward: total was -2.510000. running mean: -40.853528\n",
      "ep 30: ep_len:635 episode reward: total was -13.930000. running mean: -40.584293\n",
      "ep 30: ep_len:765 episode reward: total was -9.230000. running mean: -40.270750\n",
      "ep 30: ep_len:500 episode reward: total was 25.330000. running mean: -39.614743\n",
      "ep 30: ep_len:805 episode reward: total was 14.570000. running mean: -39.072895\n",
      "ep 30: ep_len:500 episode reward: total was -58.810000. running mean: -39.270266\n",
      "ep 30: ep_len:500 episode reward: total was 7.850000. running mean: -38.799064\n",
      "ep 30: ep_len:520 episode reward: total was -27.290000. running mean: -38.683973\n",
      "ep 30: ep_len:920 episode reward: total was 17.730000. running mean: -38.119833\n",
      "ep 30: ep_len:1935 episode reward: total was -177.980000. running mean: -39.518435\n",
      "ep 30: ep_len:570 episode reward: total was 0.120000. running mean: -39.122051\n",
      "ep 30: ep_len:725 episode reward: total was -4.660000. running mean: -38.777430\n",
      "ep 30: ep_len:500 episode reward: total was 13.760000. running mean: -38.252056\n",
      "ep 30: ep_len:690 episode reward: total was -2.710000. running mean: -37.896635\n",
      "ep 30: ep_len:98 episode reward: total was 9.500000. running mean: -37.422669\n",
      "ep 30: ep_len:525 episode reward: total was 7.400000. running mean: -36.974442\n",
      "ep 30: ep_len:955 episode reward: total was -6.500000. running mean: -36.669698\n",
      "ep 30: ep_len:565 episode reward: total was -14.070000. running mean: -36.443701\n",
      "ep 30: ep_len:505 episode reward: total was 16.000000. running mean: -35.919264\n",
      "ep 30: ep_len:635 episode reward: total was 18.630000. running mean: -35.373771\n",
      "ep 30: ep_len:500 episode reward: total was 0.370000. running mean: -35.016333\n",
      "ep 30: ep_len:500 episode reward: total was 10.020000. running mean: -34.565970\n",
      "ep 30: ep_len:525 episode reward: total was -3.890000. running mean: -34.259210\n",
      "ep 30: ep_len:815 episode reward: total was -14.580000. running mean: -34.062418\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 30: ep_len:827 episode reward: total was -76.150000. running mean: -34.483294\n",
      "ep 30: ep_len:1525 episode reward: total was -152.170000. running mean: -35.660161\n",
      "ep 30: ep_len:500 episode reward: total was 8.220000. running mean: -35.221360\n",
      "ep 30: ep_len:500 episode reward: total was 30.320000. running mean: -34.565946\n",
      "ep 30: ep_len:500 episode reward: total was -26.320000. running mean: -34.483486\n",
      "ep 30: ep_len:1091 episode reward: total was -161.520000. running mean: -35.753852\n",
      "ep 30: ep_len:695 episode reward: total was -1.690000. running mean: -35.413213\n",
      "ep 30: ep_len:500 episode reward: total was 33.750000. running mean: -34.721581\n",
      "ep 30: ep_len:705 episode reward: total was -66.310000. running mean: -35.037465\n",
      "ep 30: ep_len:500 episode reward: total was 25.820000. running mean: -34.428890\n",
      "ep 30: ep_len:910 episode reward: total was -38.480000. running mean: -34.469402\n",
      "ep 30: ep_len:261 episode reward: total was 26.000000. running mean: -33.864708\n",
      "ep 30: ep_len:829 episode reward: total was -63.020000. running mean: -34.156260\n",
      "ep 30: ep_len:560 episode reward: total was -24.670000. running mean: -34.061398\n",
      "ep 30: ep_len:255 episode reward: total was 24.000000. running mean: -33.480784\n",
      "ep 30: ep_len:500 episode reward: total was 20.310000. running mean: -32.942876\n",
      "ep 30: ep_len:127 episode reward: total was 11.000000. running mean: -32.503447\n",
      "ep 30: ep_len:500 episode reward: total was 17.370000. running mean: -32.004713\n",
      "ep 30: ep_len:500 episode reward: total was 20.370000. running mean: -31.480966\n",
      "ep 30: ep_len:805 episode reward: total was -11.570000. running mean: -31.281856\n",
      "ep 30: ep_len:500 episode reward: total was 31.820000. running mean: -30.650837\n",
      "ep 30: ep_len:500 episode reward: total was 23.720000. running mean: -30.107129\n",
      "ep 30: ep_len:895 episode reward: total was -42.700000. running mean: -30.233058\n",
      "ep 30: ep_len:500 episode reward: total was 6.100000. running mean: -29.869727\n",
      "ep 30: ep_len:775 episode reward: total was -21.620000. running mean: -29.787230\n",
      "ep 30: ep_len:950 episode reward: total was -59.740000. running mean: -30.086758\n",
      "ep 30: ep_len:500 episode reward: total was 12.680000. running mean: -29.659090\n",
      "ep 30: ep_len:855 episode reward: total was 24.210000. running mean: -29.120399\n",
      "ep 30: ep_len:880 episode reward: total was 2.680000. running mean: -28.802395\n",
      "ep 30: ep_len:700 episode reward: total was 5.190000. running mean: -28.462471\n",
      "ep 30: ep_len:940 episode reward: total was 14.730000. running mean: -28.030547\n",
      "ep 30: ep_len:500 episode reward: total was 50.000000. running mean: -27.250241\n",
      "ep 30: ep_len:500 episode reward: total was -4.150000. running mean: -27.019239\n",
      "ep 30: ep_len:950 episode reward: total was 6.910000. running mean: -26.679946\n",
      "ep 30: ep_len:96 episode reward: total was 8.000000. running mean: -26.333147\n",
      "ep 30: ep_len:500 episode reward: total was 22.730000. running mean: -25.842515\n",
      "ep 30: ep_len:875 episode reward: total was -29.700000. running mean: -25.881090\n",
      "ep 30: ep_len:570 episode reward: total was 10.870000. running mean: -25.513579\n",
      "ep 30: ep_len:245 episode reward: total was 21.500000. running mean: -25.043443\n",
      "ep 30: ep_len:2140 episode reward: total was -318.470000. running mean: -27.977709\n",
      "ep 30: ep_len:500 episode reward: total was 23.400000. running mean: -27.463932\n",
      "ep 30: ep_len:2165 episode reward: total was -128.640000. running mean: -28.475693\n",
      "ep 30: ep_len:2504 episode reward: total was -147.190000. running mean: -29.662836\n",
      "ep 30: ep_len:1195 episode reward: total was 10.440000. running mean: -29.261807\n",
      "ep 30: ep_len:500 episode reward: total was -5.840000. running mean: -29.027589\n",
      "ep 30: ep_len:500 episode reward: total was 25.850000. running mean: -28.478813\n",
      "ep 30: ep_len:500 episode reward: total was 47.000000. running mean: -27.724025\n",
      "ep 30: ep_len:500 episode reward: total was 29.740000. running mean: -27.149385\n",
      "ep 30: ep_len:500 episode reward: total was -2.140000. running mean: -26.899291\n",
      "ep 30: ep_len:1665 episode reward: total was -35.220000. running mean: -26.982498\n",
      "ep 30: ep_len:500 episode reward: total was 29.800000. running mean: -26.414673\n",
      "ep 30: ep_len:500 episode reward: total was 33.810000. running mean: -25.812427\n",
      "ep 30: ep_len:635 episode reward: total was -10.900000. running mean: -25.663302\n",
      "ep 30: ep_len:620 episode reward: total was 23.150000. running mean: -25.175169\n",
      "ep 30: ep_len:650 episode reward: total was -1.780000. running mean: -24.941218\n",
      "ep 30: ep_len:570 episode reward: total was -16.230000. running mean: -24.854105\n",
      "ep 30: ep_len:500 episode reward: total was 28.270000. running mean: -24.322864\n",
      "ep 30: ep_len:955 episode reward: total was 8.030000. running mean: -23.999336\n",
      "ep 30: ep_len:500 episode reward: total was -30.880000. running mean: -24.068142\n",
      "ep 30: ep_len:980 episode reward: total was 21.800000. running mean: -23.609461\n",
      "ep 30: ep_len:500 episode reward: total was 15.500000. running mean: -23.218366\n",
      "ep 30: ep_len:925 episode reward: total was 19.760000. running mean: -22.788583\n",
      "ep 30: ep_len:755 episode reward: total was 10.800000. running mean: -22.452697\n",
      "ep 30: ep_len:865 episode reward: total was 20.070000. running mean: -22.027470\n",
      "ep 30: ep_len:725 episode reward: total was -2.640000. running mean: -21.833595\n",
      "ep 30: ep_len:316 episode reward: total was 16.260000. running mean: -21.452659\n",
      "ep 30: ep_len:500 episode reward: total was 20.310000. running mean: -21.035033\n",
      "ep 30: ep_len:500 episode reward: total was 27.290000. running mean: -20.551782\n",
      "ep 30: ep_len:500 episode reward: total was 6.260000. running mean: -20.283664\n",
      "ep 30: ep_len:2470 episode reward: total was -157.560000. running mean: -21.656428\n",
      "ep 30: ep_len:685 episode reward: total was -7.770000. running mean: -21.517564\n",
      "ep 30: ep_len:575 episode reward: total was -27.180000. running mean: -21.574188\n",
      "ep 30: ep_len:500 episode reward: total was 37.270000. running mean: -20.985746\n",
      "ep 30: ep_len:500 episode reward: total was 3.010000. running mean: -20.745789\n",
      "ep 30: ep_len:640 episode reward: total was 0.220000. running mean: -20.536131\n",
      "ep 30: ep_len:920 episode reward: total was 18.180000. running mean: -20.148969\n",
      "ep 30: ep_len:545 episode reward: total was -22.190000. running mean: -20.169380\n",
      "ep 30: ep_len:500 episode reward: total was 6.590000. running mean: -19.901786\n",
      "ep 30: ep_len:500 episode reward: total was 2.830000. running mean: -19.674468\n",
      "ep 30: ep_len:685 episode reward: total was -2.720000. running mean: -19.504923\n",
      "ep 30: ep_len:166 episode reward: total was 16.500000. running mean: -19.144874\n",
      "ep 30: ep_len:2490 episode reward: total was -234.440000. running mean: -21.297825\n",
      "ep 30: ep_len:675 episode reward: total was -8.800000. running mean: -21.172847\n",
      "ep 30: ep_len:126 episode reward: total was 11.500000. running mean: -20.846119\n",
      "ep 30: ep_len:500 episode reward: total was 5.310000. running mean: -20.584557\n",
      "ep 30: ep_len:865 episode reward: total was 25.610000. running mean: -20.122612\n",
      "ep 30: ep_len:555 episode reward: total was 27.400000. running mean: -19.647386\n",
      "ep 30: ep_len:765 episode reward: total was -9.630000. running mean: -19.547212\n",
      "ep 30: ep_len:500 episode reward: total was -2.650000. running mean: -19.378240\n",
      "ep 30: ep_len:500 episode reward: total was 48.500000. running mean: -18.699457\n",
      "ep 30: ep_len:500 episode reward: total was -63.500000. running mean: -19.147463\n",
      "ep 30: ep_len:500 episode reward: total was -2.230000. running mean: -18.978288\n",
      "ep 30: ep_len:500 episode reward: total was 50.000000. running mean: -18.288505\n",
      "ep 30: ep_len:500 episode reward: total was 28.300000. running mean: -17.822620\n",
      "ep 30: ep_len:575 episode reward: total was 1.900000. running mean: -17.625394\n",
      "ep 30: ep_len:500 episode reward: total was -0.180000. running mean: -17.450940\n",
      "ep 30: ep_len:580 episode reward: total was -23.130000. running mean: -17.507731\n",
      "ep 30: ep_len:655 episode reward: total was -6.820000. running mean: -17.400853\n",
      "ep 30: ep_len:183 episode reward: total was 18.000000. running mean: -17.046845\n",
      "ep 30: ep_len:810 episode reward: total was -4.490000. running mean: -16.921276\n",
      "ep 30: ep_len:214 episode reward: total was 19.500000. running mean: -16.557064\n",
      "ep 30: ep_len:500 episode reward: total was 11.830000. running mean: -16.273193\n",
      "ep 30: ep_len:525 episode reward: total was 18.550000. running mean: -15.924961\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 30: ep_len:396 episode reward: total was 38.000000. running mean: -15.385711\n",
      "ep 30: ep_len:500 episode reward: total was 26.280000. running mean: -14.969054\n",
      "ep 30: ep_len:585 episode reward: total was -31.170000. running mean: -15.131064\n",
      "ep 30: ep_len:700 episode reward: total was -5.720000. running mean: -15.036953\n",
      "ep 30: ep_len:1010 episode reward: total was 20.690000. running mean: -14.679684\n",
      "ep 30: ep_len:690 episode reward: total was -9.750000. running mean: -14.630387\n",
      "ep 30: ep_len:237 episode reward: total was 16.000000. running mean: -14.324083\n",
      "ep 30: ep_len:675 episode reward: total was -13.850000. running mean: -14.319342\n",
      "ep 30: ep_len:610 episode reward: total was -2.870000. running mean: -14.204849\n",
      "ep 30: ep_len:500 episode reward: total was -8.140000. running mean: -14.144200\n",
      "ep 30: ep_len:565 episode reward: total was 15.170000. running mean: -13.851058\n",
      "ep 30: ep_len:500 episode reward: total was 6.620000. running mean: -13.646348\n",
      "ep 30: ep_len:500 episode reward: total was 19.790000. running mean: -13.311984\n",
      "ep 30: ep_len:500 episode reward: total was 6.280000. running mean: -13.116064\n",
      "ep 30: ep_len:500 episode reward: total was 13.140000. running mean: -12.853504\n",
      "ep 30: ep_len:820 episode reward: total was 10.000000. running mean: -12.624969\n",
      "ep 30: ep_len:800 episode reward: total was -40.180000. running mean: -12.900519\n",
      "ep 30: ep_len:118 episode reward: total was 11.500000. running mean: -12.656514\n",
      "ep 30: ep_len:500 episode reward: total was 15.650000. running mean: -12.373449\n",
      "ep 30: ep_len:279 episode reward: total was 27.500000. running mean: -11.974714\n",
      "ep 30: ep_len:655 episode reward: total was -4.800000. running mean: -11.902967\n",
      "ep 30: ep_len:500 episode reward: total was 17.920000. running mean: -11.604737\n",
      "ep 30: ep_len:660 episode reward: total was 25.010000. running mean: -11.238590\n",
      "ep 30: ep_len:500 episode reward: total was 16.820000. running mean: -10.958004\n",
      "ep 30: ep_len:510 episode reward: total was -4.230000. running mean: -10.890724\n",
      "ep 30: ep_len:500 episode reward: total was 19.850000. running mean: -10.583317\n",
      "ep 30: ep_len:500 episode reward: total was -0.020000. running mean: -10.477684\n",
      "ep 30: ep_len:1015 episode reward: total was 18.310000. running mean: -10.189807\n",
      "ep 30: ep_len:525 episode reward: total was 23.480000. running mean: -9.853109\n",
      "ep 30: ep_len:670 episode reward: total was -15.880000. running mean: -9.913378\n",
      "ep 30: ep_len:805 episode reward: total was -45.910000. running mean: -10.273344\n",
      "ep 30: ep_len:393 episode reward: total was 19.840000. running mean: -9.972210\n",
      "ep 30: ep_len:620 episode reward: total was 16.290000. running mean: -9.709588\n",
      "ep 30: ep_len:500 episode reward: total was 7.290000. running mean: -9.539592\n",
      "ep 30: ep_len:535 episode reward: total was 5.800000. running mean: -9.386196\n",
      "ep 30: ep_len:500 episode reward: total was 2.330000. running mean: -9.269035\n",
      "ep 30: ep_len:850 episode reward: total was 21.030000. running mean: -8.966044\n",
      "ep 30: ep_len:500 episode reward: total was 27.410000. running mean: -8.602284\n",
      "ep 30: ep_len:620 episode reward: total was -0.240000. running mean: -8.518661\n",
      "ep 30: ep_len:665 episode reward: total was -128.000000. running mean: -9.713474\n",
      "ep 30: ep_len:605 episode reward: total was -48.330000. running mean: -10.099640\n",
      "ep 30: ep_len:500 episode reward: total was -8.320000. running mean: -10.081843\n",
      "ep 30: ep_len:510 episode reward: total was -9.130000. running mean: -10.072325\n",
      "ep 30: ep_len:500 episode reward: total was 16.080000. running mean: -9.810801\n",
      "ep 30: ep_len:494 episode reward: total was 32.230000. running mean: -9.390393\n",
      "ep 30: ep_len:765 episode reward: total was -5.590000. running mean: -9.352390\n",
      "ep 30: ep_len:660 episode reward: total was -18.930000. running mean: -9.448166\n",
      "ep 30: ep_len:500 episode reward: total was 15.160000. running mean: -9.202084\n",
      "ep 30: ep_len:500 episode reward: total was 2.800000. running mean: -9.082063\n",
      "ep 30: ep_len:735 episode reward: total was -13.210000. running mean: -9.123342\n",
      "ep 30: ep_len:500 episode reward: total was 11.460000. running mean: -8.917509\n",
      "ep 30: ep_len:133 episode reward: total was 12.000000. running mean: -8.708334\n",
      "ep 30: ep_len:570 episode reward: total was 27.370000. running mean: -8.347551\n",
      "ep 30: ep_len:615 episode reward: total was -9.900000. running mean: -8.363075\n",
      "ep 30: ep_len:605 episode reward: total was -20.500000. running mean: -8.484444\n",
      "ep 30: ep_len:337 episode reward: total was -3.500000. running mean: -8.434600\n",
      "ep 30: ep_len:495 episode reward: total was 27.280000. running mean: -8.077454\n",
      "ep 30: ep_len:600 episode reward: total was -22.080000. running mean: -8.217479\n",
      "ep 30: ep_len:500 episode reward: total was 1.720000. running mean: -8.118105\n",
      "ep 30: ep_len:500 episode reward: total was -84.500000. running mean: -8.881924\n",
      "ep 30: ep_len:1065 episode reward: total was -29.070000. running mean: -9.083804\n",
      "ep 30: ep_len:565 episode reward: total was 0.070000. running mean: -8.992266\n",
      "ep 30: ep_len:510 episode reward: total was -44.480000. running mean: -9.347144\n",
      "ep 30: ep_len:520 episode reward: total was 19.520000. running mean: -9.058472\n",
      "ep 30: ep_len:224 episode reward: total was 22.000000. running mean: -8.747887\n",
      "ep 30: ep_len:705 episode reward: total was 24.420000. running mean: -8.416209\n",
      "ep 30: ep_len:500 episode reward: total was 16.850000. running mean: -8.163546\n",
      "ep 30: ep_len:251 episode reward: total was 25.000000. running mean: -7.831911\n",
      "ep 30: ep_len:500 episode reward: total was 14.520000. running mean: -7.608392\n",
      "ep 30: ep_len:1070 episode reward: total was 8.750000. running mean: -7.444808\n",
      "ep 30: ep_len:500 episode reward: total was 29.860000. running mean: -7.071760\n",
      "ep 30: ep_len:228 episode reward: total was 21.000000. running mean: -6.791042\n",
      "ep 30: ep_len:184 episode reward: total was 18.000000. running mean: -6.543132\n",
      "ep 30: ep_len:166 episode reward: total was 16.500000. running mean: -6.312701\n",
      "ep 30: ep_len:500 episode reward: total was 17.030000. running mean: -6.079274\n",
      "ep 30: ep_len:163 episode reward: total was 14.500000. running mean: -5.873481\n",
      "ep 30: ep_len:620 episode reward: total was -2.850000. running mean: -5.843246\n",
      "ep 30: ep_len:500 episode reward: total was 30.810000. running mean: -5.476714\n",
      "ep 30: ep_len:500 episode reward: total was 4.830000. running mean: -5.373646\n",
      "ep 30: ep_len:645 episode reward: total was -8.860000. running mean: -5.408510\n",
      "ep 30: ep_len:500 episode reward: total was 50.000000. running mean: -4.854425\n",
      "ep 30: ep_len:650 episode reward: total was 20.270000. running mean: -4.603181\n",
      "ep 30: ep_len:313 episode reward: total was 31.000000. running mean: -4.247149\n",
      "ep 30: ep_len:500 episode reward: total was 24.270000. running mean: -3.961977\n",
      "ep 30: ep_len:620 episode reward: total was -0.340000. running mean: -3.925758\n",
      "ep 30: ep_len:520 episode reward: total was -16.260000. running mean: -4.049100\n",
      "ep 30: ep_len:1035 episode reward: total was 8.290000. running mean: -3.925709\n",
      "ep 30: ep_len:2933 episode reward: total was -506.210000. running mean: -8.948552\n",
      "ep 30: ep_len:500 episode reward: total was 48.500000. running mean: -8.374066\n",
      "ep 30: ep_len:855 episode reward: total was 18.610000. running mean: -8.104226\n",
      "ep 30: ep_len:515 episode reward: total was -1.530000. running mean: -8.038483\n",
      "ep 30: ep_len:500 episode reward: total was 8.830000. running mean: -7.869799\n",
      "ep 30: ep_len:234 episode reward: total was 13.000000. running mean: -7.661101\n",
      "ep 30: ep_len:250 episode reward: total was 24.000000. running mean: -7.344490\n",
      "ep 30: ep_len:174 episode reward: total was 17.000000. running mean: -7.101045\n",
      "ep 30: ep_len:745 episode reward: total was 4.570000. running mean: -6.984334\n",
      "ep 30: ep_len:390 episode reward: total was 36.000000. running mean: -6.554491\n",
      "ep 30: ep_len:1258 episode reward: total was -195.010000. running mean: -8.439046\n",
      "ep 30: ep_len:500 episode reward: total was 3.470000. running mean: -8.319956\n",
      "ep 30: ep_len:505 episode reward: total was 25.340000. running mean: -7.983356\n",
      "ep 30: ep_len:1055 episode reward: total was -37.650000. running mean: -8.280022\n",
      "ep 30: ep_len:1475 episode reward: total was -166.780000. running mean: -9.865022\n",
      "ep 30: ep_len:705 episode reward: total was -5.710000. running mean: -9.823472\n",
      "ep 30: ep_len:500 episode reward: total was 50.000000. running mean: -9.225237\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 30: ep_len:770 episode reward: total was -25.780000. running mean: -9.390785\n",
      "ep 30: ep_len:500 episode reward: total was 3.710000. running mean: -9.259777\n",
      "ep 30: ep_len:590 episode reward: total was -1.900000. running mean: -9.186179\n",
      "ep 30: ep_len:715 episode reward: total was 0.370000. running mean: -9.090617\n",
      "ep 30: ep_len:1120 episode reward: total was -37.860000. running mean: -9.378311\n",
      "ep 30: ep_len:505 episode reward: total was -7.120000. running mean: -9.355728\n",
      "ep 30: ep_len:500 episode reward: total was -20.320000. running mean: -9.465371\n",
      "ep 30: ep_len:540 episode reward: total was 19.190000. running mean: -9.178817\n",
      "ep 30: ep_len:1683 episode reward: total was -316.810000. running mean: -12.255129\n",
      "ep 30: ep_len:695 episode reward: total was -33.000000. running mean: -12.462578\n",
      "ep 30: ep_len:500 episode reward: total was 22.300000. running mean: -12.114952\n",
      "ep 30: ep_len:500 episode reward: total was -19.250000. running mean: -12.186302\n",
      "ep 30: ep_len:690 episode reward: total was -17.580000. running mean: -12.240239\n",
      "ep 30: ep_len:276 episode reward: total was 28.000000. running mean: -11.837837\n",
      "ep 30: ep_len:388 episode reward: total was 31.500000. running mean: -11.404459\n",
      "ep 30: ep_len:830 episode reward: total was -63.030000. running mean: -11.920714\n",
      "ep 30: ep_len:865 episode reward: total was 18.880000. running mean: -11.612707\n",
      "ep 30: ep_len:206 episode reward: total was 19.000000. running mean: -11.306580\n",
      "ep 30: ep_len:585 episode reward: total was 16.250000. running mean: -11.031014\n",
      "ep 30: ep_len:500 episode reward: total was 14.740000. running mean: -10.773304\n",
      "ep 30: ep_len:500 episode reward: total was 18.930000. running mean: -10.476271\n",
      "ep 30: ep_len:265 episode reward: total was 25.000000. running mean: -10.121508\n",
      "ep 30: ep_len:500 episode reward: total was -8.140000. running mean: -10.101693\n",
      "ep 30: ep_len:210 episode reward: total was 19.500000. running mean: -9.805676\n",
      "ep 30: ep_len:585 episode reward: total was -30.190000. running mean: -10.009519\n",
      "ep 30: ep_len:500 episode reward: total was 26.290000. running mean: -9.646524\n",
      "ep 30: ep_len:820 episode reward: total was -23.660000. running mean: -9.786659\n",
      "ep 30: ep_len:730 episode reward: total was -22.830000. running mean: -9.917092\n",
      "ep 30: ep_len:630 episode reward: total was 9.250000. running mean: -9.725421\n",
      "ep 30: ep_len:500 episode reward: total was -6.120000. running mean: -9.689367\n",
      "ep 30: ep_len:810 episode reward: total was -31.760000. running mean: -9.910074\n",
      "ep 30: ep_len:840 episode reward: total was 6.240000. running mean: -9.748573\n",
      "ep 30: ep_len:500 episode reward: total was 34.270000. running mean: -9.308387\n",
      "ep 30: ep_len:925 episode reward: total was -3.260000. running mean: -9.247903\n",
      "ep 30: ep_len:1025 episode reward: total was -111.120000. running mean: -10.266624\n",
      "ep 30: ep_len:378 episode reward: total was 18.830000. running mean: -9.975658\n",
      "ep 30: ep_len:1010 episode reward: total was -21.990000. running mean: -10.095801\n",
      "ep 30: ep_len:500 episode reward: total was 12.230000. running mean: -9.872543\n",
      "ep 30: ep_len:815 episode reward: total was -5.510000. running mean: -9.828918\n",
      "ep 30: ep_len:282 episode reward: total was 26.500000. running mean: -9.465629\n",
      "ep 30: ep_len:880 episode reward: total was -1.600000. running mean: -9.386972\n",
      "ep 30: ep_len:500 episode reward: total was -10.800000. running mean: -9.401103\n",
      "ep 30: ep_len:790 episode reward: total was -8.690000. running mean: -9.393992\n",
      "ep 30: ep_len:500 episode reward: total was 22.250000. running mean: -9.077552\n",
      "ep 30: ep_len:251 episode reward: total was 23.500000. running mean: -8.751776\n",
      "ep 30: ep_len:1937 episode reward: total was -283.600000. running mean: -11.500259\n",
      "ep 30: ep_len:500 episode reward: total was 3.830000. running mean: -11.346956\n",
      "ep 30: ep_len:232 episode reward: total was 23.000000. running mean: -11.003486\n",
      "ep 30: ep_len:316 episode reward: total was 15.800000. running mean: -10.735452\n",
      "ep 30: ep_len:1030 episode reward: total was -89.900000. running mean: -11.527097\n",
      "ep 30: ep_len:505 episode reward: total was -12.170000. running mean: -11.533526\n",
      "ep 30: ep_len:915 episode reward: total was -85.080000. running mean: -12.268991\n",
      "ep 30: ep_len:855 episode reward: total was 16.430000. running mean: -11.982001\n",
      "ep 30: ep_len:500 episode reward: total was 30.290000. running mean: -11.559281\n",
      "ep 30: ep_len:685 episode reward: total was -5.300000. running mean: -11.496688\n",
      "ep 30: ep_len:1030 episode reward: total was -10.910000. running mean: -11.490821\n",
      "ep 30: ep_len:825 episode reward: total was -38.110000. running mean: -11.757013\n",
      "ep 30: ep_len:737 episode reward: total was -144.000000. running mean: -13.079443\n",
      "ep 30: ep_len:500 episode reward: total was 23.460000. running mean: -12.714048\n",
      "ep 30: ep_len:550 episode reward: total was -8.040000. running mean: -12.667308\n",
      "ep 30: ep_len:201 episode reward: total was 20.500000. running mean: -12.335635\n",
      "ep 30: ep_len:236 episode reward: total was 23.500000. running mean: -11.977278\n",
      "ep 30: ep_len:1025 episode reward: total was -123.240000. running mean: -13.089906\n",
      "ep 30: ep_len:560 episode reward: total was -22.160000. running mean: -13.180607\n",
      "ep 30: ep_len:655 episode reward: total was -7.830000. running mean: -13.127101\n",
      "ep 30: ep_len:560 episode reward: total was -25.160000. running mean: -13.247430\n",
      "ep 30: ep_len:500 episode reward: total was 27.810000. running mean: -12.836855\n",
      "ep 30: ep_len:590 episode reward: total was -31.190000. running mean: -13.020387\n",
      "ep 30: ep_len:247 episode reward: total was 24.500000. running mean: -12.645183\n",
      "ep 30: ep_len:500 episode reward: total was -1.310000. running mean: -12.531831\n",
      "ep 30: ep_len:500 episode reward: total was 0.740000. running mean: -12.399113\n",
      "ep 30: ep_len:625 episode reward: total was -11.930000. running mean: -12.394422\n",
      "ep 30: ep_len:695 episode reward: total was 33.100000. running mean: -11.939477\n",
      "ep 30: ep_len:555 episode reward: total was -13.080000. running mean: -11.950883\n",
      "ep 30: ep_len:900 episode reward: total was -40.670000. running mean: -12.238074\n",
      "ep 30: ep_len:432 episode reward: total was -47.210000. running mean: -12.587793\n",
      "ep 30: ep_len:500 episode reward: total was 50.000000. running mean: -11.961915\n",
      "ep 30: ep_len:500 episode reward: total was 4.290000. running mean: -11.799396\n",
      "ep 30: ep_len:765 episode reward: total was -6.500000. running mean: -11.746402\n",
      "ep 30: ep_len:600 episode reward: total was -5.150000. running mean: -11.680438\n",
      "ep 30: ep_len:560 episode reward: total was -1.960000. running mean: -11.583234\n",
      "ep 30: ep_len:1015 episode reward: total was 7.680000. running mean: -11.390601\n",
      "ep 30: ep_len:234 episode reward: total was 20.000000. running mean: -11.076695\n",
      "ep 30: ep_len:500 episode reward: total was 7.360000. running mean: -10.892328\n",
      "ep 30: ep_len:590 episode reward: total was -21.090000. running mean: -10.994305\n",
      "ep 30: ep_len:219 episode reward: total was 21.500000. running mean: -10.669362\n",
      "ep 30: ep_len:595 episode reward: total was -4.920000. running mean: -10.611868\n",
      "ep 30: ep_len:500 episode reward: total was 8.210000. running mean: -10.423650\n",
      "ep 30: ep_len:680 episode reward: total was -13.840000. running mean: -10.457813\n",
      "ep 30: ep_len:635 episode reward: total was 7.600000. running mean: -10.277235\n",
      "ep 30: ep_len:800 episode reward: total was 15.930000. running mean: -10.015163\n",
      "ep 30: ep_len:500 episode reward: total was 9.100000. running mean: -9.824011\n",
      "ep 30: ep_len:2105 episode reward: total was -259.450000. running mean: -12.320271\n",
      "ep 30: ep_len:500 episode reward: total was 24.320000. running mean: -11.953868\n",
      "ep 30: ep_len:1000 episode reward: total was 8.270000. running mean: -11.751630\n",
      "ep 30: ep_len:1610 episode reward: total was -104.580000. running mean: -12.679913\n",
      "ep 30: ep_len:500 episode reward: total was 24.260000. running mean: -12.310514\n",
      "ep 30: ep_len:860 episode reward: total was -4.930000. running mean: -12.236709\n",
      "ep 30: ep_len:775 episode reward: total was -49.270000. running mean: -12.607042\n",
      "ep 30: ep_len:1065 episode reward: total was -115.080000. running mean: -13.631771\n",
      "ep 30: ep_len:640 episode reward: total was 24.720000. running mean: -13.248254\n",
      "ep 30: ep_len:1420 episode reward: total was -40.640000. running mean: -13.522171\n",
      "ep 30: ep_len:500 episode reward: total was 7.230000. running mean: -13.314650\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 30: ep_len:500 episode reward: total was 48.500000. running mean: -12.696503\n",
      "ep 30: ep_len:935 episode reward: total was -10.600000. running mean: -12.675538\n",
      "ep 30: ep_len:575 episode reward: total was -22.130000. running mean: -12.770083\n",
      "ep 30: ep_len:500 episode reward: total was 23.430000. running mean: -12.408082\n",
      "ep 30: ep_len:86 episode reward: total was 8.500000. running mean: -12.199001\n",
      "ep 30: ep_len:215 episode reward: total was 20.000000. running mean: -11.877011\n",
      "ep 30: ep_len:740 episode reward: total was -20.760000. running mean: -11.965841\n",
      "ep 30: ep_len:1478 episode reward: total was -240.080000. running mean: -14.246982\n",
      "ep 30: ep_len:680 episode reward: total was -4.750000. running mean: -14.152013\n",
      "ep 30: ep_len:1315 episode reward: total was -179.220000. running mean: -15.802692\n",
      "ep 30: ep_len:500 episode reward: total was 1.320000. running mean: -15.631466\n",
      "ep 30: ep_len:835 episode reward: total was -24.640000. running mean: -15.721551\n",
      "ep 30: ep_len:500 episode reward: total was 5.390000. running mean: -15.510435\n",
      "ep 30: ep_len:217 episode reward: total was 18.500000. running mean: -15.170331\n",
      "ep 30: ep_len:1345 episode reward: total was 30.730000. running mean: -14.711328\n",
      "ep 30: ep_len:711 episode reward: total was -49.110000. running mean: -15.055314\n",
      "ep 30: ep_len:500 episode reward: total was 14.890000. running mean: -14.755861\n",
      "ep 30: ep_len:735 episode reward: total was -1.610000. running mean: -14.624403\n",
      "ep 30: ep_len:500 episode reward: total was 1.690000. running mean: -14.461259\n",
      "ep 30: ep_len:500 episode reward: total was -11.260000. running mean: -14.429246\n",
      "ep 30: ep_len:500 episode reward: total was 5.880000. running mean: -14.226154\n",
      "ep 30: ep_len:810 episode reward: total was -9.540000. running mean: -14.179292\n",
      "ep 30: ep_len:267 episode reward: total was 26.500000. running mean: -13.772499\n",
      "ep 30: ep_len:500 episode reward: total was 4.660000. running mean: -13.588174\n",
      "ep 30: ep_len:1005 episode reward: total was -102.070000. running mean: -14.472992\n",
      "ep 30: ep_len:1520 episode reward: total was -206.080000. running mean: -16.389062\n",
      "ep 30: ep_len:500 episode reward: total was 19.240000. running mean: -16.032772\n",
      "ep 30: ep_len:964 episode reward: total was -90.570000. running mean: -16.778144\n",
      "ep 30: ep_len:1000 episode reward: total was -107.130000. running mean: -17.681663\n",
      "ep 30: ep_len:500 episode reward: total was 28.390000. running mean: -17.220946\n",
      "ep 30: ep_len:910 episode reward: total was -22.470000. running mean: -17.273437\n",
      "ep 30: ep_len:650 episode reward: total was -54.270000. running mean: -17.643402\n",
      "ep 30: ep_len:590 episode reward: total was -0.960000. running mean: -17.476568\n",
      "ep 30: ep_len:500 episode reward: total was 14.920000. running mean: -17.152603\n",
      "ep 30: ep_len:692 episode reward: total was -27.750000. running mean: -17.258577\n",
      "ep 30: ep_len:920 episode reward: total was 14.060000. running mean: -16.945391\n",
      "ep 30: ep_len:750 episode reward: total was -20.490000. running mean: -16.980837\n",
      "ep 30: ep_len:830 episode reward: total was -5.740000. running mean: -16.868428\n",
      "ep 30: ep_len:500 episode reward: total was -4.480000. running mean: -16.744544\n",
      "ep 30: ep_len:895 episode reward: total was -21.490000. running mean: -16.791999\n",
      "ep 30: ep_len:500 episode reward: total was 16.480000. running mean: -16.459279\n",
      "ep 30: ep_len:500 episode reward: total was -11.170000. running mean: -16.406386\n",
      "ep 30: ep_len:500 episode reward: total was 18.930000. running mean: -16.053022\n",
      "ep 30: ep_len:735 episode reward: total was -21.870000. running mean: -16.111192\n",
      "ep 30: ep_len:855 episode reward: total was 2.770000. running mean: -15.922380\n",
      "ep 30: ep_len:500 episode reward: total was 32.740000. running mean: -15.435756\n",
      "ep 30: ep_len:605 episode reward: total was -27.120000. running mean: -15.552599\n",
      "ep 30: ep_len:520 episode reward: total was -34.360000. running mean: -15.740673\n",
      "ep 30: ep_len:500 episode reward: total was 24.750000. running mean: -15.335766\n",
      "ep 30: ep_len:500 episode reward: total was 2.060000. running mean: -15.161808\n",
      "ep 30: ep_len:720 episode reward: total was 0.380000. running mean: -15.006390\n",
      "ep 30: ep_len:505 episode reward: total was -10.150000. running mean: -14.957826\n",
      "ep 30: ep_len:600 episode reward: total was -8.950000. running mean: -14.897748\n",
      "ep 30: ep_len:925 episode reward: total was 17.190000. running mean: -14.576871\n",
      "ep 30: ep_len:500 episode reward: total was 22.360000. running mean: -14.207502\n",
      "ep 30: ep_len:500 episode reward: total was 14.780000. running mean: -13.917627\n",
      "ep 30: ep_len:930 episode reward: total was 16.300000. running mean: -13.615451\n",
      "ep 30: ep_len:500 episode reward: total was 17.430000. running mean: -13.304996\n",
      "ep 30: ep_len:760 episode reward: total was -15.700000. running mean: -13.328946\n",
      "ep 30: ep_len:650 episode reward: total was -1.780000. running mean: -13.213457\n",
      "ep 30: ep_len:615 episode reward: total was -2.020000. running mean: -13.101522\n",
      "ep 30: ep_len:915 episode reward: total was -33.570000. running mean: -13.306207\n",
      "ep 30: ep_len:570 episode reward: total was 32.790000. running mean: -12.845245\n",
      "ep 30: ep_len:500 episode reward: total was 22.940000. running mean: -12.487392\n",
      "ep 30: ep_len:720 episode reward: total was -12.710000. running mean: -12.489618\n",
      "ep 30: ep_len:343 episode reward: total was -0.460000. running mean: -12.369322\n",
      "ep 30: ep_len:500 episode reward: total was 18.410000. running mean: -12.061529\n",
      "ep 30: ep_len:723 episode reward: total was -68.280000. running mean: -12.623714\n",
      "ep 30: ep_len:500 episode reward: total was 25.240000. running mean: -12.245077\n",
      "ep 30: ep_len:735 episode reward: total was 16.310000. running mean: -11.959526\n",
      "ep 30: ep_len:500 episode reward: total was 10.270000. running mean: -11.737231\n",
      "ep 30: ep_len:384 episode reward: total was 38.000000. running mean: -11.239858\n",
      "ep 30: ep_len:500 episode reward: total was -25.310000. running mean: -11.380560\n",
      "ep 30: ep_len:500 episode reward: total was 25.390000. running mean: -11.012854\n",
      "ep 30: ep_len:535 episode reward: total was -5.040000. running mean: -10.953126\n",
      "ep 30: ep_len:545 episode reward: total was -10.070000. running mean: -10.944294\n",
      "ep 30: ep_len:500 episode reward: total was 12.380000. running mean: -10.711051\n",
      "ep 30: ep_len:820 episode reward: total was -21.640000. running mean: -10.820341\n",
      "ep 30: ep_len:660 episode reward: total was -5.800000. running mean: -10.770137\n",
      "ep 30: ep_len:645 episode reward: total was 3.450000. running mean: -10.627936\n",
      "ep 30: ep_len:835 episode reward: total was -58.980000. running mean: -11.111457\n",
      "ep 30: ep_len:500 episode reward: total was 6.770000. running mean: -10.932642\n",
      "ep 30: ep_len:805 episode reward: total was -4.280000. running mean: -10.866116\n",
      "ep 30: ep_len:500 episode reward: total was 22.790000. running mean: -10.529555\n",
      "ep 30: ep_len:147 episode reward: total was 14.500000. running mean: -10.279259\n",
      "ep 30: ep_len:785 episode reward: total was -9.590000. running mean: -10.272366\n",
      "ep 30: ep_len:500 episode reward: total was 11.950000. running mean: -10.050143\n",
      "ep 30: ep_len:995 episode reward: total was -25.330000. running mean: -10.202941\n",
      "ep 30: ep_len:740 episode reward: total was -8.940000. running mean: -10.190312\n",
      "ep 30: ep_len:675 episode reward: total was 0.200000. running mean: -10.086409\n",
      "ep 30: ep_len:487 episode reward: total was 28.330000. running mean: -9.702245\n",
      "ep 30: ep_len:500 episode reward: total was 5.460000. running mean: -9.550622\n",
      "ep 30: ep_len:695 episode reward: total was 32.180000. running mean: -9.133316\n",
      "ep 30: ep_len:1045 episode reward: total was 22.900000. running mean: -8.812983\n",
      "ep 30: ep_len:1237 episode reward: total was -185.110000. running mean: -10.575953\n",
      "ep 30: ep_len:500 episode reward: total was 6.800000. running mean: -10.402193\n",
      "ep 30: ep_len:500 episode reward: total was 0.020000. running mean: -10.297972\n",
      "ep 30: ep_len:910 episode reward: total was -52.770000. running mean: -10.722692\n",
      "ep 30: ep_len:685 episode reward: total was -5.750000. running mean: -10.672965\n",
      "ep 30: ep_len:960 episode reward: total was 14.380000. running mean: -10.422435\n",
      "ep 30: ep_len:1080 episode reward: total was 6.440000. running mean: -10.253811\n",
      "ep 30: ep_len:665 episode reward: total was -46.330000. running mean: -10.614573\n",
      "ep 30: ep_len:361 episode reward: total was 8.700000. running mean: -10.421427\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 30: ep_len:560 episode reward: total was -22.160000. running mean: -10.538813\n",
      "ep 30: ep_len:575 episode reward: total was 7.450000. running mean: -10.358925\n",
      "ep 30: ep_len:500 episode reward: total was -19.400000. running mean: -10.449335\n",
      "ep 30: ep_len:175 episode reward: total was 16.000000. running mean: -10.184842\n",
      "ep 30: ep_len:500 episode reward: total was 7.780000. running mean: -10.005194\n",
      "ep 30: ep_len:500 episode reward: total was 0.860000. running mean: -9.896542\n",
      "ep 30: ep_len:1030 episode reward: total was -1.900000. running mean: -9.816576\n",
      "ep 30: ep_len:1531 episode reward: total was -222.200000. running mean: -11.940411\n",
      "ep 30: ep_len:500 episode reward: total was 14.400000. running mean: -11.677006\n",
      "ep 30: ep_len:628 episode reward: total was -88.670000. running mean: -12.446936\n",
      "ep 30: ep_len:540 episode reward: total was -2.000000. running mean: -12.342467\n",
      "ep 30: ep_len:1080 episode reward: total was -96.950000. running mean: -13.188542\n",
      "ep 30: ep_len:505 episode reward: total was -7.120000. running mean: -13.127857\n",
      "ep 30: ep_len:510 episode reward: total was -11.120000. running mean: -13.107778\n",
      "ep 30: ep_len:835 episode reward: total was 28.180000. running mean: -12.694901\n",
      "ep 30: ep_len:1475 episode reward: total was -177.890000. running mean: -14.346852\n",
      "ep 30: ep_len:500 episode reward: total was -0.730000. running mean: -14.210683\n",
      "ep 30: ep_len:710 episode reward: total was -18.830000. running mean: -14.256876\n",
      "ep 30: ep_len:1450 episode reward: total was -194.590000. running mean: -16.060207\n",
      "ep 30: ep_len:705 episode reward: total was -13.080000. running mean: -16.030405\n",
      "ep 30: ep_len:500 episode reward: total was 28.820000. running mean: -15.581901\n",
      "ep 30: ep_len:560 episode reward: total was -1.100000. running mean: -15.437082\n",
      "ep 30: ep_len:500 episode reward: total was -10.860000. running mean: -15.391311\n",
      "ep 30: ep_len:500 episode reward: total was -14.010000. running mean: -15.377498\n",
      "ep 30: ep_len:1375 episode reward: total was -95.270000. running mean: -16.176423\n",
      "ep 30: ep_len:1000 episode reward: total was -68.750000. running mean: -16.702159\n",
      "ep 30: ep_len:500 episode reward: total was 7.910000. running mean: -16.456038\n",
      "ep 30: ep_len:500 episode reward: total was -3.360000. running mean: -16.325077\n",
      "ep 30: ep_len:670 episode reward: total was -2.750000. running mean: -16.189326\n",
      "ep 30: ep_len:520 episode reward: total was -12.140000. running mean: -16.148833\n",
      "ep 30: ep_len:472 episode reward: total was -3.700000. running mean: -16.024345\n",
      "ep 30: ep_len:500 episode reward: total was 24.780000. running mean: -15.616301\n",
      "ep 30: ep_len:500 episode reward: total was 30.810000. running mean: -15.152038\n",
      "ep 30: ep_len:500 episode reward: total was -8.320000. running mean: -15.083718\n",
      "ep 30: ep_len:615 episode reward: total was -57.820000. running mean: -15.511081\n",
      "ep 30: ep_len:535 episode reward: total was -14.130000. running mean: -15.497270\n",
      "ep 30: ep_len:600 episode reward: total was -7.940000. running mean: -15.421697\n",
      "ep 30: ep_len:555 episode reward: total was 10.370000. running mean: -15.163780\n",
      "ep 30: ep_len:745 episode reward: total was 2.330000. running mean: -14.988843\n",
      "ep 30: ep_len:650 episode reward: total was -26.020000. running mean: -15.099154\n",
      "ep 30: ep_len:1190 episode reward: total was -84.920000. running mean: -15.797363\n",
      "ep 30: ep_len:1197 episode reward: total was -139.040000. running mean: -17.029789\n",
      "ep 30: ep_len:1010 episode reward: total was -13.110000. running mean: -16.990591\n",
      "ep 30: ep_len:500 episode reward: total was 20.430000. running mean: -16.616385\n",
      "ep 30: ep_len:319 episode reward: total was 31.500000. running mean: -16.135221\n",
      "ep 30: ep_len:424 episode reward: total was 14.360000. running mean: -15.830269\n",
      "ep 30: ep_len:500 episode reward: total was 31.300000. running mean: -15.358966\n",
      "ep 30: ep_len:805 episode reward: total was -20.660000. running mean: -15.411977\n",
      "ep 30: ep_len:735 episode reward: total was -4.020000. running mean: -15.298057\n",
      "ep 30: ep_len:500 episode reward: total was 22.790000. running mean: -14.917176\n",
      "ep 30: ep_len:890 episode reward: total was 7.480000. running mean: -14.693205\n",
      "ep 30: ep_len:241 episode reward: total was 22.500000. running mean: -14.321273\n",
      "ep 30: ep_len:1835 episode reward: total was -197.370000. running mean: -16.151760\n",
      "ep 30: ep_len:170 episode reward: total was 15.500000. running mean: -15.835242\n",
      "ep 30: ep_len:500 episode reward: total was -4.890000. running mean: -15.725790\n",
      "ep 30: ep_len:305 episode reward: total was 27.500000. running mean: -15.293532\n",
      "ep 30: ep_len:675 episode reward: total was 11.540000. running mean: -15.025197\n",
      "ep 30: ep_len:266 episode reward: total was 26.500000. running mean: -14.609945\n",
      "ep 30: ep_len:500 episode reward: total was 5.240000. running mean: -14.411445\n",
      "ep 30: ep_len:500 episode reward: total was 3.380000. running mean: -14.233531\n",
      "ep 30: ep_len:500 episode reward: total was 5.280000. running mean: -14.038395\n",
      "ep 30: ep_len:500 episode reward: total was 3.710000. running mean: -13.860911\n",
      "ep 30: ep_len:775 episode reward: total was -22.740000. running mean: -13.949702\n",
      "ep 30: ep_len:500 episode reward: total was 6.310000. running mean: -13.747105\n",
      "ep 30: ep_len:252 episode reward: total was 25.000000. running mean: -13.359634\n",
      "ep 30: ep_len:600 episode reward: total was -21.070000. running mean: -13.436738\n",
      "ep 30: ep_len:274 episode reward: total was 27.000000. running mean: -13.032371\n",
      "ep 30: ep_len:500 episode reward: total was 3.100000. running mean: -12.871047\n",
      "ep 30: ep_len:640 episode reward: total was -4.830000. running mean: -12.790636\n",
      "ep 30: ep_len:885 episode reward: total was -34.640000. running mean: -13.009130\n",
      "ep 30: ep_len:1115 episode reward: total was 2.230000. running mean: -12.856739\n",
      "ep 30: ep_len:500 episode reward: total was 15.930000. running mean: -12.568871\n",
      "ep 30: ep_len:710 episode reward: total was 10.450000. running mean: -12.338683\n",
      "ep 30: ep_len:500 episode reward: total was 13.790000. running mean: -12.077396\n",
      "ep 30: ep_len:990 episode reward: total was 10.770000. running mean: -11.848922\n",
      "ep 30: ep_len:505 episode reward: total was 1.160000. running mean: -11.718833\n",
      "ep 30: ep_len:163 episode reward: total was 16.000000. running mean: -11.441644\n",
      "ep 30: ep_len:500 episode reward: total was -18.910000. running mean: -11.516328\n",
      "ep 30: ep_len:1280 episode reward: total was -83.340000. running mean: -12.234565\n",
      "ep 30: ep_len:114 episode reward: total was 11.000000. running mean: -12.002219\n",
      "ep 30: ep_len:500 episode reward: total was 29.830000. running mean: -11.583897\n",
      "ep 30: ep_len:500 episode reward: total was -7.860000. running mean: -11.546658\n",
      "ep 30: ep_len:530 episode reward: total was 8.400000. running mean: -11.347191\n",
      "ep 30: ep_len:740 episode reward: total was -17.760000. running mean: -11.411319\n",
      "ep 30: ep_len:500 episode reward: total was -25.340000. running mean: -11.550606\n",
      "ep 30: ep_len:885 episode reward: total was -28.270000. running mean: -11.717800\n",
      "ep 30: ep_len:500 episode reward: total was 8.530000. running mean: -11.515322\n",
      "ep 30: ep_len:600 episode reward: total was 19.780000. running mean: -11.202369\n",
      "ep 30: ep_len:500 episode reward: total was -8.690000. running mean: -11.177245\n",
      "ep 30: ep_len:500 episode reward: total was 26.280000. running mean: -10.802673\n",
      "ep 30: ep_len:825 episode reward: total was 10.960000. running mean: -10.585046\n",
      "ep 30: ep_len:640 episode reward: total was -11.530000. running mean: -10.594495\n",
      "ep 30: ep_len:775 episode reward: total was 0.740000. running mean: -10.481151\n",
      "ep 30: ep_len:500 episode reward: total was 3.590000. running mean: -10.340439\n",
      "ep 30: ep_len:500 episode reward: total was 25.820000. running mean: -9.978835\n",
      "ep 30: ep_len:500 episode reward: total was -10.400000. running mean: -9.983046\n",
      "ep 30: ep_len:960 episode reward: total was -43.580000. running mean: -10.319016\n",
      "ep 30: ep_len:945 episode reward: total was 2.540000. running mean: -10.190426\n",
      "ep 30: ep_len:195 episode reward: total was 18.000000. running mean: -9.908521\n",
      "ep 30: ep_len:500 episode reward: total was 9.710000. running mean: -9.712336\n",
      "ep 30: ep_len:414 episode reward: total was 20.830000. running mean: -9.406913\n",
      "ep 30: ep_len:877 episode reward: total was -65.950000. running mean: -9.972344\n",
      "ep 30: ep_len:157 episode reward: total was 15.500000. running mean: -9.717620\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 30: ep_len:500 episode reward: total was 12.040000. running mean: -9.500044\n",
      "ep 30: ep_len:1785 episode reward: total was -205.550000. running mean: -11.460544\n",
      "ep 30: ep_len:299 episode reward: total was 27.000000. running mean: -11.075938\n",
      "ep 30: ep_len:895 episode reward: total was 19.200000. running mean: -10.773179\n",
      "ep 30: ep_len:500 episode reward: total was 23.340000. running mean: -10.432047\n",
      "ep 30: ep_len:500 episode reward: total was 48.500000. running mean: -9.842727\n",
      "ep 30: ep_len:825 episode reward: total was 9.950000. running mean: -9.644799\n",
      "ep 30: ep_len:740 episode reward: total was -10.690000. running mean: -9.655251\n",
      "ep 30: ep_len:805 episode reward: total was -83.280000. running mean: -10.391499\n",
      "ep 30: ep_len:500 episode reward: total was 9.230000. running mean: -10.195284\n",
      "ep 30: ep_len:860 episode reward: total was -20.550000. running mean: -10.298831\n",
      "ep 30: ep_len:605 episode reward: total was -15.000000. running mean: -10.345843\n",
      "ep 30: ep_len:650 episode reward: total was 18.900000. running mean: -10.053384\n",
      "ep 30: ep_len:168 episode reward: total was 15.000000. running mean: -9.802850\n",
      "ep 30: ep_len:716 episode reward: total was -114.230000. running mean: -10.847122\n",
      "ep 30: ep_len:500 episode reward: total was 35.780000. running mean: -10.380851\n",
      "ep 30: ep_len:535 episode reward: total was 26.960000. running mean: -10.007442\n",
      "ep 30: ep_len:640 episode reward: total was -7.860000. running mean: -9.985968\n",
      "ep 30: ep_len:1845 episode reward: total was -95.340000. running mean: -10.839508\n",
      "ep 30: ep_len:760 episode reward: total was -19.740000. running mean: -10.928513\n",
      "ep 30: ep_len:590 episode reward: total was -17.050000. running mean: -10.989728\n",
      "ep 30: ep_len:750 episode reward: total was -3.750000. running mean: -10.917331\n",
      "ep 30: ep_len:500 episode reward: total was -2.780000. running mean: -10.835957\n",
      "ep 30: ep_len:500 episode reward: total was 4.380000. running mean: -10.683798\n",
      "ep 30: ep_len:595 episode reward: total was -31.180000. running mean: -10.888760\n",
      "ep 30: ep_len:714 episode reward: total was -5.680000. running mean: -10.836672\n",
      "ep 30: ep_len:500 episode reward: total was 14.000000. running mean: -10.588305\n",
      "ep 30: ep_len:675 episode reward: total was 27.670000. running mean: -10.205722\n",
      "ep 30: ep_len:590 episode reward: total was 26.250000. running mean: -9.841165\n",
      "ep 30: ep_len:500 episode reward: total was -26.740000. running mean: -10.010153\n",
      "ep 30: ep_len:268 episode reward: total was 26.500000. running mean: -9.645052\n",
      "ep 30: ep_len:698 episode reward: total was -102.670000. running mean: -10.575301\n",
      "ep 30: ep_len:500 episode reward: total was -15.360000. running mean: -10.623148\n",
      "ep 30: ep_len:1330 episode reward: total was -101.720000. running mean: -11.534117\n",
      "ep 30: ep_len:805 episode reward: total was -16.620000. running mean: -11.584976\n",
      "ep 30: ep_len:500 episode reward: total was 21.810000. running mean: -11.251026\n",
      "ep 30: ep_len:725 episode reward: total was -5.670000. running mean: -11.195216\n",
      "ep 30: ep_len:1085 episode reward: total was 6.860000. running mean: -11.014664\n",
      "ep 30: ep_len:565 episode reward: total was 16.800000. running mean: -10.736517\n",
      "ep 30: ep_len:500 episode reward: total was 24.300000. running mean: -10.386152\n",
      "ep 30: ep_len:500 episode reward: total was -5.000000. running mean: -10.332290\n",
      "ep 30: ep_len:500 episode reward: total was -0.390000. running mean: -10.232867\n",
      "ep 30: ep_len:500 episode reward: total was 22.760000. running mean: -9.902939\n",
      "ep 30: ep_len:845 episode reward: total was -25.630000. running mean: -10.060209\n",
      "ep 30: ep_len:715 episode reward: total was -13.770000. running mean: -10.097307\n",
      "ep 30: ep_len:670 episode reward: total was -22.950000. running mean: -10.225834\n",
      "ep 30: ep_len:685 episode reward: total was -5.750000. running mean: -10.181076\n",
      "ep 30: ep_len:500 episode reward: total was -0.790000. running mean: -10.087165\n",
      "ep 30: ep_len:520 episode reward: total was -8.100000. running mean: -10.067293\n",
      "ep 30: ep_len:515 episode reward: total was -7.100000. running mean: -10.037620\n",
      "ep 30: ep_len:660 episode reward: total was -31.050000. running mean: -10.247744\n",
      "ep 30: ep_len:885 episode reward: total was -30.600000. running mean: -10.451267\n",
      "ep 30: ep_len:500 episode reward: total was 48.500000. running mean: -9.861754\n",
      "ep 30: ep_len:500 episode reward: total was 26.340000. running mean: -9.499737\n",
      "ep 30: ep_len:500 episode reward: total was -18.850000. running mean: -9.593239\n",
      "ep 30: ep_len:500 episode reward: total was 26.280000. running mean: -9.234507\n",
      "ep 30: ep_len:555 episode reward: total was -11.550000. running mean: -9.257662\n",
      "ep 30: ep_len:446 episode reward: total was 17.110000. running mean: -8.993985\n",
      "ep 30: ep_len:500 episode reward: total was 20.280000. running mean: -8.701245\n",
      "ep 30: ep_len:1135 episode reward: total was -42.350000. running mean: -9.037733\n",
      "ep 30: ep_len:1408 episode reward: total was -211.570000. running mean: -11.063055\n",
      "ep 30: ep_len:1737 episode reward: total was -288.710000. running mean: -13.839525\n",
      "ep 30: ep_len:500 episode reward: total was -3.820000. running mean: -13.739330\n",
      "ep 30: ep_len:845 episode reward: total was 11.920000. running mean: -13.482736\n",
      "ep 30: ep_len:900 episode reward: total was 19.650000. running mean: -13.151409\n",
      "ep 30: ep_len:510 episode reward: total was -12.160000. running mean: -13.141495\n",
      "ep 30: ep_len:500 episode reward: total was 31.820000. running mean: -12.691880\n",
      "ep 30: ep_len:995 episode reward: total was 7.280000. running mean: -12.492161\n",
      "ep 30: ep_len:580 episode reward: total was -16.060000. running mean: -12.527840\n",
      "ep 30: ep_len:920 episode reward: total was -6.450000. running mean: -12.467061\n",
      "ep 30: ep_len:635 episode reward: total was -39.180000. running mean: -12.734191\n",
      "ep 30: ep_len:500 episode reward: total was 25.300000. running mean: -12.353849\n",
      "ep 30: ep_len:171 episode reward: total was 17.000000. running mean: -12.060310\n",
      "ep 30: ep_len:500 episode reward: total was 7.110000. running mean: -11.868607\n",
      "ep 30: ep_len:590 episode reward: total was -20.080000. running mean: -11.950721\n",
      "ep 30: ep_len:860 episode reward: total was -0.760000. running mean: -11.838814\n",
      "ep 30: ep_len:765 episode reward: total was -43.970000. running mean: -12.160126\n",
      "ep 30: ep_len:500 episode reward: total was 11.710000. running mean: -11.921424\n",
      "ep 30: ep_len:500 episode reward: total was -15.300000. running mean: -11.955210\n",
      "ep 30: ep_len:494 episode reward: total was 33.730000. running mean: -11.498358\n",
      "ep 30: ep_len:800 episode reward: total was 3.190000. running mean: -11.351474\n",
      "ep 30: ep_len:930 episode reward: total was 14.040000. running mean: -11.097560\n",
      "ep 30: ep_len:555 episode reward: total was -3.990000. running mean: -11.026484\n",
      "ep 30: ep_len:1259 episode reward: total was -159.230000. running mean: -12.508519\n",
      "ep 30: ep_len:630 episode reward: total was -18.990000. running mean: -12.573334\n",
      "ep 30: ep_len:230 episode reward: total was 21.500000. running mean: -12.232601\n",
      "ep 30: ep_len:670 episode reward: total was -3.760000. running mean: -12.147875\n",
      "ep 30: ep_len:500 episode reward: total was 24.780000. running mean: -11.778596\n",
      "ep 30: ep_len:875 episode reward: total was -15.470000. running mean: -11.815510\n",
      "ep 30: ep_len:1955 episode reward: total was -215.820000. running mean: -13.855555\n",
      "ep 30: ep_len:805 episode reward: total was -2.200000. running mean: -13.738999\n",
      "ep 30: ep_len:10300 episode reward: total was -1936.830000. running mean: -32.969909\n",
      "ep 30: ep_len:228 episode reward: total was 13.500000. running mean: -32.505210\n",
      "ep 30: ep_len:500 episode reward: total was 25.330000. running mean: -31.926858\n",
      "ep 30: ep_len:680 episode reward: total was -2.790000. running mean: -31.635490\n",
      "ep 30: ep_len:230 episode reward: total was 21.500000. running mean: -31.104135\n",
      "ep 30: ep_len:500 episode reward: total was 21.810000. running mean: -30.574993\n",
      "ep 30: ep_len:1725 episode reward: total was -197.500000. running mean: -32.244243\n",
      "ep 30: ep_len:505 episode reward: total was -14.720000. running mean: -32.069001\n",
      "ep 30: ep_len:776 episode reward: total was -143.920000. running mean: -33.187511\n",
      "ep 30: ep_len:715 episode reward: total was -6.330000. running mean: -32.918936\n",
      "ep 30: ep_len:625 episode reward: total was 7.870000. running mean: -32.511047\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 30: ep_len:1300 episode reward: total was -207.530000. running mean: -34.261236\n",
      "ep 30: ep_len:186 episode reward: total was 18.500000. running mean: -33.733624\n",
      "ep 30: ep_len:680 episode reward: total was 0.300000. running mean: -33.393287\n",
      "ep 30: ep_len:500 episode reward: total was 16.300000. running mean: -32.896355\n",
      "ep 30: ep_len:380 episode reward: total was 36.500000. running mean: -32.202391\n",
      "ep 30: ep_len:500 episode reward: total was 23.800000. running mean: -31.642367\n",
      "ep 30: ep_len:790 episode reward: total was 2.000000. running mean: -31.305943\n",
      "ep 30: ep_len:840 episode reward: total was 40.770000. running mean: -30.585184\n",
      "ep 30: ep_len:690 episode reward: total was -22.910000. running mean: -30.508432\n",
      "ep 30: ep_len:500 episode reward: total was 1.840000. running mean: -30.184948\n",
      "ep 30: ep_len:500 episode reward: total was -2.320000. running mean: -29.906298\n",
      "ep 30: ep_len:1225 episode reward: total was -127.420000. running mean: -30.881435\n",
      "ep 30: ep_len:865 episode reward: total was -25.560000. running mean: -30.828221\n",
      "ep 30: ep_len:790 episode reward: total was 5.920000. running mean: -30.460739\n",
      "ep 30: ep_len:915 episode reward: total was 2.390000. running mean: -30.132231\n",
      "ep 30: ep_len:434 episode reward: total was 18.760000. running mean: -29.643309\n",
      "ep 30: ep_len:500 episode reward: total was 45.500000. running mean: -28.891876\n",
      "ep 30: ep_len:500 episode reward: total was 25.330000. running mean: -28.349657\n",
      "ep 30: ep_len:500 episode reward: total was 8.340000. running mean: -27.982761\n",
      "ep 30: ep_len:991 episode reward: total was -112.670000. running mean: -28.829633\n",
      "ep 30: ep_len:895 episode reward: total was -21.910000. running mean: -28.760437\n",
      "ep 30: ep_len:730 episode reward: total was 15.750000. running mean: -28.315332\n",
      "ep 30: ep_len:500 episode reward: total was 31.790000. running mean: -27.714279\n",
      "ep 30: ep_len:1336 episode reward: total was -49.270000. running mean: -27.929836\n",
      "ep 30: ep_len:680 episode reward: total was -5.760000. running mean: -27.708138\n",
      "ep 30: ep_len:765 episode reward: total was 22.500000. running mean: -27.206057\n",
      "ep 30: ep_len:500 episode reward: total was -4.130000. running mean: -26.975296\n",
      "ep 30: ep_len:500 episode reward: total was 7.910000. running mean: -26.626443\n",
      "ep 30: ep_len:500 episode reward: total was 26.770000. running mean: -26.092479\n",
      "ep 30: ep_len:520 episode reward: total was 11.380000. running mean: -25.717754\n",
      "ep 30: ep_len:1100 episode reward: total was -38.390000. running mean: -25.844476\n",
      "ep 30: ep_len:500 episode reward: total was -22.200000. running mean: -25.808032\n",
      "ep 30: ep_len:500 episode reward: total was 15.060000. running mean: -25.399351\n",
      "ep 30: ep_len:915 episode reward: total was -9.500000. running mean: -25.240358\n",
      "ep 30: ep_len:1155 episode reward: total was 24.010000. running mean: -24.747854\n",
      "ep 30: ep_len:830 episode reward: total was 25.010000. running mean: -24.250276\n",
      "ep 30: ep_len:193 episode reward: total was 19.000000. running mean: -23.817773\n",
      "ep 30: ep_len:710 episode reward: total was 5.300000. running mean: -23.526595\n",
      "ep 30: ep_len:955 episode reward: total was -36.420000. running mean: -23.655529\n",
      "ep 30: ep_len:1660 episode reward: total was -156.310000. running mean: -24.982074\n",
      "ep 30: ep_len:500 episode reward: total was -5.620000. running mean: -24.788453\n",
      "ep 30: ep_len:505 episode reward: total was -6.110000. running mean: -24.601669\n",
      "ep 30: ep_len:730 episode reward: total was -21.820000. running mean: -24.573852\n",
      "ep 30: ep_len:500 episode reward: total was 5.310000. running mean: -24.275013\n",
      "ep 30: ep_len:585 episode reward: total was -7.200000. running mean: -24.104263\n",
      "ep 30: ep_len:231 episode reward: total was 20.000000. running mean: -23.663221\n",
      "ep 30: ep_len:500 episode reward: total was -86.000000. running mean: -24.286588\n",
      "ep 30: ep_len:745 episode reward: total was -14.720000. running mean: -24.190923\n",
      "ep 30: ep_len:1088 episode reward: total was -130.170000. running mean: -25.250713\n",
      "ep 30: ep_len:595 episode reward: total was -13.980000. running mean: -25.138006\n",
      "ep 30: ep_len:500 episode reward: total was 14.670000. running mean: -24.739926\n",
      "ep 30: ep_len:515 episode reward: total was 3.650000. running mean: -24.456027\n",
      "ep 30: ep_len:740 episode reward: total was -8.670000. running mean: -24.298167\n",
      "ep 30: ep_len:201 episode reward: total was 20.500000. running mean: -23.850185\n",
      "ep 30: ep_len:640 episode reward: total was -10.030000. running mean: -23.711983\n",
      "ep 30: ep_len:725 episode reward: total was -12.220000. running mean: -23.597063\n",
      "ep 30: ep_len:500 episode reward: total was 14.730000. running mean: -23.213793\n",
      "ep 30: ep_len:223 episode reward: total was 19.000000. running mean: -22.791655\n",
      "ep 30: ep_len:725 episode reward: total was -13.230000. running mean: -22.696038\n",
      "ep 30: ep_len:500 episode reward: total was 5.120000. running mean: -22.417878\n",
      "ep 30: ep_len:500 episode reward: total was 1.720000. running mean: -22.176499\n",
      "ep 30: ep_len:500 episode reward: total was -12.240000. running mean: -22.077134\n",
      "ep 30: ep_len:500 episode reward: total was -6.150000. running mean: -21.917863\n",
      "ep 30: ep_len:500 episode reward: total was 7.670000. running mean: -21.621984\n",
      "ep 30: ep_len:128 episode reward: total was 11.000000. running mean: -21.295764\n",
      "ep 30: ep_len:500 episode reward: total was 22.790000. running mean: -20.854907\n",
      "ep 30: ep_len:523 episode reward: total was -39.170000. running mean: -21.038057\n",
      "ep 30: ep_len:626 episode reward: total was -81.620000. running mean: -21.643877\n",
      "ep 30: ep_len:216 episode reward: total was 21.500000. running mean: -21.212438\n",
      "ep 30: ep_len:610 episode reward: total was -18.750000. running mean: -21.187814\n",
      "ep 30: ep_len:625 episode reward: total was 0.990000. running mean: -20.966036\n",
      "ep 30: ep_len:605 episode reward: total was -46.310000. running mean: -21.219475\n",
      "ep 30: ep_len:1835 episode reward: total was -306.540000. running mean: -24.072680\n",
      "ep 30: ep_len:2710 episode reward: total was -434.000000. running mean: -28.171954\n",
      "ep 30: ep_len:500 episode reward: total was -16.250000. running mean: -28.052734\n",
      "ep 30: ep_len:500 episode reward: total was 50.000000. running mean: -27.272207\n",
      "ep 30: ep_len:904 episode reward: total was -66.910000. running mean: -27.668585\n",
      "ep 30: ep_len:500 episode reward: total was -28.920000. running mean: -27.681099\n",
      "ep 30: ep_len:1340 episode reward: total was -149.880000. running mean: -28.903088\n",
      "ep 30: ep_len:500 episode reward: total was -4.000000. running mean: -28.654057\n",
      "ep 30: ep_len:467 episode reward: total was 0.010000. running mean: -28.367416\n",
      "ep 30: ep_len:600 episode reward: total was 8.270000. running mean: -28.001042\n",
      "ep 30: ep_len:249 episode reward: total was -11.500000. running mean: -27.836032\n",
      "epsilon:0.010000 episode_count: 24432. steps_count: 17701434.000000\n",
      "ep 31: ep_len:2315 episode reward: total was -308.520000. running mean: -30.642872\n",
      "ep 31: ep_len:835 episode reward: total was -0.890000. running mean: -30.345343\n",
      "ep 31: ep_len:500 episode reward: total was -0.510000. running mean: -30.046989\n",
      "ep 31: ep_len:1000 episode reward: total was -21.130000. running mean: -29.957819\n",
      "ep 31: ep_len:500 episode reward: total was 0.250000. running mean: -29.655741\n",
      "ep 31: ep_len:605 episode reward: total was -11.840000. running mean: -29.477584\n",
      "ep 31: ep_len:500 episode reward: total was 5.000000. running mean: -29.132808\n",
      "ep 31: ep_len:500 episode reward: total was -18.260000. running mean: -29.024080\n",
      "ep 31: ep_len:980 episode reward: total was -31.320000. running mean: -29.047039\n",
      "ep 31: ep_len:500 episode reward: total was 24.810000. running mean: -28.508469\n",
      "ep 31: ep_len:570 episode reward: total was -24.160000. running mean: -28.464984\n",
      "ep 31: ep_len:705 episode reward: total was -53.150000. running mean: -28.711834\n",
      "ep 31: ep_len:500 episode reward: total was -44.650000. running mean: -28.871216\n",
      "ep 31: ep_len:179 episode reward: total was -4.500000. running mean: -28.627504\n",
      "ep 31: ep_len:1195 episode reward: total was -7.250000. running mean: -28.413729\n",
      "ep 31: ep_len:1010 episode reward: total was -37.410000. running mean: -28.503691\n",
      "ep 31: ep_len:500 episode reward: total was -15.190000. running mean: -28.370555\n",
      "ep 31: ep_len:500 episode reward: total was -1.670000. running mean: -28.103549\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 31: ep_len:500 episode reward: total was 8.610000. running mean: -27.736413\n",
      "ep 31: ep_len:281 episode reward: total was 27.000000. running mean: -27.189049\n",
      "ep 31: ep_len:830 episode reward: total was 6.920000. running mean: -26.847959\n",
      "ep 31: ep_len:500 episode reward: total was 11.950000. running mean: -26.459979\n",
      "ep 31: ep_len:1430 episode reward: total was -151.720000. running mean: -27.712579\n",
      "ep 31: ep_len:197 episode reward: total was -6.000000. running mean: -27.495454\n",
      "ep 31: ep_len:980 episode reward: total was -45.090000. running mean: -27.671399\n",
      "ep 31: ep_len:2241 episode reward: total was -234.330000. running mean: -29.737985\n",
      "ep 31: ep_len:600 episode reward: total was 22.620000. running mean: -29.214405\n",
      "ep 31: ep_len:152 episode reward: total was -7.500000. running mean: -28.997261\n",
      "ep 31: ep_len:905 episode reward: total was -20.530000. running mean: -28.912589\n",
      "ep 31: ep_len:515 episode reward: total was -9.120000. running mean: -28.714663\n",
      "ep 31: ep_len:14250 episode reward: total was -2579.370000. running mean: -54.221216\n",
      "ep 31: ep_len:705 episode reward: total was -6.380000. running mean: -53.742804\n",
      "ep 31: ep_len:535 episode reward: total was -29.250000. running mean: -53.497876\n",
      "ep 31: ep_len:750 episode reward: total was 12.460000. running mean: -52.838297\n",
      "ep 31: ep_len:500 episode reward: total was -23.810000. running mean: -52.548014\n",
      "ep 31: ep_len:830 episode reward: total was -1.960000. running mean: -52.042134\n",
      "ep 31: ep_len:343 episode reward: total was 12.580000. running mean: -51.395913\n",
      "ep 31: ep_len:505 episode reward: total was -34.880000. running mean: -51.230754\n",
      "ep 31: ep_len:890 episode reward: total was -7.180000. running mean: -50.790246\n",
      "ep 31: ep_len:715 episode reward: total was -18.170000. running mean: -50.464044\n",
      "ep 31: ep_len:520 episode reward: total was -25.420000. running mean: -50.213603\n",
      "ep 31: ep_len:796 episode reward: total was -12.580000. running mean: -49.837267\n",
      "ep 31: ep_len:505 episode reward: total was -20.340000. running mean: -49.542294\n",
      "ep 31: ep_len:296 episode reward: total was 29.500000. running mean: -48.751871\n",
      "ep 31: ep_len:640 episode reward: total was 4.360000. running mean: -48.220753\n",
      "ep 31: ep_len:510 episode reward: total was -14.150000. running mean: -47.880045\n",
      "ep 31: ep_len:500 episode reward: total was -49.970000. running mean: -47.900945\n",
      "ep 31: ep_len:895 episode reward: total was -15.620000. running mean: -47.578135\n",
      "ep 31: ep_len:169 episode reward: total was -6.000000. running mean: -47.162354\n",
      "ep 31: ep_len:500 episode reward: total was -9.380000. running mean: -46.784530\n",
      "ep 31: ep_len:770 episode reward: total was -20.210000. running mean: -46.518785\n",
      "ep 31: ep_len:885 episode reward: total was -31.580000. running mean: -46.369397\n",
      "ep 31: ep_len:500 episode reward: total was -0.230000. running mean: -45.908003\n",
      "ep 31: ep_len:229 episode reward: total was -10.500000. running mean: -45.553923\n",
      "ep 31: ep_len:1015 episode reward: total was -16.890000. running mean: -45.267284\n",
      "ep 31: ep_len:500 episode reward: total was -14.920000. running mean: -44.963811\n",
      "ep 31: ep_len:505 episode reward: total was -94.500000. running mean: -45.459173\n",
      "ep 31: ep_len:770 episode reward: total was -2.330000. running mean: -45.027881\n",
      "ep 31: ep_len:500 episode reward: total was -7.880000. running mean: -44.656403\n",
      "ep 31: ep_len:705 episode reward: total was -18.840000. running mean: -44.398239\n",
      "ep 31: ep_len:591 episode reward: total was -116.500000. running mean: -45.119256\n",
      "ep 31: ep_len:865 episode reward: total was -44.260000. running mean: -45.110664\n",
      "ep 31: ep_len:525 episode reward: total was -3.040000. running mean: -44.689957\n",
      "ep 31: ep_len:620 episode reward: total was -37.160000. running mean: -44.614657\n",
      "ep 31: ep_len:238 episode reward: total was -9.000000. running mean: -44.258511\n",
      "ep 31: ep_len:167 episode reward: total was -7.000000. running mean: -43.885926\n",
      "ep 31: ep_len:895 episode reward: total was -55.590000. running mean: -44.002966\n",
      "ep 31: ep_len:500 episode reward: total was -16.700000. running mean: -43.729937\n",
      "ep 31: ep_len:1085 episode reward: total was -140.780000. running mean: -44.700437\n",
      "ep 31: ep_len:615 episode reward: total was -24.040000. running mean: -44.493833\n",
      "ep 31: ep_len:500 episode reward: total was -16.740000. running mean: -44.216295\n",
      "ep 31: ep_len:825 episode reward: total was -50.400000. running mean: -44.278132\n",
      "ep 31: ep_len:865 episode reward: total was -18.110000. running mean: -44.016450\n",
      "ep 31: ep_len:525 episode reward: total was -28.250000. running mean: -43.858786\n",
      "ep 31: ep_len:690 episode reward: total was -14.830000. running mean: -43.568498\n",
      "ep 31: ep_len:790 episode reward: total was -14.430000. running mean: -43.277113\n",
      "ep 31: ep_len:545 episode reward: total was -29.260000. running mean: -43.136942\n",
      "ep 31: ep_len:500 episode reward: total was -24.750000. running mean: -42.953073\n",
      "ep 31: ep_len:920 episode reward: total was 2.030000. running mean: -42.503242\n",
      "ep 31: ep_len:500 episode reward: total was -5.670000. running mean: -42.134909\n",
      "ep 31: ep_len:750 episode reward: total was -38.120000. running mean: -42.094760\n",
      "ep 31: ep_len:505 episode reward: total was -24.220000. running mean: -41.916013\n",
      "ep 31: ep_len:500 episode reward: total was -30.750000. running mean: -41.804353\n",
      "ep 31: ep_len:875 episode reward: total was -15.180000. running mean: -41.538109\n",
      "ep 31: ep_len:500 episode reward: total was -5.660000. running mean: -41.179328\n",
      "ep 31: ep_len:169 episode reward: total was -1.500000. running mean: -40.782535\n",
      "ep 31: ep_len:505 episode reward: total was -11.220000. running mean: -40.486909\n",
      "ep 31: ep_len:555 episode reward: total was -22.170000. running mean: -40.303740\n",
      "ep 31: ep_len:630 episode reward: total was -29.090000. running mean: -40.191603\n",
      "ep 31: ep_len:1897 episode reward: total was -180.300000. running mean: -41.592687\n",
      "ep 31: ep_len:860 episode reward: total was 3.510000. running mean: -41.141660\n",
      "ep 31: ep_len:820 episode reward: total was -69.110000. running mean: -41.421343\n",
      "ep 31: ep_len:500 episode reward: total was 21.840000. running mean: -40.788730\n",
      "ep 31: ep_len:500 episode reward: total was 14.690000. running mean: -40.233943\n",
      "ep 31: ep_len:575 episode reward: total was -39.280000. running mean: -40.224403\n",
      "ep 31: ep_len:871 episode reward: total was -144.740000. running mean: -41.269559\n",
      "ep 31: ep_len:500 episode reward: total was 7.300000. running mean: -40.783864\n",
      "ep 31: ep_len:137 episode reward: total was -7.500000. running mean: -40.451025\n",
      "ep 31: ep_len:845 episode reward: total was 16.450000. running mean: -39.882015\n",
      "ep 31: ep_len:630 episode reward: total was -30.400000. running mean: -39.787195\n",
      "ep 31: ep_len:500 episode reward: total was 28.330000. running mean: -39.106023\n",
      "ep 31: ep_len:665 episode reward: total was -15.890000. running mean: -38.873862\n",
      "ep 31: ep_len:500 episode reward: total was -19.830000. running mean: -38.683424\n",
      "ep 31: ep_len:665 episode reward: total was -62.350000. running mean: -38.920090\n",
      "ep 31: ep_len:500 episode reward: total was 25.270000. running mean: -38.278189\n",
      "ep 31: ep_len:520 episode reward: total was -42.440000. running mean: -38.319807\n",
      "ep 31: ep_len:1152 episode reward: total was -80.230000. running mean: -38.738909\n",
      "ep 31: ep_len:645 episode reward: total was -15.130000. running mean: -38.502820\n",
      "ep 31: ep_len:234 episode reward: total was 23.000000. running mean: -37.887791\n",
      "ep 31: ep_len:500 episode reward: total was 21.780000. running mean: -37.291113\n",
      "ep 31: ep_len:500 episode reward: total was 10.850000. running mean: -36.809702\n",
      "ep 31: ep_len:500 episode reward: total was 16.850000. running mean: -36.273105\n",
      "ep 31: ep_len:800 episode reward: total was -31.780000. running mean: -36.228174\n",
      "ep 31: ep_len:500 episode reward: total was -12.180000. running mean: -35.987693\n",
      "ep 31: ep_len:745 episode reward: total was -20.260000. running mean: -35.830416\n",
      "ep 31: ep_len:158 episode reward: total was -6.500000. running mean: -35.537111\n",
      "ep 31: ep_len:935 episode reward: total was -40.780000. running mean: -35.589540\n",
      "ep 31: ep_len:500 episode reward: total was 4.820000. running mean: -35.185445\n",
      "ep 31: ep_len:525 episode reward: total was -11.990000. running mean: -34.953490\n",
      "ep 31: ep_len:800 episode reward: total was -38.850000. running mean: -34.992456\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 31: ep_len:910 episode reward: total was 14.100000. running mean: -34.501531\n",
      "ep 31: ep_len:500 episode reward: total was -20.290000. running mean: -34.359416\n",
      "ep 31: ep_len:595 episode reward: total was -43.300000. running mean: -34.448822\n",
      "ep 31: ep_len:590 episode reward: total was -20.930000. running mean: -34.313633\n",
      "ep 31: ep_len:860 episode reward: total was -5.180000. running mean: -34.022297\n",
      "ep 31: ep_len:500 episode reward: total was 48.500000. running mean: -33.197074\n",
      "ep 31: ep_len:500 episode reward: total was -17.650000. running mean: -33.041603\n",
      "ep 31: ep_len:810 episode reward: total was -16.090000. running mean: -32.872087\n",
      "ep 31: ep_len:143 episode reward: total was 12.500000. running mean: -32.418366\n",
      "ep 31: ep_len:500 episode reward: total was 32.310000. running mean: -31.771083\n",
      "ep 31: ep_len:1240 episode reward: total was -10.160000. running mean: -31.554972\n",
      "ep 31: ep_len:1025 episode reward: total was -8.270000. running mean: -31.322122\n",
      "ep 31: ep_len:500 episode reward: total was 21.350000. running mean: -30.795401\n",
      "ep 31: ep_len:745 episode reward: total was 3.230000. running mean: -30.455147\n",
      "ep 31: ep_len:1500 episode reward: total was -144.110000. running mean: -31.591695\n",
      "ep 31: ep_len:500 episode reward: total was -10.580000. running mean: -31.381579\n",
      "ep 31: ep_len:500 episode reward: total was -36.500000. running mean: -31.432763\n",
      "ep 31: ep_len:500 episode reward: total was -12.040000. running mean: -31.238835\n",
      "ep 31: ep_len:500 episode reward: total was 14.830000. running mean: -30.778147\n",
      "ep 31: ep_len:3107 episode reward: total was -542.250000. running mean: -35.892865\n",
      "ep 31: ep_len:500 episode reward: total was 28.790000. running mean: -35.246037\n",
      "ep 31: ep_len:500 episode reward: total was -4.250000. running mean: -34.936076\n",
      "ep 31: ep_len:1490 episode reward: total was -172.810000. running mean: -36.314815\n",
      "ep 31: ep_len:685 episode reward: total was -38.430000. running mean: -36.335967\n",
      "ep 31: ep_len:500 episode reward: total was -20.900000. running mean: -36.181608\n",
      "ep 31: ep_len:157 episode reward: total was 16.000000. running mean: -35.659792\n",
      "ep 31: ep_len:565 episode reward: total was -21.140000. running mean: -35.514594\n",
      "ep 31: ep_len:700 episode reward: total was -38.530000. running mean: -35.544748\n",
      "ep 31: ep_len:840 episode reward: total was -8.160000. running mean: -35.270900\n",
      "ep 31: ep_len:640 episode reward: total was -49.010000. running mean: -35.408291\n",
      "ep 31: ep_len:500 episode reward: total was 32.310000. running mean: -34.731108\n",
      "ep 31: ep_len:615 episode reward: total was -25.080000. running mean: -34.634597\n",
      "ep 31: ep_len:500 episode reward: total was 48.500000. running mean: -33.803251\n",
      "ep 31: ep_len:500 episode reward: total was 14.670000. running mean: -33.318519\n",
      "ep 31: ep_len:500 episode reward: total was 20.920000. running mean: -32.776134\n",
      "ep 31: ep_len:690 episode reward: total was -36.240000. running mean: -32.810772\n",
      "ep 31: ep_len:970 episode reward: total was 29.330000. running mean: -32.189365\n",
      "ep 31: ep_len:500 episode reward: total was 21.260000. running mean: -31.654871\n",
      "ep 31: ep_len:885 episode reward: total was -17.690000. running mean: -31.515222\n",
      "ep 31: ep_len:800 episode reward: total was 14.720000. running mean: -31.052870\n",
      "ep 31: ep_len:500 episode reward: total was 7.780000. running mean: -30.664541\n",
      "ep 31: ep_len:500 episode reward: total was 28.270000. running mean: -30.075196\n",
      "ep 31: ep_len:695 episode reward: total was -30.460000. running mean: -30.079044\n",
      "ep 31: ep_len:635 episode reward: total was -22.010000. running mean: -29.998353\n",
      "ep 31: ep_len:730 episode reward: total was -5.660000. running mean: -29.754970\n",
      "ep 31: ep_len:690 episode reward: total was -22.260000. running mean: -29.680020\n",
      "ep 31: ep_len:500 episode reward: total was 8.270000. running mean: -29.300520\n",
      "ep 31: ep_len:880 episode reward: total was 10.300000. running mean: -28.904515\n",
      "ep 31: ep_len:640 episode reward: total was -0.790000. running mean: -28.623370\n",
      "ep 31: ep_len:500 episode reward: total was 3.920000. running mean: -28.297936\n",
      "ep 31: ep_len:560 episode reward: total was 10.150000. running mean: -27.913457\n",
      "ep 31: ep_len:500 episode reward: total was 5.060000. running mean: -27.583722\n",
      "ep 31: ep_len:820 episode reward: total was -26.740000. running mean: -27.575285\n",
      "ep 31: ep_len:710 episode reward: total was -5.700000. running mean: -27.356532\n",
      "ep 31: ep_len:131 episode reward: total was 11.500000. running mean: -26.967967\n",
      "ep 31: ep_len:620 episode reward: total was -50.810000. running mean: -27.206387\n",
      "ep 31: ep_len:500 episode reward: total was -33.910000. running mean: -27.273423\n",
      "ep 31: ep_len:500 episode reward: total was 15.810000. running mean: -26.842589\n",
      "ep 31: ep_len:500 episode reward: total was -30.480000. running mean: -26.878963\n",
      "ep 31: ep_len:810 episode reward: total was -37.650000. running mean: -26.986673\n",
      "ep 31: ep_len:545 episode reward: total was -25.460000. running mean: -26.971407\n",
      "ep 31: ep_len:575 episode reward: total was -33.240000. running mean: -27.034093\n",
      "ep 31: ep_len:500 episode reward: total was 45.500000. running mean: -26.308752\n",
      "ep 31: ep_len:500 episode reward: total was -68.000000. running mean: -26.725664\n",
      "ep 31: ep_len:223 episode reward: total was 22.000000. running mean: -26.238407\n",
      "ep 31: ep_len:500 episode reward: total was 30.810000. running mean: -25.667923\n",
      "ep 31: ep_len:45 episode reward: total was 3.000000. running mean: -25.381244\n",
      "ep 31: ep_len:580 episode reward: total was -7.980000. running mean: -25.207232\n",
      "ep 31: ep_len:500 episode reward: total was 29.770000. running mean: -24.657459\n",
      "ep 31: ep_len:500 episode reward: total was 31.760000. running mean: -24.093285\n",
      "ep 31: ep_len:500 episode reward: total was 0.340000. running mean: -23.848952\n",
      "ep 31: ep_len:500 episode reward: total was -3.720000. running mean: -23.647662\n",
      "ep 31: ep_len:660 episode reward: total was -6.810000. running mean: -23.479286\n",
      "ep 31: ep_len:184 episode reward: total was 18.000000. running mean: -23.064493\n",
      "ep 31: ep_len:780 episode reward: total was -10.120000. running mean: -22.935048\n",
      "ep 31: ep_len:250 episode reward: total was 19.000000. running mean: -22.515698\n",
      "ep 31: ep_len:500 episode reward: total was 13.830000. running mean: -22.152241\n",
      "ep 31: ep_len:1384 episode reward: total was -235.160000. running mean: -24.282318\n",
      "ep 31: ep_len:443 episode reward: total was -86.500000. running mean: -24.904495\n",
      "ep 31: ep_len:500 episode reward: total was 22.270000. running mean: -24.432750\n",
      "ep 31: ep_len:500 episode reward: total was 7.210000. running mean: -24.116323\n",
      "ep 31: ep_len:705 episode reward: total was -10.760000. running mean: -23.982759\n",
      "ep 31: ep_len:800 episode reward: total was -24.710000. running mean: -23.990032\n",
      "ep 31: ep_len:815 episode reward: total was -7.110000. running mean: -23.821231\n",
      "ep 31: ep_len:635 episode reward: total was -27.030000. running mean: -23.853319\n",
      "ep 31: ep_len:610 episode reward: total was -9.940000. running mean: -23.714186\n",
      "ep 31: ep_len:510 episode reward: total was -1.590000. running mean: -23.492944\n",
      "ep 31: ep_len:500 episode reward: total was 3.200000. running mean: -23.226015\n",
      "ep 31: ep_len:500 episode reward: total was -0.450000. running mean: -22.998254\n",
      "ep 31: ep_len:950 episode reward: total was -25.820000. running mean: -23.026472\n",
      "ep 31: ep_len:578 episode reward: total was -68.710000. running mean: -23.483307\n",
      "ep 31: ep_len:745 episode reward: total was -19.770000. running mean: -23.446174\n",
      "ep 31: ep_len:1343 episode reward: total was -149.590000. running mean: -24.707612\n",
      "ep 31: ep_len:2206 episode reward: total was -323.220000. running mean: -27.692736\n",
      "ep 31: ep_len:500 episode reward: total was 14.490000. running mean: -27.270909\n",
      "ep 31: ep_len:835 episode reward: total was 11.270000. running mean: -26.885500\n",
      "ep 31: ep_len:500 episode reward: total was 7.550000. running mean: -26.541145\n",
      "ep 31: ep_len:500 episode reward: total was 1.230000. running mean: -26.263433\n",
      "ep 31: ep_len:505 episode reward: total was 14.810000. running mean: -25.852699\n",
      "ep 31: ep_len:505 episode reward: total was -1.240000. running mean: -25.606572\n",
      "ep 31: ep_len:530 episode reward: total was -18.180000. running mean: -25.532306\n",
      "ep 31: ep_len:138 episode reward: total was 13.500000. running mean: -25.141983\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 31: ep_len:805 episode reward: total was -26.720000. running mean: -25.157763\n",
      "ep 31: ep_len:725 episode reward: total was -16.780000. running mean: -25.073986\n",
      "ep 31: ep_len:1329 episode reward: total was -212.130000. running mean: -26.944546\n",
      "ep 31: ep_len:890 episode reward: total was 20.570000. running mean: -26.469400\n",
      "ep 31: ep_len:625 episode reward: total was -56.270000. running mean: -26.767406\n",
      "ep 31: ep_len:500 episode reward: total was 12.270000. running mean: -26.377032\n",
      "ep 31: ep_len:500 episode reward: total was 14.310000. running mean: -25.970162\n",
      "ep 31: ep_len:500 episode reward: total was 32.740000. running mean: -25.383060\n",
      "ep 31: ep_len:500 episode reward: total was -7.190000. running mean: -25.201130\n",
      "ep 31: ep_len:500 episode reward: total was 7.260000. running mean: -24.876519\n",
      "ep 31: ep_len:855 episode reward: total was 8.950000. running mean: -24.538253\n",
      "ep 31: ep_len:725 episode reward: total was 11.730000. running mean: -24.175571\n",
      "ep 31: ep_len:835 episode reward: total was -32.720000. running mean: -24.261015\n",
      "ep 31: ep_len:500 episode reward: total was 23.710000. running mean: -23.781305\n",
      "ep 31: ep_len:600 episode reward: total was -60.460000. running mean: -24.148092\n",
      "ep 31: ep_len:720 episode reward: total was -24.870000. running mean: -24.155311\n",
      "ep 31: ep_len:745 episode reward: total was -20.780000. running mean: -24.121558\n",
      "ep 31: ep_len:500 episode reward: total was 9.070000. running mean: -23.789642\n",
      "ep 31: ep_len:540 episode reward: total was -14.120000. running mean: -23.692946\n",
      "ep 31: ep_len:500 episode reward: total was 50.000000. running mean: -22.956016\n",
      "ep 31: ep_len:975 episode reward: total was 11.320000. running mean: -22.613256\n",
      "ep 31: ep_len:500 episode reward: total was 15.470000. running mean: -22.232424\n",
      "ep 31: ep_len:525 episode reward: total was -7.080000. running mean: -22.080899\n",
      "ep 31: ep_len:520 episode reward: total was -12.140000. running mean: -21.981490\n",
      "ep 31: ep_len:500 episode reward: total was 23.370000. running mean: -21.527976\n",
      "ep 31: ep_len:990 episode reward: total was 0.100000. running mean: -21.311696\n",
      "ep 31: ep_len:500 episode reward: total was 9.220000. running mean: -21.006379\n",
      "ep 31: ep_len:545 episode reward: total was -15.800000. running mean: -20.954315\n",
      "ep 31: ep_len:675 episode reward: total was 28.160000. running mean: -20.463172\n",
      "ep 31: ep_len:505 episode reward: total was -12.170000. running mean: -20.380240\n",
      "ep 31: ep_len:81 episode reward: total was 8.000000. running mean: -20.096438\n",
      "ep 31: ep_len:940 episode reward: total was -48.670000. running mean: -20.382173\n",
      "ep 31: ep_len:500 episode reward: total was 7.790000. running mean: -20.100452\n",
      "ep 31: ep_len:1180 episode reward: total was -159.240000. running mean: -21.491847\n",
      "ep 31: ep_len:1160 episode reward: total was -3.100000. running mean: -21.307929\n",
      "ep 31: ep_len:500 episode reward: total was -0.730000. running mean: -21.102149\n",
      "ep 31: ep_len:156 episode reward: total was 15.500000. running mean: -20.736128\n",
      "ep 31: ep_len:595 episode reward: total was -59.460000. running mean: -21.123367\n",
      "ep 31: ep_len:695 episode reward: total was -29.970000. running mean: -21.211833\n",
      "ep 31: ep_len:162 episode reward: total was 14.500000. running mean: -20.854715\n",
      "ep 31: ep_len:615 episode reward: total was 11.930000. running mean: -20.526867\n",
      "ep 31: ep_len:500 episode reward: total was 11.770000. running mean: -20.203899\n",
      "ep 31: ep_len:500 episode reward: total was 14.370000. running mean: -19.858160\n",
      "ep 31: ep_len:975 episode reward: total was -7.500000. running mean: -19.734578\n",
      "ep 31: ep_len:500 episode reward: total was 15.720000. running mean: -19.380032\n",
      "ep 31: ep_len:269 episode reward: total was 25.000000. running mean: -18.936232\n",
      "ep 31: ep_len:237 episode reward: total was 23.500000. running mean: -18.511870\n",
      "ep 31: ep_len:620 episode reward: total was -5.880000. running mean: -18.385551\n",
      "ep 31: ep_len:650 episode reward: total was -18.950000. running mean: -18.391196\n",
      "ep 31: ep_len:500 episode reward: total was 33.810000. running mean: -17.869184\n",
      "ep 31: ep_len:500 episode reward: total was 10.360000. running mean: -17.586892\n",
      "ep 31: ep_len:500 episode reward: total was 28.270000. running mean: -17.128323\n",
      "ep 31: ep_len:500 episode reward: total was 20.800000. running mean: -16.749040\n",
      "ep 31: ep_len:785 episode reward: total was 6.680000. running mean: -16.514749\n",
      "ep 31: ep_len:500 episode reward: total was -20.130000. running mean: -16.550902\n",
      "ep 31: ep_len:500 episode reward: total was -18.760000. running mean: -16.572993\n",
      "ep 31: ep_len:890 episode reward: total was 8.530000. running mean: -16.321963\n",
      "ep 31: ep_len:1936 episode reward: total was -346.650000. running mean: -19.625243\n",
      "ep 31: ep_len:1185 episode reward: total was -157.260000. running mean: -21.001591\n",
      "ep 31: ep_len:500 episode reward: total was -0.640000. running mean: -20.797975\n",
      "ep 31: ep_len:500 episode reward: total was 24.350000. running mean: -20.346495\n",
      "ep 31: ep_len:570 episode reward: total was -4.970000. running mean: -20.192730\n",
      "ep 31: ep_len:305 episode reward: total was 16.000000. running mean: -19.830803\n",
      "ep 31: ep_len:755 episode reward: total was -10.040000. running mean: -19.732895\n",
      "ep 31: ep_len:1035 episode reward: total was -70.760000. running mean: -20.243166\n",
      "ep 31: ep_len:510 episode reward: total was -16.200000. running mean: -20.202734\n",
      "ep 31: ep_len:439 episode reward: total was 7.990000. running mean: -19.920807\n",
      "ep 31: ep_len:500 episode reward: total was 22.300000. running mean: -19.498599\n",
      "ep 31: ep_len:1150 episode reward: total was -32.620000. running mean: -19.629813\n",
      "ep 31: ep_len:1440 episode reward: total was -115.340000. running mean: -20.586915\n",
      "ep 31: ep_len:735 episode reward: total was -9.690000. running mean: -20.477946\n",
      "ep 31: ep_len:500 episode reward: total was 15.410000. running mean: -20.119066\n",
      "ep 31: ep_len:500 episode reward: total was 5.820000. running mean: -19.859675\n",
      "ep 31: ep_len:575 episode reward: total was -9.000000. running mean: -19.751079\n",
      "ep 31: ep_len:755 episode reward: total was -6.160000. running mean: -19.615168\n",
      "ep 31: ep_len:256 episode reward: total was 25.500000. running mean: -19.164016\n",
      "ep 31: ep_len:1205 episode reward: total was -55.750000. running mean: -19.529876\n",
      "ep 31: ep_len:510 episode reward: total was -13.170000. running mean: -19.466277\n",
      "ep 31: ep_len:735 episode reward: total was -12.400000. running mean: -19.395615\n",
      "ep 31: ep_len:500 episode reward: total was 25.790000. running mean: -18.943758\n",
      "ep 31: ep_len:171 episode reward: total was 17.000000. running mean: -18.584321\n",
      "ep 31: ep_len:500 episode reward: total was 22.940000. running mean: -18.169078\n",
      "ep 31: ep_len:705 episode reward: total was -24.900000. running mean: -18.236387\n",
      "ep 31: ep_len:500 episode reward: total was 7.210000. running mean: -17.981923\n",
      "ep 31: ep_len:570 episode reward: total was 5.050000. running mean: -17.751604\n",
      "ep 31: ep_len:555 episode reward: total was -11.060000. running mean: -17.684688\n",
      "ep 31: ep_len:223 episode reward: total was 22.000000. running mean: -17.287841\n",
      "ep 31: ep_len:273 episode reward: total was 20.000000. running mean: -16.914962\n",
      "ep 31: ep_len:1768 episode reward: total was -220.720000. running mean: -18.953013\n",
      "ep 31: ep_len:720 episode reward: total was -0.120000. running mean: -18.764683\n",
      "ep 31: ep_len:500 episode reward: total was 7.690000. running mean: -18.500136\n",
      "ep 31: ep_len:500 episode reward: total was -6.640000. running mean: -18.381534\n",
      "ep 31: ep_len:133 episode reward: total was 13.000000. running mean: -18.067719\n",
      "ep 31: ep_len:500 episode reward: total was 11.920000. running mean: -17.767842\n",
      "ep 31: ep_len:795 episode reward: total was -120.190000. running mean: -18.792063\n",
      "ep 31: ep_len:208 episode reward: total was 20.500000. running mean: -18.399143\n",
      "ep 31: ep_len:755 episode reward: total was -22.190000. running mean: -18.437051\n",
      "ep 31: ep_len:500 episode reward: total was 9.690000. running mean: -18.155781\n",
      "ep 31: ep_len:860 episode reward: total was -36.340000. running mean: -18.337623\n",
      "ep 31: ep_len:535 episode reward: total was -17.130000. running mean: -18.325547\n",
      "ep 31: ep_len:590 episode reward: total was 17.680000. running mean: -17.965491\n",
      "ep 31: ep_len:2270 episode reward: total was -280.110000. running mean: -20.586936\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 31: ep_len:800 episode reward: total was -47.420000. running mean: -20.855267\n",
      "ep 31: ep_len:685 episode reward: total was 6.780000. running mean: -20.578914\n",
      "ep 31: ep_len:500 episode reward: total was 30.290000. running mean: -20.070225\n",
      "ep 31: ep_len:675 episode reward: total was -33.860000. running mean: -20.208123\n",
      "ep 31: ep_len:1030 episode reward: total was -96.080000. running mean: -20.966842\n",
      "ep 31: ep_len:665 episode reward: total was -43.260000. running mean: -21.189773\n",
      "ep 31: ep_len:1010 episode reward: total was -28.330000. running mean: -21.261176\n",
      "ep 31: ep_len:500 episode reward: total was 6.750000. running mean: -20.981064\n",
      "ep 31: ep_len:965 episode reward: total was 8.480000. running mean: -20.686453\n",
      "ep 31: ep_len:257 episode reward: total was 25.500000. running mean: -20.224589\n",
      "ep 31: ep_len:890 episode reward: total was -11.560000. running mean: -20.137943\n",
      "ep 31: ep_len:545 episode reward: total was -21.180000. running mean: -20.148363\n",
      "ep 31: ep_len:720 episode reward: total was -4.670000. running mean: -19.993580\n",
      "ep 31: ep_len:530 episode reward: total was -7.070000. running mean: -19.864344\n",
      "ep 31: ep_len:219 episode reward: total was 20.000000. running mean: -19.465701\n",
      "ep 31: ep_len:122 episode reward: total was 12.000000. running mean: -19.151044\n",
      "ep 31: ep_len:505 episode reward: total was -7.120000. running mean: -19.030733\n",
      "ep 31: ep_len:500 episode reward: total was -0.670000. running mean: -18.847126\n",
      "ep 31: ep_len:369 episode reward: total was 35.000000. running mean: -18.308655\n",
      "ep 31: ep_len:1670 episode reward: total was -124.980000. running mean: -19.375368\n",
      "ep 31: ep_len:210 episode reward: total was 19.500000. running mean: -18.986614\n",
      "ep 31: ep_len:995 episode reward: total was -99.550000. running mean: -19.792248\n",
      "ep 31: ep_len:905 episode reward: total was -39.130000. running mean: -19.985626\n",
      "ep 31: ep_len:580 episode reward: total was -85.720000. running mean: -20.642969\n",
      "ep 31: ep_len:1349 episode reward: total was -243.800000. running mean: -22.874540\n",
      "ep 31: ep_len:935 episode reward: total was 16.800000. running mean: -22.477794\n",
      "ep 31: ep_len:500 episode reward: total was -6.260000. running mean: -22.315616\n",
      "ep 31: ep_len:500 episode reward: total was 24.320000. running mean: -21.849260\n",
      "ep 31: ep_len:274 episode reward: total was 27.000000. running mean: -21.360768\n",
      "ep 31: ep_len:720 episode reward: total was -115.740000. running mean: -22.304560\n",
      "ep 31: ep_len:500 episode reward: total was 6.780000. running mean: -22.013714\n",
      "ep 31: ep_len:500 episode reward: total was 7.950000. running mean: -21.714077\n",
      "ep 31: ep_len:700 episode reward: total was -82.500000. running mean: -22.321936\n",
      "ep 31: ep_len:965 episode reward: total was -97.270000. running mean: -23.071417\n",
      "ep 31: ep_len:795 episode reward: total was 29.790000. running mean: -22.542803\n",
      "ep 31: ep_len:865 episode reward: total was 11.300000. running mean: -22.204375\n",
      "ep 31: ep_len:555 episode reward: total was -3.990000. running mean: -22.022231\n",
      "ep 31: ep_len:500 episode reward: total was 23.740000. running mean: -21.564609\n",
      "ep 31: ep_len:1095 episode reward: total was -48.660000. running mean: -21.835563\n",
      "ep 31: ep_len:192 episode reward: total was 19.000000. running mean: -21.427207\n",
      "ep 31: ep_len:500 episode reward: total was -10.340000. running mean: -21.316335\n",
      "ep 31: ep_len:410 episode reward: total was 3.930000. running mean: -21.063872\n",
      "ep 31: ep_len:311 episode reward: total was 12.730000. running mean: -20.725933\n",
      "ep 31: ep_len:775 episode reward: total was 31.700000. running mean: -20.201674\n",
      "ep 31: ep_len:500 episode reward: total was 7.340000. running mean: -19.926257\n",
      "ep 31: ep_len:1050 episode reward: total was -9.390000. running mean: -19.820894\n",
      "ep 31: ep_len:490 episode reward: total was -48.620000. running mean: -20.108885\n",
      "ep 31: ep_len:500 episode reward: total was 48.500000. running mean: -19.422797\n",
      "ep 31: ep_len:139 episode reward: total was 12.000000. running mean: -19.108569\n",
      "ep 31: ep_len:785 episode reward: total was 6.990000. running mean: -18.847583\n",
      "ep 31: ep_len:505 episode reward: total was -67.720000. running mean: -19.336307\n",
      "ep 31: ep_len:500 episode reward: total was 1.410000. running mean: -19.128844\n",
      "ep 31: ep_len:1060 episode reward: total was 15.840000. running mean: -18.779156\n",
      "ep 31: ep_len:730 episode reward: total was -5.660000. running mean: -18.647964\n",
      "ep 31: ep_len:1645 episode reward: total was -71.500000. running mean: -19.176484\n",
      "ep 31: ep_len:610 episode reward: total was -50.340000. running mean: -19.488119\n",
      "ep 31: ep_len:306 episode reward: total was 30.500000. running mean: -18.988238\n",
      "ep 31: ep_len:605 episode reward: total was -18.000000. running mean: -18.978356\n",
      "ep 31: ep_len:500 episode reward: total was 5.640000. running mean: -18.732172\n",
      "ep 31: ep_len:510 episode reward: total was -9.280000. running mean: -18.637651\n",
      "ep 31: ep_len:500 episode reward: total was -14.930000. running mean: -18.600574\n",
      "ep 31: ep_len:967 episode reward: total was -185.500000. running mean: -20.269568\n",
      "ep 31: ep_len:565 episode reward: total was 9.000000. running mean: -19.976873\n",
      "ep 31: ep_len:2035 episode reward: total was -151.520000. running mean: -21.292304\n",
      "ep 31: ep_len:500 episode reward: total was 0.680000. running mean: -21.072581\n",
      "ep 31: ep_len:510 episode reward: total was -14.180000. running mean: -21.003655\n",
      "ep 31: ep_len:1700 episode reward: total was 13.220000. running mean: -20.661419\n",
      "ep 31: ep_len:500 episode reward: total was 26.770000. running mean: -20.187104\n",
      "ep 31: ep_len:690 episode reward: total was -39.070000. running mean: -20.375933\n",
      "ep 31: ep_len:850 episode reward: total was 2.240000. running mean: -20.149774\n",
      "ep 31: ep_len:500 episode reward: total was 48.500000. running mean: -19.463276\n",
      "ep 31: ep_len:1080 episode reward: total was -82.730000. running mean: -20.095944\n",
      "ep 31: ep_len:500 episode reward: total was 5.270000. running mean: -19.842284\n",
      "ep 31: ep_len:1570 episode reward: total was -28.220000. running mean: -19.926061\n",
      "ep 31: ep_len:182 episode reward: total was 16.500000. running mean: -19.561801\n",
      "ep 31: ep_len:500 episode reward: total was 14.770000. running mean: -19.218483\n",
      "ep 31: ep_len:500 episode reward: total was 45.500000. running mean: -18.571298\n",
      "ep 31: ep_len:850 episode reward: total was -21.060000. running mean: -18.596185\n",
      "ep 31: ep_len:500 episode reward: total was 18.260000. running mean: -18.227623\n",
      "ep 31: ep_len:500 episode reward: total was 13.360000. running mean: -17.911747\n",
      "ep 31: ep_len:930 episode reward: total was 16.420000. running mean: -17.568429\n",
      "ep 31: ep_len:840 episode reward: total was 8.430000. running mean: -17.308445\n",
      "ep 31: ep_len:745 episode reward: total was -6.640000. running mean: -17.201761\n",
      "ep 31: ep_len:1680 episode reward: total was -255.230000. running mean: -19.582043\n",
      "ep 31: ep_len:344 episode reward: total was 32.500000. running mean: -19.061222\n",
      "ep 31: ep_len:500 episode reward: total was -38.730000. running mean: -19.257910\n",
      "ep 31: ep_len:1205 episode reward: total was 18.110000. running mean: -18.884231\n",
      "ep 31: ep_len:500 episode reward: total was 22.260000. running mean: -18.472789\n",
      "ep 31: ep_len:161 episode reward: total was 16.500000. running mean: -18.123061\n",
      "ep 31: ep_len:1085 episode reward: total was -2.710000. running mean: -17.968930\n",
      "ep 31: ep_len:955 episode reward: total was 4.360000. running mean: -17.745641\n",
      "ep 31: ep_len:500 episode reward: total was 12.870000. running mean: -17.439485\n",
      "ep 31: ep_len:1670 episode reward: total was -68.070000. running mean: -17.945790\n",
      "ep 31: ep_len:500 episode reward: total was 8.670000. running mean: -17.679632\n",
      "ep 31: ep_len:143 episode reward: total was 14.000000. running mean: -17.362836\n",
      "ep 31: ep_len:520 episode reward: total was -11.130000. running mean: -17.300507\n",
      "ep 31: ep_len:1221 episode reward: total was -24.700000. running mean: -17.374502\n",
      "ep 31: ep_len:580 episode reward: total was 15.240000. running mean: -17.048357\n",
      "ep 31: ep_len:945 episode reward: total was 2.660000. running mean: -16.851274\n",
      "ep 31: ep_len:1010 episode reward: total was -102.060000. running mean: -17.703361\n",
      "ep 31: ep_len:1465 episode reward: total was -170.810000. running mean: -19.234427\n",
      "ep 31: ep_len:500 episode reward: total was 20.280000. running mean: -18.839283\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 31: ep_len:500 episode reward: total was -30.270000. running mean: -18.953590\n",
      "ep 31: ep_len:525 episode reward: total was -21.220000. running mean: -18.976254\n",
      "ep 31: ep_len:500 episode reward: total was 25.850000. running mean: -18.527992\n",
      "ep 31: ep_len:1670 episode reward: total was -27.290000. running mean: -18.615612\n",
      "ep 31: ep_len:1760 episode reward: total was -71.270000. running mean: -19.142156\n",
      "ep 31: ep_len:500 episode reward: total was 1.400000. running mean: -18.936734\n",
      "ep 31: ep_len:500 episode reward: total was 11.350000. running mean: -18.633867\n",
      "ep 31: ep_len:800 episode reward: total was -1.280000. running mean: -18.460328\n",
      "ep 31: ep_len:500 episode reward: total was 18.230000. running mean: -18.093425\n",
      "ep 31: ep_len:590 episode reward: total was 8.220000. running mean: -17.830291\n",
      "ep 31: ep_len:183 episode reward: total was 18.000000. running mean: -17.471988\n",
      "ep 31: ep_len:830 episode reward: total was 22.090000. running mean: -17.076368\n",
      "ep 31: ep_len:705 episode reward: total was -70.350000. running mean: -17.609104\n",
      "ep 31: ep_len:1105 episode reward: total was 11.910000. running mean: -17.313913\n",
      "ep 31: ep_len:660 episode reward: total was 24.490000. running mean: -16.895874\n",
      "ep 31: ep_len:500 episode reward: total was 17.830000. running mean: -16.548615\n",
      "ep 31: ep_len:620 episode reward: total was 20.520000. running mean: -16.177929\n",
      "ep 31: ep_len:925 episode reward: total was -10.500000. running mean: -16.121150\n",
      "ep 31: ep_len:1015 episode reward: total was 15.400000. running mean: -15.805938\n",
      "ep 31: ep_len:464 episode reward: total was 28.740000. running mean: -15.360479\n",
      "ep 31: ep_len:705 episode reward: total was -7.160000. running mean: -15.278474\n",
      "ep 31: ep_len:515 episode reward: total was -28.310000. running mean: -15.408789\n",
      "ep 31: ep_len:500 episode reward: total was 22.790000. running mean: -15.026801\n",
      "ep 31: ep_len:500 episode reward: total was 10.540000. running mean: -14.771133\n",
      "ep 31: ep_len:695 episode reward: total was -8.240000. running mean: -14.705822\n",
      "ep 31: ep_len:930 episode reward: total was -56.790000. running mean: -15.126664\n",
      "ep 31: ep_len:585 episode reward: total was -17.060000. running mean: -15.145997\n",
      "ep 31: ep_len:500 episode reward: total was 2.760000. running mean: -14.966937\n",
      "ep 31: ep_len:500 episode reward: total was 15.840000. running mean: -14.658868\n",
      "ep 31: ep_len:1675 episode reward: total was -242.110000. running mean: -16.933379\n",
      "ep 31: ep_len:705 episode reward: total was -0.660000. running mean: -16.770645\n",
      "ep 31: ep_len:660 episode reward: total was 29.820000. running mean: -16.304739\n",
      "ep 31: ep_len:500 episode reward: total was 0.350000. running mean: -16.138192\n",
      "ep 31: ep_len:675 episode reward: total was -1.730000. running mean: -15.994110\n",
      "ep 31: ep_len:510 episode reward: total was 13.610000. running mean: -15.698069\n",
      "ep 31: ep_len:615 episode reward: total was -38.210000. running mean: -15.923188\n",
      "ep 31: ep_len:745 episode reward: total was -14.200000. running mean: -15.905956\n",
      "ep 31: ep_len:635 episode reward: total was 2.820000. running mean: -15.718696\n",
      "ep 31: ep_len:615 episode reward: total was -40.700000. running mean: -15.968509\n",
      "ep 31: ep_len:361 episode reward: total was -1.000000. running mean: -15.818824\n",
      "ep 31: ep_len:500 episode reward: total was 13.260000. running mean: -15.528036\n",
      "ep 31: ep_len:790 episode reward: total was 4.650000. running mean: -15.326256\n",
      "ep 31: ep_len:530 episode reward: total was -4.040000. running mean: -15.213393\n",
      "ep 31: ep_len:500 episode reward: total was 17.280000. running mean: -14.888459\n",
      "ep 31: ep_len:665 episode reward: total was -81.500000. running mean: -15.554575\n",
      "ep 31: ep_len:500 episode reward: total was 4.320000. running mean: -15.355829\n",
      "ep 31: ep_len:555 episode reward: total was -0.250000. running mean: -15.204771\n",
      "ep 31: ep_len:500 episode reward: total was 19.330000. running mean: -14.859423\n",
      "ep 31: ep_len:500 episode reward: total was 13.480000. running mean: -14.576029\n",
      "ep 31: ep_len:500 episode reward: total was -2.320000. running mean: -14.453468\n",
      "ep 31: ep_len:259 episode reward: total was 19.500000. running mean: -14.113934\n",
      "ep 31: ep_len:500 episode reward: total was 47.000000. running mean: -13.502794\n",
      "ep 31: ep_len:775 episode reward: total was -17.690000. running mean: -13.544666\n",
      "ep 31: ep_len:500 episode reward: total was 2.210000. running mean: -13.387120\n",
      "ep 31: ep_len:845 episode reward: total was 23.020000. running mean: -13.023049\n",
      "ep 31: ep_len:500 episode reward: total was -21.910000. running mean: -13.111918\n",
      "ep 31: ep_len:550 episode reward: total was 24.730000. running mean: -12.733499\n",
      "ep 31: ep_len:700 episode reward: total was -6.730000. running mean: -12.673464\n",
      "ep 31: ep_len:500 episode reward: total was 7.350000. running mean: -12.473229\n",
      "ep 31: ep_len:228 episode reward: total was 23.000000. running mean: -12.118497\n",
      "ep 31: ep_len:500 episode reward: total was -3.540000. running mean: -12.032712\n",
      "ep 31: ep_len:500 episode reward: total was 12.620000. running mean: -11.786185\n",
      "ep 31: ep_len:1120 episode reward: total was -50.350000. running mean: -12.171823\n",
      "ep 31: ep_len:665 episode reward: total was -19.990000. running mean: -12.250005\n",
      "ep 31: ep_len:500 episode reward: total was 18.930000. running mean: -11.938205\n",
      "ep 31: ep_len:461 episode reward: total was 19.770000. running mean: -11.621123\n",
      "ep 31: ep_len:500 episode reward: total was -2.590000. running mean: -11.530812\n",
      "ep 31: ep_len:500 episode reward: total was 6.070000. running mean: -11.354803\n",
      "ep 31: ep_len:820 episode reward: total was -3.670000. running mean: -11.277955\n",
      "ep 31: ep_len:875 episode reward: total was -19.900000. running mean: -11.364176\n",
      "ep 31: ep_len:815 episode reward: total was -76.190000. running mean: -12.012434\n",
      "ep 31: ep_len:500 episode reward: total was 6.620000. running mean: -11.826110\n",
      "ep 31: ep_len:1905 episode reward: total was -160.870000. running mean: -13.316549\n",
      "ep 31: ep_len:735 episode reward: total was -28.880000. running mean: -13.472183\n",
      "ep 31: ep_len:1075 episode reward: total was -95.840000. running mean: -14.295861\n",
      "ep 31: ep_len:1025 episode reward: total was -51.530000. running mean: -14.668203\n",
      "ep 31: ep_len:690 episode reward: total was -3.930000. running mean: -14.560821\n",
      "ep 31: ep_len:356 episode reward: total was -52.460000. running mean: -14.939812\n",
      "ep 31: ep_len:735 episode reward: total was -12.690000. running mean: -14.917314\n",
      "ep 31: ep_len:500 episode reward: total was 8.610000. running mean: -14.682041\n",
      "ep 31: ep_len:930 episode reward: total was -1.670000. running mean: -14.551921\n",
      "ep 31: ep_len:500 episode reward: total was -22.950000. running mean: -14.635902\n",
      "ep 31: ep_len:500 episode reward: total was 26.740000. running mean: -14.222143\n",
      "ep 31: ep_len:995 episode reward: total was -25.110000. running mean: -14.331021\n",
      "ep 31: ep_len:500 episode reward: total was 3.260000. running mean: -14.155111\n",
      "ep 31: ep_len:500 episode reward: total was 5.070000. running mean: -13.962860\n",
      "ep 31: ep_len:500 episode reward: total was 9.260000. running mean: -13.730631\n",
      "ep 31: ep_len:525 episode reward: total was -5.550000. running mean: -13.648825\n",
      "ep 31: ep_len:605 episode reward: total was -4.900000. running mean: -13.561337\n",
      "ep 31: ep_len:500 episode reward: total was 24.290000. running mean: -13.182823\n",
      "ep 31: ep_len:510 episode reward: total was -2.060000. running mean: -13.071595\n",
      "ep 31: ep_len:625 episode reward: total was -19.490000. running mean: -13.135779\n",
      "ep 31: ep_len:1450 episode reward: total was -57.750000. running mean: -13.581921\n",
      "ep 31: ep_len:500 episode reward: total was 20.770000. running mean: -13.238402\n",
      "ep 31: ep_len:402 episode reward: total was 37.000000. running mean: -12.736018\n",
      "ep 31: ep_len:560 episode reward: total was 20.770000. running mean: -12.400958\n",
      "ep 31: ep_len:640 episode reward: total was -15.940000. running mean: -12.436348\n",
      "ep 31: ep_len:500 episode reward: total was -6.120000. running mean: -12.373185\n",
      "ep 31: ep_len:505 episode reward: total was 19.190000. running mean: -12.057553\n",
      "ep 31: ep_len:1455 episode reward: total was -129.970000. running mean: -13.236677\n",
      "ep 31: ep_len:540 episode reward: total was 16.470000. running mean: -12.939611\n",
      "ep 31: ep_len:1580 episode reward: total was -129.990000. running mean: -14.110115\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 31: ep_len:980 episode reward: total was -51.620000. running mean: -14.485213\n",
      "ep 31: ep_len:765 episode reward: total was -31.850000. running mean: -14.658861\n",
      "ep 31: ep_len:492 episode reward: total was -49.550000. running mean: -15.007773\n",
      "ep 31: ep_len:705 episode reward: total was -5.190000. running mean: -14.909595\n",
      "ep 31: ep_len:530 episode reward: total was -16.130000. running mean: -14.921799\n",
      "ep 31: ep_len:481 episode reward: total was -1.200000. running mean: -14.784581\n",
      "ep 31: ep_len:600 episode reward: total was -20.060000. running mean: -14.837335\n",
      "ep 31: ep_len:760 episode reward: total was -13.770000. running mean: -14.826662\n",
      "ep 31: ep_len:635 episode reward: total was 2.760000. running mean: -14.650795\n",
      "ep 31: ep_len:167 episode reward: total was 16.500000. running mean: -14.339287\n",
      "ep 31: ep_len:500 episode reward: total was 21.070000. running mean: -13.985194\n",
      "ep 31: ep_len:535 episode reward: total was -53.520000. running mean: -14.380542\n",
      "ep 31: ep_len:500 episode reward: total was 14.090000. running mean: -14.095837\n",
      "ep 31: ep_len:800 episode reward: total was 16.360000. running mean: -13.791279\n",
      "ep 31: ep_len:885 episode reward: total was 9.090000. running mean: -13.562466\n",
      "ep 31: ep_len:590 episode reward: total was -39.270000. running mean: -13.819541\n",
      "ep 31: ep_len:1025 episode reward: total was -44.230000. running mean: -14.123646\n",
      "ep 31: ep_len:1262 episode reward: total was -141.050000. running mean: -15.392909\n",
      "ep 31: ep_len:500 episode reward: total was 9.870000. running mean: -15.140280\n",
      "ep 31: ep_len:500 episode reward: total was 16.940000. running mean: -14.819477\n",
      "ep 31: ep_len:383 episode reward: total was 13.270000. running mean: -14.538583\n",
      "ep 31: ep_len:85 episode reward: total was 7.000000. running mean: -14.323197\n",
      "ep 31: ep_len:198 episode reward: total was 20.000000. running mean: -13.979965\n",
      "ep 31: ep_len:500 episode reward: total was 30.750000. running mean: -13.532665\n",
      "ep 31: ep_len:810 episode reward: total was -11.560000. running mean: -13.512939\n",
      "ep 31: ep_len:685 episode reward: total was -31.000000. running mean: -13.687809\n",
      "ep 31: ep_len:259 episode reward: total was 25.500000. running mean: -13.295931\n",
      "ep 31: ep_len:500 episode reward: total was 23.740000. running mean: -12.925572\n",
      "ep 31: ep_len:500 episode reward: total was -22.060000. running mean: -13.016916\n",
      "ep 31: ep_len:220 episode reward: total was 19.000000. running mean: -12.696747\n",
      "ep 31: ep_len:1575 episode reward: total was -109.010000. running mean: -13.659879\n",
      "ep 31: ep_len:207 episode reward: total was 19.500000. running mean: -13.328281\n",
      "ep 31: ep_len:100 episode reward: total was 8.500000. running mean: -13.109998\n",
      "ep 31: ep_len:780 episode reward: total was 31.590000. running mean: -12.662998\n",
      "ep 31: ep_len:700 episode reward: total was -19.860000. running mean: -12.734968\n",
      "ep 31: ep_len:172 episode reward: total was 16.000000. running mean: -12.447618\n",
      "ep 31: ep_len:510 episode reward: total was 14.280000. running mean: -12.180342\n",
      "ep 31: ep_len:905 episode reward: total was -158.830000. running mean: -13.646839\n",
      "ep 31: ep_len:1030 episode reward: total was 2.090000. running mean: -13.489470\n",
      "ep 31: ep_len:150 episode reward: total was 13.500000. running mean: -13.219576\n",
      "ep 31: ep_len:500 episode reward: total was 4.700000. running mean: -13.040380\n",
      "ep 31: ep_len:805 episode reward: total was -6.060000. running mean: -12.970576\n",
      "ep 31: ep_len:500 episode reward: total was 24.260000. running mean: -12.598270\n",
      "ep 31: ep_len:505 episode reward: total was 11.780000. running mean: -12.354487\n",
      "ep 31: ep_len:228 episode reward: total was 22.500000. running mean: -12.005943\n",
      "ep 31: ep_len:233 episode reward: total was 23.000000. running mean: -11.655883\n",
      "ep 31: ep_len:750 episode reward: total was 14.730000. running mean: -11.392024\n",
      "ep 31: ep_len:700 episode reward: total was -3.270000. running mean: -11.310804\n",
      "ep 31: ep_len:805 episode reward: total was -15.610000. running mean: -11.353796\n",
      "ep 31: ep_len:1030 episode reward: total was 4.930000. running mean: -11.190958\n",
      "ep 31: ep_len:565 episode reward: total was -8.010000. running mean: -11.159149\n",
      "ep 31: ep_len:500 episode reward: total was 18.210000. running mean: -10.865457\n",
      "ep 31: ep_len:570 episode reward: total was -36.280000. running mean: -11.119602\n",
      "ep 31: ep_len:510 episode reward: total was -32.360000. running mean: -11.332006\n",
      "ep 31: ep_len:500 episode reward: total was 3.630000. running mean: -11.182386\n",
      "ep 31: ep_len:715 episode reward: total was -20.840000. running mean: -11.278963\n",
      "ep 31: ep_len:1260 episode reward: total was -102.570000. running mean: -12.191873\n",
      "ep 31: ep_len:500 episode reward: total was 5.670000. running mean: -12.013254\n",
      "ep 31: ep_len:535 episode reward: total was -25.240000. running mean: -12.145522\n",
      "ep 31: ep_len:570 episode reward: total was -70.620000. running mean: -12.730266\n",
      "ep 31: ep_len:500 episode reward: total was 15.350000. running mean: -12.449464\n",
      "ep 31: ep_len:217 episode reward: total was 21.500000. running mean: -12.109969\n",
      "ep 31: ep_len:740 episode reward: total was 2.130000. running mean: -11.967569\n",
      "ep 31: ep_len:500 episode reward: total was 27.750000. running mean: -11.570394\n",
      "ep 31: ep_len:500 episode reward: total was -7.000000. running mean: -11.524690\n",
      "ep 31: ep_len:500 episode reward: total was 23.370000. running mean: -11.175743\n",
      "ep 31: ep_len:510 episode reward: total was -5.150000. running mean: -11.115485\n",
      "ep 31: ep_len:500 episode reward: total was 14.150000. running mean: -10.862831\n",
      "ep 31: ep_len:515 episode reward: total was 28.790000. running mean: -10.466302\n",
      "ep 31: ep_len:500 episode reward: total was 24.230000. running mean: -10.119339\n",
      "ep 31: ep_len:670 episode reward: total was -1.740000. running mean: -10.035546\n",
      "ep 31: ep_len:500 episode reward: total was 10.140000. running mean: -9.833790\n",
      "ep 31: ep_len:500 episode reward: total was 20.280000. running mean: -9.532653\n",
      "ep 31: ep_len:500 episode reward: total was -1.400000. running mean: -9.451326\n",
      "ep 31: ep_len:1100 episode reward: total was -34.510000. running mean: -9.701913\n",
      "ep 31: ep_len:500 episode reward: total was -19.770000. running mean: -9.802594\n",
      "ep 31: ep_len:975 episode reward: total was 27.750000. running mean: -9.427068\n",
      "ep 31: ep_len:413 episode reward: total was 23.250000. running mean: -9.100297\n",
      "ep 31: ep_len:575 episode reward: total was -38.290000. running mean: -9.392194\n",
      "ep 31: ep_len:218 episode reward: total was 22.000000. running mean: -9.078272\n",
      "ep 31: ep_len:750 episode reward: total was -34.910000. running mean: -9.336589\n",
      "ep 31: ep_len:670 episode reward: total was -20.930000. running mean: -9.452523\n",
      "ep 31: ep_len:224 episode reward: total was 22.000000. running mean: -9.137998\n",
      "ep 31: ep_len:500 episode reward: total was 22.760000. running mean: -8.819018\n",
      "ep 31: ep_len:2137 episode reward: total was -331.080000. running mean: -12.041628\n",
      "ep 31: ep_len:505 episode reward: total was 47.500000. running mean: -11.446212\n",
      "ep 31: ep_len:610 episode reward: total was -2.870000. running mean: -11.360450\n",
      "ep 31: ep_len:1020 episode reward: total was 19.310000. running mean: -11.053745\n",
      "ep 31: ep_len:500 episode reward: total was -5.260000. running mean: -10.995808\n",
      "ep 31: ep_len:760 episode reward: total was -3.380000. running mean: -10.919650\n",
      "ep 31: ep_len:985 episode reward: total was 7.350000. running mean: -10.736953\n",
      "ep 31: ep_len:555 episode reward: total was -10.050000. running mean: -10.730084\n",
      "ep 31: ep_len:758 episode reward: total was -66.760000. running mean: -11.290383\n",
      "ep 31: ep_len:184 episode reward: total was 18.000000. running mean: -10.997479\n",
      "ep 31: ep_len:500 episode reward: total was 0.860000. running mean: -10.878904\n",
      "ep 31: ep_len:500 episode reward: total was 28.270000. running mean: -10.487415\n",
      "ep 31: ep_len:244 episode reward: total was 24.000000. running mean: -10.142541\n",
      "ep 31: ep_len:600 episode reward: total was 19.590000. running mean: -9.845216\n",
      "ep 31: ep_len:500 episode reward: total was -11.750000. running mean: -9.864263\n",
      "ep 31: ep_len:1835 episode reward: total was -120.610000. running mean: -10.971721\n",
      "ep 31: ep_len:1080 episode reward: total was -37.760000. running mean: -11.239604\n",
      "ep 31: ep_len:545 episode reward: total was 19.360000. running mean: -10.933608\n",
      "ep 31: ep_len:750 episode reward: total was -10.670000. running mean: -10.930971\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 31: ep_len:755 episode reward: total was 6.700000. running mean: -10.754662\n",
      "ep 31: ep_len:500 episode reward: total was -11.260000. running mean: -10.759715\n",
      "ep 31: ep_len:293 episode reward: total was 29.000000. running mean: -10.362118\n",
      "ep 31: ep_len:500 episode reward: total was 25.940000. running mean: -9.999097\n",
      "ep 31: ep_len:500 episode reward: total was 50.000000. running mean: -9.399106\n",
      "ep 31: ep_len:500 episode reward: total was 16.600000. running mean: -9.139115\n",
      "ep 31: ep_len:500 episode reward: total was 11.670000. running mean: -8.931024\n",
      "ep 31: ep_len:500 episode reward: total was 23.280000. running mean: -8.608913\n",
      "ep 31: ep_len:500 episode reward: total was -54.500000. running mean: -9.067824\n",
      "ep 31: ep_len:714 episode reward: total was -124.860000. running mean: -10.225746\n",
      "ep 31: ep_len:695 episode reward: total was -4.720000. running mean: -10.170689\n",
      "ep 31: ep_len:1255 episode reward: total was -123.790000. running mean: -11.306882\n",
      "ep 31: ep_len:1090 episode reward: total was 13.410000. running mean: -11.059713\n",
      "ep 31: ep_len:595 episode reward: total was -25.120000. running mean: -11.200316\n",
      "ep 31: ep_len:715 episode reward: total was -5.690000. running mean: -11.145213\n",
      "ep 31: ep_len:446 episode reward: total was 10.770000. running mean: -10.926060\n",
      "ep 31: ep_len:500 episode reward: total was 7.790000. running mean: -10.738900\n",
      "ep 31: ep_len:690 episode reward: total was -12.810000. running mean: -10.759611\n",
      "ep 31: ep_len:570 episode reward: total was 5.660000. running mean: -10.595415\n",
      "ep 31: ep_len:1284 episode reward: total was -166.170000. running mean: -12.151161\n",
      "ep 31: ep_len:515 episode reward: total was -3.880000. running mean: -12.068449\n",
      "ep 31: ep_len:126 episode reward: total was 12.500000. running mean: -11.822764\n",
      "ep 31: ep_len:855 episode reward: total was -19.550000. running mean: -11.900037\n",
      "ep 31: ep_len:905 episode reward: total was -1.140000. running mean: -11.792436\n",
      "ep 31: ep_len:500 episode reward: total was 21.070000. running mean: -11.463812\n",
      "ep 31: ep_len:840 episode reward: total was -0.750000. running mean: -11.356674\n",
      "ep 31: ep_len:500 episode reward: total was 5.980000. running mean: -11.183307\n",
      "ep 31: ep_len:500 episode reward: total was 20.250000. running mean: -10.868974\n",
      "ep 31: ep_len:995 episode reward: total was 7.660000. running mean: -10.683684\n",
      "ep 31: ep_len:705 episode reward: total was 23.140000. running mean: -10.345448\n",
      "ep 31: ep_len:1190 episode reward: total was -18.960000. running mean: -10.431593\n",
      "ep 31: ep_len:740 episode reward: total was 23.460000. running mean: -10.092677\n",
      "ep 31: ep_len:500 episode reward: total was -17.260000. running mean: -10.164350\n",
      "ep 31: ep_len:860 episode reward: total was -12.970000. running mean: -10.192407\n",
      "ep 31: ep_len:311 episode reward: total was 29.500000. running mean: -9.795483\n",
      "ep 31: ep_len:245 episode reward: total was 21.500000. running mean: -9.482528\n",
      "ep 31: ep_len:510 episode reward: total was -20.300000. running mean: -9.590703\n",
      "ep 31: ep_len:500 episode reward: total was -11.860000. running mean: -9.613396\n",
      "ep 31: ep_len:500 episode reward: total was 41.160000. running mean: -9.105662\n",
      "ep 31: ep_len:500 episode reward: total was 12.260000. running mean: -8.892005\n",
      "ep 31: ep_len:1165 episode reward: total was -47.940000. running mean: -9.282485\n",
      "ep 31: ep_len:500 episode reward: total was 1.080000. running mean: -9.178860\n",
      "ep 31: ep_len:500 episode reward: total was 6.210000. running mean: -9.024972\n",
      "ep 31: ep_len:1540 episode reward: total was -238.900000. running mean: -11.323722\n",
      "ep 31: ep_len:500 episode reward: total was 27.780000. running mean: -10.932685\n",
      "ep 31: ep_len:815 episode reward: total was 5.180000. running mean: -10.771558\n",
      "ep 31: ep_len:520 episode reward: total was -12.140000. running mean: -10.785242\n",
      "ep 31: ep_len:500 episode reward: total was -1.100000. running mean: -10.688390\n",
      "ep 31: ep_len:785 episode reward: total was -15.280000. running mean: -10.734306\n",
      "ep 31: ep_len:580 episode reward: total was -21.110000. running mean: -10.838063\n",
      "ep 31: ep_len:915 episode reward: total was -2.080000. running mean: -10.750482\n",
      "ep 31: ep_len:655 episode reward: total was -40.150000. running mean: -11.044477\n",
      "ep 31: ep_len:500 episode reward: total was 19.820000. running mean: -10.735833\n",
      "ep 31: ep_len:500 episode reward: total was 13.600000. running mean: -10.492474\n",
      "ep 31: ep_len:805 episode reward: total was -0.570000. running mean: -10.393250\n",
      "ep 31: ep_len:845 episode reward: total was -0.250000. running mean: -10.291817\n",
      "ep 31: ep_len:845 episode reward: total was 7.600000. running mean: -10.112899\n",
      "ep 31: ep_len:590 episode reward: total was -24.120000. running mean: -10.252970\n",
      "ep 31: ep_len:6540 episode reward: total was -945.460000. running mean: -19.605040\n",
      "ep 31: ep_len:500 episode reward: total was 7.350000. running mean: -19.335490\n",
      "ep 31: ep_len:980 episode reward: total was 6.790000. running mean: -19.074235\n",
      "ep 31: ep_len:464 episode reward: total was 43.500000. running mean: -18.448493\n",
      "ep 31: ep_len:580 episode reward: total was -21.600000. running mean: -18.480008\n",
      "ep 31: ep_len:500 episode reward: total was -23.290000. running mean: -18.528108\n",
      "ep 31: ep_len:500 episode reward: total was -1.830000. running mean: -18.361126\n",
      "ep 31: ep_len:500 episode reward: total was -3.840000. running mean: -18.215915\n",
      "ep 31: ep_len:690 episode reward: total was -10.270000. running mean: -18.136456\n",
      "ep 31: ep_len:325 episode reward: total was 31.000000. running mean: -17.645092\n",
      "ep 31: ep_len:540 episode reward: total was 0.390000. running mean: -17.464741\n",
      "ep 31: ep_len:500 episode reward: total was 17.750000. running mean: -17.112593\n",
      "ep 31: ep_len:1750 episode reward: total was -223.510000. running mean: -19.176567\n",
      "ep 31: ep_len:870 episode reward: total was 3.810000. running mean: -18.946702\n",
      "ep 31: ep_len:750 episode reward: total was -81.860000. running mean: -19.575835\n",
      "ep 31: ep_len:195 episode reward: total was 12.500000. running mean: -19.255076\n",
      "ep 31: ep_len:865 episode reward: total was 16.060000. running mean: -18.901925\n",
      "ep 31: ep_len:730 episode reward: total was 12.960000. running mean: -18.583306\n",
      "ep 31: ep_len:220 episode reward: total was 19.000000. running mean: -18.207473\n",
      "ep 31: ep_len:515 episode reward: total was -9.120000. running mean: -18.116598\n",
      "ep 31: ep_len:500 episode reward: total was -4.150000. running mean: -17.976932\n",
      "ep 31: ep_len:525 episode reward: total was -3.560000. running mean: -17.832763\n",
      "ep 31: ep_len:500 episode reward: total was 2.010000. running mean: -17.634335\n",
      "ep 31: ep_len:905 episode reward: total was 19.160000. running mean: -17.266392\n",
      "ep 31: ep_len:1551 episode reward: total was -238.490000. running mean: -19.478628\n",
      "ep 31: ep_len:500 episode reward: total was 21.380000. running mean: -19.070042\n",
      "ep 31: ep_len:203 episode reward: total was 19.000000. running mean: -18.689342\n",
      "ep 31: ep_len:700 episode reward: total was -3.700000. running mean: -18.539448\n",
      "ep 31: ep_len:500 episode reward: total was 9.840000. running mean: -18.255654\n",
      "ep 31: ep_len:412 episode reward: total was 41.000000. running mean: -17.663097\n",
      "ep 31: ep_len:500 episode reward: total was 27.810000. running mean: -17.208366\n",
      "ep 31: ep_len:555 episode reward: total was -9.010000. running mean: -17.126382\n",
      "ep 31: ep_len:760 episode reward: total was 30.290000. running mean: -16.652219\n",
      "ep 31: ep_len:730 episode reward: total was -6.330000. running mean: -16.548996\n",
      "ep 31: ep_len:815 episode reward: total was 39.220000. running mean: -15.991306\n",
      "ep 31: ep_len:188 episode reward: total was 18.500000. running mean: -15.646393\n",
      "ep 31: ep_len:500 episode reward: total was 0.190000. running mean: -15.488029\n",
      "ep 31: ep_len:2600 episode reward: total was -484.680000. running mean: -20.179949\n",
      "ep 31: ep_len:500 episode reward: total was 12.290000. running mean: -19.855250\n",
      "ep 31: ep_len:1045 episode reward: total was 2.210000. running mean: -19.634597\n",
      "ep 31: ep_len:494 episode reward: total was 18.730000. running mean: -19.250951\n",
      "ep 31: ep_len:1195 episode reward: total was -97.650000. running mean: -20.034942\n",
      "ep 31: ep_len:620 episode reward: total was -35.660000. running mean: -20.191192\n",
      "ep 31: ep_len:500 episode reward: total was 6.810000. running mean: -19.921180\n",
      "ep 31: ep_len:952 episode reward: total was -100.140000. running mean: -20.723369\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 31: ep_len:760 episode reward: total was -22.770000. running mean: -20.743835\n",
      "ep 31: ep_len:500 episode reward: total was -43.720000. running mean: -20.973597\n",
      "ep 31: ep_len:500 episode reward: total was 31.300000. running mean: -20.450861\n",
      "ep 31: ep_len:760 episode reward: total was -17.790000. running mean: -20.424252\n",
      "ep 31: ep_len:610 episode reward: total was -5.410000. running mean: -20.274109\n",
      "ep 31: ep_len:820 episode reward: total was 15.540000. running mean: -19.915968\n",
      "ep 31: ep_len:500 episode reward: total was -56.770000. running mean: -20.284509\n",
      "ep 31: ep_len:43 episode reward: total was 4.000000. running mean: -20.041664\n",
      "ep 31: ep_len:730 episode reward: total was -32.210000. running mean: -20.163347\n",
      "ep 31: ep_len:500 episode reward: total was -20.000000. running mean: -20.161713\n",
      "ep 31: ep_len:500 episode reward: total was 23.860000. running mean: -19.721496\n",
      "ep 31: ep_len:500 episode reward: total was -2.070000. running mean: -19.544981\n",
      "ep 31: ep_len:1150 episode reward: total was -104.810000. running mean: -20.397632\n",
      "ep 31: ep_len:500 episode reward: total was -2.660000. running mean: -20.220255\n",
      "ep 31: ep_len:855 episode reward: total was -103.430000. running mean: -21.052353\n",
      "ep 31: ep_len:730 episode reward: total was -20.290000. running mean: -21.044729\n",
      "ep 31: ep_len:610 episode reward: total was -7.670000. running mean: -20.910982\n",
      "ep 31: ep_len:500 episode reward: total was 26.340000. running mean: -20.438472\n",
      "ep 31: ep_len:605 episode reward: total was -66.490000. running mean: -20.898987\n",
      "ep 31: ep_len:1935 episode reward: total was -175.310000. running mean: -22.443097\n",
      "ep 31: ep_len:735 episode reward: total was 6.710000. running mean: -22.151566\n",
      "ep 31: ep_len:505 episode reward: total was 6.260000. running mean: -21.867451\n",
      "ep 31: ep_len:900 episode reward: total was -11.220000. running mean: -21.760976\n",
      "ep 31: ep_len:725 episode reward: total was 3.710000. running mean: -21.506267\n",
      "ep 31: ep_len:500 episode reward: total was -2.720000. running mean: -21.318404\n",
      "ep 31: ep_len:695 episode reward: total was 4.230000. running mean: -21.062920\n",
      "ep 31: ep_len:730 episode reward: total was -8.690000. running mean: -20.939191\n",
      "ep 31: ep_len:1068 episode reward: total was -136.270000. running mean: -22.092499\n",
      "ep 31: ep_len:680 episode reward: total was -21.920000. running mean: -22.090774\n",
      "ep 31: ep_len:500 episode reward: total was 14.950000. running mean: -21.720366\n",
      "ep 31: ep_len:630 episode reward: total was 4.100000. running mean: -21.462162\n",
      "ep 31: ep_len:845 episode reward: total was -2.300000. running mean: -21.270541\n",
      "ep 31: ep_len:148 episode reward: total was 15.000000. running mean: -20.907835\n",
      "ep 31: ep_len:560 episode reward: total was -16.100000. running mean: -20.859757\n",
      "ep 31: ep_len:905 episode reward: total was 4.280000. running mean: -20.608359\n",
      "ep 31: ep_len:580 episode reward: total was 4.820000. running mean: -20.354076\n",
      "ep 31: ep_len:369 episode reward: total was 35.000000. running mean: -19.800535\n",
      "ep 31: ep_len:725 episode reward: total was -14.730000. running mean: -19.749830\n",
      "ep 31: ep_len:500 episode reward: total was -3.910000. running mean: -19.591431\n",
      "ep 31: ep_len:500 episode reward: total was 23.280000. running mean: -19.162717\n",
      "ep 31: ep_len:1158 episode reward: total was -194.720000. running mean: -20.918290\n",
      "ep 31: ep_len:500 episode reward: total was 33.350000. running mean: -20.375607\n",
      "ep 31: ep_len:500 episode reward: total was 29.340000. running mean: -19.878451\n",
      "ep 31: ep_len:500 episode reward: total was -0.150000. running mean: -19.681166\n",
      "ep 31: ep_len:443 episode reward: total was 18.820000. running mean: -19.296155\n",
      "ep 31: ep_len:500 episode reward: total was -62.680000. running mean: -19.729993\n",
      "ep 31: ep_len:500 episode reward: total was -49.060000. running mean: -20.023293\n",
      "ep 31: ep_len:500 episode reward: total was 25.330000. running mean: -19.569760\n",
      "ep 31: ep_len:1520 episode reward: total was -171.740000. running mean: -21.091463\n",
      "ep 31: ep_len:500 episode reward: total was 9.010000. running mean: -20.790448\n",
      "ep 31: ep_len:2575 episode reward: total was -454.970000. running mean: -25.132244\n",
      "ep 31: ep_len:895 episode reward: total was -16.200000. running mean: -25.042921\n",
      "ep 31: ep_len:500 episode reward: total was 47.000000. running mean: -24.322492\n",
      "ep 31: ep_len:1000 episode reward: total was -15.540000. running mean: -24.234667\n",
      "ep 31: ep_len:555 episode reward: total was -31.960000. running mean: -24.311920\n",
      "ep 31: ep_len:1805 episode reward: total was -157.850000. running mean: -25.647301\n",
      "ep 31: ep_len:500 episode reward: total was 2.550000. running mean: -25.365328\n",
      "ep 31: ep_len:500 episode reward: total was -30.970000. running mean: -25.421375\n",
      "ep 31: ep_len:690 episode reward: total was 0.320000. running mean: -25.163961\n",
      "epsilon:0.010000 episode_count: 25225. steps_count: 18248723.000000\n",
      "ep 32: ep_len:750 episode reward: total was -118.480000. running mean: -26.097122\n",
      "ep 32: ep_len:885 episode reward: total was -56.830000. running mean: -26.404450\n",
      "ep 32: ep_len:635 episode reward: total was 2.500000. running mean: -26.115406\n",
      "ep 32: ep_len:2110 episode reward: total was -318.570000. running mean: -29.039952\n",
      "ep 32: ep_len:905 episode reward: total was 19.570000. running mean: -28.553852\n",
      "ep 32: ep_len:500 episode reward: total was -19.950000. running mean: -28.467814\n",
      "ep 32: ep_len:970 episode reward: total was 14.220000. running mean: -28.040936\n",
      "ep 32: ep_len:755 episode reward: total was -47.310000. running mean: -28.233626\n",
      "ep 32: ep_len:800 episode reward: total was -39.860000. running mean: -28.349890\n",
      "ep 32: ep_len:500 episode reward: total was 9.250000. running mean: -27.973891\n",
      "ep 32: ep_len:565 episode reward: total was -44.340000. running mean: -28.137552\n",
      "ep 32: ep_len:500 episode reward: total was 11.250000. running mean: -27.743677\n",
      "ep 32: ep_len:500 episode reward: total was 14.190000. running mean: -27.324340\n",
      "ep 32: ep_len:960 episode reward: total was -28.270000. running mean: -27.333796\n",
      "ep 32: ep_len:805 episode reward: total was -38.840000. running mean: -27.448859\n",
      "ep 32: ep_len:500 episode reward: total was 23.160000. running mean: -26.942770\n",
      "ep 32: ep_len:500 episode reward: total was 7.080000. running mean: -26.602542\n",
      "ep 32: ep_len:500 episode reward: total was 25.940000. running mean: -26.077117\n",
      "ep 32: ep_len:229 episode reward: total was 21.500000. running mean: -25.601346\n",
      "ep 32: ep_len:545 episode reward: total was -28.250000. running mean: -25.627832\n",
      "ep 32: ep_len:585 episode reward: total was -34.000000. running mean: -25.711554\n",
      "ep 32: ep_len:1862 episode reward: total was -166.690000. running mean: -27.121338\n",
      "ep 32: ep_len:178 episode reward: total was 7.000000. running mean: -26.780125\n",
      "ep 32: ep_len:980 episode reward: total was -57.680000. running mean: -27.089124\n",
      "ep 32: ep_len:500 episode reward: total was -20.000000. running mean: -27.018232\n",
      "ep 32: ep_len:500 episode reward: total was 4.230000. running mean: -26.705750\n",
      "ep 32: ep_len:980 episode reward: total was -29.590000. running mean: -26.734593\n",
      "ep 32: ep_len:500 episode reward: total was 11.180000. running mean: -26.355447\n",
      "ep 32: ep_len:16003 episode reward: total was -2232.350000. running mean: -48.415392\n",
      "ep 32: ep_len:540 episode reward: total was 22.430000. running mean: -47.706938\n",
      "ep 32: ep_len:740 episode reward: total was -30.760000. running mean: -47.537469\n",
      "ep 32: ep_len:580 episode reward: total was -7.190000. running mean: -47.133994\n",
      "ep 32: ep_len:500 episode reward: total was 27.290000. running mean: -46.389754\n",
      "ep 32: ep_len:815 episode reward: total was -0.460000. running mean: -45.930457\n",
      "ep 32: ep_len:354 episode reward: total was -5.000000. running mean: -45.521152\n",
      "ep 32: ep_len:500 episode reward: total was 20.710000. running mean: -44.858841\n",
      "ep 32: ep_len:925 episode reward: total was -0.490000. running mean: -44.415152\n",
      "ep 32: ep_len:755 episode reward: total was -22.770000. running mean: -44.198701\n",
      "ep 32: ep_len:471 episode reward: total was 33.750000. running mean: -43.419214\n",
      "ep 32: ep_len:620 episode reward: total was 13.600000. running mean: -42.849022\n",
      "ep 32: ep_len:500 episode reward: total was 20.310000. running mean: -42.217431\n",
      "ep 32: ep_len:505 episode reward: total was -13.180000. running mean: -41.927057\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 32: ep_len:975 episode reward: total was 16.160000. running mean: -41.346186\n",
      "ep 32: ep_len:500 episode reward: total was 19.850000. running mean: -40.734225\n",
      "ep 32: ep_len:500 episode reward: total was -5.230000. running mean: -40.379182\n",
      "ep 32: ep_len:264 episode reward: total was 6.500000. running mean: -39.910391\n",
      "ep 32: ep_len:500 episode reward: total was 1.060000. running mean: -39.500687\n",
      "ep 32: ep_len:705 episode reward: total was -29.950000. running mean: -39.405180\n",
      "ep 32: ep_len:1090 episode reward: total was -42.940000. running mean: -39.440528\n",
      "ep 32: ep_len:247 episode reward: total was 15.500000. running mean: -38.891123\n",
      "ep 32: ep_len:500 episode reward: total was 3.350000. running mean: -38.468711\n",
      "ep 32: ep_len:249 episode reward: total was 3.500000. running mean: -38.049024\n",
      "ep 32: ep_len:740 episode reward: total was -26.850000. running mean: -37.937034\n",
      "ep 32: ep_len:790 episode reward: total was -94.190000. running mean: -38.499564\n",
      "ep 32: ep_len:500 episode reward: total was 15.350000. running mean: -37.961068\n",
      "ep 32: ep_len:660 episode reward: total was -12.870000. running mean: -37.710157\n",
      "ep 32: ep_len:860 episode reward: total was -48.530000. running mean: -37.818356\n",
      "ep 32: ep_len:955 episode reward: total was -8.520000. running mean: -37.525372\n",
      "ep 32: ep_len:500 episode reward: total was -4.950000. running mean: -37.199619\n",
      "ep 32: ep_len:1310 episode reward: total was -200.440000. running mean: -38.832022\n",
      "ep 32: ep_len:585 episode reward: total was -3.930000. running mean: -38.483002\n",
      "ep 32: ep_len:800 episode reward: total was -2.280000. running mean: -38.120972\n",
      "ep 32: ep_len:181 episode reward: total was 18.000000. running mean: -37.559762\n",
      "ep 32: ep_len:199 episode reward: total was 18.000000. running mean: -37.004165\n",
      "ep 32: ep_len:505 episode reward: total was 27.850000. running mean: -36.355623\n",
      "ep 32: ep_len:500 episode reward: total was -0.270000. running mean: -35.994767\n",
      "ep 32: ep_len:1441 episode reward: total was -192.660000. running mean: -37.561419\n",
      "ep 32: ep_len:590 episode reward: total was -33.210000. running mean: -37.517905\n",
      "ep 32: ep_len:500 episode reward: total was 19.820000. running mean: -36.944526\n",
      "ep 32: ep_len:600 episode reward: total was -2.890000. running mean: -36.603981\n",
      "ep 32: ep_len:765 episode reward: total was -11.650000. running mean: -36.354441\n",
      "ep 32: ep_len:940 episode reward: total was -11.610000. running mean: -36.106997\n",
      "ep 32: ep_len:500 episode reward: total was 4.260000. running mean: -35.703327\n",
      "ep 32: ep_len:1072 episode reward: total was -148.900000. running mean: -36.835293\n",
      "ep 32: ep_len:560 episode reward: total was -39.330000. running mean: -36.860240\n",
      "ep 32: ep_len:500 episode reward: total was 14.710000. running mean: -36.344538\n",
      "ep 32: ep_len:940 episode reward: total was 6.080000. running mean: -35.920293\n",
      "ep 32: ep_len:500 episode reward: total was -8.680000. running mean: -35.647890\n",
      "ep 32: ep_len:725 episode reward: total was -0.340000. running mean: -35.294811\n",
      "ep 32: ep_len:500 episode reward: total was 18.700000. running mean: -34.754863\n",
      "ep 32: ep_len:500 episode reward: total was 4.210000. running mean: -34.365214\n",
      "ep 32: ep_len:855 episode reward: total was 13.670000. running mean: -33.884862\n",
      "ep 32: ep_len:680 episode reward: total was 13.410000. running mean: -33.411913\n",
      "ep 32: ep_len:555 episode reward: total was 17.360000. running mean: -32.904194\n",
      "ep 32: ep_len:575 episode reward: total was -11.510000. running mean: -32.690252\n",
      "ep 32: ep_len:615 episode reward: total was -25.050000. running mean: -32.613850\n",
      "ep 32: ep_len:700 episode reward: total was -25.050000. running mean: -32.538211\n",
      "ep 32: ep_len:500 episode reward: total was -0.240000. running mean: -32.215229\n",
      "ep 32: ep_len:650 episode reward: total was 0.560000. running mean: -31.887477\n",
      "ep 32: ep_len:700 episode reward: total was 12.110000. running mean: -31.447502\n",
      "ep 32: ep_len:545 episode reward: total was -25.220000. running mean: -31.385227\n",
      "ep 32: ep_len:500 episode reward: total was 3.730000. running mean: -31.034075\n",
      "ep 32: ep_len:20375 episode reward: total was -1399.510000. running mean: -44.718834\n",
      "ep 32: ep_len:500 episode reward: total was 5.740000. running mean: -44.214246\n",
      "ep 32: ep_len:500 episode reward: total was 3.830000. running mean: -43.733803\n",
      "ep 32: ep_len:500 episode reward: total was 15.170000. running mean: -43.144765\n",
      "ep 32: ep_len:940 episode reward: total was 15.690000. running mean: -42.556418\n",
      "ep 32: ep_len:730 episode reward: total was -20.810000. running mean: -42.338953\n",
      "ep 32: ep_len:500 episode reward: total was -5.810000. running mean: -41.973664\n",
      "ep 32: ep_len:1327 episode reward: total was -111.370000. running mean: -42.667627\n",
      "ep 32: ep_len:500 episode reward: total was 17.740000. running mean: -42.063551\n",
      "ep 32: ep_len:730 episode reward: total was -21.380000. running mean: -41.856715\n",
      "ep 32: ep_len:1269 episode reward: total was -22.050000. running mean: -41.658648\n",
      "ep 32: ep_len:845 episode reward: total was -11.620000. running mean: -41.358262\n",
      "ep 32: ep_len:193 episode reward: total was 16.000000. running mean: -40.784679\n",
      "ep 32: ep_len:545 episode reward: total was -36.330000. running mean: -40.740132\n",
      "ep 32: ep_len:238 episode reward: total was 22.000000. running mean: -40.112731\n",
      "ep 32: ep_len:500 episode reward: total was 17.950000. running mean: -39.532104\n",
      "ep 32: ep_len:500 episode reward: total was 21.320000. running mean: -38.923583\n",
      "ep 32: ep_len:500 episode reward: total was 15.440000. running mean: -38.379947\n",
      "ep 32: ep_len:500 episode reward: total was 26.710000. running mean: -37.729047\n",
      "ep 32: ep_len:500 episode reward: total was 17.740000. running mean: -37.174357\n",
      "ep 32: ep_len:870 episode reward: total was -31.350000. running mean: -37.116113\n",
      "ep 32: ep_len:500 episode reward: total was 13.910000. running mean: -36.605852\n",
      "ep 32: ep_len:800 episode reward: total was -25.110000. running mean: -36.490894\n",
      "ep 32: ep_len:835 episode reward: total was 0.250000. running mean: -36.123485\n",
      "ep 32: ep_len:500 episode reward: total was 27.780000. running mean: -35.484450\n",
      "ep 32: ep_len:805 episode reward: total was 26.250000. running mean: -34.867105\n",
      "ep 32: ep_len:9843 episode reward: total was -1794.800000. running mean: -52.466434\n",
      "ep 32: ep_len:500 episode reward: total was -18.910000. running mean: -52.130870\n",
      "ep 32: ep_len:1010 episode reward: total was 18.730000. running mean: -51.422261\n",
      "ep 32: ep_len:835 episode reward: total was -65.530000. running mean: -51.563339\n",
      "ep 32: ep_len:500 episode reward: total was 3.380000. running mean: -51.013905\n",
      "ep 32: ep_len:1050 episode reward: total was 14.740000. running mean: -50.356366\n",
      "ep 32: ep_len:93 episode reward: total was 9.000000. running mean: -49.762803\n",
      "ep 32: ep_len:560 episode reward: total was -20.110000. running mean: -49.466275\n",
      "ep 32: ep_len:1170 episode reward: total was -10.270000. running mean: -49.074312\n",
      "ep 32: ep_len:850 episode reward: total was -72.780000. running mean: -49.311369\n",
      "ep 32: ep_len:685 episode reward: total was -6.370000. running mean: -48.881955\n",
      "ep 32: ep_len:500 episode reward: total was 19.330000. running mean: -48.199835\n",
      "ep 32: ep_len:1970 episode reward: total was -230.240000. running mean: -50.020237\n",
      "ep 32: ep_len:2295 episode reward: total was -329.700000. running mean: -52.817035\n",
      "ep 32: ep_len:500 episode reward: total was 5.370000. running mean: -52.235164\n",
      "ep 32: ep_len:500 episode reward: total was -33.570000. running mean: -52.048513\n",
      "ep 32: ep_len:500 episode reward: total was 17.310000. running mean: -51.354928\n",
      "ep 32: ep_len:500 episode reward: total was 48.500000. running mean: -50.356378\n",
      "ep 32: ep_len:500 episode reward: total was -4.480000. running mean: -49.897615\n",
      "ep 32: ep_len:500 episode reward: total was 24.810000. running mean: -49.150538\n",
      "ep 32: ep_len:1835 episode reward: total was -176.910000. running mean: -50.428133\n",
      "ep 32: ep_len:500 episode reward: total was 1.520000. running mean: -49.908652\n",
      "ep 32: ep_len:500 episode reward: total was 0.510000. running mean: -49.404465\n",
      "ep 32: ep_len:106 episode reward: total was 10.500000. running mean: -48.805421\n",
      "ep 32: ep_len:615 episode reward: total was -28.080000. running mean: -48.598166\n",
      "ep 32: ep_len:141 episode reward: total was 14.000000. running mean: -47.972185\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 32: ep_len:500 episode reward: total was 16.110000. running mean: -47.331363\n",
      "ep 32: ep_len:695 episode reward: total was -4.720000. running mean: -46.905249\n",
      "ep 32: ep_len:500 episode reward: total was 8.710000. running mean: -46.349097\n",
      "ep 32: ep_len:500 episode reward: total was 25.220000. running mean: -45.633406\n",
      "ep 32: ep_len:660 episode reward: total was -30.010000. running mean: -45.477172\n",
      "ep 32: ep_len:500 episode reward: total was 50.000000. running mean: -44.522400\n",
      "ep 32: ep_len:515 episode reward: total was 11.730000. running mean: -43.959876\n",
      "ep 32: ep_len:170 episode reward: total was 15.500000. running mean: -43.365277\n",
      "ep 32: ep_len:500 episode reward: total was 17.440000. running mean: -42.757224\n",
      "ep 32: ep_len:500 episode reward: total was -62.890000. running mean: -42.958552\n",
      "ep 32: ep_len:740 episode reward: total was -18.370000. running mean: -42.712667\n",
      "ep 32: ep_len:755 episode reward: total was -38.540000. running mean: -42.670940\n",
      "ep 32: ep_len:1010 episode reward: total was -43.840000. running mean: -42.682631\n",
      "ep 32: ep_len:690 episode reward: total was -22.560000. running mean: -42.481404\n",
      "ep 32: ep_len:500 episode reward: total was -13.920000. running mean: -42.195790\n",
      "ep 32: ep_len:500 episode reward: total was -51.780000. running mean: -42.291632\n",
      "ep 32: ep_len:570 episode reward: total was 15.370000. running mean: -41.715016\n",
      "ep 32: ep_len:500 episode reward: total was 10.700000. running mean: -41.190866\n",
      "ep 32: ep_len:720 episode reward: total was -25.360000. running mean: -41.032557\n",
      "ep 32: ep_len:500 episode reward: total was 13.680000. running mean: -40.485432\n",
      "ep 32: ep_len:412 episode reward: total was 21.130000. running mean: -39.869277\n",
      "ep 32: ep_len:915 episode reward: total was 9.760000. running mean: -39.372985\n",
      "ep 32: ep_len:870 episode reward: total was -28.480000. running mean: -39.264055\n",
      "ep 32: ep_len:975 episode reward: total was 17.720000. running mean: -38.694214\n",
      "ep 32: ep_len:560 episode reward: total was -39.330000. running mean: -38.700572\n",
      "ep 32: ep_len:282 episode reward: total was 26.500000. running mean: -38.048566\n",
      "ep 32: ep_len:630 episode reward: total was -54.340000. running mean: -38.211481\n",
      "ep 32: ep_len:685 episode reward: total was -9.790000. running mean: -37.927266\n",
      "ep 32: ep_len:186 episode reward: total was 17.000000. running mean: -37.377993\n",
      "ep 32: ep_len:910 episode reward: total was -56.810000. running mean: -37.572313\n",
      "ep 32: ep_len:500 episode reward: total was -13.830000. running mean: -37.334890\n",
      "ep 32: ep_len:500 episode reward: total was 14.280000. running mean: -36.818741\n",
      "ep 32: ep_len:760 episode reward: total was -27.820000. running mean: -36.728754\n",
      "ep 32: ep_len:500 episode reward: total was 21.230000. running mean: -36.149166\n",
      "ep 32: ep_len:710 episode reward: total was -33.270000. running mean: -36.120375\n",
      "ep 32: ep_len:500 episode reward: total was -14.670000. running mean: -35.905871\n",
      "ep 32: ep_len:500 episode reward: total was -51.080000. running mean: -36.057612\n",
      "ep 32: ep_len:510 episode reward: total was 24.800000. running mean: -35.449036\n",
      "ep 32: ep_len:565 episode reward: total was 12.750000. running mean: -34.967046\n",
      "ep 32: ep_len:505 episode reward: total was 49.000000. running mean: -34.127375\n",
      "ep 32: ep_len:705 episode reward: total was -0.250000. running mean: -33.788601\n",
      "ep 32: ep_len:505 episode reward: total was -14.160000. running mean: -33.592315\n",
      "ep 32: ep_len:695 episode reward: total was 12.310000. running mean: -33.133292\n",
      "ep 32: ep_len:500 episode reward: total was -1.210000. running mean: -32.814059\n",
      "ep 32: ep_len:675 episode reward: total was -15.350000. running mean: -32.639419\n",
      "ep 32: ep_len:229 episode reward: total was 19.500000. running mean: -32.118025\n",
      "ep 32: ep_len:1060 episode reward: total was 3.770000. running mean: -31.759144\n",
      "ep 32: ep_len:2660 episode reward: total was -455.270000. running mean: -35.994253\n",
      "ep 32: ep_len:500 episode reward: total was 3.100000. running mean: -35.603310\n",
      "ep 32: ep_len:2068 episode reward: total was -270.670000. running mean: -37.953977\n",
      "ep 32: ep_len:500 episode reward: total was 25.820000. running mean: -37.316237\n",
      "ep 32: ep_len:625 episode reward: total was -26.070000. running mean: -37.203775\n",
      "ep 32: ep_len:930 episode reward: total was 10.090000. running mean: -36.730837\n",
      "ep 32: ep_len:735 episode reward: total was -24.840000. running mean: -36.611929\n",
      "ep 32: ep_len:890 episode reward: total was -8.270000. running mean: -36.328510\n",
      "ep 32: ep_len:570 episode reward: total was -17.090000. running mean: -36.136125\n",
      "ep 32: ep_len:725 episode reward: total was 2.510000. running mean: -35.749663\n",
      "ep 32: ep_len:500 episode reward: total was -6.760000. running mean: -35.459767\n",
      "ep 32: ep_len:500 episode reward: total was 5.150000. running mean: -35.053669\n",
      "ep 32: ep_len:500 episode reward: total was 7.690000. running mean: -34.626232\n",
      "ep 32: ep_len:525 episode reward: total was -18.190000. running mean: -34.461870\n",
      "ep 32: ep_len:500 episode reward: total was 33.290000. running mean: -33.784351\n",
      "ep 32: ep_len:500 episode reward: total was 18.440000. running mean: -33.262108\n",
      "ep 32: ep_len:500 episode reward: total was 17.340000. running mean: -32.756087\n",
      "ep 32: ep_len:995 episode reward: total was -77.600000. running mean: -33.204526\n",
      "ep 32: ep_len:100 episode reward: total was 9.000000. running mean: -32.782481\n",
      "ep 32: ep_len:500 episode reward: total was 14.150000. running mean: -32.313156\n",
      "ep 32: ep_len:500 episode reward: total was -1.190000. running mean: -32.001924\n",
      "ep 32: ep_len:745 episode reward: total was -11.780000. running mean: -31.799705\n",
      "ep 32: ep_len:500 episode reward: total was 2.460000. running mean: -31.457108\n",
      "ep 32: ep_len:500 episode reward: total was -18.820000. running mean: -31.330737\n",
      "ep 32: ep_len:1025 episode reward: total was -89.190000. running mean: -31.909329\n",
      "ep 32: ep_len:635 episode reward: total was -5.080000. running mean: -31.641036\n",
      "ep 32: ep_len:216 episode reward: total was 20.000000. running mean: -31.124626\n",
      "ep 32: ep_len:500 episode reward: total was 2.550000. running mean: -30.787880\n",
      "ep 32: ep_len:830 episode reward: total was -14.240000. running mean: -30.622401\n",
      "ep 32: ep_len:930 episode reward: total was -13.270000. running mean: -30.448877\n",
      "ep 32: ep_len:755 episode reward: total was 4.560000. running mean: -30.098788\n",
      "ep 32: ep_len:500 episode reward: total was -20.960000. running mean: -30.007400\n",
      "ep 32: ep_len:383 episode reward: total was 20.780000. running mean: -29.499526\n",
      "ep 32: ep_len:500 episode reward: total was 0.160000. running mean: -29.202931\n",
      "ep 32: ep_len:505 episode reward: total was -6.110000. running mean: -28.972002\n",
      "ep 32: ep_len:600 episode reward: total was -24.120000. running mean: -28.923482\n",
      "ep 32: ep_len:500 episode reward: total was 32.770000. running mean: -28.306547\n",
      "ep 32: ep_len:500 episode reward: total was 29.770000. running mean: -27.725781\n",
      "ep 32: ep_len:500 episode reward: total was 18.840000. running mean: -27.260123\n",
      "ep 32: ep_len:825 episode reward: total was -35.740000. running mean: -27.344922\n",
      "ep 32: ep_len:500 episode reward: total was 22.790000. running mean: -26.843573\n",
      "ep 32: ep_len:570 episode reward: total was -49.410000. running mean: -27.069237\n",
      "ep 32: ep_len:500 episode reward: total was -5.410000. running mean: -26.852645\n",
      "ep 32: ep_len:805 episode reward: total was -17.140000. running mean: -26.755518\n",
      "ep 32: ep_len:1810 episode reward: total was -66.610000. running mean: -27.154063\n",
      "ep 32: ep_len:500 episode reward: total was 25.300000. running mean: -26.629523\n",
      "ep 32: ep_len:725 episode reward: total was -10.720000. running mean: -26.470427\n",
      "ep 32: ep_len:900 episode reward: total was -27.250000. running mean: -26.478223\n",
      "ep 32: ep_len:500 episode reward: total was 18.500000. running mean: -26.028441\n",
      "ep 32: ep_len:515 episode reward: total was -2.140000. running mean: -25.789556\n",
      "ep 32: ep_len:825 episode reward: total was -24.380000. running mean: -25.775461\n",
      "ep 32: ep_len:500 episode reward: total was 19.400000. running mean: -25.323706\n",
      "ep 32: ep_len:170 episode reward: total was 15.500000. running mean: -24.915469\n",
      "ep 32: ep_len:1050 episode reward: total was -41.190000. running mean: -25.078215\n",
      "ep 32: ep_len:500 episode reward: total was -18.840000. running mean: -25.015832\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 32: ep_len:925 episode reward: total was -18.730000. running mean: -24.952974\n",
      "ep 32: ep_len:610 episode reward: total was 14.540000. running mean: -24.558044\n",
      "ep 32: ep_len:500 episode reward: total was 25.790000. running mean: -24.054564\n",
      "ep 32: ep_len:52 episode reward: total was 5.000000. running mean: -23.764018\n",
      "ep 32: ep_len:1160 episode reward: total was -55.240000. running mean: -24.078778\n",
      "ep 32: ep_len:500 episode reward: total was 15.480000. running mean: -23.683190\n",
      "ep 32: ep_len:500 episode reward: total was 17.830000. running mean: -23.268058\n",
      "ep 32: ep_len:1281 episode reward: total was -77.520000. running mean: -23.810578\n",
      "ep 32: ep_len:850 episode reward: total was 6.080000. running mean: -23.511672\n",
      "ep 32: ep_len:1190 episode reward: total was -133.500000. running mean: -24.611555\n",
      "ep 32: ep_len:670 episode reward: total was -8.450000. running mean: -24.449940\n",
      "ep 32: ep_len:500 episode reward: total was -7.650000. running mean: -24.281940\n",
      "ep 32: ep_len:500 episode reward: total was 14.800000. running mean: -23.891121\n",
      "ep 32: ep_len:165 episode reward: total was 15.000000. running mean: -23.502210\n",
      "ep 32: ep_len:500 episode reward: total was 19.970000. running mean: -23.067488\n",
      "ep 32: ep_len:965 episode reward: total was 3.590000. running mean: -22.800913\n",
      "ep 32: ep_len:500 episode reward: total was -15.820000. running mean: -22.731104\n",
      "ep 32: ep_len:187 episode reward: total was 17.000000. running mean: -22.333793\n",
      "ep 32: ep_len:500 episode reward: total was 24.410000. running mean: -21.866355\n",
      "ep 32: ep_len:670 episode reward: total was -16.370000. running mean: -21.811391\n",
      "ep 32: ep_len:815 episode reward: total was 31.720000. running mean: -21.276077\n",
      "ep 32: ep_len:223 episode reward: total was 22.000000. running mean: -20.843316\n",
      "ep 32: ep_len:760 episode reward: total was -7.180000. running mean: -20.706683\n",
      "ep 32: ep_len:805 episode reward: total was 12.050000. running mean: -20.379116\n",
      "ep 32: ep_len:500 episode reward: total was 45.500000. running mean: -19.720325\n",
      "ep 32: ep_len:530 episode reward: total was 6.250000. running mean: -19.460622\n",
      "ep 32: ep_len:193 episode reward: total was 19.000000. running mean: -19.076016\n",
      "ep 32: ep_len:690 episode reward: total was 10.250000. running mean: -18.782756\n",
      "ep 32: ep_len:850 episode reward: total was 22.640000. running mean: -18.368528\n",
      "ep 32: ep_len:500 episode reward: total was 16.330000. running mean: -18.021543\n",
      "ep 32: ep_len:500 episode reward: total was -18.210000. running mean: -18.023427\n",
      "ep 32: ep_len:680 episode reward: total was -0.670000. running mean: -17.849893\n",
      "ep 32: ep_len:1540 episode reward: total was -135.260000. running mean: -19.023994\n",
      "ep 32: ep_len:900 episode reward: total was 11.690000. running mean: -18.716854\n",
      "ep 32: ep_len:500 episode reward: total was 1.260000. running mean: -18.517086\n",
      "ep 32: ep_len:860 episode reward: total was -9.330000. running mean: -18.425215\n",
      "ep 32: ep_len:281 episode reward: total was -18.000000. running mean: -18.420963\n",
      "ep 32: ep_len:178 episode reward: total was 17.500000. running mean: -18.061753\n",
      "ep 32: ep_len:645 episode reward: total was -48.250000. running mean: -18.363636\n",
      "ep 32: ep_len:1020 episode reward: total was -112.140000. running mean: -19.301399\n",
      "ep 32: ep_len:500 episode reward: total was 23.890000. running mean: -18.869485\n",
      "ep 32: ep_len:407 episode reward: total was 7.960000. running mean: -18.601190\n",
      "ep 32: ep_len:1045 episode reward: total was -27.700000. running mean: -18.692178\n",
      "ep 32: ep_len:795 episode reward: total was -61.080000. running mean: -19.116057\n",
      "ep 32: ep_len:2173 episode reward: total was -146.140000. running mean: -20.386296\n",
      "ep 32: ep_len:855 episode reward: total was -5.310000. running mean: -20.235533\n",
      "ep 32: ep_len:500 episode reward: total was -2.290000. running mean: -20.056078\n",
      "ep 32: ep_len:500 episode reward: total was 8.270000. running mean: -19.772817\n",
      "ep 32: ep_len:745 episode reward: total was -16.110000. running mean: -19.736189\n",
      "ep 32: ep_len:700 episode reward: total was -17.840000. running mean: -19.717227\n",
      "ep 32: ep_len:237 episode reward: total was 22.000000. running mean: -19.300055\n",
      "ep 32: ep_len:1520 episode reward: total was -82.790000. running mean: -19.934954\n",
      "ep 32: ep_len:500 episode reward: total was 23.370000. running mean: -19.501905\n",
      "ep 32: ep_len:389 episode reward: total was 34.000000. running mean: -18.966886\n",
      "ep 32: ep_len:720 episode reward: total was 37.220000. running mean: -18.405017\n",
      "ep 32: ep_len:580 episode reward: total was -15.050000. running mean: -18.371467\n",
      "ep 32: ep_len:765 episode reward: total was -53.060000. running mean: -18.718352\n",
      "ep 32: ep_len:500 episode reward: total was 25.850000. running mean: -18.272668\n",
      "ep 32: ep_len:625 episode reward: total was 12.540000. running mean: -17.964542\n",
      "ep 32: ep_len:575 episode reward: total was -22.130000. running mean: -18.006196\n",
      "ep 32: ep_len:292 episode reward: total was 20.500000. running mean: -17.621134\n",
      "ep 32: ep_len:500 episode reward: total was 8.730000. running mean: -17.357623\n",
      "ep 32: ep_len:500 episode reward: total was -7.280000. running mean: -17.256847\n",
      "ep 32: ep_len:500 episode reward: total was 26.860000. running mean: -16.815678\n",
      "ep 32: ep_len:1020 episode reward: total was -103.050000. running mean: -17.678021\n",
      "ep 32: ep_len:635 episode reward: total was -4.320000. running mean: -17.544441\n",
      "ep 32: ep_len:500 episode reward: total was 45.500000. running mean: -16.913997\n",
      "ep 32: ep_len:500 episode reward: total was 30.320000. running mean: -16.441657\n",
      "ep 32: ep_len:331 episode reward: total was 33.000000. running mean: -15.947240\n",
      "ep 32: ep_len:760 episode reward: total was -28.070000. running mean: -16.068468\n",
      "ep 32: ep_len:765 episode reward: total was -12.630000. running mean: -16.034083\n",
      "ep 32: ep_len:810 episode reward: total was -22.640000. running mean: -16.100142\n",
      "ep 32: ep_len:500 episode reward: total was 14.890000. running mean: -15.790241\n",
      "ep 32: ep_len:500 episode reward: total was 9.780000. running mean: -15.534539\n",
      "ep 32: ep_len:500 episode reward: total was 28.790000. running mean: -15.091293\n",
      "ep 32: ep_len:1065 episode reward: total was -58.290000. running mean: -15.523280\n",
      "ep 32: ep_len:500 episode reward: total was -8.230000. running mean: -15.450347\n",
      "ep 32: ep_len:500 episode reward: total was 30.810000. running mean: -14.987744\n",
      "ep 32: ep_len:905 episode reward: total was -1.340000. running mean: -14.851267\n",
      "ep 32: ep_len:595 episode reward: total was -17.160000. running mean: -14.874354\n",
      "ep 32: ep_len:570 episode reward: total was -29.080000. running mean: -15.016410\n",
      "ep 32: ep_len:955 episode reward: total was -18.310000. running mean: -15.049346\n",
      "ep 32: ep_len:505 episode reward: total was 5.830000. running mean: -14.840553\n",
      "ep 32: ep_len:1090 episode reward: total was 9.900000. running mean: -14.593147\n",
      "ep 32: ep_len:595 episode reward: total was 1.100000. running mean: -14.436216\n",
      "ep 32: ep_len:1302 episode reward: total was -195.390000. running mean: -16.245754\n",
      "ep 32: ep_len:695 episode reward: total was -2.670000. running mean: -16.109996\n",
      "ep 32: ep_len:500 episode reward: total was 29.830000. running mean: -15.650596\n",
      "ep 32: ep_len:500 episode reward: total was 25.910000. running mean: -15.234990\n",
      "ep 32: ep_len:500 episode reward: total was 30.290000. running mean: -14.779740\n",
      "ep 32: ep_len:530 episode reward: total was 35.310000. running mean: -14.278843\n",
      "ep 32: ep_len:202 episode reward: total was 18.500000. running mean: -13.951054\n",
      "ep 32: ep_len:1110 episode reward: total was -108.930000. running mean: -14.900844\n",
      "ep 32: ep_len:865 episode reward: total was -40.740000. running mean: -15.159235\n",
      "ep 32: ep_len:930 episode reward: total was -111.310000. running mean: -16.120743\n",
      "ep 32: ep_len:264 episode reward: total was 24.500000. running mean: -15.714536\n",
      "ep 32: ep_len:500 episode reward: total was -32.900000. running mean: -15.886390\n",
      "ep 32: ep_len:935 episode reward: total was 15.680000. running mean: -15.570726\n",
      "ep 32: ep_len:765 episode reward: total was -62.150000. running mean: -16.036519\n",
      "ep 32: ep_len:990 episode reward: total was 16.740000. running mean: -15.708754\n",
      "ep 32: ep_len:735 episode reward: total was -62.210000. running mean: -16.173766\n",
      "ep 32: ep_len:203 episode reward: total was 20.000000. running mean: -15.812029\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 32: ep_len:570 episode reward: total was -14.060000. running mean: -15.794508\n",
      "ep 32: ep_len:520 episode reward: total was -3.040000. running mean: -15.666963\n",
      "ep 32: ep_len:1482 episode reward: total was -230.000000. running mean: -17.810294\n",
      "ep 32: ep_len:173 episode reward: total was 17.000000. running mean: -17.462191\n",
      "ep 32: ep_len:150 episode reward: total was 13.500000. running mean: -17.152569\n",
      "ep 32: ep_len:695 episode reward: total was 31.880000. running mean: -16.662243\n",
      "ep 32: ep_len:825 episode reward: total was 27.760000. running mean: -16.218021\n",
      "ep 32: ep_len:775 episode reward: total was -21.210000. running mean: -16.267941\n",
      "ep 32: ep_len:590 episode reward: total was 3.400000. running mean: -16.071261\n",
      "ep 32: ep_len:800 episode reward: total was 20.880000. running mean: -15.701749\n",
      "ep 32: ep_len:515 episode reward: total was -15.180000. running mean: -15.696531\n",
      "ep 32: ep_len:2425 episode reward: total was -438.280000. running mean: -19.922366\n",
      "ep 32: ep_len:515 episode reward: total was -16.210000. running mean: -19.885242\n",
      "ep 32: ep_len:303 episode reward: total was -27.730000. running mean: -19.963690\n",
      "ep 32: ep_len:985 episode reward: total was 24.690000. running mean: -19.517153\n",
      "ep 32: ep_len:500 episode reward: total was 1.830000. running mean: -19.303681\n",
      "ep 32: ep_len:500 episode reward: total was 0.440000. running mean: -19.106244\n",
      "ep 32: ep_len:845 episode reward: total was 39.800000. running mean: -18.517182\n",
      "ep 32: ep_len:269 episode reward: total was 26.500000. running mean: -18.067010\n",
      "ep 32: ep_len:560 episode reward: total was 9.800000. running mean: -17.788340\n",
      "ep 32: ep_len:500 episode reward: total was -18.170000. running mean: -17.792157\n",
      "ep 32: ep_len:690 episode reward: total was 8.350000. running mean: -17.530735\n",
      "ep 32: ep_len:605 episode reward: total was -11.970000. running mean: -17.475128\n",
      "ep 32: ep_len:1013 episode reward: total was -69.200000. running mean: -17.992376\n",
      "ep 32: ep_len:500 episode reward: total was 3.170000. running mean: -17.780753\n",
      "ep 32: ep_len:645 episode reward: total was -33.100000. running mean: -17.933945\n",
      "ep 32: ep_len:615 episode reward: total was 18.240000. running mean: -17.572206\n",
      "ep 32: ep_len:500 episode reward: total was 2.240000. running mean: -17.374084\n",
      "ep 32: ep_len:290 episode reward: total was 27.500000. running mean: -16.925343\n",
      "ep 32: ep_len:500 episode reward: total was 21.320000. running mean: -16.542889\n",
      "ep 32: ep_len:655 episode reward: total was -8.950000. running mean: -16.466960\n",
      "ep 32: ep_len:500 episode reward: total was -13.300000. running mean: -16.435291\n",
      "ep 32: ep_len:610 episode reward: total was 4.960000. running mean: -16.221338\n",
      "ep 32: ep_len:2922 episode reward: total was -452.700000. running mean: -20.586125\n",
      "ep 32: ep_len:500 episode reward: total was 4.810000. running mean: -20.332163\n",
      "ep 32: ep_len:500 episode reward: total was 31.300000. running mean: -19.815842\n",
      "ep 32: ep_len:1465 episode reward: total was -114.770000. running mean: -20.765383\n",
      "ep 32: ep_len:500 episode reward: total was 21.690000. running mean: -20.340829\n",
      "ep 32: ep_len:905 episode reward: total was -14.250000. running mean: -20.279921\n",
      "ep 32: ep_len:905 episode reward: total was -2.810000. running mean: -20.105222\n",
      "ep 32: ep_len:500 episode reward: total was 45.500000. running mean: -19.449170\n",
      "ep 32: ep_len:1140 episode reward: total was -75.200000. running mean: -20.006678\n",
      "ep 32: ep_len:740 episode reward: total was 33.740000. running mean: -19.469211\n",
      "ep 32: ep_len:1540 episode reward: total was -50.100000. running mean: -19.775519\n",
      "ep 32: ep_len:500 episode reward: total was 13.230000. running mean: -19.445464\n",
      "ep 32: ep_len:500 episode reward: total was 25.880000. running mean: -18.992209\n",
      "ep 32: ep_len:520 episode reward: total was 17.750000. running mean: -18.624787\n",
      "ep 32: ep_len:1045 episode reward: total was -17.990000. running mean: -18.618439\n",
      "ep 32: ep_len:500 episode reward: total was 21.320000. running mean: -18.219055\n",
      "ep 32: ep_len:225 episode reward: total was 21.000000. running mean: -17.826864\n",
      "ep 32: ep_len:815 episode reward: total was -16.140000. running mean: -17.809996\n",
      "ep 32: ep_len:1075 episode reward: total was -15.130000. running mean: -17.783196\n",
      "ep 32: ep_len:675 episode reward: total was -0.200000. running mean: -17.607364\n",
      "ep 32: ep_len:500 episode reward: total was -8.870000. running mean: -17.519990\n",
      "ep 32: ep_len:500 episode reward: total was 2.240000. running mean: -17.322390\n",
      "ep 32: ep_len:900 episode reward: total was -20.960000. running mean: -17.358766\n",
      "ep 32: ep_len:500 episode reward: total was 0.100000. running mean: -17.184179\n",
      "ep 32: ep_len:192 episode reward: total was -5.000000. running mean: -17.062337\n",
      "ep 32: ep_len:1005 episode reward: total was -26.290000. running mean: -17.154614\n",
      "ep 32: ep_len:500 episode reward: total was -7.680000. running mean: -17.059867\n",
      "ep 32: ep_len:150 episode reward: total was 13.500000. running mean: -16.754269\n",
      "ep 32: ep_len:500 episode reward: total was -1.740000. running mean: -16.604126\n",
      "ep 32: ep_len:870 episode reward: total was -46.760000. running mean: -16.905685\n",
      "ep 32: ep_len:585 episode reward: total was -18.070000. running mean: -16.917328\n",
      "ep 32: ep_len:525 episode reward: total was -3.040000. running mean: -16.778555\n",
      "ep 32: ep_len:790 episode reward: total was 25.850000. running mean: -16.352269\n",
      "ep 32: ep_len:970 episode reward: total was -15.520000. running mean: -16.343946\n",
      "ep 32: ep_len:500 episode reward: total was 25.850000. running mean: -15.922007\n",
      "ep 32: ep_len:1260 episode reward: total was -84.580000. running mean: -16.608587\n",
      "ep 32: ep_len:1530 episode reward: total was -178.790000. running mean: -18.230401\n",
      "ep 32: ep_len:500 episode reward: total was 9.660000. running mean: -17.951497\n",
      "ep 32: ep_len:502 episode reward: total was -42.050000. running mean: -18.192482\n",
      "ep 32: ep_len:965 episode reward: total was -95.080000. running mean: -18.961357\n",
      "ep 32: ep_len:500 episode reward: total was 26.890000. running mean: -18.502844\n",
      "ep 32: ep_len:1210 episode reward: total was -75.890000. running mean: -19.076715\n",
      "ep 32: ep_len:1110 episode reward: total was -26.070000. running mean: -19.146648\n",
      "ep 32: ep_len:590 episode reward: total was -5.310000. running mean: -19.008282\n",
      "ep 32: ep_len:1530 episode reward: total was -212.080000. running mean: -20.938999\n",
      "ep 32: ep_len:735 episode reward: total was -18.720000. running mean: -20.916809\n",
      "ep 32: ep_len:700 episode reward: total was -1.160000. running mean: -20.719241\n",
      "ep 32: ep_len:520 episode reward: total was 2.230000. running mean: -20.489748\n",
      "ep 32: ep_len:500 episode reward: total was -10.710000. running mean: -20.391951\n",
      "ep 32: ep_len:700 episode reward: total was 20.530000. running mean: -19.982731\n",
      "ep 32: ep_len:950 episode reward: total was -16.990000. running mean: -19.952804\n",
      "ep 32: ep_len:500 episode reward: total was 3.630000. running mean: -19.716976\n",
      "ep 32: ep_len:535 episode reward: total was -4.240000. running mean: -19.562206\n",
      "ep 32: ep_len:500 episode reward: total was 4.110000. running mean: -19.325484\n",
      "ep 32: ep_len:880 episode reward: total was -76.060000. running mean: -19.892829\n",
      "ep 32: ep_len:860 episode reward: total was 0.760000. running mean: -19.686301\n",
      "ep 32: ep_len:456 episode reward: total was 29.190000. running mean: -19.197538\n",
      "ep 32: ep_len:565 episode reward: total was -21.140000. running mean: -19.216963\n",
      "ep 32: ep_len:10 episode reward: total was -0.500000. running mean: -19.029793\n",
      "ep 32: ep_len:500 episode reward: total was 11.150000. running mean: -18.727995\n",
      "ep 32: ep_len:500 episode reward: total was 4.600000. running mean: -18.494715\n",
      "ep 32: ep_len:665 episode reward: total was -5.270000. running mean: -18.362468\n",
      "ep 32: ep_len:500 episode reward: total was 5.340000. running mean: -18.125443\n",
      "ep 32: ep_len:625 episode reward: total was -17.990000. running mean: -18.124089\n",
      "ep 32: ep_len:880 episode reward: total was 21.080000. running mean: -17.732048\n",
      "ep 32: ep_len:500 episode reward: total was 16.890000. running mean: -17.385827\n",
      "ep 32: ep_len:640 episode reward: total was -27.050000. running mean: -17.482469\n",
      "ep 32: ep_len:790 episode reward: total was -10.650000. running mean: -17.414145\n",
      "ep 32: ep_len:674 episode reward: total was -131.000000. running mean: -18.550003\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 32: ep_len:241 episode reward: total was 21.000000. running mean: -18.154503\n",
      "ep 32: ep_len:500 episode reward: total was -2.810000. running mean: -18.001058\n",
      "ep 32: ep_len:705 episode reward: total was -6.290000. running mean: -17.883947\n",
      "ep 32: ep_len:525 episode reward: total was 16.600000. running mean: -17.539108\n",
      "ep 32: ep_len:825 episode reward: total was -37.410000. running mean: -17.737817\n",
      "ep 32: ep_len:500 episode reward: total was 24.240000. running mean: -17.318039\n",
      "ep 32: ep_len:500 episode reward: total was 16.910000. running mean: -16.975758\n",
      "ep 32: ep_len:555 episode reward: total was -25.980000. running mean: -17.065801\n",
      "ep 32: ep_len:555 episode reward: total was 16.570000. running mean: -16.729443\n",
      "ep 32: ep_len:590 episode reward: total was 27.380000. running mean: -16.288348\n",
      "ep 32: ep_len:530 episode reward: total was -32.320000. running mean: -16.448665\n",
      "ep 32: ep_len:500 episode reward: total was 33.180000. running mean: -15.952378\n",
      "ep 32: ep_len:500 episode reward: total was 23.920000. running mean: -15.553654\n",
      "ep 32: ep_len:1204 episode reward: total was -204.680000. running mean: -17.444918\n",
      "ep 32: ep_len:1422 episode reward: total was -227.530000. running mean: -19.545769\n",
      "ep 32: ep_len:500 episode reward: total was 4.410000. running mean: -19.306211\n",
      "ep 32: ep_len:925 episode reward: total was 12.050000. running mean: -18.992649\n",
      "ep 32: ep_len:500 episode reward: total was 14.010000. running mean: -18.662622\n",
      "ep 32: ep_len:505 episode reward: total was -10.120000. running mean: -18.577196\n",
      "ep 32: ep_len:264 episode reward: total was 26.000000. running mean: -18.131424\n",
      "ep 32: ep_len:216 episode reward: total was 21.500000. running mean: -17.735110\n",
      "ep 32: ep_len:500 episode reward: total was 5.830000. running mean: -17.499459\n",
      "ep 32: ep_len:500 episode reward: total was -24.820000. running mean: -17.572664\n",
      "ep 32: ep_len:605 episode reward: total was 0.670000. running mean: -17.390238\n",
      "ep 32: ep_len:580 episode reward: total was -19.090000. running mean: -17.407235\n",
      "ep 32: ep_len:500 episode reward: total was -15.480000. running mean: -17.387963\n",
      "ep 32: ep_len:590 episode reward: total was 29.800000. running mean: -16.916083\n",
      "ep 32: ep_len:695 episode reward: total was -12.280000. running mean: -16.869722\n",
      "ep 32: ep_len:500 episode reward: total was -1.130000. running mean: -16.712325\n",
      "ep 32: ep_len:500 episode reward: total was 4.570000. running mean: -16.499502\n",
      "ep 32: ep_len:500 episode reward: total was 19.970000. running mean: -16.134807\n",
      "ep 32: ep_len:1000 episode reward: total was -45.000000. running mean: -16.423459\n",
      "ep 32: ep_len:950 episode reward: total was -21.090000. running mean: -16.470124\n",
      "ep 32: ep_len:680 episode reward: total was -18.370000. running mean: -16.489123\n",
      "ep 32: ep_len:481 episode reward: total was 24.270000. running mean: -16.081532\n",
      "ep 32: ep_len:895 episode reward: total was -46.220000. running mean: -16.382916\n",
      "ep 32: ep_len:500 episode reward: total was -2.660000. running mean: -16.245687\n",
      "ep 32: ep_len:500 episode reward: total was 3.340000. running mean: -16.049830\n",
      "ep 32: ep_len:1438 episode reward: total was -140.500000. running mean: -17.294332\n",
      "ep 32: ep_len:575 episode reward: total was 42.260000. running mean: -16.698789\n",
      "ep 32: ep_len:500 episode reward: total was 9.540000. running mean: -16.436401\n",
      "ep 32: ep_len:2561 episode reward: total was -453.420000. running mean: -20.806237\n",
      "ep 32: ep_len:645 episode reward: total was -5.310000. running mean: -20.651275\n",
      "ep 32: ep_len:500 episode reward: total was 22.970000. running mean: -20.215062\n",
      "ep 32: ep_len:1040 episode reward: total was -29.580000. running mean: -20.308711\n",
      "ep 32: ep_len:423 episode reward: total was -18.550000. running mean: -20.291124\n",
      "ep 32: ep_len:500 episode reward: total was 17.320000. running mean: -19.915013\n",
      "ep 32: ep_len:750 episode reward: total was -8.650000. running mean: -19.802363\n",
      "ep 32: ep_len:545 episode reward: total was -10.100000. running mean: -19.705339\n",
      "ep 32: ep_len:500 episode reward: total was -5.230000. running mean: -19.560586\n",
      "ep 32: ep_len:955 episode reward: total was 16.700000. running mean: -19.197980\n",
      "ep 32: ep_len:500 episode reward: total was 29.750000. running mean: -18.708500\n",
      "ep 32: ep_len:890 episode reward: total was -26.030000. running mean: -18.781715\n",
      "ep 32: ep_len:500 episode reward: total was 17.800000. running mean: -18.415898\n",
      "ep 32: ep_len:500 episode reward: total was 6.100000. running mean: -18.170739\n",
      "ep 32: ep_len:586 episode reward: total was -117.000000. running mean: -19.159032\n",
      "ep 32: ep_len:505 episode reward: total was -19.270000. running mean: -19.160141\n",
      "ep 32: ep_len:585 episode reward: total was -33.220000. running mean: -19.300740\n",
      "ep 32: ep_len:500 episode reward: total was 31.220000. running mean: -18.795532\n",
      "ep 32: ep_len:700 episode reward: total was 11.920000. running mean: -18.488377\n",
      "ep 32: ep_len:640 episode reward: total was -47.250000. running mean: -18.775993\n",
      "ep 32: ep_len:500 episode reward: total was -14.900000. running mean: -18.737233\n",
      "ep 32: ep_len:610 episode reward: total was 8.710000. running mean: -18.462761\n",
      "ep 32: ep_len:675 episode reward: total was -8.800000. running mean: -18.366133\n",
      "ep 32: ep_len:1395 episode reward: total was -147.750000. running mean: -19.659972\n",
      "ep 32: ep_len:625 episode reward: total was -39.200000. running mean: -19.855372\n",
      "ep 32: ep_len:520 episode reward: total was -19.210000. running mean: -19.848919\n",
      "ep 32: ep_len:500 episode reward: total was 32.800000. running mean: -19.322429\n",
      "ep 32: ep_len:1700 episode reward: total was -191.940000. running mean: -21.048605\n",
      "ep 32: ep_len:590 episode reward: total was 13.430000. running mean: -20.703819\n",
      "ep 32: ep_len:1430 episode reward: total was -146.150000. running mean: -21.958281\n",
      "ep 32: ep_len:1015 episode reward: total was -65.690000. running mean: -22.395598\n",
      "ep 32: ep_len:835 episode reward: total was -58.460000. running mean: -22.756242\n",
      "ep 32: ep_len:1115 episode reward: total was -121.060000. running mean: -23.739280\n",
      "ep 32: ep_len:690 episode reward: total was -14.800000. running mean: -23.649887\n",
      "ep 32: ep_len:540 episode reward: total was -11.090000. running mean: -23.524288\n",
      "ep 32: ep_len:508 episode reward: total was -8.250000. running mean: -23.371545\n",
      "ep 32: ep_len:745 episode reward: total was 16.180000. running mean: -22.976030\n",
      "ep 32: ep_len:820 episode reward: total was -9.710000. running mean: -22.843369\n",
      "ep 32: ep_len:610 episode reward: total was 4.760000. running mean: -22.567336\n",
      "ep 32: ep_len:204 episode reward: total was 20.000000. running mean: -22.141662\n",
      "ep 32: ep_len:515 episode reward: total was 17.430000. running mean: -21.745946\n",
      "ep 32: ep_len:570 episode reward: total was 23.850000. running mean: -21.289986\n",
      "ep 32: ep_len:500 episode reward: total was 10.570000. running mean: -20.971386\n",
      "ep 32: ep_len:500 episode reward: total was 33.750000. running mean: -20.424173\n",
      "ep 32: ep_len:875 episode reward: total was -3.100000. running mean: -20.250931\n",
      "ep 32: ep_len:620 episode reward: total was -18.000000. running mean: -20.228422\n",
      "ep 32: ep_len:2346 episode reward: total was -321.570000. running mean: -23.241837\n",
      "ep 32: ep_len:406 episode reward: total was -12.060000. running mean: -23.130019\n",
      "ep 32: ep_len:500 episode reward: total was 16.660000. running mean: -22.732119\n",
      "ep 32: ep_len:500 episode reward: total was 22.970000. running mean: -22.275098\n",
      "ep 32: ep_len:820 episode reward: total was -27.180000. running mean: -22.324147\n",
      "ep 32: ep_len:500 episode reward: total was 30.290000. running mean: -21.798005\n",
      "ep 32: ep_len:805 episode reward: total was -34.770000. running mean: -21.927725\n",
      "ep 32: ep_len:500 episode reward: total was -7.400000. running mean: -21.782448\n",
      "ep 32: ep_len:500 episode reward: total was -2.660000. running mean: -21.591223\n",
      "ep 32: ep_len:880 episode reward: total was 18.170000. running mean: -21.193611\n",
      "ep 32: ep_len:500 episode reward: total was -45.770000. running mean: -21.439375\n",
      "ep 32: ep_len:152 episode reward: total was 15.000000. running mean: -21.074981\n",
      "ep 32: ep_len:178 episode reward: total was 17.500000. running mean: -20.689231\n",
      "ep 32: ep_len:500 episode reward: total was -1.460000. running mean: -20.496939\n",
      "ep 32: ep_len:500 episode reward: total was -5.410000. running mean: -20.346070\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 32: ep_len:238 episode reward: total was 23.500000. running mean: -19.907609\n",
      "ep 32: ep_len:500 episode reward: total was 0.310000. running mean: -19.705433\n",
      "ep 32: ep_len:870 episode reward: total was -101.970000. running mean: -20.528079\n",
      "ep 32: ep_len:500 episode reward: total was -8.310000. running mean: -20.405898\n",
      "ep 32: ep_len:500 episode reward: total was 10.730000. running mean: -20.094539\n",
      "ep 32: ep_len:895 episode reward: total was -1.650000. running mean: -19.910093\n",
      "ep 32: ep_len:500 episode reward: total was 4.350000. running mean: -19.667493\n",
      "ep 32: ep_len:294 episode reward: total was 27.500000. running mean: -19.195818\n",
      "ep 32: ep_len:500 episode reward: total was 26.830000. running mean: -18.735559\n",
      "ep 32: ep_len:176 episode reward: total was 17.500000. running mean: -18.373204\n",
      "ep 32: ep_len:127 episode reward: total was 12.500000. running mean: -18.064472\n",
      "ep 32: ep_len:740 episode reward: total was 17.770000. running mean: -17.706127\n",
      "ep 32: ep_len:800 episode reward: total was -7.180000. running mean: -17.600866\n",
      "ep 32: ep_len:885 episode reward: total was -28.580000. running mean: -17.710657\n",
      "ep 32: ep_len:750 episode reward: total was -11.680000. running mean: -17.650351\n",
      "ep 32: ep_len:500 episode reward: total was 9.380000. running mean: -17.380047\n",
      "ep 32: ep_len:571 episode reward: total was -76.190000. running mean: -17.968147\n",
      "ep 32: ep_len:530 episode reward: total was -15.150000. running mean: -17.939965\n",
      "ep 32: ep_len:500 episode reward: total was -11.690000. running mean: -17.877465\n",
      "ep 32: ep_len:580 episode reward: total was -25.560000. running mean: -17.954291\n",
      "ep 32: ep_len:500 episode reward: total was 3.410000. running mean: -17.740648\n",
      "ep 32: ep_len:2097 episode reward: total was -366.510000. running mean: -21.228341\n",
      "ep 32: ep_len:620 episode reward: total was 26.150000. running mean: -20.754558\n",
      "ep 32: ep_len:635 episode reward: total was -4.040000. running mean: -20.587412\n",
      "ep 32: ep_len:780 episode reward: total was -48.670000. running mean: -20.868238\n",
      "ep 32: ep_len:500 episode reward: total was 20.950000. running mean: -20.450056\n",
      "ep 32: ep_len:500 episode reward: total was -26.870000. running mean: -20.514255\n",
      "ep 32: ep_len:830 episode reward: total was -1.120000. running mean: -20.320313\n",
      "ep 32: ep_len:500 episode reward: total was -0.390000. running mean: -20.121010\n",
      "ep 32: ep_len:234 episode reward: total was 23.000000. running mean: -19.689800\n",
      "ep 32: ep_len:500 episode reward: total was 21.870000. running mean: -19.274202\n",
      "ep 32: ep_len:476 episode reward: total was 46.000000. running mean: -18.621460\n",
      "ep 32: ep_len:500 episode reward: total was 1.240000. running mean: -18.422845\n",
      "ep 32: ep_len:720 episode reward: total was 29.110000. running mean: -17.947517\n",
      "ep 32: ep_len:845 episode reward: total was -4.150000. running mean: -17.809541\n",
      "ep 32: ep_len:560 episode reward: total was -14.080000. running mean: -17.772246\n",
      "ep 32: ep_len:680 episode reward: total was 7.710000. running mean: -17.517423\n",
      "ep 32: ep_len:500 episode reward: total was 22.940000. running mean: -17.112849\n",
      "ep 32: ep_len:500 episode reward: total was 25.790000. running mean: -16.683821\n",
      "ep 32: ep_len:500 episode reward: total was 5.520000. running mean: -16.461783\n",
      "ep 32: ep_len:910 episode reward: total was -41.660000. running mean: -16.713765\n",
      "ep 32: ep_len:505 episode reward: total was -32.890000. running mean: -16.875527\n",
      "ep 32: ep_len:555 episode reward: total was -35.300000. running mean: -17.059772\n",
      "ep 32: ep_len:288 episode reward: total was 9.770000. running mean: -16.791474\n",
      "ep 32: ep_len:580 episode reward: total was -60.500000. running mean: -17.228559\n",
      "ep 32: ep_len:2398 episode reward: total was -397.240000. running mean: -21.028674\n",
      "ep 32: ep_len:640 episode reward: total was 23.350000. running mean: -20.584887\n",
      "ep 32: ep_len:253 episode reward: total was 22.000000. running mean: -20.159038\n",
      "ep 32: ep_len:500 episode reward: total was 27.290000. running mean: -19.684548\n",
      "ep 32: ep_len:500 episode reward: total was 19.790000. running mean: -19.289802\n",
      "ep 32: ep_len:500 episode reward: total was 47.000000. running mean: -18.626904\n",
      "ep 32: ep_len:650 episode reward: total was 0.240000. running mean: -18.438235\n",
      "ep 32: ep_len:765 episode reward: total was -8.620000. running mean: -18.340053\n",
      "ep 32: ep_len:151 episode reward: total was 15.000000. running mean: -18.006652\n",
      "ep 32: ep_len:805 episode reward: total was -6.620000. running mean: -17.892786\n",
      "ep 32: ep_len:500 episode reward: total was 8.250000. running mean: -17.631358\n",
      "ep 32: ep_len:965 episode reward: total was -8.090000. running mean: -17.535944\n",
      "ep 32: ep_len:610 episode reward: total was -19.030000. running mean: -17.550885\n",
      "ep 32: ep_len:500 episode reward: total was 1.400000. running mean: -17.361376\n",
      "ep 32: ep_len:189 episode reward: total was 18.500000. running mean: -17.002762\n",
      "ep 32: ep_len:500 episode reward: total was 0.250000. running mean: -16.830235\n",
      "ep 32: ep_len:495 episode reward: total was 26.210000. running mean: -16.399832\n",
      "ep 32: ep_len:580 episode reward: total was -31.210000. running mean: -16.547934\n",
      "ep 32: ep_len:845 episode reward: total was -12.680000. running mean: -16.509255\n",
      "ep 32: ep_len:1200 episode reward: total was -40.070000. running mean: -16.744862\n",
      "ep 32: ep_len:995 episode reward: total was -5.060000. running mean: -16.628014\n",
      "ep 32: ep_len:520 episode reward: total was -26.280000. running mean: -16.724533\n",
      "ep 32: ep_len:720 episode reward: total was -6.170000. running mean: -16.618988\n",
      "ep 32: ep_len:500 episode reward: total was 25.670000. running mean: -16.196098\n",
      "ep 32: ep_len:545 episode reward: total was 0.380000. running mean: -16.030337\n",
      "ep 32: ep_len:310 episode reward: total was -57.990000. running mean: -16.449934\n",
      "ep 32: ep_len:500 episode reward: total was 20.460000. running mean: -16.080834\n",
      "ep 32: ep_len:500 episode reward: total was 47.000000. running mean: -15.450026\n",
      "ep 32: ep_len:505 episode reward: total was 23.040000. running mean: -15.065126\n",
      "ep 32: ep_len:585 episode reward: total was -31.200000. running mean: -15.226475\n",
      "ep 32: ep_len:1105 episode reward: total was -53.490000. running mean: -15.609110\n",
      "ep 32: ep_len:500 episode reward: total was -24.230000. running mean: -15.695319\n",
      "ep 32: ep_len:265 episode reward: total was 25.000000. running mean: -15.288366\n",
      "ep 32: ep_len:701 episode reward: total was -117.810000. running mean: -16.313582\n",
      "ep 32: ep_len:960 episode reward: total was -20.630000. running mean: -16.356746\n",
      "ep 32: ep_len:1300 episode reward: total was -145.520000. running mean: -17.648379\n",
      "ep 32: ep_len:1010 episode reward: total was -24.630000. running mean: -17.718195\n",
      "ep 32: ep_len:500 episode reward: total was 21.260000. running mean: -17.328413\n",
      "ep 32: ep_len:920 episode reward: total was -9.080000. running mean: -17.245929\n",
      "ep 32: ep_len:413 episode reward: total was 17.770000. running mean: -16.895770\n",
      "ep 32: ep_len:500 episode reward: total was 2.310000. running mean: -16.703712\n",
      "ep 32: ep_len:500 episode reward: total was 21.750000. running mean: -16.319175\n",
      "ep 32: ep_len:605 episode reward: total was -28.130000. running mean: -16.437283\n",
      "ep 32: ep_len:500 episode reward: total was 24.930000. running mean: -16.023610\n",
      "ep 32: ep_len:500 episode reward: total was 8.240000. running mean: -15.780974\n",
      "ep 32: ep_len:1100 episode reward: total was 14.040000. running mean: -15.482764\n",
      "ep 32: ep_len:930 episode reward: total was -0.980000. running mean: -15.337737\n",
      "ep 32: ep_len:500 episode reward: total was 11.460000. running mean: -15.069759\n",
      "ep 32: ep_len:790 episode reward: total was 5.360000. running mean: -14.865462\n",
      "ep 32: ep_len:500 episode reward: total was -8.530000. running mean: -14.802107\n",
      "ep 32: ep_len:500 episode reward: total was 29.310000. running mean: -14.360986\n",
      "ep 32: ep_len:820 episode reward: total was 35.740000. running mean: -13.859976\n",
      "ep 32: ep_len:500 episode reward: total was 16.140000. running mean: -13.559976\n",
      "ep 32: ep_len:870 episode reward: total was -24.570000. running mean: -13.670077\n",
      "ep 32: ep_len:745 episode reward: total was -4.620000. running mean: -13.579576\n",
      "ep 32: ep_len:640 episode reward: total was 12.790000. running mean: -13.315880\n",
      "ep 32: ep_len:500 episode reward: total was -7.390000. running mean: -13.256621\n",
      "ep 32: ep_len:500 episode reward: total was -10.710000. running mean: -13.231155\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 32: ep_len:535 episode reward: total was 21.360000. running mean: -12.885244\n",
      "ep 32: ep_len:217 episode reward: total was -4.820000. running mean: -12.804591\n",
      "ep 32: ep_len:500 episode reward: total was 17.190000. running mean: -12.504645\n",
      "ep 32: ep_len:1190 episode reward: total was -13.530000. running mean: -12.514899\n",
      "ep 32: ep_len:650 episode reward: total was 28.940000. running mean: -12.100350\n",
      "ep 32: ep_len:775 episode reward: total was -27.170000. running mean: -12.251046\n",
      "ep 32: ep_len:3620 episode reward: total was -523.050000. running mean: -17.359036\n",
      "ep 32: ep_len:735 episode reward: total was -9.690000. running mean: -17.282345\n",
      "ep 32: ep_len:500 episode reward: total was -5.890000. running mean: -17.168422\n",
      "ep 32: ep_len:572 episode reward: total was -78.760000. running mean: -17.784338\n",
      "ep 32: ep_len:500 episode reward: total was 30.260000. running mean: -17.303894\n",
      "ep 32: ep_len:740 episode reward: total was -8.670000. running mean: -17.217555\n",
      "ep 32: ep_len:615 episode reward: total was -21.040000. running mean: -17.255780\n",
      "ep 32: ep_len:181 episode reward: total was 18.000000. running mean: -16.903222\n",
      "ep 32: ep_len:905 episode reward: total was -5.000000. running mean: -16.784190\n",
      "ep 32: ep_len:133 episode reward: total was 13.000000. running mean: -16.486348\n",
      "ep 32: ep_len:500 episode reward: total was 12.260000. running mean: -16.198884\n",
      "ep 32: ep_len:500 episode reward: total was -32.410000. running mean: -16.360996\n",
      "ep 32: ep_len:500 episode reward: total was 10.660000. running mean: -16.090786\n",
      "ep 32: ep_len:505 episode reward: total was 18.820000. running mean: -15.741678\n",
      "ep 32: ep_len:500 episode reward: total was 22.420000. running mean: -15.360061\n",
      "ep 32: ep_len:500 episode reward: total was -14.290000. running mean: -15.349360\n",
      "ep 32: ep_len:500 episode reward: total was 20.310000. running mean: -14.992767\n",
      "ep 32: ep_len:500 episode reward: total was 44.500000. running mean: -14.397839\n",
      "ep 32: ep_len:500 episode reward: total was 2.150000. running mean: -14.232361\n",
      "ep 32: ep_len:950 episode reward: total was 15.420000. running mean: -13.935837\n",
      "ep 32: ep_len:342 episode reward: total was 31.000000. running mean: -13.486479\n",
      "ep 32: ep_len:600 episode reward: total was -20.060000. running mean: -13.552214\n",
      "ep 32: ep_len:560 episode reward: total was 13.360000. running mean: -13.283092\n",
      "ep 32: ep_len:890 episode reward: total was -21.750000. running mean: -13.367761\n",
      "ep 32: ep_len:875 episode reward: total was 39.340000. running mean: -12.840683\n",
      "ep 32: ep_len:835 episode reward: total was 9.280000. running mean: -12.619476\n",
      "ep 32: ep_len:670 episode reward: total was 5.740000. running mean: -12.435882\n",
      "ep 32: ep_len:880 episode reward: total was -15.460000. running mean: -12.466123\n",
      "ep 32: ep_len:500 episode reward: total was 11.490000. running mean: -12.226562\n",
      "ep 32: ep_len:500 episode reward: total was -14.010000. running mean: -12.244396\n",
      "ep 32: ep_len:6620 episode reward: total was -1036.760000. running mean: -22.489552\n",
      "ep 32: ep_len:326 episode reward: total was 29.500000. running mean: -21.969657\n",
      "ep 32: ep_len:500 episode reward: total was -6.210000. running mean: -21.812060\n",
      "ep 32: ep_len:750 episode reward: total was 6.510000. running mean: -21.528839\n",
      "ep 32: ep_len:500 episode reward: total was 26.310000. running mean: -21.050451\n",
      "ep 32: ep_len:4330 episode reward: total was -728.690000. running mean: -28.126847\n",
      "ep 32: ep_len:500 episode reward: total was -8.660000. running mean: -27.932178\n",
      "ep 32: ep_len:500 episode reward: total was 11.040000. running mean: -27.542456\n",
      "ep 32: ep_len:635 episode reward: total was -4.840000. running mean: -27.315432\n",
      "ep 32: ep_len:695 episode reward: total was 18.930000. running mean: -26.852977\n",
      "ep 32: ep_len:4915 episode reward: total was -774.990000. running mean: -34.334348\n",
      "ep 32: ep_len:705 episode reward: total was -3.690000. running mean: -34.027904\n",
      "ep 32: ep_len:520 episode reward: total was 13.310000. running mean: -33.554525\n",
      "ep 32: ep_len:361 episode reward: total was 36.000000. running mean: -32.858980\n",
      "ep 32: ep_len:500 episode reward: total was 26.800000. running mean: -32.262390\n",
      "ep 32: ep_len:595 episode reward: total was -26.130000. running mean: -32.201066\n",
      "ep 32: ep_len:500 episode reward: total was 3.280000. running mean: -31.846255\n",
      "ep 32: ep_len:500 episode reward: total was 21.440000. running mean: -31.313393\n",
      "ep 32: ep_len:850 episode reward: total was 35.370000. running mean: -30.646559\n",
      "ep 32: ep_len:500 episode reward: total was -29.100000. running mean: -30.631093\n",
      "ep 32: ep_len:600 episode reward: total was -25.110000. running mean: -30.575882\n",
      "ep 32: ep_len:1955 episode reward: total was -323.380000. running mean: -33.503924\n",
      "ep 32: ep_len:500 episode reward: total was 10.280000. running mean: -33.066084\n",
      "ep 32: ep_len:750 episode reward: total was -16.300000. running mean: -32.898424\n",
      "ep 32: ep_len:500 episode reward: total was 2.760000. running mean: -32.541839\n",
      "ep 32: ep_len:1140 episode reward: total was -91.700000. running mean: -33.133421\n",
      "ep 32: ep_len:500 episode reward: total was 27.320000. running mean: -32.528887\n",
      "ep 32: ep_len:605 episode reward: total was 18.320000. running mean: -32.020398\n",
      "ep 32: ep_len:934 episode reward: total was -107.220000. running mean: -32.772394\n",
      "ep 32: ep_len:730 episode reward: total was -20.810000. running mean: -32.652770\n",
      "ep 32: ep_len:505 episode reward: total was -12.840000. running mean: -32.454642\n",
      "ep 32: ep_len:500 episode reward: total was 28.820000. running mean: -31.841896\n",
      "ep 32: ep_len:1126 episode reward: total was -82.270000. running mean: -32.346177\n",
      "ep 32: ep_len:915 episode reward: total was 21.140000. running mean: -31.811315\n",
      "ep 32: ep_len:500 episode reward: total was 32.740000. running mean: -31.165802\n",
      "ep 32: ep_len:500 episode reward: total was -8.290000. running mean: -30.937044\n",
      "ep 32: ep_len:500 episode reward: total was 14.280000. running mean: -30.484873\n",
      "ep 32: ep_len:1397 episode reward: total was -138.640000. running mean: -31.566425\n",
      "ep 32: ep_len:505 episode reward: total was 10.560000. running mean: -31.145161\n",
      "ep 32: ep_len:500 episode reward: total was -38.640000. running mean: -31.220109\n",
      "ep 32: ep_len:224 episode reward: total was 20.500000. running mean: -30.702908\n",
      "ep 32: ep_len:1240 episode reward: total was -97.560000. running mean: -31.371479\n",
      "ep 32: ep_len:785 episode reward: total was -6.160000. running mean: -31.119364\n",
      "ep 32: ep_len:680 episode reward: total was -29.510000. running mean: -31.103270\n",
      "ep 32: ep_len:835 episode reward: total was -17.570000. running mean: -30.967938\n",
      "ep 32: ep_len:560 episode reward: total was -2.970000. running mean: -30.687958\n",
      "ep 32: ep_len:500 episode reward: total was -13.740000. running mean: -30.518479\n",
      "ep 32: ep_len:609 episode reward: total was -61.440000. running mean: -30.827694\n",
      "ep 32: ep_len:1480 episode reward: total was -93.040000. running mean: -31.449817\n",
      "ep 32: ep_len:500 episode reward: total was 3.350000. running mean: -31.101819\n",
      "ep 32: ep_len:500 episode reward: total was 3.750000. running mean: -30.753301\n",
      "ep 32: ep_len:715 episode reward: total was -20.840000. running mean: -30.654168\n",
      "ep 32: ep_len:500 episode reward: total was -16.860000. running mean: -30.516226\n",
      "ep 32: ep_len:540 episode reward: total was -6.040000. running mean: -30.271464\n",
      "ep 32: ep_len:279 episode reward: total was 26.000000. running mean: -29.708749\n",
      "ep 32: ep_len:500 episode reward: total was -9.270000. running mean: -29.504361\n",
      "ep 32: ep_len:1040 episode reward: total was 13.340000. running mean: -29.075918\n",
      "ep 32: ep_len:1425 episode reward: total was -87.200000. running mean: -29.657159\n",
      "ep 32: ep_len:785 episode reward: total was -8.910000. running mean: -29.449687\n",
      "ep 32: ep_len:500 episode reward: total was 18.110000. running mean: -28.974090\n",
      "ep 32: ep_len:660 episode reward: total was -34.080000. running mean: -29.025149\n",
      "ep 32: ep_len:745 episode reward: total was -11.170000. running mean: -28.846598\n",
      "ep 32: ep_len:186 episode reward: total was 17.000000. running mean: -28.388132\n",
      "ep 32: ep_len:585 episode reward: total was -32.180000. running mean: -28.426051\n",
      "ep 32: ep_len:417 episode reward: total was 40.000000. running mean: -27.741790\n",
      "ep 32: ep_len:500 episode reward: total was 32.300000. running mean: -27.141372\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 32: ep_len:710 episode reward: total was -9.740000. running mean: -26.967358\n",
      "ep 32: ep_len:710 episode reward: total was -43.070000. running mean: -27.128385\n",
      "ep 32: ep_len:500 episode reward: total was 5.210000. running mean: -26.805001\n",
      "ep 32: ep_len:205 episode reward: total was 19.000000. running mean: -26.346951\n",
      "ep 32: ep_len:500 episode reward: total was -5.000000. running mean: -26.133481\n",
      "ep 32: ep_len:500 episode reward: total was 31.330000. running mean: -25.558847\n",
      "ep 32: ep_len:500 episode reward: total was 27.350000. running mean: -25.029758\n",
      "ep 32: ep_len:127 episode reward: total was 12.500000. running mean: -24.654461\n",
      "ep 32: ep_len:500 episode reward: total was -11.720000. running mean: -24.525116\n",
      "ep 32: ep_len:459 episode reward: total was 7.700000. running mean: -24.202865\n",
      "ep 32: ep_len:570 episode reward: total was -62.290000. running mean: -24.583736\n",
      "ep 32: ep_len:535 episode reward: total was -21.200000. running mean: -24.549899\n",
      "ep 32: ep_len:555 episode reward: total was -23.180000. running mean: -24.536200\n",
      "ep 32: ep_len:540 episode reward: total was -8.060000. running mean: -24.371438\n",
      "ep 32: ep_len:510 episode reward: total was 10.470000. running mean: -24.023023\n",
      "ep 32: ep_len:2775 episode reward: total was -428.480000. running mean: -28.067593\n",
      "ep 32: ep_len:590 episode reward: total was 32.310000. running mean: -27.463817\n",
      "ep 32: ep_len:5353 episode reward: total was -437.540000. running mean: -31.564579\n",
      "ep 32: ep_len:740 episode reward: total was -35.940000. running mean: -31.608333\n",
      "ep 32: ep_len:227 episode reward: total was -39.000000. running mean: -31.682250\n",
      "ep 32: ep_len:668 episode reward: total was -70.550000. running mean: -32.070928\n",
      "ep 32: ep_len:500 episode reward: total was 50.000000. running mean: -31.250218\n",
      "ep 32: ep_len:500 episode reward: total was 50.000000. running mean: -30.437716\n",
      "ep 32: ep_len:840 episode reward: total was 7.730000. running mean: -30.056039\n",
      "epsilon:0.010000 episode_count: 26006. steps_count: 18831614.000000\n",
      "ep 33: ep_len:500 episode reward: total was 19.850000. running mean: -29.556978\n",
      "ep 33: ep_len:795 episode reward: total was -9.540000. running mean: -29.356809\n",
      "ep 33: ep_len:500 episode reward: total was -1.950000. running mean: -29.082741\n",
      "ep 33: ep_len:500 episode reward: total was -23.290000. running mean: -29.024813\n",
      "ep 33: ep_len:540 episode reward: total was -14.120000. running mean: -28.875765\n",
      "ep 33: ep_len:500 episode reward: total was 3.980000. running mean: -28.547207\n",
      "ep 33: ep_len:750 episode reward: total was -10.300000. running mean: -28.364735\n",
      "ep 33: ep_len:565 episode reward: total was 17.290000. running mean: -27.908188\n",
      "ep 33: ep_len:1065 episode reward: total was -3.680000. running mean: -27.665906\n",
      "ep 33: ep_len:500 episode reward: total was 23.280000. running mean: -27.156447\n",
      "ep 33: ep_len:500 episode reward: total was 12.190000. running mean: -26.762983\n",
      "ep 33: ep_len:500 episode reward: total was 11.770000. running mean: -26.377653\n",
      "ep 33: ep_len:500 episode reward: total was 8.330000. running mean: -26.030576\n",
      "ep 33: ep_len:230 episode reward: total was 6.000000. running mean: -25.710270\n",
      "ep 33: ep_len:1005 episode reward: total was -54.600000. running mean: -25.999168\n",
      "ep 33: ep_len:815 episode reward: total was -35.790000. running mean: -26.097076\n",
      "ep 33: ep_len:500 episode reward: total was 29.800000. running mean: -25.538105\n",
      "ep 33: ep_len:500 episode reward: total was 4.050000. running mean: -25.242224\n",
      "ep 33: ep_len:500 episode reward: total was 6.100000. running mean: -24.928802\n",
      "ep 33: ep_len:735 episode reward: total was -2.550000. running mean: -24.705014\n",
      "ep 33: ep_len:500 episode reward: total was 10.480000. running mean: -24.353164\n",
      "ep 33: ep_len:1770 episode reward: total was -97.590000. running mean: -25.085532\n",
      "ep 33: ep_len:132 episode reward: total was 12.000000. running mean: -24.714677\n",
      "ep 33: ep_len:990 episode reward: total was -55.640000. running mean: -25.023930\n",
      "ep 33: ep_len:500 episode reward: total was -4.300000. running mean: -24.816691\n",
      "ep 33: ep_len:450 episode reward: total was 23.790000. running mean: -24.330624\n",
      "ep 33: ep_len:500 episode reward: total was -11.860000. running mean: -24.205918\n",
      "ep 33: ep_len:540 episode reward: total was -4.020000. running mean: -24.004059\n",
      "ep 33: ep_len:500 episode reward: total was 3.750000. running mean: -23.726518\n",
      "ep 33: ep_len:680 episode reward: total was -11.790000. running mean: -23.607153\n",
      "ep 33: ep_len:630 episode reward: total was -25.690000. running mean: -23.627981\n",
      "ep 33: ep_len:810 episode reward: total was -2.660000. running mean: -23.418301\n",
      "ep 33: ep_len:223 episode reward: total was 5.500000. running mean: -23.129118\n",
      "ep 33: ep_len:500 episode reward: total was -8.690000. running mean: -22.984727\n",
      "ep 33: ep_len:755 episode reward: total was 2.520000. running mean: -22.729680\n",
      "ep 33: ep_len:1626 episode reward: total was -320.990000. running mean: -25.712283\n",
      "ep 33: ep_len:505 episode reward: total was 29.810000. running mean: -25.157060\n",
      "ep 33: ep_len:910 episode reward: total was 3.480000. running mean: -24.870690\n",
      "ep 33: ep_len:600 episode reward: total was -14.000000. running mean: -24.761983\n",
      "ep 33: ep_len:500 episode reward: total was -11.780000. running mean: -24.632163\n",
      "ep 33: ep_len:500 episode reward: total was 6.990000. running mean: -24.315941\n",
      "ep 33: ep_len:1299 episode reward: total was -151.980000. running mean: -25.592582\n",
      "ep 33: ep_len:318 episode reward: total was 31.500000. running mean: -25.021656\n",
      "ep 33: ep_len:540 episode reward: total was -2.000000. running mean: -24.791440\n",
      "ep 33: ep_len:510 episode reward: total was -2.060000. running mean: -24.564125\n",
      "ep 33: ep_len:550 episode reward: total was 17.320000. running mean: -24.145284\n",
      "ep 33: ep_len:500 episode reward: total was -9.670000. running mean: -24.000531\n",
      "ep 33: ep_len:224 episode reward: total was 7.500000. running mean: -23.685526\n",
      "ep 33: ep_len:20815 episode reward: total was -4052.940000. running mean: -63.978071\n",
      "ep 33: ep_len:720 episode reward: total was -11.740000. running mean: -63.455690\n",
      "ep 33: ep_len:1100 episode reward: total was -45.300000. running mean: -63.274133\n",
      "ep 33: ep_len:236 episode reward: total was 5.500000. running mean: -62.586392\n",
      "ep 33: ep_len:500 episode reward: total was -4.000000. running mean: -62.000528\n",
      "ep 33: ep_len:169 episode reward: total was 7.500000. running mean: -61.305522\n",
      "ep 33: ep_len:127 episode reward: total was 9.500000. running mean: -60.597467\n",
      "ep 33: ep_len:800 episode reward: total was -37.070000. running mean: -60.362192\n",
      "ep 33: ep_len:625 episode reward: total was -50.310000. running mean: -60.261671\n",
      "ep 33: ep_len:780 episode reward: total was -34.710000. running mean: -60.006154\n",
      "ep 33: ep_len:770 episode reward: total was -50.800000. running mean: -59.914092\n",
      "ep 33: ep_len:483 episode reward: total was -31.800000. running mean: -59.632951\n",
      "ep 33: ep_len:500 episode reward: total was 9.690000. running mean: -58.939722\n",
      "ep 33: ep_len:500 episode reward: total was -29.680000. running mean: -58.647125\n",
      "ep 33: ep_len:930 episode reward: total was -66.530000. running mean: -58.725953\n",
      "ep 33: ep_len:500 episode reward: total was 22.730000. running mean: -57.911394\n",
      "ep 33: ep_len:525 episode reward: total was -65.660000. running mean: -57.988880\n",
      "ep 33: ep_len:183 episode reward: total was 19.000000. running mean: -57.218991\n",
      "ep 33: ep_len:500 episode reward: total was -12.820000. running mean: -56.775001\n",
      "ep 33: ep_len:500 episode reward: total was -38.010000. running mean: -56.587351\n",
      "ep 33: ep_len:1325 episode reward: total was -110.540000. running mean: -57.126878\n",
      "ep 33: ep_len:565 episode reward: total was -42.350000. running mean: -56.979109\n",
      "ep 33: ep_len:500 episode reward: total was 13.250000. running mean: -56.276818\n",
      "ep 33: ep_len:635 episode reward: total was -7.870000. running mean: -55.792750\n",
      "ep 33: ep_len:750 episode reward: total was -6.630000. running mean: -55.301122\n",
      "ep 33: ep_len:199 episode reward: total was 19.500000. running mean: -54.553111\n",
      "ep 33: ep_len:895 episode reward: total was -12.190000. running mean: -54.129480\n",
      "ep 33: ep_len:700 episode reward: total was -15.820000. running mean: -53.746385\n",
      "ep 33: ep_len:500 episode reward: total was -40.570000. running mean: -53.614621\n",
      "ep 33: ep_len:500 episode reward: total was 0.230000. running mean: -53.076175\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 33: ep_len:745 episode reward: total was -21.850000. running mean: -52.763913\n",
      "ep 33: ep_len:500 episode reward: total was -37.980000. running mean: -52.616074\n",
      "ep 33: ep_len:640 episode reward: total was 2.350000. running mean: -52.066413\n",
      "ep 33: ep_len:500 episode reward: total was -20.870000. running mean: -51.754449\n",
      "ep 33: ep_len:1662 episode reward: total was -257.700000. running mean: -53.813905\n",
      "ep 33: ep_len:500 episode reward: total was 14.250000. running mean: -53.133266\n",
      "ep 33: ep_len:960 episode reward: total was 15.140000. running mean: -52.450533\n",
      "ep 33: ep_len:63 episode reward: total was 6.000000. running mean: -51.866028\n",
      "ep 33: ep_len:500 episode reward: total was -5.080000. running mean: -51.398167\n",
      "ep 33: ep_len:167 episode reward: total was 16.500000. running mean: -50.719186\n",
      "ep 33: ep_len:710 episode reward: total was -35.710000. running mean: -50.569094\n",
      "ep 33: ep_len:750 episode reward: total was -3.040000. running mean: -50.093803\n",
      "ep 33: ep_len:650 episode reward: total was -26.020000. running mean: -49.853065\n",
      "ep 33: ep_len:500 episode reward: total was 17.340000. running mean: -49.181134\n",
      "ep 33: ep_len:500 episode reward: total was 26.260000. running mean: -48.426723\n",
      "ep 33: ep_len:1220 episode reward: total was -26.540000. running mean: -48.207856\n",
      "ep 33: ep_len:1700 episode reward: total was -236.020000. running mean: -50.085977\n",
      "ep 33: ep_len:500 episode reward: total was 18.750000. running mean: -49.397617\n",
      "ep 33: ep_len:560 episode reward: total was -34.280000. running mean: -49.246441\n",
      "ep 33: ep_len:500 episode reward: total was 45.500000. running mean: -48.298977\n",
      "ep 33: ep_len:960 episode reward: total was -76.640000. running mean: -48.582387\n",
      "ep 33: ep_len:129 episode reward: total was 13.000000. running mean: -47.966563\n",
      "ep 33: ep_len:500 episode reward: total was -5.290000. running mean: -47.539798\n",
      "ep 33: ep_len:520 episode reward: total was -32.340000. running mean: -47.387800\n",
      "ep 33: ep_len:500 episode reward: total was -2.870000. running mean: -46.942622\n",
      "ep 33: ep_len:640 episode reward: total was -5.840000. running mean: -46.531595\n",
      "ep 33: ep_len:500 episode reward: total was -8.660000. running mean: -46.152879\n",
      "ep 33: ep_len:1119 episode reward: total was -145.260000. running mean: -47.143951\n",
      "ep 33: ep_len:500 episode reward: total was 26.800000. running mean: -46.404511\n",
      "ep 33: ep_len:815 episode reward: total was -26.560000. running mean: -46.206066\n",
      "ep 33: ep_len:1292 episode reward: total was -18.540000. running mean: -45.929405\n",
      "ep 33: ep_len:575 episode reward: total was -20.110000. running mean: -45.671211\n",
      "ep 33: ep_len:204 episode reward: total was 20.000000. running mean: -45.014499\n",
      "ep 33: ep_len:600 episode reward: total was -27.130000. running mean: -44.835654\n",
      "ep 33: ep_len:295 episode reward: total was 28.000000. running mean: -44.107298\n",
      "ep 33: ep_len:201 episode reward: total was 20.000000. running mean: -43.466225\n",
      "ep 33: ep_len:500 episode reward: total was 22.480000. running mean: -42.806762\n",
      "ep 33: ep_len:925 episode reward: total was 0.580000. running mean: -42.372895\n",
      "ep 33: ep_len:20090 episode reward: total was -3750.480000. running mean: -79.453966\n",
      "ep 33: ep_len:500 episode reward: total was 37.250000. running mean: -78.286926\n",
      "ep 33: ep_len:500 episode reward: total was 15.790000. running mean: -77.346157\n",
      "ep 33: ep_len:825 episode reward: total was -33.750000. running mean: -76.910195\n",
      "ep 33: ep_len:940 episode reward: total was -7.770000. running mean: -76.218793\n",
      "ep 33: ep_len:760 episode reward: total was -34.810000. running mean: -75.804705\n",
      "ep 33: ep_len:810 episode reward: total was -13.580000. running mean: -75.182458\n",
      "ep 33: ep_len:500 episode reward: total was 22.240000. running mean: -74.208234\n",
      "ep 33: ep_len:500 episode reward: total was -5.630000. running mean: -73.522451\n",
      "ep 33: ep_len:9260 episode reward: total was -500.640000. running mean: -77.793627\n",
      "ep 33: ep_len:500 episode reward: total was -25.980000. running mean: -77.275491\n",
      "ep 33: ep_len:830 episode reward: total was -5.240000. running mean: -76.555136\n",
      "ep 33: ep_len:500 episode reward: total was 47.000000. running mean: -75.319584\n",
      "ep 33: ep_len:715 episode reward: total was 27.910000. running mean: -74.287289\n",
      "ep 33: ep_len:750 episode reward: total was -23.800000. running mean: -73.782416\n",
      "ep 33: ep_len:112 episode reward: total was 11.000000. running mean: -72.934592\n",
      "ep 33: ep_len:500 episode reward: total was 15.760000. running mean: -72.047646\n",
      "ep 33: ep_len:940 episode reward: total was -40.280000. running mean: -71.729969\n",
      "ep 33: ep_len:736 episode reward: total was -147.000000. running mean: -72.482669\n",
      "ep 33: ep_len:580 episode reward: total was 11.240000. running mean: -71.645443\n",
      "ep 33: ep_len:600 episode reward: total was 21.740000. running mean: -70.711588\n",
      "ep 33: ep_len:500 episode reward: total was 26.770000. running mean: -69.736772\n",
      "ep 33: ep_len:2230 episode reward: total was -339.980000. running mean: -72.439205\n",
      "ep 33: ep_len:1020 episode reward: total was -37.910000. running mean: -72.093913\n",
      "ep 33: ep_len:500 episode reward: total was -23.040000. running mean: -71.603374\n",
      "ep 33: ep_len:985 episode reward: total was -54.890000. running mean: -71.436240\n",
      "ep 33: ep_len:500 episode reward: total was 47.000000. running mean: -70.251877\n",
      "ep 33: ep_len:500 episode reward: total was 24.320000. running mean: -69.306159\n",
      "ep 33: ep_len:500 episode reward: total was -32.500000. running mean: -68.938097\n",
      "ep 33: ep_len:1620 episode reward: total was -149.250000. running mean: -69.741216\n",
      "ep 33: ep_len:500 episode reward: total was 24.260000. running mean: -68.801204\n",
      "ep 33: ep_len:500 episode reward: total was -22.520000. running mean: -68.338392\n",
      "ep 33: ep_len:89 episode reward: total was 8.500000. running mean: -67.570008\n",
      "ep 33: ep_len:610 episode reward: total was -68.520000. running mean: -67.579508\n",
      "ep 33: ep_len:253 episode reward: total was 23.500000. running mean: -66.668713\n",
      "ep 33: ep_len:500 episode reward: total was 0.530000. running mean: -65.996726\n",
      "ep 33: ep_len:1025 episode reward: total was 20.730000. running mean: -65.129458\n",
      "ep 33: ep_len:500 episode reward: total was 14.250000. running mean: -64.335664\n",
      "ep 33: ep_len:500 episode reward: total was -18.300000. running mean: -63.875307\n",
      "ep 33: ep_len:760 episode reward: total was -53.400000. running mean: -63.770554\n",
      "ep 33: ep_len:6804 episode reward: total was -1300.490000. running mean: -76.137749\n",
      "ep 33: ep_len:500 episode reward: total was -3.810000. running mean: -75.414471\n",
      "ep 33: ep_len:229 episode reward: total was 22.500000. running mean: -74.435326\n",
      "ep 33: ep_len:500 episode reward: total was -9.080000. running mean: -73.781773\n",
      "ep 33: ep_len:875 episode reward: total was -25.360000. running mean: -73.297555\n",
      "ep 33: ep_len:500 episode reward: total was 7.910000. running mean: -72.485480\n",
      "ep 33: ep_len:865 episode reward: total was 4.980000. running mean: -71.710825\n",
      "ep 33: ep_len:900 episode reward: total was 6.520000. running mean: -70.928517\n",
      "ep 33: ep_len:620 episode reward: total was -2.850000. running mean: -70.247732\n",
      "ep 33: ep_len:660 episode reward: total was 16.250000. running mean: -69.382754\n",
      "ep 33: ep_len:500 episode reward: total was 26.310000. running mean: -68.425827\n",
      "ep 33: ep_len:660 episode reward: total was -48.220000. running mean: -68.223769\n",
      "ep 33: ep_len:735 episode reward: total was -34.720000. running mean: -67.888731\n",
      "ep 33: ep_len:695 episode reward: total was -12.800000. running mean: -67.337844\n",
      "ep 33: ep_len:560 episode reward: total was -39.330000. running mean: -67.057765\n",
      "ep 33: ep_len:500 episode reward: total was 7.110000. running mean: -66.316087\n",
      "ep 33: ep_len:595 episode reward: total was 27.540000. running mean: -65.377527\n",
      "ep 33: ep_len:478 episode reward: total was 47.500000. running mean: -64.248751\n",
      "ep 33: ep_len:500 episode reward: total was 24.290000. running mean: -63.363364\n",
      "ep 33: ep_len:985 episode reward: total was -2.870000. running mean: -62.758430\n",
      "ep 33: ep_len:678 episode reward: total was -69.400000. running mean: -62.824846\n",
      "ep 33: ep_len:500 episode reward: total was -20.000000. running mean: -62.396597\n",
      "ep 33: ep_len:655 episode reward: total was -4.800000. running mean: -61.820631\n",
      "ep 33: ep_len:204 episode reward: total was 20.000000. running mean: -61.002425\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 33: ep_len:990 episode reward: total was -26.070000. running mean: -60.653101\n",
      "ep 33: ep_len:690 episode reward: total was -13.820000. running mean: -60.184770\n",
      "ep 33: ep_len:206 episode reward: total was 20.500000. running mean: -59.377922\n",
      "ep 33: ep_len:555 episode reward: total was 13.780000. running mean: -58.646343\n",
      "ep 33: ep_len:219 episode reward: total was 18.500000. running mean: -57.874879\n",
      "ep 33: ep_len:720 episode reward: total was -17.800000. running mean: -57.474131\n",
      "ep 33: ep_len:500 episode reward: total was 47.000000. running mean: -56.429389\n",
      "ep 33: ep_len:745 episode reward: total was 7.240000. running mean: -55.792695\n",
      "ep 33: ep_len:1934 episode reward: total was -299.990000. running mean: -58.234669\n",
      "ep 33: ep_len:570 episode reward: total was -32.240000. running mean: -57.974722\n",
      "ep 33: ep_len:805 episode reward: total was -21.100000. running mean: -57.605975\n",
      "ep 33: ep_len:575 episode reward: total was -68.000000. running mean: -57.709915\n",
      "ep 33: ep_len:197 episode reward: total was 19.500000. running mean: -56.937816\n",
      "ep 33: ep_len:500 episode reward: total was 12.190000. running mean: -56.246538\n",
      "ep 33: ep_len:68 episode reward: total was 3.500000. running mean: -55.649072\n",
      "ep 33: ep_len:535 episode reward: total was -16.150000. running mean: -55.254081\n",
      "ep 33: ep_len:500 episode reward: total was 30.780000. running mean: -54.393741\n",
      "ep 33: ep_len:510 episode reward: total was -12.160000. running mean: -53.971403\n",
      "ep 33: ep_len:620 episode reward: total was 2.820000. running mean: -53.403489\n",
      "ep 33: ep_len:690 episode reward: total was 10.720000. running mean: -52.762254\n",
      "ep 33: ep_len:650 episode reward: total was -8.850000. running mean: -52.323132\n",
      "ep 33: ep_len:176 episode reward: total was 17.500000. running mean: -51.624900\n",
      "ep 33: ep_len:174 episode reward: total was 15.500000. running mean: -50.953651\n",
      "ep 33: ep_len:398 episode reward: total was 38.000000. running mean: -50.064115\n",
      "ep 33: ep_len:117 episode reward: total was 11.500000. running mean: -49.448474\n",
      "ep 33: ep_len:910 episode reward: total was -75.480000. running mean: -49.708789\n",
      "ep 33: ep_len:580 episode reward: total was -13.030000. running mean: -49.342001\n",
      "ep 33: ep_len:1991 episode reward: total was -260.670000. running mean: -51.455281\n",
      "ep 33: ep_len:500 episode reward: total was 23.280000. running mean: -50.707928\n",
      "ep 33: ep_len:595 episode reward: total was -33.200000. running mean: -50.532849\n",
      "ep 33: ep_len:830 episode reward: total was 2.780000. running mean: -49.999721\n",
      "ep 33: ep_len:1055 episode reward: total was 8.750000. running mean: -49.412223\n",
      "ep 33: ep_len:500 episode reward: total was 30.810000. running mean: -48.610001\n",
      "ep 33: ep_len:635 episode reward: total was -25.040000. running mean: -48.374301\n",
      "ep 33: ep_len:980 episode reward: total was 26.020000. running mean: -47.630358\n",
      "ep 33: ep_len:591 episode reward: total was -40.280000. running mean: -47.556855\n",
      "ep 33: ep_len:585 episode reward: total was -13.020000. running mean: -47.211486\n",
      "ep 33: ep_len:718 episode reward: total was -64.300000. running mean: -47.382371\n",
      "ep 33: ep_len:500 episode reward: total was -20.810000. running mean: -47.116647\n",
      "ep 33: ep_len:1159 episode reward: total was -113.430000. running mean: -47.779781\n",
      "ep 33: ep_len:845 episode reward: total was 1.710000. running mean: -47.284883\n",
      "ep 33: ep_len:680 episode reward: total was -6.770000. running mean: -46.879734\n",
      "ep 33: ep_len:535 episode reward: total was -17.160000. running mean: -46.582537\n",
      "ep 33: ep_len:149 episode reward: total was 14.500000. running mean: -45.971712\n",
      "ep 33: ep_len:570 episode reward: total was -44.780000. running mean: -45.959794\n",
      "ep 33: ep_len:244 episode reward: total was 22.500000. running mean: -45.275197\n",
      "ep 33: ep_len:825 episode reward: total was 9.030000. running mean: -44.732145\n",
      "ep 33: ep_len:500 episode reward: total was 22.850000. running mean: -44.056323\n",
      "ep 33: ep_len:690 episode reward: total was -2.510000. running mean: -43.640860\n",
      "ep 33: ep_len:500 episode reward: total was 9.750000. running mean: -43.106951\n",
      "ep 33: ep_len:500 episode reward: total was 4.290000. running mean: -42.632982\n",
      "ep 33: ep_len:625 episode reward: total was -10.640000. running mean: -42.313052\n",
      "ep 33: ep_len:740 episode reward: total was -14.730000. running mean: -42.037221\n",
      "ep 33: ep_len:815 episode reward: total was -4.230000. running mean: -41.659149\n",
      "ep 33: ep_len:500 episode reward: total was 25.490000. running mean: -40.987658\n",
      "ep 33: ep_len:780 episode reward: total was 17.100000. running mean: -40.406781\n",
      "ep 33: ep_len:775 episode reward: total was -42.790000. running mean: -40.430613\n",
      "ep 33: ep_len:535 episode reward: total was 28.250000. running mean: -39.743807\n",
      "ep 33: ep_len:500 episode reward: total was 9.750000. running mean: -39.248869\n",
      "ep 33: ep_len:565 episode reward: total was 12.840000. running mean: -38.727980\n",
      "ep 33: ep_len:490 episode reward: total was 32.290000. running mean: -38.017801\n",
      "ep 33: ep_len:500 episode reward: total was 32.310000. running mean: -37.314523\n",
      "ep 33: ep_len:500 episode reward: total was 17.710000. running mean: -36.764277\n",
      "ep 33: ep_len:1231 episode reward: total was -205.220000. running mean: -38.448835\n",
      "ep 33: ep_len:500 episode reward: total was 2.060000. running mean: -38.043746\n",
      "ep 33: ep_len:650 episode reward: total was 14.470000. running mean: -37.518609\n",
      "ep 33: ep_len:500 episode reward: total was -31.240000. running mean: -37.455823\n",
      "ep 33: ep_len:500 episode reward: total was -24.570000. running mean: -37.326965\n",
      "ep 33: ep_len:500 episode reward: total was 23.280000. running mean: -36.720895\n",
      "ep 33: ep_len:500 episode reward: total was 13.020000. running mean: -36.223486\n",
      "ep 33: ep_len:645 episode reward: total was -4.200000. running mean: -35.903251\n",
      "ep 33: ep_len:690 episode reward: total was -14.830000. running mean: -35.692519\n",
      "ep 33: ep_len:685 episode reward: total was -3.730000. running mean: -35.372893\n",
      "ep 33: ep_len:615 episode reward: total was -5.890000. running mean: -35.078064\n",
      "ep 33: ep_len:500 episode reward: total was 0.780000. running mean: -34.719484\n",
      "ep 33: ep_len:1025 episode reward: total was -94.250000. running mean: -35.314789\n",
      "ep 33: ep_len:500 episode reward: total was 3.900000. running mean: -34.922641\n",
      "ep 33: ep_len:206 episode reward: total was 20.500000. running mean: -34.368415\n",
      "ep 33: ep_len:169 episode reward: total was 16.500000. running mean: -33.859730\n",
      "ep 33: ep_len:555 episode reward: total was -17.120000. running mean: -33.692333\n",
      "ep 33: ep_len:1160 episode reward: total was -4.500000. running mean: -33.400410\n",
      "ep 33: ep_len:565 episode reward: total was -14.230000. running mean: -33.208706\n",
      "ep 33: ep_len:334 episode reward: total was 2.030000. running mean: -32.856319\n",
      "ep 33: ep_len:494 episode reward: total was 31.290000. running mean: -32.214856\n",
      "ep 33: ep_len:33 episode reward: total was 3.000000. running mean: -31.862707\n",
      "ep 33: ep_len:500 episode reward: total was 14.320000. running mean: -31.400880\n",
      "ep 33: ep_len:1080 episode reward: total was -152.940000. running mean: -32.616271\n",
      "ep 33: ep_len:750 episode reward: total was 16.290000. running mean: -32.127208\n",
      "ep 33: ep_len:1205 episode reward: total was 4.370000. running mean: -31.762236\n",
      "ep 33: ep_len:870 episode reward: total was 19.530000. running mean: -31.249314\n",
      "ep 33: ep_len:227 episode reward: total was 22.500000. running mean: -30.711821\n",
      "ep 33: ep_len:500 episode reward: total was -14.530000. running mean: -30.550003\n",
      "ep 33: ep_len:500 episode reward: total was 11.460000. running mean: -30.129903\n",
      "ep 33: ep_len:178 episode reward: total was 16.000000. running mean: -29.668604\n",
      "ep 33: ep_len:122 episode reward: total was 12.000000. running mean: -29.251917\n",
      "ep 33: ep_len:1040 episode reward: total was 21.810000. running mean: -28.741298\n",
      "ep 33: ep_len:1025 episode reward: total was -4.250000. running mean: -28.496385\n",
      "ep 33: ep_len:246 episode reward: total was 24.500000. running mean: -27.966421\n",
      "ep 33: ep_len:565 episode reward: total was -0.940000. running mean: -27.696157\n",
      "ep 33: ep_len:500 episode reward: total was 16.790000. running mean: -27.251296\n",
      "ep 33: ep_len:500 episode reward: total was 6.220000. running mean: -26.916583\n",
      "ep 33: ep_len:181 episode reward: total was 18.000000. running mean: -26.467417\n",
      "ep 33: ep_len:242 episode reward: total was 24.000000. running mean: -25.962743\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 33: ep_len:635 episode reward: total was 0.210000. running mean: -25.701015\n",
      "ep 33: ep_len:246 episode reward: total was 23.000000. running mean: -25.214005\n",
      "ep 33: ep_len:905 episode reward: total was 15.210000. running mean: -24.809765\n",
      "ep 33: ep_len:500 episode reward: total was 34.760000. running mean: -24.214067\n",
      "ep 33: ep_len:5302 episode reward: total was -579.270000. running mean: -29.764627\n",
      "ep 33: ep_len:680 episode reward: total was 0.300000. running mean: -29.463981\n",
      "ep 33: ep_len:500 episode reward: total was 20.860000. running mean: -28.960741\n",
      "ep 33: ep_len:178 episode reward: total was 17.500000. running mean: -28.496133\n",
      "ep 33: ep_len:147 episode reward: total was 14.500000. running mean: -28.066172\n",
      "ep 33: ep_len:905 episode reward: total was 36.770000. running mean: -27.417810\n",
      "ep 33: ep_len:500 episode reward: total was 15.410000. running mean: -26.989532\n",
      "ep 33: ep_len:500 episode reward: total was -4.270000. running mean: -26.762337\n",
      "ep 33: ep_len:500 episode reward: total was 23.800000. running mean: -26.256713\n",
      "ep 33: ep_len:500 episode reward: total was -13.150000. running mean: -26.125646\n",
      "ep 33: ep_len:12128 episode reward: total was -1944.760000. running mean: -45.311990\n",
      "ep 33: ep_len:890 episode reward: total was 24.190000. running mean: -44.616970\n",
      "ep 33: ep_len:530 episode reward: total was -12.120000. running mean: -44.292000\n",
      "ep 33: ep_len:670 episode reward: total was 4.360000. running mean: -43.805480\n",
      "ep 33: ep_len:271 episode reward: total was 17.000000. running mean: -43.197425\n",
      "ep 33: ep_len:635 episode reward: total was -63.420000. running mean: -43.399651\n",
      "ep 33: ep_len:1045 episode reward: total was -69.670000. running mean: -43.662355\n",
      "ep 33: ep_len:500 episode reward: total was -6.700000. running mean: -43.292731\n",
      "ep 33: ep_len:500 episode reward: total was 19.420000. running mean: -42.665604\n",
      "ep 33: ep_len:735 episode reward: total was -11.710000. running mean: -42.356048\n",
      "ep 33: ep_len:1542 episode reward: total was -61.380000. running mean: -42.546287\n",
      "ep 33: ep_len:1440 episode reward: total was -60.800000. running mean: -42.728824\n",
      "ep 33: ep_len:1060 episode reward: total was 7.660000. running mean: -42.224936\n",
      "ep 33: ep_len:500 episode reward: total was 21.990000. running mean: -41.582787\n",
      "ep 33: ep_len:730 episode reward: total was 26.280000. running mean: -40.904159\n",
      "ep 33: ep_len:585 episode reward: total was -21.100000. running mean: -40.706117\n",
      "ep 33: ep_len:995 episode reward: total was 9.240000. running mean: -40.206656\n",
      "ep 33: ep_len:995 episode reward: total was -38.460000. running mean: -40.189190\n",
      "ep 33: ep_len:500 episode reward: total was -11.200000. running mean: -39.899298\n",
      "ep 33: ep_len:500 episode reward: total was -32.470000. running mean: -39.825005\n",
      "ep 33: ep_len:500 episode reward: total was 7.230000. running mean: -39.354455\n",
      "ep 33: ep_len:227 episode reward: total was 22.500000. running mean: -38.735910\n",
      "ep 33: ep_len:202 episode reward: total was 17.000000. running mean: -38.178551\n",
      "ep 33: ep_len:500 episode reward: total was 20.950000. running mean: -37.587266\n",
      "ep 33: ep_len:755 episode reward: total was -41.970000. running mean: -37.631093\n",
      "ep 33: ep_len:500 episode reward: total was 24.780000. running mean: -37.006982\n",
      "ep 33: ep_len:585 episode reward: total was 5.110000. running mean: -36.585812\n",
      "ep 33: ep_len:670 episode reward: total was -13.580000. running mean: -36.355754\n",
      "ep 33: ep_len:257 episode reward: total was 25.500000. running mean: -35.737196\n",
      "ep 33: ep_len:296 episode reward: total was 29.500000. running mean: -35.084825\n",
      "ep 33: ep_len:368 episode reward: total was 35.000000. running mean: -34.383976\n",
      "ep 33: ep_len:391 episode reward: total was 30.500000. running mean: -33.735137\n",
      "ep 33: ep_len:695 episode reward: total was -39.060000. running mean: -33.788385\n",
      "ep 33: ep_len:600 episode reward: total was -1.880000. running mean: -33.469301\n",
      "ep 33: ep_len:500 episode reward: total was 0.770000. running mean: -33.126908\n",
      "ep 33: ep_len:500 episode reward: total was 11.190000. running mean: -32.683739\n",
      "ep 33: ep_len:144 episode reward: total was 14.000000. running mean: -32.216902\n",
      "ep 33: ep_len:650 episode reward: total was 2.260000. running mean: -31.872133\n",
      "ep 33: ep_len:441 episode reward: total was 39.500000. running mean: -31.158411\n",
      "ep 33: ep_len:500 episode reward: total was -11.690000. running mean: -30.963727\n",
      "ep 33: ep_len:635 episode reward: total was -40.190000. running mean: -31.055990\n",
      "ep 33: ep_len:775 episode reward: total was -9.300000. running mean: -30.838430\n",
      "ep 33: ep_len:830 episode reward: total was -26.670000. running mean: -30.796746\n",
      "ep 33: ep_len:695 episode reward: total was -30.980000. running mean: -30.798578\n",
      "ep 33: ep_len:500 episode reward: total was 6.720000. running mean: -30.423393\n",
      "ep 33: ep_len:500 episode reward: total was 27.320000. running mean: -29.845959\n",
      "ep 33: ep_len:1166 episode reward: total was -188.070000. running mean: -31.428199\n",
      "ep 33: ep_len:920 episode reward: total was 15.710000. running mean: -30.956817\n",
      "ep 33: ep_len:500 episode reward: total was 24.720000. running mean: -30.400049\n",
      "ep 33: ep_len:500 episode reward: total was 26.280000. running mean: -29.833248\n",
      "ep 33: ep_len:595 episode reward: total was -34.210000. running mean: -29.877016\n",
      "ep 33: ep_len:347 episode reward: total was 19.260000. running mean: -29.385646\n",
      "ep 33: ep_len:1125 episode reward: total was -80.000000. running mean: -29.891789\n",
      "ep 33: ep_len:500 episode reward: total was 13.300000. running mean: -29.459871\n",
      "ep 33: ep_len:1045 episode reward: total was 24.040000. running mean: -28.924873\n",
      "ep 33: ep_len:575 episode reward: total was 1.150000. running mean: -28.624124\n",
      "ep 33: ep_len:745 episode reward: total was -0.580000. running mean: -28.343683\n",
      "ep 33: ep_len:730 episode reward: total was -9.670000. running mean: -28.156946\n",
      "ep 33: ep_len:690 episode reward: total was 15.360000. running mean: -27.721777\n",
      "ep 33: ep_len:94 episode reward: total was 9.000000. running mean: -27.354559\n",
      "ep 33: ep_len:500 episode reward: total was 18.820000. running mean: -26.892813\n",
      "ep 33: ep_len:500 episode reward: total was 31.790000. running mean: -26.305985\n",
      "ep 33: ep_len:315 episode reward: total was 14.790000. running mean: -25.895025\n",
      "ep 33: ep_len:1395 episode reward: total was -75.590000. running mean: -26.391975\n",
      "ep 33: ep_len:885 episode reward: total was -42.720000. running mean: -26.555255\n",
      "ep 33: ep_len:640 episode reward: total was 24.820000. running mean: -26.041503\n",
      "ep 33: ep_len:237 episode reward: total was 23.500000. running mean: -25.546088\n",
      "ep 33: ep_len:575 episode reward: total was 11.310000. running mean: -25.177527\n",
      "ep 33: ep_len:940 episode reward: total was 11.630000. running mean: -24.809451\n",
      "ep 33: ep_len:500 episode reward: total was -14.710000. running mean: -24.708457\n",
      "ep 33: ep_len:535 episode reward: total was -2.010000. running mean: -24.481472\n",
      "ep 33: ep_len:765 episode reward: total was -46.220000. running mean: -24.698858\n",
      "ep 33: ep_len:545 episode reward: total was -18.150000. running mean: -24.633369\n",
      "ep 33: ep_len:555 episode reward: total was -38.990000. running mean: -24.776935\n",
      "ep 33: ep_len:1566 episode reward: total was -212.960000. running mean: -26.658766\n",
      "ep 33: ep_len:176 episode reward: total was 17.500000. running mean: -26.217178\n",
      "ep 33: ep_len:700 episode reward: total was -74.400000. running mean: -26.699007\n",
      "ep 33: ep_len:500 episode reward: total was 25.240000. running mean: -26.179617\n",
      "ep 33: ep_len:690 episode reward: total was 1.300000. running mean: -25.904820\n",
      "ep 33: ep_len:590 episode reward: total was 1.010000. running mean: -25.635672\n",
      "ep 33: ep_len:530 episode reward: total was -13.130000. running mean: -25.510615\n",
      "ep 33: ep_len:695 episode reward: total was 31.230000. running mean: -24.943209\n",
      "ep 33: ep_len:500 episode reward: total was -12.850000. running mean: -24.822277\n",
      "ep 33: ep_len:510 episode reward: total was -5.840000. running mean: -24.632454\n",
      "ep 33: ep_len:650 episode reward: total was -5.820000. running mean: -24.444330\n",
      "ep 33: ep_len:500 episode reward: total was 29.800000. running mean: -23.901887\n",
      "ep 33: ep_len:530 episode reward: total was 6.810000. running mean: -23.594768\n",
      "ep 33: ep_len:755 episode reward: total was 25.450000. running mean: -23.104320\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 33: ep_len:445 episode reward: total was -45.680000. running mean: -23.330077\n",
      "ep 33: ep_len:715 episode reward: total was 13.430000. running mean: -22.962476\n",
      "ep 33: ep_len:1390 episode reward: total was -123.520000. running mean: -23.968051\n",
      "ep 33: ep_len:500 episode reward: total was 30.290000. running mean: -23.425471\n",
      "ep 33: ep_len:500 episode reward: total was 28.790000. running mean: -22.903316\n",
      "ep 33: ep_len:720 episode reward: total was -10.730000. running mean: -22.781583\n",
      "ep 33: ep_len:209 episode reward: total was 20.500000. running mean: -22.348767\n",
      "ep 33: ep_len:780 episode reward: total was -12.630000. running mean: -22.251579\n",
      "ep 33: ep_len:625 episode reward: total was -12.040000. running mean: -22.149464\n",
      "ep 33: ep_len:251 episode reward: total was 25.000000. running mean: -21.677969\n",
      "ep 33: ep_len:500 episode reward: total was 0.780000. running mean: -21.453389\n",
      "ep 33: ep_len:500 episode reward: total was 8.670000. running mean: -21.152155\n",
      "ep 33: ep_len:500 episode reward: total was -7.740000. running mean: -21.018034\n",
      "ep 33: ep_len:500 episode reward: total was 9.960000. running mean: -20.708254\n",
      "ep 33: ep_len:500 episode reward: total was 3.380000. running mean: -20.467371\n",
      "ep 33: ep_len:705 episode reward: total was -15.810000. running mean: -20.420797\n",
      "ep 33: ep_len:3123 episode reward: total was -373.690000. running mean: -23.953489\n",
      "ep 33: ep_len:500 episode reward: total was 16.270000. running mean: -23.551254\n",
      "ep 33: ep_len:955 episode reward: total was 11.130000. running mean: -23.204442\n",
      "ep 33: ep_len:1430 episode reward: total was -71.930000. running mean: -23.691697\n",
      "ep 33: ep_len:500 episode reward: total was 32.770000. running mean: -23.127080\n",
      "ep 33: ep_len:685 episode reward: total was -26.930000. running mean: -23.165110\n",
      "ep 33: ep_len:680 episode reward: total was -7.780000. running mean: -23.011259\n",
      "ep 33: ep_len:1305 episode reward: total was -51.690000. running mean: -23.298046\n",
      "ep 33: ep_len:980 episode reward: total was 17.190000. running mean: -22.893166\n",
      "ep 33: ep_len:1405 episode reward: total was -41.680000. running mean: -23.081034\n",
      "ep 33: ep_len:800 episode reward: total was 14.470000. running mean: -22.705524\n",
      "ep 33: ep_len:500 episode reward: total was 21.840000. running mean: -22.260068\n",
      "ep 33: ep_len:850 episode reward: total was -24.150000. running mean: -22.278968\n",
      "ep 33: ep_len:500 episode reward: total was 23.830000. running mean: -21.817878\n",
      "ep 33: ep_len:520 episode reward: total was -19.210000. running mean: -21.791799\n",
      "ep 33: ep_len:136 episode reward: total was 13.500000. running mean: -21.438881\n",
      "ep 33: ep_len:1100 episode reward: total was 10.310000. running mean: -21.121392\n",
      "ep 33: ep_len:226 episode reward: total was 22.500000. running mean: -20.685178\n",
      "ep 33: ep_len:1551 episode reward: total was -230.780000. running mean: -22.786127\n",
      "ep 33: ep_len:484 episode reward: total was 6.500000. running mean: -22.493265\n",
      "ep 33: ep_len:1275 episode reward: total was -88.400000. running mean: -23.152333\n",
      "ep 33: ep_len:565 episode reward: total was 3.350000. running mean: -22.887309\n",
      "ep 33: ep_len:1205 episode reward: total was 18.970000. running mean: -22.468736\n",
      "ep 33: ep_len:945 episode reward: total was 1.620000. running mean: -22.227849\n",
      "ep 33: ep_len:222 episode reward: total was 22.000000. running mean: -21.785570\n",
      "ep 33: ep_len:1605 episode reward: total was -2.170000. running mean: -21.589415\n",
      "ep 33: ep_len:645 episode reward: total was 18.490000. running mean: -21.188621\n",
      "ep 33: ep_len:500 episode reward: total was 20.520000. running mean: -20.771534\n",
      "ep 33: ep_len:500 episode reward: total was -0.020000. running mean: -20.564019\n",
      "ep 33: ep_len:500 episode reward: total was 3.740000. running mean: -20.320979\n",
      "ep 33: ep_len:164 episode reward: total was 14.500000. running mean: -19.972769\n",
      "ep 33: ep_len:520 episode reward: total was -10.120000. running mean: -19.874241\n",
      "ep 33: ep_len:774 episode reward: total was -64.140000. running mean: -20.316899\n",
      "ep 33: ep_len:378 episode reward: total was 6.280000. running mean: -20.050930\n",
      "ep 33: ep_len:605 episode reward: total was 18.190000. running mean: -19.668521\n",
      "ep 33: ep_len:500 episode reward: total was 50.000000. running mean: -18.971835\n",
      "ep 33: ep_len:1490 episode reward: total was -134.430000. running mean: -20.126417\n",
      "ep 33: ep_len:500 episode reward: total was 22.300000. running mean: -19.702153\n",
      "ep 33: ep_len:524 episode reward: total was -46.020000. running mean: -19.965331\n",
      "ep 33: ep_len:1170 episode reward: total was -85.570000. running mean: -20.621378\n",
      "ep 33: ep_len:500 episode reward: total was -2.110000. running mean: -20.436264\n",
      "ep 33: ep_len:895 episode reward: total was -7.350000. running mean: -20.305402\n",
      "ep 33: ep_len:500 episode reward: total was -12.730000. running mean: -20.229648\n",
      "ep 33: ep_len:500 episode reward: total was 15.110000. running mean: -19.876251\n",
      "ep 33: ep_len:505 episode reward: total was 26.940000. running mean: -19.408089\n",
      "ep 33: ep_len:759 episode reward: total was -10.770000. running mean: -19.321708\n",
      "ep 33: ep_len:710 episode reward: total was -2.670000. running mean: -19.155191\n",
      "ep 33: ep_len:530 episode reward: total was 13.760000. running mean: -18.826039\n",
      "ep 33: ep_len:367 episode reward: total was 32.000000. running mean: -18.317778\n",
      "ep 33: ep_len:500 episode reward: total was -14.720000. running mean: -18.281801\n",
      "ep 33: ep_len:500 episode reward: total was -16.030000. running mean: -18.259283\n",
      "ep 33: ep_len:875 episode reward: total was -14.460000. running mean: -18.221290\n",
      "ep 33: ep_len:605 episode reward: total was 6.480000. running mean: -17.974277\n",
      "ep 33: ep_len:755 episode reward: total was 20.820000. running mean: -17.586334\n",
      "ep 33: ep_len:1325 episode reward: total was -97.100000. running mean: -18.381471\n",
      "ep 33: ep_len:1145 episode reward: total was 15.600000. running mean: -18.041656\n",
      "ep 33: ep_len:745 episode reward: total was -5.630000. running mean: -17.917540\n",
      "ep 33: ep_len:500 episode reward: total was -5.320000. running mean: -17.791564\n",
      "ep 33: ep_len:750 episode reward: total was -6.130000. running mean: -17.674948\n",
      "ep 33: ep_len:406 episode reward: total was 40.500000. running mean: -17.093199\n",
      "ep 33: ep_len:520 episode reward: total was -1.030000. running mean: -16.932567\n",
      "ep 33: ep_len:1140 episode reward: total was -19.990000. running mean: -16.963141\n",
      "ep 33: ep_len:680 episode reward: total was -0.710000. running mean: -16.800610\n",
      "ep 33: ep_len:500 episode reward: total was 3.800000. running mean: -16.594604\n",
      "ep 33: ep_len:575 episode reward: total was -18.090000. running mean: -16.609558\n",
      "ep 33: ep_len:500 episode reward: total was -0.150000. running mean: -16.444962\n",
      "ep 33: ep_len:500 episode reward: total was 16.330000. running mean: -16.117213\n",
      "ep 33: ep_len:680 episode reward: total was -37.070000. running mean: -16.326740\n",
      "ep 33: ep_len:660 episode reward: total was -1.760000. running mean: -16.181073\n",
      "ep 33: ep_len:500 episode reward: total was 17.370000. running mean: -15.845562\n",
      "ep 33: ep_len:785 episode reward: total was -10.600000. running mean: -15.793107\n",
      "ep 33: ep_len:670 episode reward: total was 19.880000. running mean: -15.436376\n",
      "ep 33: ep_len:1070 episode reward: total was 23.420000. running mean: -15.047812\n",
      "ep 33: ep_len:1000 episode reward: total was -11.130000. running mean: -15.008634\n",
      "ep 33: ep_len:1015 episode reward: total was 21.900000. running mean: -14.639547\n",
      "ep 33: ep_len:500 episode reward: total was 12.870000. running mean: -14.364452\n",
      "ep 33: ep_len:585 episode reward: total was -28.170000. running mean: -14.502507\n",
      "ep 33: ep_len:500 episode reward: total was -1.030000. running mean: -14.367782\n",
      "ep 33: ep_len:590 episode reward: total was -10.130000. running mean: -14.325405\n",
      "ep 33: ep_len:635 episode reward: total was -47.260000. running mean: -14.654750\n",
      "ep 33: ep_len:540 episode reward: total was -6.040000. running mean: -14.568603\n",
      "ep 33: ep_len:660 episode reward: total was 4.890000. running mean: -14.374017\n",
      "ep 33: ep_len:1200 episode reward: total was -127.160000. running mean: -15.501877\n",
      "ep 33: ep_len:500 episode reward: total was 4.750000. running mean: -15.299358\n",
      "ep 33: ep_len:535 episode reward: total was -2.860000. running mean: -15.174964\n",
      "ep 33: ep_len:525 episode reward: total was 31.780000. running mean: -14.705415\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 33: ep_len:500 episode reward: total was 5.980000. running mean: -14.498561\n",
      "ep 33: ep_len:500 episode reward: total was -5.720000. running mean: -14.410775\n",
      "ep 33: ep_len:227 episode reward: total was 22.500000. running mean: -14.041667\n",
      "ep 33: ep_len:500 episode reward: total was -18.410000. running mean: -14.085351\n",
      "ep 33: ep_len:570 episode reward: total was -6.710000. running mean: -14.011597\n",
      "ep 33: ep_len:835 episode reward: total was 11.570000. running mean: -13.755781\n",
      "ep 33: ep_len:865 episode reward: total was 24.010000. running mean: -13.378123\n",
      "ep 33: ep_len:500 episode reward: total was 50.000000. running mean: -12.744342\n",
      "ep 33: ep_len:500 episode reward: total was 2.330000. running mean: -12.593599\n",
      "ep 33: ep_len:715 episode reward: total was -7.710000. running mean: -12.544763\n",
      "ep 33: ep_len:500 episode reward: total was -2.080000. running mean: -12.440115\n",
      "ep 33: ep_len:250 episode reward: total was 22.000000. running mean: -12.095714\n",
      "ep 33: ep_len:690 episode reward: total was 37.010000. running mean: -11.604657\n",
      "ep 33: ep_len:500 episode reward: total was -2.980000. running mean: -11.518410\n",
      "ep 33: ep_len:985 episode reward: total was -5.150000. running mean: -11.454726\n",
      "ep 33: ep_len:910 episode reward: total was 2.150000. running mean: -11.318679\n",
      "ep 33: ep_len:710 episode reward: total was -11.820000. running mean: -11.323692\n",
      "ep 33: ep_len:449 episode reward: total was 27.740000. running mean: -10.933055\n",
      "ep 33: ep_len:500 episode reward: total was 4.260000. running mean: -10.781125\n",
      "ep 33: ep_len:555 episode reward: total was -5.000000. running mean: -10.723313\n",
      "ep 33: ep_len:42155 episode reward: total was -8330.100000. running mean: -93.917080\n",
      "ep 33: ep_len:760 episode reward: total was -11.660000. running mean: -93.094509\n",
      "ep 33: ep_len:705 episode reward: total was -60.250000. running mean: -92.766064\n",
      "ep 33: ep_len:500 episode reward: total was -10.000000. running mean: -91.938404\n",
      "ep 33: ep_len:1135 episode reward: total was -162.410000. running mean: -92.643120\n",
      "ep 33: ep_len:660 episode reward: total was -6.810000. running mean: -91.784788\n",
      "ep 33: ep_len:1105 episode reward: total was -28.390000. running mean: -91.150841\n",
      "ep 33: ep_len:775 episode reward: total was -67.180000. running mean: -90.911132\n",
      "ep 33: ep_len:442 episode reward: total was -25.270000. running mean: -90.254721\n",
      "ep 33: ep_len:540 episode reward: total was -19.850000. running mean: -89.550674\n",
      "ep 33: ep_len:575 episode reward: total was -104.490000. running mean: -89.700067\n",
      "ep 33: ep_len:500 episode reward: total was -14.830000. running mean: -88.951366\n",
      "ep 33: ep_len:500 episode reward: total was 11.400000. running mean: -87.947853\n",
      "ep 33: ep_len:925 episode reward: total was -3.650000. running mean: -87.104874\n",
      "ep 33: ep_len:500 episode reward: total was 24.720000. running mean: -85.986625\n",
      "ep 33: ep_len:925 episode reward: total was -94.150000. running mean: -86.068259\n",
      "ep 33: ep_len:1495 episode reward: total was -144.680000. running mean: -86.654376\n",
      "ep 33: ep_len:500 episode reward: total was 10.910000. running mean: -85.678733\n",
      "ep 33: ep_len:582 episode reward: total was -87.750000. running mean: -85.699445\n",
      "ep 33: ep_len:500 episode reward: total was -39.020000. running mean: -85.232651\n",
      "ep 33: ep_len:575 episode reward: total was -67.580000. running mean: -85.056124\n",
      "ep 33: ep_len:500 episode reward: total was -21.390000. running mean: -84.419463\n",
      "ep 33: ep_len:500 episode reward: total was -61.210000. running mean: -84.187368\n",
      "ep 33: ep_len:745 episode reward: total was 1.000000. running mean: -83.335495\n",
      "ep 33: ep_len:1475 episode reward: total was -191.020000. running mean: -84.412340\n",
      "ep 33: ep_len:500 episode reward: total was -26.440000. running mean: -83.832616\n",
      "ep 33: ep_len:730 episode reward: total was -28.490000. running mean: -83.279190\n",
      "ep 33: ep_len:1360 episode reward: total was -135.700000. running mean: -83.803398\n",
      "ep 33: ep_len:655 episode reward: total was -26.010000. running mean: -83.225464\n",
      "ep 33: ep_len:1005 episode reward: total was 17.740000. running mean: -82.215810\n",
      "ep 33: ep_len:510 episode reward: total was -23.760000. running mean: -81.631252\n",
      "ep 33: ep_len:2180 episode reward: total was -268.390000. running mean: -83.498839\n",
      "ep 33: ep_len:500 episode reward: total was 4.910000. running mean: -82.614751\n",
      "ep 33: ep_len:1675 episode reward: total was -124.650000. running mean: -83.035103\n",
      "ep 33: ep_len:1025 episode reward: total was -91.930000. running mean: -83.124052\n",
      "ep 33: ep_len:770 episode reward: total was -14.670000. running mean: -82.439512\n",
      "ep 33: ep_len:545 episode reward: total was 6.160000. running mean: -81.553517\n",
      "ep 33: ep_len:995 episode reward: total was 26.810000. running mean: -80.469881\n",
      "ep 33: ep_len:500 episode reward: total was 23.280000. running mean: -79.432383\n",
      "ep 33: ep_len:397 episode reward: total was -22.740000. running mean: -78.865459\n",
      "ep 33: ep_len:585 episode reward: total was -15.040000. running mean: -78.227204\n",
      "ep 33: ep_len:840 episode reward: total was -10.130000. running mean: -77.546232\n",
      "ep 33: ep_len:500 episode reward: total was -10.890000. running mean: -76.879670\n",
      "ep 33: ep_len:181 episode reward: total was 18.000000. running mean: -75.930873\n",
      "ep 33: ep_len:500 episode reward: total was 1.460000. running mean: -75.156964\n",
      "ep 33: ep_len:800 episode reward: total was -38.680000. running mean: -74.792195\n",
      "ep 33: ep_len:500 episode reward: total was 3.440000. running mean: -74.009873\n",
      "ep 33: ep_len:500 episode reward: total was 28.700000. running mean: -72.982774\n",
      "ep 33: ep_len:850 episode reward: total was -19.780000. running mean: -72.450746\n",
      "ep 33: ep_len:685 episode reward: total was -30.630000. running mean: -72.032539\n",
      "ep 33: ep_len:735 episode reward: total was -37.970000. running mean: -71.691913\n",
      "ep 33: ep_len:780 episode reward: total was -16.020000. running mean: -71.135194\n",
      "ep 33: ep_len:500 episode reward: total was 6.710000. running mean: -70.356742\n",
      "ep 33: ep_len:500 episode reward: total was 15.440000. running mean: -69.498775\n",
      "ep 33: ep_len:285 episode reward: total was 27.000000. running mean: -68.533787\n",
      "ep 33: ep_len:790 episode reward: total was -11.600000. running mean: -67.964449\n",
      "ep 33: ep_len:500 episode reward: total was 29.770000. running mean: -66.987105\n",
      "ep 33: ep_len:1055 episode reward: total was 13.860000. running mean: -66.178634\n",
      "ep 33: ep_len:680 episode reward: total was -27.980000. running mean: -65.796647\n",
      "ep 33: ep_len:500 episode reward: total was 0.890000. running mean: -65.129781\n",
      "ep 33: ep_len:885 episode reward: total was -5.110000. running mean: -64.529583\n",
      "ep 33: ep_len:1855 episode reward: total was -159.960000. running mean: -65.483887\n",
      "ep 33: ep_len:288 episode reward: total was 28.500000. running mean: -64.544048\n",
      "ep 33: ep_len:500 episode reward: total was -12.020000. running mean: -64.018808\n",
      "ep 33: ep_len:322 episode reward: total was 32.000000. running mean: -63.058620\n",
      "ep 33: ep_len:735 episode reward: total was -94.000000. running mean: -63.368034\n",
      "ep 33: ep_len:204 episode reward: total was 20.000000. running mean: -62.534353\n",
      "ep 33: ep_len:500 episode reward: total was 18.290000. running mean: -61.726110\n",
      "ep 33: ep_len:85 episode reward: total was 6.000000. running mean: -61.048849\n",
      "ep 33: ep_len:500 episode reward: total was 20.250000. running mean: -60.235860\n",
      "ep 33: ep_len:705 episode reward: total was -38.030000. running mean: -60.013802\n",
      "ep 33: ep_len:500 episode reward: total was 28.240000. running mean: -59.131264\n",
      "ep 33: ep_len:730 episode reward: total was -14.750000. running mean: -58.687451\n",
      "ep 33: ep_len:1189 episode reward: total was -113.830000. running mean: -59.238877\n",
      "ep 33: ep_len:308 episode reward: total was 30.500000. running mean: -58.341488\n",
      "ep 33: ep_len:500 episode reward: total was 13.300000. running mean: -57.625073\n",
      "ep 33: ep_len:204 episode reward: total was 18.500000. running mean: -56.863822\n",
      "ep 33: ep_len:590 episode reward: total was -55.430000. running mean: -56.849484\n",
      "ep 33: ep_len:620 episode reward: total was -1.840000. running mean: -56.299389\n",
      "ep 33: ep_len:885 episode reward: total was -40.700000. running mean: -56.143395\n",
      "ep 33: ep_len:785 episode reward: total was -21.710000. running mean: -55.799061\n",
      "ep 33: ep_len:500 episode reward: total was -0.050000. running mean: -55.241571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 33: ep_len:500 episode reward: total was 28.760000. running mean: -54.401555\n",
      "ep 33: ep_len:505 episode reward: total was 3.300000. running mean: -53.824539\n",
      "ep 33: ep_len:500 episode reward: total was 9.750000. running mean: -53.188794\n",
      "ep 33: ep_len:619 episode reward: total was -41.270000. running mean: -53.069606\n",
      "ep 33: ep_len:500 episode reward: total was 11.950000. running mean: -52.419410\n",
      "ep 33: ep_len:1150 episode reward: total was -106.880000. running mean: -52.964016\n",
      "ep 33: ep_len:135 episode reward: total was 10.500000. running mean: -52.329376\n",
      "ep 33: ep_len:500 episode reward: total was 26.770000. running mean: -51.538382\n",
      "ep 33: ep_len:750 episode reward: total was 8.900000. running mean: -50.933998\n",
      "ep 33: ep_len:805 episode reward: total was -65.230000. running mean: -51.076958\n",
      "ep 33: ep_len:590 episode reward: total was 28.420000. running mean: -50.281989\n",
      "ep 33: ep_len:500 episode reward: total was -31.980000. running mean: -50.098969\n",
      "ep 33: ep_len:870 episode reward: total was 0.400000. running mean: -49.593979\n",
      "ep 33: ep_len:500 episode reward: total was 9.650000. running mean: -49.001539\n",
      "ep 33: ep_len:500 episode reward: total was 21.300000. running mean: -48.298524\n",
      "ep 33: ep_len:494 episode reward: total was 47.500000. running mean: -47.340539\n",
      "ep 33: ep_len:500 episode reward: total was 1.900000. running mean: -46.848133\n",
      "ep 33: ep_len:500 episode reward: total was 3.190000. running mean: -46.347752\n",
      "ep 33: ep_len:860 episode reward: total was -3.570000. running mean: -45.919974\n",
      "ep 33: ep_len:500 episode reward: total was 22.820000. running mean: -45.232575\n",
      "ep 33: ep_len:670 episode reward: total was -1.740000. running mean: -44.797649\n",
      "ep 33: ep_len:500 episode reward: total was 22.910000. running mean: -44.120572\n",
      "ep 33: ep_len:500 episode reward: total was 24.320000. running mean: -43.436167\n",
      "ep 33: ep_len:500 episode reward: total was -17.990000. running mean: -43.181705\n",
      "ep 33: ep_len:930 episode reward: total was -37.580000. running mean: -43.125688\n",
      "ep 33: ep_len:820 episode reward: total was -10.530000. running mean: -42.799731\n",
      "ep 33: ep_len:530 episode reward: total was -60.600000. running mean: -42.977734\n",
      "ep 33: ep_len:330 episode reward: total was 14.820000. running mean: -42.399756\n",
      "ep 33: ep_len:897 episode reward: total was -61.870000. running mean: -42.594459\n",
      "ep 33: ep_len:238 episode reward: total was 23.500000. running mean: -41.933514\n",
      "ep 33: ep_len:500 episode reward: total was -7.920000. running mean: -41.593379\n",
      "ep 33: ep_len:660 episode reward: total was 22.750000. running mean: -40.949945\n",
      "ep 33: ep_len:205 episode reward: total was 19.500000. running mean: -40.345446\n",
      "ep 33: ep_len:695 episode reward: total was 0.330000. running mean: -39.938691\n",
      "ep 33: ep_len:500 episode reward: total was 16.300000. running mean: -39.376304\n",
      "ep 33: ep_len:500 episode reward: total was 47.000000. running mean: -38.512541\n",
      "ep 33: ep_len:685 episode reward: total was 0.310000. running mean: -38.124316\n",
      "ep 33: ep_len:1000 episode reward: total was 22.390000. running mean: -37.519173\n",
      "ep 33: ep_len:172 episode reward: total was 16.000000. running mean: -36.983981\n",
      "ep 33: ep_len:820 episode reward: total was 7.560000. running mean: -36.538541\n",
      "ep 33: ep_len:845 episode reward: total was 24.740000. running mean: -35.925756\n",
      "ep 33: ep_len:825 episode reward: total was -12.540000. running mean: -35.691898\n",
      "ep 33: ep_len:630 episode reward: total was -23.000000. running mean: -35.564979\n",
      "ep 33: ep_len:500 episode reward: total was 6.650000. running mean: -35.142830\n",
      "ep 33: ep_len:125 episode reward: total was 9.500000. running mean: -34.696401\n",
      "ep 33: ep_len:479 episode reward: total was 31.770000. running mean: -34.031737\n",
      "ep 33: ep_len:720 episode reward: total was 11.410000. running mean: -33.577320\n",
      "ep 33: ep_len:228 episode reward: total was 22.500000. running mean: -33.016547\n",
      "ep 33: ep_len:565 episode reward: total was -2.960000. running mean: -32.715981\n",
      "ep 33: ep_len:500 episode reward: total was -4.740000. running mean: -32.436221\n",
      "ep 33: ep_len:695 episode reward: total was -69.360000. running mean: -32.805459\n",
      "ep 33: ep_len:860 episode reward: total was -20.550000. running mean: -32.682905\n",
      "ep 33: ep_len:545 episode reward: total was -36.330000. running mean: -32.719376\n",
      "ep 33: ep_len:690 episode reward: total was -8.770000. running mean: -32.479882\n",
      "ep 33: ep_len:820 episode reward: total was 7.490000. running mean: -32.080183\n",
      "ep 33: ep_len:220 episode reward: total was 20.500000. running mean: -31.554381\n",
      "ep 33: ep_len:500 episode reward: total was 23.890000. running mean: -30.999937\n",
      "ep 33: ep_len:701 episode reward: total was -5.700000. running mean: -30.746938\n",
      "ep 33: ep_len:560 episode reward: total was 2.080000. running mean: -30.418669\n",
      "ep 33: ep_len:500 episode reward: total was 4.020000. running mean: -30.074282\n",
      "ep 33: ep_len:920 episode reward: total was -29.520000. running mean: -30.068739\n",
      "ep 33: ep_len:500 episode reward: total was -27.170000. running mean: -30.039752\n",
      "ep 33: ep_len:463 episode reward: total was 12.520000. running mean: -29.614154\n",
      "ep 33: ep_len:500 episode reward: total was 16.270000. running mean: -29.155313\n",
      "ep 33: ep_len:324 episode reward: total was 32.000000. running mean: -28.543760\n",
      "ep 33: ep_len:975 episode reward: total was 2.370000. running mean: -28.234622\n",
      "ep 33: ep_len:665 episode reward: total was -10.500000. running mean: -28.057276\n",
      "ep 33: ep_len:500 episode reward: total was -13.220000. running mean: -27.908903\n",
      "ep 33: ep_len:800 episode reward: total was -38.330000. running mean: -28.013114\n",
      "ep 33: ep_len:500 episode reward: total was 7.790000. running mean: -27.655083\n",
      "ep 33: ep_len:985 episode reward: total was 22.260000. running mean: -27.155932\n",
      "ep 33: ep_len:900 episode reward: total was 17.120000. running mean: -26.713173\n",
      "ep 33: ep_len:760 episode reward: total was 3.800000. running mean: -26.408041\n",
      "ep 33: ep_len:500 episode reward: total was 19.330000. running mean: -25.950660\n",
      "ep 33: ep_len:1095 episode reward: total was 10.820000. running mean: -25.582954\n",
      "ep 33: ep_len:710 episode reward: total was -0.130000. running mean: -25.328424\n",
      "ep 33: ep_len:500 episode reward: total was 18.990000. running mean: -24.885240\n",
      "ep 33: ep_len:670 episode reward: total was -2.290000. running mean: -24.659288\n",
      "ep 33: ep_len:710 episode reward: total was 11.030000. running mean: -24.302395\n",
      "ep 33: ep_len:500 episode reward: total was -21.790000. running mean: -24.277271\n",
      "ep 33: ep_len:535 episode reward: total was -2.010000. running mean: -24.054598\n",
      "ep 33: ep_len:500 episode reward: total was 1.480000. running mean: -23.799252\n",
      "ep 33: ep_len:880 episode reward: total was -30.090000. running mean: -23.862160\n",
      "ep 33: ep_len:920 episode reward: total was -78.000000. running mean: -24.403538\n",
      "ep 33: ep_len:500 episode reward: total was -0.580000. running mean: -24.165303\n",
      "ep 33: ep_len:500 episode reward: total was -14.290000. running mean: -24.066550\n",
      "ep 33: ep_len:349 episode reward: total was 31.500000. running mean: -23.510884\n",
      "ep 33: ep_len:795 episode reward: total was 23.200000. running mean: -23.043775\n",
      "ep 33: ep_len:560 episode reward: total was -27.210000. running mean: -23.085438\n",
      "ep 33: ep_len:800 episode reward: total was -61.130000. running mean: -23.465883\n",
      "ep 33: ep_len:500 episode reward: total was 18.350000. running mean: -23.047724\n",
      "ep 33: ep_len:785 episode reward: total was -79.250000. running mean: -23.609747\n",
      "ep 33: ep_len:745 episode reward: total was -4.100000. running mean: -23.414650\n",
      "ep 33: ep_len:670 episode reward: total was -16.890000. running mean: -23.349403\n",
      "ep 33: ep_len:615 episode reward: total was -10.420000. running mean: -23.220109\n",
      "ep 33: ep_len:850 episode reward: total was 17.590000. running mean: -22.812008\n",
      "ep 33: ep_len:500 episode reward: total was 18.350000. running mean: -22.400388\n",
      "ep 33: ep_len:925 episode reward: total was -68.890000. running mean: -22.865284\n",
      "ep 33: ep_len:500 episode reward: total was 34.760000. running mean: -22.289031\n",
      "ep 33: ep_len:730 episode reward: total was -7.680000. running mean: -22.142941\n",
      "ep 33: ep_len:905 episode reward: total was 21.580000. running mean: -21.705712\n",
      "ep 33: ep_len:500 episode reward: total was -15.730000. running mean: -21.645954\n",
      "ep 33: ep_len:655 episode reward: total was -32.070000. running mean: -21.750195\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 33: ep_len:500 episode reward: total was -3.610000. running mean: -21.568793\n",
      "ep 33: ep_len:500 episode reward: total was 2.370000. running mean: -21.329405\n",
      "ep 33: ep_len:715 episode reward: total was -6.560000. running mean: -21.181711\n",
      "ep 33: ep_len:500 episode reward: total was 20.400000. running mean: -20.765894\n",
      "ep 33: ep_len:790 episode reward: total was -28.770000. running mean: -20.845935\n",
      "ep 33: ep_len:500 episode reward: total was 19.820000. running mean: -20.439276\n",
      "ep 33: ep_len:500 episode reward: total was -18.790000. running mean: -20.422783\n",
      "ep 33: ep_len:500 episode reward: total was 29.800000. running mean: -19.920555\n",
      "ep 33: ep_len:965 episode reward: total was 16.280000. running mean: -19.558549\n",
      "ep 33: ep_len:307 episode reward: total was 29.500000. running mean: -19.067964\n",
      "ep 33: ep_len:1025 episode reward: total was 31.620000. running mean: -18.561084\n",
      "ep 33: ep_len:830 episode reward: total was -6.360000. running mean: -18.439073\n",
      "ep 33: ep_len:1090 episode reward: total was -187.780000. running mean: -20.132483\n",
      "ep 33: ep_len:850 episode reward: total was 29.770000. running mean: -19.633458\n",
      "ep 33: ep_len:765 episode reward: total was -7.610000. running mean: -19.513223\n",
      "ep 33: ep_len:297 episode reward: total was 30.000000. running mean: -19.018091\n",
      "ep 33: ep_len:500 episode reward: total was 24.810000. running mean: -18.579810\n",
      "ep 33: ep_len:500 episode reward: total was 1.250000. running mean: -18.381512\n",
      "ep 33: ep_len:500 episode reward: total was 12.470000. running mean: -18.072997\n",
      "ep 33: ep_len:760 episode reward: total was -3.580000. running mean: -17.928067\n",
      "ep 33: ep_len:630 episode reward: total was -24.010000. running mean: -17.988886\n",
      "ep 33: ep_len:306 episode reward: total was 30.500000. running mean: -17.503997\n",
      "ep 33: ep_len:500 episode reward: total was -5.750000. running mean: -17.386457\n",
      "ep 33: ep_len:655 episode reward: total was -2.780000. running mean: -17.240393\n",
      "ep 33: ep_len:500 episode reward: total was 24.260000. running mean: -16.825389\n",
      "ep 33: ep_len:500 episode reward: total was 47.000000. running mean: -16.187135\n",
      "ep 33: ep_len:670 episode reward: total was 12.470000. running mean: -15.900564\n",
      "ep 33: ep_len:575 episode reward: total was -25.260000. running mean: -15.994158\n",
      "ep 33: ep_len:665 episode reward: total was -4.780000. running mean: -15.882016\n",
      "ep 33: ep_len:1135 episode reward: total was -4.560000. running mean: -15.768796\n",
      "ep 33: ep_len:4475 episode reward: total was -868.270000. running mean: -24.293808\n",
      "ep 33: ep_len:985 episode reward: total was 18.250000. running mean: -23.868370\n",
      "ep 33: ep_len:500 episode reward: total was 10.760000. running mean: -23.522087\n",
      "ep 33: ep_len:625 episode reward: total was -19.000000. running mean: -23.476866\n",
      "ep 33: ep_len:570 episode reward: total was -9.010000. running mean: -23.332197\n",
      "ep 33: ep_len:500 episode reward: total was 2.190000. running mean: -23.076975\n",
      "ep 33: ep_len:1005 episode reward: total was 8.250000. running mean: -22.763705\n",
      "ep 33: ep_len:600 episode reward: total was 15.300000. running mean: -22.383068\n",
      "ep 33: ep_len:500 episode reward: total was 3.800000. running mean: -22.121238\n",
      "ep 33: ep_len:600 episode reward: total was -5.920000. running mean: -21.959225\n",
      "ep 33: ep_len:500 episode reward: total was 21.810000. running mean: -21.521533\n",
      "ep 33: ep_len:500 episode reward: total was 6.840000. running mean: -21.237918\n",
      "ep 33: ep_len:755 episode reward: total was 9.840000. running mean: -20.927138\n",
      "ep 33: ep_len:505 episode reward: total was -7.790000. running mean: -20.795767\n",
      "ep 33: ep_len:1450 episode reward: total was -61.040000. running mean: -21.198209\n",
      "ep 33: ep_len:500 episode reward: total was 25.300000. running mean: -20.733227\n",
      "ep 33: ep_len:500 episode reward: total was 6.290000. running mean: -20.462995\n",
      "ep 33: ep_len:530 episode reward: total was -15.150000. running mean: -20.409865\n",
      "ep 33: ep_len:705 episode reward: total was -7.210000. running mean: -20.277866\n",
      "ep 33: ep_len:500 episode reward: total was -19.400000. running mean: -20.269088\n",
      "ep 33: ep_len:540 episode reward: total was -7.050000. running mean: -20.136897\n",
      "ep 33: ep_len:895 episode reward: total was -16.020000. running mean: -20.095728\n",
      "ep 33: ep_len:835 episode reward: total was 8.150000. running mean: -19.813271\n",
      "ep 33: ep_len:845 episode reward: total was 31.000000. running mean: -19.305138\n",
      "ep 33: ep_len:500 episode reward: total was -21.990000. running mean: -19.331987\n",
      "ep 33: ep_len:500 episode reward: total was -26.960000. running mean: -19.408267\n",
      "ep 33: ep_len:510 episode reward: total was -3.070000. running mean: -19.244884\n",
      "ep 33: ep_len:620 episode reward: total was 0.180000. running mean: -19.050635\n",
      "ep 33: ep_len:500 episode reward: total was 4.350000. running mean: -18.816629\n",
      "ep 33: ep_len:225 episode reward: total was 21.000000. running mean: -18.418463\n",
      "ep 33: ep_len:1365 episode reward: total was -117.320000. running mean: -19.407478\n",
      "ep 33: ep_len:500 episode reward: total was -8.660000. running mean: -19.300003\n",
      "ep 33: ep_len:1055 episode reward: total was 19.130000. running mean: -18.915703\n",
      "ep 33: ep_len:1175 episode reward: total was 9.940000. running mean: -18.627146\n",
      "ep 33: ep_len:605 episode reward: total was 5.480000. running mean: -18.386075\n",
      "ep 33: ep_len:500 episode reward: total was 21.840000. running mean: -17.983814\n",
      "ep 33: ep_len:900 episode reward: total was -52.160000. running mean: -18.325576\n",
      "ep 33: ep_len:1480 episode reward: total was -136.470000. running mean: -19.507020\n",
      "ep 33: ep_len:500 episode reward: total was 4.910000. running mean: -19.262850\n",
      "ep 33: ep_len:565 episode reward: total was 12.290000. running mean: -18.947321\n",
      "ep 33: ep_len:705 episode reward: total was -9.750000. running mean: -18.855348\n",
      "ep 33: ep_len:500 episode reward: total was -13.800000. running mean: -18.804795\n",
      "ep 33: ep_len:790 episode reward: total was 25.420000. running mean: -18.362547\n",
      "ep 33: ep_len:217 episode reward: total was 21.500000. running mean: -17.963921\n",
      "ep 33: ep_len:500 episode reward: total was 17.190000. running mean: -17.612382\n",
      "ep 33: ep_len:755 episode reward: total was -6.190000. running mean: -17.498158\n",
      "ep 33: ep_len:1198 episode reward: total was -94.470000. running mean: -18.267877\n",
      "ep 33: ep_len:715 episode reward: total was -16.860000. running mean: -18.253798\n",
      "ep 33: ep_len:500 episode reward: total was 4.950000. running mean: -18.021760\n",
      "ep 33: ep_len:500 episode reward: total was -1.090000. running mean: -17.852442\n",
      "ep 33: ep_len:820 episode reward: total was -0.640000. running mean: -17.680318\n",
      "ep 33: ep_len:610 episode reward: total was -7.580000. running mean: -17.579315\n",
      "ep 33: ep_len:745 episode reward: total was -7.650000. running mean: -17.480021\n",
      "ep 33: ep_len:500 episode reward: total was 31.300000. running mean: -16.992221\n",
      "ep 33: ep_len:193 episode reward: total was 19.000000. running mean: -16.632299\n",
      "ep 33: ep_len:730 episode reward: total was -8.690000. running mean: -16.552876\n",
      "ep 33: ep_len:500 episode reward: total was -7.980000. running mean: -16.467147\n",
      "ep 33: ep_len:500 episode reward: total was 24.780000. running mean: -16.054676\n",
      "ep 33: ep_len:500 episode reward: total was 14.800000. running mean: -15.746129\n",
      "ep 33: ep_len:500 episode reward: total was 21.780000. running mean: -15.370868\n",
      "ep 33: ep_len:520 episode reward: total was -6.570000. running mean: -15.282859\n",
      "ep 33: ep_len:505 episode reward: total was -4.090000. running mean: -15.170930\n",
      "ep 33: ep_len:496 episode reward: total was 26.730000. running mean: -14.751921\n",
      "ep 33: ep_len:500 episode reward: total was -57.630000. running mean: -15.180702\n",
      "ep 33: ep_len:175 episode reward: total was 16.000000. running mean: -14.868895\n",
      "ep 33: ep_len:515 episode reward: total was -7.100000. running mean: -14.791206\n",
      "ep 33: ep_len:188 episode reward: total was 18.500000. running mean: -14.458294\n",
      "ep 33: ep_len:710 episode reward: total was 15.890000. running mean: -14.154811\n",
      "ep 33: ep_len:500 episode reward: total was 25.390000. running mean: -13.759363\n",
      "ep 33: ep_len:500 episode reward: total was 13.510000. running mean: -13.486669\n",
      "ep 33: ep_len:2495 episode reward: total was -446.500000. running mean: -17.816803\n",
      "ep 33: ep_len:930 episode reward: total was 5.050000. running mean: -17.588135\n",
      "ep 33: ep_len:5260 episode reward: total was -847.340000. running mean: -25.885653\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 33: ep_len:935 episode reward: total was -90.070000. running mean: -26.527497\n",
      "ep 33: ep_len:500 episode reward: total was -19.770000. running mean: -26.459922\n",
      "ep 33: ep_len:1660 episode reward: total was -141.860000. running mean: -27.613922\n",
      "ep 33: ep_len:500 episode reward: total was 47.000000. running mean: -26.867783\n",
      "ep 33: ep_len:413 episode reward: total was 4.000000. running mean: -26.559105\n",
      "ep 33: ep_len:500 episode reward: total was 12.360000. running mean: -26.169914\n",
      "epsilon:0.010000 episode_count: 26807. steps_count: 19468344.000000\n",
      "ep 34: ep_len:1840 episode reward: total was -56.970000. running mean: -26.477915\n",
      "ep 34: ep_len:940 episode reward: total was -14.010000. running mean: -26.353236\n",
      "ep 34: ep_len:500 episode reward: total was -12.560000. running mean: -26.215304\n",
      "ep 34: ep_len:1020 episode reward: total was -16.040000. running mean: -26.113551\n",
      "ep 34: ep_len:560 episode reward: total was -21.150000. running mean: -26.063915\n",
      "ep 34: ep_len:525 episode reward: total was 1.560000. running mean: -25.787676\n",
      "ep 34: ep_len:960 episode reward: total was 5.250000. running mean: -25.477299\n",
      "ep 34: ep_len:500 episode reward: total was 11.310000. running mean: -25.109426\n",
      "ep 34: ep_len:830 episode reward: total was -28.690000. running mean: -25.145232\n",
      "ep 34: ep_len:570 episode reward: total was -8.000000. running mean: -24.973780\n",
      "ep 34: ep_len:700 episode reward: total was 26.770000. running mean: -24.456342\n",
      "ep 34: ep_len:680 episode reward: total was -12.830000. running mean: -24.340078\n",
      "ep 34: ep_len:500 episode reward: total was 27.380000. running mean: -23.822878\n",
      "ep 34: ep_len:910 episode reward: total was -43.680000. running mean: -24.021449\n",
      "ep 34: ep_len:950 episode reward: total was -19.200000. running mean: -23.973234\n",
      "ep 34: ep_len:500 episode reward: total was 25.240000. running mean: -23.481102\n",
      "ep 34: ep_len:995 episode reward: total was 16.660000. running mean: -23.079691\n",
      "ep 34: ep_len:500 episode reward: total was -70.450000. running mean: -23.553394\n",
      "ep 34: ep_len:600 episode reward: total was -1.450000. running mean: -23.332360\n",
      "ep 34: ep_len:500 episode reward: total was 36.170000. running mean: -22.737337\n",
      "ep 34: ep_len:2170 episode reward: total was -82.190000. running mean: -23.331863\n",
      "ep 34: ep_len:156 episode reward: total was 0.500000. running mean: -23.093545\n",
      "ep 34: ep_len:950 episode reward: total was -47.640000. running mean: -23.339009\n",
      "ep 34: ep_len:1545 episode reward: total was -104.190000. running mean: -24.147519\n",
      "ep 34: ep_len:473 episode reward: total was 26.830000. running mean: -23.637744\n",
      "ep 34: ep_len:985 episode reward: total was -9.930000. running mean: -23.500666\n",
      "ep 34: ep_len:500 episode reward: total was 3.190000. running mean: -23.233760\n",
      "ep 34: ep_len:14030 episode reward: total was -2635.360000. running mean: -49.355022\n",
      "ep 34: ep_len:500 episode reward: total was -14.100000. running mean: -49.002472\n",
      "ep 34: ep_len:510 episode reward: total was -15.160000. running mean: -48.664047\n",
      "ep 34: ep_len:500 episode reward: total was 8.220000. running mean: -48.095207\n",
      "ep 34: ep_len:181 episode reward: total was -4.500000. running mean: -47.659255\n",
      "ep 34: ep_len:500 episode reward: total was -10.710000. running mean: -47.289762\n",
      "ep 34: ep_len:740 episode reward: total was 12.840000. running mean: -46.688465\n",
      "ep 34: ep_len:500 episode reward: total was -8.260000. running mean: -46.304180\n",
      "ep 34: ep_len:650 episode reward: total was -28.770000. running mean: -46.128838\n",
      "ep 34: ep_len:680 episode reward: total was -10.810000. running mean: -45.775650\n",
      "ep 34: ep_len:580 episode reward: total was -1.920000. running mean: -45.337093\n",
      "ep 34: ep_len:500 episode reward: total was -3.300000. running mean: -44.916722\n",
      "ep 34: ep_len:771 episode reward: total was -10.610000. running mean: -44.573655\n",
      "ep 34: ep_len:990 episode reward: total was -98.830000. running mean: -45.116219\n",
      "ep 34: ep_len:800 episode reward: total was 16.960000. running mean: -44.495456\n",
      "ep 34: ep_len:660 episode reward: total was 5.450000. running mean: -43.996002\n",
      "ep 34: ep_len:555 episode reward: total was -103.980000. running mean: -44.595842\n",
      "ep 34: ep_len:920 episode reward: total was 23.290000. running mean: -43.916983\n",
      "ep 34: ep_len:233 episode reward: total was 15.500000. running mean: -43.322813\n",
      "ep 34: ep_len:500 episode reward: total was 0.780000. running mean: -42.881785\n",
      "ep 34: ep_len:680 episode reward: total was -6.250000. running mean: -42.515467\n",
      "ep 34: ep_len:403 episode reward: total was 37.000000. running mean: -41.720313\n",
      "ep 34: ep_len:500 episode reward: total was 16.980000. running mean: -41.133310\n",
      "ep 34: ep_len:191 episode reward: total was 19.000000. running mean: -40.531977\n",
      "ep 34: ep_len:158 episode reward: total was 14.000000. running mean: -39.986657\n",
      "ep 34: ep_len:860 episode reward: total was -35.030000. running mean: -39.937090\n",
      "ep 34: ep_len:690 episode reward: total was 12.660000. running mean: -39.411119\n",
      "ep 34: ep_len:500 episode reward: total was -26.930000. running mean: -39.286308\n",
      "ep 34: ep_len:655 episode reward: total was -1.770000. running mean: -38.911145\n",
      "ep 34: ep_len:785 episode reward: total was -8.310000. running mean: -38.605134\n",
      "ep 34: ep_len:930 episode reward: total was 10.330000. running mean: -38.115782\n",
      "ep 34: ep_len:500 episode reward: total was -14.590000. running mean: -37.880524\n",
      "ep 34: ep_len:1245 episode reward: total was -199.530000. running mean: -39.497019\n",
      "ep 34: ep_len:910 episode reward: total was -3.530000. running mean: -39.137349\n",
      "ep 34: ep_len:565 episode reward: total was -12.570000. running mean: -38.871676\n",
      "ep 34: ep_len:256 episode reward: total was 25.500000. running mean: -38.227959\n",
      "ep 34: ep_len:900 episode reward: total was -23.720000. running mean: -38.082879\n",
      "ep 34: ep_len:500 episode reward: total was -5.200000. running mean: -37.754050\n",
      "ep 34: ep_len:1055 episode reward: total was -103.990000. running mean: -38.416410\n",
      "ep 34: ep_len:595 episode reward: total was -13.490000. running mean: -38.167146\n",
      "ep 34: ep_len:500 episode reward: total was 17.250000. running mean: -37.612974\n",
      "ep 34: ep_len:645 episode reward: total was -3.810000. running mean: -37.274945\n",
      "ep 34: ep_len:750 episode reward: total was -10.670000. running mean: -37.008895\n",
      "ep 34: ep_len:500 episode reward: total was 17.770000. running mean: -36.461106\n",
      "ep 34: ep_len:500 episode reward: total was 27.290000. running mean: -35.823595\n",
      "ep 34: ep_len:655 episode reward: total was -31.930000. running mean: -35.784659\n",
      "ep 34: ep_len:500 episode reward: total was 3.780000. running mean: -35.389013\n",
      "ep 34: ep_len:530 episode reward: total was -15.150000. running mean: -35.186622\n",
      "ep 34: ep_len:625 episode reward: total was 12.260000. running mean: -34.712156\n",
      "ep 34: ep_len:2005 episode reward: total was -134.410000. running mean: -35.709135\n",
      "ep 34: ep_len:670 episode reward: total was 1.290000. running mean: -35.339143\n",
      "ep 34: ep_len:500 episode reward: total was 22.270000. running mean: -34.763052\n",
      "ep 34: ep_len:500 episode reward: total was 7.730000. running mean: -34.338121\n",
      "ep 34: ep_len:710 episode reward: total was 6.210000. running mean: -33.932640\n",
      "ep 34: ep_len:82 episode reward: total was 8.000000. running mean: -33.513314\n",
      "ep 34: ep_len:520 episode reward: total was -1.030000. running mean: -33.188481\n",
      "ep 34: ep_len:1015 episode reward: total was -98.550000. running mean: -33.842096\n",
      "ep 34: ep_len:695 episode reward: total was 4.530000. running mean: -33.458375\n",
      "ep 34: ep_len:500 episode reward: total was -5.010000. running mean: -33.173891\n",
      "ep 34: ep_len:1540 episode reward: total was -71.360000. running mean: -33.555752\n",
      "ep 34: ep_len:895 episode reward: total was 22.290000. running mean: -32.997295\n",
      "ep 34: ep_len:545 episode reward: total was 15.470000. running mean: -32.512622\n",
      "ep 34: ep_len:500 episode reward: total was 3.100000. running mean: -32.156496\n",
      "ep 34: ep_len:520 episode reward: total was 20.260000. running mean: -31.632331\n",
      "ep 34: ep_len:500 episode reward: total was 8.740000. running mean: -31.228607\n",
      "ep 34: ep_len:500 episode reward: total was 14.250000. running mean: -30.773821\n",
      "ep 34: ep_len:940 episode reward: total was -6.970000. running mean: -30.535783\n",
      "ep 34: ep_len:180 episode reward: total was 16.500000. running mean: -30.065425\n",
      "ep 34: ep_len:910 episode reward: total was 18.020000. running mean: -29.584571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 34: ep_len:500 episode reward: total was -20.000000. running mean: -29.488725\n",
      "ep 34: ep_len:500 episode reward: total was -3.790000. running mean: -29.231738\n",
      "ep 34: ep_len:770 episode reward: total was 2.290000. running mean: -28.916521\n",
      "ep 34: ep_len:500 episode reward: total was 33.780000. running mean: -28.289555\n",
      "ep 34: ep_len:184 episode reward: total was 18.000000. running mean: -27.826660\n",
      "ep 34: ep_len:795 episode reward: total was -87.340000. running mean: -28.421793\n",
      "ep 34: ep_len:500 episode reward: total was -9.240000. running mean: -28.229975\n",
      "ep 34: ep_len:500 episode reward: total was -43.030000. running mean: -28.377976\n",
      "ep 34: ep_len:313 episode reward: total was -45.500000. running mean: -28.549196\n",
      "ep 34: ep_len:1271 episode reward: total was -12.520000. running mean: -28.388904\n",
      "ep 34: ep_len:580 episode reward: total was -16.060000. running mean: -28.265615\n",
      "ep 34: ep_len:227 episode reward: total was 22.500000. running mean: -27.757959\n",
      "ep 34: ep_len:500 episode reward: total was 24.320000. running mean: -27.237179\n",
      "ep 34: ep_len:296 episode reward: total was 29.500000. running mean: -26.669807\n",
      "ep 34: ep_len:500 episode reward: total was 23.980000. running mean: -26.163309\n",
      "ep 34: ep_len:705 episode reward: total was -87.790000. running mean: -26.779576\n",
      "ep 34: ep_len:810 episode reward: total was -35.800000. running mean: -26.869780\n",
      "ep 34: ep_len:500 episode reward: total was 29.280000. running mean: -26.308283\n",
      "ep 34: ep_len:725 episode reward: total was -26.880000. running mean: -26.314000\n",
      "ep 34: ep_len:277 episode reward: total was 27.500000. running mean: -25.775860\n",
      "ep 34: ep_len:845 episode reward: total was -21.590000. running mean: -25.734001\n",
      "ep 34: ep_len:725 episode reward: total was -26.880000. running mean: -25.745461\n",
      "ep 34: ep_len:500 episode reward: total was 7.030000. running mean: -25.417706\n",
      "ep 34: ep_len:1036 episode reward: total was -55.530000. running mean: -25.718829\n",
      "ep 34: ep_len:830 episode reward: total was 10.430000. running mean: -25.357341\n",
      "ep 34: ep_len:740 episode reward: total was 16.320000. running mean: -24.940568\n",
      "ep 34: ep_len:9771 episode reward: total was -1916.660000. running mean: -43.857762\n",
      "ep 34: ep_len:640 episode reward: total was -105.000000. running mean: -44.469184\n",
      "ep 34: ep_len:710 episode reward: total was -5.700000. running mean: -44.081493\n",
      "ep 34: ep_len:500 episode reward: total was 50.000000. running mean: -43.140678\n",
      "ep 34: ep_len:500 episode reward: total was -0.850000. running mean: -42.717771\n",
      "ep 34: ep_len:805 episode reward: total was -10.620000. running mean: -42.396793\n",
      "ep 34: ep_len:835 episode reward: total was 9.500000. running mean: -41.877825\n",
      "ep 34: ep_len:815 episode reward: total was -31.750000. running mean: -41.776547\n",
      "ep 34: ep_len:860 episode reward: total was -30.830000. running mean: -41.667081\n",
      "ep 34: ep_len:271 episode reward: total was 27.000000. running mean: -40.980411\n",
      "ep 34: ep_len:500 episode reward: total was 8.830000. running mean: -40.482307\n",
      "ep 34: ep_len:1015 episode reward: total was -43.230000. running mean: -40.509784\n",
      "ep 34: ep_len:1370 episode reward: total was -99.320000. running mean: -41.097886\n",
      "ep 34: ep_len:1880 episode reward: total was -216.470000. running mean: -42.851607\n",
      "ep 34: ep_len:500 episode reward: total was -1.990000. running mean: -42.442991\n",
      "ep 34: ep_len:388 episode reward: total was -57.500000. running mean: -42.593561\n",
      "ep 34: ep_len:580 episode reward: total was 19.740000. running mean: -41.970225\n",
      "ep 34: ep_len:500 episode reward: total was 48.500000. running mean: -41.065523\n",
      "ep 34: ep_len:576 episode reward: total was -78.690000. running mean: -41.441768\n",
      "ep 34: ep_len:500 episode reward: total was 25.760000. running mean: -40.769750\n",
      "ep 34: ep_len:1870 episode reward: total was -48.600000. running mean: -40.848053\n",
      "ep 34: ep_len:500 episode reward: total was 20.310000. running mean: -40.236472\n",
      "ep 34: ep_len:500 episode reward: total was 24.170000. running mean: -39.592407\n",
      "ep 34: ep_len:121 episode reward: total was -2.500000. running mean: -39.221483\n",
      "ep 34: ep_len:500 episode reward: total was 50.000000. running mean: -38.329268\n",
      "ep 34: ep_len:263 episode reward: total was -3.500000. running mean: -37.980976\n",
      "ep 34: ep_len:745 episode reward: total was 13.030000. running mean: -37.470866\n",
      "ep 34: ep_len:845 episode reward: total was -4.170000. running mean: -37.137857\n",
      "ep 34: ep_len:500 episode reward: total was 12.780000. running mean: -36.638679\n",
      "ep 34: ep_len:500 episode reward: total was 33.290000. running mean: -35.939392\n",
      "ep 34: ep_len:990 episode reward: total was 14.500000. running mean: -35.434998\n",
      "ep 34: ep_len:500 episode reward: total was -18.760000. running mean: -35.268248\n",
      "ep 34: ep_len:500 episode reward: total was 14.210000. running mean: -34.773466\n",
      "ep 34: ep_len:246 episode reward: total was 5.000000. running mean: -34.375731\n",
      "ep 34: ep_len:500 episode reward: total was 3.900000. running mean: -33.992974\n",
      "ep 34: ep_len:500 episode reward: total was 19.220000. running mean: -33.460844\n",
      "ep 34: ep_len:690 episode reward: total was -8.770000. running mean: -33.213935\n",
      "ep 34: ep_len:715 episode reward: total was -15.760000. running mean: -33.039396\n",
      "ep 34: ep_len:720 episode reward: total was -14.770000. running mean: -32.856702\n",
      "ep 34: ep_len:292 episode reward: total was 15.750000. running mean: -32.370635\n",
      "ep 34: ep_len:1040 episode reward: total was 16.910000. running mean: -31.877829\n",
      "ep 34: ep_len:500 episode reward: total was -16.280000. running mean: -31.721850\n",
      "ep 34: ep_len:680 episode reward: total was -18.890000. running mean: -31.593532\n",
      "ep 34: ep_len:1380 episode reward: total was 23.490000. running mean: -31.042697\n",
      "ep 34: ep_len:177 episode reward: total was -9.500000. running mean: -30.827270\n",
      "ep 34: ep_len:690 episode reward: total was -13.820000. running mean: -30.657197\n",
      "ep 34: ep_len:635 episode reward: total was -31.160000. running mean: -30.662225\n",
      "ep 34: ep_len:500 episode reward: total was 33.260000. running mean: -30.023003\n",
      "ep 34: ep_len:500 episode reward: total was 17.060000. running mean: -29.552173\n",
      "ep 34: ep_len:685 episode reward: total was -6.730000. running mean: -29.323951\n",
      "ep 34: ep_len:500 episode reward: total was -10.830000. running mean: -29.139011\n",
      "ep 34: ep_len:710 episode reward: total was -18.830000. running mean: -29.035921\n",
      "ep 34: ep_len:500 episode reward: total was 12.590000. running mean: -28.619662\n",
      "ep 34: ep_len:500 episode reward: total was 2.310000. running mean: -28.310366\n",
      "ep 34: ep_len:675 episode reward: total was -9.780000. running mean: -28.125062\n",
      "ep 34: ep_len:173 episode reward: total was -10.000000. running mean: -27.943811\n",
      "ep 34: ep_len:580 episode reward: total was -67.570000. running mean: -28.340073\n",
      "ep 34: ep_len:905 episode reward: total was 9.670000. running mean: -27.959972\n",
      "ep 34: ep_len:210 episode reward: total was -12.000000. running mean: -27.800373\n",
      "ep 34: ep_len:500 episode reward: total was 8.280000. running mean: -27.439569\n",
      "ep 34: ep_len:151 episode reward: total was -5.500000. running mean: -27.220173\n",
      "ep 34: ep_len:500 episode reward: total was -35.010000. running mean: -27.298072\n",
      "ep 34: ep_len:500 episode reward: total was 14.220000. running mean: -26.882891\n",
      "ep 34: ep_len:825 episode reward: total was -42.940000. running mean: -27.043462\n",
      "ep 34: ep_len:560 episode reward: total was -25.680000. running mean: -27.029827\n",
      "ep 34: ep_len:500 episode reward: total was 46.000000. running mean: -26.299529\n",
      "ep 34: ep_len:505 episode reward: total was -8.190000. running mean: -26.118434\n",
      "ep 34: ep_len:500 episode reward: total was 26.830000. running mean: -25.588949\n",
      "ep 34: ep_len:550 episode reward: total was -7.520000. running mean: -25.408260\n",
      "ep 34: ep_len:635 episode reward: total was -22.160000. running mean: -25.375777\n",
      "ep 34: ep_len:500 episode reward: total was 22.270000. running mean: -24.899320\n",
      "ep 34: ep_len:500 episode reward: total was -0.760000. running mean: -24.657926\n",
      "ep 34: ep_len:500 episode reward: total was -5.740000. running mean: -24.468747\n",
      "ep 34: ep_len:700 episode reward: total was -10.400000. running mean: -24.328060\n",
      "ep 34: ep_len:215 episode reward: total was -11.500000. running mean: -24.199779\n",
      "ep 34: ep_len:765 episode reward: total was -26.280000. running mean: -24.220581\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 34: ep_len:500 episode reward: total was 5.280000. running mean: -23.925575\n",
      "ep 34: ep_len:500 episode reward: total was 15.990000. running mean: -23.526420\n",
      "ep 34: ep_len:1929 episode reward: total was -295.200000. running mean: -26.243155\n",
      "ep 34: ep_len:500 episode reward: total was 21.290000. running mean: -25.767824\n",
      "ep 34: ep_len:500 episode reward: total was 20.310000. running mean: -25.307046\n",
      "ep 34: ep_len:665 episode reward: total was -14.880000. running mean: -25.202775\n",
      "ep 34: ep_len:775 episode reward: total was -22.740000. running mean: -25.178147\n",
      "ep 34: ep_len:635 episode reward: total was -11.390000. running mean: -25.040266\n",
      "ep 34: ep_len:630 episode reward: total was -18.990000. running mean: -24.979763\n",
      "ep 34: ep_len:900 episode reward: total was 20.040000. running mean: -24.529566\n",
      "ep 34: ep_len:525 episode reward: total was -10.110000. running mean: -24.385370\n",
      "ep 34: ep_len:580 episode reward: total was -5.960000. running mean: -24.201116\n",
      "ep 34: ep_len:770 episode reward: total was -30.830000. running mean: -24.267405\n",
      "ep 34: ep_len:6288 episode reward: total was -1025.020000. running mean: -34.274931\n",
      "ep 34: ep_len:500 episode reward: total was 32.800000. running mean: -33.604182\n",
      "ep 34: ep_len:840 episode reward: total was -14.370000. running mean: -33.411840\n",
      "ep 34: ep_len:815 episode reward: total was 11.490000. running mean: -32.962822\n",
      "ep 34: ep_len:800 episode reward: total was -33.660000. running mean: -32.969793\n",
      "ep 34: ep_len:500 episode reward: total was 7.970000. running mean: -32.560395\n",
      "ep 34: ep_len:283 episode reward: total was -14.000000. running mean: -32.374791\n",
      "ep 34: ep_len:805 episode reward: total was 1.920000. running mean: -32.031844\n",
      "ep 34: ep_len:500 episode reward: total was 9.930000. running mean: -31.612225\n",
      "ep 34: ep_len:835 episode reward: total was 10.470000. running mean: -31.191403\n",
      "ep 34: ep_len:690 episode reward: total was -34.020000. running mean: -31.219689\n",
      "ep 34: ep_len:625 episode reward: total was -71.500000. running mean: -31.622492\n",
      "ep 34: ep_len:500 episode reward: total was 14.280000. running mean: -31.163467\n",
      "ep 34: ep_len:167 episode reward: total was 1.500000. running mean: -30.836832\n",
      "ep 34: ep_len:1050 episode reward: total was 4.120000. running mean: -30.487264\n",
      "ep 34: ep_len:740 episode reward: total was -11.700000. running mean: -30.299391\n",
      "ep 34: ep_len:700 episode reward: total was -2.690000. running mean: -30.023297\n",
      "ep 34: ep_len:655 episode reward: total was -16.890000. running mean: -29.891965\n",
      "ep 34: ep_len:780 episode reward: total was -46.970000. running mean: -30.062745\n",
      "ep 34: ep_len:500 episode reward: total was 30.250000. running mean: -29.459617\n",
      "ep 34: ep_len:2271 episode reward: total was -375.760000. running mean: -32.922621\n",
      "ep 34: ep_len:426 episode reward: total was 28.770000. running mean: -32.305695\n",
      "ep 34: ep_len:500 episode reward: total was -0.670000. running mean: -31.989338\n",
      "ep 34: ep_len:500 episode reward: total was 0.340000. running mean: -31.666045\n",
      "ep 34: ep_len:710 episode reward: total was -3.680000. running mean: -31.386184\n",
      "ep 34: ep_len:650 episode reward: total was 20.270000. running mean: -30.869622\n",
      "ep 34: ep_len:585 episode reward: total was -2.580000. running mean: -30.586726\n",
      "ep 34: ep_len:500 episode reward: total was 20.280000. running mean: -30.078059\n",
      "ep 34: ep_len:585 episode reward: total was -50.390000. running mean: -30.281178\n",
      "ep 34: ep_len:500 episode reward: total was -6.110000. running mean: -30.039467\n",
      "ep 34: ep_len:510 episode reward: total was -49.500000. running mean: -30.234072\n",
      "ep 34: ep_len:2065 episode reward: total was -161.340000. running mean: -31.545131\n",
      "ep 34: ep_len:570 episode reward: total was -11.150000. running mean: -31.341180\n",
      "ep 34: ep_len:500 episode reward: total was 47.000000. running mean: -30.557768\n",
      "ep 34: ep_len:745 episode reward: total was -7.650000. running mean: -30.328690\n",
      "ep 34: ep_len:615 episode reward: total was -4.360000. running mean: -30.069003\n",
      "ep 34: ep_len:750 episode reward: total was -6.740000. running mean: -29.835713\n",
      "ep 34: ep_len:695 episode reward: total was -0.710000. running mean: -29.544456\n",
      "ep 34: ep_len:500 episode reward: total was -40.790000. running mean: -29.656912\n",
      "ep 34: ep_len:145 episode reward: total was 8.500000. running mean: -29.275343\n",
      "ep 34: ep_len:1035 episode reward: total was -10.460000. running mean: -29.087189\n",
      "ep 34: ep_len:500 episode reward: total was -9.570000. running mean: -28.892017\n",
      "ep 34: ep_len:500 episode reward: total was -25.980000. running mean: -28.862897\n",
      "ep 34: ep_len:535 episode reward: total was -4.600000. running mean: -28.620268\n",
      "ep 34: ep_len:525 episode reward: total was -9.650000. running mean: -28.430565\n",
      "ep 34: ep_len:920 episode reward: total was -37.600000. running mean: -28.522260\n",
      "ep 34: ep_len:500 episode reward: total was -9.020000. running mean: -28.327237\n",
      "ep 34: ep_len:530 episode reward: total was -44.000000. running mean: -28.483965\n",
      "ep 34: ep_len:1222 episode reward: total was -66.630000. running mean: -28.865425\n",
      "ep 34: ep_len:625 episode reward: total was -7.890000. running mean: -28.655671\n",
      "ep 34: ep_len:162 episode reward: total was -8.000000. running mean: -28.449114\n",
      "ep 34: ep_len:785 episode reward: total was -9.290000. running mean: -28.257523\n",
      "ep 34: ep_len:500 episode reward: total was -17.560000. running mean: -28.150548\n",
      "ep 34: ep_len:293 episode reward: total was -13.000000. running mean: -27.999042\n",
      "ep 34: ep_len:113 episode reward: total was -5.500000. running mean: -27.774052\n",
      "ep 34: ep_len:500 episode reward: total was 26.340000. running mean: -27.232911\n",
      "ep 34: ep_len:500 episode reward: total was -23.780000. running mean: -27.198382\n",
      "ep 34: ep_len:500 episode reward: total was 12.010000. running mean: -26.806299\n",
      "ep 34: ep_len:740 episode reward: total was -12.710000. running mean: -26.665336\n",
      "ep 34: ep_len:500 episode reward: total was 16.770000. running mean: -26.230982\n",
      "ep 34: ep_len:500 episode reward: total was 19.430000. running mean: -25.774372\n",
      "ep 34: ep_len:226 episode reward: total was -10.500000. running mean: -25.621629\n",
      "ep 34: ep_len:885 episode reward: total was 28.150000. running mean: -25.083912\n",
      "ep 34: ep_len:655 episode reward: total was 15.520000. running mean: -24.677873\n",
      "ep 34: ep_len:500 episode reward: total was 7.330000. running mean: -24.357794\n",
      "ep 34: ep_len:870 episode reward: total was 15.580000. running mean: -23.958417\n",
      "ep 34: ep_len:500 episode reward: total was -0.240000. running mean: -23.721232\n",
      "ep 34: ep_len:500 episode reward: total was 22.240000. running mean: -23.261620\n",
      "ep 34: ep_len:830 episode reward: total was 4.690000. running mean: -22.982104\n",
      "ep 34: ep_len:560 episode reward: total was -9.030000. running mean: -22.842583\n",
      "ep 34: ep_len:995 episode reward: total was 20.230000. running mean: -22.411857\n",
      "ep 34: ep_len:500 episode reward: total was -19.700000. running mean: -22.384738\n",
      "ep 34: ep_len:1315 episode reward: total was -137.310000. running mean: -23.533991\n",
      "ep 34: ep_len:500 episode reward: total was -5.720000. running mean: -23.355851\n",
      "ep 34: ep_len:785 episode reward: total was 27.710000. running mean: -22.845193\n",
      "ep 34: ep_len:895 episode reward: total was 27.630000. running mean: -22.340441\n",
      "ep 34: ep_len:313 episode reward: total was 19.010000. running mean: -21.926936\n",
      "ep 34: ep_len:800 episode reward: total was 0.610000. running mean: -21.701567\n",
      "ep 34: ep_len:1075 episode reward: total was -93.330000. running mean: -22.417851\n",
      "ep 34: ep_len:830 episode reward: total was 19.870000. running mean: -21.994973\n",
      "ep 34: ep_len:469 episode reward: total was 15.040000. running mean: -21.624623\n",
      "ep 34: ep_len:990 episode reward: total was 5.080000. running mean: -21.357577\n",
      "ep 34: ep_len:760 episode reward: total was -78.320000. running mean: -21.927201\n",
      "ep 34: ep_len:1510 episode reward: total was -59.620000. running mean: -22.304129\n",
      "ep 34: ep_len:725 episode reward: total was -20.790000. running mean: -22.288988\n",
      "ep 34: ep_len:500 episode reward: total was -0.270000. running mean: -22.068798\n",
      "ep 34: ep_len:780 episode reward: total was 30.730000. running mean: -21.540810\n",
      "ep 34: ep_len:575 episode reward: total was -2.940000. running mean: -21.354802\n",
      "ep 34: ep_len:705 episode reward: total was -25.880000. running mean: -21.400054\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 34: ep_len:327 episode reward: total was -15.500000. running mean: -21.341053\n",
      "ep 34: ep_len:1390 episode reward: total was -99.280000. running mean: -22.120443\n",
      "ep 34: ep_len:530 episode reward: total was 14.740000. running mean: -21.751838\n",
      "ep 34: ep_len:500 episode reward: total was -18.820000. running mean: -21.722520\n",
      "ep 34: ep_len:500 episode reward: total was 10.260000. running mean: -21.402695\n",
      "ep 34: ep_len:500 episode reward: total was 24.410000. running mean: -20.944568\n",
      "ep 34: ep_len:1135 episode reward: total was 17.180000. running mean: -20.563322\n",
      "ep 34: ep_len:520 episode reward: total was -32.340000. running mean: -20.681089\n",
      "ep 34: ep_len:500 episode reward: total was -3.390000. running mean: -20.508178\n",
      "ep 34: ep_len:660 episode reward: total was -31.540000. running mean: -20.618496\n",
      "ep 34: ep_len:211 episode reward: total was -9.000000. running mean: -20.502311\n",
      "ep 34: ep_len:230 episode reward: total was -11.500000. running mean: -20.412288\n",
      "ep 34: ep_len:312 episode reward: total was 25.500000. running mean: -19.953165\n",
      "ep 34: ep_len:560 episode reward: total was 11.580000. running mean: -19.637834\n",
      "ep 34: ep_len:500 episode reward: total was 10.200000. running mean: -19.339455\n",
      "ep 34: ep_len:260 episode reward: total was -14.500000. running mean: -19.291061\n",
      "ep 34: ep_len:695 episode reward: total was 28.720000. running mean: -18.810950\n",
      "ep 34: ep_len:785 episode reward: total was 14.420000. running mean: -18.478641\n",
      "ep 34: ep_len:875 episode reward: total was 10.130000. running mean: -18.192554\n",
      "ep 34: ep_len:343 episode reward: total was 34.500000. running mean: -17.665629\n",
      "ep 34: ep_len:520 episode reward: total was -5.560000. running mean: -17.544572\n",
      "ep 34: ep_len:510 episode reward: total was 18.310000. running mean: -17.186027\n",
      "ep 34: ep_len:865 episode reward: total was -10.920000. running mean: -17.123366\n",
      "ep 34: ep_len:780 episode reward: total was -25.760000. running mean: -17.209733\n",
      "ep 34: ep_len:500 episode reward: total was 13.880000. running mean: -16.898835\n",
      "ep 34: ep_len:500 episode reward: total was -8.140000. running mean: -16.811247\n",
      "ep 34: ep_len:1880 episode reward: total was -179.590000. running mean: -18.439035\n",
      "ep 34: ep_len:805 episode reward: total was -29.750000. running mean: -18.552144\n",
      "ep 34: ep_len:835 episode reward: total was 12.750000. running mean: -18.239123\n",
      "ep 34: ep_len:500 episode reward: total was 26.310000. running mean: -17.793631\n",
      "ep 34: ep_len:530 episode reward: total was -28.770000. running mean: -17.903395\n",
      "ep 34: ep_len:1065 episode reward: total was -122.640000. running mean: -18.950761\n",
      "ep 34: ep_len:610 episode reward: total was -33.220000. running mean: -19.093454\n",
      "ep 34: ep_len:910 episode reward: total was -20.450000. running mean: -19.107019\n",
      "ep 34: ep_len:500 episode reward: total was -1.650000. running mean: -18.932449\n",
      "ep 34: ep_len:890 episode reward: total was 10.590000. running mean: -18.637224\n",
      "ep 34: ep_len:320 episode reward: total was -6.500000. running mean: -18.515852\n",
      "ep 34: ep_len:545 episode reward: total was -4.790000. running mean: -18.378594\n",
      "ep 34: ep_len:500 episode reward: total was 11.060000. running mean: -18.084208\n",
      "ep 34: ep_len:885 episode reward: total was 12.870000. running mean: -17.774666\n",
      "ep 34: ep_len:500 episode reward: total was 30.270000. running mean: -17.294219\n",
      "ep 34: ep_len:500 episode reward: total was 11.150000. running mean: -17.009777\n",
      "ep 34: ep_len:500 episode reward: total was 30.320000. running mean: -16.536479\n",
      "ep 34: ep_len:196 episode reward: total was 7.500000. running mean: -16.296114\n",
      "ep 34: ep_len:265 episode reward: total was 2.210000. running mean: -16.111053\n",
      "ep 34: ep_len:155 episode reward: total was 0.500000. running mean: -15.944943\n",
      "ep 34: ep_len:1005 episode reward: total was -88.940000. running mean: -16.674893\n",
      "ep 34: ep_len:860 episode reward: total was -42.740000. running mean: -16.935544\n",
      "ep 34: ep_len:915 episode reward: total was -53.770000. running mean: -17.303889\n",
      "ep 34: ep_len:500 episode reward: total was 4.270000. running mean: -17.088150\n",
      "ep 34: ep_len:500 episode reward: total was 23.770000. running mean: -16.679568\n",
      "ep 34: ep_len:845 episode reward: total was -56.630000. running mean: -17.079073\n",
      "ep 34: ep_len:500 episode reward: total was 26.290000. running mean: -16.645382\n",
      "ep 34: ep_len:525 episode reward: total was -70.710000. running mean: -17.186028\n",
      "ep 34: ep_len:500 episode reward: total was 14.830000. running mean: -16.865868\n",
      "ep 34: ep_len:545 episode reward: total was 1.040000. running mean: -16.686809\n",
      "ep 34: ep_len:500 episode reward: total was -80.000000. running mean: -17.319941\n",
      "ep 34: ep_len:625 episode reward: total was 23.290000. running mean: -16.913842\n",
      "ep 34: ep_len:500 episode reward: total was 29.860000. running mean: -16.446103\n",
      "ep 34: ep_len:775 episode reward: total was 0.800000. running mean: -16.273642\n",
      "ep 34: ep_len:580 episode reward: total was -4.950000. running mean: -16.160406\n",
      "ep 34: ep_len:510 episode reward: total was -14.150000. running mean: -16.140302\n",
      "ep 34: ep_len:500 episode reward: total was 18.260000. running mean: -15.796299\n",
      "ep 34: ep_len:500 episode reward: total was -7.190000. running mean: -15.710236\n",
      "ep 34: ep_len:775 episode reward: total was 28.730000. running mean: -15.265833\n",
      "ep 34: ep_len:337 episode reward: total was 11.770000. running mean: -14.995475\n",
      "ep 34: ep_len:540 episode reward: total was -9.070000. running mean: -14.936220\n",
      "ep 34: ep_len:730 episode reward: total was 28.860000. running mean: -14.498258\n",
      "ep 34: ep_len:500 episode reward: total was 4.750000. running mean: -14.305776\n",
      "ep 34: ep_len:500 episode reward: total was 8.270000. running mean: -14.080018\n",
      "ep 34: ep_len:500 episode reward: total was 2.620000. running mean: -13.913018\n",
      "ep 34: ep_len:660 episode reward: total was -39.130000. running mean: -14.165187\n",
      "ep 34: ep_len:500 episode reward: total was 33.320000. running mean: -13.690336\n",
      "ep 34: ep_len:580 episode reward: total was -7.980000. running mean: -13.633232\n",
      "ep 34: ep_len:840 episode reward: total was 0.810000. running mean: -13.488800\n",
      "ep 34: ep_len:500 episode reward: total was 12.780000. running mean: -13.226112\n",
      "ep 34: ep_len:500 episode reward: total was -10.950000. running mean: -13.203351\n",
      "ep 34: ep_len:525 episode reward: total was 4.770000. running mean: -13.023617\n",
      "ep 34: ep_len:500 episode reward: total was 6.140000. running mean: -12.831981\n",
      "ep 34: ep_len:292 episode reward: total was 29.500000. running mean: -12.408661\n",
      "ep 34: ep_len:675 episode reward: total was -18.900000. running mean: -12.473575\n",
      "ep 34: ep_len:500 episode reward: total was -13.920000. running mean: -12.488039\n",
      "ep 34: ep_len:500 episode reward: total was -9.230000. running mean: -12.455458\n",
      "ep 34: ep_len:520 episode reward: total was 14.470000. running mean: -12.186204\n",
      "ep 34: ep_len:2080 episode reward: total was -184.760000. running mean: -13.911942\n",
      "ep 34: ep_len:500 episode reward: total was 17.230000. running mean: -13.600522\n",
      "ep 34: ep_len:500 episode reward: total was 22.740000. running mean: -13.237117\n",
      "ep 34: ep_len:1685 episode reward: total was -46.220000. running mean: -13.566946\n",
      "ep 34: ep_len:500 episode reward: total was 31.790000. running mean: -13.113377\n",
      "ep 34: ep_len:720 episode reward: total was -22.850000. running mean: -13.210743\n",
      "ep 34: ep_len:660 episode reward: total was 1.270000. running mean: -13.065935\n",
      "ep 34: ep_len:3055 episode reward: total was -603.000000. running mean: -18.965276\n",
      "ep 34: ep_len:1100 episode reward: total was -47.340000. running mean: -19.249023\n",
      "ep 34: ep_len:735 episode reward: total was 23.200000. running mean: -18.824533\n",
      "ep 34: ep_len:1455 episode reward: total was -60.770000. running mean: -19.243988\n",
      "ep 34: ep_len:149 episode reward: total was 14.500000. running mean: -18.906548\n",
      "ep 34: ep_len:895 episode reward: total was -131.140000. running mean: -20.028882\n",
      "ep 34: ep_len:500 episode reward: total was 2.330000. running mean: -19.805294\n",
      "ep 34: ep_len:820 episode reward: total was -27.180000. running mean: -19.879041\n",
      "ep 34: ep_len:940 episode reward: total was -12.090000. running mean: -19.801150\n",
      "ep 34: ep_len:500 episode reward: total was -2.660000. running mean: -19.629739\n",
      "ep 34: ep_len:257 episode reward: total was 25.500000. running mean: -19.178441\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 34: ep_len:970 episode reward: total was 5.450000. running mean: -18.932157\n",
      "ep 34: ep_len:945 episode reward: total was 0.410000. running mean: -18.738735\n",
      "ep 34: ep_len:695 episode reward: total was -4.200000. running mean: -18.593348\n",
      "ep 34: ep_len:1440 episode reward: total was -224.460000. running mean: -20.652014\n",
      "ep 34: ep_len:354 episode reward: total was 30.500000. running mean: -20.140494\n",
      "ep 34: ep_len:500 episode reward: total was 34.300000. running mean: -19.596089\n",
      "ep 34: ep_len:885 episode reward: total was -19.490000. running mean: -19.595029\n",
      "ep 34: ep_len:500 episode reward: total was 32.310000. running mean: -19.075978\n",
      "ep 34: ep_len:265 episode reward: total was 25.500000. running mean: -18.630218\n",
      "ep 34: ep_len:1010 episode reward: total was -25.300000. running mean: -18.696916\n",
      "ep 34: ep_len:940 episode reward: total was -4.240000. running mean: -18.552347\n",
      "ep 34: ep_len:214 episode reward: total was 21.000000. running mean: -18.156824\n",
      "ep 34: ep_len:224 episode reward: total was 15.500000. running mean: -17.820255\n",
      "ep 34: ep_len:755 episode reward: total was -83.380000. running mean: -18.475853\n",
      "ep 34: ep_len:730 episode reward: total was 1.840000. running mean: -18.272694\n",
      "ep 34: ep_len:875 episode reward: total was -28.080000. running mean: -18.370767\n",
      "ep 34: ep_len:147 episode reward: total was 10.500000. running mean: -18.082060\n",
      "ep 34: ep_len:700 episode reward: total was -47.680000. running mean: -18.378039\n",
      "ep 34: ep_len:505 episode reward: total was -10.150000. running mean: -18.295759\n",
      "ep 34: ep_len:395 episode reward: total was 2.710000. running mean: -18.085701\n",
      "ep 34: ep_len:267 episode reward: total was 25.000000. running mean: -17.654844\n",
      "ep 34: ep_len:505 episode reward: total was -0.050000. running mean: -17.478796\n",
      "ep 34: ep_len:975 episode reward: total was -84.960000. running mean: -18.153608\n",
      "ep 34: ep_len:1505 episode reward: total was -157.630000. running mean: -19.548372\n",
      "ep 34: ep_len:500 episode reward: total was 21.780000. running mean: -19.135088\n",
      "ep 34: ep_len:921 episode reward: total was -87.070000. running mean: -19.814437\n",
      "ep 34: ep_len:1135 episode reward: total was -95.650000. running mean: -20.572793\n",
      "ep 34: ep_len:500 episode reward: total was 19.820000. running mean: -20.168865\n",
      "ep 34: ep_len:890 episode reward: total was -15.440000. running mean: -20.121576\n",
      "ep 34: ep_len:600 episode reward: total was -27.130000. running mean: -20.191660\n",
      "ep 34: ep_len:500 episode reward: total was -24.880000. running mean: -20.238544\n",
      "ep 34: ep_len:875 episode reward: total was 15.800000. running mean: -19.878158\n",
      "ep 34: ep_len:678 episode reward: total was -31.790000. running mean: -19.997277\n",
      "ep 34: ep_len:269 episode reward: total was 26.500000. running mean: -19.532304\n",
      "ep 34: ep_len:740 episode reward: total was -2.610000. running mean: -19.363081\n",
      "ep 34: ep_len:500 episode reward: total was 8.340000. running mean: -19.086050\n",
      "ep 34: ep_len:500 episode reward: total was -15.910000. running mean: -19.054290\n",
      "ep 34: ep_len:705 episode reward: total was 19.070000. running mean: -18.673047\n",
      "ep 34: ep_len:875 episode reward: total was -20.520000. running mean: -18.691516\n",
      "ep 34: ep_len:500 episode reward: total was -3.450000. running mean: -18.539101\n",
      "ep 34: ep_len:500 episode reward: total was 18.320000. running mean: -18.170510\n",
      "ep 34: ep_len:565 episode reward: total was 8.040000. running mean: -17.908405\n",
      "ep 34: ep_len:870 episode reward: total was -57.900000. running mean: -18.308321\n",
      "ep 34: ep_len:351 episode reward: total was 35.000000. running mean: -17.775238\n",
      "ep 34: ep_len:500 episode reward: total was 5.150000. running mean: -17.545985\n",
      "ep 34: ep_len:530 episode reward: total was -10.100000. running mean: -17.471525\n",
      "ep 34: ep_len:10 episode reward: total was -0.500000. running mean: -17.301810\n",
      "ep 34: ep_len:500 episode reward: total was 25.820000. running mean: -16.870592\n",
      "ep 34: ep_len:500 episode reward: total was -1.460000. running mean: -16.716486\n",
      "ep 34: ep_len:545 episode reward: total was 24.960000. running mean: -16.299721\n",
      "ep 34: ep_len:635 episode reward: total was 5.820000. running mean: -16.078524\n",
      "ep 34: ep_len:725 episode reward: total was -15.580000. running mean: -16.073539\n",
      "ep 34: ep_len:500 episode reward: total was 3.250000. running mean: -15.880303\n",
      "ep 34: ep_len:580 episode reward: total was -15.540000. running mean: -15.876900\n",
      "ep 34: ep_len:500 episode reward: total was 16.820000. running mean: -15.549931\n",
      "ep 34: ep_len:655 episode reward: total was -0.760000. running mean: -15.402032\n",
      "ep 34: ep_len:500 episode reward: total was 21.380000. running mean: -15.034212\n",
      "ep 34: ep_len:810 episode reward: total was -11.070000. running mean: -14.994570\n",
      "ep 34: ep_len:685 episode reward: total was 1.320000. running mean: -14.831424\n",
      "ep 34: ep_len:500 episode reward: total was 18.960000. running mean: -14.493510\n",
      "ep 34: ep_len:930 episode reward: total was -31.000000. running mean: -14.658575\n",
      "ep 34: ep_len:520 episode reward: total was -28.300000. running mean: -14.794989\n",
      "ep 34: ep_len:940 episode reward: total was -17.330000. running mean: -14.820339\n",
      "ep 34: ep_len:640 episode reward: total was 1.100000. running mean: -14.661136\n",
      "ep 34: ep_len:210 episode reward: total was 18.000000. running mean: -14.334524\n",
      "ep 34: ep_len:500 episode reward: total was 7.540000. running mean: -14.115779\n",
      "ep 34: ep_len:910 episode reward: total was -34.590000. running mean: -14.320521\n",
      "ep 34: ep_len:737 episode reward: total was -72.780000. running mean: -14.905116\n",
      "ep 34: ep_len:500 episode reward: total was 18.230000. running mean: -14.573765\n",
      "ep 34: ep_len:500 episode reward: total was 20.900000. running mean: -14.219027\n",
      "ep 34: ep_len:695 episode reward: total was 26.330000. running mean: -13.813537\n",
      "ep 34: ep_len:370 episode reward: total was 35.500000. running mean: -13.320402\n",
      "ep 34: ep_len:500 episode reward: total was -20.260000. running mean: -13.389798\n",
      "ep 34: ep_len:500 episode reward: total was 24.760000. running mean: -13.008300\n",
      "ep 34: ep_len:500 episode reward: total was 20.950000. running mean: -12.668717\n",
      "ep 34: ep_len:500 episode reward: total was 25.330000. running mean: -12.288729\n",
      "ep 34: ep_len:225 episode reward: total was 21.000000. running mean: -11.955842\n",
      "ep 34: ep_len:500 episode reward: total was -4.160000. running mean: -11.877884\n",
      "ep 34: ep_len:885 episode reward: total was -3.620000. running mean: -11.795305\n",
      "ep 34: ep_len:500 episode reward: total was -7.340000. running mean: -11.750752\n",
      "ep 34: ep_len:560 episode reward: total was -3.980000. running mean: -11.673044\n",
      "ep 34: ep_len:500 episode reward: total was -23.440000. running mean: -11.790714\n",
      "ep 34: ep_len:120 episode reward: total was 10.500000. running mean: -11.567807\n",
      "ep 34: ep_len:950 episode reward: total was 23.670000. running mean: -11.215429\n",
      "ep 34: ep_len:735 episode reward: total was -8.160000. running mean: -11.184874\n",
      "ep 34: ep_len:500 episode reward: total was -1.740000. running mean: -11.090426\n",
      "ep 34: ep_len:159 episode reward: total was 15.500000. running mean: -10.824521\n",
      "ep 34: ep_len:500 episode reward: total was -6.130000. running mean: -10.777576\n",
      "ep 34: ep_len:500 episode reward: total was 18.990000. running mean: -10.479900\n",
      "ep 34: ep_len:1245 episode reward: total was 16.110000. running mean: -10.214001\n",
      "ep 34: ep_len:675 episode reward: total was -12.870000. running mean: -10.240561\n",
      "ep 34: ep_len:775 episode reward: total was 3.220000. running mean: -10.105956\n",
      "ep 34: ep_len:450 episode reward: total was 19.320000. running mean: -9.811696\n",
      "ep 34: ep_len:870 episode reward: total was -19.520000. running mean: -9.908779\n",
      "ep 34: ep_len:915 episode reward: total was 22.260000. running mean: -9.587091\n",
      "ep 34: ep_len:43210 episode reward: total was -8451.660000. running mean: -94.007821\n",
      "ep 34: ep_len:1147 episode reward: total was -129.040000. running mean: -94.358142\n",
      "ep 34: ep_len:500 episode reward: total was 48.500000. running mean: -92.929561\n",
      "ep 34: ep_len:500 episode reward: total was 2.040000. running mean: -91.979865\n",
      "ep 34: ep_len:1870 episode reward: total was -318.500000. running mean: -94.245067\n",
      "ep 34: ep_len:715 episode reward: total was -23.590000. running mean: -93.538516\n",
      "ep 34: ep_len:565 episode reward: total was -19.120000. running mean: -92.794331\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 34: ep_len:975 episode reward: total was -71.210000. running mean: -92.578488\n",
      "ep 34: ep_len:755 episode reward: total was -35.260000. running mean: -92.005303\n",
      "ep 34: ep_len:375 episode reward: total was 1.660000. running mean: -91.068650\n",
      "ep 34: ep_len:2537 episode reward: total was -488.850000. running mean: -95.046463\n",
      "ep 34: ep_len:500 episode reward: total was 15.500000. running mean: -93.940998\n",
      "ep 34: ep_len:500 episode reward: total was -16.400000. running mean: -93.165588\n",
      "ep 34: ep_len:500 episode reward: total was -31.060000. running mean: -92.544533\n",
      "ep 34: ep_len:500 episode reward: total was -28.610000. running mean: -91.905187\n",
      "ep 34: ep_len:900 episode reward: total was -99.250000. running mean: -91.978635\n",
      "ep 34: ep_len:500 episode reward: total was -12.500000. running mean: -91.183849\n",
      "ep 34: ep_len:500 episode reward: total was 17.000000. running mean: -90.102011\n",
      "ep 34: ep_len:605 episode reward: total was -106.860000. running mean: -90.269590\n",
      "ep 34: ep_len:610 episode reward: total was -88.900000. running mean: -90.255895\n",
      "ep 34: ep_len:500 episode reward: total was 15.260000. running mean: -89.200736\n",
      "ep 34: ep_len:875 episode reward: total was -171.500000. running mean: -90.023728\n",
      "ep 34: ep_len:530 episode reward: total was -36.360000. running mean: -89.487091\n",
      "ep 34: ep_len:500 episode reward: total was -20.410000. running mean: -88.796320\n",
      "ep 34: ep_len:700 episode reward: total was -6.590000. running mean: -87.974257\n",
      "ep 34: ep_len:500 episode reward: total was -19.460000. running mean: -87.289114\n",
      "ep 34: ep_len:1010 episode reward: total was -3.430000. running mean: -86.450523\n",
      "ep 34: ep_len:2125 episode reward: total was -315.450000. running mean: -88.740518\n",
      "ep 34: ep_len:610 episode reward: total was -32.160000. running mean: -88.174713\n",
      "ep 34: ep_len:810 episode reward: total was 18.300000. running mean: -87.109966\n",
      "ep 34: ep_len:520 episode reward: total was -31.330000. running mean: -86.552166\n",
      "ep 34: ep_len:2808 episode reward: total was -330.430000. running mean: -88.990944\n",
      "ep 34: ep_len:695 episode reward: total was 13.910000. running mean: -87.961935\n",
      "ep 34: ep_len:1510 episode reward: total was -151.560000. running mean: -88.597916\n",
      "ep 34: ep_len:1030 episode reward: total was -81.820000. running mean: -88.530136\n",
      "ep 34: ep_len:1160 episode reward: total was 16.830000. running mean: -87.476535\n",
      "ep 34: ep_len:500 episode reward: total was -51.230000. running mean: -87.114070\n",
      "ep 34: ep_len:810 episode reward: total was 1.760000. running mean: -86.225329\n",
      "ep 34: ep_len:500 episode reward: total was 12.690000. running mean: -85.236176\n",
      "ep 34: ep_len:463 episode reward: total was 0.210000. running mean: -84.381714\n",
      "ep 34: ep_len:500 episode reward: total was -1.830000. running mean: -83.556197\n",
      "ep 34: ep_len:610 episode reward: total was 0.190000. running mean: -82.718735\n",
      "ep 34: ep_len:500 episode reward: total was -14.350000. running mean: -82.035047\n",
      "ep 34: ep_len:540 episode reward: total was -4.020000. running mean: -81.254897\n",
      "ep 34: ep_len:595 episode reward: total was 13.310000. running mean: -80.309248\n",
      "ep 34: ep_len:580 episode reward: total was -1.920000. running mean: -79.525356\n",
      "ep 34: ep_len:500 episode reward: total was -14.260000. running mean: -78.872702\n",
      "ep 34: ep_len:670 episode reward: total was -10.830000. running mean: -78.192275\n",
      "ep 34: ep_len:500 episode reward: total was 7.210000. running mean: -77.338252\n",
      "ep 34: ep_len:1179 episode reward: total was -92.160000. running mean: -77.486470\n",
      "ep 34: ep_len:670 episode reward: total was 16.590000. running mean: -76.545705\n",
      "ep 34: ep_len:500 episode reward: total was 8.800000. running mean: -75.692248\n",
      "ep 34: ep_len:1259 episode reward: total was -206.120000. running mean: -76.996525\n",
      "ep 34: ep_len:1100 episode reward: total was 6.820000. running mean: -76.158360\n",
      "ep 34: ep_len:500 episode reward: total was 24.260000. running mean: -75.154177\n",
      "ep 34: ep_len:1000 episode reward: total was -0.700000. running mean: -74.409635\n",
      "ep 34: ep_len:690 episode reward: total was -17.400000. running mean: -73.839538\n",
      "ep 34: ep_len:500 episode reward: total was 24.230000. running mean: -72.858843\n",
      "ep 34: ep_len:500 episode reward: total was 19.240000. running mean: -71.937855\n",
      "ep 34: ep_len:158 episode reward: total was 16.000000. running mean: -71.058476\n",
      "ep 34: ep_len:505 episode reward: total was 18.240000. running mean: -70.165491\n",
      "ep 34: ep_len:256 episode reward: total was 25.500000. running mean: -69.208836\n",
      "ep 34: ep_len:500 episode reward: total was 1.510000. running mean: -68.501648\n",
      "ep 34: ep_len:353 episode reward: total was 33.500000. running mean: -67.481632\n",
      "ep 34: ep_len:685 episode reward: total was -35.040000. running mean: -67.157215\n",
      "ep 34: ep_len:500 episode reward: total was 15.730000. running mean: -66.328343\n",
      "ep 34: ep_len:1070 episode reward: total was -100.340000. running mean: -66.668460\n",
      "ep 34: ep_len:865 episode reward: total was -33.570000. running mean: -66.337475\n",
      "ep 34: ep_len:560 episode reward: total was -13.070000. running mean: -65.804800\n",
      "ep 34: ep_len:800 episode reward: total was -6.530000. running mean: -65.212052\n",
      "ep 34: ep_len:490 episode reward: total was 22.740000. running mean: -64.332532\n",
      "ep 34: ep_len:500 episode reward: total was 15.300000. running mean: -63.536207\n",
      "ep 34: ep_len:149 episode reward: total was 14.500000. running mean: -62.755844\n",
      "ep 34: ep_len:178 episode reward: total was 17.500000. running mean: -61.953286\n",
      "ep 34: ep_len:725 episode reward: total was -4.720000. running mean: -61.380953\n",
      "ep 34: ep_len:500 episode reward: total was -25.460000. running mean: -61.021744\n",
      "ep 34: ep_len:1140 episode reward: total was -18.080000. running mean: -60.592326\n",
      "ep 34: ep_len:805 episode reward: total was -8.540000. running mean: -60.071803\n",
      "ep 34: ep_len:500 episode reward: total was 11.400000. running mean: -59.357085\n",
      "ep 34: ep_len:500 episode reward: total was 23.810000. running mean: -58.525414\n",
      "ep 34: ep_len:500 episode reward: total was 6.320000. running mean: -57.876960\n",
      "ep 34: ep_len:500 episode reward: total was 0.250000. running mean: -57.295690\n",
      "ep 34: ep_len:530 episode reward: total was 1.610000. running mean: -56.706633\n",
      "ep 34: ep_len:247 episode reward: total was 24.500000. running mean: -55.894567\n",
      "ep 34: ep_len:500 episode reward: total was -24.970000. running mean: -55.585321\n",
      "ep 34: ep_len:500 episode reward: total was -5.280000. running mean: -55.082268\n",
      "ep 34: ep_len:500 episode reward: total was 13.200000. running mean: -54.399445\n",
      "ep 34: ep_len:1450 episode reward: total was -257.730000. running mean: -56.432751\n",
      "ep 34: ep_len:580 episode reward: total was -80.700000. running mean: -56.675424\n",
      "ep 34: ep_len:719 episode reward: total was -66.320000. running mean: -56.771869\n",
      "ep 34: ep_len:189 episode reward: total was 18.500000. running mean: -56.019151\n",
      "ep 34: ep_len:500 episode reward: total was -25.980000. running mean: -55.718759\n",
      "ep 34: ep_len:605 episode reward: total was -13.960000. running mean: -55.301171\n",
      "ep 34: ep_len:500 episode reward: total was -10.550000. running mean: -54.853660\n",
      "ep 34: ep_len:500 episode reward: total was 14.770000. running mean: -54.157423\n",
      "ep 34: ep_len:570 episode reward: total was -14.790000. running mean: -53.763749\n",
      "ep 34: ep_len:500 episode reward: total was 31.280000. running mean: -52.913311\n",
      "ep 34: ep_len:500 episode reward: total was -14.010000. running mean: -52.524278\n",
      "ep 34: ep_len:535 episode reward: total was -27.260000. running mean: -52.271636\n",
      "ep 34: ep_len:650 episode reward: total was -4.410000. running mean: -51.793019\n",
      "ep 34: ep_len:500 episode reward: total was 7.540000. running mean: -51.199689\n",
      "ep 34: ep_len:500 episode reward: total was 29.800000. running mean: -50.389692\n",
      "ep 34: ep_len:500 episode reward: total was -10.430000. running mean: -49.990095\n",
      "ep 34: ep_len:995 episode reward: total was -50.580000. running mean: -49.995994\n",
      "ep 34: ep_len:540 episode reward: total was -42.400000. running mean: -49.920034\n",
      "ep 34: ep_len:257 episode reward: total was 24.000000. running mean: -49.180834\n",
      "ep 34: ep_len:675 episode reward: total was 0.780000. running mean: -48.681226\n",
      "ep 34: ep_len:294 episode reward: total was -26.770000. running mean: -48.462113\n",
      "ep 34: ep_len:625 episode reward: total was -51.320000. running mean: -48.490692\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 34: ep_len:735 episode reward: total was -28.880000. running mean: -48.294585\n",
      "ep 34: ep_len:500 episode reward: total was 9.320000. running mean: -47.718439\n",
      "ep 34: ep_len:680 episode reward: total was -1.720000. running mean: -47.258455\n",
      "ep 34: ep_len:1895 episode reward: total was -242.700000. running mean: -49.212871\n",
      "ep 34: ep_len:500 episode reward: total was 48.500000. running mean: -48.235742\n",
      "ep 34: ep_len:675 episode reward: total was -1.730000. running mean: -47.770684\n",
      "ep 34: ep_len:760 episode reward: total was -0.550000. running mean: -47.298478\n",
      "ep 34: ep_len:500 episode reward: total was -11.900000. running mean: -46.944493\n",
      "ep 34: ep_len:675 episode reward: total was -14.860000. running mean: -46.623648\n",
      "ep 34: ep_len:990 episode reward: total was -2.040000. running mean: -46.177811\n",
      "ep 34: ep_len:660 episode reward: total was -30.530000. running mean: -46.021333\n",
      "ep 34: ep_len:500 episode reward: total was 3.930000. running mean: -45.521820\n",
      "ep 34: ep_len:176 episode reward: total was 16.000000. running mean: -44.906602\n",
      "ep 34: ep_len:500 episode reward: total was 33.260000. running mean: -44.124936\n",
      "ep 34: ep_len:500 episode reward: total was 32.310000. running mean: -43.360586\n",
      "ep 34: ep_len:555 episode reward: total was 19.100000. running mean: -42.735980\n",
      "ep 34: ep_len:500 episode reward: total was -22.830000. running mean: -42.536921\n",
      "ep 34: ep_len:500 episode reward: total was 13.140000. running mean: -41.980151\n",
      "ep 34: ep_len:805 episode reward: total was -7.530000. running mean: -41.635650\n",
      "ep 34: ep_len:500 episode reward: total was 12.290000. running mean: -41.096393\n",
      "ep 34: ep_len:815 episode reward: total was 10.830000. running mean: -40.577130\n",
      "ep 34: ep_len:950 episode reward: total was 13.970000. running mean: -40.031658\n",
      "ep 34: ep_len:500 episode reward: total was 1.410000. running mean: -39.617242\n",
      "ep 34: ep_len:245 episode reward: total was 23.000000. running mean: -38.991069\n",
      "ep 34: ep_len:500 episode reward: total was 12.590000. running mean: -38.475259\n",
      "ep 34: ep_len:703 episode reward: total was -4.660000. running mean: -38.137106\n",
      "ep 34: ep_len:500 episode reward: total was 12.100000. running mean: -37.634735\n",
      "ep 34: ep_len:620 episode reward: total was -7.900000. running mean: -37.337388\n",
      "ep 34: ep_len:1080 episode reward: total was -28.090000. running mean: -37.244914\n",
      "ep 34: ep_len:500 episode reward: total was -26.710000. running mean: -37.139565\n",
      "ep 34: ep_len:288 episode reward: total was 11.640000. running mean: -36.651769\n",
      "ep 34: ep_len:685 episode reward: total was -0.350000. running mean: -36.288751\n",
      "ep 34: ep_len:1320 episode reward: total was -124.150000. running mean: -37.167364\n",
      "ep 34: ep_len:760 episode reward: total was -15.700000. running mean: -36.952690\n",
      "ep 34: ep_len:500 episode reward: total was 22.800000. running mean: -36.355163\n",
      "ep 34: ep_len:500 episode reward: total was -23.350000. running mean: -36.225112\n",
      "ep 34: ep_len:1050 episode reward: total was -0.080000. running mean: -35.863660\n",
      "ep 34: ep_len:500 episode reward: total was 10.760000. running mean: -35.397424\n",
      "ep 34: ep_len:955 episode reward: total was 15.830000. running mean: -34.885150\n",
      "ep 34: ep_len:505 episode reward: total was -14.500000. running mean: -34.681298\n",
      "ep 34: ep_len:815 episode reward: total was 8.260000. running mean: -34.251885\n",
      "ep 34: ep_len:2135 episode reward: total was -264.440000. running mean: -36.553766\n",
      "ep 34: ep_len:960 episode reward: total was 5.950000. running mean: -36.128729\n",
      "ep 34: ep_len:690 episode reward: total was -2.710000. running mean: -35.794541\n",
      "ep 34: ep_len:520 episode reward: total was 0.300000. running mean: -35.433596\n",
      "ep 34: ep_len:730 episode reward: total was -3.120000. running mean: -35.110460\n",
      "ep 34: ep_len:765 episode reward: total was -37.390000. running mean: -35.133255\n",
      "ep 34: ep_len:500 episode reward: total was 28.270000. running mean: -34.499223\n",
      "ep 34: ep_len:525 episode reward: total was -0.010000. running mean: -34.154331\n",
      "ep 34: ep_len:500 episode reward: total was 7.820000. running mean: -33.734587\n",
      "ep 34: ep_len:865 episode reward: total was -20.540000. running mean: -33.602641\n",
      "ep 34: ep_len:500 episode reward: total was -29.650000. running mean: -33.563115\n",
      "ep 34: ep_len:500 episode reward: total was 29.770000. running mean: -32.929784\n",
      "ep 34: ep_len:895 episode reward: total was 0.420000. running mean: -32.596286\n",
      "ep 34: ep_len:420 episode reward: total was 40.500000. running mean: -31.865323\n",
      "ep 34: ep_len:525 episode reward: total was 1.000000. running mean: -31.536670\n",
      "ep 34: ep_len:500 episode reward: total was 15.810000. running mean: -31.063203\n",
      "ep 34: ep_len:237 episode reward: total was 10.650000. running mean: -30.646071\n",
      "ep 34: ep_len:520 episode reward: total was -1.030000. running mean: -30.349910\n",
      "ep 34: ep_len:500 episode reward: total was 45.500000. running mean: -29.591411\n",
      "ep 34: ep_len:500 episode reward: total was 9.470000. running mean: -29.200797\n",
      "ep 34: ep_len:500 episode reward: total was 10.300000. running mean: -28.805789\n",
      "ep 34: ep_len:520 episode reward: total was -0.530000. running mean: -28.523031\n",
      "ep 34: ep_len:775 episode reward: total was -5.320000. running mean: -28.291001\n",
      "ep 34: ep_len:500 episode reward: total was -11.290000. running mean: -28.120991\n",
      "ep 34: ep_len:560 episode reward: total was -17.720000. running mean: -28.016981\n",
      "ep 34: ep_len:500 episode reward: total was -7.280000. running mean: -27.809611\n",
      "ep 34: ep_len:940 episode reward: total was 8.790000. running mean: -27.443615\n",
      "ep 34: ep_len:590 episode reward: total was -1.900000. running mean: -27.188179\n",
      "ep 34: ep_len:960 episode reward: total was 23.800000. running mean: -26.678297\n",
      "ep 34: ep_len:520 episode reward: total was 22.250000. running mean: -26.189014\n",
      "ep 34: ep_len:1318 episode reward: total was -176.170000. running mean: -27.688824\n",
      "ep 34: ep_len:500 episode reward: total was 4.080000. running mean: -27.371136\n",
      "ep 34: ep_len:500 episode reward: total was 17.250000. running mean: -26.924925\n",
      "ep 34: ep_len:500 episode reward: total was -14.320000. running mean: -26.798875\n",
      "ep 34: ep_len:750 episode reward: total was -63.160000. running mean: -27.162487\n",
      "ep 34: ep_len:625 episode reward: total was -36.170000. running mean: -27.252562\n",
      "ep 34: ep_len:580 episode reward: total was -29.190000. running mean: -27.271936\n",
      "ep 34: ep_len:500 episode reward: total was -4.220000. running mean: -27.041417\n",
      "ep 34: ep_len:690 episode reward: total was -1.700000. running mean: -26.788003\n",
      "ep 34: ep_len:705 episode reward: total was 4.610000. running mean: -26.474022\n",
      "ep 34: ep_len:550 episode reward: total was -23.190000. running mean: -26.441182\n",
      "ep 34: ep_len:515 episode reward: total was 22.790000. running mean: -25.948870\n",
      "ep 34: ep_len:243 episode reward: total was 22.500000. running mean: -25.464382\n",
      "ep 34: ep_len:500 episode reward: total was 13.210000. running mean: -25.077638\n",
      "ep 34: ep_len:920 episode reward: total was 20.320000. running mean: -24.623662\n",
      "ep 34: ep_len:235 episode reward: total was 22.000000. running mean: -24.157425\n",
      "ep 34: ep_len:500 episode reward: total was 2.820000. running mean: -23.887651\n",
      "ep 34: ep_len:500 episode reward: total was -12.180000. running mean: -23.770574\n",
      "ep 34: ep_len:500 episode reward: total was 0.350000. running mean: -23.529368\n",
      "ep 34: ep_len:780 episode reward: total was -0.510000. running mean: -23.299175\n",
      "ep 34: ep_len:500 episode reward: total was -21.020000. running mean: -23.276383\n",
      "ep 34: ep_len:203 episode reward: total was 20.000000. running mean: -22.843619\n",
      "ep 34: ep_len:500 episode reward: total was 18.260000. running mean: -22.432583\n",
      "ep 34: ep_len:735 episode reward: total was 3.780000. running mean: -22.170457\n",
      "ep 34: ep_len:500 episode reward: total was 26.860000. running mean: -21.680153\n",
      "ep 34: ep_len:500 episode reward: total was 50.000000. running mean: -20.963351\n",
      "ep 34: ep_len:505 episode reward: total was -3.080000. running mean: -20.784518\n",
      "ep 34: ep_len:500 episode reward: total was 26.680000. running mean: -20.309872\n",
      "ep 34: ep_len:745 episode reward: total was 6.710000. running mean: -20.039674\n",
      "ep 34: ep_len:820 episode reward: total was -21.640000. running mean: -20.055677\n",
      "ep 34: ep_len:1705 episode reward: total was -160.880000. running mean: -21.463920\n",
      "ep 34: ep_len:720 episode reward: total was -4.670000. running mean: -21.295981\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 34: ep_len:500 episode reward: total was 14.370000. running mean: -20.939321\n",
      "ep 34: ep_len:500 episode reward: total was 26.830000. running mean: -20.461628\n",
      "ep 34: ep_len:441 episode reward: total was 42.500000. running mean: -19.832012\n",
      "ep 34: ep_len:500 episode reward: total was 16.360000. running mean: -19.470092\n",
      "ep 34: ep_len:500 episode reward: total was -6.820000. running mean: -19.343591\n",
      "ep 34: ep_len:500 episode reward: total was 24.990000. running mean: -18.900255\n",
      "ep 34: ep_len:500 episode reward: total was 0.680000. running mean: -18.704452\n",
      "ep 34: ep_len:500 episode reward: total was -32.960000. running mean: -18.847008\n",
      "ep 34: ep_len:580 episode reward: total was -0.910000. running mean: -18.667638\n",
      "ep 34: ep_len:2280 episode reward: total was -303.920000. running mean: -21.520161\n",
      "ep 34: ep_len:500 episode reward: total was 17.800000. running mean: -21.126960\n",
      "ep 34: ep_len:520 episode reward: total was -31.330000. running mean: -21.228990\n",
      "ep 34: ep_len:500 episode reward: total was 24.170000. running mean: -20.775000\n",
      "ep 34: ep_len:1090 episode reward: total was -62.510000. running mean: -21.192350\n",
      "ep 34: ep_len:650 episode reward: total was -18.090000. running mean: -21.161327\n",
      "ep 34: ep_len:710 episode reward: total was 29.310000. running mean: -20.656613\n",
      "ep 34: ep_len:998 episode reward: total was -101.180000. running mean: -21.461847\n",
      "ep 34: ep_len:448 episode reward: total was -0.800000. running mean: -21.255229\n",
      "ep 34: ep_len:730 episode reward: total was -13.050000. running mean: -21.173176\n",
      "ep 34: ep_len:500 episode reward: total was 27.780000. running mean: -20.683645\n",
      "ep 34: ep_len:635 episode reward: total was -13.180000. running mean: -20.608608\n",
      "ep 34: ep_len:500 episode reward: total was 25.940000. running mean: -20.143122\n",
      "ep 34: ep_len:500 episode reward: total was -9.910000. running mean: -20.040791\n",
      "ep 34: ep_len:575 episode reward: total was -20.500000. running mean: -20.045383\n",
      "ep 34: ep_len:39 episode reward: total was 3.500000. running mean: -19.809929\n",
      "ep 34: ep_len:1183 episode reward: total was -132.020000. running mean: -20.932030\n",
      "ep 34: ep_len:500 episode reward: total was 29.830000. running mean: -20.424410\n",
      "ep 34: ep_len:500 episode reward: total was -8.770000. running mean: -20.307865\n",
      "ep 34: ep_len:1110 episode reward: total was -1.030000. running mean: -20.115087\n",
      "ep 34: ep_len:214 episode reward: total was 21.000000. running mean: -19.703936\n",
      "ep 34: ep_len:580 episode reward: total was 12.480000. running mean: -19.382097\n",
      "ep 34: ep_len:500 episode reward: total was -14.290000. running mean: -19.331176\n",
      "ep 34: ep_len:630 episode reward: total was -6.350000. running mean: -19.201364\n",
      "ep 34: ep_len:760 episode reward: total was -12.670000. running mean: -19.136050\n",
      "ep 34: ep_len:825 episode reward: total was 14.590000. running mean: -18.798790\n",
      "ep 34: ep_len:500 episode reward: total was 12.810000. running mean: -18.482702\n",
      "ep 34: ep_len:705 episode reward: total was -17.840000. running mean: -18.476275\n",
      "ep 34: ep_len:1645 episode reward: total was -147.390000. running mean: -19.765412\n",
      "ep 34: ep_len:660 episode reward: total was -7.770000. running mean: -19.645458\n",
      "ep 34: ep_len:500 episode reward: total was 22.300000. running mean: -19.226003\n",
      "ep 34: ep_len:730 episode reward: total was -3.640000. running mean: -19.070143\n",
      "ep 34: ep_len:510 episode reward: total was -19.230000. running mean: -19.071742\n",
      "ep 34: ep_len:765 episode reward: total was 6.880000. running mean: -18.812224\n",
      "ep 34: ep_len:500 episode reward: total was 18.320000. running mean: -18.440902\n",
      "ep 34: ep_len:720 episode reward: total was -39.990000. running mean: -18.656393\n",
      "ep 34: ep_len:775 episode reward: total was -77.280000. running mean: -19.242629\n",
      "ep 34: ep_len:695 episode reward: total was -17.450000. running mean: -19.224703\n",
      "ep 34: ep_len:500 episode reward: total was 14.000000. running mean: -18.892456\n",
      "ep 34: ep_len:500 episode reward: total was -19.000000. running mean: -18.893531\n",
      "ep 34: ep_len:715 episode reward: total was -4.680000. running mean: -18.751396\n",
      "ep 34: ep_len:105 episode reward: total was 9.000000. running mean: -18.473882\n",
      "ep 34: ep_len:229 episode reward: total was 21.000000. running mean: -18.079143\n",
      "ep 34: ep_len:575 episode reward: total was -17.080000. running mean: -18.069152\n",
      "ep 34: ep_len:735 episode reward: total was -4.640000. running mean: -17.934860\n",
      "ep 34: ep_len:500 episode reward: total was 28.300000. running mean: -17.472512\n",
      "ep 34: ep_len:266 episode reward: total was 26.500000. running mean: -17.032787\n",
      "ep 34: ep_len:735 episode reward: total was -9.690000. running mean: -16.959359\n",
      "ep 34: ep_len:500 episode reward: total was 11.490000. running mean: -16.674865\n",
      "ep 34: ep_len:500 episode reward: total was 26.310000. running mean: -16.245017\n",
      "ep 34: ep_len:241 episode reward: total was 24.500000. running mean: -15.837566\n",
      "ep 34: ep_len:500 episode reward: total was 16.330000. running mean: -15.515891\n",
      "ep 34: ep_len:500 episode reward: total was 34.300000. running mean: -15.017732\n",
      "ep 34: ep_len:505 episode reward: total was 22.770000. running mean: -14.639854\n",
      "ep 34: ep_len:525 episode reward: total was -5.060000. running mean: -14.544056\n",
      "ep 34: ep_len:451 episode reward: total was 20.790000. running mean: -14.190715\n",
      "ep 34: ep_len:500 episode reward: total was -61.700000. running mean: -14.665808\n",
      "ep 34: ep_len:253 episode reward: total was 25.000000. running mean: -14.269150\n",
      "ep 34: ep_len:545 episode reward: total was -9.120000. running mean: -14.217659\n",
      "ep 34: ep_len:590 episode reward: total was 4.750000. running mean: -14.027982\n",
      "ep 34: ep_len:750 episode reward: total was -13.700000. running mean: -14.024702\n",
      "ep 34: ep_len:2510 episode reward: total was -452.000000. running mean: -18.404455\n",
      "ep 34: ep_len:930 episode reward: total was -1.010000. running mean: -18.230511\n",
      "ep 34: ep_len:500 episode reward: total was 48.500000. running mean: -17.563206\n",
      "ep 34: ep_len:615 episode reward: total was -35.180000. running mean: -17.739373\n",
      "ep 34: ep_len:500 episode reward: total was -15.910000. running mean: -17.721080\n",
      "ep 34: ep_len:1740 episode reward: total was -154.130000. running mean: -19.085169\n",
      "ep 34: ep_len:500 episode reward: total was 13.140000. running mean: -18.762917\n",
      "ep 34: ep_len:500 episode reward: total was 50.000000. running mean: -18.075288\n",
      "ep 34: ep_len:500 episode reward: total was 9.590000. running mean: -17.798635\n",
      "ep 34: ep_len:220 episode reward: total was -11.000000. running mean: -17.730649\n",
      "epsilon:0.010000 episode_count: 27596. steps_count: 20055157.000000\n",
      "ep 35: ep_len:2210 episode reward: total was -177.430000. running mean: -19.327642\n",
      "ep 35: ep_len:975 episode reward: total was -49.320000. running mean: -19.627566\n",
      "ep 35: ep_len:820 episode reward: total was 15.510000. running mean: -19.276190\n",
      "ep 35: ep_len:1015 episode reward: total was -119.710000. running mean: -20.280528\n",
      "ep 35: ep_len:985 episode reward: total was 9.630000. running mean: -19.981423\n",
      "ep 35: ep_len:930 episode reward: total was -36.570000. running mean: -20.147309\n",
      "ep 35: ep_len:890 episode reward: total was 14.900000. running mean: -19.796836\n",
      "ep 35: ep_len:500 episode reward: total was 14.830000. running mean: -19.450567\n",
      "ep 35: ep_len:725 episode reward: total was -14.760000. running mean: -19.403662\n",
      "ep 35: ep_len:500 episode reward: total was 25.820000. running mean: -18.951425\n",
      "ep 35: ep_len:500 episode reward: total was 26.310000. running mean: -18.498811\n",
      "ep 35: ep_len:690 episode reward: total was -9.780000. running mean: -18.411623\n",
      "ep 35: ep_len:500 episode reward: total was 6.830000. running mean: -18.159207\n",
      "ep 35: ep_len:146 episode reward: total was 14.500000. running mean: -17.832614\n",
      "ep 35: ep_len:960 episode reward: total was -25.400000. running mean: -17.908288\n",
      "ep 35: ep_len:845 episode reward: total was -13.050000. running mean: -17.859705\n",
      "ep 35: ep_len:500 episode reward: total was 35.220000. running mean: -17.328908\n",
      "ep 35: ep_len:500 episode reward: total was 22.510000. running mean: -16.930519\n",
      "ep 35: ep_len:530 episode reward: total was 27.450000. running mean: -16.486714\n",
      "ep 35: ep_len:510 episode reward: total was 1.000000. running mean: -16.311847\n",
      "ep 35: ep_len:500 episode reward: total was 12.010000. running mean: -16.028629\n",
      "ep 35: ep_len:1750 episode reward: total was -102.580000. running mean: -16.894142\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 35: ep_len:253 episode reward: total was 19.000000. running mean: -16.535201\n",
      "ep 35: ep_len:945 episode reward: total was -21.390000. running mean: -16.583749\n",
      "ep 35: ep_len:1740 episode reward: total was -25.410000. running mean: -16.672011\n",
      "ep 35: ep_len:580 episode reward: total was 21.140000. running mean: -16.293891\n",
      "ep 35: ep_len:525 episode reward: total was -11.810000. running mean: -16.249052\n",
      "ep 35: ep_len:700 episode reward: total was 29.710000. running mean: -15.789462\n",
      "ep 35: ep_len:860 episode reward: total was -24.600000. running mean: -15.877567\n",
      "ep 35: ep_len:500 episode reward: total was 8.090000. running mean: -15.637891\n",
      "ep 35: ep_len:515 episode reward: total was -6.090000. running mean: -15.542413\n",
      "ep 35: ep_len:790 episode reward: total was -4.690000. running mean: -15.433888\n",
      "ep 35: ep_len:500 episode reward: total was -4.130000. running mean: -15.320850\n",
      "ep 35: ep_len:700 episode reward: total was -3.700000. running mean: -15.204641\n",
      "ep 35: ep_len:372 episode reward: total was 10.130000. running mean: -14.951295\n",
      "ep 35: ep_len:500 episode reward: total was 28.820000. running mean: -14.513582\n",
      "ep 35: ep_len:1335 episode reward: total was -234.240000. running mean: -16.710846\n",
      "ep 35: ep_len:615 episode reward: total was -5.890000. running mean: -16.602637\n",
      "ep 35: ep_len:500 episode reward: total was 36.230000. running mean: -16.074311\n",
      "ep 35: ep_len:500 episode reward: total was -0.080000. running mean: -15.914368\n",
      "ep 35: ep_len:500 episode reward: total was -20.990000. running mean: -15.965124\n",
      "ep 35: ep_len:850 episode reward: total was 15.940000. running mean: -15.646073\n",
      "ep 35: ep_len:550 episode reward: total was -8.040000. running mean: -15.570012\n",
      "ep 35: ep_len:500 episode reward: total was 19.790000. running mean: -15.216412\n",
      "ep 35: ep_len:500 episode reward: total was 25.330000. running mean: -14.810948\n",
      "ep 35: ep_len:22055 episode reward: total was -4286.790000. running mean: -57.530739\n",
      "ep 35: ep_len:735 episode reward: total was -0.600000. running mean: -56.961431\n",
      "ep 35: ep_len:940 episode reward: total was -11.850000. running mean: -56.510317\n",
      "ep 35: ep_len:242 episode reward: total was 24.000000. running mean: -55.705214\n",
      "ep 35: ep_len:740 episode reward: total was 2.780000. running mean: -55.120362\n",
      "ep 35: ep_len:100 episode reward: total was 8.500000. running mean: -54.484158\n",
      "ep 35: ep_len:735 episode reward: total was -4.230000. running mean: -53.981616\n",
      "ep 35: ep_len:715 episode reward: total was -19.800000. running mean: -53.639800\n",
      "ep 35: ep_len:500 episode reward: total was -72.380000. running mean: -53.827202\n",
      "ep 35: ep_len:680 episode reward: total was -91.610000. running mean: -54.205030\n",
      "ep 35: ep_len:855 episode reward: total was -54.570000. running mean: -54.208680\n",
      "ep 35: ep_len:500 episode reward: total was 20.220000. running mean: -53.464393\n",
      "ep 35: ep_len:500 episode reward: total was -43.180000. running mean: -53.361549\n",
      "ep 35: ep_len:349 episode reward: total was 33.000000. running mean: -52.497934\n",
      "ep 35: ep_len:20595 episode reward: total was -4016.020000. running mean: -92.133154\n",
      "ep 35: ep_len:500 episode reward: total was -14.960000. running mean: -91.361423\n",
      "ep 35: ep_len:530 episode reward: total was -7.040000. running mean: -90.518209\n",
      "ep 35: ep_len:205 episode reward: total was 17.500000. running mean: -89.438026\n",
      "ep 35: ep_len:229 episode reward: total was 21.000000. running mean: -88.333646\n",
      "ep 35: ep_len:500 episode reward: total was 1.610000. running mean: -87.434210\n",
      "ep 35: ep_len:500 episode reward: total was 16.610000. running mean: -86.393768\n",
      "ep 35: ep_len:1120 episode reward: total was -161.400000. running mean: -87.143830\n",
      "ep 35: ep_len:605 episode reward: total was -6.920000. running mean: -86.341592\n",
      "ep 35: ep_len:500 episode reward: total was 3.090000. running mean: -85.447276\n",
      "ep 35: ep_len:615 episode reward: total was -9.930000. running mean: -84.692103\n",
      "ep 35: ep_len:695 episode reward: total was -27.950000. running mean: -84.124682\n",
      "ep 35: ep_len:131 episode reward: total was 13.000000. running mean: -83.153435\n",
      "ep 35: ep_len:895 episode reward: total was -1.080000. running mean: -82.332701\n",
      "ep 35: ep_len:820 episode reward: total was 6.830000. running mean: -81.441074\n",
      "ep 35: ep_len:1175 episode reward: total was -150.280000. running mean: -82.129463\n",
      "ep 35: ep_len:500 episode reward: total was -10.360000. running mean: -81.411768\n",
      "ep 35: ep_len:500 episode reward: total was 19.730000. running mean: -80.400351\n",
      "ep 35: ep_len:500 episode reward: total was -33.110000. running mean: -79.927447\n",
      "ep 35: ep_len:3233 episode reward: total was -454.640000. running mean: -83.674573\n",
      "ep 35: ep_len:590 episode reward: total was 3.800000. running mean: -82.799827\n",
      "ep 35: ep_len:1455 episode reward: total was -157.070000. running mean: -83.542529\n",
      "ep 35: ep_len:500 episode reward: total was 6.260000. running mean: -82.644503\n",
      "ep 35: ep_len:650 episode reward: total was 1.250000. running mean: -81.805558\n",
      "ep 35: ep_len:620 episode reward: total was 5.970000. running mean: -80.927803\n",
      "ep 35: ep_len:228 episode reward: total was 21.000000. running mean: -79.908525\n",
      "ep 35: ep_len:500 episode reward: total was 3.200000. running mean: -79.077440\n",
      "ep 35: ep_len:585 episode reward: total was -0.870000. running mean: -78.295365\n",
      "ep 35: ep_len:500 episode reward: total was -17.070000. running mean: -77.683112\n",
      "ep 35: ep_len:655 episode reward: total was 21.730000. running mean: -76.688980\n",
      "ep 35: ep_len:660 episode reward: total was -3.260000. running mean: -75.954691\n",
      "ep 35: ep_len:785 episode reward: total was -44.910000. running mean: -75.644244\n",
      "ep 35: ep_len:580 episode reward: total was 11.710000. running mean: -74.770701\n",
      "ep 35: ep_len:1030 episode reward: total was -23.030000. running mean: -74.253294\n",
      "ep 35: ep_len:500 episode reward: total was 2.290000. running mean: -73.487861\n",
      "ep 35: ep_len:500 episode reward: total was 0.140000. running mean: -72.751583\n",
      "ep 35: ep_len:1605 episode reward: total was -230.380000. running mean: -74.327867\n",
      "ep 35: ep_len:690 episode reward: total was -13.070000. running mean: -73.715288\n",
      "ep 35: ep_len:500 episode reward: total was 48.500000. running mean: -72.493135\n",
      "ep 35: ep_len:890 episode reward: total was -22.200000. running mean: -71.990204\n",
      "ep 35: ep_len:780 episode reward: total was 5.770000. running mean: -71.212602\n",
      "ep 35: ep_len:493 episode reward: total was 18.240000. running mean: -70.318076\n",
      "ep 35: ep_len:905 episode reward: total was -42.240000. running mean: -70.037295\n",
      "ep 35: ep_len:500 episode reward: total was 31.210000. running mean: -69.024822\n",
      "ep 35: ep_len:810 episode reward: total was -21.600000. running mean: -68.550574\n",
      "ep 35: ep_len:799 episode reward: total was -69.110000. running mean: -68.556168\n",
      "ep 35: ep_len:630 episode reward: total was -23.000000. running mean: -68.100607\n",
      "ep 35: ep_len:580 episode reward: total was -30.200000. running mean: -67.721600\n",
      "ep 35: ep_len:193 episode reward: total was 19.000000. running mean: -66.854384\n",
      "ep 35: ep_len:124 episode reward: total was 12.000000. running mean: -66.065841\n",
      "ep 35: ep_len:640 episode reward: total was -0.790000. running mean: -65.413082\n",
      "ep 35: ep_len:500 episode reward: total was 16.800000. running mean: -64.590951\n",
      "ep 35: ep_len:805 episode reward: total was -8.540000. running mean: -64.030442\n",
      "ep 35: ep_len:500 episode reward: total was 3.310000. running mean: -63.357037\n",
      "ep 35: ep_len:500 episode reward: total was -10.710000. running mean: -62.830567\n",
      "ep 35: ep_len:189 episode reward: total was 18.500000. running mean: -62.017261\n",
      "ep 35: ep_len:865 episode reward: total was -30.640000. running mean: -61.703489\n",
      "ep 35: ep_len:500 episode reward: total was 15.040000. running mean: -60.936054\n",
      "ep 35: ep_len:850 episode reward: total was -18.130000. running mean: -60.507993\n",
      "ep 35: ep_len:971 episode reward: total was -45.560000. running mean: -60.358513\n",
      "ep 35: ep_len:500 episode reward: total was 1.690000. running mean: -59.738028\n",
      "ep 35: ep_len:500 episode reward: total was -7.770000. running mean: -59.218348\n",
      "ep 35: ep_len:1997 episode reward: total was -209.150000. running mean: -60.717665\n",
      "ep 35: ep_len:685 episode reward: total was -5.540000. running mean: -60.165888\n",
      "ep 35: ep_len:705 episode reward: total was -2.680000. running mean: -59.591029\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 35: ep_len:3790 episode reward: total was -523.680000. running mean: -64.231919\n",
      "ep 35: ep_len:1500 episode reward: total was -150.500000. running mean: -65.094600\n",
      "ep 35: ep_len:1095 episode reward: total was 17.410000. running mean: -64.269554\n",
      "ep 35: ep_len:835 episode reward: total was 22.600000. running mean: -63.400858\n",
      "ep 35: ep_len:855 episode reward: total was -32.680000. running mean: -63.093649\n",
      "ep 35: ep_len:500 episode reward: total was -4.520000. running mean: -62.507913\n",
      "ep 35: ep_len:500 episode reward: total was -37.060000. running mean: -62.253434\n",
      "ep 35: ep_len:500 episode reward: total was 17.310000. running mean: -61.457799\n",
      "ep 35: ep_len:1610 episode reward: total was -48.340000. running mean: -61.326621\n",
      "ep 35: ep_len:2050 episode reward: total was -179.670000. running mean: -62.510055\n",
      "ep 35: ep_len:521 episode reward: total was -90.430000. running mean: -62.789255\n",
      "ep 35: ep_len:500 episode reward: total was -18.510000. running mean: -62.346462\n",
      "ep 35: ep_len:500 episode reward: total was 18.810000. running mean: -61.534898\n",
      "ep 35: ep_len:3064 episode reward: total was -334.280000. running mean: -64.262349\n",
      "ep 35: ep_len:500 episode reward: total was 23.710000. running mean: -63.382625\n",
      "ep 35: ep_len:830 episode reward: total was 1.330000. running mean: -62.735499\n",
      "ep 35: ep_len:1485 episode reward: total was -70.810000. running mean: -62.816244\n",
      "ep 35: ep_len:525 episode reward: total was -11.120000. running mean: -62.299281\n",
      "ep 35: ep_len:500 episode reward: total was 29.740000. running mean: -61.378889\n",
      "ep 35: ep_len:112 episode reward: total was 9.500000. running mean: -60.670100\n",
      "ep 35: ep_len:218 episode reward: total was 21.500000. running mean: -59.848399\n",
      "ep 35: ep_len:500 episode reward: total was 50.000000. running mean: -58.749915\n",
      "ep 35: ep_len:175 episode reward: total was 14.500000. running mean: -58.017416\n",
      "ep 35: ep_len:705 episode reward: total was -3.690000. running mean: -57.474141\n",
      "ep 35: ep_len:725 episode reward: total was -2.730000. running mean: -56.926700\n",
      "ep 35: ep_len:500 episode reward: total was 15.750000. running mean: -56.199933\n",
      "ep 35: ep_len:500 episode reward: total was 30.660000. running mean: -55.331334\n",
      "ep 35: ep_len:855 episode reward: total was 15.720000. running mean: -54.620820\n",
      "ep 35: ep_len:500 episode reward: total was -34.920000. running mean: -54.423812\n",
      "ep 35: ep_len:500 episode reward: total was 5.210000. running mean: -53.827474\n",
      "ep 35: ep_len:151 episode reward: total was 15.000000. running mean: -53.139199\n",
      "ep 35: ep_len:500 episode reward: total was 0.940000. running mean: -52.598407\n",
      "ep 35: ep_len:500 episode reward: total was -7.340000. running mean: -52.145823\n",
      "ep 35: ep_len:675 episode reward: total was -0.720000. running mean: -51.631565\n",
      "ep 35: ep_len:500 episode reward: total was -8.720000. running mean: -51.202449\n",
      "ep 35: ep_len:725 episode reward: total was -4.660000. running mean: -50.737025\n",
      "ep 35: ep_len:500 episode reward: total was 28.270000. running mean: -49.946955\n",
      "ep 35: ep_len:590 episode reward: total was -9.460000. running mean: -49.542085\n",
      "ep 35: ep_len:500 episode reward: total was -6.360000. running mean: -49.110264\n",
      "ep 35: ep_len:665 episode reward: total was -11.330000. running mean: -48.732462\n",
      "ep 35: ep_len:1200 episode reward: total was 20.430000. running mean: -48.040837\n",
      "ep 35: ep_len:204 episode reward: total was 18.500000. running mean: -47.375429\n",
      "ep 35: ep_len:690 episode reward: total was -5.740000. running mean: -46.959074\n",
      "ep 35: ep_len:800 episode reward: total was -9.180000. running mean: -46.581284\n",
      "ep 35: ep_len:490 episode reward: total was 27.210000. running mean: -45.843371\n",
      "ep 35: ep_len:500 episode reward: total was 24.930000. running mean: -45.135637\n",
      "ep 35: ep_len:435 episode reward: total was -84.490000. running mean: -45.529181\n",
      "ep 35: ep_len:500 episode reward: total was 4.140000. running mean: -45.032489\n",
      "ep 35: ep_len:1055 episode reward: total was -12.480000. running mean: -44.706964\n",
      "ep 35: ep_len:500 episode reward: total was 11.120000. running mean: -44.148694\n",
      "ep 35: ep_len:500 episode reward: total was -14.430000. running mean: -43.851507\n",
      "ep 35: ep_len:735 episode reward: total was -2.620000. running mean: -43.439192\n",
      "ep 35: ep_len:1010 episode reward: total was -11.920000. running mean: -43.124000\n",
      "ep 35: ep_len:720 episode reward: total was -12.720000. running mean: -42.819960\n",
      "ep 35: ep_len:1144 episode reward: total was -156.860000. running mean: -43.960361\n",
      "ep 35: ep_len:500 episode reward: total was 4.810000. running mean: -43.472657\n",
      "ep 35: ep_len:560 episode reward: total was 15.780000. running mean: -42.880131\n",
      "ep 35: ep_len:775 episode reward: total was -27.630000. running mean: -42.727629\n",
      "ep 35: ep_len:550 episode reward: total was -7.230000. running mean: -42.372653\n",
      "ep 35: ep_len:520 episode reward: total was -29.260000. running mean: -42.241526\n",
      "ep 35: ep_len:500 episode reward: total was -7.710000. running mean: -41.896211\n",
      "ep 35: ep_len:254 episode reward: total was 23.500000. running mean: -41.242249\n",
      "ep 35: ep_len:500 episode reward: total was 20.190000. running mean: -40.627927\n",
      "ep 35: ep_len:585 episode reward: total was -2.920000. running mean: -40.250847\n",
      "ep 35: ep_len:500 episode reward: total was -6.120000. running mean: -39.909539\n",
      "ep 35: ep_len:500 episode reward: total was 26.800000. running mean: -39.242443\n",
      "ep 35: ep_len:500 episode reward: total was -0.700000. running mean: -38.857019\n",
      "ep 35: ep_len:500 episode reward: total was -3.260000. running mean: -38.501049\n",
      "ep 35: ep_len:725 episode reward: total was -8.700000. running mean: -38.203038\n",
      "ep 35: ep_len:207 episode reward: total was 21.000000. running mean: -37.611008\n",
      "ep 35: ep_len:196 episode reward: total was 18.000000. running mean: -37.054898\n",
      "ep 35: ep_len:790 episode reward: total was -16.650000. running mean: -36.850849\n",
      "ep 35: ep_len:180 episode reward: total was 15.000000. running mean: -36.332340\n",
      "ep 35: ep_len:500 episode reward: total was 14.370000. running mean: -35.825317\n",
      "ep 35: ep_len:500 episode reward: total was 13.910000. running mean: -35.327964\n",
      "ep 35: ep_len:2046 episode reward: total was -297.530000. running mean: -37.949984\n",
      "ep 35: ep_len:500 episode reward: total was 20.280000. running mean: -37.367684\n",
      "ep 35: ep_len:580 episode reward: total was -23.130000. running mean: -37.225307\n",
      "ep 35: ep_len:805 episode reward: total was -0.390000. running mean: -36.856954\n",
      "ep 35: ep_len:780 episode reward: total was -16.670000. running mean: -36.655085\n",
      "ep 35: ep_len:840 episode reward: total was 16.990000. running mean: -36.118634\n",
      "ep 35: ep_len:615 episode reward: total was -4.360000. running mean: -35.801048\n",
      "ep 35: ep_len:965 episode reward: total was 38.050000. running mean: -35.062537\n",
      "ep 35: ep_len:600 episode reward: total was -5.150000. running mean: -34.763412\n",
      "ep 35: ep_len:500 episode reward: total was -0.990000. running mean: -34.425678\n",
      "ep 35: ep_len:500 episode reward: total was 8.120000. running mean: -34.000221\n",
      "ep 35: ep_len:4380 episode reward: total was -606.430000. running mean: -39.724519\n",
      "ep 35: ep_len:505 episode reward: total was 28.770000. running mean: -39.039574\n",
      "ep 35: ep_len:500 episode reward: total was 8.180000. running mean: -38.567378\n",
      "ep 35: ep_len:555 episode reward: total was 19.530000. running mean: -37.986404\n",
      "ep 35: ep_len:855 episode reward: total was -18.090000. running mean: -37.787440\n",
      "ep 35: ep_len:690 episode reward: total was 28.530000. running mean: -37.124266\n",
      "ep 35: ep_len:294 episode reward: total was 26.000000. running mean: -36.493023\n",
      "ep 35: ep_len:695 episode reward: total was -4.260000. running mean: -36.170693\n",
      "ep 35: ep_len:800 episode reward: total was -2.700000. running mean: -35.835986\n",
      "ep 35: ep_len:500 episode reward: total was -8.650000. running mean: -35.564126\n",
      "ep 35: ep_len:500 episode reward: total was -13.770000. running mean: -35.346185\n",
      "ep 35: ep_len:500 episode reward: total was -42.690000. running mean: -35.419623\n",
      "ep 35: ep_len:670 episode reward: total was 0.290000. running mean: -35.062527\n",
      "ep 35: ep_len:500 episode reward: total was 12.560000. running mean: -34.586301\n",
      "ep 35: ep_len:1030 episode reward: total was 21.770000. running mean: -34.022738\n",
      "ep 35: ep_len:500 episode reward: total was -3.330000. running mean: -33.715811\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 35: ep_len:815 episode reward: total was 1.500000. running mean: -33.363653\n",
      "ep 35: ep_len:500 episode reward: total was -19.950000. running mean: -33.229516\n",
      "ep 35: ep_len:505 episode reward: total was 26.290000. running mean: -32.634321\n",
      "ep 35: ep_len:500 episode reward: total was -7.310000. running mean: -32.381078\n",
      "ep 35: ep_len:500 episode reward: total was 0.830000. running mean: -32.048967\n",
      "ep 35: ep_len:500 episode reward: total was 2.850000. running mean: -31.699977\n",
      "ep 35: ep_len:500 episode reward: total was 4.290000. running mean: -31.340078\n",
      "ep 35: ep_len:700 episode reward: total was -2.690000. running mean: -31.053577\n",
      "ep 35: ep_len:500 episode reward: total was -0.670000. running mean: -30.749741\n",
      "ep 35: ep_len:760 episode reward: total was -23.780000. running mean: -30.680044\n",
      "ep 35: ep_len:625 episode reward: total was 12.400000. running mean: -30.249243\n",
      "ep 35: ep_len:540 episode reward: total was -47.450000. running mean: -30.421251\n",
      "ep 35: ep_len:500 episode reward: total was -6.660000. running mean: -30.183638\n",
      "ep 35: ep_len:835 episode reward: total was -6.270000. running mean: -29.944502\n",
      "ep 35: ep_len:1875 episode reward: total was -157.650000. running mean: -31.221557\n",
      "ep 35: ep_len:500 episode reward: total was 29.280000. running mean: -30.616541\n",
      "ep 35: ep_len:745 episode reward: total was -5.630000. running mean: -30.366676\n",
      "ep 35: ep_len:720 episode reward: total was -13.760000. running mean: -30.200609\n",
      "ep 35: ep_len:500 episode reward: total was 7.330000. running mean: -29.825303\n",
      "ep 35: ep_len:500 episode reward: total was 3.290000. running mean: -29.494150\n",
      "ep 35: ep_len:500 episode reward: total was 24.290000. running mean: -28.956309\n",
      "ep 35: ep_len:595 episode reward: total was 0.130000. running mean: -28.665445\n",
      "ep 35: ep_len:500 episode reward: total was 13.270000. running mean: -28.246091\n",
      "ep 35: ep_len:500 episode reward: total was 4.830000. running mean: -27.915330\n",
      "ep 35: ep_len:670 episode reward: total was -1.770000. running mean: -27.653877\n",
      "ep 35: ep_len:670 episode reward: total was 23.620000. running mean: -27.141138\n",
      "ep 35: ep_len:497 episode reward: total was 35.760000. running mean: -26.512127\n",
      "ep 35: ep_len:42 episode reward: total was 2.500000. running mean: -26.222005\n",
      "ep 35: ep_len:1150 episode reward: total was 8.800000. running mean: -25.871785\n",
      "ep 35: ep_len:535 episode reward: total was 4.790000. running mean: -25.565168\n",
      "ep 35: ep_len:500 episode reward: total was 17.340000. running mean: -25.136116\n",
      "ep 35: ep_len:875 episode reward: total was -22.540000. running mean: -25.110155\n",
      "ep 35: ep_len:780 episode reward: total was 16.530000. running mean: -24.693753\n",
      "ep 35: ep_len:500 episode reward: total was -12.050000. running mean: -24.567316\n",
      "ep 35: ep_len:500 episode reward: total was -6.170000. running mean: -24.383342\n",
      "ep 35: ep_len:870 episode reward: total was 26.500000. running mean: -23.874509\n",
      "ep 35: ep_len:990 episode reward: total was -4.980000. running mean: -23.685564\n",
      "ep 35: ep_len:132 episode reward: total was 13.000000. running mean: -23.318708\n",
      "ep 35: ep_len:500 episode reward: total was 9.350000. running mean: -22.992021\n",
      "ep 35: ep_len:830 episode reward: total was 0.850000. running mean: -22.753601\n",
      "ep 35: ep_len:500 episode reward: total was 25.370000. running mean: -22.272365\n",
      "ep 35: ep_len:229 episode reward: total was 22.500000. running mean: -21.824641\n",
      "ep 35: ep_len:130 episode reward: total was 8.500000. running mean: -21.521395\n",
      "ep 35: ep_len:500 episode reward: total was 8.770000. running mean: -21.218481\n",
      "ep 35: ep_len:625 episode reward: total was -0.820000. running mean: -21.014496\n",
      "ep 35: ep_len:660 episode reward: total was 3.560000. running mean: -20.768751\n",
      "ep 35: ep_len:500 episode reward: total was 47.000000. running mean: -20.091064\n",
      "ep 35: ep_len:500 episode reward: total was 3.220000. running mean: -19.857953\n",
      "ep 35: ep_len:500 episode reward: total was 4.720000. running mean: -19.612174\n",
      "ep 35: ep_len:219 episode reward: total was 20.000000. running mean: -19.216052\n",
      "ep 35: ep_len:500 episode reward: total was 17.250000. running mean: -18.851391\n",
      "ep 35: ep_len:850 episode reward: total was 16.610000. running mean: -18.496777\n",
      "ep 35: ep_len:660 episode reward: total was 23.850000. running mean: -18.073310\n",
      "ep 35: ep_len:500 episode reward: total was 22.790000. running mean: -17.664676\n",
      "ep 35: ep_len:500 episode reward: total was -11.680000. running mean: -17.604830\n",
      "ep 35: ep_len:1185 episode reward: total was -156.740000. running mean: -18.996181\n",
      "ep 35: ep_len:500 episode reward: total was 0.250000. running mean: -18.803720\n",
      "ep 35: ep_len:560 episode reward: total was -4.990000. running mean: -18.665582\n",
      "ep 35: ep_len:915 episode reward: total was 28.010000. running mean: -18.198827\n",
      "ep 35: ep_len:309 episode reward: total was 19.000000. running mean: -17.826838\n",
      "ep 35: ep_len:232 episode reward: total was 23.000000. running mean: -17.418570\n",
      "ep 35: ep_len:620 episode reward: total was -25.070000. running mean: -17.495084\n",
      "ep 35: ep_len:1330 episode reward: total was -178.180000. running mean: -19.101933\n",
      "ep 35: ep_len:505 episode reward: total was -30.350000. running mean: -19.214414\n",
      "ep 35: ep_len:500 episode reward: total was 9.470000. running mean: -18.927570\n",
      "ep 35: ep_len:500 episode reward: total was -14.780000. running mean: -18.886094\n",
      "ep 35: ep_len:790 episode reward: total was -77.250000. running mean: -19.469733\n",
      "ep 35: ep_len:1525 episode reward: total was -20.230000. running mean: -19.477336\n",
      "ep 35: ep_len:1020 episode reward: total was 14.830000. running mean: -19.134263\n",
      "ep 35: ep_len:500 episode reward: total was 47.000000. running mean: -18.472920\n",
      "ep 35: ep_len:500 episode reward: total was -10.860000. running mean: -18.396791\n",
      "ep 35: ep_len:580 episode reward: total was 5.250000. running mean: -18.160323\n",
      "ep 35: ep_len:825 episode reward: total was -1.170000. running mean: -17.990420\n",
      "ep 35: ep_len:755 episode reward: total was -7.630000. running mean: -17.886815\n",
      "ep 35: ep_len:1040 episode reward: total was -5.040000. running mean: -17.758347\n",
      "ep 35: ep_len:515 episode reward: total was -15.180000. running mean: -17.732564\n",
      "ep 35: ep_len:500 episode reward: total was -13.310000. running mean: -17.688338\n",
      "ep 35: ep_len:500 episode reward: total was 10.230000. running mean: -17.409155\n",
      "ep 35: ep_len:187 episode reward: total was 18.500000. running mean: -17.050063\n",
      "ep 35: ep_len:605 episode reward: total was -9.950000. running mean: -16.979063\n",
      "ep 35: ep_len:1035 episode reward: total was -15.010000. running mean: -16.959372\n",
      "ep 35: ep_len:500 episode reward: total was -16.740000. running mean: -16.957178\n",
      "ep 35: ep_len:500 episode reward: total was 17.000000. running mean: -16.617606\n",
      "ep 35: ep_len:600 episode reward: total was -23.090000. running mean: -16.682330\n",
      "ep 35: ep_len:249 episode reward: total was 24.500000. running mean: -16.270507\n",
      "ep 35: ep_len:201 episode reward: total was 20.000000. running mean: -15.907802\n",
      "ep 35: ep_len:265 episode reward: total was 23.500000. running mean: -15.513724\n",
      "ep 35: ep_len:358 episode reward: total was 27.000000. running mean: -15.088587\n",
      "ep 35: ep_len:625 episode reward: total was 11.650000. running mean: -14.821201\n",
      "ep 35: ep_len:705 episode reward: total was -8.820000. running mean: -14.761189\n",
      "ep 35: ep_len:154 episode reward: total was 15.000000. running mean: -14.463577\n",
      "ep 35: ep_len:500 episode reward: total was 7.700000. running mean: -14.241941\n",
      "ep 35: ep_len:500 episode reward: total was 25.910000. running mean: -13.840422\n",
      "ep 35: ep_len:760 episode reward: total was -3.790000. running mean: -13.739918\n",
      "ep 35: ep_len:715 episode reward: total was 12.840000. running mean: -13.474118\n",
      "ep 35: ep_len:660 episode reward: total was -41.150000. running mean: -13.750877\n",
      "ep 35: ep_len:399 episode reward: total was 11.250000. running mean: -13.500868\n",
      "ep 35: ep_len:790 episode reward: total was -11.600000. running mean: -13.481860\n",
      "ep 35: ep_len:710 episode reward: total was 0.740000. running mean: -13.339641\n",
      "ep 35: ep_len:500 episode reward: total was 18.410000. running mean: -13.022145\n",
      "ep 35: ep_len:500 episode reward: total was 30.780000. running mean: -12.584123\n",
      "ep 35: ep_len:1115 episode reward: total was 16.430000. running mean: -12.293982\n",
      "ep 35: ep_len:500 episode reward: total was -0.320000. running mean: -12.174242\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 35: ep_len:500 episode reward: total was 34.270000. running mean: -11.709800\n",
      "ep 35: ep_len:500 episode reward: total was 31.730000. running mean: -11.275402\n",
      "ep 35: ep_len:1060 episode reward: total was -96.910000. running mean: -12.131748\n",
      "ep 35: ep_len:354 episode reward: total was 17.830000. running mean: -11.832130\n",
      "ep 35: ep_len:950 episode reward: total was -6.230000. running mean: -11.776109\n",
      "ep 35: ep_len:655 episode reward: total was 17.430000. running mean: -11.484048\n",
      "ep 35: ep_len:900 episode reward: total was 1.000000. running mean: -11.359207\n",
      "ep 35: ep_len:316 episode reward: total was 27.500000. running mean: -10.970615\n",
      "ep 35: ep_len:279 episode reward: total was 27.500000. running mean: -10.585909\n",
      "ep 35: ep_len:580 episode reward: total was 4.680000. running mean: -10.433250\n",
      "ep 35: ep_len:880 episode reward: total was -2.690000. running mean: -10.355818\n",
      "ep 35: ep_len:875 episode reward: total was 8.810000. running mean: -10.164159\n",
      "ep 35: ep_len:642 episode reward: total was -65.790000. running mean: -10.720418\n",
      "ep 35: ep_len:99 episode reward: total was 9.500000. running mean: -10.518214\n",
      "ep 35: ep_len:500 episode reward: total was 10.260000. running mean: -10.310432\n",
      "ep 35: ep_len:565 episode reward: total was 4.880000. running mean: -10.158527\n",
      "ep 35: ep_len:500 episode reward: total was 34.270000. running mean: -9.714242\n",
      "ep 35: ep_len:500 episode reward: total was 50.000000. running mean: -9.117100\n",
      "ep 35: ep_len:795 episode reward: total was 4.360000. running mean: -8.982329\n",
      "ep 35: ep_len:5775 episode reward: total was -956.660000. running mean: -18.459105\n",
      "ep 35: ep_len:233 episode reward: total was 21.500000. running mean: -18.059514\n",
      "ep 35: ep_len:500 episode reward: total was 18.380000. running mean: -17.695119\n",
      "ep 35: ep_len:815 episode reward: total was -0.620000. running mean: -17.524368\n",
      "ep 35: ep_len:500 episode reward: total was -20.740000. running mean: -17.556524\n",
      "ep 35: ep_len:2220 episode reward: total was -345.540000. running mean: -20.836359\n",
      "ep 35: ep_len:152 episode reward: total was 15.000000. running mean: -20.477995\n",
      "ep 35: ep_len:875 episode reward: total was -26.070000. running mean: -20.533915\n",
      "ep 35: ep_len:285 episode reward: total was 27.000000. running mean: -20.058576\n",
      "ep 35: ep_len:525 episode reward: total was -16.140000. running mean: -20.019391\n",
      "ep 35: ep_len:2024 episode reward: total was -326.280000. running mean: -23.081997\n",
      "ep 35: ep_len:515 episode reward: total was -11.140000. running mean: -22.962577\n",
      "ep 35: ep_len:500 episode reward: total was 17.890000. running mean: -22.554051\n",
      "ep 35: ep_len:500 episode reward: total was 10.750000. running mean: -22.221010\n",
      "ep 35: ep_len:640 episode reward: total was -8.870000. running mean: -22.087500\n",
      "ep 35: ep_len:500 episode reward: total was -22.280000. running mean: -22.089425\n",
      "ep 35: ep_len:500 episode reward: total was 22.760000. running mean: -21.640931\n",
      "ep 35: ep_len:500 episode reward: total was 7.690000. running mean: -21.347622\n",
      "ep 35: ep_len:535 episode reward: total was 18.540000. running mean: -20.948745\n",
      "ep 35: ep_len:392 episode reward: total was 6.890000. running mean: -20.670358\n",
      "ep 35: ep_len:765 episode reward: total was -1.300000. running mean: -20.476654\n",
      "ep 35: ep_len:500 episode reward: total was 10.200000. running mean: -20.169888\n",
      "ep 35: ep_len:500 episode reward: total was 12.380000. running mean: -19.844389\n",
      "ep 35: ep_len:895 episode reward: total was -27.550000. running mean: -19.921445\n",
      "ep 35: ep_len:475 episode reward: total was -70.350000. running mean: -20.425731\n",
      "ep 35: ep_len:525 episode reward: total was 0.670000. running mean: -20.214773\n",
      "ep 35: ep_len:505 episode reward: total was -45.040000. running mean: -20.463026\n",
      "ep 35: ep_len:560 episode reward: total was -14.080000. running mean: -20.399195\n",
      "ep 35: ep_len:590 episode reward: total was 7.510000. running mean: -20.120103\n",
      "ep 35: ep_len:750 episode reward: total was -17.740000. running mean: -20.096302\n",
      "ep 35: ep_len:980 episode reward: total was -153.900000. running mean: -21.434339\n",
      "ep 35: ep_len:830 episode reward: total was 28.600000. running mean: -20.933996\n",
      "ep 35: ep_len:185 episode reward: total was 17.000000. running mean: -20.554656\n",
      "ep 35: ep_len:500 episode reward: total was -4.250000. running mean: -20.391609\n",
      "ep 35: ep_len:1025 episode reward: total was 18.770000. running mean: -19.999993\n",
      "ep 35: ep_len:780 episode reward: total was 3.120000. running mean: -19.768793\n",
      "ep 35: ep_len:500 episode reward: total was 7.450000. running mean: -19.496605\n",
      "ep 35: ep_len:500 episode reward: total was -28.790000. running mean: -19.589539\n",
      "ep 35: ep_len:500 episode reward: total was 1.510000. running mean: -19.378544\n",
      "ep 35: ep_len:2785 episode reward: total was -337.560000. running mean: -22.560359\n",
      "ep 35: ep_len:800 episode reward: total was 17.700000. running mean: -22.157755\n",
      "ep 35: ep_len:965 episode reward: total was 5.060000. running mean: -21.885577\n",
      "ep 35: ep_len:1440 episode reward: total was -127.460000. running mean: -22.941322\n",
      "ep 35: ep_len:500 episode reward: total was -3.660000. running mean: -22.748508\n",
      "ep 35: ep_len:680 episode reward: total was -33.520000. running mean: -22.856223\n",
      "ep 35: ep_len:695 episode reward: total was -1.690000. running mean: -22.644561\n",
      "ep 35: ep_len:382 episode reward: total was 38.500000. running mean: -22.033116\n",
      "ep 35: ep_len:678 episode reward: total was -39.100000. running mean: -22.203784\n",
      "ep 35: ep_len:1415 episode reward: total was -121.450000. running mean: -23.196247\n",
      "ep 35: ep_len:195 episode reward: total was 18.000000. running mean: -22.784284\n",
      "ep 35: ep_len:535 episode reward: total was 27.330000. running mean: -22.283141\n",
      "ep 35: ep_len:910 episode reward: total was -34.590000. running mean: -22.406210\n",
      "ep 35: ep_len:545 episode reward: total was -28.250000. running mean: -22.464648\n",
      "ep 35: ep_len:1130 episode reward: total was 13.340000. running mean: -22.106601\n",
      "ep 35: ep_len:500 episode reward: total was 22.940000. running mean: -21.656135\n",
      "ep 35: ep_len:387 episode reward: total was 37.000000. running mean: -21.069574\n",
      "ep 35: ep_len:286 episode reward: total was 28.500000. running mean: -20.573878\n",
      "ep 35: ep_len:500 episode reward: total was 18.530000. running mean: -20.182839\n",
      "ep 35: ep_len:725 episode reward: total was -4.660000. running mean: -20.027611\n",
      "ep 35: ep_len:565 episode reward: total was -14.030000. running mean: -19.967635\n",
      "ep 35: ep_len:283 episode reward: total was 26.500000. running mean: -19.502959\n",
      "ep 35: ep_len:500 episode reward: total was 33.200000. running mean: -18.975929\n",
      "ep 35: ep_len:940 episode reward: total was -40.340000. running mean: -19.189570\n",
      "ep 35: ep_len:500 episode reward: total was 15.650000. running mean: -18.841174\n",
      "ep 35: ep_len:178 episode reward: total was 18.000000. running mean: -18.472762\n",
      "ep 35: ep_len:1055 episode reward: total was -51.470000. running mean: -18.802735\n",
      "ep 35: ep_len:500 episode reward: total was -26.500000. running mean: -18.879707\n",
      "ep 35: ep_len:189 episode reward: total was 18.500000. running mean: -18.505910\n",
      "ep 35: ep_len:293 episode reward: total was 29.000000. running mean: -18.030851\n",
      "ep 35: ep_len:845 episode reward: total was -12.770000. running mean: -17.978243\n",
      "ep 35: ep_len:680 episode reward: total was 0.300000. running mean: -17.795460\n",
      "ep 35: ep_len:500 episode reward: total was -21.600000. running mean: -17.833506\n",
      "ep 35: ep_len:520 episode reward: total was -16.180000. running mean: -17.816970\n",
      "ep 35: ep_len:735 episode reward: total was -57.630000. running mean: -18.215101\n",
      "ep 35: ep_len:770 episode reward: total was -9.620000. running mean: -18.129150\n",
      "ep 35: ep_len:920 episode reward: total was 16.210000. running mean: -17.785758\n",
      "ep 35: ep_len:500 episode reward: total was 50.000000. running mean: -17.107901\n",
      "ep 35: ep_len:1490 episode reward: total was -76.550000. running mean: -17.702322\n",
      "ep 35: ep_len:500 episode reward: total was 19.240000. running mean: -17.332898\n",
      "ep 35: ep_len:956 episode reward: total was -93.060000. running mean: -18.090169\n",
      "ep 35: ep_len:680 episode reward: total was -12.730000. running mean: -18.036568\n",
      "ep 35: ep_len:500 episode reward: total was -7.710000. running mean: -17.933302\n",
      "ep 35: ep_len:920 episode reward: total was -25.480000. running mean: -18.008769\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 35: ep_len:880 episode reward: total was -23.540000. running mean: -18.064081\n",
      "ep 35: ep_len:500 episode reward: total was -8.170000. running mean: -17.965141\n",
      "ep 35: ep_len:500 episode reward: total was -2.890000. running mean: -17.814389\n",
      "ep 35: ep_len:719 episode reward: total was -14.320000. running mean: -17.779445\n",
      "ep 35: ep_len:535 episode reward: total was 27.820000. running mean: -17.323451\n",
      "ep 35: ep_len:1005 episode reward: total was -10.570000. running mean: -17.255916\n",
      "ep 35: ep_len:299 episode reward: total was 29.500000. running mean: -16.788357\n",
      "ep 35: ep_len:660 episode reward: total was -1.930000. running mean: -16.639774\n",
      "ep 35: ep_len:1050 episode reward: total was -170.660000. running mean: -18.179976\n",
      "ep 35: ep_len:825 episode reward: total was -10.000000. running mean: -18.098176\n",
      "ep 35: ep_len:500 episode reward: total was -9.630000. running mean: -18.013494\n",
      "ep 35: ep_len:500 episode reward: total was 17.280000. running mean: -17.660559\n",
      "ep 35: ep_len:530 episode reward: total was 11.980000. running mean: -17.364154\n",
      "ep 35: ep_len:980 episode reward: total was -8.640000. running mean: -17.276912\n",
      "ep 35: ep_len:755 episode reward: total was -13.690000. running mean: -17.241043\n",
      "ep 35: ep_len:500 episode reward: total was 1.230000. running mean: -17.056333\n",
      "ep 35: ep_len:590 episode reward: total was -22.100000. running mean: -17.106769\n",
      "ep 35: ep_len:10 episode reward: total was -0.500000. running mean: -16.940702\n",
      "ep 35: ep_len:745 episode reward: total was 12.930000. running mean: -16.641995\n",
      "ep 35: ep_len:1259 episode reward: total was -198.510000. running mean: -18.460675\n",
      "ep 35: ep_len:775 episode reward: total was 5.850000. running mean: -18.217568\n",
      "ep 35: ep_len:500 episode reward: total was 2.360000. running mean: -18.011792\n",
      "ep 35: ep_len:610 episode reward: total was -18.020000. running mean: -18.011874\n",
      "ep 35: ep_len:500 episode reward: total was 27.380000. running mean: -17.557956\n",
      "ep 35: ep_len:575 episode reward: total was -18.090000. running mean: -17.563276\n",
      "ep 35: ep_len:660 episode reward: total was -27.010000. running mean: -17.657743\n",
      "ep 35: ep_len:720 episode reward: total was -2.650000. running mean: -17.507666\n",
      "ep 35: ep_len:500 episode reward: total was 26.800000. running mean: -17.064589\n",
      "ep 35: ep_len:251 episode reward: total was 25.000000. running mean: -16.643943\n",
      "ep 35: ep_len:500 episode reward: total was 20.520000. running mean: -16.272304\n",
      "ep 35: ep_len:810 episode reward: total was -80.210000. running mean: -16.911681\n",
      "ep 35: ep_len:650 episode reward: total was -6.830000. running mean: -16.810864\n",
      "ep 35: ep_len:500 episode reward: total was 17.340000. running mean: -16.469355\n",
      "ep 35: ep_len:715 episode reward: total was -19.830000. running mean: -16.502962\n",
      "ep 35: ep_len:550 episode reward: total was -2.680000. running mean: -16.364732\n",
      "ep 35: ep_len:770 episode reward: total was -8.110000. running mean: -16.282185\n",
      "ep 35: ep_len:235 episode reward: total was 22.000000. running mean: -15.899363\n",
      "ep 35: ep_len:500 episode reward: total was 5.490000. running mean: -15.685469\n",
      "ep 35: ep_len:945 episode reward: total was -46.640000. running mean: -15.995015\n",
      "ep 35: ep_len:525 episode reward: total was -31.320000. running mean: -16.148265\n",
      "ep 35: ep_len:530 episode reward: total was -8.080000. running mean: -16.067582\n",
      "ep 35: ep_len:630 episode reward: total was 8.870000. running mean: -15.818206\n",
      "ep 35: ep_len:525 episode reward: total was -5.060000. running mean: -15.710624\n",
      "ep 35: ep_len:500 episode reward: total was 8.760000. running mean: -15.465918\n",
      "ep 35: ep_len:570 episode reward: total was -28.900000. running mean: -15.600259\n",
      "ep 35: ep_len:500 episode reward: total was -2.110000. running mean: -15.465356\n",
      "ep 35: ep_len:500 episode reward: total was 13.270000. running mean: -15.178002\n",
      "ep 35: ep_len:500 episode reward: total was 26.800000. running mean: -14.758222\n",
      "ep 35: ep_len:197 episode reward: total was 16.500000. running mean: -14.445640\n",
      "ep 35: ep_len:500 episode reward: total was 2.310000. running mean: -14.278084\n",
      "ep 35: ep_len:1770 episode reward: total was -144.420000. running mean: -15.579503\n",
      "ep 35: ep_len:500 episode reward: total was 30.240000. running mean: -15.121308\n",
      "ep 35: ep_len:550 episode reward: total was -1.980000. running mean: -14.989895\n",
      "ep 35: ep_len:845 episode reward: total was -47.850000. running mean: -15.318496\n",
      "ep 35: ep_len:200 episode reward: total was 18.500000. running mean: -14.980311\n",
      "ep 35: ep_len:500 episode reward: total was 23.310000. running mean: -14.597408\n",
      "ep 35: ep_len:710 episode reward: total was -9.740000. running mean: -14.548834\n",
      "ep 35: ep_len:500 episode reward: total was -1.590000. running mean: -14.419245\n",
      "ep 35: ep_len:990 episode reward: total was 11.830000. running mean: -14.156753\n",
      "ep 35: ep_len:500 episode reward: total was 5.400000. running mean: -13.961185\n",
      "ep 35: ep_len:1240 episode reward: total was 8.580000. running mean: -13.735774\n",
      "ep 35: ep_len:760 episode reward: total was -11.010000. running mean: -13.708516\n",
      "ep 35: ep_len:710 episode reward: total was -5.700000. running mean: -13.628431\n",
      "ep 35: ep_len:500 episode reward: total was 24.810000. running mean: -13.244046\n",
      "ep 35: ep_len:500 episode reward: total was 20.580000. running mean: -12.905806\n",
      "ep 35: ep_len:950 episode reward: total was 28.290000. running mean: -12.493848\n",
      "ep 35: ep_len:500 episode reward: total was 4.810000. running mean: -12.320809\n",
      "ep 35: ep_len:715 episode reward: total was -76.390000. running mean: -12.961501\n",
      "ep 35: ep_len:500 episode reward: total was 30.780000. running mean: -12.524086\n",
      "ep 35: ep_len:500 episode reward: total was 3.960000. running mean: -12.359245\n",
      "ep 35: ep_len:855 episode reward: total was -56.400000. running mean: -12.799653\n",
      "ep 35: ep_len:625 episode reward: total was -4.860000. running mean: -12.720256\n",
      "ep 35: ep_len:500 episode reward: total was 21.870000. running mean: -12.374354\n",
      "ep 35: ep_len:1100 episode reward: total was 16.890000. running mean: -12.081710\n",
      "ep 35: ep_len:825 episode reward: total was -9.360000. running mean: -12.054493\n",
      "ep 35: ep_len:355 episode reward: total was 6.700000. running mean: -11.866948\n",
      "ep 35: ep_len:500 episode reward: total was 21.900000. running mean: -11.529279\n",
      "ep 35: ep_len:500 episode reward: total was 3.040000. running mean: -11.383586\n",
      "ep 35: ep_len:620 episode reward: total was 32.980000. running mean: -10.939950\n",
      "ep 35: ep_len:500 episode reward: total was -1.160000. running mean: -10.842151\n",
      "ep 35: ep_len:500 episode reward: total was 6.280000. running mean: -10.670929\n",
      "ep 35: ep_len:875 episode reward: total was -6.380000. running mean: -10.628020\n",
      "ep 35: ep_len:500 episode reward: total was 19.390000. running mean: -10.327840\n",
      "ep 35: ep_len:750 episode reward: total was 25.620000. running mean: -9.968361\n",
      "ep 35: ep_len:617 episode reward: total was -111.890000. running mean: -10.987578\n",
      "ep 35: ep_len:530 episode reward: total was -3.030000. running mean: -10.908002\n",
      "ep 35: ep_len:560 episode reward: total was -62.000000. running mean: -11.418922\n",
      "ep 35: ep_len:825 episode reward: total was 14.600000. running mean: -11.158733\n",
      "ep 35: ep_len:500 episode reward: total was -4.130000. running mean: -11.088445\n",
      "ep 35: ep_len:625 episode reward: total was -38.190000. running mean: -11.359461\n",
      "ep 35: ep_len:675 episode reward: total was 0.980000. running mean: -11.236066\n",
      "ep 35: ep_len:510 episode reward: total was -11.390000. running mean: -11.237606\n",
      "ep 35: ep_len:740 episode reward: total was -8.670000. running mean: -11.211930\n",
      "ep 35: ep_len:500 episode reward: total was 25.880000. running mean: -10.841010\n",
      "ep 35: ep_len:625 episode reward: total was -10.920000. running mean: -10.841800\n",
      "ep 35: ep_len:520 episode reward: total was -1.030000. running mean: -10.743682\n",
      "ep 35: ep_len:500 episode reward: total was 34.790000. running mean: -10.288345\n",
      "ep 35: ep_len:500 episode reward: total was -24.390000. running mean: -10.429362\n",
      "ep 35: ep_len:500 episode reward: total was -4.400000. running mean: -10.369068\n",
      "ep 35: ep_len:284 episode reward: total was -14.000000. running mean: -10.405378\n",
      "ep 35: ep_len:1790 episode reward: total was -52.890000. running mean: -10.830224\n",
      "ep 35: ep_len:1010 episode reward: total was -57.620000. running mean: -11.298122\n",
      "ep 35: ep_len:500 episode reward: total was 18.040000. running mean: -11.004740\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 35: ep_len:1020 episode reward: total was -106.080000. running mean: -11.955493\n",
      "ep 35: ep_len:675 episode reward: total was -3.230000. running mean: -11.868238\n",
      "ep 35: ep_len:500 episode reward: total was -5.690000. running mean: -11.806456\n",
      "ep 35: ep_len:451 episode reward: total was -9.220000. running mean: -11.780591\n",
      "ep 35: ep_len:620 episode reward: total was -20.020000. running mean: -11.862985\n",
      "ep 35: ep_len:835 episode reward: total was 15.050000. running mean: -11.593855\n",
      "ep 35: ep_len:500 episode reward: total was -17.900000. running mean: -11.656917\n",
      "ep 35: ep_len:560 episode reward: total was -12.060000. running mean: -11.660948\n",
      "ep 35: ep_len:525 episode reward: total was -10.110000. running mean: -11.645438\n",
      "ep 35: ep_len:500 episode reward: total was 19.420000. running mean: -11.334784\n",
      "ep 35: ep_len:745 episode reward: total was 9.360000. running mean: -11.127836\n",
      "ep 35: ep_len:500 episode reward: total was -0.700000. running mean: -11.023558\n",
      "ep 35: ep_len:895 episode reward: total was -9.080000. running mean: -11.004122\n",
      "ep 35: ep_len:845 episode reward: total was -40.530000. running mean: -11.299381\n",
      "ep 35: ep_len:1174 episode reward: total was -140.100000. running mean: -12.587387\n",
      "ep 35: ep_len:500 episode reward: total was 12.200000. running mean: -12.339513\n",
      "ep 35: ep_len:500 episode reward: total was 9.560000. running mean: -12.120518\n",
      "ep 35: ep_len:318 episode reward: total was 31.500000. running mean: -11.684313\n",
      "ep 35: ep_len:401 episode reward: total was 9.280000. running mean: -11.474670\n",
      "ep 35: ep_len:116 episode reward: total was 9.000000. running mean: -11.269923\n",
      "ep 35: ep_len:500 episode reward: total was 23.770000. running mean: -10.919524\n",
      "ep 35: ep_len:830 episode reward: total was -16.570000. running mean: -10.976028\n",
      "ep 35: ep_len:500 episode reward: total was 3.770000. running mean: -10.828568\n",
      "ep 35: ep_len:500 episode reward: total was -6.640000. running mean: -10.786683\n",
      "ep 35: ep_len:890 episode reward: total was 21.660000. running mean: -10.462216\n",
      "ep 35: ep_len:165 episode reward: total was 13.500000. running mean: -10.222594\n",
      "ep 35: ep_len:1940 episode reward: total was -334.700000. running mean: -13.467368\n",
      "ep 35: ep_len:219 episode reward: total was 21.500000. running mean: -13.117694\n",
      "ep 35: ep_len:610 episode reward: total was 9.570000. running mean: -12.890817\n",
      "ep 35: ep_len:500 episode reward: total was -4.370000. running mean: -12.805609\n",
      "ep 35: ep_len:500 episode reward: total was 6.770000. running mean: -12.609853\n",
      "ep 35: ep_len:129 episode reward: total was 12.500000. running mean: -12.358754\n",
      "ep 35: ep_len:1148 episode reward: total was -186.610000. running mean: -14.101267\n",
      "ep 35: ep_len:500 episode reward: total was -8.770000. running mean: -14.047954\n",
      "ep 35: ep_len:66 episode reward: total was 5.000000. running mean: -13.857474\n",
      "ep 35: ep_len:500 episode reward: total was 5.240000. running mean: -13.666500\n",
      "ep 35: ep_len:800 episode reward: total was -11.580000. running mean: -13.645635\n",
      "ep 35: ep_len:500 episode reward: total was 19.790000. running mean: -13.311278\n",
      "ep 35: ep_len:500 episode reward: total was 21.320000. running mean: -12.964966\n",
      "ep 35: ep_len:160 episode reward: total was 14.500000. running mean: -12.690316\n",
      "ep 35: ep_len:580 episode reward: total was 23.590000. running mean: -12.327513\n",
      "ep 35: ep_len:655 episode reward: total was 1.260000. running mean: -12.191638\n",
      "ep 35: ep_len:475 episode reward: total was 46.000000. running mean: -11.609721\n",
      "ep 35: ep_len:810 episode reward: total was -14.590000. running mean: -11.639524\n",
      "ep 35: ep_len:500 episode reward: total was 18.070000. running mean: -11.342429\n",
      "ep 35: ep_len:500 episode reward: total was 25.760000. running mean: -10.971405\n",
      "ep 35: ep_len:555 episode reward: total was -21.160000. running mean: -11.073290\n",
      "ep 35: ep_len:500 episode reward: total was 23.310000. running mean: -10.729458\n",
      "ep 35: ep_len:500 episode reward: total was -1.850000. running mean: -10.640663\n",
      "ep 35: ep_len:213 episode reward: total was 21.000000. running mean: -10.324256\n",
      "ep 35: ep_len:500 episode reward: total was -1.060000. running mean: -10.231614\n",
      "ep 35: ep_len:1010 episode reward: total was -119.230000. running mean: -11.321598\n",
      "ep 35: ep_len:148 episode reward: total was 14.500000. running mean: -11.063382\n",
      "ep 35: ep_len:500 episode reward: total was 13.630000. running mean: -10.816448\n",
      "ep 35: ep_len:1435 episode reward: total was -256.750000. running mean: -13.275783\n",
      "ep 35: ep_len:800 episode reward: total was -55.730000. running mean: -13.700326\n",
      "ep 35: ep_len:795 episode reward: total was -3.630000. running mean: -13.599622\n",
      "ep 35: ep_len:840 episode reward: total was 16.190000. running mean: -13.301726\n",
      "ep 35: ep_len:720 episode reward: total was -20.830000. running mean: -13.377009\n",
      "ep 35: ep_len:500 episode reward: total was 10.660000. running mean: -13.136639\n",
      "ep 35: ep_len:190 episode reward: total was 16.000000. running mean: -12.845272\n",
      "ep 35: ep_len:500 episode reward: total was 20.860000. running mean: -12.508220\n",
      "ep 35: ep_len:645 episode reward: total was 5.870000. running mean: -12.324437\n",
      "ep 35: ep_len:500 episode reward: total was -3.210000. running mean: -12.233293\n",
      "ep 35: ep_len:875 episode reward: total was 27.130000. running mean: -11.839660\n",
      "ep 35: ep_len:500 episode reward: total was 25.210000. running mean: -11.469164\n",
      "ep 35: ep_len:700 episode reward: total was -1.740000. running mean: -11.371872\n",
      "ep 35: ep_len:555 episode reward: total was -22.140000. running mean: -11.479553\n",
      "ep 35: ep_len:705 episode reward: total was -11.640000. running mean: -11.481158\n",
      "ep 35: ep_len:800 episode reward: total was 26.550000. running mean: -11.100846\n",
      "ep 35: ep_len:2388 episode reward: total was -320.480000. running mean: -14.194638\n",
      "ep 35: ep_len:510 episode reward: total was -16.200000. running mean: -14.214691\n",
      "ep 35: ep_len:195 episode reward: total was 18.000000. running mean: -13.892544\n",
      "ep 35: ep_len:1115 episode reward: total was -117.760000. running mean: -14.931219\n",
      "ep 35: ep_len:330 episode reward: total was 12.800000. running mean: -14.653907\n",
      "ep 35: ep_len:555 episode reward: total was -96.880000. running mean: -15.476168\n",
      "ep 35: ep_len:660 episode reward: total was 13.190000. running mean: -15.189506\n",
      "ep 35: ep_len:1920 episode reward: total was -303.250000. running mean: -18.070111\n",
      "ep 35: ep_len:204 episode reward: total was 18.500000. running mean: -17.704410\n",
      "ep 35: ep_len:875 episode reward: total was 14.090000. running mean: -17.386466\n",
      "ep 35: ep_len:500 episode reward: total was 24.320000. running mean: -16.969401\n",
      "ep 35: ep_len:500 episode reward: total was 48.500000. running mean: -16.314707\n",
      "ep 35: ep_len:785 episode reward: total was 19.480000. running mean: -15.956760\n",
      "ep 35: ep_len:885 episode reward: total was 13.420000. running mean: -15.662992\n",
      "ep 35: ep_len:182 episode reward: total was 16.500000. running mean: -15.341362\n",
      "ep 35: ep_len:860 episode reward: total was 10.080000. running mean: -15.087149\n",
      "ep 35: ep_len:500 episode reward: total was -30.130000. running mean: -15.237577\n",
      "ep 35: ep_len:1030 episode reward: total was 6.520000. running mean: -15.020002\n",
      "ep 35: ep_len:660 episode reward: total was -30.040000. running mean: -15.170201\n",
      "ep 35: ep_len:500 episode reward: total was -2.870000. running mean: -15.047199\n",
      "ep 35: ep_len:495 episode reward: total was -64.710000. running mean: -15.543827\n",
      "ep 35: ep_len:520 episode reward: total was -8.100000. running mean: -15.469389\n",
      "ep 35: ep_len:289 episode reward: total was 28.500000. running mean: -15.029695\n",
      "ep 35: ep_len:580 episode reward: total was -12.020000. running mean: -14.999598\n",
      "ep 35: ep_len:730 episode reward: total was -1.280000. running mean: -14.862402\n",
      "ep 35: ep_len:500 episode reward: total was 6.590000. running mean: -14.647878\n",
      "ep 35: ep_len:835 episode reward: total was -9.490000. running mean: -14.596300\n",
      "ep 35: ep_len:740 episode reward: total was 34.360000. running mean: -14.106737\n",
      "ep 35: ep_len:765 episode reward: total was -3.630000. running mean: -14.001969\n",
      "ep 35: ep_len:865 episode reward: total was 12.540000. running mean: -13.736550\n",
      "ep 35: ep_len:560 episode reward: total was 6.920000. running mean: -13.529984\n",
      "ep 35: ep_len:595 episode reward: total was 21.170000. running mean: -13.182984\n",
      "ep 35: ep_len:690 episode reward: total was -12.790000. running mean: -13.179054\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 35: ep_len:1571 episode reward: total was -228.590000. running mean: -15.333164\n",
      "ep 35: ep_len:500 episode reward: total was 2.320000. running mean: -15.156632\n",
      "ep 35: ep_len:2801 episode reward: total was -380.430000. running mean: -18.809366\n",
      "ep 35: ep_len:500 episode reward: total was -17.190000. running mean: -18.793172\n",
      "ep 35: ep_len:731 episode reward: total was -110.250000. running mean: -19.707740\n",
      "ep 35: ep_len:500 episode reward: total was -15.940000. running mean: -19.670063\n",
      "ep 35: ep_len:1265 episode reward: total was -91.450000. running mean: -20.387862\n",
      "ep 35: ep_len:387 episode reward: total was 38.500000. running mean: -19.798984\n",
      "ep 35: ep_len:535 episode reward: total was 21.700000. running mean: -19.383994\n",
      "ep 35: ep_len:560 episode reward: total was -27.210000. running mean: -19.462254\n",
      "ep 35: ep_len:500 episode reward: total was 20.280000. running mean: -19.064831\n",
      "ep 35: ep_len:1060 episode reward: total was 5.760000. running mean: -18.816583\n",
      "ep 35: ep_len:500 episode reward: total was -2.340000. running mean: -18.651817\n",
      "ep 35: ep_len:500 episode reward: total was -24.880000. running mean: -18.714099\n",
      "ep 35: ep_len:500 episode reward: total was 21.750000. running mean: -18.309458\n",
      "ep 35: ep_len:500 episode reward: total was 21.380000. running mean: -17.912564\n",
      "ep 35: ep_len:500 episode reward: total was 20.310000. running mean: -17.530338\n",
      "ep 35: ep_len:835 episode reward: total was -28.680000. running mean: -17.641835\n",
      "ep 35: ep_len:500 episode reward: total was 21.210000. running mean: -17.253316\n",
      "ep 35: ep_len:500 episode reward: total was 10.940000. running mean: -16.971383\n",
      "ep 35: ep_len:735 episode reward: total was -13.730000. running mean: -16.938969\n",
      "ep 35: ep_len:710 episode reward: total was 10.890000. running mean: -16.660680\n",
      "ep 35: ep_len:665 episode reward: total was -2.660000. running mean: -16.520673\n",
      "ep 35: ep_len:500 episode reward: total was 23.800000. running mean: -16.117466\n",
      "ep 35: ep_len:695 episode reward: total was -26.940000. running mean: -16.225691\n",
      "ep 35: ep_len:895 episode reward: total was -52.800000. running mean: -16.591434\n",
      "ep 35: ep_len:500 episode reward: total was 2.490000. running mean: -16.400620\n",
      "ep 35: ep_len:532 episode reward: total was -15.780000. running mean: -16.394414\n",
      "ep 35: ep_len:840 episode reward: total was -3.580000. running mean: -16.266270\n",
      "ep 35: ep_len:1980 episode reward: total was -311.810000. running mean: -19.221707\n",
      "ep 35: ep_len:540 episode reward: total was -27.250000. running mean: -19.301990\n",
      "ep 35: ep_len:227 episode reward: total was 3.160000. running mean: -19.077370\n",
      "ep 35: ep_len:530 episode reward: total was -13.130000. running mean: -19.017896\n",
      "ep 35: ep_len:500 episode reward: total was -27.200000. running mean: -19.099717\n",
      "ep 35: ep_len:510 episode reward: total was 4.930000. running mean: -18.859420\n",
      "ep 35: ep_len:500 episode reward: total was 17.830000. running mean: -18.492526\n",
      "ep 35: ep_len:665 episode reward: total was -12.860000. running mean: -18.436201\n",
      "ep 35: ep_len:880 episode reward: total was 2.500000. running mean: -18.226839\n",
      "ep 35: ep_len:500 episode reward: total was 11.800000. running mean: -17.926570\n",
      "ep 35: ep_len:500 episode reward: total was 19.210000. running mean: -17.555205\n",
      "ep 35: ep_len:500 episode reward: total was -2.690000. running mean: -17.406553\n",
      "ep 35: ep_len:780 episode reward: total was -14.340000. running mean: -17.375887\n",
      "ep 35: ep_len:224 episode reward: total was 22.000000. running mean: -16.982128\n",
      "ep 35: ep_len:540 episode reward: total was -26.240000. running mean: -17.074707\n",
      "ep 35: ep_len:515 episode reward: total was -19.220000. running mean: -17.096160\n",
      "ep 35: ep_len:155 episode reward: total was 14.000000. running mean: -16.785198\n",
      "ep 35: ep_len:500 episode reward: total was 13.760000. running mean: -16.479746\n",
      "ep 35: ep_len:500 episode reward: total was 15.720000. running mean: -16.157749\n",
      "ep 35: ep_len:183 episode reward: total was 18.000000. running mean: -15.816171\n",
      "ep 35: ep_len:2254 episode reward: total was -361.170000. running mean: -19.269710\n",
      "ep 35: ep_len:500 episode reward: total was 9.230000. running mean: -18.984713\n",
      "ep 35: ep_len:695 episode reward: total was -8.760000. running mean: -18.882465\n",
      "ep 35: ep_len:500 episode reward: total was -15.050000. running mean: -18.844141\n",
      "ep 35: ep_len:500 episode reward: total was 15.690000. running mean: -18.498799\n",
      "ep 35: ep_len:500 episode reward: total was 45.500000. running mean: -17.858811\n",
      "ep 35: ep_len:500 episode reward: total was -66.720000. running mean: -18.347423\n",
      "ep 35: ep_len:755 episode reward: total was -13.170000. running mean: -18.295649\n",
      "ep 35: ep_len:441 episode reward: total was 44.000000. running mean: -17.672693\n",
      "ep 35: ep_len:170 episode reward: total was 15.500000. running mean: -17.340966\n",
      "ep 35: ep_len:900 episode reward: total was -4.230000. running mean: -17.209856\n",
      "ep 35: ep_len:500 episode reward: total was 15.840000. running mean: -16.879357\n",
      "ep 35: ep_len:500 episode reward: total was 8.210000. running mean: -16.628464\n",
      "ep 35: ep_len:165 episode reward: total was 15.000000. running mean: -16.312179\n",
      "ep 35: ep_len:615 episode reward: total was -32.150000. running mean: -16.470557\n",
      "ep 35: ep_len:177 episode reward: total was 17.500000. running mean: -16.130852\n",
      "ep 35: ep_len:710 episode reward: total was -13.780000. running mean: -16.107343\n",
      "ep 35: ep_len:287 episode reward: total was 28.500000. running mean: -15.661270\n",
      "ep 35: ep_len:500 episode reward: total was -6.210000. running mean: -15.566757\n",
      "ep 35: ep_len:790 episode reward: total was 2.190000. running mean: -15.389190\n",
      "ep 35: ep_len:500 episode reward: total was 12.410000. running mean: -15.111198\n",
      "ep 35: ep_len:740 episode reward: total was -11.700000. running mean: -15.077086\n",
      "ep 35: ep_len:6135 episode reward: total was -1041.730000. running mean: -25.343615\n",
      "ep 35: ep_len:595 episode reward: total was -8.800000. running mean: -25.178179\n",
      "ep 35: ep_len:750 episode reward: total was 4.210000. running mean: -24.884297\n",
      "ep 35: ep_len:500 episode reward: total was 14.250000. running mean: -24.492954\n",
      "ep 35: ep_len:500 episode reward: total was 1.400000. running mean: -24.234024\n",
      "ep 35: ep_len:500 episode reward: total was -10.160000. running mean: -24.093284\n",
      "ep 35: ep_len:605 episode reward: total was -2.940000. running mean: -23.881751\n",
      "ep 35: ep_len:625 episode reward: total was -14.960000. running mean: -23.792534\n",
      "ep 35: ep_len:242 episode reward: total was 22.500000. running mean: -23.329608\n",
      "ep 35: ep_len:840 episode reward: total was -47.860000. running mean: -23.574912\n",
      "ep 35: ep_len:1795 episode reward: total was -297.440000. running mean: -26.313563\n",
      "ep 35: ep_len:176 episode reward: total was 17.500000. running mean: -25.875428\n",
      "ep 35: ep_len:720 episode reward: total was -2.650000. running mean: -25.643173\n",
      "ep 35: ep_len:500 episode reward: total was 9.740000. running mean: -25.289342\n",
      "ep 35: ep_len:232 episode reward: total was 23.000000. running mean: -24.806448\n",
      "ep 35: ep_len:500 episode reward: total was 24.760000. running mean: -24.310784\n",
      "ep 35: ep_len:413 episode reward: total was 41.000000. running mean: -23.657676\n",
      "ep 35: ep_len:500 episode reward: total was 10.790000. running mean: -23.313199\n",
      "ep 35: ep_len:695 episode reward: total was 21.740000. running mean: -22.862667\n",
      "ep 35: ep_len:500 episode reward: total was 18.440000. running mean: -22.449640\n",
      "ep 35: ep_len:550 episode reward: total was -9.050000. running mean: -22.315644\n",
      "ep 35: ep_len:500 episode reward: total was -2.930000. running mean: -22.121788\n",
      "ep 35: ep_len:715 episode reward: total was 15.690000. running mean: -21.743670\n",
      "ep 35: ep_len:2240 episode reward: total was -261.950000. running mean: -24.145733\n",
      "ep 35: ep_len:730 episode reward: total was -33.810000. running mean: -24.242376\n",
      "ep 35: ep_len:715 episode reward: total was -13.250000. running mean: -24.132452\n",
      "ep 35: ep_len:482 episode reward: total was 31.260000. running mean: -23.578527\n",
      "ep 35: ep_len:1180 episode reward: total was -110.810000. running mean: -24.450842\n",
      "ep 35: ep_len:500 episode reward: total was 21.260000. running mean: -23.993734\n",
      "ep 35: ep_len:500 episode reward: total was 1.300000. running mean: -23.740796\n",
      "ep 35: ep_len:972 episode reward: total was -113.230000. running mean: -24.635688\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 35: ep_len:760 episode reward: total was -15.700000. running mean: -24.546332\n",
      "ep 35: ep_len:690 episode reward: total was -82.000000. running mean: -25.120868\n",
      "ep 35: ep_len:500 episode reward: total was 26.780000. running mean: -24.601860\n",
      "ep 35: ep_len:500 episode reward: total was -55.360000. running mean: -24.909441\n",
      "ep 35: ep_len:500 episode reward: total was -4.670000. running mean: -24.707047\n",
      "ep 35: ep_len:800 episode reward: total was 9.960000. running mean: -24.360376\n",
      "ep 35: ep_len:500 episode reward: total was -49.670000. running mean: -24.613472\n",
      "ep 35: ep_len:36 episode reward: total was 3.500000. running mean: -24.332338\n",
      "ep 35: ep_len:500 episode reward: total was 7.760000. running mean: -24.011414\n",
      "ep 35: ep_len:685 episode reward: total was 5.370000. running mean: -23.717600\n",
      "ep 35: ep_len:575 episode reward: total was -12.520000. running mean: -23.605624\n",
      "ep 35: ep_len:500 episode reward: total was 2.340000. running mean: -23.346168\n",
      "ep 35: ep_len:234 episode reward: total was 23.500000. running mean: -22.877706\n",
      "ep 35: ep_len:555 episode reward: total was 2.910000. running mean: -22.619829\n",
      "ep 35: ep_len:500 episode reward: total was -14.780000. running mean: -22.541431\n",
      "ep 35: ep_len:645 episode reward: total was -30.070000. running mean: -22.616717\n",
      "ep 35: ep_len:760 episode reward: total was -14.690000. running mean: -22.537449\n",
      "ep 35: ep_len:525 episode reward: total was -4.050000. running mean: -22.352575\n",
      "ep 35: ep_len:183 episode reward: total was 12.000000. running mean: -22.009049\n",
      "ep 35: ep_len:790 episode reward: total was -4.050000. running mean: -21.829459\n",
      "ep 35: ep_len:660 episode reward: total was -89.500000. running mean: -22.506164\n",
      "ep 35: ep_len:244 episode reward: total was 22.500000. running mean: -22.056102\n",
      "ep 35: ep_len:500 episode reward: total was 19.850000. running mean: -21.637041\n",
      "ep 35: ep_len:605 episode reward: total was 2.800000. running mean: -21.392671\n",
      "ep 35: ep_len:500 episode reward: total was 29.710000. running mean: -20.881644\n",
      "ep 35: ep_len:755 episode reward: total was -12.680000. running mean: -20.799628\n",
      "ep 35: ep_len:500 episode reward: total was 10.850000. running mean: -20.483132\n",
      "ep 35: ep_len:560 episode reward: total was 0.950000. running mean: -20.268800\n",
      "ep 35: ep_len:290 episode reward: total was 26.000000. running mean: -19.806112\n",
      "ep 35: ep_len:725 episode reward: total was 9.800000. running mean: -19.510051\n",
      "ep 35: ep_len:860 episode reward: total was -0.590000. running mean: -19.320851\n",
      "ep 35: ep_len:1065 episode reward: total was -111.370000. running mean: -20.241342\n",
      "ep 35: ep_len:690 episode reward: total was -26.950000. running mean: -20.308429\n",
      "ep 35: ep_len:500 episode reward: total was 14.550000. running mean: -19.959844\n",
      "ep 35: ep_len:630 episode reward: total was -4.530000. running mean: -19.805546\n",
      "ep 35: ep_len:690 episode reward: total was -8.250000. running mean: -19.689990\n",
      "ep 35: ep_len:143 episode reward: total was 14.000000. running mean: -19.353091\n",
      "ep 35: ep_len:505 episode reward: total was 8.780000. running mean: -19.071760\n",
      "ep 35: ep_len:730 episode reward: total was -6.670000. running mean: -18.947742\n",
      "ep 35: ep_len:500 episode reward: total was 30.780000. running mean: -18.450465\n",
      "ep 35: ep_len:374 episode reward: total was 37.000000. running mean: -17.895960\n",
      "ep 35: ep_len:695 episode reward: total was -8.760000. running mean: -17.804600\n",
      "ep 35: ep_len:500 episode reward: total was -7.980000. running mean: -17.706354\n",
      "ep 35: ep_len:500 episode reward: total was 20.280000. running mean: -17.326491\n",
      "ep 35: ep_len:500 episode reward: total was 25.360000. running mean: -16.899626\n",
      "ep 35: ep_len:500 episode reward: total was 29.750000. running mean: -16.433130\n",
      "ep 35: ep_len:500 episode reward: total was 24.290000. running mean: -16.025898\n",
      "ep 35: ep_len:500 episode reward: total was 29.770000. running mean: -15.567939\n",
      "ep 35: ep_len:445 episode reward: total was 22.860000. running mean: -15.183660\n",
      "ep 35: ep_len:500 episode reward: total was -54.660000. running mean: -15.578423\n",
      "ep 35: ep_len:535 episode reward: total was -24.230000. running mean: -15.664939\n",
      "ep 35: ep_len:500 episode reward: total was 26.280000. running mean: -15.245490\n",
      "ep 35: ep_len:500 episode reward: total was -1.220000. running mean: -15.105235\n",
      "ep 35: ep_len:715 episode reward: total was -38.010000. running mean: -15.334283\n",
      "ep 35: ep_len:2735 episode reward: total was -434.990000. running mean: -19.530840\n",
      "ep 35: ep_len:500 episode reward: total was -4.280000. running mean: -19.378331\n",
      "ep 35: ep_len:5517 episode reward: total was -919.530000. running mean: -28.379848\n",
      "ep 35: ep_len:910 episode reward: total was -58.810000. running mean: -28.684150\n",
      "ep 35: ep_len:640 episode reward: total was 4.790000. running mean: -28.349408\n",
      "ep 35: ep_len:1260 episode reward: total was -67.220000. running mean: -28.738114\n",
      "ep 35: ep_len:720 episode reward: total was -62.240000. running mean: -29.073133\n",
      "ep 35: ep_len:500 episode reward: total was 48.500000. running mean: -28.297401\n",
      "ep 35: ep_len:500 episode reward: total was 20.950000. running mean: -27.804927\n",
      "epsilon:0.010000 episode_count: 28398. steps_count: 20639023.000000\n",
      "ep 36: ep_len:1885 episode reward: total was -224.540000. running mean: -29.772278\n",
      "ep 36: ep_len:815 episode reward: total was -15.590000. running mean: -29.630455\n",
      "ep 36: ep_len:680 episode reward: total was -36.060000. running mean: -29.694751\n",
      "ep 36: ep_len:540 episode reward: total was -19.170000. running mean: -29.589503\n",
      "ep 36: ep_len:500 episode reward: total was 5.790000. running mean: -29.235708\n",
      "ep 36: ep_len:625 episode reward: total was -20.980000. running mean: -29.153151\n",
      "ep 36: ep_len:500 episode reward: total was -0.450000. running mean: -28.866120\n",
      "ep 36: ep_len:500 episode reward: total was 11.280000. running mean: -28.464659\n",
      "ep 36: ep_len:431 episode reward: total was 43.000000. running mean: -27.750012\n",
      "ep 36: ep_len:1040 episode reward: total was 9.310000. running mean: -27.379412\n",
      "ep 36: ep_len:565 episode reward: total was -10.030000. running mean: -27.205918\n",
      "ep 36: ep_len:500 episode reward: total was 17.350000. running mean: -26.760359\n",
      "ep 36: ep_len:500 episode reward: total was -6.670000. running mean: -26.559455\n",
      "ep 36: ep_len:211 episode reward: total was 0.000000. running mean: -26.293860\n",
      "ep 36: ep_len:1270 episode reward: total was 2.330000. running mean: -26.007622\n",
      "ep 36: ep_len:810 episode reward: total was -34.790000. running mean: -26.095446\n",
      "ep 36: ep_len:426 episode reward: total was 42.500000. running mean: -25.409491\n",
      "ep 36: ep_len:500 episode reward: total was 2.890000. running mean: -25.126496\n",
      "ep 36: ep_len:500 episode reward: total was 10.270000. running mean: -24.772531\n",
      "ep 36: ep_len:705 episode reward: total was -3.130000. running mean: -24.556106\n",
      "ep 36: ep_len:705 episode reward: total was -38.030000. running mean: -24.690845\n",
      "ep 36: ep_len:2278 episode reward: total was -175.390000. running mean: -26.197836\n",
      "ep 36: ep_len:995 episode reward: total was -56.640000. running mean: -26.502258\n",
      "ep 36: ep_len:1595 episode reward: total was -69.660000. running mean: -26.933835\n",
      "ep 36: ep_len:487 episode reward: total was 23.860000. running mean: -26.425897\n",
      "ep 36: ep_len:183 episode reward: total was 4.500000. running mean: -26.116638\n",
      "ep 36: ep_len:545 episode reward: total was -3.810000. running mean: -25.893572\n",
      "ep 36: ep_len:500 episode reward: total was 27.350000. running mean: -25.361136\n",
      "ep 36: ep_len:15593 episode reward: total was -2849.330000. running mean: -53.600825\n",
      "ep 36: ep_len:755 episode reward: total was -0.250000. running mean: -53.067316\n",
      "ep 36: ep_len:520 episode reward: total was -7.090000. running mean: -52.607543\n",
      "ep 36: ep_len:500 episode reward: total was 18.750000. running mean: -51.893968\n",
      "ep 36: ep_len:251 episode reward: total was 5.500000. running mean: -51.320028\n",
      "ep 36: ep_len:500 episode reward: total was 16.180000. running mean: -50.645028\n",
      "ep 36: ep_len:500 episode reward: total was 20.620000. running mean: -49.932378\n",
      "ep 36: ep_len:505 episode reward: total was -4.090000. running mean: -49.473954\n",
      "ep 36: ep_len:500 episode reward: total was -0.470000. running mean: -48.983914\n",
      "ep 36: ep_len:970 episode reward: total was 8.670000. running mean: -48.407375\n",
      "ep 36: ep_len:570 episode reward: total was -51.400000. running mean: -48.437301\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 36: ep_len:500 episode reward: total was -6.750000. running mean: -48.020428\n",
      "ep 36: ep_len:670 episode reward: total was 16.580000. running mean: -47.374424\n",
      "ep 36: ep_len:500 episode reward: total was -3.710000. running mean: -46.937780\n",
      "ep 36: ep_len:500 episode reward: total was -4.710000. running mean: -46.515502\n",
      "ep 36: ep_len:755 episode reward: total was 0.740000. running mean: -46.042947\n",
      "ep 36: ep_len:565 episode reward: total was 21.310000. running mean: -45.369418\n",
      "ep 36: ep_len:630 episode reward: total was 1.210000. running mean: -44.903623\n",
      "ep 36: ep_len:164 episode reward: total was 16.000000. running mean: -44.294587\n",
      "ep 36: ep_len:20964 episode reward: total was -3902.350000. running mean: -82.875141\n",
      "ep 36: ep_len:760 episode reward: total was -15.700000. running mean: -82.203390\n",
      "ep 36: ep_len:1205 episode reward: total was -16.750000. running mean: -81.548856\n",
      "ep 36: ep_len:500 episode reward: total was -3.290000. running mean: -80.766267\n",
      "ep 36: ep_len:835 episode reward: total was -48.080000. running mean: -80.439405\n",
      "ep 36: ep_len:500 episode reward: total was 17.500000. running mean: -79.460011\n",
      "ep 36: ep_len:500 episode reward: total was -85.500000. running mean: -79.520411\n",
      "ep 36: ep_len:795 episode reward: total was -25.540000. running mean: -78.980606\n",
      "ep 36: ep_len:790 episode reward: total was -66.640000. running mean: -78.857200\n",
      "ep 36: ep_len:725 episode reward: total was -20.820000. running mean: -78.276828\n",
      "ep 36: ep_len:500 episode reward: total was -15.570000. running mean: -77.649760\n",
      "ep 36: ep_len:364 episode reward: total was 34.500000. running mean: -76.528263\n",
      "ep 36: ep_len:500 episode reward: total was -9.650000. running mean: -75.859480\n",
      "ep 36: ep_len:500 episode reward: total was 14.740000. running mean: -74.953485\n",
      "ep 36: ep_len:540 episode reward: total was -18.160000. running mean: -74.385550\n",
      "ep 36: ep_len:880 episode reward: total was -53.510000. running mean: -74.176795\n",
      "ep 36: ep_len:474 episode reward: total was 10.620000. running mean: -73.328827\n",
      "ep 36: ep_len:1205 episode reward: total was -139.830000. running mean: -73.993839\n",
      "ep 36: ep_len:595 episode reward: total was -28.150000. running mean: -73.535400\n",
      "ep 36: ep_len:500 episode reward: total was 13.760000. running mean: -72.662446\n",
      "ep 36: ep_len:600 episode reward: total was -2.890000. running mean: -71.964722\n",
      "ep 36: ep_len:920 episode reward: total was 4.590000. running mean: -71.199174\n",
      "ep 36: ep_len:129 episode reward: total was 11.000000. running mean: -70.377183\n",
      "ep 36: ep_len:900 episode reward: total was -6.480000. running mean: -69.738211\n",
      "ep 36: ep_len:710 episode reward: total was -19.840000. running mean: -69.239229\n",
      "ep 36: ep_len:1111 episode reward: total was -152.340000. running mean: -70.070236\n",
      "ep 36: ep_len:500 episode reward: total was 6.240000. running mean: -69.307134\n",
      "ep 36: ep_len:500 episode reward: total was -7.500000. running mean: -68.689063\n",
      "ep 36: ep_len:890 episode reward: total was -9.690000. running mean: -68.099072\n",
      "ep 36: ep_len:1970 episode reward: total was -249.370000. running mean: -69.911781\n",
      "ep 36: ep_len:645 episode reward: total was -6.840000. running mean: -69.281064\n",
      "ep 36: ep_len:685 episode reward: total was -7.770000. running mean: -68.665953\n",
      "ep 36: ep_len:500 episode reward: total was 15.690000. running mean: -67.822393\n",
      "ep 36: ep_len:665 episode reward: total was -2.760000. running mean: -67.171770\n",
      "ep 36: ep_len:80 episode reward: total was 6.500000. running mean: -66.435052\n",
      "ep 36: ep_len:505 episode reward: total was -12.170000. running mean: -65.892401\n",
      "ep 36: ep_len:500 episode reward: total was -30.000000. running mean: -65.533477\n",
      "ep 36: ep_len:850 episode reward: total was 14.430000. running mean: -64.733843\n",
      "ep 36: ep_len:500 episode reward: total was -12.510000. running mean: -64.211604\n",
      "ep 36: ep_len:605 episode reward: total was 26.220000. running mean: -63.307288\n",
      "ep 36: ep_len:845 episode reward: total was 13.710000. running mean: -62.537115\n",
      "ep 36: ep_len:680 episode reward: total was -3.050000. running mean: -61.942244\n",
      "ep 36: ep_len:500 episode reward: total was 23.740000. running mean: -61.085422\n",
      "ep 36: ep_len:775 episode reward: total was -34.830000. running mean: -60.822867\n",
      "ep 36: ep_len:515 episode reward: total was 4.330000. running mean: -60.171339\n",
      "ep 36: ep_len:500 episode reward: total was 18.200000. running mean: -59.387625\n",
      "ep 36: ep_len:590 episode reward: total was -72.930000. running mean: -59.523049\n",
      "ep 36: ep_len:138 episode reward: total was 13.500000. running mean: -58.792819\n",
      "ep 36: ep_len:500 episode reward: total was -0.210000. running mean: -58.206990\n",
      "ep 36: ep_len:500 episode reward: total was -8.750000. running mean: -57.712420\n",
      "ep 36: ep_len:500 episode reward: total was 26.280000. running mean: -56.872496\n",
      "ep 36: ep_len:700 episode reward: total was -11.780000. running mean: -56.421571\n",
      "ep 36: ep_len:500 episode reward: total was -17.260000. running mean: -56.029956\n",
      "ep 36: ep_len:695 episode reward: total was -56.230000. running mean: -56.031956\n",
      "ep 36: ep_len:1265 episode reward: total was -251.500000. running mean: -57.986636\n",
      "ep 36: ep_len:500 episode reward: total was -35.990000. running mean: -57.766670\n",
      "ep 36: ep_len:810 episode reward: total was -65.040000. running mean: -57.839403\n",
      "ep 36: ep_len:670 episode reward: total was -17.040000. running mean: -57.431409\n",
      "ep 36: ep_len:750 episode reward: total was -17.670000. running mean: -57.033795\n",
      "ep 36: ep_len:258 episode reward: total was 12.000000. running mean: -56.343457\n",
      "ep 36: ep_len:202 episode reward: total was 20.000000. running mean: -55.580023\n",
      "ep 36: ep_len:500 episode reward: total was -8.040000. running mean: -55.104623\n",
      "ep 36: ep_len:720 episode reward: total was 20.820000. running mean: -54.345376\n",
      "ep 36: ep_len:500 episode reward: total was -29.310000. running mean: -54.095023\n",
      "ep 36: ep_len:500 episode reward: total was 6.510000. running mean: -53.488972\n",
      "ep 36: ep_len:940 episode reward: total was 6.110000. running mean: -52.892983\n",
      "ep 36: ep_len:190 episode reward: total was -5.000000. running mean: -52.414053\n",
      "ep 36: ep_len:895 episode reward: total was -72.480000. running mean: -52.614712\n",
      "ep 36: ep_len:725 episode reward: total was -14.760000. running mean: -52.236165\n",
      "ep 36: ep_len:585 episode reward: total was -2.640000. running mean: -51.740203\n",
      "ep 36: ep_len:1292 episode reward: total was -34.040000. running mean: -51.563201\n",
      "ep 36: ep_len:500 episode reward: total was 33.290000. running mean: -50.714669\n",
      "ep 36: ep_len:895 episode reward: total was 33.720000. running mean: -49.870323\n",
      "ep 36: ep_len:500 episode reward: total was 0.320000. running mean: -49.368419\n",
      "ep 36: ep_len:890 episode reward: total was 13.080000. running mean: -48.743935\n",
      "ep 36: ep_len:760 episode reward: total was -22.250000. running mean: -48.478996\n",
      "ep 36: ep_len:845 episode reward: total was -57.950000. running mean: -48.573706\n",
      "ep 36: ep_len:500 episode reward: total was -7.980000. running mean: -48.167769\n",
      "ep 36: ep_len:715 episode reward: total was -12.730000. running mean: -47.813391\n",
      "ep 36: ep_len:150 episode reward: total was -3.000000. running mean: -47.365257\n",
      "ep 36: ep_len:825 episode reward: total was 13.990000. running mean: -46.751705\n",
      "ep 36: ep_len:945 episode reward: total was -29.590000. running mean: -46.580088\n",
      "ep 36: ep_len:1522 episode reward: total was -194.010000. running mean: -48.054387\n",
      "ep 36: ep_len:690 episode reward: total was -16.830000. running mean: -47.742143\n",
      "ep 36: ep_len:500 episode reward: total was 20.860000. running mean: -47.056122\n",
      "ep 36: ep_len:1630 episode reward: total was -74.820000. running mean: -47.333760\n",
      "ep 36: ep_len:1415 episode reward: total was -136.320000. running mean: -48.223623\n",
      "ep 36: ep_len:845 episode reward: total was -43.810000. running mean: -48.179486\n",
      "ep 36: ep_len:500 episode reward: total was -18.510000. running mean: -47.882792\n",
      "ep 36: ep_len:505 episode reward: total was -3.110000. running mean: -47.435064\n",
      "ep 36: ep_len:2740 episode reward: total was -326.860000. running mean: -50.229313\n",
      "ep 36: ep_len:500 episode reward: total was 0.510000. running mean: -49.721920\n",
      "ep 36: ep_len:865 episode reward: total was 16.150000. running mean: -49.063201\n",
      "ep 36: ep_len:1990 episode reward: total was -178.450000. running mean: -50.357069\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 36: ep_len:750 episode reward: total was -65.280000. running mean: -50.506298\n",
      "ep 36: ep_len:500 episode reward: total was 29.740000. running mean: -49.703835\n",
      "ep 36: ep_len:500 episode reward: total was 50.000000. running mean: -48.706797\n",
      "ep 36: ep_len:280 episode reward: total was 4.000000. running mean: -48.179729\n",
      "ep 36: ep_len:500 episode reward: total was 5.090000. running mean: -47.647031\n",
      "ep 36: ep_len:730 episode reward: total was -5.660000. running mean: -47.227161\n",
      "ep 36: ep_len:500 episode reward: total was 5.190000. running mean: -46.702990\n",
      "ep 36: ep_len:500 episode reward: total was -11.690000. running mean: -46.352860\n",
      "ep 36: ep_len:875 episode reward: total was 12.490000. running mean: -45.764431\n",
      "ep 36: ep_len:500 episode reward: total was 50.000000. running mean: -44.806787\n",
      "ep 36: ep_len:500 episode reward: total was 0.710000. running mean: -44.351619\n",
      "ep 36: ep_len:500 episode reward: total was 11.560000. running mean: -43.792503\n",
      "ep 36: ep_len:920 episode reward: total was 25.660000. running mean: -43.097978\n",
      "ep 36: ep_len:500 episode reward: total was 20.960000. running mean: -42.457398\n",
      "ep 36: ep_len:920 episode reward: total was 25.570000. running mean: -41.777124\n",
      "ep 36: ep_len:860 episode reward: total was 18.590000. running mean: -41.173453\n",
      "ep 36: ep_len:615 episode reward: total was -1.850000. running mean: -40.780218\n",
      "ep 36: ep_len:540 episode reward: total was -6.530000. running mean: -40.437716\n",
      "ep 36: ep_len:500 episode reward: total was 27.350000. running mean: -39.759839\n",
      "ep 36: ep_len:690 episode reward: total was -18.870000. running mean: -39.550940\n",
      "ep 36: ep_len:670 episode reward: total was -4.490000. running mean: -39.200331\n",
      "ep 36: ep_len:294 episode reward: total was 2.000000. running mean: -38.788328\n",
      "ep 36: ep_len:665 episode reward: total was -8.820000. running mean: -38.488644\n",
      "ep 36: ep_len:570 episode reward: total was -27.190000. running mean: -38.375658\n",
      "ep 36: ep_len:493 episode reward: total was 7.080000. running mean: -37.921101\n",
      "ep 36: ep_len:600 episode reward: total was 24.090000. running mean: -37.300990\n",
      "ep 36: ep_len:930 episode reward: total was 22.770000. running mean: -36.700280\n",
      "ep 36: ep_len:500 episode reward: total was 3.160000. running mean: -36.301678\n",
      "ep 36: ep_len:770 episode reward: total was -25.780000. running mean: -36.196461\n",
      "ep 36: ep_len:500 episode reward: total was 9.620000. running mean: -35.738296\n",
      "ep 36: ep_len:500 episode reward: total was -5.770000. running mean: -35.438613\n",
      "ep 36: ep_len:770 episode reward: total was 4.310000. running mean: -35.041127\n",
      "ep 36: ep_len:905 episode reward: total was -28.540000. running mean: -34.976116\n",
      "ep 36: ep_len:500 episode reward: total was -0.790000. running mean: -34.634255\n",
      "ep 36: ep_len:500 episode reward: total was -4.770000. running mean: -34.335612\n",
      "ep 36: ep_len:850 episode reward: total was 21.600000. running mean: -33.776256\n",
      "ep 36: ep_len:505 episode reward: total was -9.140000. running mean: -33.529894\n",
      "ep 36: ep_len:500 episode reward: total was 7.750000. running mean: -33.117095\n",
      "ep 36: ep_len:555 episode reward: total was -23.180000. running mean: -33.017724\n",
      "ep 36: ep_len:805 episode reward: total was -11.490000. running mean: -32.802446\n",
      "ep 36: ep_len:705 episode reward: total was 20.350000. running mean: -32.270922\n",
      "ep 36: ep_len:299 episode reward: total was 26.500000. running mean: -31.683213\n",
      "ep 36: ep_len:500 episode reward: total was 17.640000. running mean: -31.189981\n",
      "ep 36: ep_len:500 episode reward: total was 48.500000. running mean: -30.393081\n",
      "ep 36: ep_len:500 episode reward: total was 22.240000. running mean: -29.866750\n",
      "ep 36: ep_len:510 episode reward: total was -9.620000. running mean: -29.664282\n",
      "ep 36: ep_len:630 episode reward: total was 7.840000. running mean: -29.289240\n",
      "ep 36: ep_len:500 episode reward: total was -16.200000. running mean: -29.158347\n",
      "ep 36: ep_len:915 episode reward: total was 16.150000. running mean: -28.705264\n",
      "ep 36: ep_len:184 episode reward: total was -1.500000. running mean: -28.433211\n",
      "ep 36: ep_len:775 episode reward: total was -5.570000. running mean: -28.204579\n",
      "ep 36: ep_len:171 episode reward: total was 14.000000. running mean: -27.782533\n",
      "ep 36: ep_len:980 episode reward: total was -35.460000. running mean: -27.859308\n",
      "ep 36: ep_len:500 episode reward: total was 19.540000. running mean: -27.385315\n",
      "ep 36: ep_len:1853 episode reward: total was -272.060000. running mean: -29.832062\n",
      "ep 36: ep_len:500 episode reward: total was 2.590000. running mean: -29.507841\n",
      "ep 36: ep_len:500 episode reward: total was 6.630000. running mean: -29.146463\n",
      "ep 36: ep_len:660 episode reward: total was -10.850000. running mean: -28.963498\n",
      "ep 36: ep_len:840 episode reward: total was -14.860000. running mean: -28.822463\n",
      "ep 36: ep_len:500 episode reward: total was -1.160000. running mean: -28.545838\n",
      "ep 36: ep_len:670 episode reward: total was -10.830000. running mean: -28.368680\n",
      "ep 36: ep_len:565 episode reward: total was -1.950000. running mean: -28.104493\n",
      "ep 36: ep_len:515 episode reward: total was -1.680000. running mean: -27.840248\n",
      "ep 36: ep_len:615 episode reward: total was -2.860000. running mean: -27.590446\n",
      "ep 36: ep_len:706 episode reward: total was -71.450000. running mean: -28.029041\n",
      "ep 36: ep_len:4290 episode reward: total was -646.650000. running mean: -34.215251\n",
      "ep 36: ep_len:500 episode reward: total was -4.210000. running mean: -33.915198\n",
      "ep 36: ep_len:761 episode reward: total was -59.890000. running mean: -34.174946\n",
      "ep 36: ep_len:663 episode reward: total was -54.890000. running mean: -34.382097\n",
      "ep 36: ep_len:825 episode reward: total was -33.150000. running mean: -34.369776\n",
      "ep 36: ep_len:500 episode reward: total was -13.790000. running mean: -34.163978\n",
      "ep 36: ep_len:500 episode reward: total was 36.260000. running mean: -33.459738\n",
      "ep 36: ep_len:975 episode reward: total was 15.870000. running mean: -32.966441\n",
      "ep 36: ep_len:720 episode reward: total was -13.760000. running mean: -32.774377\n",
      "ep 36: ep_len:695 episode reward: total was -18.860000. running mean: -32.635233\n",
      "ep 36: ep_len:505 episode reward: total was -1.670000. running mean: -32.325581\n",
      "ep 36: ep_len:500 episode reward: total was 7.160000. running mean: -31.930725\n",
      "ep 36: ep_len:665 episode reward: total was 27.100000. running mean: -31.340418\n",
      "ep 36: ep_len:815 episode reward: total was 2.200000. running mean: -31.005013\n",
      "ep 36: ep_len:665 episode reward: total was -4.780000. running mean: -30.742763\n",
      "ep 36: ep_len:655 episode reward: total was -28.000000. running mean: -30.715336\n",
      "ep 36: ep_len:500 episode reward: total was -7.400000. running mean: -30.482182\n",
      "ep 36: ep_len:421 episode reward: total was 9.770000. running mean: -30.079660\n",
      "ep 36: ep_len:670 episode reward: total was -14.870000. running mean: -29.927564\n",
      "ep 36: ep_len:585 episode reward: total was -13.710000. running mean: -29.765388\n",
      "ep 36: ep_len:500 episode reward: total was 26.710000. running mean: -29.200634\n",
      "ep 36: ep_len:620 episode reward: total was -11.620000. running mean: -29.024828\n",
      "ep 36: ep_len:910 episode reward: total was -3.210000. running mean: -28.766680\n",
      "ep 36: ep_len:500 episode reward: total was 2.650000. running mean: -28.452513\n",
      "ep 36: ep_len:500 episode reward: total was 3.130000. running mean: -28.136688\n",
      "ep 36: ep_len:500 episode reward: total was 25.300000. running mean: -27.602321\n",
      "ep 36: ep_len:575 episode reward: total was -47.870000. running mean: -27.804998\n",
      "ep 36: ep_len:500 episode reward: total was -5.150000. running mean: -27.578448\n",
      "ep 36: ep_len:805 episode reward: total was -14.290000. running mean: -27.445563\n",
      "ep 36: ep_len:2219 episode reward: total was -203.660000. running mean: -29.207708\n",
      "ep 36: ep_len:545 episode reward: total was -4.500000. running mean: -28.960630\n",
      "ep 36: ep_len:500 episode reward: total was -24.000000. running mean: -28.911024\n",
      "ep 36: ep_len:735 episode reward: total was -5.770000. running mean: -28.679614\n",
      "ep 36: ep_len:630 episode reward: total was 0.200000. running mean: -28.390818\n",
      "ep 36: ep_len:520 episode reward: total was -4.580000. running mean: -28.152710\n",
      "ep 36: ep_len:630 episode reward: total was -4.850000. running mean: -27.919683\n",
      "ep 36: ep_len:2036 episode reward: total was -404.000000. running mean: -31.680486\n",
      "ep 36: ep_len:193 episode reward: total was -9.500000. running mean: -31.458681\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 36: ep_len:1040 episode reward: total was 2.240000. running mean: -31.121694\n",
      "ep 36: ep_len:500 episode reward: total was 9.840000. running mean: -30.712077\n",
      "ep 36: ep_len:770 episode reward: total was 5.320000. running mean: -30.351756\n",
      "ep 36: ep_len:500 episode reward: total was 12.020000. running mean: -29.928039\n",
      "ep 36: ep_len:500 episode reward: total was -2.630000. running mean: -29.655058\n",
      "ep 36: ep_len:600 episode reward: total was -38.240000. running mean: -29.740908\n",
      "ep 36: ep_len:1180 episode reward: total was -115.680000. running mean: -30.600299\n",
      "ep 36: ep_len:505 episode reward: total was -11.190000. running mean: -30.406196\n",
      "ep 36: ep_len:955 episode reward: total was -46.620000. running mean: -30.568334\n",
      "ep 36: ep_len:760 episode reward: total was 13.060000. running mean: -30.132050\n",
      "ep 36: ep_len:795 episode reward: total was -8.320000. running mean: -29.913930\n",
      "ep 36: ep_len:500 episode reward: total was -28.030000. running mean: -29.895091\n",
      "ep 36: ep_len:151 episode reward: total was -6.000000. running mean: -29.656140\n",
      "ep 36: ep_len:500 episode reward: total was -5.110000. running mean: -29.410678\n",
      "ep 36: ep_len:500 episode reward: total was 21.780000. running mean: -28.898772\n",
      "ep 36: ep_len:575 episode reward: total was -4.960000. running mean: -28.659384\n",
      "ep 36: ep_len:985 episode reward: total was 4.640000. running mean: -28.326390\n",
      "ep 36: ep_len:500 episode reward: total was -0.410000. running mean: -28.047226\n",
      "ep 36: ep_len:197 episode reward: total was -9.000000. running mean: -27.856754\n",
      "ep 36: ep_len:550 episode reward: total was -8.010000. running mean: -27.658286\n",
      "ep 36: ep_len:133 episode reward: total was -6.500000. running mean: -27.446703\n",
      "ep 36: ep_len:850 episode reward: total was 11.270000. running mean: -27.059536\n",
      "ep 36: ep_len:605 episode reward: total was 6.570000. running mean: -26.723241\n",
      "ep 36: ep_len:500 episode reward: total was 5.770000. running mean: -26.398309\n",
      "ep 36: ep_len:625 episode reward: total was -5.870000. running mean: -26.193026\n",
      "ep 36: ep_len:590 episode reward: total was -5.940000. running mean: -25.990495\n",
      "ep 36: ep_len:298 episode reward: total was -15.500000. running mean: -25.885590\n",
      "ep 36: ep_len:224 episode reward: total was -10.500000. running mean: -25.731734\n",
      "ep 36: ep_len:620 episode reward: total was -3.790000. running mean: -25.512317\n",
      "ep 36: ep_len:500 episode reward: total was 11.460000. running mean: -25.142594\n",
      "ep 36: ep_len:505 episode reward: total was -13.870000. running mean: -25.029868\n",
      "ep 36: ep_len:965 episode reward: total was 9.700000. running mean: -24.682569\n",
      "ep 36: ep_len:750 episode reward: total was -23.800000. running mean: -24.673744\n",
      "ep 36: ep_len:1265 episode reward: total was -167.200000. running mean: -26.099006\n",
      "ep 36: ep_len:850 episode reward: total was 21.050000. running mean: -25.627516\n",
      "ep 36: ep_len:675 episode reward: total was 6.740000. running mean: -25.303841\n",
      "ep 36: ep_len:500 episode reward: total was -0.260000. running mean: -25.053403\n",
      "ep 36: ep_len:184 episode reward: total was 16.500000. running mean: -24.637869\n",
      "ep 36: ep_len:645 episode reward: total was -11.890000. running mean: -24.510390\n",
      "ep 36: ep_len:1055 episode reward: total was -109.530000. running mean: -25.360586\n",
      "ep 36: ep_len:500 episode reward: total was -29.410000. running mean: -25.401080\n",
      "ep 36: ep_len:453 episode reward: total was 6.400000. running mean: -25.083069\n",
      "ep 36: ep_len:765 episode reward: total was -20.740000. running mean: -25.039639\n",
      "ep 36: ep_len:790 episode reward: total was -76.240000. running mean: -25.551642\n",
      "ep 36: ep_len:1480 episode reward: total was -77.370000. running mean: -26.069826\n",
      "ep 36: ep_len:725 episode reward: total was -24.830000. running mean: -26.057428\n",
      "ep 36: ep_len:500 episode reward: total was -17.810000. running mean: -25.974953\n",
      "ep 36: ep_len:500 episode reward: total was 12.290000. running mean: -25.592304\n",
      "ep 36: ep_len:575 episode reward: total was -3.430000. running mean: -25.370681\n",
      "ep 36: ep_len:920 episode reward: total was -41.880000. running mean: -25.535774\n",
      "ep 36: ep_len:980 episode reward: total was -31.420000. running mean: -25.594616\n",
      "ep 36: ep_len:525 episode reward: total was 15.740000. running mean: -25.181270\n",
      "ep 36: ep_len:500 episode reward: total was -19.860000. running mean: -25.128057\n",
      "ep 36: ep_len:500 episode reward: total was 21.780000. running mean: -24.658977\n",
      "ep 36: ep_len:500 episode reward: total was -2.030000. running mean: -24.432687\n",
      "ep 36: ep_len:910 episode reward: total was -11.780000. running mean: -24.306160\n",
      "ep 36: ep_len:500 episode reward: total was 29.800000. running mean: -23.765098\n",
      "ep 36: ep_len:1040 episode reward: total was -4.970000. running mean: -23.577147\n",
      "ep 36: ep_len:625 episode reward: total was -28.580000. running mean: -23.627176\n",
      "ep 36: ep_len:216 episode reward: total was -8.500000. running mean: -23.475904\n",
      "ep 36: ep_len:184 episode reward: total was -7.500000. running mean: -23.316145\n",
      "ep 36: ep_len:210 episode reward: total was 11.000000. running mean: -22.972984\n",
      "ep 36: ep_len:545 episode reward: total was 7.660000. running mean: -22.666654\n",
      "ep 36: ep_len:825 episode reward: total was 14.850000. running mean: -22.291487\n",
      "ep 36: ep_len:279 episode reward: total was -8.000000. running mean: -22.148572\n",
      "ep 36: ep_len:500 episode reward: total was 23.280000. running mean: -21.694287\n",
      "ep 36: ep_len:500 episode reward: total was 11.770000. running mean: -21.359644\n",
      "ep 36: ep_len:103 episode reward: total was 8.500000. running mean: -21.061047\n",
      "ep 36: ep_len:695 episode reward: total was 9.700000. running mean: -20.753437\n",
      "ep 36: ep_len:500 episode reward: total was 29.310000. running mean: -20.252803\n",
      "ep 36: ep_len:230 episode reward: total was 21.500000. running mean: -19.835275\n",
      "ep 36: ep_len:500 episode reward: total was 13.330000. running mean: -19.503622\n",
      "ep 36: ep_len:745 episode reward: total was -19.280000. running mean: -19.501386\n",
      "ep 36: ep_len:790 episode reward: total was -26.750000. running mean: -19.573872\n",
      "ep 36: ep_len:715 episode reward: total was -18.300000. running mean: -19.561133\n",
      "ep 36: ep_len:500 episode reward: total was -18.900000. running mean: -19.554522\n",
      "ep 36: ep_len:500 episode reward: total was 31.330000. running mean: -19.045676\n",
      "ep 36: ep_len:795 episode reward: total was -30.780000. running mean: -19.163020\n",
      "ep 36: ep_len:500 episode reward: total was -25.860000. running mean: -19.229990\n",
      "ep 36: ep_len:500 episode reward: total was 29.800000. running mean: -18.739690\n",
      "ep 36: ep_len:500 episode reward: total was 30.780000. running mean: -18.244493\n",
      "ep 36: ep_len:580 episode reward: total was -28.180000. running mean: -18.343848\n",
      "ep 36: ep_len:357 episode reward: total was 17.810000. running mean: -17.982309\n",
      "ep 36: ep_len:975 episode reward: total was -28.920000. running mean: -18.091686\n",
      "ep 36: ep_len:640 episode reward: total was 19.820000. running mean: -17.712569\n",
      "ep 36: ep_len:630 episode reward: total was -13.910000. running mean: -17.674544\n",
      "ep 36: ep_len:267 episode reward: total was 26.500000. running mean: -17.232798\n",
      "ep 36: ep_len:600 episode reward: total was -11.760000. running mean: -17.178070\n",
      "ep 36: ep_len:1366 episode reward: total was -132.640000. running mean: -18.332690\n",
      "ep 36: ep_len:715 episode reward: total was -5.690000. running mean: -18.206263\n",
      "ep 36: ep_len:500 episode reward: total was -7.130000. running mean: -18.095500\n",
      "ep 36: ep_len:327 episode reward: total was 30.000000. running mean: -17.614545\n",
      "ep 36: ep_len:107 episode reward: total was 10.500000. running mean: -17.333400\n",
      "ep 36: ep_len:500 episode reward: total was 9.730000. running mean: -17.062766\n",
      "ep 36: ep_len:500 episode reward: total was 31.760000. running mean: -16.574538\n",
      "ep 36: ep_len:319 episode reward: total was 13.320000. running mean: -16.275593\n",
      "ep 36: ep_len:205 episode reward: total was 11.500000. running mean: -15.997837\n",
      "ep 36: ep_len:1045 episode reward: total was -98.960000. running mean: -16.827458\n",
      "ep 36: ep_len:795 episode reward: total was 11.850000. running mean: -16.540684\n",
      "ep 36: ep_len:500 episode reward: total was -11.430000. running mean: -16.489577\n",
      "ep 36: ep_len:286 episode reward: total was 28.500000. running mean: -16.039681\n",
      "ep 36: ep_len:805 episode reward: total was 17.890000. running mean: -15.700384\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 36: ep_len:705 episode reward: total was 2.370000. running mean: -15.519680\n",
      "ep 36: ep_len:735 episode reward: total was -60.190000. running mean: -15.966384\n",
      "ep 36: ep_len:500 episode reward: total was 26.250000. running mean: -15.544220\n",
      "ep 36: ep_len:709 episode reward: total was -3.670000. running mean: -15.425478\n",
      "ep 36: ep_len:565 episode reward: total was -22.150000. running mean: -15.492723\n",
      "ep 36: ep_len:510 episode reward: total was 1.980000. running mean: -15.317996\n",
      "ep 36: ep_len:1232 episode reward: total was -213.710000. running mean: -17.301916\n",
      "ep 36: ep_len:166 episode reward: total was 10.500000. running mean: -17.023896\n",
      "ep 36: ep_len:1750 episode reward: total was -288.990000. running mean: -19.743558\n",
      "ep 36: ep_len:500 episode reward: total was 10.720000. running mean: -19.438922\n",
      "ep 36: ep_len:675 episode reward: total was -0.200000. running mean: -19.246533\n",
      "ep 36: ep_len:510 episode reward: total was -0.040000. running mean: -19.054467\n",
      "ep 36: ep_len:625 episode reward: total was 0.900000. running mean: -18.854923\n",
      "ep 36: ep_len:500 episode reward: total was 7.260000. running mean: -18.593773\n",
      "ep 36: ep_len:950 episode reward: total was -101.410000. running mean: -19.421936\n",
      "ep 36: ep_len:500 episode reward: total was 11.730000. running mean: -19.110416\n",
      "ep 36: ep_len:310 episode reward: total was 14.230000. running mean: -18.777012\n",
      "ep 36: ep_len:500 episode reward: total was 3.280000. running mean: -18.556442\n",
      "ep 36: ep_len:590 episode reward: total was -16.040000. running mean: -18.531278\n",
      "ep 36: ep_len:835 episode reward: total was -29.170000. running mean: -18.637665\n",
      "ep 36: ep_len:745 episode reward: total was 33.750000. running mean: -18.113788\n",
      "ep 36: ep_len:500 episode reward: total was 48.500000. running mean: -17.447650\n",
      "ep 36: ep_len:232 episode reward: total was -7.500000. running mean: -17.348174\n",
      "ep 36: ep_len:775 episode reward: total was 15.540000. running mean: -17.019292\n",
      "ep 36: ep_len:500 episode reward: total was 47.000000. running mean: -16.379099\n",
      "ep 36: ep_len:481 episode reward: total was 34.260000. running mean: -15.872708\n",
      "ep 36: ep_len:610 episode reward: total was 17.100000. running mean: -15.542981\n",
      "ep 36: ep_len:695 episode reward: total was -2.700000. running mean: -15.414551\n",
      "ep 36: ep_len:267 episode reward: total was -10.500000. running mean: -15.365406\n",
      "ep 36: ep_len:2715 episode reward: total was -251.760000. running mean: -17.729352\n",
      "ep 36: ep_len:3240 episode reward: total was -371.640000. running mean: -21.268458\n",
      "ep 36: ep_len:247 episode reward: total was 15.500000. running mean: -20.900774\n",
      "ep 36: ep_len:500 episode reward: total was 9.780000. running mean: -20.593966\n",
      "ep 36: ep_len:500 episode reward: total was 6.250000. running mean: -20.325526\n",
      "ep 36: ep_len:322 episode reward: total was 30.500000. running mean: -19.817271\n",
      "ep 36: ep_len:500 episode reward: total was 10.300000. running mean: -19.516098\n",
      "ep 36: ep_len:520 episode reward: total was 10.920000. running mean: -19.211737\n",
      "ep 36: ep_len:960 episode reward: total was -123.090000. running mean: -20.250520\n",
      "ep 36: ep_len:2320 episode reward: total was -397.390000. running mean: -24.021915\n",
      "ep 36: ep_len:2779 episode reward: total was -234.340000. running mean: -26.125096\n",
      "ep 36: ep_len:600 episode reward: total was -18.530000. running mean: -26.049145\n",
      "ep 36: ep_len:950 episode reward: total was 8.640000. running mean: -25.702253\n",
      "ep 36: ep_len:1620 episode reward: total was -46.230000. running mean: -25.907531\n",
      "ep 36: ep_len:540 episode reward: total was -5.640000. running mean: -25.704855\n",
      "ep 36: ep_len:745 episode reward: total was -27.850000. running mean: -25.726307\n",
      "ep 36: ep_len:775 episode reward: total was -17.690000. running mean: -25.645944\n",
      "ep 36: ep_len:420 episode reward: total was 40.500000. running mean: -24.984484\n",
      "ep 36: ep_len:500 episode reward: total was 4.410000. running mean: -24.690539\n",
      "ep 36: ep_len:1770 episode reward: total was -9.010000. running mean: -24.533734\n",
      "ep 36: ep_len:510 episode reward: total was 20.330000. running mean: -24.085097\n",
      "ep 36: ep_len:8920 episode reward: total was -1544.230000. running mean: -39.286546\n",
      "ep 36: ep_len:520 episode reward: total was -40.420000. running mean: -39.297880\n",
      "ep 36: ep_len:500 episode reward: total was 23.800000. running mean: -38.666901\n",
      "ep 36: ep_len:625 episode reward: total was 25.340000. running mean: -38.026832\n",
      "ep 36: ep_len:156 episode reward: total was 15.500000. running mean: -37.491564\n",
      "ep 36: ep_len:815 episode reward: total was -26.180000. running mean: -37.378448\n",
      "ep 36: ep_len:665 episode reward: total was 20.520000. running mean: -36.799464\n",
      "ep 36: ep_len:710 episode reward: total was -21.860000. running mean: -36.650069\n",
      "ep 36: ep_len:1270 episode reward: total was -53.060000. running mean: -36.814169\n",
      "ep 36: ep_len:570 episode reward: total was -0.160000. running mean: -36.447627\n",
      "ep 36: ep_len:1220 episode reward: total was -2.610000. running mean: -36.109251\n",
      "ep 36: ep_len:505 episode reward: total was -1.080000. running mean: -35.758958\n",
      "ep 36: ep_len:218 episode reward: total was 21.500000. running mean: -35.186369\n",
      "ep 36: ep_len:970 episode reward: total was -20.330000. running mean: -35.037805\n",
      "ep 36: ep_len:500 episode reward: total was 5.920000. running mean: -34.628227\n",
      "ep 36: ep_len:173 episode reward: total was -1.000000. running mean: -34.291945\n",
      "ep 36: ep_len:153 episode reward: total was 1.500000. running mean: -33.934025\n",
      "ep 36: ep_len:500 episode reward: total was -1.000000. running mean: -33.604685\n",
      "ep 36: ep_len:500 episode reward: total was -8.990000. running mean: -33.358538\n",
      "ep 36: ep_len:500 episode reward: total was -5.440000. running mean: -33.079353\n",
      "ep 36: ep_len:500 episode reward: total was -2.080000. running mean: -32.769359\n",
      "ep 36: ep_len:600 episode reward: total was -31.170000. running mean: -32.753366\n",
      "ep 36: ep_len:795 episode reward: total was -16.640000. running mean: -32.592232\n",
      "ep 36: ep_len:365 episode reward: total was 32.000000. running mean: -31.946310\n",
      "ep 36: ep_len:510 episode reward: total was 10.620000. running mean: -31.520647\n",
      "ep 36: ep_len:1020 episode reward: total was -99.010000. running mean: -32.195540\n",
      "ep 36: ep_len:1515 episode reward: total was -98.020000. running mean: -32.853785\n",
      "ep 36: ep_len:500 episode reward: total was 20.310000. running mean: -32.322147\n",
      "ep 36: ep_len:963 episode reward: total was -91.030000. running mean: -32.909225\n",
      "ep 36: ep_len:985 episode reward: total was -103.120000. running mean: -33.611333\n",
      "ep 36: ep_len:500 episode reward: total was 20.260000. running mean: -33.072620\n",
      "ep 36: ep_len:935 episode reward: total was -9.290000. running mean: -32.834794\n",
      "ep 36: ep_len:1255 episode reward: total was 10.050000. running mean: -32.405946\n",
      "ep 36: ep_len:700 episode reward: total was 6.940000. running mean: -32.012486\n",
      "ep 36: ep_len:500 episode reward: total was 20.460000. running mean: -31.487761\n",
      "ep 36: ep_len:846 episode reward: total was -39.710000. running mean: -31.569984\n",
      "ep 36: ep_len:500 episode reward: total was 18.260000. running mean: -31.071684\n",
      "ep 36: ep_len:730 episode reward: total was -48.170000. running mean: -31.242667\n",
      "ep 36: ep_len:261 episode reward: total was -8.000000. running mean: -31.010240\n",
      "ep 36: ep_len:500 episode reward: total was 11.070000. running mean: -30.589438\n",
      "ep 36: ep_len:500 episode reward: total was -7.950000. running mean: -30.363044\n",
      "ep 36: ep_len:1215 episode reward: total was 17.960000. running mean: -29.879813\n",
      "ep 36: ep_len:705 episode reward: total was -14.800000. running mean: -29.729015\n",
      "ep 36: ep_len:500 episode reward: total was -8.750000. running mean: -29.519225\n",
      "ep 36: ep_len:530 episode reward: total was 2.990000. running mean: -29.194133\n",
      "ep 36: ep_len:500 episode reward: total was 20.800000. running mean: -28.694191\n",
      "ep 36: ep_len:980 episode reward: total was -43.870000. running mean: -28.845949\n",
      "ep 36: ep_len:455 episode reward: total was 22.730000. running mean: -28.330190\n",
      "ep 36: ep_len:545 episode reward: total was -5.020000. running mean: -28.097088\n",
      "ep 36: ep_len:10 episode reward: total was -0.500000. running mean: -27.821117\n",
      "ep 36: ep_len:500 episode reward: total was -2.170000. running mean: -27.564606\n",
      "ep 36: ep_len:1165 episode reward: total was -42.160000. running mean: -27.710560\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 36: ep_len:730 episode reward: total was 0.280000. running mean: -27.430654\n",
      "ep 36: ep_len:500 episode reward: total was 24.260000. running mean: -26.913748\n",
      "ep 36: ep_len:500 episode reward: total was 24.810000. running mean: -26.396510\n",
      "ep 36: ep_len:930 episode reward: total was 8.030000. running mean: -26.052245\n",
      "ep 36: ep_len:500 episode reward: total was 4.760000. running mean: -25.744123\n",
      "ep 36: ep_len:640 episode reward: total was -34.120000. running mean: -25.827881\n",
      "ep 36: ep_len:885 episode reward: total was 7.610000. running mean: -25.493503\n",
      "ep 36: ep_len:664 episode reward: total was -38.120000. running mean: -25.619768\n",
      "ep 36: ep_len:1040 episode reward: total was 6.360000. running mean: -25.299970\n",
      "ep 36: ep_len:500 episode reward: total was 0.860000. running mean: -25.038370\n",
      "ep 36: ep_len:500 episode reward: total was 2.980000. running mean: -24.758187\n",
      "ep 36: ep_len:945 episode reward: total was -24.420000. running mean: -24.754805\n",
      "ep 36: ep_len:970 episode reward: total was 1.150000. running mean: -24.495757\n",
      "ep 36: ep_len:920 episode reward: total was -17.400000. running mean: -24.424799\n",
      "ep 36: ep_len:1035 episode reward: total was -23.020000. running mean: -24.410751\n",
      "ep 36: ep_len:500 episode reward: total was 1.020000. running mean: -24.156444\n",
      "ep 36: ep_len:510 episode reward: total was -3.070000. running mean: -23.945579\n",
      "ep 36: ep_len:530 episode reward: total was -26.750000. running mean: -23.973623\n",
      "ep 36: ep_len:500 episode reward: total was 32.340000. running mean: -23.410487\n",
      "ep 36: ep_len:520 episode reward: total was -0.020000. running mean: -23.176582\n",
      "ep 36: ep_len:1185 episode reward: total was -145.120000. running mean: -24.396016\n",
      "ep 36: ep_len:1040 episode reward: total was -138.590000. running mean: -25.537956\n",
      "ep 36: ep_len:500 episode reward: total was -25.890000. running mean: -25.541477\n",
      "ep 36: ep_len:515 episode reward: total was -2.050000. running mean: -25.306562\n",
      "ep 36: ep_len:500 episode reward: total was 11.980000. running mean: -24.933696\n",
      "ep 36: ep_len:500 episode reward: total was -10.160000. running mean: -24.785959\n",
      "ep 36: ep_len:199 episode reward: total was 5.000000. running mean: -24.488100\n",
      "ep 36: ep_len:273 episode reward: total was -1.500000. running mean: -24.258219\n",
      "ep 36: ep_len:500 episode reward: total was 0.290000. running mean: -24.012737\n",
      "ep 36: ep_len:510 episode reward: total was -37.410000. running mean: -24.146709\n",
      "ep 36: ep_len:815 episode reward: total was -34.780000. running mean: -24.253042\n",
      "ep 36: ep_len:560 episode reward: total was -10.040000. running mean: -24.110912\n",
      "ep 36: ep_len:500 episode reward: total was 48.500000. running mean: -23.384803\n",
      "ep 36: ep_len:605 episode reward: total was 27.810000. running mean: -22.872855\n",
      "ep 36: ep_len:725 episode reward: total was -4.630000. running mean: -22.690426\n",
      "ep 36: ep_len:500 episode reward: total was 27.260000. running mean: -22.190922\n",
      "ep 36: ep_len:193 episode reward: total was 4.500000. running mean: -21.924013\n",
      "ep 36: ep_len:775 episode reward: total was -15.670000. running mean: -21.861472\n",
      "ep 36: ep_len:500 episode reward: total was 3.320000. running mean: -21.609658\n",
      "ep 36: ep_len:935 episode reward: total was -22.390000. running mean: -21.617461\n",
      "ep 36: ep_len:605 episode reward: total was -22.070000. running mean: -21.621986\n",
      "ep 36: ep_len:500 episode reward: total was 10.110000. running mean: -21.304667\n",
      "ep 36: ep_len:500 episode reward: total was 27.290000. running mean: -20.818720\n",
      "ep 36: ep_len:960 episode reward: total was -24.630000. running mean: -20.856833\n",
      "ep 36: ep_len:500 episode reward: total was -4.650000. running mean: -20.694764\n",
      "ep 36: ep_len:500 episode reward: total was 4.320000. running mean: -20.444617\n",
      "ep 36: ep_len:760 episode reward: total was -58.120000. running mean: -20.821371\n",
      "ep 36: ep_len:710 episode reward: total was -57.210000. running mean: -21.185257\n",
      "ep 36: ep_len:500 episode reward: total was 17.400000. running mean: -20.799404\n",
      "ep 36: ep_len:2225 episode reward: total was -372.330000. running mean: -24.314710\n",
      "ep 36: ep_len:575 episode reward: total was -2.940000. running mean: -24.100963\n",
      "ep 36: ep_len:500 episode reward: total was 21.440000. running mean: -23.645554\n",
      "ep 36: ep_len:805 episode reward: total was -17.630000. running mean: -23.585398\n",
      "ep 36: ep_len:454 episode reward: total was -37.530000. running mean: -23.724844\n",
      "ep 36: ep_len:1175 episode reward: total was -100.010000. running mean: -24.487696\n",
      "ep 36: ep_len:760 episode reward: total was -7.620000. running mean: -24.319019\n",
      "ep 36: ep_len:500 episode reward: total was -8.590000. running mean: -24.161728\n",
      "ep 36: ep_len:670 episode reward: total was 28.000000. running mean: -23.640111\n",
      "ep 36: ep_len:500 episode reward: total was -5.660000. running mean: -23.460310\n",
      "ep 36: ep_len:500 episode reward: total was 31.760000. running mean: -22.908107\n",
      "ep 36: ep_len:945 episode reward: total was -24.420000. running mean: -22.923226\n",
      "ep 36: ep_len:1795 episode reward: total was -97.310000. running mean: -23.667094\n",
      "ep 36: ep_len:500 episode reward: total was 19.480000. running mean: -23.235623\n",
      "ep 36: ep_len:500 episode reward: total was 23.830000. running mean: -22.764966\n",
      "ep 36: ep_len:645 episode reward: total was 5.440000. running mean: -22.482917\n",
      "ep 36: ep_len:1010 episode reward: total was 11.240000. running mean: -22.145688\n",
      "ep 36: ep_len:1010 episode reward: total was 22.400000. running mean: -21.700231\n",
      "ep 36: ep_len:610 episode reward: total was 5.890000. running mean: -21.424328\n",
      "ep 36: ep_len:500 episode reward: total was 25.790000. running mean: -20.952185\n",
      "ep 36: ep_len:1485 episode reward: total was -167.770000. running mean: -22.420363\n",
      "ep 36: ep_len:560 episode reward: total was 2.150000. running mean: -22.174660\n",
      "ep 36: ep_len:675 episode reward: total was -4.760000. running mean: -22.000513\n",
      "ep 36: ep_len:1770 episode reward: total was -118.680000. running mean: -22.967308\n",
      "ep 36: ep_len:575 episode reward: total was -19.100000. running mean: -22.928635\n",
      "ep 36: ep_len:500 episode reward: total was 27.320000. running mean: -22.426149\n",
      "ep 36: ep_len:1257 episode reward: total was -125.350000. running mean: -23.455387\n",
      "ep 36: ep_len:500 episode reward: total was -27.390000. running mean: -23.494733\n",
      "ep 36: ep_len:500 episode reward: total was 6.930000. running mean: -23.190486\n",
      "ep 36: ep_len:1680 episode reward: total was -118.920000. running mean: -24.147781\n",
      "ep 36: ep_len:955 episode reward: total was -47.630000. running mean: -24.382603\n",
      "ep 36: ep_len:500 episode reward: total was -2.900000. running mean: -24.167777\n",
      "ep 36: ep_len:500 episode reward: total was -3.240000. running mean: -23.958499\n",
      "ep 36: ep_len:710 episode reward: total was -4.690000. running mean: -23.765814\n",
      "ep 36: ep_len:585 episode reward: total was -3.130000. running mean: -23.559456\n",
      "ep 36: ep_len:407 episode reward: total was -14.760000. running mean: -23.471462\n",
      "ep 36: ep_len:610 episode reward: total was -38.220000. running mean: -23.618947\n",
      "ep 36: ep_len:500 episode reward: total was 36.200000. running mean: -23.020758\n",
      "ep 36: ep_len:500 episode reward: total was -23.380000. running mean: -23.024350\n",
      "ep 36: ep_len:146 episode reward: total was 14.500000. running mean: -22.649106\n",
      "ep 36: ep_len:500 episode reward: total was -25.820000. running mean: -22.680815\n",
      "ep 36: ep_len:1359 episode reward: total was -204.390000. running mean: -24.497907\n",
      "ep 36: ep_len:580 episode reward: total was -25.150000. running mean: -24.504428\n",
      "ep 36: ep_len:790 episode reward: total was 21.420000. running mean: -24.045184\n",
      "ep 36: ep_len:715 episode reward: total was -7.220000. running mean: -23.876932\n",
      "ep 36: ep_len:500 episode reward: total was 19.270000. running mean: -23.445463\n",
      "ep 36: ep_len:930 episode reward: total was 14.830000. running mean: -23.062708\n",
      "ep 36: ep_len:545 episode reward: total was -34.390000. running mean: -23.175981\n",
      "ep 36: ep_len:520 episode reward: total was 18.970000. running mean: -22.754521\n",
      "ep 36: ep_len:605 episode reward: total was 33.500000. running mean: -22.191976\n",
      "ep 36: ep_len:424 episode reward: total was 10.290000. running mean: -21.867156\n",
      "ep 36: ep_len:66 episode reward: total was 5.000000. running mean: -21.598485\n",
      "ep 36: ep_len:162 episode reward: total was 16.000000. running mean: -21.222500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 36: ep_len:500 episode reward: total was 22.720000. running mean: -20.783075\n",
      "ep 36: ep_len:770 episode reward: total was -11.640000. running mean: -20.691644\n",
      "ep 36: ep_len:500 episode reward: total was 10.230000. running mean: -20.382428\n",
      "ep 36: ep_len:725 episode reward: total was 18.430000. running mean: -19.994303\n",
      "ep 36: ep_len:500 episode reward: total was -9.760000. running mean: -19.891960\n",
      "ep 36: ep_len:258 episode reward: total was 25.500000. running mean: -19.438041\n",
      "ep 36: ep_len:2125 episode reward: total was -248.010000. running mean: -21.723760\n",
      "ep 36: ep_len:288 episode reward: total was 28.500000. running mean: -21.221523\n",
      "ep 36: ep_len:595 episode reward: total was 0.050000. running mean: -21.008808\n",
      "ep 36: ep_len:500 episode reward: total was 10.940000. running mean: -20.689319\n",
      "ep 36: ep_len:500 episode reward: total was 3.740000. running mean: -20.445026\n",
      "ep 36: ep_len:500 episode reward: total was 8.960000. running mean: -20.150976\n",
      "ep 36: ep_len:500 episode reward: total was -3.650000. running mean: -19.985966\n",
      "ep 36: ep_len:710 episode reward: total was 26.270000. running mean: -19.523407\n",
      "ep 36: ep_len:1070 episode reward: total was 25.370000. running mean: -19.074473\n",
      "ep 36: ep_len:500 episode reward: total was 5.240000. running mean: -18.831328\n",
      "ep 36: ep_len:500 episode reward: total was 13.840000. running mean: -18.504614\n",
      "ep 36: ep_len:500 episode reward: total was 10.060000. running mean: -18.218968\n",
      "ep 36: ep_len:820 episode reward: total was 14.010000. running mean: -17.896679\n",
      "ep 36: ep_len:855 episode reward: total was -21.570000. running mean: -17.933412\n",
      "ep 36: ep_len:775 episode reward: total was -9.610000. running mean: -17.850178\n",
      "ep 36: ep_len:500 episode reward: total was 23.470000. running mean: -17.436976\n",
      "ep 36: ep_len:500 episode reward: total was 25.790000. running mean: -17.004706\n",
      "ep 36: ep_len:820 episode reward: total was 3.990000. running mean: -16.794759\n",
      "ep 36: ep_len:500 episode reward: total was -4.620000. running mean: -16.673012\n",
      "ep 36: ep_len:500 episode reward: total was 5.100000. running mean: -16.455281\n",
      "ep 36: ep_len:500 episode reward: total was -14.380000. running mean: -16.434529\n",
      "ep 36: ep_len:500 episode reward: total was 6.810000. running mean: -16.202083\n",
      "ep 36: ep_len:500 episode reward: total was 21.320000. running mean: -15.826863\n",
      "ep 36: ep_len:685 episode reward: total was 4.910000. running mean: -15.619494\n",
      "ep 36: ep_len:600 episode reward: total was 16.990000. running mean: -15.293399\n",
      "ep 36: ep_len:500 episode reward: total was -0.960000. running mean: -15.150065\n",
      "ep 36: ep_len:500 episode reward: total was -22.340000. running mean: -15.221964\n",
      "ep 36: ep_len:875 episode reward: total was -8.510000. running mean: -15.154845\n",
      "ep 36: ep_len:500 episode reward: total was 4.660000. running mean: -14.956696\n",
      "ep 36: ep_len:510 episode reward: total was 25.840000. running mean: -14.548729\n",
      "ep 36: ep_len:500 episode reward: total was -5.110000. running mean: -14.454342\n",
      "ep 36: ep_len:500 episode reward: total was 17.640000. running mean: -14.133399\n",
      "ep 36: ep_len:825 episode reward: total was 14.480000. running mean: -13.847265\n",
      "ep 36: ep_len:535 episode reward: total was -13.120000. running mean: -13.839992\n",
      "ep 36: ep_len:610 episode reward: total was -2.870000. running mean: -13.730292\n",
      "ep 36: ep_len:565 episode reward: total was -5.990000. running mean: -13.652889\n",
      "ep 36: ep_len:615 episode reward: total was -4.080000. running mean: -13.557160\n",
      "ep 36: ep_len:610 episode reward: total was 16.120000. running mean: -13.260389\n",
      "ep 36: ep_len:950 episode reward: total was -47.640000. running mean: -13.604185\n",
      "ep 36: ep_len:980 episode reward: total was -5.470000. running mean: -13.522843\n",
      "ep 36: ep_len:940 episode reward: total was -6.360000. running mean: -13.451214\n",
      "ep 36: ep_len:284 episode reward: total was 8.230000. running mean: -13.234402\n",
      "ep 36: ep_len:876 episode reward: total was -91.200000. running mean: -14.014058\n",
      "ep 36: ep_len:675 episode reward: total was -88.970000. running mean: -14.763618\n",
      "ep 36: ep_len:570 episode reward: total was 16.360000. running mean: -14.452382\n",
      "ep 36: ep_len:184 episode reward: total was 18.000000. running mean: -14.127858\n",
      "ep 36: ep_len:670 episode reward: total was -2.230000. running mean: -14.008879\n",
      "ep 36: ep_len:500 episode reward: total was 21.290000. running mean: -13.655890\n",
      "ep 36: ep_len:500 episode reward: total was 50.000000. running mean: -13.019331\n",
      "ep 36: ep_len:680 episode reward: total was -2.730000. running mean: -12.916438\n",
      "ep 36: ep_len:780 episode reward: total was -3.540000. running mean: -12.822674\n",
      "ep 36: ep_len:216 episode reward: total was 22.000000. running mean: -12.474447\n",
      "ep 36: ep_len:500 episode reward: total was -10.370000. running mean: -12.453403\n",
      "ep 36: ep_len:500 episode reward: total was 15.840000. running mean: -12.170468\n",
      "ep 36: ep_len:845 episode reward: total was -14.580000. running mean: -12.194564\n",
      "ep 36: ep_len:685 episode reward: total was -44.620000. running mean: -12.518818\n",
      "ep 36: ep_len:500 episode reward: total was -1.890000. running mean: -12.412530\n",
      "ep 36: ep_len:176 episode reward: total was 18.000000. running mean: -12.108405\n",
      "ep 36: ep_len:491 episode reward: total was 32.790000. running mean: -11.659421\n",
      "ep 36: ep_len:500 episode reward: total was -2.110000. running mean: -11.563926\n",
      "ep 36: ep_len:300 episode reward: total was 28.500000. running mean: -11.163287\n",
      "ep 36: ep_len:565 episode reward: total was -15.050000. running mean: -11.202154\n",
      "ep 36: ep_len:705 episode reward: total was 3.320000. running mean: -11.056933\n",
      "ep 36: ep_len:500 episode reward: total was -7.920000. running mean: -11.025563\n",
      "ep 36: ep_len:1070 episode reward: total was 20.050000. running mean: -10.714808\n",
      "ep 36: ep_len:620 episode reward: total was -39.210000. running mean: -10.999760\n",
      "ep 36: ep_len:820 episode reward: total was -1.130000. running mean: -10.901062\n",
      "ep 36: ep_len:805 episode reward: total was 6.450000. running mean: -10.727551\n",
      "ep 36: ep_len:500 episode reward: total was -14.290000. running mean: -10.763176\n",
      "ep 36: ep_len:645 episode reward: total was -28.050000. running mean: -10.936044\n",
      "ep 36: ep_len:720 episode reward: total was -7.680000. running mean: -10.903484\n",
      "ep 36: ep_len:500 episode reward: total was 12.130000. running mean: -10.673149\n",
      "ep 36: ep_len:500 episode reward: total was 6.350000. running mean: -10.502917\n",
      "ep 36: ep_len:1200 episode reward: total was -11.190000. running mean: -10.509788\n",
      "ep 36: ep_len:500 episode reward: total was -23.160000. running mean: -10.636290\n",
      "ep 36: ep_len:482 episode reward: total was 21.070000. running mean: -10.319227\n",
      "ep 36: ep_len:915 episode reward: total was -7.530000. running mean: -10.291335\n",
      "ep 36: ep_len:1250 episode reward: total was -67.240000. running mean: -10.860822\n",
      "ep 36: ep_len:301 episode reward: total was 30.000000. running mean: -10.452214\n",
      "ep 36: ep_len:535 episode reward: total was -32.310000. running mean: -10.670792\n",
      "ep 36: ep_len:800 episode reward: total was 8.910000. running mean: -10.474984\n",
      "ep 36: ep_len:500 episode reward: total was -21.390000. running mean: -10.584134\n",
      "ep 36: ep_len:565 episode reward: total was 29.220000. running mean: -10.186092\n",
      "ep 36: ep_len:500 episode reward: total was -5.280000. running mean: -10.137031\n",
      "ep 36: ep_len:720 episode reward: total was -5.680000. running mean: -10.092461\n",
      "ep 36: ep_len:500 episode reward: total was 10.230000. running mean: -9.889237\n",
      "ep 36: ep_len:500 episode reward: total was 17.920000. running mean: -9.611144\n",
      "ep 36: ep_len:500 episode reward: total was 8.180000. running mean: -9.433233\n",
      "ep 36: ep_len:145 episode reward: total was 13.500000. running mean: -9.203900\n",
      "ep 36: ep_len:940 episode reward: total was -16.220000. running mean: -9.274061\n",
      "ep 36: ep_len:990 episode reward: total was 2.190000. running mean: -9.159421\n",
      "ep 36: ep_len:500 episode reward: total was 18.990000. running mean: -8.877927\n",
      "ep 36: ep_len:755 episode reward: total was -9.650000. running mean: -8.885647\n",
      "ep 36: ep_len:500 episode reward: total was -11.060000. running mean: -8.907391\n",
      "ep 36: ep_len:500 episode reward: total was 15.260000. running mean: -8.665717\n",
      "ep 36: ep_len:635 episode reward: total was 18.740000. running mean: -8.391660\n",
      "ep 36: ep_len:500 episode reward: total was 14.670000. running mean: -8.161043\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 36: ep_len:1235 episode reward: total was 2.450000. running mean: -8.054933\n",
      "ep 36: ep_len:12380 episode reward: total was -2324.270000. running mean: -31.217083\n",
      "ep 36: ep_len:600 episode reward: total was -5.660000. running mean: -30.961513\n",
      "ep 36: ep_len:880 episode reward: total was -14.180000. running mean: -30.793697\n",
      "ep 36: ep_len:315 episode reward: total was 28.500000. running mean: -30.200760\n",
      "ep 36: ep_len:500 episode reward: total was -4.740000. running mean: -29.946153\n",
      "ep 36: ep_len:500 episode reward: total was 10.800000. running mean: -29.538691\n",
      "ep 36: ep_len:221 episode reward: total was 11.140000. running mean: -29.131904\n",
      "ep 36: ep_len:520 episode reward: total was -4.060000. running mean: -28.881185\n",
      "ep 36: ep_len:1215 episode reward: total was -25.810000. running mean: -28.850474\n",
      "ep 36: ep_len:500 episode reward: total was 10.200000. running mean: -28.459969\n",
      "ep 36: ep_len:500 episode reward: total was 19.880000. running mean: -27.976569\n",
      "ep 36: ep_len:500 episode reward: total was 50.000000. running mean: -27.196803\n",
      "ep 36: ep_len:655 episode reward: total was -5.810000. running mean: -26.982935\n",
      "ep 36: ep_len:500 episode reward: total was 15.840000. running mean: -26.554706\n",
      "ep 36: ep_len:500 episode reward: total was 27.290000. running mean: -26.016259\n",
      "ep 36: ep_len:650 episode reward: total was 19.350000. running mean: -25.562596\n",
      "ep 36: ep_len:800 episode reward: total was -32.790000. running mean: -25.634870\n",
      "ep 36: ep_len:615 episode reward: total was -18.010000. running mean: -25.558622\n",
      "ep 36: ep_len:870 episode reward: total was -4.240000. running mean: -25.345436\n",
      "ep 36: ep_len:660 episode reward: total was -30.040000. running mean: -25.392381\n",
      "ep 36: ep_len:530 episode reward: total was -5.050000. running mean: -25.188957\n",
      "ep 36: ep_len:505 episode reward: total was 18.110000. running mean: -24.755968\n",
      "ep 36: ep_len:560 episode reward: total was -16.100000. running mean: -24.669408\n",
      "ep 36: ep_len:500 episode reward: total was -24.420000. running mean: -24.666914\n",
      "ep 36: ep_len:500 episode reward: total was -14.320000. running mean: -24.563445\n",
      "ep 36: ep_len:605 episode reward: total was -26.110000. running mean: -24.578910\n",
      "ep 36: ep_len:500 episode reward: total was -17.470000. running mean: -24.507821\n",
      "ep 36: ep_len:500 episode reward: total was 3.860000. running mean: -24.224143\n",
      "ep 36: ep_len:710 episode reward: total was -12.770000. running mean: -24.109602\n",
      "ep 36: ep_len:635 episode reward: total was -21.000000. running mean: -24.078506\n",
      "ep 36: ep_len:530 episode reward: total was -24.730000. running mean: -24.085021\n",
      "ep 36: ep_len:840 episode reward: total was -12.700000. running mean: -23.971170\n",
      "ep 36: ep_len:222 episode reward: total was 22.000000. running mean: -23.511459\n",
      "ep 36: ep_len:500 episode reward: total was 1.690000. running mean: -23.259444\n",
      "ep 36: ep_len:680 episode reward: total was -11.820000. running mean: -23.145050\n",
      "ep 36: ep_len:500 episode reward: total was 27.740000. running mean: -22.636199\n",
      "ep 36: ep_len:885 episode reward: total was -23.530000. running mean: -22.645137\n",
      "ep 36: ep_len:665 episode reward: total was -37.100000. running mean: -22.789686\n",
      "ep 36: ep_len:500 episode reward: total was 5.150000. running mean: -22.510289\n",
      "ep 36: ep_len:620 episode reward: total was -22.040000. running mean: -22.505586\n",
      "ep 36: ep_len:500 episode reward: total was 26.830000. running mean: -22.012230\n",
      "ep 36: ep_len:775 episode reward: total was 3.190000. running mean: -21.760208\n",
      "ep 36: ep_len:505 episode reward: total was 24.300000. running mean: -21.299606\n",
      "ep 36: ep_len:500 episode reward: total was 0.900000. running mean: -21.077610\n",
      "ep 36: ep_len:500 episode reward: total was -5.490000. running mean: -20.921734\n",
      "ep 36: ep_len:348 episode reward: total was -62.990000. running mean: -21.342416\n",
      "ep 36: ep_len:955 episode reward: total was 24.250000. running mean: -20.886492\n",
      "ep 36: ep_len:500 episode reward: total was -0.390000. running mean: -20.681527\n",
      "ep 36: ep_len:12135 episode reward: total was -2373.480000. running mean: -44.209512\n",
      "ep 36: ep_len:735 episode reward: total was -4.640000. running mean: -43.813817\n",
      "ep 36: ep_len:500 episode reward: total was 11.740000. running mean: -43.258279\n",
      "ep 36: ep_len:254 episode reward: total was 25.000000. running mean: -42.575696\n",
      "ep 36: ep_len:815 episode reward: total was -8.050000. running mean: -42.230439\n",
      "ep 36: ep_len:243 episode reward: total was 21.000000. running mean: -41.598135\n",
      "ep 36: ep_len:600 episode reward: total was -25.110000. running mean: -41.433253\n",
      "ep 36: ep_len:500 episode reward: total was 8.700000. running mean: -40.931921\n",
      "ep 36: ep_len:750 episode reward: total was -28.850000. running mean: -40.811101\n",
      "ep 36: ep_len:525 episode reward: total was 17.660000. running mean: -40.226390\n",
      "ep 36: ep_len:500 episode reward: total was 8.670000. running mean: -39.737427\n",
      "ep 36: ep_len:500 episode reward: total was 32.370000. running mean: -39.016352\n",
      "ep 36: ep_len:895 episode reward: total was -68.960000. running mean: -39.315789\n",
      "ep 36: ep_len:830 episode reward: total was -15.270000. running mean: -39.075331\n",
      "ep 36: ep_len:930 episode reward: total was -4.590000. running mean: -38.730478\n",
      "ep 36: ep_len:625 episode reward: total was -25.880000. running mean: -38.601973\n",
      "ep 36: ep_len:1445 episode reward: total was -70.780000. running mean: -38.923753\n",
      "ep 36: ep_len:500 episode reward: total was 30.780000. running mean: -38.226716\n",
      "ep 36: ep_len:500 episode reward: total was -6.230000. running mean: -37.906748\n",
      "ep 36: ep_len:605 episode reward: total was -47.320000. running mean: -38.000881\n",
      "ep 36: ep_len:1060 episode reward: total was 12.770000. running mean: -37.493172\n",
      "ep 36: ep_len:895 episode reward: total was -104.940000. running mean: -38.167640\n",
      "ep 36: ep_len:500 episode reward: total was 26.800000. running mean: -37.517964\n",
      "ep 36: ep_len:810 episode reward: total was -86.280000. running mean: -38.005584\n",
      "ep 36: ep_len:500 episode reward: total was 8.250000. running mean: -37.543028\n",
      "ep 36: ep_len:800 episode reward: total was 12.410000. running mean: -37.043498\n",
      "ep 36: ep_len:500 episode reward: total was -15.760000. running mean: -36.830663\n",
      "ep 36: ep_len:1247 episode reward: total was -183.090000. running mean: -38.293257\n",
      "ep 36: ep_len:500 episode reward: total was -7.160000. running mean: -37.981924\n",
      "ep 36: ep_len:500 episode reward: total was 22.940000. running mean: -37.372705\n",
      "ep 36: ep_len:500 episode reward: total was 13.140000. running mean: -36.867578\n",
      "ep 36: ep_len:1250 episode reward: total was -151.070000. running mean: -38.009602\n",
      "ep 36: ep_len:745 episode reward: total was -19.770000. running mean: -37.827206\n",
      "ep 36: ep_len:675 episode reward: total was -25.020000. running mean: -37.699134\n",
      "ep 36: ep_len:775 episode reward: total was -46.980000. running mean: -37.791943\n",
      "ep 36: ep_len:600 episode reward: total was 1.950000. running mean: -37.394523\n",
      "ep 36: ep_len:500 episode reward: total was 21.350000. running mean: -36.807078\n",
      "ep 36: ep_len:654 episode reward: total was -64.380000. running mean: -37.082807\n",
      "ep 36: ep_len:263 episode reward: total was 26.000000. running mean: -36.451979\n",
      "ep 36: ep_len:530 episode reward: total was 18.380000. running mean: -35.903659\n",
      "ep 36: ep_len:555 episode reward: total was -10.000000. running mean: -35.644623\n",
      "ep 36: ep_len:520 episode reward: total was 4.880000. running mean: -35.239376\n",
      "ep 36: ep_len:745 episode reward: total was -15.730000. running mean: -35.044283\n",
      "ep 36: ep_len:500 episode reward: total was 15.850000. running mean: -34.535340\n",
      "ep 36: ep_len:530 episode reward: total was -4.040000. running mean: -34.230386\n",
      "ep 36: ep_len:213 episode reward: total was 19.500000. running mean: -33.693083\n",
      "ep 36: ep_len:500 episode reward: total was -8.750000. running mean: -33.443652\n",
      "ep 36: ep_len:740 episode reward: total was -28.350000. running mean: -33.392715\n",
      "ep 36: ep_len:1080 episode reward: total was -42.160000. running mean: -33.480388\n",
      "ep 36: ep_len:895 episode reward: total was -6.420000. running mean: -33.209784\n",
      "ep 36: ep_len:500 episode reward: total was 13.510000. running mean: -32.742586\n",
      "ep 36: ep_len:500 episode reward: total was -0.820000. running mean: -32.423360\n",
      "ep 36: ep_len:750 episode reward: total was -9.660000. running mean: -32.195727\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 36: ep_len:500 episode reward: total was 16.240000. running mean: -31.711370\n",
      "ep 36: ep_len:745 episode reward: total was -6.640000. running mean: -31.460656\n",
      "ep 36: ep_len:500 episode reward: total was -1.280000. running mean: -31.158849\n",
      "ep 36: ep_len:685 episode reward: total was -11.810000. running mean: -30.965361\n",
      "ep 36: ep_len:500 episode reward: total was 14.030000. running mean: -30.515407\n",
      "ep 36: ep_len:500 episode reward: total was 9.250000. running mean: -30.117753\n",
      "ep 36: ep_len:940 episode reward: total was -79.660000. running mean: -30.613176\n",
      "ep 36: ep_len:510 episode reward: total was -2.060000. running mean: -30.327644\n",
      "ep 36: ep_len:500 episode reward: total was 4.440000. running mean: -29.979967\n",
      "ep 36: ep_len:500 episode reward: total was 4.440000. running mean: -29.635768\n",
      "ep 36: ep_len:500 episode reward: total was 25.820000. running mean: -29.081210\n",
      "ep 36: ep_len:500 episode reward: total was -59.160000. running mean: -29.381998\n",
      "ep 36: ep_len:271 episode reward: total was 27.000000. running mean: -28.818178\n",
      "ep 36: ep_len:188 episode reward: total was 18.500000. running mean: -28.344996\n",
      "ep 36: ep_len:585 episode reward: total was -3.040000. running mean: -28.091946\n",
      "ep 36: ep_len:500 episode reward: total was 7.690000. running mean: -27.734127\n",
      "ep 36: ep_len:650 episode reward: total was 21.560000. running mean: -27.241186\n",
      "ep 36: ep_len:2655 episode reward: total was -430.000000. running mean: -31.268774\n",
      "ep 36: ep_len:910 episode reward: total was -9.530000. running mean: -31.051386\n",
      "ep 36: ep_len:500 episode reward: total was 48.500000. running mean: -30.255872\n",
      "ep 36: ep_len:948 episode reward: total was -79.030000. running mean: -30.743613\n",
      "ep 36: ep_len:719 episode reward: total was -53.220000. running mean: -30.968377\n",
      "ep 36: ep_len:500 episode reward: total was 14.180000. running mean: -30.516893\n",
      "ep 36: ep_len:500 episode reward: total was 11.670000. running mean: -30.095025\n",
      "ep 36: ep_len:500 episode reward: total was 48.500000. running mean: -29.309074\n",
      "ep 36: ep_len:500 episode reward: total was 18.160000. running mean: -28.834384\n",
      "epsilon:0.010000 episode_count: 29179. steps_count: 21225341.000000\n",
      "ep 37: ep_len:500 episode reward: total was 21.750000. running mean: -28.328540\n",
      "ep 37: ep_len:805 episode reward: total was -12.670000. running mean: -28.171954\n",
      "ep 37: ep_len:605 episode reward: total was 4.110000. running mean: -27.849135\n",
      "ep 37: ep_len:1110 episode reward: total was -129.220000. running mean: -28.862843\n",
      "ep 37: ep_len:625 episode reward: total was 15.290000. running mean: -28.421315\n",
      "ep 37: ep_len:890 episode reward: total was -59.880000. running mean: -28.735902\n",
      "ep 37: ep_len:500 episode reward: total was 9.070000. running mean: -28.357843\n",
      "ep 37: ep_len:500 episode reward: total was 11.830000. running mean: -27.955964\n",
      "ep 37: ep_len:1070 episode reward: total was -4.780000. running mean: -27.724205\n",
      "ep 37: ep_len:540 episode reward: total was 0.020000. running mean: -27.446763\n",
      "ep 37: ep_len:500 episode reward: total was 10.210000. running mean: -27.070195\n",
      "ep 37: ep_len:645 episode reward: total was -24.010000. running mean: -27.039593\n",
      "ep 37: ep_len:500 episode reward: total was 0.920000. running mean: -26.759997\n",
      "ep 37: ep_len:209 episode reward: total was 20.500000. running mean: -26.287397\n",
      "ep 37: ep_len:1000 episode reward: total was -49.820000. running mean: -26.522723\n",
      "ep 37: ep_len:845 episode reward: total was -35.730000. running mean: -26.614796\n",
      "ep 37: ep_len:500 episode reward: total was 29.310000. running mean: -26.055548\n",
      "ep 37: ep_len:550 episode reward: total was -42.560000. running mean: -26.220593\n",
      "ep 37: ep_len:500 episode reward: total was 13.940000. running mean: -25.818987\n",
      "ep 37: ep_len:246 episode reward: total was 23.000000. running mean: -25.330797\n",
      "ep 37: ep_len:570 episode reward: total was -5.980000. running mean: -25.137289\n",
      "ep 37: ep_len:720 episode reward: total was -32.950000. running mean: -25.215416\n",
      "ep 37: ep_len:1860 episode reward: total was -67.310000. running mean: -25.636362\n",
      "ep 37: ep_len:258 episode reward: total was 24.000000. running mean: -25.139998\n",
      "ep 37: ep_len:1045 episode reward: total was -38.020000. running mean: -25.268798\n",
      "ep 37: ep_len:500 episode reward: total was 3.320000. running mean: -24.982910\n",
      "ep 37: ep_len:500 episode reward: total was -0.790000. running mean: -24.740981\n",
      "ep 37: ep_len:118 episode reward: total was 11.500000. running mean: -24.378571\n",
      "ep 37: ep_len:730 episode reward: total was -1.640000. running mean: -24.151186\n",
      "ep 37: ep_len:500 episode reward: total was -4.100000. running mean: -23.950674\n",
      "ep 37: ep_len:500 episode reward: total was -2.230000. running mean: -23.733467\n",
      "ep 37: ep_len:500 episode reward: total was 22.420000. running mean: -23.271932\n",
      "ep 37: ep_len:500 episode reward: total was 23.710000. running mean: -22.802113\n",
      "ep 37: ep_len:875 episode reward: total was 1.510000. running mean: -22.558992\n",
      "ep 37: ep_len:243 episode reward: total was 24.000000. running mean: -22.093402\n",
      "ep 37: ep_len:500 episode reward: total was -0.580000. running mean: -21.878268\n",
      "ep 37: ep_len:840 episode reward: total was 9.320000. running mean: -21.566285\n",
      "ep 37: ep_len:828 episode reward: total was -139.780000. running mean: -22.748422\n",
      "ep 37: ep_len:555 episode reward: total was -2.980000. running mean: -22.550738\n",
      "ep 37: ep_len:720 episode reward: total was -3.660000. running mean: -22.361831\n",
      "ep 37: ep_len:590 episode reward: total was -16.040000. running mean: -22.298612\n",
      "ep 37: ep_len:500 episode reward: total was 0.800000. running mean: -22.067626\n",
      "ep 37: ep_len:750 episode reward: total was 35.090000. running mean: -21.496050\n",
      "ep 37: ep_len:940 episode reward: total was 13.220000. running mean: -21.148890\n",
      "ep 37: ep_len:500 episode reward: total was 1.380000. running mean: -20.923601\n",
      "ep 37: ep_len:1255 episode reward: total was -213.190000. running mean: -22.846265\n",
      "ep 37: ep_len:500 episode reward: total was 17.370000. running mean: -22.444102\n",
      "ep 37: ep_len:715 episode reward: total was -4.280000. running mean: -22.262461\n",
      "ep 37: ep_len:1815 episode reward: total was -172.230000. running mean: -23.762136\n",
      "ep 37: ep_len:1010 episode reward: total was 23.410000. running mean: -23.290415\n",
      "ep 37: ep_len:850 episode reward: total was -23.600000. running mean: -23.293511\n",
      "ep 37: ep_len:500 episode reward: total was 12.380000. running mean: -22.936776\n",
      "ep 37: ep_len:191 episode reward: total was 19.000000. running mean: -22.517408\n",
      "ep 37: ep_len:920 episode reward: total was -37.390000. running mean: -22.666134\n",
      "ep 37: ep_len:2210 episode reward: total was -372.820000. running mean: -26.167673\n",
      "ep 37: ep_len:500 episode reward: total was 14.810000. running mean: -25.757896\n",
      "ep 37: ep_len:665 episode reward: total was 0.270000. running mean: -25.497617\n",
      "ep 37: ep_len:500 episode reward: total was -52.940000. running mean: -25.772041\n",
      "ep 37: ep_len:840 episode reward: total was 4.850000. running mean: -25.465820\n",
      "ep 37: ep_len:500 episode reward: total was 4.690000. running mean: -25.164262\n",
      "ep 37: ep_len:1300 episode reward: total was -187.330000. running mean: -26.785920\n",
      "ep 37: ep_len:500 episode reward: total was 22.820000. running mean: -26.289860\n",
      "ep 37: ep_len:565 episode reward: total was -9.020000. running mean: -26.117162\n",
      "ep 37: ep_len:520 episode reward: total was 29.870000. running mean: -25.557290\n",
      "ep 37: ep_len:500 episode reward: total was 33.750000. running mean: -24.964217\n",
      "ep 37: ep_len:1240 episode reward: total was -51.670000. running mean: -25.231275\n",
      "ep 37: ep_len:575 episode reward: total was -16.070000. running mean: -25.139662\n",
      "ep 37: ep_len:500 episode reward: total was -15.760000. running mean: -25.045866\n",
      "ep 37: ep_len:725 episode reward: total was -23.850000. running mean: -25.033907\n",
      "ep 37: ep_len:735 episode reward: total was -4.610000. running mean: -24.829668\n",
      "ep 37: ep_len:900 episode reward: total was 9.030000. running mean: -24.491071\n",
      "ep 37: ep_len:825 episode reward: total was 15.560000. running mean: -24.090561\n",
      "ep 37: ep_len:543 episode reward: total was -44.970000. running mean: -24.299355\n",
      "ep 37: ep_len:535 episode reward: total was 8.350000. running mean: -23.972861\n",
      "ep 37: ep_len:520 episode reward: total was -9.110000. running mean: -23.824233\n",
      "ep 37: ep_len:865 episode reward: total was 14.140000. running mean: -23.444590\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 37: ep_len:3165 episode reward: total was -503.720000. running mean: -28.247345\n",
      "ep 37: ep_len:540 episode reward: total was -1.890000. running mean: -27.983771\n",
      "ep 37: ep_len:645 episode reward: total was -2.280000. running mean: -27.726733\n",
      "ep 37: ep_len:530 episode reward: total was 10.740000. running mean: -27.342066\n",
      "ep 37: ep_len:680 episode reward: total was 3.330000. running mean: -27.035345\n",
      "ep 37: ep_len:555 episode reward: total was 2.410000. running mean: -26.740892\n",
      "ep 37: ep_len:266 episode reward: total was 25.000000. running mean: -26.223483\n",
      "ep 37: ep_len:500 episode reward: total was -14.810000. running mean: -26.109348\n",
      "ep 37: ep_len:745 episode reward: total was 4.360000. running mean: -25.804655\n",
      "ep 37: ep_len:500 episode reward: total was 9.930000. running mean: -25.447308\n",
      "ep 37: ep_len:1390 episode reward: total was -179.560000. running mean: -26.988435\n",
      "ep 37: ep_len:500 episode reward: total was -7.710000. running mean: -26.795651\n",
      "ep 37: ep_len:500 episode reward: total was 7.510000. running mean: -26.452594\n",
      "ep 37: ep_len:500 episode reward: total was 22.270000. running mean: -25.965368\n",
      "ep 37: ep_len:500 episode reward: total was 13.270000. running mean: -25.573015\n",
      "ep 37: ep_len:840 episode reward: total was -4.690000. running mean: -25.364184\n",
      "ep 37: ep_len:630 episode reward: total was -90.700000. running mean: -26.017543\n",
      "ep 37: ep_len:715 episode reward: total was -33.450000. running mean: -26.091867\n",
      "ep 37: ep_len:665 episode reward: total was 3.220000. running mean: -25.798748\n",
      "ep 37: ep_len:520 episode reward: total was -17.680000. running mean: -25.717561\n",
      "ep 37: ep_len:860 episode reward: total was 3.010000. running mean: -25.430285\n",
      "ep 37: ep_len:680 episode reward: total was -7.780000. running mean: -25.253783\n",
      "ep 37: ep_len:496 episode reward: total was 26.770000. running mean: -24.733545\n",
      "ep 37: ep_len:705 episode reward: total was -54.190000. running mean: -25.028109\n",
      "ep 37: ep_len:500 episode reward: total was -8.230000. running mean: -24.860128\n",
      "ep 37: ep_len:505 episode reward: total was -41.460000. running mean: -25.026127\n",
      "ep 37: ep_len:500 episode reward: total was 48.500000. running mean: -24.290866\n",
      "ep 37: ep_len:620 episode reward: total was -11.050000. running mean: -24.158457\n",
      "ep 37: ep_len:580 episode reward: total was -23.130000. running mean: -24.148172\n",
      "ep 37: ep_len:290 episode reward: total was 28.000000. running mean: -23.626691\n",
      "ep 37: ep_len:855 episode reward: total was 12.720000. running mean: -23.263224\n",
      "ep 37: ep_len:540 episode reward: total was 19.320000. running mean: -22.837392\n",
      "ep 37: ep_len:790 episode reward: total was -21.700000. running mean: -22.826018\n",
      "ep 37: ep_len:1210 episode reward: total was -131.470000. running mean: -23.912457\n",
      "ep 37: ep_len:500 episode reward: total was -4.220000. running mean: -23.715533\n",
      "ep 37: ep_len:155 episode reward: total was 11.500000. running mean: -23.363378\n",
      "ep 37: ep_len:825 episode reward: total was -10.520000. running mean: -23.234944\n",
      "ep 37: ep_len:845 episode reward: total was 44.640000. running mean: -22.556194\n",
      "ep 37: ep_len:1450 episode reward: total was -188.910000. running mean: -24.219732\n",
      "ep 37: ep_len:850 episode reward: total was -99.930000. running mean: -24.976835\n",
      "ep 37: ep_len:500 episode reward: total was 25.300000. running mean: -24.474067\n",
      "ep 37: ep_len:845 episode reward: total was 26.790000. running mean: -23.961426\n",
      "ep 37: ep_len:615 episode reward: total was -38.210000. running mean: -24.103912\n",
      "ep 37: ep_len:740 episode reward: total was 1.570000. running mean: -23.847173\n",
      "ep 37: ep_len:750 episode reward: total was -6.630000. running mean: -23.675001\n",
      "ep 37: ep_len:2830 episode reward: total was -510.470000. running mean: -28.542951\n",
      "ep 37: ep_len:915 episode reward: total was -8.400000. running mean: -28.341521\n",
      "ep 37: ep_len:700 episode reward: total was -4.680000. running mean: -28.104906\n",
      "ep 37: ep_len:545 episode reward: total was -76.700000. running mean: -28.590857\n",
      "ep 37: ep_len:1040 episode reward: total was -44.580000. running mean: -28.750749\n",
      "ep 37: ep_len:590 episode reward: total was -43.080000. running mean: -28.894041\n",
      "ep 37: ep_len:255 episode reward: total was 22.500000. running mean: -28.380101\n",
      "ep 37: ep_len:500 episode reward: total was -52.610000. running mean: -28.622400\n",
      "ep 37: ep_len:500 episode reward: total was 16.850000. running mean: -28.167676\n",
      "ep 37: ep_len:500 episode reward: total was 24.690000. running mean: -27.639099\n",
      "ep 37: ep_len:500 episode reward: total was 11.640000. running mean: -27.246308\n",
      "ep 37: ep_len:1205 episode reward: total was -158.440000. running mean: -28.558245\n",
      "ep 37: ep_len:500 episode reward: total was 1.170000. running mean: -28.260962\n",
      "ep 37: ep_len:955 episode reward: total was 11.620000. running mean: -27.862153\n",
      "ep 37: ep_len:500 episode reward: total was 48.500000. running mean: -27.098531\n",
      "ep 37: ep_len:500 episode reward: total was 18.660000. running mean: -26.640946\n",
      "ep 37: ep_len:875 episode reward: total was 4.080000. running mean: -26.333736\n",
      "ep 37: ep_len:1510 episode reward: total was -69.750000. running mean: -26.767899\n",
      "ep 37: ep_len:500 episode reward: total was 14.190000. running mean: -26.358320\n",
      "ep 37: ep_len:500 episode reward: total was -5.260000. running mean: -26.147337\n",
      "ep 37: ep_len:96 episode reward: total was 9.500000. running mean: -25.790864\n",
      "ep 37: ep_len:575 episode reward: total was -11.020000. running mean: -25.643155\n",
      "ep 37: ep_len:500 episode reward: total was -6.260000. running mean: -25.449323\n",
      "ep 37: ep_len:855 episode reward: total was 7.880000. running mean: -25.116030\n",
      "ep 37: ep_len:605 episode reward: total was -10.650000. running mean: -24.971370\n",
      "ep 37: ep_len:525 episode reward: total was -11.120000. running mean: -24.832856\n",
      "ep 37: ep_len:580 episode reward: total was -22.120000. running mean: -24.805728\n",
      "ep 37: ep_len:500 episode reward: total was 50.000000. running mean: -24.057670\n",
      "ep 37: ep_len:735 episode reward: total was 30.730000. running mean: -23.509794\n",
      "ep 37: ep_len:119 episode reward: total was 11.500000. running mean: -23.159696\n",
      "ep 37: ep_len:500 episode reward: total was 7.600000. running mean: -22.852099\n",
      "ep 37: ep_len:500 episode reward: total was 6.250000. running mean: -22.561078\n",
      "ep 37: ep_len:690 episode reward: total was -10.790000. running mean: -22.443367\n",
      "ep 37: ep_len:790 episode reward: total was -7.890000. running mean: -22.297833\n",
      "ep 37: ep_len:810 episode reward: total was 0.890000. running mean: -22.065955\n",
      "ep 37: ep_len:324 episode reward: total was 17.280000. running mean: -21.672495\n",
      "ep 37: ep_len:735 episode reward: total was 28.740000. running mean: -21.168370\n",
      "ep 37: ep_len:500 episode reward: total was 27.870000. running mean: -20.677987\n",
      "ep 37: ep_len:500 episode reward: total was 9.440000. running mean: -20.376807\n",
      "ep 37: ep_len:615 episode reward: total was -13.670000. running mean: -20.309739\n",
      "ep 37: ep_len:247 episode reward: total was 24.500000. running mean: -19.861641\n",
      "ep 37: ep_len:685 episode reward: total was -10.800000. running mean: -19.771025\n",
      "ep 37: ep_len:600 episode reward: total was -22.110000. running mean: -19.794415\n",
      "ep 37: ep_len:500 episode reward: total was 28.730000. running mean: -19.309171\n",
      "ep 37: ep_len:525 episode reward: total was -4.050000. running mean: -19.156579\n",
      "ep 37: ep_len:620 episode reward: total was -6.890000. running mean: -19.033913\n",
      "ep 37: ep_len:910 episode reward: total was 18.600000. running mean: -18.657574\n",
      "ep 37: ep_len:500 episode reward: total was 16.790000. running mean: -18.303098\n",
      "ep 37: ep_len:500 episode reward: total was 12.680000. running mean: -17.993267\n",
      "ep 37: ep_len:645 episode reward: total was -37.140000. running mean: -18.184735\n",
      "ep 37: ep_len:845 episode reward: total was 13.310000. running mean: -17.869787\n",
      "ep 37: ep_len:735 episode reward: total was -26.730000. running mean: -17.958389\n",
      "ep 37: ep_len:540 episode reward: total was 20.210000. running mean: -17.576705\n",
      "ep 37: ep_len:223 episode reward: total was 22.000000. running mean: -17.180938\n",
      "ep 37: ep_len:500 episode reward: total was 17.800000. running mean: -16.831129\n",
      "ep 37: ep_len:117 episode reward: total was 11.500000. running mean: -16.547818\n",
      "ep 37: ep_len:765 episode reward: total was -20.740000. running mean: -16.589740\n",
      "ep 37: ep_len:965 episode reward: total was 8.610000. running mean: -16.337742\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 37: ep_len:665 episode reward: total was -40.130000. running mean: -16.575665\n",
      "ep 37: ep_len:585 episode reward: total was -27.160000. running mean: -16.681508\n",
      "ep 37: ep_len:870 episode reward: total was -13.100000. running mean: -16.645693\n",
      "ep 37: ep_len:730 episode reward: total was 15.290000. running mean: -16.326336\n",
      "ep 37: ep_len:195 episode reward: total was 16.010000. running mean: -16.002973\n",
      "ep 37: ep_len:500 episode reward: total was 22.790000. running mean: -15.615043\n",
      "ep 37: ep_len:54 episode reward: total was 5.000000. running mean: -15.408893\n",
      "ep 37: ep_len:605 episode reward: total was -3.890000. running mean: -15.293704\n",
      "ep 37: ep_len:510 episode reward: total was -5.090000. running mean: -15.191667\n",
      "ep 37: ep_len:500 episode reward: total was 23.720000. running mean: -14.802550\n",
      "ep 37: ep_len:640 episode reward: total was 8.830000. running mean: -14.566224\n",
      "ep 37: ep_len:500 episode reward: total was -7.610000. running mean: -14.496662\n",
      "ep 37: ep_len:680 episode reward: total was -11.790000. running mean: -14.469596\n",
      "ep 37: ep_len:257 episode reward: total was 25.500000. running mean: -14.069900\n",
      "ep 37: ep_len:775 episode reward: total was -2.540000. running mean: -13.954601\n",
      "ep 37: ep_len:179 episode reward: total was 17.500000. running mean: -13.640055\n",
      "ep 37: ep_len:1349 episode reward: total was -148.320000. running mean: -14.986854\n",
      "ep 37: ep_len:500 episode reward: total was 27.440000. running mean: -14.562586\n",
      "ep 37: ep_len:1798 episode reward: total was -240.860000. running mean: -16.825560\n",
      "ep 37: ep_len:500 episode reward: total was 14.220000. running mean: -16.515104\n",
      "ep 37: ep_len:500 episode reward: total was 14.250000. running mean: -16.207453\n",
      "ep 37: ep_len:715 episode reward: total was -3.670000. running mean: -16.082078\n",
      "ep 37: ep_len:785 episode reward: total was -15.650000. running mean: -16.077758\n",
      "ep 37: ep_len:645 episode reward: total was -7.850000. running mean: -15.995480\n",
      "ep 37: ep_len:329 episode reward: total was 32.500000. running mean: -15.510525\n",
      "ep 37: ep_len:620 episode reward: total was -11.420000. running mean: -15.469620\n",
      "ep 37: ep_len:620 episode reward: total was -5.880000. running mean: -15.373724\n",
      "ep 37: ep_len:640 episode reward: total was 12.870000. running mean: -15.091287\n",
      "ep 37: ep_len:500 episode reward: total was 13.140000. running mean: -14.808974\n",
      "ep 37: ep_len:730 episode reward: total was -24.850000. running mean: -14.909384\n",
      "ep 37: ep_len:5920 episode reward: total was -849.320000. running mean: -23.253490\n",
      "ep 37: ep_len:500 episode reward: total was 0.310000. running mean: -23.017855\n",
      "ep 37: ep_len:500 episode reward: total was 16.630000. running mean: -22.621377\n",
      "ep 37: ep_len:690 episode reward: total was -7.760000. running mean: -22.472763\n",
      "ep 37: ep_len:580 episode reward: total was -20.250000. running mean: -22.450535\n",
      "ep 37: ep_len:500 episode reward: total was 21.990000. running mean: -22.006130\n",
      "ep 37: ep_len:755 episode reward: total was 6.210000. running mean: -21.723969\n",
      "ep 37: ep_len:500 episode reward: total was 14.670000. running mean: -21.360029\n",
      "ep 37: ep_len:500 episode reward: total was 7.020000. running mean: -21.076229\n",
      "ep 37: ep_len:500 episode reward: total was 16.280000. running mean: -20.702666\n",
      "ep 37: ep_len:500 episode reward: total was 0.190000. running mean: -20.493740\n",
      "ep 37: ep_len:525 episode reward: total was -3.040000. running mean: -20.319202\n",
      "ep 37: ep_len:235 episode reward: total was 22.500000. running mean: -19.891010\n",
      "ep 37: ep_len:530 episode reward: total was 8.430000. running mean: -19.607800\n",
      "ep 37: ep_len:725 episode reward: total was -5.670000. running mean: -19.468422\n",
      "ep 37: ep_len:730 episode reward: total was 9.650000. running mean: -19.177238\n",
      "ep 37: ep_len:660 episode reward: total was -14.890000. running mean: -19.134366\n",
      "ep 37: ep_len:2195 episode reward: total was -357.220000. running mean: -22.515222\n",
      "ep 37: ep_len:402 episode reward: total was 23.320000. running mean: -22.056870\n",
      "ep 37: ep_len:500 episode reward: total was 24.810000. running mean: -21.588201\n",
      "ep 37: ep_len:500 episode reward: total was 34.270000. running mean: -21.029619\n",
      "ep 37: ep_len:570 episode reward: total was 5.840000. running mean: -20.760923\n",
      "ep 37: ep_len:500 episode reward: total was 29.250000. running mean: -20.260814\n",
      "ep 37: ep_len:900 episode reward: total was 1.010000. running mean: -20.048105\n",
      "ep 37: ep_len:500 episode reward: total was 24.810000. running mean: -19.599524\n",
      "ep 37: ep_len:845 episode reward: total was -21.590000. running mean: -19.619429\n",
      "ep 37: ep_len:500 episode reward: total was 17.770000. running mean: -19.245535\n",
      "ep 37: ep_len:765 episode reward: total was -31.860000. running mean: -19.371680\n",
      "ep 37: ep_len:680 episode reward: total was -24.950000. running mean: -19.427463\n",
      "ep 37: ep_len:505 episode reward: total was -13.180000. running mean: -19.364988\n",
      "ep 37: ep_len:500 episode reward: total was 14.610000. running mean: -19.025238\n",
      "ep 37: ep_len:500 episode reward: total was 32.740000. running mean: -18.507586\n",
      "ep 37: ep_len:500 episode reward: total was 48.500000. running mean: -17.837510\n",
      "ep 37: ep_len:975 episode reward: total was 12.840000. running mean: -17.530735\n",
      "ep 37: ep_len:500 episode reward: total was 11.640000. running mean: -17.239028\n",
      "ep 37: ep_len:500 episode reward: total was -7.270000. running mean: -17.139337\n",
      "ep 37: ep_len:900 episode reward: total was 15.550000. running mean: -16.812444\n",
      "ep 37: ep_len:500 episode reward: total was 18.040000. running mean: -16.463919\n",
      "ep 37: ep_len:645 episode reward: total was 27.780000. running mean: -16.021480\n",
      "ep 37: ep_len:500 episode reward: total was 12.900000. running mean: -15.732265\n",
      "ep 37: ep_len:500 episode reward: total was -32.010000. running mean: -15.895043\n",
      "ep 37: ep_len:500 episode reward: total was 11.500000. running mean: -15.621092\n",
      "ep 37: ep_len:660 episode reward: total was 11.350000. running mean: -15.351381\n",
      "ep 37: ep_len:54 episode reward: total was 5.000000. running mean: -15.147868\n",
      "ep 37: ep_len:1745 episode reward: total was -158.160000. running mean: -16.577989\n",
      "ep 37: ep_len:500 episode reward: total was 5.270000. running mean: -16.359509\n",
      "ep 37: ep_len:500 episode reward: total was 25.850000. running mean: -15.937414\n",
      "ep 37: ep_len:1014 episode reward: total was -54.570000. running mean: -16.323740\n",
      "ep 37: ep_len:830 episode reward: total was 0.470000. running mean: -16.155802\n",
      "ep 37: ep_len:500 episode reward: total was 37.610000. running mean: -15.618144\n",
      "ep 37: ep_len:600 episode reward: total was -51.390000. running mean: -15.975863\n",
      "ep 37: ep_len:249 episode reward: total was 24.500000. running mean: -15.571104\n",
      "ep 37: ep_len:158 episode reward: total was 15.500000. running mean: -15.260393\n",
      "ep 37: ep_len:775 episode reward: total was 29.410000. running mean: -14.813689\n",
      "ep 37: ep_len:520 episode reward: total was -14.160000. running mean: -14.807152\n",
      "ep 37: ep_len:255 episode reward: total was 22.500000. running mean: -14.434081\n",
      "ep 37: ep_len:735 episode reward: total was 20.600000. running mean: -14.083740\n",
      "ep 37: ep_len:545 episode reward: total was -17.140000. running mean: -14.114303\n",
      "ep 37: ep_len:600 episode reward: total was 34.380000. running mean: -13.629360\n",
      "ep 37: ep_len:152 episode reward: total was 15.000000. running mean: -13.343066\n",
      "ep 37: ep_len:156 episode reward: total was 15.500000. running mean: -13.054635\n",
      "ep 37: ep_len:640 episode reward: total was -8.870000. running mean: -13.012789\n",
      "ep 37: ep_len:236 episode reward: total was 22.000000. running mean: -12.662661\n",
      "ep 37: ep_len:730 episode reward: total was 7.230000. running mean: -12.463735\n",
      "ep 37: ep_len:630 episode reward: total was -14.440000. running mean: -12.483497\n",
      "ep 37: ep_len:3125 episode reward: total was -512.940000. running mean: -17.488062\n",
      "ep 37: ep_len:500 episode reward: total was 10.720000. running mean: -17.205982\n",
      "ep 37: ep_len:500 episode reward: total was -9.960000. running mean: -17.133522\n",
      "ep 37: ep_len:500 episode reward: total was 0.220000. running mean: -16.959987\n",
      "ep 37: ep_len:820 episode reward: total was 17.070000. running mean: -16.619687\n",
      "ep 37: ep_len:500 episode reward: total was 10.850000. running mean: -16.344990\n",
      "ep 37: ep_len:500 episode reward: total was -2.170000. running mean: -16.203240\n",
      "ep 37: ep_len:500 episode reward: total was -14.260000. running mean: -16.183808\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 37: ep_len:500 episode reward: total was 47.000000. running mean: -15.551970\n",
      "ep 37: ep_len:500 episode reward: total was 27.230000. running mean: -15.124150\n",
      "ep 37: ep_len:735 episode reward: total was 19.680000. running mean: -14.776108\n",
      "ep 37: ep_len:500 episode reward: total was 6.840000. running mean: -14.559947\n",
      "ep 37: ep_len:360 episode reward: total was 15.500000. running mean: -14.259348\n",
      "ep 37: ep_len:180 episode reward: total was 17.000000. running mean: -13.946754\n",
      "ep 37: ep_len:142 episode reward: total was 14.000000. running mean: -13.667287\n",
      "ep 37: ep_len:256 episode reward: total was 25.500000. running mean: -13.275614\n",
      "ep 37: ep_len:570 episode reward: total was -23.150000. running mean: -13.374358\n",
      "ep 37: ep_len:1035 episode reward: total was -94.450000. running mean: -14.185114\n",
      "ep 37: ep_len:500 episode reward: total was 23.870000. running mean: -13.804563\n",
      "ep 37: ep_len:447 episode reward: total was 15.020000. running mean: -13.516317\n",
      "ep 37: ep_len:520 episode reward: total was -12.140000. running mean: -13.502554\n",
      "ep 37: ep_len:1100 episode reward: total was -56.290000. running mean: -13.930429\n",
      "ep 37: ep_len:1864 episode reward: total was -107.410000. running mean: -14.865224\n",
      "ep 37: ep_len:760 episode reward: total was -2.570000. running mean: -14.742272\n",
      "ep 37: ep_len:1115 episode reward: total was 0.220000. running mean: -14.592649\n",
      "ep 37: ep_len:500 episode reward: total was 12.190000. running mean: -14.324823\n",
      "ep 37: ep_len:590 episode reward: total was -4.930000. running mean: -14.230875\n",
      "ep 37: ep_len:815 episode reward: total was -9.190000. running mean: -14.180466\n",
      "ep 37: ep_len:323 episode reward: total was 32.000000. running mean: -13.718661\n",
      "ep 37: ep_len:1300 episode reward: total was -10.720000. running mean: -13.688675\n",
      "ep 37: ep_len:500 episode reward: total was 21.840000. running mean: -13.333388\n",
      "ep 37: ep_len:505 episode reward: total was -21.260000. running mean: -13.412654\n",
      "ep 37: ep_len:670 episode reward: total was 28.760000. running mean: -12.990928\n",
      "ep 37: ep_len:226 episode reward: total was 21.000000. running mean: -12.651018\n",
      "ep 37: ep_len:500 episode reward: total was 19.400000. running mean: -12.330508\n",
      "ep 37: ep_len:765 episode reward: total was -38.400000. running mean: -12.591203\n",
      "ep 37: ep_len:500 episode reward: total was 27.290000. running mean: -12.192391\n",
      "ep 37: ep_len:500 episode reward: total was -4.770000. running mean: -12.118167\n",
      "ep 37: ep_len:630 episode reward: total was -21.010000. running mean: -12.207085\n",
      "ep 37: ep_len:224 episode reward: total was 19.000000. running mean: -11.895015\n",
      "ep 37: ep_len:320 episode reward: total was 23.500000. running mean: -11.541064\n",
      "ep 37: ep_len:500 episode reward: total was -54.900000. running mean: -11.974654\n",
      "ep 37: ep_len:500 episode reward: total was 8.150000. running mean: -11.773407\n",
      "ep 37: ep_len:560 episode reward: total was -6.000000. running mean: -11.715673\n",
      "ep 37: ep_len:750 episode reward: total was -19.470000. running mean: -11.793216\n",
      "ep 37: ep_len:135 episode reward: total was 10.500000. running mean: -11.570284\n",
      "ep 37: ep_len:500 episode reward: total was 25.450000. running mean: -11.200081\n",
      "ep 37: ep_len:271 episode reward: total was 27.000000. running mean: -10.818081\n",
      "ep 37: ep_len:505 episode reward: total was -2.070000. running mean: -10.730600\n",
      "ep 37: ep_len:395 episode reward: total was 36.500000. running mean: -10.258294\n",
      "ep 37: ep_len:500 episode reward: total was 4.790000. running mean: -10.107811\n",
      "ep 37: ep_len:800 episode reward: total was -5.520000. running mean: -10.061933\n",
      "ep 37: ep_len:805 episode reward: total was -3.490000. running mean: -9.996213\n",
      "ep 37: ep_len:500 episode reward: total was 11.860000. running mean: -9.777651\n",
      "ep 37: ep_len:500 episode reward: total was 17.400000. running mean: -9.505875\n",
      "ep 37: ep_len:1865 episode reward: total was -116.510000. running mean: -10.575916\n",
      "ep 37: ep_len:870 episode reward: total was -7.400000. running mean: -10.544157\n",
      "ep 37: ep_len:500 episode reward: total was 17.830000. running mean: -10.260415\n",
      "ep 37: ep_len:500 episode reward: total was 32.290000. running mean: -9.834911\n",
      "ep 37: ep_len:500 episode reward: total was 34.760000. running mean: -9.388962\n",
      "ep 37: ep_len:1070 episode reward: total was -46.670000. running mean: -9.761772\n",
      "ep 37: ep_len:1925 episode reward: total was -204.920000. running mean: -11.713355\n",
      "ep 37: ep_len:1025 episode reward: total was -6.140000. running mean: -11.657621\n",
      "ep 37: ep_len:500 episode reward: total was 8.770000. running mean: -11.453345\n",
      "ep 37: ep_len:660 episode reward: total was -9.840000. running mean: -11.437211\n",
      "ep 37: ep_len:960 episode reward: total was -15.000000. running mean: -11.472839\n",
      "ep 37: ep_len:2108 episode reward: total was -181.660000. running mean: -13.174711\n",
      "ep 37: ep_len:805 episode reward: total was -4.680000. running mean: -13.089764\n",
      "ep 37: ep_len:500 episode reward: total was -1.680000. running mean: -12.975666\n",
      "ep 37: ep_len:132 episode reward: total was 13.000000. running mean: -12.715910\n",
      "ep 37: ep_len:500 episode reward: total was 9.160000. running mean: -12.497150\n",
      "ep 37: ep_len:500 episode reward: total was 4.380000. running mean: -12.328379\n",
      "ep 37: ep_len:324 episode reward: total was 16.300000. running mean: -12.042095\n",
      "ep 37: ep_len:206 episode reward: total was 19.000000. running mean: -11.731674\n",
      "ep 37: ep_len:1015 episode reward: total was -73.770000. running mean: -12.352057\n",
      "ep 37: ep_len:520 episode reward: total was -12.140000. running mean: -12.349937\n",
      "ep 37: ep_len:550 episode reward: total was -76.720000. running mean: -12.993638\n",
      "ep 37: ep_len:180 episode reward: total was 17.000000. running mean: -12.693701\n",
      "ep 37: ep_len:500 episode reward: total was 17.370000. running mean: -12.393064\n",
      "ep 37: ep_len:500 episode reward: total was -2.600000. running mean: -12.295133\n",
      "ep 37: ep_len:1030 episode reward: total was -38.680000. running mean: -12.558982\n",
      "ep 37: ep_len:500 episode reward: total was 24.270000. running mean: -12.190692\n",
      "ep 37: ep_len:224 episode reward: total was 22.500000. running mean: -11.843785\n",
      "ep 37: ep_len:699 episode reward: total was -7.730000. running mean: -11.802648\n",
      "ep 37: ep_len:154 episode reward: total was 15.000000. running mean: -11.534621\n",
      "ep 37: ep_len:645 episode reward: total was -22.140000. running mean: -11.640675\n",
      "ep 37: ep_len:660 episode reward: total was -59.300000. running mean: -12.117268\n",
      "ep 37: ep_len:530 episode reward: total was -6.060000. running mean: -12.056695\n",
      "ep 37: ep_len:134 episode reward: total was 13.000000. running mean: -11.806128\n",
      "ep 37: ep_len:710 episode reward: total was -74.380000. running mean: -12.431867\n",
      "ep 37: ep_len:625 episode reward: total was -47.250000. running mean: -12.780049\n",
      "ep 37: ep_len:705 episode reward: total was 4.270000. running mean: -12.609548\n",
      "ep 37: ep_len:605 episode reward: total was -54.360000. running mean: -13.027053\n",
      "ep 37: ep_len:514 episode reward: total was -66.700000. running mean: -13.563782\n",
      "ep 37: ep_len:605 episode reward: total was -39.210000. running mean: -13.820244\n",
      "ep 37: ep_len:640 episode reward: total was -104.790000. running mean: -14.729942\n",
      "ep 37: ep_len:575 episode reward: total was 6.160000. running mean: -14.521042\n",
      "ep 37: ep_len:322 episode reward: total was 14.280000. running mean: -14.233032\n",
      "ep 37: ep_len:500 episode reward: total was 2.730000. running mean: -14.063402\n",
      "ep 37: ep_len:600 episode reward: total was -14.000000. running mean: -14.062768\n",
      "ep 37: ep_len:1355 episode reward: total was -138.110000. running mean: -15.303240\n",
      "ep 37: ep_len:475 episode reward: total was -56.210000. running mean: -15.712308\n",
      "ep 37: ep_len:500 episode reward: total was -89.000000. running mean: -16.445184\n",
      "ep 37: ep_len:175 episode reward: total was 16.000000. running mean: -16.120733\n",
      "ep 37: ep_len:580 episode reward: total was 6.780000. running mean: -15.891725\n",
      "ep 37: ep_len:1030 episode reward: total was -15.750000. running mean: -15.890308\n",
      "ep 37: ep_len:500 episode reward: total was -2.200000. running mean: -15.753405\n",
      "ep 37: ep_len:590 episode reward: total was -4.900000. running mean: -15.644871\n",
      "ep 37: ep_len:695 episode reward: total was -15.830000. running mean: -15.646722\n",
      "ep 37: ep_len:2490 episode reward: total was -159.710000. running mean: -17.087355\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 37: ep_len:500 episode reward: total was -6.910000. running mean: -16.985581\n",
      "ep 37: ep_len:500 episode reward: total was 20.830000. running mean: -16.607426\n",
      "ep 37: ep_len:765 episode reward: total was 31.250000. running mean: -16.128851\n",
      "ep 37: ep_len:500 episode reward: total was -16.220000. running mean: -16.129763\n",
      "ep 37: ep_len:500 episode reward: total was 7.940000. running mean: -15.889065\n",
      "ep 37: ep_len:735 episode reward: total was 8.820000. running mean: -15.641975\n",
      "ep 37: ep_len:500 episode reward: total was 8.650000. running mean: -15.399055\n",
      "ep 37: ep_len:1970 episode reward: total was -139.530000. running mean: -16.640364\n",
      "ep 37: ep_len:500 episode reward: total was 23.370000. running mean: -16.240261\n",
      "ep 37: ep_len:900 episode reward: total was 15.100000. running mean: -15.926858\n",
      "ep 37: ep_len:1530 episode reward: total was -18.380000. running mean: -15.951389\n",
      "ep 37: ep_len:650 episode reward: total was 5.830000. running mean: -15.733576\n",
      "ep 37: ep_len:815 episode reward: total was -26.910000. running mean: -15.845340\n",
      "ep 37: ep_len:740 episode reward: total was -18.770000. running mean: -15.874586\n",
      "ep 37: ep_len:1315 episode reward: total was -75.270000. running mean: -16.468541\n",
      "ep 37: ep_len:515 episode reward: total was 9.740000. running mean: -16.206455\n",
      "ep 37: ep_len:1970 episode reward: total was -161.530000. running mean: -17.659691\n",
      "ep 37: ep_len:500 episode reward: total was -5.200000. running mean: -17.535094\n",
      "ep 37: ep_len:500 episode reward: total was 8.820000. running mean: -17.271543\n",
      "ep 37: ep_len:1040 episode reward: total was -11.710000. running mean: -17.215927\n",
      "ep 37: ep_len:1462 episode reward: total was -254.190000. running mean: -19.585668\n",
      "ep 37: ep_len:500 episode reward: total was 21.320000. running mean: -19.176611\n",
      "ep 37: ep_len:190 episode reward: total was 14.500000. running mean: -18.839845\n",
      "ep 37: ep_len:755 episode reward: total was -1.570000. running mean: -18.667147\n",
      "ep 37: ep_len:1225 episode reward: total was -55.700000. running mean: -19.037475\n",
      "ep 37: ep_len:950 episode reward: total was 15.760000. running mean: -18.689501\n",
      "ep 37: ep_len:1706 episode reward: total was -298.610000. running mean: -21.488706\n",
      "ep 37: ep_len:500 episode reward: total was 31.300000. running mean: -20.960818\n",
      "ep 37: ep_len:1256 episode reward: total was -80.340000. running mean: -21.554610\n",
      "ep 37: ep_len:500 episode reward: total was -0.610000. running mean: -21.345164\n",
      "ep 37: ep_len:2043 episode reward: total was -103.990000. running mean: -22.171613\n",
      "ep 37: ep_len:1085 episode reward: total was -0.200000. running mean: -21.951896\n",
      "ep 37: ep_len:630 episode reward: total was 25.590000. running mean: -21.476477\n",
      "ep 37: ep_len:271 episode reward: total was 25.500000. running mean: -21.006713\n",
      "ep 37: ep_len:500 episode reward: total was 17.520000. running mean: -20.621446\n",
      "ep 37: ep_len:880 episode reward: total was 8.760000. running mean: -20.327631\n",
      "ep 37: ep_len:925 episode reward: total was -22.440000. running mean: -20.348755\n",
      "ep 37: ep_len:228 episode reward: total was 22.500000. running mean: -19.920267\n",
      "ep 37: ep_len:500 episode reward: total was -1.160000. running mean: -19.732665\n",
      "ep 37: ep_len:1010 episode reward: total was -3.640000. running mean: -19.571738\n",
      "ep 37: ep_len:880 episode reward: total was -2.080000. running mean: -19.396821\n",
      "ep 37: ep_len:1847 episode reward: total was -254.430000. running mean: -21.747152\n",
      "ep 37: ep_len:1485 episode reward: total was -11.070000. running mean: -21.640381\n",
      "ep 37: ep_len:1450 episode reward: total was -169.860000. running mean: -23.122577\n",
      "ep 37: ep_len:500 episode reward: total was 22.790000. running mean: -22.663451\n",
      "ep 37: ep_len:1020 episode reward: total was -94.430000. running mean: -23.381117\n",
      "ep 37: ep_len:695 episode reward: total was -4.160000. running mean: -23.188906\n",
      "ep 37: ep_len:500 episode reward: total was -4.680000. running mean: -23.003817\n",
      "ep 37: ep_len:915 episode reward: total was -8.320000. running mean: -22.856978\n",
      "ep 37: ep_len:655 episode reward: total was -17.930000. running mean: -22.807709\n",
      "ep 37: ep_len:760 episode reward: total was -12.070000. running mean: -22.700331\n",
      "ep 37: ep_len:730 episode reward: total was -1.620000. running mean: -22.489528\n",
      "ep 37: ep_len:811 episode reward: total was -19.730000. running mean: -22.461933\n",
      "ep 37: ep_len:212 episode reward: total was 19.500000. running mean: -22.042314\n",
      "ep 37: ep_len:755 episode reward: total was 0.880000. running mean: -21.813090\n",
      "ep 37: ep_len:665 episode reward: total was -33.060000. running mean: -21.925560\n",
      "ep 37: ep_len:500 episode reward: total was -9.730000. running mean: -21.803604\n",
      "ep 37: ep_len:500 episode reward: total was 9.190000. running mean: -21.493668\n",
      "ep 37: ep_len:820 episode reward: total was -36.270000. running mean: -21.641431\n",
      "ep 37: ep_len:500 episode reward: total was 13.630000. running mean: -21.288717\n",
      "ep 37: ep_len:500 episode reward: total was -4.910000. running mean: -21.124930\n",
      "ep 37: ep_len:525 episode reward: total was 21.920000. running mean: -20.694480\n",
      "ep 37: ep_len:870 episode reward: total was -38.220000. running mean: -20.869736\n",
      "ep 37: ep_len:815 episode reward: total was 0.880000. running mean: -20.652238\n",
      "ep 37: ep_len:615 episode reward: total was 3.210000. running mean: -20.413616\n",
      "ep 37: ep_len:575 episode reward: total was -20.110000. running mean: -20.410580\n",
      "ep 37: ep_len:10 episode reward: total was -0.500000. running mean: -20.211474\n",
      "ep 37: ep_len:530 episode reward: total was -11.110000. running mean: -20.120459\n",
      "ep 37: ep_len:500 episode reward: total was 10.600000. running mean: -19.813255\n",
      "ep 37: ep_len:710 episode reward: total was -0.650000. running mean: -19.621622\n",
      "ep 37: ep_len:500 episode reward: total was 7.300000. running mean: -19.352406\n",
      "ep 37: ep_len:630 episode reward: total was -25.050000. running mean: -19.409382\n",
      "ep 37: ep_len:500 episode reward: total was 6.830000. running mean: -19.146988\n",
      "ep 37: ep_len:500 episode reward: total was 20.900000. running mean: -18.746518\n",
      "ep 37: ep_len:500 episode reward: total was 20.310000. running mean: -18.355953\n",
      "ep 37: ep_len:740 episode reward: total was 5.780000. running mean: -18.114593\n",
      "ep 37: ep_len:500 episode reward: total was 19.850000. running mean: -17.734947\n",
      "ep 37: ep_len:259 episode reward: total was 25.500000. running mean: -17.302598\n",
      "ep 37: ep_len:510 episode reward: total was 9.520000. running mean: -17.034372\n",
      "ep 37: ep_len:830 episode reward: total was 15.210000. running mean: -16.711928\n",
      "ep 37: ep_len:500 episode reward: total was 15.160000. running mean: -16.393209\n",
      "ep 37: ep_len:500 episode reward: total was 0.230000. running mean: -16.226977\n",
      "ep 37: ep_len:840 episode reward: total was -5.100000. running mean: -16.115707\n",
      "ep 37: ep_len:515 episode reward: total was -9.120000. running mean: -16.045750\n",
      "ep 37: ep_len:675 episode reward: total was -28.460000. running mean: -16.169893\n",
      "ep 37: ep_len:500 episode reward: total was 13.000000. running mean: -15.878194\n",
      "ep 37: ep_len:920 episode reward: total was -35.580000. running mean: -16.075212\n",
      "ep 37: ep_len:673 episode reward: total was -68.380000. running mean: -16.598260\n",
      "ep 37: ep_len:500 episode reward: total was 18.750000. running mean: -16.244777\n",
      "ep 37: ep_len:680 episode reward: total was 11.400000. running mean: -15.968329\n",
      "ep 37: ep_len:500 episode reward: total was 0.310000. running mean: -15.805546\n",
      "ep 37: ep_len:500 episode reward: total was -1.680000. running mean: -15.664290\n",
      "ep 37: ep_len:720 episode reward: total was 3.240000. running mean: -15.475248\n",
      "ep 37: ep_len:500 episode reward: total was 5.330000. running mean: -15.267195\n",
      "ep 37: ep_len:500 episode reward: total was 17.370000. running mean: -14.940823\n",
      "ep 37: ep_len:505 episode reward: total was 10.790000. running mean: -14.683515\n",
      "ep 37: ep_len:319 episode reward: total was 32.000000. running mean: -14.216680\n",
      "ep 37: ep_len:205 episode reward: total was 19.500000. running mean: -13.879513\n",
      "ep 37: ep_len:182 episode reward: total was 17.000000. running mean: -13.570718\n",
      "ep 37: ep_len:500 episode reward: total was -6.240000. running mean: -13.497411\n",
      "ep 37: ep_len:510 episode reward: total was -19.200000. running mean: -13.554437\n",
      "ep 37: ep_len:875 episode reward: total was 13.600000. running mean: -13.282892\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 37: ep_len:570 episode reward: total was -0.930000. running mean: -13.159363\n",
      "ep 37: ep_len:500 episode reward: total was -6.360000. running mean: -13.091370\n",
      "ep 37: ep_len:188 episode reward: total was 18.500000. running mean: -12.775456\n",
      "ep 37: ep_len:500 episode reward: total was 27.440000. running mean: -12.373301\n",
      "ep 37: ep_len:1040 episode reward: total was 27.350000. running mean: -11.976068\n",
      "ep 37: ep_len:500 episode reward: total was 28.270000. running mean: -11.573608\n",
      "ep 37: ep_len:760 episode reward: total was -6.610000. running mean: -11.523972\n",
      "ep 37: ep_len:500 episode reward: total was 4.300000. running mean: -11.365732\n",
      "ep 37: ep_len:985 episode reward: total was -15.250000. running mean: -11.404575\n",
      "ep 37: ep_len:625 episode reward: total was -11.930000. running mean: -11.409829\n",
      "ep 37: ep_len:500 episode reward: total was 29.440000. running mean: -11.001331\n",
      "ep 37: ep_len:475 episode reward: total was 27.300000. running mean: -10.618317\n",
      "ep 37: ep_len:890 episode reward: total was -31.600000. running mean: -10.828134\n",
      "ep 37: ep_len:500 episode reward: total was 16.690000. running mean: -10.552953\n",
      "ep 37: ep_len:880 episode reward: total was 7.320000. running mean: -10.374223\n",
      "ep 37: ep_len:1194 episode reward: total was -116.830000. running mean: -11.438781\n",
      "ep 37: ep_len:640 episode reward: total was -42.200000. running mean: -11.746393\n",
      "ep 37: ep_len:500 episode reward: total was -0.660000. running mean: -11.635529\n",
      "ep 37: ep_len:2841 episode reward: total was -420.760000. running mean: -15.726774\n",
      "ep 37: ep_len:635 episode reward: total was -9.400000. running mean: -15.663506\n",
      "ep 37: ep_len:575 episode reward: total was 27.080000. running mean: -15.236071\n",
      "ep 37: ep_len:825 episode reward: total was -15.570000. running mean: -15.239410\n",
      "ep 37: ep_len:450 episode reward: total was -21.030000. running mean: -15.297316\n",
      "ep 37: ep_len:923 episode reward: total was -139.220000. running mean: -16.536543\n",
      "ep 37: ep_len:885 episode reward: total was 15.940000. running mean: -16.211778\n",
      "ep 37: ep_len:500 episode reward: total was 16.420000. running mean: -15.885460\n",
      "ep 37: ep_len:800 episode reward: total was -21.680000. running mean: -15.943405\n",
      "ep 37: ep_len:500 episode reward: total was 19.360000. running mean: -15.590371\n",
      "ep 37: ep_len:500 episode reward: total was 31.290000. running mean: -15.121568\n",
      "ep 37: ep_len:925 episode reward: total was -16.990000. running mean: -15.140252\n",
      "ep 37: ep_len:1835 episode reward: total was -174.460000. running mean: -16.733449\n",
      "ep 37: ep_len:500 episode reward: total was 15.650000. running mean: -16.409615\n",
      "ep 37: ep_len:346 episode reward: total was 32.000000. running mean: -15.925519\n",
      "ep 37: ep_len:640 episode reward: total was -19.300000. running mean: -15.959264\n",
      "ep 37: ep_len:500 episode reward: total was 1.180000. running mean: -15.787871\n",
      "ep 37: ep_len:980 episode reward: total was -117.500000. running mean: -16.804992\n",
      "ep 37: ep_len:575 episode reward: total was -0.640000. running mean: -16.643342\n",
      "ep 37: ep_len:500 episode reward: total was -3.900000. running mean: -16.515909\n",
      "ep 37: ep_len:765 episode reward: total was 8.170000. running mean: -16.269050\n",
      "ep 37: ep_len:680 episode reward: total was 7.690000. running mean: -16.029459\n",
      "ep 37: ep_len:765 episode reward: total was -9.630000. running mean: -15.965465\n",
      "ep 37: ep_len:2077 episode reward: total was -367.490000. running mean: -19.480710\n",
      "ep 37: ep_len:650 episode reward: total was -17.450000. running mean: -19.460403\n",
      "ep 37: ep_len:500 episode reward: total was 12.190000. running mean: -19.143899\n",
      "ep 37: ep_len:500 episode reward: total was 26.740000. running mean: -18.685060\n",
      "ep 37: ep_len:1515 episode reward: total was -58.630000. running mean: -19.084509\n",
      "ep 37: ep_len:500 episode reward: total was -6.880000. running mean: -18.962464\n",
      "ep 37: ep_len:283 episode reward: total was 25.000000. running mean: -18.522840\n",
      "ep 37: ep_len:1545 episode reward: total was -105.270000. running mean: -19.390311\n",
      "ep 37: ep_len:1330 episode reward: total was -41.170000. running mean: -19.608108\n",
      "ep 37: ep_len:500 episode reward: total was 8.920000. running mean: -19.322827\n",
      "ep 37: ep_len:500 episode reward: total was 1.200000. running mean: -19.117599\n",
      "ep 37: ep_len:705 episode reward: total was -1.670000. running mean: -18.943123\n",
      "ep 37: ep_len:500 episode reward: total was 21.780000. running mean: -18.535891\n",
      "ep 37: ep_len:327 episode reward: total was -19.240000. running mean: -18.542933\n",
      "ep 37: ep_len:500 episode reward: total was -3.360000. running mean: -18.391103\n",
      "ep 37: ep_len:500 episode reward: total was -27.600000. running mean: -18.483192\n",
      "ep 37: ep_len:480 episode reward: total was 47.000000. running mean: -17.828360\n",
      "ep 37: ep_len:500 episode reward: total was -2.040000. running mean: -17.670477\n",
      "ep 37: ep_len:590 episode reward: total was 26.860000. running mean: -17.225172\n",
      "ep 37: ep_len:500 episode reward: total was 17.460000. running mean: -16.878320\n",
      "ep 37: ep_len:500 episode reward: total was 19.180000. running mean: -16.517737\n",
      "ep 37: ep_len:500 episode reward: total was -22.860000. running mean: -16.581160\n",
      "ep 37: ep_len:505 episode reward: total was 6.670000. running mean: -16.348648\n",
      "ep 37: ep_len:2300 episode reward: total was -305.500000. running mean: -19.240162\n",
      "ep 37: ep_len:1212 episode reward: total was -133.960000. running mean: -20.387360\n",
      "ep 37: ep_len:500 episode reward: total was 18.010000. running mean: -20.003386\n",
      "ep 37: ep_len:500 episode reward: total was -11.500000. running mean: -19.918352\n",
      "ep 37: ep_len:785 episode reward: total was -23.210000. running mean: -19.951269\n",
      "ep 37: ep_len:114 episode reward: total was 11.000000. running mean: -19.641756\n",
      "ep 37: ep_len:167 episode reward: total was 16.500000. running mean: -19.280339\n",
      "ep 37: ep_len:500 episode reward: total was 27.730000. running mean: -18.810235\n",
      "ep 37: ep_len:770 episode reward: total was -19.720000. running mean: -18.819333\n",
      "ep 37: ep_len:795 episode reward: total was -3.460000. running mean: -18.665740\n",
      "ep 37: ep_len:510 episode reward: total was -4.080000. running mean: -18.519882\n",
      "ep 37: ep_len:750 episode reward: total was -8.360000. running mean: -18.418283\n",
      "ep 37: ep_len:195 episode reward: total was 18.000000. running mean: -18.054101\n",
      "ep 37: ep_len:510 episode reward: total was -67.710000. running mean: -18.550660\n",
      "ep 37: ep_len:125 episode reward: total was 11.000000. running mean: -18.255153\n",
      "ep 37: ep_len:125 episode reward: total was 11.000000. running mean: -17.962601\n",
      "ep 37: ep_len:670 episode reward: total was 22.180000. running mean: -17.561175\n",
      "ep 37: ep_len:1059 episode reward: total was -126.190000. running mean: -18.647464\n",
      "ep 37: ep_len:266 episode reward: total was 24.000000. running mean: -18.220989\n",
      "ep 37: ep_len:500 episode reward: total was 14.220000. running mean: -17.896579\n",
      "ep 37: ep_len:130 episode reward: total was 11.500000. running mean: -17.602613\n",
      "ep 37: ep_len:505 episode reward: total was -1.510000. running mean: -17.441687\n",
      "ep 37: ep_len:850 episode reward: total was -117.340000. running mean: -18.440670\n",
      "ep 37: ep_len:72 episode reward: total was 7.000000. running mean: -18.186264\n",
      "ep 37: ep_len:500 episode reward: total was 6.220000. running mean: -17.942201\n",
      "ep 37: ep_len:870 episode reward: total was -2.040000. running mean: -17.783179\n",
      "ep 37: ep_len:500 episode reward: total was 1.380000. running mean: -17.591547\n",
      "ep 37: ep_len:203 episode reward: total was 20.000000. running mean: -17.215632\n",
      "ep 37: ep_len:705 episode reward: total was 43.350000. running mean: -16.609975\n",
      "ep 37: ep_len:306 episode reward: total was 29.000000. running mean: -16.153876\n",
      "ep 37: ep_len:770 episode reward: total was -127.790000. running mean: -17.270237\n",
      "ep 37: ep_len:775 episode reward: total was 15.200000. running mean: -16.945535\n",
      "ep 37: ep_len:910 episode reward: total was -136.600000. running mean: -18.142079\n",
      "ep 37: ep_len:675 episode reward: total was -4.760000. running mean: -18.008258\n",
      "ep 37: ep_len:500 episode reward: total was 18.590000. running mean: -17.642276\n",
      "ep 37: ep_len:605 episode reward: total was -3.090000. running mean: -17.496753\n",
      "ep 37: ep_len:500 episode reward: total was 2.740000. running mean: -17.294386\n",
      "ep 37: ep_len:500 episode reward: total was -8.140000. running mean: -17.202842\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 37: ep_len:500 episode reward: total was 0.660000. running mean: -17.024213\n",
      "ep 37: ep_len:166 episode reward: total was 16.500000. running mean: -16.688971\n",
      "ep 37: ep_len:745 episode reward: total was -29.870000. running mean: -16.820781\n",
      "ep 37: ep_len:1485 episode reward: total was -33.790000. running mean: -16.990474\n",
      "ep 37: ep_len:500 episode reward: total was 15.650000. running mean: -16.664069\n",
      "ep 37: ep_len:500 episode reward: total was -4.100000. running mean: -16.538428\n",
      "ep 37: ep_len:500 episode reward: total was 4.420000. running mean: -16.328844\n",
      "ep 37: ep_len:500 episode reward: total was 19.420000. running mean: -15.971355\n",
      "ep 37: ep_len:500 episode reward: total was -15.820000. running mean: -15.969842\n",
      "ep 37: ep_len:500 episode reward: total was -14.290000. running mean: -15.953043\n",
      "ep 37: ep_len:500 episode reward: total was 12.710000. running mean: -15.666413\n",
      "ep 37: ep_len:520 episode reward: total was 22.340000. running mean: -15.286349\n",
      "ep 37: ep_len:310 episode reward: total was 28.000000. running mean: -14.853485\n",
      "ep 37: ep_len:500 episode reward: total was 1.770000. running mean: -14.687251\n",
      "ep 37: ep_len:865 episode reward: total was 2.010000. running mean: -14.520278\n",
      "ep 37: ep_len:855 episode reward: total was 2.480000. running mean: -14.350275\n",
      "ep 37: ep_len:500 episode reward: total was 26.220000. running mean: -13.944573\n",
      "ep 37: ep_len:905 episode reward: total was 10.280000. running mean: -13.702327\n",
      "ep 37: ep_len:500 episode reward: total was 25.420000. running mean: -13.311104\n",
      "ep 37: ep_len:500 episode reward: total was 26.740000. running mean: -12.910593\n",
      "ep 37: ep_len:550 episode reward: total was 8.960000. running mean: -12.691887\n",
      "ep 37: ep_len:940 episode reward: total was -42.610000. running mean: -12.991068\n",
      "ep 37: ep_len:520 episode reward: total was -31.300000. running mean: -13.174157\n",
      "ep 37: ep_len:1075 episode reward: total was 24.800000. running mean: -12.794415\n",
      "ep 37: ep_len:330 episode reward: total was -8.260000. running mean: -12.749071\n",
      "ep 37: ep_len:896 episode reward: total was -92.170000. running mean: -13.543281\n",
      "ep 37: ep_len:750 episode reward: total was -31.880000. running mean: -13.726648\n",
      "ep 37: ep_len:540 episode reward: total was 22.870000. running mean: -13.360681\n",
      "ep 37: ep_len:214 episode reward: total was 21.000000. running mean: -13.017075\n",
      "ep 37: ep_len:665 episode reward: total was 6.650000. running mean: -12.820404\n",
      "ep 37: ep_len:500 episode reward: total was 27.380000. running mean: -12.418400\n",
      "ep 37: ep_len:500 episode reward: total was 47.000000. running mean: -11.824216\n",
      "ep 37: ep_len:825 episode reward: total was 14.650000. running mean: -11.559474\n",
      "ep 37: ep_len:745 episode reward: total was -5.110000. running mean: -11.494979\n",
      "ep 37: ep_len:170 episode reward: total was 15.500000. running mean: -11.225029\n",
      "ep 37: ep_len:790 episode reward: total was -2.030000. running mean: -11.133079\n",
      "ep 37: ep_len:700 episode reward: total was 14.250000. running mean: -10.879248\n",
      "ep 37: ep_len:855 episode reward: total was -2.620000. running mean: -10.796655\n",
      "ep 37: ep_len:745 episode reward: total was -3.050000. running mean: -10.719189\n",
      "ep 37: ep_len:500 episode reward: total was 14.030000. running mean: -10.471697\n",
      "ep 37: ep_len:186 episode reward: total was 18.500000. running mean: -10.181980\n",
      "ep 37: ep_len:500 episode reward: total was 37.220000. running mean: -9.707960\n",
      "ep 37: ep_len:505 episode reward: total was -11.130000. running mean: -9.722181\n",
      "ep 37: ep_len:203 episode reward: total was 20.000000. running mean: -9.424959\n",
      "ep 37: ep_len:500 episode reward: total was 19.020000. running mean: -9.140509\n",
      "ep 37: ep_len:725 episode reward: total was 0.760000. running mean: -9.041504\n",
      "ep 37: ep_len:1865 episode reward: total was -190.240000. running mean: -10.853489\n",
      "ep 37: ep_len:870 episode reward: total was -18.510000. running mean: -10.930054\n",
      "ep 37: ep_len:500 episode reward: total was 12.440000. running mean: -10.696354\n",
      "ep 37: ep_len:765 episode reward: total was -8.620000. running mean: -10.675590\n",
      "ep 37: ep_len:705 episode reward: total was -15.810000. running mean: -10.726934\n",
      "ep 37: ep_len:500 episode reward: total was -12.240000. running mean: -10.742065\n",
      "ep 37: ep_len:605 episode reward: total was -21.060000. running mean: -10.845244\n",
      "ep 37: ep_len:680 episode reward: total was -0.710000. running mean: -10.743892\n",
      "ep 37: ep_len:550 episode reward: total was -4.000000. running mean: -10.676453\n",
      "ep 37: ep_len:650 episode reward: total was 27.650000. running mean: -10.293188\n",
      "ep 37: ep_len:500 episode reward: total was 21.810000. running mean: -9.972156\n",
      "ep 37: ep_len:500 episode reward: total was -28.210000. running mean: -10.154535\n",
      "ep 37: ep_len:605 episode reward: total was 15.730000. running mean: -9.895690\n",
      "ep 37: ep_len:500 episode reward: total was -10.250000. running mean: -9.899233\n",
      "ep 37: ep_len:1345 episode reward: total was -138.910000. running mean: -11.189340\n",
      "ep 37: ep_len:1035 episode reward: total was -16.010000. running mean: -11.237547\n",
      "ep 37: ep_len:565 episode reward: total was -36.290000. running mean: -11.488071\n",
      "ep 37: ep_len:685 episode reward: total was -3.730000. running mean: -11.410491\n",
      "ep 37: ep_len:585 episode reward: total was 29.310000. running mean: -11.003286\n",
      "ep 37: ep_len:500 episode reward: total was 2.800000. running mean: -10.865253\n",
      "ep 37: ep_len:500 episode reward: total was 22.800000. running mean: -10.528600\n",
      "ep 37: ep_len:580 episode reward: total was -16.060000. running mean: -10.583914\n",
      "ep 37: ep_len:500 episode reward: total was 25.480000. running mean: -10.223275\n",
      "ep 37: ep_len:595 episode reward: total was -19.030000. running mean: -10.311343\n",
      "ep 37: ep_len:825 episode reward: total was -19.610000. running mean: -10.404329\n",
      "ep 37: ep_len:500 episode reward: total was 24.760000. running mean: -10.052686\n",
      "ep 37: ep_len:695 episode reward: total was -15.830000. running mean: -10.110459\n",
      "ep 37: ep_len:740 episode reward: total was -9.680000. running mean: -10.106154\n",
      "ep 37: ep_len:590 episode reward: total was 2.460000. running mean: -9.980493\n",
      "ep 37: ep_len:500 episode reward: total was 16.270000. running mean: -9.717988\n",
      "ep 37: ep_len:500 episode reward: total was 6.190000. running mean: -9.558908\n",
      "ep 37: ep_len:500 episode reward: total was 20.980000. running mean: -9.253519\n",
      "ep 37: ep_len:895 episode reward: total was -32.600000. running mean: -9.486984\n",
      "ep 37: ep_len:500 episode reward: total was 12.440000. running mean: -9.267714\n",
      "ep 37: ep_len:500 episode reward: total was 21.780000. running mean: -8.957237\n",
      "ep 37: ep_len:630 episode reward: total was -7.880000. running mean: -8.946464\n",
      "ep 37: ep_len:500 episode reward: total was 15.780000. running mean: -8.699200\n",
      "ep 37: ep_len:660 episode reward: total was 36.890000. running mean: -8.243308\n",
      "ep 37: ep_len:485 episode reward: total was 24.170000. running mean: -7.919175\n",
      "ep 37: ep_len:545 episode reward: total was 12.220000. running mean: -7.717783\n",
      "ep 37: ep_len:500 episode reward: total was 48.500000. running mean: -7.155605\n",
      "ep 37: ep_len:810 episode reward: total was -16.640000. running mean: -7.250449\n",
      "ep 37: ep_len:795 episode reward: total was -23.000000. running mean: -7.407945\n",
      "ep 37: ep_len:500 episode reward: total was -5.990000. running mean: -7.393765\n",
      "ep 37: ep_len:855 episode reward: total was 5.510000. running mean: -7.264728\n",
      "ep 37: ep_len:505 episode reward: total was -11.770000. running mean: -7.309780\n",
      "ep 37: ep_len:500 episode reward: total was 28.270000. running mean: -6.953982\n",
      "ep 37: ep_len:500 episode reward: total was 35.280000. running mean: -6.531643\n",
      "ep 37: ep_len:735 episode reward: total was -17.770000. running mean: -6.644026\n",
      "ep 37: ep_len:845 episode reward: total was 18.430000. running mean: -6.393286\n",
      "ep 37: ep_len:500 episode reward: total was -13.280000. running mean: -6.462153\n",
      "ep 37: ep_len:925 episode reward: total was -25.700000. running mean: -6.654532\n",
      "ep 37: ep_len:500 episode reward: total was -18.880000. running mean: -6.776786\n",
      "ep 37: ep_len:1836 episode reward: total was -171.050000. running mean: -8.419518\n",
      "ep 37: ep_len:500 episode reward: total was 19.850000. running mean: -8.136823\n",
      "ep 37: ep_len:500 episode reward: total was -14.780000. running mean: -8.203255\n",
      "ep 37: ep_len:500 episode reward: total was -19.310000. running mean: -8.314322\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 37: ep_len:620 episode reward: total was -42.240000. running mean: -8.653579\n",
      "ep 37: ep_len:600 episode reward: total was -39.250000. running mean: -8.959543\n",
      "ep 37: ep_len:500 episode reward: total was 28.790000. running mean: -8.582048\n",
      "ep 37: ep_len:700 episode reward: total was -15.820000. running mean: -8.654427\n",
      "ep 37: ep_len:225 episode reward: total was 21.000000. running mean: -8.357883\n",
      "ep 37: ep_len:565 episode reward: total was -17.100000. running mean: -8.445304\n",
      "ep 37: ep_len:1175 episode reward: total was -178.140000. running mean: -10.142251\n",
      "ep 37: ep_len:845 episode reward: total was 10.020000. running mean: -9.940629\n",
      "ep 37: ep_len:645 episode reward: total was -23.000000. running mean: -10.071223\n",
      "ep 37: ep_len:865 episode reward: total was 11.240000. running mean: -9.858110\n",
      "ep 37: ep_len:269 episode reward: total was 26.500000. running mean: -9.494529\n",
      "ep 37: ep_len:607 episode reward: total was -87.720000. running mean: -10.276784\n",
      "ep 37: ep_len:800 episode reward: total was 7.240000. running mean: -10.101616\n",
      "ep 37: ep_len:1465 episode reward: total was -231.410000. running mean: -12.314700\n",
      "ep 37: ep_len:500 episode reward: total was 7.140000. running mean: -12.120153\n",
      "ep 37: ep_len:4310 episode reward: total was -744.500000. running mean: -19.443951\n",
      "ep 37: ep_len:855 episode reward: total was 25.220000. running mean: -18.997312\n",
      "ep 37: ep_len:635 episode reward: total was -8.880000. running mean: -18.896139\n",
      "ep 37: ep_len:500 episode reward: total was 21.290000. running mean: -18.494277\n",
      "ep 37: ep_len:4730 episode reward: total was -721.230000. running mean: -25.521635\n",
      "ep 37: ep_len:500 episode reward: total was 26.770000. running mean: -24.998718\n",
      "ep 37: ep_len:147 episode reward: total was 14.500000. running mean: -24.603731\n",
      "ep 37: ep_len:329 episode reward: total was 8.090000. running mean: -24.276794\n",
      "ep 37: ep_len:895 episode reward: total was 26.180000. running mean: -23.772226\n",
      "ep 37: ep_len:181 episode reward: total was 16.500000. running mean: -23.369504\n",
      "ep 37: ep_len:900 episode reward: total was -22.490000. running mean: -23.360708\n",
      "ep 37: ep_len:8890 episode reward: total was -1547.600000. running mean: -38.603101\n",
      "ep 37: ep_len:1045 episode reward: total was 19.810000. running mean: -38.018970\n",
      "ep 37: ep_len:500 episode reward: total was 7.820000. running mean: -37.560581\n",
      "ep 37: ep_len:555 episode reward: total was -19.140000. running mean: -37.376375\n",
      "ep 37: ep_len:259 episode reward: total was 25.500000. running mean: -36.747611\n",
      "ep 37: ep_len:550 episode reward: total was -16.120000. running mean: -36.541335\n",
      "ep 37: ep_len:760 episode reward: total was 28.180000. running mean: -35.894122\n",
      "ep 37: ep_len:820 episode reward: total was -5.260000. running mean: -35.587780\n",
      "ep 37: ep_len:500 episode reward: total was 1.660000. running mean: -35.215303\n",
      "ep 37: ep_len:500 episode reward: total was -12.010000. running mean: -34.983250\n",
      "ep 37: ep_len:625 episode reward: total was 10.700000. running mean: -34.526417\n",
      "ep 37: ep_len:1010 episode reward: total was -83.880000. running mean: -35.019953\n",
      "ep 37: ep_len:600 episode reward: total was -15.010000. running mean: -34.819853\n",
      "ep 37: ep_len:925 episode reward: total was 1.950000. running mean: -34.452155\n",
      "ep 37: ep_len:500 episode reward: total was -14.350000. running mean: -34.251133\n",
      "ep 37: ep_len:1195 episode reward: total was -87.550000. running mean: -34.784122\n",
      "ep 37: ep_len:605 episode reward: total was -23.080000. running mean: -34.667081\n",
      "ep 37: ep_len:500 episode reward: total was -8.430000. running mean: -34.404710\n",
      "ep 37: ep_len:392 episode reward: total was 39.000000. running mean: -33.670663\n",
      "ep 37: ep_len:404 episode reward: total was 4.740000. running mean: -33.286556\n",
      "ep 37: ep_len:500 episode reward: total was 30.810000. running mean: -32.645591\n",
      "ep 37: ep_len:500 episode reward: total was 33.780000. running mean: -31.981335\n",
      "ep 37: ep_len:1296 episode reward: total was -72.090000. running mean: -32.382421\n",
      "ep 37: ep_len:1402 episode reward: total was -161.440000. running mean: -33.672997\n",
      "ep 37: ep_len:635 episode reward: total was 20.300000. running mean: -33.133267\n",
      "ep 37: ep_len:500 episode reward: total was -21.880000. running mean: -33.020735\n",
      "ep 37: ep_len:500 episode reward: total was -27.420000. running mean: -32.964727\n",
      "ep 37: ep_len:570 episode reward: total was -1.110000. running mean: -32.646180\n",
      "ep 37: ep_len:600 episode reward: total was 20.570000. running mean: -32.114018\n",
      "ep 37: ep_len:1561 episode reward: total was -224.480000. running mean: -34.037678\n",
      "ep 37: ep_len:1255 episode reward: total was -51.070000. running mean: -34.208001\n",
      "ep 37: ep_len:545 episode reward: total was 0.830000. running mean: -33.857621\n",
      "ep 37: ep_len:615 episode reward: total was -23.060000. running mean: -33.749645\n",
      "ep 37: ep_len:940 episode reward: total was -54.680000. running mean: -33.958949\n",
      "ep 37: ep_len:675 episode reward: total was 10.040000. running mean: -33.518959\n",
      "ep 37: ep_len:500 episode reward: total was -5.430000. running mean: -33.238069\n",
      "ep 37: ep_len:690 episode reward: total was -75.500000. running mean: -33.660689\n",
      "ep 37: ep_len:505 episode reward: total was 20.870000. running mean: -33.115382\n",
      "ep 37: ep_len:500 episode reward: total was -12.650000. running mean: -32.910728\n",
      "ep 37: ep_len:471 episode reward: total was 26.770000. running mean: -32.313921\n",
      "ep 37: ep_len:1020 episode reward: total was -6.380000. running mean: -32.054582\n",
      "ep 37: ep_len:500 episode reward: total was -10.380000. running mean: -31.837836\n",
      "ep 37: ep_len:710 episode reward: total was 18.890000. running mean: -31.330557\n",
      "ep 37: ep_len:300 episode reward: total was 29.500000. running mean: -30.722252\n",
      "ep 37: ep_len:500 episode reward: total was -1.220000. running mean: -30.427229\n",
      "ep 37: ep_len:725 episode reward: total was -50.110000. running mean: -30.624057\n",
      "ep 37: ep_len:1055 episode reward: total was -81.790000. running mean: -31.135716\n",
      "ep 37: ep_len:625 episode reward: total was -57.380000. running mean: -31.398159\n",
      "ep 37: ep_len:545 episode reward: total was 20.950000. running mean: -30.874678\n",
      "ep 37: ep_len:605 episode reward: total was -27.870000. running mean: -30.844631\n",
      "ep 37: ep_len:1020 episode reward: total was -1.820000. running mean: -30.554385\n",
      "ep 37: ep_len:146 episode reward: total was 10.000000. running mean: -30.148841\n",
      "ep 37: ep_len:500 episode reward: total was 11.740000. running mean: -29.729952\n",
      "ep 37: ep_len:1000 episode reward: total was 11.670000. running mean: -29.315953\n",
      "ep 37: ep_len:565 episode reward: total was -5.710000. running mean: -29.079893\n",
      "ep 37: ep_len:335 episode reward: total was 32.500000. running mean: -28.464094\n",
      "ep 37: ep_len:835 episode reward: total was -2.230000. running mean: -28.201753\n",
      "ep 37: ep_len:500 episode reward: total was 26.400000. running mean: -27.655736\n",
      "ep 37: ep_len:500 episode reward: total was 2.760000. running mean: -27.351579\n",
      "ep 37: ep_len:500 episode reward: total was 26.340000. running mean: -26.814663\n",
      "ep 37: ep_len:625 episode reward: total was -1.240000. running mean: -26.558916\n",
      "ep 37: ep_len:500 episode reward: total was 17.260000. running mean: -26.120727\n",
      "ep 37: ep_len:153 episode reward: total was 15.000000. running mean: -25.709520\n",
      "ep 37: ep_len:500 episode reward: total was 30.230000. running mean: -25.150124\n",
      "ep 37: ep_len:447 episode reward: total was 23.840000. running mean: -24.660223\n",
      "ep 37: ep_len:500 episode reward: total was -65.710000. running mean: -25.070721\n",
      "ep 37: ep_len:159 episode reward: total was 15.500000. running mean: -24.665014\n",
      "ep 37: ep_len:530 episode reward: total was -15.150000. running mean: -24.569864\n",
      "ep 37: ep_len:500 episode reward: total was 25.280000. running mean: -24.071365\n",
      "ep 37: ep_len:500 episode reward: total was 15.290000. running mean: -23.677751\n",
      "ep 37: ep_len:500 episode reward: total was 11.460000. running mean: -23.326374\n",
      "ep 37: ep_len:2645 episode reward: total was -415.000000. running mean: -27.243110\n",
      "ep 37: ep_len:730 episode reward: total was 7.790000. running mean: -26.892779\n",
      "ep 37: ep_len:500 episode reward: total was 48.500000. running mean: -26.138851\n",
      "ep 37: ep_len:988 episode reward: total was -76.990000. running mean: -26.647363\n",
      "ep 37: ep_len:510 episode reward: total was -13.170000. running mean: -26.512589\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 37: ep_len:500 episode reward: total was -14.190000. running mean: -26.389363\n",
      "ep 37: ep_len:500 episode reward: total was -31.330000. running mean: -26.438770\n",
      "ep 37: ep_len:500 episode reward: total was 50.000000. running mean: -25.674382\n",
      "ep 37: ep_len:960 episode reward: total was 26.770000. running mean: -25.149938\n",
      "ep 37: ep_len:200 episode reward: total was 18.500000. running mean: -24.713439\n",
      "epsilon:0.010000 episode_count: 29977. steps_count: 21775576.000000\n",
      "ep 38: ep_len:2285 episode reward: total was -241.920000. running mean: -26.885504\n",
      "ep 38: ep_len:885 episode reward: total was -23.220000. running mean: -26.848849\n",
      "ep 38: ep_len:685 episode reward: total was -15.120000. running mean: -26.731561\n",
      "ep 38: ep_len:2794 episode reward: total was -416.960000. running mean: -30.633845\n",
      "ep 38: ep_len:500 episode reward: total was 5.330000. running mean: -30.274207\n",
      "ep 38: ep_len:500 episode reward: total was -10.580000. running mean: -30.077265\n",
      "ep 38: ep_len:500 episode reward: total was 1.540000. running mean: -29.761092\n",
      "ep 38: ep_len:500 episode reward: total was 16.270000. running mean: -29.300781\n",
      "ep 38: ep_len:800 episode reward: total was -25.720000. running mean: -29.264973\n",
      "ep 38: ep_len:965 episode reward: total was 13.140000. running mean: -28.840924\n",
      "ep 38: ep_len:540 episode reward: total was 12.240000. running mean: -28.430114\n",
      "ep 38: ep_len:1040 episode reward: total was 0.550000. running mean: -28.140313\n",
      "ep 38: ep_len:795 episode reward: total was 36.760000. running mean: -27.491310\n",
      "ep 38: ep_len:1374 episode reward: total was -73.120000. running mean: -27.947597\n",
      "ep 38: ep_len:795 episode reward: total was -29.770000. running mean: -27.965821\n",
      "ep 38: ep_len:500 episode reward: total was 36.260000. running mean: -27.323563\n",
      "ep 38: ep_len:925 episode reward: total was 22.640000. running mean: -26.823927\n",
      "ep 38: ep_len:635 episode reward: total was -21.000000. running mean: -26.765688\n",
      "ep 38: ep_len:725 episode reward: total was 10.900000. running mean: -26.389031\n",
      "ep 38: ep_len:500 episode reward: total was 2.800000. running mean: -26.097141\n",
      "ep 38: ep_len:1545 episode reward: total was -68.670000. running mean: -26.522869\n",
      "ep 38: ep_len:139 episode reward: total was 13.500000. running mean: -26.122641\n",
      "ep 38: ep_len:995 episode reward: total was -51.590000. running mean: -26.377314\n",
      "ep 38: ep_len:500 episode reward: total was -0.720000. running mean: -26.120741\n",
      "ep 38: ep_len:433 episode reward: total was 11.660000. running mean: -25.742934\n",
      "ep 38: ep_len:940 episode reward: total was -29.210000. running mean: -25.777604\n",
      "ep 38: ep_len:510 episode reward: total was -4.080000. running mean: -25.560628\n",
      "ep 38: ep_len:16390 episode reward: total was -2990.160000. running mean: -55.206622\n",
      "ep 38: ep_len:635 episode reward: total was -2.820000. running mean: -54.682756\n",
      "ep 38: ep_len:505 episode reward: total was -1.060000. running mean: -54.146528\n",
      "ep 38: ep_len:795 episode reward: total was -3.060000. running mean: -53.635663\n",
      "ep 38: ep_len:510 episode reward: total was -0.040000. running mean: -53.099706\n",
      "ep 38: ep_len:655 episode reward: total was -9.820000. running mean: -52.666909\n",
      "ep 38: ep_len:369 episode reward: total was 0.540000. running mean: -52.134840\n",
      "ep 38: ep_len:500 episode reward: total was 26.310000. running mean: -51.350392\n",
      "ep 38: ep_len:925 episode reward: total was 7.000000. running mean: -50.766888\n",
      "ep 38: ep_len:525 episode reward: total was -15.130000. running mean: -50.410519\n",
      "ep 38: ep_len:500 episode reward: total was 2.760000. running mean: -49.878814\n",
      "ep 38: ep_len:500 episode reward: total was 8.030000. running mean: -49.299726\n",
      "ep 38: ep_len:915 episode reward: total was 0.500000. running mean: -48.801728\n",
      "ep 38: ep_len:645 episode reward: total was 7.890000. running mean: -48.234811\n",
      "ep 38: ep_len:500 episode reward: total was 0.570000. running mean: -47.746763\n",
      "ep 38: ep_len:585 episode reward: total was 21.770000. running mean: -47.051595\n",
      "ep 38: ep_len:500 episode reward: total was 18.300000. running mean: -46.398079\n",
      "ep 38: ep_len:244 episode reward: total was 10.500000. running mean: -45.829099\n",
      "ep 38: ep_len:500 episode reward: total was -24.500000. running mean: -45.615808\n",
      "ep 38: ep_len:720 episode reward: total was -13.760000. running mean: -45.297249\n",
      "ep 38: ep_len:880 episode reward: total was -33.700000. running mean: -45.181277\n",
      "ep 38: ep_len:500 episode reward: total was 15.070000. running mean: -44.578764\n",
      "ep 38: ep_len:660 episode reward: total was -34.710000. running mean: -44.480077\n",
      "ep 38: ep_len:685 episode reward: total was -24.940000. running mean: -44.284676\n",
      "ep 38: ep_len:505 episode reward: total was 24.330000. running mean: -43.598529\n",
      "ep 38: ep_len:720 episode reward: total was -1.270000. running mean: -43.175244\n",
      "ep 38: ep_len:820 episode reward: total was 16.980000. running mean: -42.573691\n",
      "ep 38: ep_len:790 episode reward: total was -1.650000. running mean: -42.164454\n",
      "ep 38: ep_len:500 episode reward: total was -32.980000. running mean: -42.072610\n",
      "ep 38: ep_len:1280 episode reward: total was -173.230000. running mean: -43.384184\n",
      "ep 38: ep_len:775 episode reward: total was 4.630000. running mean: -42.904042\n",
      "ep 38: ep_len:725 episode reward: total was 6.950000. running mean: -42.405502\n",
      "ep 38: ep_len:500 episode reward: total was -6.790000. running mean: -42.049346\n",
      "ep 38: ep_len:500 episode reward: total was -47.010000. running mean: -42.098953\n",
      "ep 38: ep_len:1080 episode reward: total was -58.490000. running mean: -42.262863\n",
      "ep 38: ep_len:745 episode reward: total was 1.600000. running mean: -41.824235\n",
      "ep 38: ep_len:500 episode reward: total was 23.370000. running mean: -41.172293\n",
      "ep 38: ep_len:690 episode reward: total was 5.040000. running mean: -40.710170\n",
      "ep 38: ep_len:840 episode reward: total was 6.290000. running mean: -40.240168\n",
      "ep 38: ep_len:116 episode reward: total was 11.500000. running mean: -39.722766\n",
      "ep 38: ep_len:955 episode reward: total was 6.570000. running mean: -39.259839\n",
      "ep 38: ep_len:500 episode reward: total was 31.240000. running mean: -38.554840\n",
      "ep 38: ep_len:745 episode reward: total was -26.460000. running mean: -38.433892\n",
      "ep 38: ep_len:500 episode reward: total was 15.870000. running mean: -37.890853\n",
      "ep 38: ep_len:505 episode reward: total was -27.290000. running mean: -37.784844\n",
      "ep 38: ep_len:520 episode reward: total was 30.760000. running mean: -37.099396\n",
      "ep 38: ep_len:1870 episode reward: total was -188.270000. running mean: -38.611102\n",
      "ep 38: ep_len:500 episode reward: total was -7.270000. running mean: -38.297691\n",
      "ep 38: ep_len:1600 episode reward: total was -232.050000. running mean: -40.235214\n",
      "ep 38: ep_len:500 episode reward: total was -3.840000. running mean: -39.871262\n",
      "ep 38: ep_len:640 episode reward: total was -3.820000. running mean: -39.510749\n",
      "ep 38: ep_len:500 episode reward: total was -1.590000. running mean: -39.131542\n",
      "ep 38: ep_len:695 episode reward: total was 11.210000. running mean: -38.628126\n",
      "ep 38: ep_len:575 episode reward: total was -3.950000. running mean: -38.281345\n",
      "ep 38: ep_len:650 episode reward: total was -8.850000. running mean: -37.987032\n",
      "ep 38: ep_len:1440 episode reward: total was -121.400000. running mean: -38.821161\n",
      "ep 38: ep_len:895 episode reward: total was 15.220000. running mean: -38.280750\n",
      "ep 38: ep_len:500 episode reward: total was -40.270000. running mean: -38.300642\n",
      "ep 38: ep_len:2115 episode reward: total was -207.330000. running mean: -39.990936\n",
      "ep 38: ep_len:845 episode reward: total was -27.650000. running mean: -39.867526\n",
      "ep 38: ep_len:500 episode reward: total was 10.850000. running mean: -39.360351\n",
      "ep 38: ep_len:500 episode reward: total was 48.500000. running mean: -38.481748\n",
      "ep 38: ep_len:500 episode reward: total was -8.860000. running mean: -38.185530\n",
      "ep 38: ep_len:235 episode reward: total was 22.500000. running mean: -37.578675\n",
      "ep 38: ep_len:900 episode reward: total was 16.630000. running mean: -37.036588\n",
      "ep 38: ep_len:500 episode reward: total was 19.240000. running mean: -36.473822\n",
      "ep 38: ep_len:500 episode reward: total was -2.290000. running mean: -36.131984\n",
      "ep 38: ep_len:675 episode reward: total was -10.820000. running mean: -35.878864\n",
      "ep 38: ep_len:500 episode reward: total was 33.230000. running mean: -35.187776\n",
      "ep 38: ep_len:645 episode reward: total was -42.190000. running mean: -35.257798\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 38: ep_len:1359 episode reward: total was -252.970000. running mean: -37.434920\n",
      "ep 38: ep_len:525 episode reward: total was -38.390000. running mean: -37.444471\n",
      "ep 38: ep_len:232 episode reward: total was 23.000000. running mean: -36.840026\n",
      "ep 38: ep_len:797 episode reward: total was -64.090000. running mean: -37.112526\n",
      "ep 38: ep_len:980 episode reward: total was 24.000000. running mean: -36.501400\n",
      "ep 38: ep_len:670 episode reward: total was -12.690000. running mean: -36.263286\n",
      "ep 38: ep_len:635 episode reward: total was -0.800000. running mean: -35.908653\n",
      "ep 38: ep_len:500 episode reward: total was 23.840000. running mean: -35.311167\n",
      "ep 38: ep_len:840 episode reward: total was -42.810000. running mean: -35.386155\n",
      "ep 38: ep_len:720 episode reward: total was -46.990000. running mean: -35.502194\n",
      "ep 38: ep_len:857 episode reward: total was -85.720000. running mean: -36.004372\n",
      "ep 38: ep_len:885 episode reward: total was -17.470000. running mean: -35.819028\n",
      "ep 38: ep_len:705 episode reward: total was -30.440000. running mean: -35.765238\n",
      "ep 38: ep_len:635 episode reward: total was -9.760000. running mean: -35.505185\n",
      "ep 38: ep_len:959 episode reward: total was -47.610000. running mean: -35.626234\n",
      "ep 38: ep_len:652 episode reward: total was -48.240000. running mean: -35.752371\n",
      "ep 38: ep_len:835 episode reward: total was 24.200000. running mean: -35.152848\n",
      "ep 38: ep_len:500 episode reward: total was 0.720000. running mean: -34.794119\n",
      "ep 38: ep_len:500 episode reward: total was -14.410000. running mean: -34.590278\n",
      "ep 38: ep_len:700 episode reward: total was -5.720000. running mean: -34.301575\n",
      "ep 38: ep_len:760 episode reward: total was -44.990000. running mean: -34.408459\n",
      "ep 38: ep_len:755 episode reward: total was -18.830000. running mean: -34.252675\n",
      "ep 38: ep_len:1080 episode reward: total was 26.340000. running mean: -33.646748\n",
      "ep 38: ep_len:107 episode reward: total was 10.500000. running mean: -33.205281\n",
      "ep 38: ep_len:645 episode reward: total was -2.980000. running mean: -32.903028\n",
      "ep 38: ep_len:895 episode reward: total was -27.550000. running mean: -32.849497\n",
      "ep 38: ep_len:780 episode reward: total was -24.750000. running mean: -32.768502\n",
      "ep 38: ep_len:500 episode reward: total was -57.230000. running mean: -33.013117\n",
      "ep 38: ep_len:515 episode reward: total was -17.690000. running mean: -32.859886\n",
      "ep 38: ep_len:500 episode reward: total was 23.770000. running mean: -32.293587\n",
      "ep 38: ep_len:1580 episode reward: total was -49.370000. running mean: -32.464352\n",
      "ep 38: ep_len:540 episode reward: total was 3.490000. running mean: -32.104808\n",
      "ep 38: ep_len:500 episode reward: total was -57.810000. running mean: -32.361860\n",
      "ep 38: ep_len:500 episode reward: total was 23.870000. running mean: -31.799541\n",
      "ep 38: ep_len:2435 episode reward: total was -124.460000. running mean: -32.726146\n",
      "ep 38: ep_len:500 episode reward: total was 26.310000. running mean: -32.135784\n",
      "ep 38: ep_len:875 episode reward: total was 20.670000. running mean: -31.607727\n",
      "ep 38: ep_len:1836 episode reward: total was -131.700000. running mean: -32.608649\n",
      "ep 38: ep_len:610 episode reward: total was 0.410000. running mean: -32.278463\n",
      "ep 38: ep_len:500 episode reward: total was 3.310000. running mean: -31.922578\n",
      "ep 38: ep_len:575 episode reward: total was -11.020000. running mean: -31.713552\n",
      "ep 38: ep_len:152 episode reward: total was 15.000000. running mean: -31.246417\n",
      "ep 38: ep_len:171 episode reward: total was 17.500000. running mean: -30.758953\n",
      "ep 38: ep_len:500 episode reward: total was 13.600000. running mean: -30.315363\n",
      "ep 38: ep_len:835 episode reward: total was 10.750000. running mean: -29.904710\n",
      "ep 38: ep_len:500 episode reward: total was 14.740000. running mean: -29.458262\n",
      "ep 38: ep_len:181 episode reward: total was 15.000000. running mean: -29.013680\n",
      "ep 38: ep_len:1335 episode reward: total was -153.930000. running mean: -30.262843\n",
      "ep 38: ep_len:775 episode reward: total was 2.030000. running mean: -29.939915\n",
      "ep 38: ep_len:5327 episode reward: total was -966.000000. running mean: -39.300515\n",
      "ep 38: ep_len:1015 episode reward: total was 28.760000. running mean: -38.619910\n",
      "ep 38: ep_len:500 episode reward: total was 15.560000. running mean: -38.078111\n",
      "ep 38: ep_len:500 episode reward: total was 29.340000. running mean: -37.403930\n",
      "ep 38: ep_len:1296 episode reward: total was -180.270000. running mean: -38.832591\n",
      "ep 38: ep_len:870 episode reward: total was 17.600000. running mean: -38.268265\n",
      "ep 38: ep_len:935 episode reward: total was 13.280000. running mean: -37.752782\n",
      "ep 38: ep_len:332 episode reward: total was 16.320000. running mean: -37.212054\n",
      "ep 38: ep_len:1000 episode reward: total was 17.780000. running mean: -36.662134\n",
      "ep 38: ep_len:500 episode reward: total was 3.770000. running mean: -36.257813\n",
      "ep 38: ep_len:500 episode reward: total was -2.840000. running mean: -35.923634\n",
      "ep 38: ep_len:2710 episode reward: total was -143.500000. running mean: -36.999398\n",
      "ep 38: ep_len:730 episode reward: total was -7.680000. running mean: -36.706204\n",
      "ep 38: ep_len:825 episode reward: total was -2.060000. running mean: -36.359742\n",
      "ep 38: ep_len:500 episode reward: total was 33.810000. running mean: -35.658045\n",
      "ep 38: ep_len:500 episode reward: total was 21.560000. running mean: -35.085864\n",
      "ep 38: ep_len:650 episode reward: total was 2.260000. running mean: -34.712406\n",
      "ep 38: ep_len:640 episode reward: total was 24.570000. running mean: -34.119581\n",
      "ep 38: ep_len:845 episode reward: total was -15.530000. running mean: -33.933686\n",
      "ep 38: ep_len:500 episode reward: total was 5.980000. running mean: -33.534549\n",
      "ep 38: ep_len:920 episode reward: total was -18.670000. running mean: -33.385903\n",
      "ep 38: ep_len:690 episode reward: total was -1.700000. running mean: -33.069044\n",
      "ep 38: ep_len:660 episode reward: total was -42.160000. running mean: -33.159954\n",
      "ep 38: ep_len:955 episode reward: total was 18.250000. running mean: -32.645854\n",
      "ep 38: ep_len:161 episode reward: total was 14.500000. running mean: -32.174396\n",
      "ep 38: ep_len:500 episode reward: total was 20.310000. running mean: -31.649552\n",
      "ep 38: ep_len:840 episode reward: total was 3.980000. running mean: -31.293256\n",
      "ep 38: ep_len:950 episode reward: total was 11.590000. running mean: -30.864424\n",
      "ep 38: ep_len:775 episode reward: total was -8.180000. running mean: -30.637579\n",
      "ep 38: ep_len:500 episode reward: total was -11.130000. running mean: -30.442504\n",
      "ep 38: ep_len:630 episode reward: total was -37.990000. running mean: -30.517979\n",
      "ep 38: ep_len:860 episode reward: total was 11.080000. running mean: -30.101999\n",
      "ep 38: ep_len:488 episode reward: total was 25.250000. running mean: -29.548479\n",
      "ep 38: ep_len:500 episode reward: total was 50.000000. running mean: -28.752994\n",
      "ep 38: ep_len:515 episode reward: total was -14.170000. running mean: -28.607164\n",
      "ep 38: ep_len:510 episode reward: total was -3.220000. running mean: -28.353293\n",
      "ep 38: ep_len:500 episode reward: total was 3.250000. running mean: -28.037260\n",
      "ep 38: ep_len:500 episode reward: total was -6.660000. running mean: -27.823487\n",
      "ep 38: ep_len:715 episode reward: total was -7.710000. running mean: -27.622352\n",
      "ep 38: ep_len:137 episode reward: total was 13.500000. running mean: -27.211129\n",
      "ep 38: ep_len:1005 episode reward: total was 4.850000. running mean: -26.890517\n",
      "ep 38: ep_len:2692 episode reward: total was -361.880000. running mean: -30.240412\n",
      "ep 38: ep_len:500 episode reward: total was 20.060000. running mean: -29.737408\n",
      "ep 38: ep_len:376 episode reward: total was 37.500000. running mean: -29.065034\n",
      "ep 38: ep_len:500 episode reward: total was 20.800000. running mean: -28.566384\n",
      "ep 38: ep_len:500 episode reward: total was 25.330000. running mean: -28.027420\n",
      "ep 38: ep_len:720 episode reward: total was -4.210000. running mean: -27.789246\n",
      "ep 38: ep_len:690 episode reward: total was -10.270000. running mean: -27.614053\n",
      "ep 38: ep_len:705 episode reward: total was -3.690000. running mean: -27.374813\n",
      "ep 38: ep_len:252 episode reward: total was 20.500000. running mean: -26.896064\n",
      "ep 38: ep_len:635 episode reward: total was -9.890000. running mean: -26.726004\n",
      "ep 38: ep_len:610 episode reward: total was -0.850000. running mean: -26.467244\n",
      "ep 38: ep_len:770 episode reward: total was 8.880000. running mean: -26.113771\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 38: ep_len:500 episode reward: total was 9.530000. running mean: -25.757334\n",
      "ep 38: ep_len:905 episode reward: total was -9.770000. running mean: -25.597460\n",
      "ep 38: ep_len:4475 episode reward: total was -549.250000. running mean: -30.833986\n",
      "ep 38: ep_len:500 episode reward: total was 13.260000. running mean: -30.393046\n",
      "ep 38: ep_len:500 episode reward: total was 28.450000. running mean: -29.804615\n",
      "ep 38: ep_len:740 episode reward: total was -7.660000. running mean: -29.583169\n",
      "ep 38: ep_len:550 episode reward: total was -32.830000. running mean: -29.615638\n",
      "ep 38: ep_len:217 episode reward: total was 21.500000. running mean: -29.104481\n",
      "ep 38: ep_len:620 episode reward: total was -6.890000. running mean: -28.882336\n",
      "ep 38: ep_len:302 episode reward: total was 30.000000. running mean: -28.293513\n",
      "ep 38: ep_len:655 episode reward: total was -1.770000. running mean: -28.028278\n",
      "ep 38: ep_len:500 episode reward: total was 17.150000. running mean: -27.576495\n",
      "ep 38: ep_len:845 episode reward: total was 26.610000. running mean: -27.034630\n",
      "ep 38: ep_len:500 episode reward: total was 9.290000. running mean: -26.671384\n",
      "ep 38: ep_len:660 episode reward: total was -8.080000. running mean: -26.485470\n",
      "ep 38: ep_len:555 episode reward: total was -10.050000. running mean: -26.321115\n",
      "ep 38: ep_len:161 episode reward: total was 16.000000. running mean: -25.897904\n",
      "ep 38: ep_len:540 episode reward: total was 16.010000. running mean: -25.478825\n",
      "ep 38: ep_len:815 episode reward: total was 1.310000. running mean: -25.210937\n",
      "ep 38: ep_len:500 episode reward: total was 24.960000. running mean: -24.709227\n",
      "ep 38: ep_len:715 episode reward: total was -19.830000. running mean: -24.660435\n",
      "ep 38: ep_len:715 episode reward: total was -99.590000. running mean: -25.409731\n",
      "ep 38: ep_len:424 episode reward: total was 21.870000. running mean: -24.936934\n",
      "ep 38: ep_len:500 episode reward: total was -32.500000. running mean: -25.012564\n",
      "ep 38: ep_len:500 episode reward: total was 34.270000. running mean: -24.419739\n",
      "ep 38: ep_len:500 episode reward: total was 2.360000. running mean: -24.151941\n",
      "ep 38: ep_len:560 episode reward: total was 10.350000. running mean: -23.806922\n",
      "ep 38: ep_len:500 episode reward: total was 2.820000. running mean: -23.540653\n",
      "ep 38: ep_len:500 episode reward: total was 27.380000. running mean: -23.031446\n",
      "ep 38: ep_len:500 episode reward: total was -69.500000. running mean: -23.496132\n",
      "ep 38: ep_len:650 episode reward: total was -7.740000. running mean: -23.338570\n",
      "ep 38: ep_len:635 episode reward: total was -31.890000. running mean: -23.424085\n",
      "ep 38: ep_len:500 episode reward: total was -7.150000. running mean: -23.261344\n",
      "ep 38: ep_len:960 episode reward: total was 7.040000. running mean: -22.958330\n",
      "ep 38: ep_len:1285 episode reward: total was -63.130000. running mean: -23.360047\n",
      "ep 38: ep_len:500 episode reward: total was 31.300000. running mean: -22.813446\n",
      "ep 38: ep_len:760 episode reward: total was -2.570000. running mean: -22.611012\n",
      "ep 38: ep_len:700 episode reward: total was -2.780000. running mean: -22.412702\n",
      "ep 38: ep_len:640 episode reward: total was -7.860000. running mean: -22.267175\n",
      "ep 38: ep_len:500 episode reward: total was 5.830000. running mean: -21.986203\n",
      "ep 38: ep_len:935 episode reward: total was 13.170000. running mean: -21.634641\n",
      "ep 38: ep_len:500 episode reward: total was 14.920000. running mean: -21.269095\n",
      "ep 38: ep_len:500 episode reward: total was 13.240000. running mean: -20.924004\n",
      "ep 38: ep_len:500 episode reward: total was 13.420000. running mean: -20.580564\n",
      "ep 38: ep_len:500 episode reward: total was -84.500000. running mean: -21.219758\n",
      "ep 38: ep_len:500 episode reward: total was 6.100000. running mean: -20.946560\n",
      "ep 38: ep_len:492 episode reward: total was 28.770000. running mean: -20.449395\n",
      "ep 38: ep_len:50 episode reward: total was 3.500000. running mean: -20.209901\n",
      "ep 38: ep_len:580 episode reward: total was 22.800000. running mean: -19.779802\n",
      "ep 38: ep_len:830 episode reward: total was 1.110000. running mean: -19.570904\n",
      "ep 38: ep_len:555 episode reward: total was 22.380000. running mean: -19.151395\n",
      "ep 38: ep_len:1107 episode reward: total was -66.500000. running mean: -19.624881\n",
      "ep 38: ep_len:635 episode reward: total was -3.830000. running mean: -19.466932\n",
      "ep 38: ep_len:645 episode reward: total was -22.880000. running mean: -19.501063\n",
      "ep 38: ep_len:745 episode reward: total was -22.800000. running mean: -19.534052\n",
      "ep 38: ep_len:218 episode reward: total was 21.500000. running mean: -19.123712\n",
      "ep 38: ep_len:1046 episode reward: total was -209.000000. running mean: -21.022475\n",
      "ep 38: ep_len:915 episode reward: total was -14.160000. running mean: -20.953850\n",
      "ep 38: ep_len:500 episode reward: total was -5.410000. running mean: -20.798411\n",
      "ep 38: ep_len:500 episode reward: total was 24.810000. running mean: -20.342327\n",
      "ep 38: ep_len:500 episode reward: total was -14.290000. running mean: -20.281804\n",
      "ep 38: ep_len:685 episode reward: total was 9.080000. running mean: -19.988186\n",
      "ep 38: ep_len:224 episode reward: total was 22.000000. running mean: -19.568304\n",
      "ep 38: ep_len:635 episode reward: total was -2.820000. running mean: -19.400821\n",
      "ep 38: ep_len:590 episode reward: total was -8.400000. running mean: -19.290813\n",
      "ep 38: ep_len:319 episode reward: total was 30.000000. running mean: -18.797905\n",
      "ep 38: ep_len:900 episode reward: total was -24.000000. running mean: -18.849926\n",
      "ep 38: ep_len:680 episode reward: total was -1.720000. running mean: -18.678626\n",
      "ep 38: ep_len:500 episode reward: total was 22.360000. running mean: -18.268240\n",
      "ep 38: ep_len:145 episode reward: total was 13.000000. running mean: -17.955558\n",
      "ep 38: ep_len:500 episode reward: total was 19.330000. running mean: -17.582702\n",
      "ep 38: ep_len:700 episode reward: total was 1.570000. running mean: -17.391175\n",
      "ep 38: ep_len:510 episode reward: total was -28.320000. running mean: -17.500463\n",
      "ep 38: ep_len:735 episode reward: total was -9.690000. running mean: -17.422359\n",
      "ep 38: ep_len:500 episode reward: total was -11.160000. running mean: -17.359735\n",
      "ep 38: ep_len:1215 episode reward: total was -174.370000. running mean: -18.929838\n",
      "ep 38: ep_len:655 episode reward: total was -0.760000. running mean: -18.748139\n",
      "ep 38: ep_len:500 episode reward: total was 19.820000. running mean: -18.362458\n",
      "ep 38: ep_len:780 episode reward: total was 14.590000. running mean: -18.032933\n",
      "ep 38: ep_len:314 episode reward: total was 19.500000. running mean: -17.657604\n",
      "ep 38: ep_len:261 episode reward: total was 26.000000. running mean: -17.221028\n",
      "ep 38: ep_len:141 episode reward: total was 11.000000. running mean: -16.938818\n",
      "ep 38: ep_len:945 episode reward: total was -97.000000. running mean: -17.739430\n",
      "ep 38: ep_len:1070 episode reward: total was -181.360000. running mean: -19.375635\n",
      "ep 38: ep_len:505 episode reward: total was 21.360000. running mean: -18.968279\n",
      "ep 38: ep_len:441 episode reward: total was 19.970000. running mean: -18.578896\n",
      "ep 38: ep_len:745 episode reward: total was -17.750000. running mean: -18.570607\n",
      "ep 38: ep_len:750 episode reward: total was -68.240000. running mean: -19.067301\n",
      "ep 38: ep_len:1836 episode reward: total was -125.640000. running mean: -20.133028\n",
      "ep 38: ep_len:910 episode reward: total was 2.820000. running mean: -19.903498\n",
      "ep 38: ep_len:500 episode reward: total was 47.000000. running mean: -19.234463\n",
      "ep 38: ep_len:500 episode reward: total was 20.060000. running mean: -18.841518\n",
      "ep 38: ep_len:600 episode reward: total was -7.940000. running mean: -18.732503\n",
      "ep 38: ep_len:865 episode reward: total was 14.980000. running mean: -18.395378\n",
      "ep 38: ep_len:745 episode reward: total was -3.610000. running mean: -18.247524\n",
      "ep 38: ep_len:1537 episode reward: total was -84.240000. running mean: -18.907449\n",
      "ep 38: ep_len:500 episode reward: total was -22.280000. running mean: -18.941174\n",
      "ep 38: ep_len:500 episode reward: total was -22.310000. running mean: -18.974863\n",
      "ep 38: ep_len:500 episode reward: total was 16.110000. running mean: -18.624014\n",
      "ep 38: ep_len:202 episode reward: total was 20.000000. running mean: -18.237774\n",
      "ep 38: ep_len:500 episode reward: total was 8.980000. running mean: -17.965596\n",
      "ep 38: ep_len:1145 episode reward: total was -4.470000. running mean: -17.830640\n",
      "ep 38: ep_len:540 episode reward: total was -12.100000. running mean: -17.773334\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 38: ep_len:830 episode reward: total was 5.000000. running mean: -17.545601\n",
      "ep 38: ep_len:560 episode reward: total was -12.060000. running mean: -17.490744\n",
      "ep 38: ep_len:174 episode reward: total was 17.000000. running mean: -17.145837\n",
      "ep 38: ep_len:200 episode reward: total was 17.000000. running mean: -16.804379\n",
      "ep 38: ep_len:351 episode reward: total was 33.500000. running mean: -16.301335\n",
      "ep 38: ep_len:388 episode reward: total was 31.500000. running mean: -15.823322\n",
      "ep 38: ep_len:500 episode reward: total was 5.670000. running mean: -15.608388\n",
      "ep 38: ep_len:855 episode reward: total was 20.710000. running mean: -15.245204\n",
      "ep 38: ep_len:680 episode reward: total was 25.750000. running mean: -14.835252\n",
      "ep 38: ep_len:500 episode reward: total was -14.720000. running mean: -14.834100\n",
      "ep 38: ep_len:108 episode reward: total was 10.500000. running mean: -14.580759\n",
      "ep 38: ep_len:500 episode reward: total was 23.980000. running mean: -14.195151\n",
      "ep 38: ep_len:500 episode reward: total was -5.630000. running mean: -14.109500\n",
      "ep 38: ep_len:249 episode reward: total was 25.000000. running mean: -13.718405\n",
      "ep 38: ep_len:900 episode reward: total was -9.010000. running mean: -13.671321\n",
      "ep 38: ep_len:875 episode reward: total was -4.140000. running mean: -13.576008\n",
      "ep 38: ep_len:860 episode reward: total was -22.570000. running mean: -13.665947\n",
      "ep 38: ep_len:500 episode reward: total was 24.870000. running mean: -13.280588\n",
      "ep 38: ep_len:500 episode reward: total was 17.860000. running mean: -12.969182\n",
      "ep 38: ep_len:990 episode reward: total was -63.590000. running mean: -13.475390\n",
      "ep 38: ep_len:850 episode reward: total was -24.670000. running mean: -13.587336\n",
      "ep 38: ep_len:725 episode reward: total was 7.750000. running mean: -13.373963\n",
      "ep 38: ep_len:540 episode reward: total was -7.050000. running mean: -13.310723\n",
      "ep 38: ep_len:500 episode reward: total was 26.740000. running mean: -12.910216\n",
      "ep 38: ep_len:1345 episode reward: total was -118.560000. running mean: -13.966714\n",
      "ep 38: ep_len:610 episode reward: total was -39.190000. running mean: -14.218947\n",
      "ep 38: ep_len:930 episode reward: total was -23.440000. running mean: -14.311157\n",
      "ep 38: ep_len:500 episode reward: total was 16.300000. running mean: -14.005046\n",
      "ep 38: ep_len:605 episode reward: total was -22.070000. running mean: -14.085695\n",
      "ep 38: ep_len:318 episode reward: total was 31.500000. running mean: -13.629838\n",
      "ep 38: ep_len:435 episode reward: total was -85.990000. running mean: -14.353440\n",
      "ep 38: ep_len:940 episode reward: total was -13.620000. running mean: -14.346106\n",
      "ep 38: ep_len:1005 episode reward: total was 27.290000. running mean: -13.929745\n",
      "ep 38: ep_len:995 episode reward: total was 13.370000. running mean: -13.656747\n",
      "ep 38: ep_len:500 episode reward: total was 29.770000. running mean: -13.222480\n",
      "ep 38: ep_len:500 episode reward: total was 14.230000. running mean: -12.947955\n",
      "ep 38: ep_len:500 episode reward: total was 29.280000. running mean: -12.525675\n",
      "ep 38: ep_len:1570 episode reward: total was -52.480000. running mean: -12.925219\n",
      "ep 38: ep_len:215 episode reward: total was 18.500000. running mean: -12.610966\n",
      "ep 38: ep_len:500 episode reward: total was 50.000000. running mean: -11.984857\n",
      "ep 38: ep_len:825 episode reward: total was 2.260000. running mean: -11.842408\n",
      "ep 38: ep_len:1885 episode reward: total was -260.930000. running mean: -14.333284\n",
      "ep 38: ep_len:655 episode reward: total was 28.860000. running mean: -13.901351\n",
      "ep 38: ep_len:875 episode reward: total was 3.300000. running mean: -13.729338\n",
      "ep 38: ep_len:500 episode reward: total was -2.220000. running mean: -13.614244\n",
      "ep 38: ep_len:1040 episode reward: total was -88.940000. running mean: -14.367502\n",
      "ep 38: ep_len:1563 episode reward: total was -147.300000. running mean: -15.696827\n",
      "ep 38: ep_len:188 episode reward: total was 18.500000. running mean: -15.354859\n",
      "ep 38: ep_len:755 episode reward: total was -4.990000. running mean: -15.251210\n",
      "ep 38: ep_len:565 episode reward: total was 0.070000. running mean: -15.097998\n",
      "ep 38: ep_len:565 episode reward: total was -23.160000. running mean: -15.178618\n",
      "ep 38: ep_len:625 episode reward: total was -93.710000. running mean: -15.963932\n",
      "ep 38: ep_len:795 episode reward: total was 33.700000. running mean: -15.467292\n",
      "ep 38: ep_len:710 episode reward: total was -10.230000. running mean: -15.414919\n",
      "ep 38: ep_len:575 episode reward: total was -3.950000. running mean: -15.300270\n",
      "ep 38: ep_len:495 episode reward: total was 32.240000. running mean: -14.824868\n",
      "ep 38: ep_len:500 episode reward: total was -7.680000. running mean: -14.753419\n",
      "ep 38: ep_len:230 episode reward: total was 21.500000. running mean: -14.390885\n",
      "ep 38: ep_len:1120 episode reward: total was -137.500000. running mean: -15.621976\n",
      "ep 38: ep_len:655 episode reward: total was 17.740000. running mean: -15.288356\n",
      "ep 38: ep_len:341 episode reward: total was 15.790000. running mean: -14.977573\n",
      "ep 38: ep_len:545 episode reward: total was -3.000000. running mean: -14.857797\n",
      "ep 38: ep_len:500 episode reward: total was 48.500000. running mean: -14.224219\n",
      "ep 38: ep_len:500 episode reward: total was 13.480000. running mean: -13.947177\n",
      "ep 38: ep_len:500 episode reward: total was 12.740000. running mean: -13.680305\n",
      "ep 38: ep_len:735 episode reward: total was 10.870000. running mean: -13.434802\n",
      "ep 38: ep_len:1515 episode reward: total was -202.000000. running mean: -15.320454\n",
      "ep 38: ep_len:500 episode reward: total was 30.290000. running mean: -14.864349\n",
      "ep 38: ep_len:530 episode reward: total was 2.180000. running mean: -14.693906\n",
      "ep 38: ep_len:710 episode reward: total was -4.690000. running mean: -14.593867\n",
      "ep 38: ep_len:2014 episode reward: total was -200.030000. running mean: -16.448228\n",
      "ep 38: ep_len:3180 episode reward: total was -461.320000. running mean: -20.896946\n",
      "ep 38: ep_len:306 episode reward: total was 30.500000. running mean: -20.382976\n",
      "ep 38: ep_len:500 episode reward: total was -0.380000. running mean: -20.182947\n",
      "ep 38: ep_len:500 episode reward: total was -5.410000. running mean: -20.035217\n",
      "ep 38: ep_len:635 episode reward: total was -0.300000. running mean: -19.837865\n",
      "ep 38: ep_len:500 episode reward: total was 7.390000. running mean: -19.565586\n",
      "ep 38: ep_len:500 episode reward: total was -5.100000. running mean: -19.420930\n",
      "ep 38: ep_len:500 episode reward: total was 1.080000. running mean: -19.215921\n",
      "ep 38: ep_len:738 episode reward: total was -64.790000. running mean: -19.671662\n",
      "ep 38: ep_len:500 episode reward: total was -8.720000. running mean: -19.562145\n",
      "ep 38: ep_len:985 episode reward: total was 22.720000. running mean: -19.139324\n",
      "ep 38: ep_len:1450 episode reward: total was -60.750000. running mean: -19.555431\n",
      "ep 38: ep_len:1254 episode reward: total was -248.500000. running mean: -21.844876\n",
      "ep 38: ep_len:685 episode reward: total was -29.990000. running mean: -21.926328\n",
      "ep 38: ep_len:665 episode reward: total was -25.990000. running mean: -21.966964\n",
      "ep 38: ep_len:1040 episode reward: total was -92.910000. running mean: -22.676395\n",
      "ep 38: ep_len:515 episode reward: total was -1.040000. running mean: -22.460031\n",
      "ep 38: ep_len:1811 episode reward: total was -158.010000. running mean: -23.815530\n",
      "ep 38: ep_len:590 episode reward: total was 32.400000. running mean: -23.253375\n",
      "ep 38: ep_len:500 episode reward: total was 48.500000. running mean: -22.535841\n",
      "ep 38: ep_len:835 episode reward: total was -17.540000. running mean: -22.485883\n",
      "ep 38: ep_len:780 episode reward: total was -15.140000. running mean: -22.412424\n",
      "ep 38: ep_len:500 episode reward: total was 14.400000. running mean: -22.044300\n",
      "ep 38: ep_len:249 episode reward: total was 24.500000. running mean: -21.578857\n",
      "ep 38: ep_len:113 episode reward: total was 11.000000. running mean: -21.253068\n",
      "ep 38: ep_len:785 episode reward: total was -14.640000. running mean: -21.186938\n",
      "ep 38: ep_len:217 episode reward: total was 20.000000. running mean: -20.775068\n",
      "ep 38: ep_len:790 episode reward: total was -14.630000. running mean: -20.713618\n",
      "ep 38: ep_len:695 episode reward: total was 0.330000. running mean: -20.503181\n",
      "ep 38: ep_len:500 episode reward: total was -3.880000. running mean: -20.336950\n",
      "ep 38: ep_len:500 episode reward: total was 32.770000. running mean: -19.805880\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 38: ep_len:1095 episode reward: total was -1.070000. running mean: -19.618521\n",
      "ep 38: ep_len:500 episode reward: total was 4.380000. running mean: -19.378536\n",
      "ep 38: ep_len:226 episode reward: total was 21.000000. running mean: -18.974751\n",
      "ep 38: ep_len:1045 episode reward: total was -22.350000. running mean: -19.008503\n",
      "ep 38: ep_len:676 episode reward: total was -47.160000. running mean: -19.290018\n",
      "ep 38: ep_len:500 episode reward: total was 19.020000. running mean: -18.906918\n",
      "ep 38: ep_len:500 episode reward: total was 5.580000. running mean: -18.662049\n",
      "ep 38: ep_len:775 episode reward: total was -1.550000. running mean: -18.490928\n",
      "ep 38: ep_len:675 episode reward: total was 17.470000. running mean: -18.131319\n",
      "ep 38: ep_len:758 episode reward: total was -63.160000. running mean: -18.581606\n",
      "ep 38: ep_len:940 episode reward: total was 5.260000. running mean: -18.343190\n",
      "ep 38: ep_len:262 episode reward: total was 24.500000. running mean: -17.914758\n",
      "ep 38: ep_len:970 episode reward: total was 7.670000. running mean: -17.658910\n",
      "ep 38: ep_len:500 episode reward: total was 50.000000. running mean: -16.982321\n",
      "ep 38: ep_len:1460 episode reward: total was -150.650000. running mean: -18.318998\n",
      "ep 38: ep_len:500 episode reward: total was 23.340000. running mean: -17.902408\n",
      "ep 38: ep_len:387 episode reward: total was -28.600000. running mean: -18.009384\n",
      "ep 38: ep_len:590 episode reward: total was -34.220000. running mean: -18.171490\n",
      "ep 38: ep_len:500 episode reward: total was 5.330000. running mean: -17.936475\n",
      "ep 38: ep_len:1255 episode reward: total was 5.170000. running mean: -17.705410\n",
      "ep 38: ep_len:500 episode reward: total was -8.720000. running mean: -17.615556\n",
      "ep 38: ep_len:500 episode reward: total was 6.050000. running mean: -17.378901\n",
      "ep 38: ep_len:500 episode reward: total was 15.990000. running mean: -17.045212\n",
      "ep 38: ep_len:714 episode reward: total was -25.230000. running mean: -17.127060\n",
      "ep 38: ep_len:855 episode reward: total was 13.790000. running mean: -16.817889\n",
      "ep 38: ep_len:625 episode reward: total was -34.150000. running mean: -16.991210\n",
      "ep 38: ep_len:615 episode reward: total was -1.840000. running mean: -16.839698\n",
      "ep 38: ep_len:500 episode reward: total was 3.680000. running mean: -16.634501\n",
      "ep 38: ep_len:880 episode reward: total was -15.460000. running mean: -16.622756\n",
      "ep 38: ep_len:575 episode reward: total was 7.910000. running mean: -16.377428\n",
      "ep 38: ep_len:500 episode reward: total was -17.290000. running mean: -16.386554\n",
      "ep 38: ep_len:1050 episode reward: total was 14.970000. running mean: -16.072989\n",
      "ep 38: ep_len:1180 episode reward: total was -101.540000. running mean: -16.927659\n",
      "ep 38: ep_len:755 episode reward: total was -22.260000. running mean: -16.980982\n",
      "ep 38: ep_len:505 episode reward: total was -9.380000. running mean: -16.904972\n",
      "ep 38: ep_len:660 episode reward: total was -11.820000. running mean: -16.854123\n",
      "ep 38: ep_len:735 episode reward: total was 6.790000. running mean: -16.617681\n",
      "ep 38: ep_len:500 episode reward: total was 19.250000. running mean: -16.259005\n",
      "ep 38: ep_len:500 episode reward: total was 9.160000. running mean: -16.004815\n",
      "ep 38: ep_len:875 episode reward: total was 11.410000. running mean: -15.730666\n",
      "ep 38: ep_len:500 episode reward: total was 2.880000. running mean: -15.544560\n",
      "ep 38: ep_len:500 episode reward: total was 29.770000. running mean: -15.091414\n",
      "ep 38: ep_len:500 episode reward: total was 21.810000. running mean: -14.722400\n",
      "ep 38: ep_len:570 episode reward: total was -20.120000. running mean: -14.776376\n",
      "ep 38: ep_len:690 episode reward: total was -30.470000. running mean: -14.933312\n",
      "ep 38: ep_len:640 episode reward: total was -1.800000. running mean: -14.801979\n",
      "ep 38: ep_len:600 episode reward: total was 32.360000. running mean: -14.330359\n",
      "ep 38: ep_len:500 episode reward: total was 23.000000. running mean: -13.957056\n",
      "ep 38: ep_len:675 episode reward: total was -0.720000. running mean: -13.824685\n",
      "ep 38: ep_len:500 episode reward: total was 20.960000. running mean: -13.476838\n",
      "ep 38: ep_len:980 episode reward: total was -17.690000. running mean: -13.518970\n",
      "ep 38: ep_len:795 episode reward: total was -7.520000. running mean: -13.458980\n",
      "ep 38: ep_len:960 episode reward: total was -53.680000. running mean: -13.861190\n",
      "ep 38: ep_len:1020 episode reward: total was -31.160000. running mean: -14.034179\n",
      "ep 38: ep_len:335 episode reward: total was 30.500000. running mean: -13.588837\n",
      "ep 38: ep_len:570 episode reward: total was 21.650000. running mean: -13.236448\n",
      "ep 38: ep_len:625 episode reward: total was 33.910000. running mean: -12.764984\n",
      "ep 38: ep_len:500 episode reward: total was -14.320000. running mean: -12.780534\n",
      "ep 38: ep_len:500 episode reward: total was 28.280000. running mean: -12.369929\n",
      "ep 38: ep_len:530 episode reward: total was -3.030000. running mean: -12.276529\n",
      "ep 38: ep_len:960 episode reward: total was -39.000000. running mean: -12.543764\n",
      "ep 38: ep_len:1940 episode reward: total was -281.980000. running mean: -15.238126\n",
      "ep 38: ep_len:500 episode reward: total was -3.730000. running mean: -15.123045\n",
      "ep 38: ep_len:500 episode reward: total was 25.830000. running mean: -14.713515\n",
      "ep 38: ep_len:500 episode reward: total was 23.980000. running mean: -14.326580\n",
      "ep 38: ep_len:500 episode reward: total was 23.800000. running mean: -13.945314\n",
      "ep 38: ep_len:173 episode reward: total was 15.500000. running mean: -13.650861\n",
      "ep 38: ep_len:530 episode reward: total was -9.090000. running mean: -13.605252\n",
      "ep 38: ep_len:1010 episode reward: total was 14.850000. running mean: -13.320700\n",
      "ep 38: ep_len:635 episode reward: total was -9.890000. running mean: -13.286393\n",
      "ep 38: ep_len:500 episode reward: total was -17.290000. running mean: -13.326429\n",
      "ep 38: ep_len:500 episode reward: total was 47.000000. running mean: -12.723164\n",
      "ep 38: ep_len:197 episode reward: total was 18.000000. running mean: -12.415933\n",
      "ep 38: ep_len:500 episode reward: total was 7.290000. running mean: -12.218873\n",
      "ep 38: ep_len:745 episode reward: total was -10.680000. running mean: -12.203485\n",
      "ep 38: ep_len:595 episode reward: total was -1.090000. running mean: -12.092350\n",
      "ep 38: ep_len:265 episode reward: total was 23.500000. running mean: -11.736426\n",
      "ep 38: ep_len:500 episode reward: total was -17.620000. running mean: -11.795262\n",
      "ep 38: ep_len:500 episode reward: total was 1.570000. running mean: -11.661609\n",
      "ep 38: ep_len:1085 episode reward: total was 4.520000. running mean: -11.499793\n",
      "ep 38: ep_len:655 episode reward: total was -47.220000. running mean: -11.856995\n",
      "ep 38: ep_len:500 episode reward: total was 9.160000. running mean: -11.646825\n",
      "ep 38: ep_len:500 episode reward: total was 24.790000. running mean: -11.282457\n",
      "ep 38: ep_len:875 episode reward: total was -18.500000. running mean: -11.354633\n",
      "ep 38: ep_len:905 episode reward: total was 6.500000. running mean: -11.176086\n",
      "ep 38: ep_len:735 episode reward: total was -16.730000. running mean: -11.231625\n",
      "ep 38: ep_len:790 episode reward: total was -53.010000. running mean: -11.649409\n",
      "ep 38: ep_len:1005 episode reward: total was -89.210000. running mean: -12.425015\n",
      "ep 38: ep_len:620 episode reward: total was -24.060000. running mean: -12.541365\n",
      "ep 38: ep_len:2514 episode reward: total was -423.250000. running mean: -16.648451\n",
      "ep 38: ep_len:690 episode reward: total was -17.860000. running mean: -16.660567\n",
      "ep 38: ep_len:500 episode reward: total was 10.020000. running mean: -16.393761\n",
      "ep 38: ep_len:860 episode reward: total was -22.570000. running mean: -16.455523\n",
      "ep 38: ep_len:755 episode reward: total was -23.980000. running mean: -16.530768\n",
      "ep 38: ep_len:500 episode reward: total was 16.760000. running mean: -16.197861\n",
      "ep 38: ep_len:520 episode reward: total was -11.130000. running mean: -16.147182\n",
      "ep 38: ep_len:500 episode reward: total was 15.440000. running mean: -15.831310\n",
      "ep 38: ep_len:570 episode reward: total was 14.900000. running mean: -15.523997\n",
      "ep 38: ep_len:196 episode reward: total was 19.500000. running mean: -15.173757\n",
      "ep 38: ep_len:890 episode reward: total was 25.170000. running mean: -14.770320\n",
      "ep 38: ep_len:500 episode reward: total was 9.770000. running mean: -14.524916\n",
      "ep 38: ep_len:895 episode reward: total was -51.790000. running mean: -14.897567\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 38: ep_len:1523 episode reward: total was -209.090000. running mean: -16.839491\n",
      "ep 38: ep_len:1115 episode reward: total was -127.670000. running mean: -17.947797\n",
      "ep 38: ep_len:500 episode reward: total was 12.320000. running mean: -17.645119\n",
      "ep 38: ep_len:500 episode reward: total was -11.170000. running mean: -17.580367\n",
      "ep 38: ep_len:1020 episode reward: total was -5.440000. running mean: -17.458964\n",
      "ep 38: ep_len:700 episode reward: total was -116.300000. running mean: -18.447374\n",
      "ep 38: ep_len:535 episode reward: total was -2.010000. running mean: -18.283000\n",
      "ep 38: ep_len:500 episode reward: total was 20.720000. running mean: -17.892970\n",
      "ep 38: ep_len:805 episode reward: total was -0.410000. running mean: -17.718141\n",
      "ep 38: ep_len:705 episode reward: total was 14.750000. running mean: -17.393459\n",
      "ep 38: ep_len:700 episode reward: total was -10.770000. running mean: -17.327225\n",
      "ep 38: ep_len:810 episode reward: total was -27.720000. running mean: -17.431152\n",
      "ep 38: ep_len:535 episode reward: total was -95.940000. running mean: -18.216241\n",
      "ep 38: ep_len:515 episode reward: total was -12.150000. running mean: -18.155578\n",
      "ep 38: ep_len:525 episode reward: total was -6.070000. running mean: -18.034723\n",
      "ep 38: ep_len:500 episode reward: total was -1.130000. running mean: -17.865675\n",
      "ep 38: ep_len:730 episode reward: total was -44.040000. running mean: -18.127419\n",
      "ep 38: ep_len:1545 episode reward: total was -148.460000. running mean: -19.430745\n",
      "ep 38: ep_len:1230 episode reward: total was -25.120000. running mean: -19.487637\n",
      "ep 38: ep_len:500 episode reward: total was 7.910000. running mean: -19.213661\n",
      "ep 38: ep_len:832 episode reward: total was -26.940000. running mean: -19.290924\n",
      "ep 38: ep_len:720 episode reward: total was 0.380000. running mean: -19.094215\n",
      "ep 38: ep_len:500 episode reward: total was 27.810000. running mean: -18.625173\n",
      "ep 38: ep_len:465 episode reward: total was -5.240000. running mean: -18.491321\n",
      "ep 38: ep_len:500 episode reward: total was -0.760000. running mean: -18.314008\n",
      "ep 38: ep_len:500 episode reward: total was -28.980000. running mean: -18.420668\n",
      "ep 38: ep_len:500 episode reward: total was 2.240000. running mean: -18.214061\n",
      "ep 38: ep_len:208 episode reward: total was 19.000000. running mean: -17.841920\n",
      "ep 38: ep_len:535 episode reward: total was -9.080000. running mean: -17.754301\n",
      "ep 38: ep_len:500 episode reward: total was 8.800000. running mean: -17.488758\n",
      "ep 38: ep_len:500 episode reward: total was 17.920000. running mean: -17.134671\n",
      "ep 38: ep_len:500 episode reward: total was 31.790000. running mean: -16.645424\n",
      "ep 38: ep_len:715 episode reward: total was -0.640000. running mean: -16.485370\n",
      "ep 38: ep_len:635 episode reward: total was -22.010000. running mean: -16.540616\n",
      "ep 38: ep_len:780 episode reward: total was -46.110000. running mean: -16.836310\n",
      "ep 38: ep_len:411 episode reward: total was 4.360000. running mean: -16.624347\n",
      "ep 38: ep_len:500 episode reward: total was 9.710000. running mean: -16.361003\n",
      "ep 38: ep_len:500 episode reward: total was -11.380000. running mean: -16.311193\n",
      "ep 38: ep_len:196 episode reward: total was 19.500000. running mean: -15.953081\n",
      "ep 38: ep_len:900 episode reward: total was -11.530000. running mean: -15.908850\n",
      "ep 38: ep_len:72 episode reward: total was 2.500000. running mean: -15.724762\n",
      "ep 38: ep_len:500 episode reward: total was 28.790000. running mean: -15.279614\n",
      "ep 38: ep_len:855 episode reward: total was -15.110000. running mean: -15.277918\n",
      "ep 38: ep_len:500 episode reward: total was 34.790000. running mean: -14.777239\n",
      "ep 38: ep_len:500 episode reward: total was -7.160000. running mean: -14.701067\n",
      "ep 38: ep_len:500 episode reward: total was 27.750000. running mean: -14.276556\n",
      "ep 38: ep_len:500 episode reward: total was -36.530000. running mean: -14.499090\n",
      "ep 38: ep_len:154 episode reward: total was 15.000000. running mean: -14.204099\n",
      "ep 38: ep_len:500 episode reward: total was 4.630000. running mean: -14.015758\n",
      "ep 38: ep_len:312 episode reward: total was 29.500000. running mean: -13.580601\n",
      "ep 38: ep_len:500 episode reward: total was 11.490000. running mean: -13.329895\n",
      "ep 38: ep_len:500 episode reward: total was 16.330000. running mean: -13.033296\n",
      "ep 38: ep_len:1114 episode reward: total was -183.650000. running mean: -14.739463\n",
      "ep 38: ep_len:500 episode reward: total was -14.250000. running mean: -14.734568\n",
      "ep 38: ep_len:515 episode reward: total was 6.680000. running mean: -14.520423\n",
      "ep 38: ep_len:965 episode reward: total was -3.070000. running mean: -14.405918\n",
      "ep 38: ep_len:570 episode reward: total was 16.260000. running mean: -14.099259\n",
      "ep 38: ep_len:500 episode reward: total was 17.280000. running mean: -13.785467\n",
      "ep 38: ep_len:267 episode reward: total was 26.500000. running mean: -13.382612\n",
      "ep 38: ep_len:835 episode reward: total was 3.300000. running mean: -13.215786\n",
      "ep 38: ep_len:500 episode reward: total was -18.330000. running mean: -13.266928\n",
      "ep 38: ep_len:985 episode reward: total was -17.070000. running mean: -13.304959\n",
      "ep 38: ep_len:775 episode reward: total was -15.670000. running mean: -13.328609\n",
      "ep 38: ep_len:515 episode reward: total was 18.440000. running mean: -13.010923\n",
      "ep 38: ep_len:675 episode reward: total was 1.890000. running mean: -12.861914\n",
      "ep 38: ep_len:590 episode reward: total was -17.020000. running mean: -12.903495\n",
      "ep 38: ep_len:910 episode reward: total was -127.010000. running mean: -14.044560\n",
      "ep 38: ep_len:540 episode reward: total was -2.900000. running mean: -13.933114\n",
      "ep 38: ep_len:500 episode reward: total was -31.950000. running mean: -14.113283\n",
      "ep 38: ep_len:500 episode reward: total was 2.740000. running mean: -13.944750\n",
      "ep 38: ep_len:239 episode reward: total was 23.500000. running mean: -13.570303\n",
      "ep 38: ep_len:500 episode reward: total was 6.710000. running mean: -13.367500\n",
      "ep 38: ep_len:1630 episode reward: total was -221.000000. running mean: -15.443825\n",
      "ep 38: ep_len:715 episode reward: total was -63.650000. running mean: -15.925886\n",
      "ep 38: ep_len:760 episode reward: total was -4.680000. running mean: -15.813428\n",
      "ep 38: ep_len:500 episode reward: total was -7.310000. running mean: -15.728393\n",
      "ep 38: ep_len:910 episode reward: total was -5.060000. running mean: -15.621709\n",
      "ep 38: ep_len:500 episode reward: total was 3.080000. running mean: -15.434692\n",
      "ep 38: ep_len:500 episode reward: total was -2.720000. running mean: -15.307545\n",
      "ep 38: ep_len:500 episode reward: total was 45.500000. running mean: -14.699470\n",
      "ep 38: ep_len:560 episode reward: total was 8.310000. running mean: -14.469375\n",
      "ep 38: ep_len:525 episode reward: total was 12.180000. running mean: -14.202881\n",
      "ep 38: ep_len:500 episode reward: total was -8.350000. running mean: -14.144353\n",
      "ep 38: ep_len:500 episode reward: total was 20.340000. running mean: -13.799509\n",
      "ep 38: ep_len:362 episode reward: total was 33.000000. running mean: -13.331514\n",
      "ep 38: ep_len:545 episode reward: total was -9.060000. running mean: -13.288799\n",
      "ep 38: ep_len:500 episode reward: total was 28.730000. running mean: -12.868611\n",
      "ep 38: ep_len:500 episode reward: total was 0.650000. running mean: -12.733425\n",
      "ep 38: ep_len:965 episode reward: total was -41.520000. running mean: -13.021291\n",
      "ep 38: ep_len:810 episode reward: total was -8.500000. running mean: -12.976078\n",
      "ep 38: ep_len:246 episode reward: total was 24.500000. running mean: -12.601317\n",
      "ep 38: ep_len:815 episode reward: total was -18.680000. running mean: -12.662104\n",
      "ep 38: ep_len:254 episode reward: total was 14.720000. running mean: -12.388283\n",
      "ep 38: ep_len:882 episode reward: total was -118.460000. running mean: -13.449000\n",
      "ep 38: ep_len:170 episode reward: total was 15.500000. running mean: -13.159510\n",
      "ep 38: ep_len:500 episode reward: total was 5.670000. running mean: -12.971215\n",
      "ep 38: ep_len:500 episode reward: total was 6.780000. running mean: -12.773703\n",
      "ep 38: ep_len:500 episode reward: total was -23.810000. running mean: -12.884066\n",
      "ep 38: ep_len:2295 episode reward: total was -223.570000. running mean: -14.990925\n",
      "ep 38: ep_len:500 episode reward: total was 50.000000. running mean: -14.341016\n",
      "ep 38: ep_len:820 episode reward: total was 0.390000. running mean: -14.193705\n",
      "ep 38: ep_len:920 episode reward: total was -8.640000. running mean: -14.138168\n",
      "ep 38: ep_len:196 episode reward: total was 19.500000. running mean: -13.801787\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 38: ep_len:500 episode reward: total was -11.350000. running mean: -13.777269\n",
      "ep 38: ep_len:500 episode reward: total was -10.800000. running mean: -13.747496\n",
      "ep 38: ep_len:1000 episode reward: total was 6.520000. running mean: -13.544821\n",
      "ep 38: ep_len:1073 episode reward: total was -28.140000. running mean: -13.690773\n",
      "ep 38: ep_len:500 episode reward: total was 2.790000. running mean: -13.525965\n",
      "ep 38: ep_len:133 episode reward: total was 13.000000. running mean: -13.260706\n",
      "ep 38: ep_len:500 episode reward: total was 0.860000. running mean: -13.119499\n",
      "ep 38: ep_len:510 episode reward: total was -6.100000. running mean: -13.049304\n",
      "ep 38: ep_len:635 episode reward: total was 30.650000. running mean: -12.612311\n",
      "ep 38: ep_len:715 episode reward: total was -2.660000. running mean: -12.512787\n",
      "ep 38: ep_len:1365 episode reward: total was -171.040000. running mean: -14.098060\n",
      "ep 38: ep_len:945 episode reward: total was -2.070000. running mean: -13.977779\n",
      "ep 38: ep_len:500 episode reward: total was 12.290000. running mean: -13.715101\n",
      "ep 38: ep_len:910 episode reward: total was 13.750000. running mean: -13.440450\n",
      "ep 38: ep_len:1141 episode reward: total was -228.000000. running mean: -15.586046\n",
      "ep 38: ep_len:500 episode reward: total was 3.310000. running mean: -15.397085\n",
      "ep 38: ep_len:195 episode reward: total was 18.000000. running mean: -15.063114\n",
      "ep 38: ep_len:640 episode reward: total was -30.080000. running mean: -15.213283\n",
      "ep 38: ep_len:500 episode reward: total was 43.000000. running mean: -14.631150\n",
      "ep 38: ep_len:500 episode reward: total was 14.520000. running mean: -14.339639\n",
      "ep 38: ep_len:500 episode reward: total was 10.110000. running mean: -14.095142\n",
      "ep 38: ep_len:935 episode reward: total was -20.220000. running mean: -14.156391\n",
      "ep 38: ep_len:500 episode reward: total was -33.810000. running mean: -14.352927\n",
      "ep 38: ep_len:149 episode reward: total was 14.500000. running mean: -14.064398\n",
      "ep 38: ep_len:570 episode reward: total was 15.750000. running mean: -13.766254\n",
      "ep 38: ep_len:895 episode reward: total was -7.570000. running mean: -13.704291\n",
      "ep 38: ep_len:1315 episode reward: total was -60.530000. running mean: -14.172548\n",
      "ep 38: ep_len:520 episode reward: total was -23.740000. running mean: -14.268223\n",
      "ep 38: ep_len:530 episode reward: total was 19.820000. running mean: -13.927341\n",
      "ep 38: ep_len:500 episode reward: total was -12.300000. running mean: -13.911067\n",
      "ep 38: ep_len:835 episode reward: total was -26.660000. running mean: -14.038557\n",
      "ep 38: ep_len:500 episode reward: total was 12.870000. running mean: -13.769471\n",
      "ep 38: ep_len:500 episode reward: total was -10.280000. running mean: -13.734576\n",
      "ep 38: ep_len:685 episode reward: total was 27.260000. running mean: -13.324631\n",
      "ep 38: ep_len:500 episode reward: total was 26.370000. running mean: -12.927684\n",
      "ep 38: ep_len:630 episode reward: total was -24.040000. running mean: -13.038807\n",
      "ep 38: ep_len:141 episode reward: total was 12.500000. running mean: -12.783419\n",
      "ep 38: ep_len:1055 episode reward: total was -14.820000. running mean: -12.803785\n",
      "ep 38: ep_len:207 episode reward: total was 20.500000. running mean: -12.470747\n",
      "ep 38: ep_len:500 episode reward: total was 24.230000. running mean: -12.103740\n",
      "ep 38: ep_len:500 episode reward: total was -25.300000. running mean: -12.235702\n",
      "ep 38: ep_len:895 episode reward: total was -7.190000. running mean: -12.185245\n",
      "ep 38: ep_len:500 episode reward: total was -14.560000. running mean: -12.208993\n",
      "ep 38: ep_len:520 episode reward: total was -12.140000. running mean: -12.208303\n",
      "ep 38: ep_len:970 episode reward: total was 11.630000. running mean: -11.969920\n",
      "ep 38: ep_len:500 episode reward: total was 19.510000. running mean: -11.655121\n",
      "ep 38: ep_len:1140 episode reward: total was -24.630000. running mean: -11.784870\n",
      "ep 38: ep_len:500 episode reward: total was -11.010000. running mean: -11.777121\n",
      "ep 38: ep_len:630 episode reward: total was 5.410000. running mean: -11.605250\n",
      "ep 38: ep_len:610 episode reward: total was 1.680000. running mean: -11.472397\n",
      "ep 38: ep_len:256 episode reward: total was 25.500000. running mean: -11.102673\n",
      "ep 38: ep_len:500 episode reward: total was -16.830000. running mean: -11.159947\n",
      "ep 38: ep_len:560 episode reward: total was -28.220000. running mean: -11.330547\n",
      "ep 38: ep_len:206 episode reward: total was 5.630000. running mean: -11.160942\n",
      "ep 38: ep_len:655 episode reward: total was 14.190000. running mean: -10.907432\n",
      "ep 38: ep_len:500 episode reward: total was -64.480000. running mean: -11.443158\n",
      "ep 38: ep_len:755 episode reward: total was -19.750000. running mean: -11.526226\n",
      "ep 38: ep_len:500 episode reward: total was 8.220000. running mean: -11.328764\n",
      "ep 38: ep_len:500 episode reward: total was -3.020000. running mean: -11.245676\n",
      "ep 38: ep_len:500 episode reward: total was -1.310000. running mean: -11.146320\n",
      "ep 38: ep_len:500 episode reward: total was 8.220000. running mean: -10.952656\n",
      "ep 38: ep_len:545 episode reward: total was -5.020000. running mean: -10.893330\n",
      "ep 38: ep_len:585 episode reward: total was 7.400000. running mean: -10.710397\n",
      "ep 38: ep_len:725 episode reward: total was -15.770000. running mean: -10.760993\n",
      "ep 38: ep_len:655 episode reward: total was -8.530000. running mean: -10.738683\n",
      "ep 38: ep_len:710 episode reward: total was -12.770000. running mean: -10.758996\n",
      "ep 38: ep_len:650 episode reward: total was -32.570000. running mean: -10.977106\n",
      "ep 38: ep_len:500 episode reward: total was 22.790000. running mean: -10.639435\n",
      "ep 38: ep_len:1335 episode reward: total was -137.770000. running mean: -11.910740\n",
      "ep 38: ep_len:500 episode reward: total was 25.330000. running mean: -11.538333\n",
      "ep 38: ep_len:1518 episode reward: total was -217.010000. running mean: -13.593050\n",
      "ep 38: ep_len:500 episode reward: total was -13.280000. running mean: -13.589919\n",
      "ep 38: ep_len:550 episode reward: total was 21.330000. running mean: -13.240720\n",
      "ep 38: ep_len:500 episode reward: total was -45.050000. running mean: -13.558813\n",
      "ep 38: ep_len:511 episode reward: total was -57.730000. running mean: -14.000525\n",
      "ep 38: ep_len:725 episode reward: total was -9.710000. running mean: -13.957619\n",
      "ep 38: ep_len:382 episode reward: total was 37.000000. running mean: -13.448043\n",
      "ep 38: ep_len:595 episode reward: total was -20.070000. running mean: -13.514263\n",
      "ep 38: ep_len:835 episode reward: total was -4.850000. running mean: -13.427620\n",
      "ep 38: ep_len:500 episode reward: total was 26.370000. running mean: -13.029644\n",
      "ep 38: ep_len:500 episode reward: total was -9.730000. running mean: -12.996648\n",
      "ep 38: ep_len:191 episode reward: total was 19.000000. running mean: -12.676681\n",
      "ep 38: ep_len:364 episode reward: total was 35.000000. running mean: -12.199914\n",
      "ep 38: ep_len:500 episode reward: total was 28.820000. running mean: -11.789715\n",
      "ep 38: ep_len:885 episode reward: total was -29.590000. running mean: -11.967718\n",
      "ep 38: ep_len:1700 episode reward: total was -212.260000. running mean: -13.970641\n",
      "ep 38: ep_len:755 episode reward: total was -13.690000. running mean: -13.967834\n",
      "ep 38: ep_len:500 episode reward: total was 10.230000. running mean: -13.725856\n",
      "ep 38: ep_len:237 episode reward: total was 23.500000. running mean: -13.353597\n",
      "ep 38: ep_len:530 episode reward: total was -8.080000. running mean: -13.300862\n",
      "ep 38: ep_len:885 episode reward: total was 18.320000. running mean: -12.984653\n",
      "ep 38: ep_len:210 episode reward: total was 19.500000. running mean: -12.659806\n",
      "ep 38: ep_len:500 episode reward: total was 25.850000. running mean: -12.274708\n",
      "ep 38: ep_len:500 episode reward: total was 9.990000. running mean: -12.052061\n",
      "ep 38: ep_len:500 episode reward: total was 3.460000. running mean: -11.896941\n",
      "ep 38: ep_len:113 episode reward: total was 11.000000. running mean: -11.667971\n",
      "ep 38: ep_len:605 episode reward: total was 12.270000. running mean: -11.428591\n",
      "ep 38: ep_len:775 episode reward: total was -6.790000. running mean: -11.382206\n",
      "ep 38: ep_len:845 episode reward: total was -12.500000. running mean: -11.393384\n",
      "ep 38: ep_len:1330 episode reward: total was -65.710000. running mean: -11.936550\n",
      "ep 38: ep_len:239 episode reward: total was 23.500000. running mean: -11.582184\n",
      "ep 38: ep_len:695 episode reward: total was -2.180000. running mean: -11.488162\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 38: ep_len:500 episode reward: total was 7.790000. running mean: -11.295381\n",
      "ep 38: ep_len:640 episode reward: total was -19.980000. running mean: -11.382227\n",
      "ep 38: ep_len:500 episode reward: total was 18.300000. running mean: -11.085405\n",
      "ep 38: ep_len:500 episode reward: total was 3.250000. running mean: -10.942051\n",
      "ep 38: ep_len:540 episode reward: total was 30.920000. running mean: -10.523430\n",
      "ep 38: ep_len:570 episode reward: total was -19.280000. running mean: -10.610996\n",
      "ep 38: ep_len:199 episode reward: total was 19.500000. running mean: -10.309886\n",
      "ep 38: ep_len:500 episode reward: total was 22.280000. running mean: -9.983987\n",
      "ep 38: ep_len:2450 episode reward: total was -299.510000. running mean: -12.879247\n",
      "ep 38: ep_len:500 episode reward: total was 10.820000. running mean: -12.642255\n",
      "ep 38: ep_len:500 episode reward: total was 20.250000. running mean: -12.313332\n",
      "ep 38: ep_len:500 episode reward: total was 23.720000. running mean: -11.952999\n",
      "ep 38: ep_len:1205 episode reward: total was -96.620000. running mean: -12.799669\n",
      "ep 38: ep_len:600 episode reward: total was -11.980000. running mean: -12.791472\n",
      "ep 38: ep_len:500 episode reward: total was 10.270000. running mean: -12.560857\n",
      "ep 38: ep_len:325 episode reward: total was 29.500000. running mean: -12.140249\n",
      "ep 38: ep_len:755 episode reward: total was -6.620000. running mean: -12.085046\n",
      "ep 38: ep_len:669 episode reward: total was -37.190000. running mean: -12.336096\n",
      "ep 38: ep_len:500 episode reward: total was 28.820000. running mean: -11.924535\n",
      "ep 38: ep_len:810 episode reward: total was -96.380000. running mean: -12.769090\n",
      "ep 38: ep_len:625 episode reward: total was -1.830000. running mean: -12.659699\n",
      "ep 38: ep_len:620 episode reward: total was 20.210000. running mean: -12.331002\n",
      "ep 38: ep_len:500 episode reward: total was -6.210000. running mean: -12.269792\n",
      "ep 38: ep_len:29 episode reward: total was 2.500000. running mean: -12.122094\n",
      "ep 38: ep_len:500 episode reward: total was 15.810000. running mean: -11.842773\n",
      "ep 38: ep_len:530 episode reward: total was -10.100000. running mean: -11.825345\n",
      "ep 38: ep_len:500 episode reward: total was 18.480000. running mean: -11.522292\n",
      "ep 38: ep_len:500 episode reward: total was 3.960000. running mean: -11.367469\n",
      "ep 38: ep_len:152 episode reward: total was 15.000000. running mean: -11.103794\n",
      "ep 38: ep_len:500 episode reward: total was -1.920000. running mean: -11.011956\n",
      "ep 38: ep_len:815 episode reward: total was 2.920000. running mean: -10.872637\n",
      "ep 38: ep_len:860 episode reward: total was -7.100000. running mean: -10.834910\n",
      "ep 38: ep_len:910 episode reward: total was -7.770000. running mean: -10.804261\n",
      "ep 38: ep_len:500 episode reward: total was 0.950000. running mean: -10.686718\n",
      "ep 38: ep_len:500 episode reward: total was -15.240000. running mean: -10.732251\n",
      "ep 38: ep_len:654 episode reward: total was -66.400000. running mean: -11.288929\n",
      "ep 38: ep_len:260 episode reward: total was 23.000000. running mean: -10.946039\n",
      "ep 38: ep_len:1770 episode reward: total was -152.190000. running mean: -12.358479\n",
      "ep 38: ep_len:655 episode reward: total was 17.640000. running mean: -12.058494\n",
      "ep 38: ep_len:446 episode reward: total was 26.760000. running mean: -11.670309\n",
      "ep 38: ep_len:735 episode reward: total was -9.690000. running mean: -11.650506\n",
      "ep 38: ep_len:500 episode reward: total was 8.800000. running mean: -11.446001\n",
      "ep 38: ep_len:510 episode reward: total was -1.050000. running mean: -11.342041\n",
      "ep 38: ep_len:500 episode reward: total was -13.250000. running mean: -11.361121\n",
      "ep 38: ep_len:1010 episode reward: total was 16.340000. running mean: -11.084110\n",
      "ep 38: ep_len:855 episode reward: total was -94.290000. running mean: -11.916168\n",
      "ep 38: ep_len:680 episode reward: total was -15.860000. running mean: -11.955607\n",
      "ep 38: ep_len:500 episode reward: total was 8.550000. running mean: -11.750551\n",
      "ep 38: ep_len:500 episode reward: total was 18.500000. running mean: -11.448045\n",
      "ep 38: ep_len:715 episode reward: total was -7.710000. running mean: -11.410665\n",
      "ep 38: ep_len:153 episode reward: total was 15.000000. running mean: -11.146558\n",
      "ep 38: ep_len:530 episode reward: total was -8.050000. running mean: -11.115592\n",
      "ep 38: ep_len:775 episode reward: total was -4.560000. running mean: -11.050037\n",
      "ep 38: ep_len:500 episode reward: total was 10.260000. running mean: -10.836936\n",
      "ep 38: ep_len:260 episode reward: total was 24.500000. running mean: -10.483567\n",
      "ep 38: ep_len:1025 episode reward: total was 19.860000. running mean: -10.180131\n",
      "ep 38: ep_len:700 episode reward: total was -31.980000. running mean: -10.398130\n",
      "ep 38: ep_len:500 episode reward: total was -16.830000. running mean: -10.462449\n",
      "ep 38: ep_len:262 episode reward: total was 24.500000. running mean: -10.112824\n",
      "ep 38: ep_len:500 episode reward: total was 24.350000. running mean: -9.768196\n",
      "ep 38: ep_len:520 episode reward: total was 1.850000. running mean: -9.652014\n",
      "ep 38: ep_len:500 episode reward: total was 24.810000. running mean: -9.307394\n",
      "ep 38: ep_len:156 episode reward: total was 15.500000. running mean: -9.059320\n",
      "ep 38: ep_len:505 episode reward: total was -2.070000. running mean: -8.989427\n",
      "ep 38: ep_len:435 episode reward: total was 19.320000. running mean: -8.706332\n",
      "ep 38: ep_len:575 episode reward: total was -45.230000. running mean: -9.071569\n",
      "ep 38: ep_len:520 episode reward: total was -19.210000. running mean: -9.172953\n",
      "ep 38: ep_len:505 episode reward: total was 19.800000. running mean: -8.883224\n",
      "ep 38: ep_len:500 episode reward: total was 29.800000. running mean: -8.496392\n",
      "ep 38: ep_len:775 episode reward: total was -38.900000. running mean: -8.800428\n",
      "ep 38: ep_len:2710 episode reward: total was -441.990000. running mean: -13.132323\n",
      "ep 38: ep_len:895 episode reward: total was 9.570000. running mean: -12.905300\n",
      "ep 38: ep_len:6040 episode reward: total was -1128.270000. running mean: -24.058947\n",
      "ep 38: ep_len:895 episode reward: total was -71.970000. running mean: -24.538058\n",
      "ep 38: ep_len:500 episode reward: total was -10.190000. running mean: -24.394577\n",
      "ep 38: ep_len:1790 episode reward: total was -176.640000. running mean: -25.917031\n",
      "ep 38: ep_len:500 episode reward: total was 12.650000. running mean: -25.531361\n",
      "ep 38: ep_len:500 episode reward: total was -8.750000. running mean: -25.363547\n",
      "ep 38: ep_len:500 episode reward: total was 24.870000. running mean: -24.861212\n",
      "ep 38: ep_len:292 episode reward: total was -10.000000. running mean: -24.712600\n",
      "epsilon:0.010000 episode_count: 30768. steps_count: 22334982.000000\n",
      "ep 39: ep_len:1460 episode reward: total was -171.860000. running mean: -26.184074\n",
      "ep 39: ep_len:790 episode reward: total was -25.710000. running mean: -26.179333\n",
      "ep 39: ep_len:500 episode reward: total was 10.170000. running mean: -25.815840\n",
      "ep 39: ep_len:1000 episode reward: total was -16.020000. running mean: -25.717881\n",
      "ep 39: ep_len:990 episode reward: total was 2.720000. running mean: -25.433503\n",
      "ep 39: ep_len:500 episode reward: total was 5.550000. running mean: -25.123667\n",
      "ep 39: ep_len:500 episode reward: total was 16.420000. running mean: -24.708231\n",
      "ep 39: ep_len:690 episode reward: total was -59.240000. running mean: -25.053549\n",
      "ep 39: ep_len:825 episode reward: total was -18.690000. running mean: -24.989913\n",
      "ep 39: ep_len:540 episode reward: total was -6.040000. running mean: -24.800414\n",
      "ep 39: ep_len:600 episode reward: total was -8.420000. running mean: -24.636610\n",
      "ep 39: ep_len:920 episode reward: total was -174.440000. running mean: -26.134644\n",
      "ep 39: ep_len:510 episode reward: total was 1.770000. running mean: -25.855597\n",
      "ep 39: ep_len:172 episode reward: total was 15.500000. running mean: -25.442041\n",
      "ep 39: ep_len:940 episode reward: total was -33.520000. running mean: -25.522821\n",
      "ep 39: ep_len:865 episode reward: total was -31.650000. running mean: -25.584093\n",
      "ep 39: ep_len:500 episode reward: total was 22.240000. running mean: -25.105852\n",
      "ep 39: ep_len:500 episode reward: total was 14.460000. running mean: -24.710193\n",
      "ep 39: ep_len:505 episode reward: total was 8.650000. running mean: -24.376591\n",
      "ep 39: ep_len:187 episode reward: total was 19.000000. running mean: -23.942825\n",
      "ep 39: ep_len:555 episode reward: total was -14.090000. running mean: -23.844297\n",
      "ep 39: ep_len:500 episode reward: total was 5.280000. running mean: -23.553054\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 39: ep_len:1450 episode reward: total was -109.260000. running mean: -24.410124\n",
      "ep 39: ep_len:975 episode reward: total was -55.670000. running mean: -24.722722\n",
      "ep 39: ep_len:1745 episode reward: total was -80.890000. running mean: -25.284395\n",
      "ep 39: ep_len:500 episode reward: total was 9.620000. running mean: -24.935351\n",
      "ep 39: ep_len:615 episode reward: total was -9.680000. running mean: -24.782798\n",
      "ep 39: ep_len:945 episode reward: total was 23.140000. running mean: -24.303570\n",
      "ep 39: ep_len:500 episode reward: total was 4.320000. running mean: -24.017334\n",
      "ep 39: ep_len:500 episode reward: total was 21.910000. running mean: -23.558061\n",
      "ep 39: ep_len:500 episode reward: total was 24.290000. running mean: -23.079580\n",
      "ep 39: ep_len:830 episode reward: total was 3.470000. running mean: -22.814084\n",
      "ep 39: ep_len:203 episode reward: total was 15.500000. running mean: -22.430943\n",
      "ep 39: ep_len:645 episode reward: total was -49.280000. running mean: -22.699434\n",
      "ep 39: ep_len:790 episode reward: total was 19.060000. running mean: -22.281840\n",
      "ep 39: ep_len:346 episode reward: total was -44.810000. running mean: -22.507121\n",
      "ep 39: ep_len:660 episode reward: total was 8.930000. running mean: -22.192750\n",
      "ep 39: ep_len:730 episode reward: total was -5.660000. running mean: -22.027423\n",
      "ep 39: ep_len:555 episode reward: total was -13.050000. running mean: -21.937648\n",
      "ep 39: ep_len:500 episode reward: total was -7.250000. running mean: -21.790772\n",
      "ep 39: ep_len:650 episode reward: total was 19.080000. running mean: -21.382064\n",
      "ep 39: ep_len:500 episode reward: total was -22.280000. running mean: -21.391043\n",
      "ep 39: ep_len:1072 episode reward: total was -86.410000. running mean: -22.041233\n",
      "ep 39: ep_len:515 episode reward: total was -0.030000. running mean: -21.821121\n",
      "ep 39: ep_len:530 episode reward: total was -35.350000. running mean: -21.956409\n",
      "ep 39: ep_len:835 episode reward: total was 16.290000. running mean: -21.573945\n",
      "ep 39: ep_len:177 episode reward: total was 17.500000. running mean: -21.183206\n",
      "ep 39: ep_len:1314 episode reward: total was -231.730000. running mean: -23.288674\n",
      "ep 39: ep_len:775 episode reward: total was -5.570000. running mean: -23.111487\n",
      "ep 39: ep_len:1010 episode reward: total was -20.090000. running mean: -23.081272\n",
      "ep 39: ep_len:685 episode reward: total was 0.310000. running mean: -22.847360\n",
      "ep 39: ep_len:275 episode reward: total was 24.500000. running mean: -22.373886\n",
      "ep 39: ep_len:120 episode reward: total was 10.500000. running mean: -22.045147\n",
      "ep 39: ep_len:975 episode reward: total was 5.250000. running mean: -21.772196\n",
      "ep 39: ep_len:500 episode reward: total was 21.010000. running mean: -21.344374\n",
      "ep 39: ep_len:500 episode reward: total was 10.270000. running mean: -21.028230\n",
      "ep 39: ep_len:820 episode reward: total was 11.240000. running mean: -20.705548\n",
      "ep 39: ep_len:525 episode reward: total was 33.800000. running mean: -20.160492\n",
      "ep 39: ep_len:955 episode reward: total was 13.210000. running mean: -19.826787\n",
      "ep 39: ep_len:690 episode reward: total was -12.180000. running mean: -19.750319\n",
      "ep 39: ep_len:1315 episode reward: total was -187.300000. running mean: -21.425816\n",
      "ep 39: ep_len:500 episode reward: total was 2.790000. running mean: -21.183658\n",
      "ep 39: ep_len:560 episode reward: total was -5.600000. running mean: -21.027821\n",
      "ep 39: ep_len:175 episode reward: total was 16.500000. running mean: -20.652543\n",
      "ep 39: ep_len:500 episode reward: total was 1.750000. running mean: -20.428518\n",
      "ep 39: ep_len:437 episode reward: total was 28.760000. running mean: -19.936633\n",
      "ep 39: ep_len:1215 episode reward: total was -49.520000. running mean: -20.232466\n",
      "ep 39: ep_len:755 episode reward: total was -48.120000. running mean: -20.511342\n",
      "ep 39: ep_len:500 episode reward: total was 22.880000. running mean: -20.077428\n",
      "ep 39: ep_len:815 episode reward: total was -6.460000. running mean: -19.941254\n",
      "ep 39: ep_len:745 episode reward: total was -5.630000. running mean: -19.798141\n",
      "ep 39: ep_len:500 episode reward: total was 29.310000. running mean: -19.307060\n",
      "ep 39: ep_len:725 episode reward: total was -5.670000. running mean: -19.170689\n",
      "ep 39: ep_len:540 episode reward: total was -25.890000. running mean: -19.237882\n",
      "ep 39: ep_len:510 episode reward: total was -33.860000. running mean: -19.384104\n",
      "ep 39: ep_len:500 episode reward: total was 23.280000. running mean: -18.957463\n",
      "ep 39: ep_len:625 episode reward: total was 35.780000. running mean: -18.410088\n",
      "ep 39: ep_len:1990 episode reward: total was -237.460000. running mean: -20.600587\n",
      "ep 39: ep_len:1880 episode reward: total was -221.490000. running mean: -22.609481\n",
      "ep 39: ep_len:850 episode reward: total was 7.290000. running mean: -22.310486\n",
      "ep 39: ep_len:500 episode reward: total was 3.200000. running mean: -22.055382\n",
      "ep 39: ep_len:805 episode reward: total was 9.770000. running mean: -21.737128\n",
      "ep 39: ep_len:103 episode reward: total was 8.500000. running mean: -21.434756\n",
      "ep 39: ep_len:650 episode reward: total was -7.710000. running mean: -21.297509\n",
      "ep 39: ep_len:500 episode reward: total was 23.830000. running mean: -20.846234\n",
      "ep 39: ep_len:765 episode reward: total was -23.080000. running mean: -20.868571\n",
      "ep 39: ep_len:500 episode reward: total was -53.890000. running mean: -21.198786\n",
      "ep 39: ep_len:595 episode reward: total was 13.540000. running mean: -20.851398\n",
      "ep 39: ep_len:825 episode reward: total was 17.970000. running mean: -20.463184\n",
      "ep 39: ep_len:795 episode reward: total was -59.060000. running mean: -20.849152\n",
      "ep 39: ep_len:670 episode reward: total was 25.240000. running mean: -20.388261\n",
      "ep 39: ep_len:1090 episode reward: total was -176.230000. running mean: -21.946678\n",
      "ep 39: ep_len:560 episode reward: total was -51.450000. running mean: -22.241711\n",
      "ep 39: ep_len:500 episode reward: total was 25.270000. running mean: -21.766594\n",
      "ep 39: ep_len:715 episode reward: total was -49.120000. running mean: -22.040128\n",
      "ep 39: ep_len:143 episode reward: total was 14.000000. running mean: -21.679727\n",
      "ep 39: ep_len:500 episode reward: total was -27.970000. running mean: -21.742630\n",
      "ep 39: ep_len:500 episode reward: total was -20.260000. running mean: -21.727803\n",
      "ep 39: ep_len:500 episode reward: total was -37.030000. running mean: -21.880825\n",
      "ep 39: ep_len:675 episode reward: total was -5.770000. running mean: -21.719717\n",
      "ep 39: ep_len:500 episode reward: total was -3.790000. running mean: -21.540420\n",
      "ep 39: ep_len:237 episode reward: total was 22.000000. running mean: -21.105016\n",
      "ep 39: ep_len:690 episode reward: total was -57.250000. running mean: -21.466465\n",
      "ep 39: ep_len:500 episode reward: total was 20.770000. running mean: -21.044101\n",
      "ep 39: ep_len:740 episode reward: total was -13.520000. running mean: -20.968860\n",
      "ep 39: ep_len:311 episode reward: total was -59.000000. running mean: -21.349171\n",
      "ep 39: ep_len:847 episode reward: total was -75.070000. running mean: -21.886379\n",
      "ep 39: ep_len:705 episode reward: total was -36.680000. running mean: -22.034316\n",
      "ep 39: ep_len:181 episode reward: total was 12.000000. running mean: -21.693973\n",
      "ep 39: ep_len:500 episode reward: total was 24.780000. running mean: -21.229233\n",
      "ep 39: ep_len:1228 episode reward: total was -174.900000. running mean: -22.765940\n",
      "ep 39: ep_len:980 episode reward: total was -109.240000. running mean: -23.630681\n",
      "ep 39: ep_len:770 episode reward: total was -12.650000. running mean: -23.520874\n",
      "ep 39: ep_len:500 episode reward: total was 29.250000. running mean: -22.993166\n",
      "ep 39: ep_len:1035 episode reward: total was -172.710000. running mean: -24.490334\n",
      "ep 39: ep_len:885 episode reward: total was -20.500000. running mean: -24.450431\n",
      "ep 39: ep_len:500 episode reward: total was 12.900000. running mean: -24.076926\n",
      "ep 39: ep_len:520 episode reward: total was -20.740000. running mean: -24.043557\n",
      "ep 39: ep_len:725 episode reward: total was -7.170000. running mean: -23.874821\n",
      "ep 39: ep_len:805 episode reward: total was 6.420000. running mean: -23.571873\n",
      "ep 39: ep_len:770 episode reward: total was 14.700000. running mean: -23.189154\n",
      "ep 39: ep_len:810 episode reward: total was -9.770000. running mean: -23.054963\n",
      "ep 39: ep_len:500 episode reward: total was -29.410000. running mean: -23.118513\n",
      "ep 39: ep_len:745 episode reward: total was -0.670000. running mean: -22.894028\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 39: ep_len:500 episode reward: total was 50.000000. running mean: -22.165088\n",
      "ep 39: ep_len:500 episode reward: total was 8.430000. running mean: -21.859137\n",
      "ep 39: ep_len:715 episode reward: total was -1.650000. running mean: -21.657046\n",
      "ep 39: ep_len:108 episode reward: total was 10.500000. running mean: -21.335475\n",
      "ep 39: ep_len:575 episode reward: total was -31.710000. running mean: -21.439220\n",
      "ep 39: ep_len:875 episode reward: total was -27.590000. running mean: -21.500728\n",
      "ep 39: ep_len:1242 episode reward: total was -199.570000. running mean: -23.281421\n",
      "ep 39: ep_len:500 episode reward: total was 9.200000. running mean: -22.956607\n",
      "ep 39: ep_len:740 episode reward: total was 5.730000. running mean: -22.669741\n",
      "ep 39: ep_len:2010 episode reward: total was -184.710000. running mean: -24.290143\n",
      "ep 39: ep_len:500 episode reward: total was 8.210000. running mean: -23.965142\n",
      "ep 39: ep_len:820 episode reward: total was -24.670000. running mean: -23.972190\n",
      "ep 39: ep_len:500 episode reward: total was 8.670000. running mean: -23.645768\n",
      "ep 39: ep_len:500 episode reward: total was 19.790000. running mean: -23.211411\n",
      "ep 39: ep_len:3118 episode reward: total was -510.920000. running mean: -28.088497\n",
      "ep 39: ep_len:500 episode reward: total was 0.000000. running mean: -27.807612\n",
      "ep 39: ep_len:625 episode reward: total was 7.180000. running mean: -27.457736\n",
      "ep 39: ep_len:1655 episode reward: total was -35.140000. running mean: -27.534558\n",
      "ep 39: ep_len:520 episode reward: total was -12.140000. running mean: -27.380613\n",
      "ep 39: ep_len:500 episode reward: total was 3.340000. running mean: -27.073407\n",
      "ep 39: ep_len:600 episode reward: total was -26.610000. running mean: -27.068772\n",
      "ep 39: ep_len:500 episode reward: total was 14.920000. running mean: -26.648885\n",
      "ep 39: ep_len:1015 episode reward: total was 24.860000. running mean: -26.133796\n",
      "ep 39: ep_len:500 episode reward: total was 8.250000. running mean: -25.789958\n",
      "ep 39: ep_len:560 episode reward: total was -18.690000. running mean: -25.718958\n",
      "ep 39: ep_len:600 episode reward: total was -30.650000. running mean: -25.768269\n",
      "ep 39: ep_len:515 episode reward: total was -19.220000. running mean: -25.702786\n",
      "ep 39: ep_len:985 episode reward: total was -41.510000. running mean: -25.860858\n",
      "ep 39: ep_len:241 episode reward: total was 24.000000. running mean: -25.362250\n",
      "ep 39: ep_len:500 episode reward: total was -21.480000. running mean: -25.323427\n",
      "ep 39: ep_len:500 episode reward: total was -7.370000. running mean: -25.143893\n",
      "ep 39: ep_len:510 episode reward: total was 7.290000. running mean: -24.819554\n",
      "ep 39: ep_len:705 episode reward: total was -2.680000. running mean: -24.598158\n",
      "ep 39: ep_len:500 episode reward: total was -11.750000. running mean: -24.469677\n",
      "ep 39: ep_len:307 episode reward: total was 16.270000. running mean: -24.062280\n",
      "ep 39: ep_len:500 episode reward: total was 10.720000. running mean: -23.714457\n",
      "ep 39: ep_len:500 episode reward: total was 30.810000. running mean: -23.169213\n",
      "ep 39: ep_len:680 episode reward: total was -26.970000. running mean: -23.207221\n",
      "ep 39: ep_len:2345 episode reward: total was -234.300000. running mean: -25.318148\n",
      "ep 39: ep_len:143 episode reward: total was 12.500000. running mean: -24.939967\n",
      "ep 39: ep_len:645 episode reward: total was -6.320000. running mean: -24.753767\n",
      "ep 39: ep_len:540 episode reward: total was -26.240000. running mean: -24.768630\n",
      "ep 39: ep_len:500 episode reward: total was 33.760000. running mean: -24.183343\n",
      "ep 39: ep_len:500 episode reward: total was 19.540000. running mean: -23.746110\n",
      "ep 39: ep_len:625 episode reward: total was -0.820000. running mean: -23.516849\n",
      "ep 39: ep_len:580 episode reward: total was 17.190000. running mean: -23.109780\n",
      "ep 39: ep_len:550 episode reward: total was -24.200000. running mean: -23.120682\n",
      "ep 39: ep_len:500 episode reward: total was 18.590000. running mean: -22.703576\n",
      "ep 39: ep_len:780 episode reward: total was -27.680000. running mean: -22.753340\n",
      "ep 39: ep_len:720 episode reward: total was -4.670000. running mean: -22.572506\n",
      "ep 39: ep_len:174 episode reward: total was 15.500000. running mean: -22.191781\n",
      "ep 39: ep_len:675 episode reward: total was 3.240000. running mean: -21.937464\n",
      "ep 39: ep_len:500 episode reward: total was -11.320000. running mean: -21.831289\n",
      "ep 39: ep_len:500 episode reward: total was 21.360000. running mean: -21.399376\n",
      "ep 39: ep_len:221 episode reward: total was 22.000000. running mean: -20.965382\n",
      "ep 39: ep_len:1065 episode reward: total was 21.810000. running mean: -20.537628\n",
      "ep 39: ep_len:500 episode reward: total was 50.000000. running mean: -19.832252\n",
      "ep 39: ep_len:500 episode reward: total was 20.830000. running mean: -19.425630\n",
      "ep 39: ep_len:500 episode reward: total was -7.910000. running mean: -19.310473\n",
      "ep 39: ep_len:500 episode reward: total was -36.410000. running mean: -19.481469\n",
      "ep 39: ep_len:550 episode reward: total was -48.930000. running mean: -19.775954\n",
      "ep 39: ep_len:1485 episode reward: total was -205.500000. running mean: -21.633194\n",
      "ep 39: ep_len:525 episode reward: total was 13.220000. running mean: -21.284662\n",
      "ep 39: ep_len:505 episode reward: total was -13.500000. running mean: -21.206816\n",
      "ep 39: ep_len:500 episode reward: total was 23.680000. running mean: -20.757948\n",
      "ep 39: ep_len:500 episode reward: total was -5.630000. running mean: -20.606668\n",
      "ep 39: ep_len:500 episode reward: total was 3.830000. running mean: -20.362302\n",
      "ep 39: ep_len:635 episode reward: total was 9.380000. running mean: -20.064878\n",
      "ep 39: ep_len:660 episode reward: total was -13.850000. running mean: -20.002730\n",
      "ep 39: ep_len:830 episode reward: total was -7.480000. running mean: -19.877502\n",
      "ep 39: ep_len:2100 episode reward: total was -292.790000. running mean: -22.606627\n",
      "ep 39: ep_len:540 episode reward: total was 9.610000. running mean: -22.284461\n",
      "ep 39: ep_len:415 episode reward: total was 37.000000. running mean: -21.691616\n",
      "ep 39: ep_len:500 episode reward: total was 15.230000. running mean: -21.322400\n",
      "ep 39: ep_len:500 episode reward: total was 20.220000. running mean: -20.906976\n",
      "ep 39: ep_len:740 episode reward: total was -10.170000. running mean: -20.799607\n",
      "ep 39: ep_len:715 episode reward: total was -13.770000. running mean: -20.729310\n",
      "ep 39: ep_len:885 episode reward: total was 8.710000. running mean: -20.434917\n",
      "ep 39: ep_len:880 episode reward: total was 5.460000. running mean: -20.175968\n",
      "ep 39: ep_len:720 episode reward: total was -1.970000. running mean: -19.993909\n",
      "ep 39: ep_len:705 episode reward: total was 20.840000. running mean: -19.585569\n",
      "ep 39: ep_len:620 episode reward: total was -10.930000. running mean: -19.499014\n",
      "ep 39: ep_len:575 episode reward: total was -10.270000. running mean: -19.406724\n",
      "ep 39: ep_len:990 episode reward: total was 0.490000. running mean: -19.207756\n",
      "ep 39: ep_len:500 episode reward: total was 2.880000. running mean: -18.986879\n",
      "ep 39: ep_len:735 episode reward: total was -18.780000. running mean: -18.984810\n",
      "ep 39: ep_len:580 episode reward: total was 23.590000. running mean: -18.559062\n",
      "ep 39: ep_len:1020 episode reward: total was -93.560000. running mean: -19.309071\n",
      "ep 39: ep_len:610 episode reward: total was -7.920000. running mean: -19.195181\n",
      "ep 39: ep_len:635 episode reward: total was -2.820000. running mean: -19.031429\n",
      "ep 39: ep_len:500 episode reward: total was 17.650000. running mean: -18.664615\n",
      "ep 39: ep_len:545 episode reward: total was -33.500000. running mean: -18.812968\n",
      "ep 39: ep_len:665 episode reward: total was -27.000000. running mean: -18.894839\n",
      "ep 39: ep_len:530 episode reward: total was -3.030000. running mean: -18.736190\n",
      "ep 39: ep_len:565 episode reward: total was -10.030000. running mean: -18.649128\n",
      "ep 39: ep_len:500 episode reward: total was 4.970000. running mean: -18.412937\n",
      "ep 39: ep_len:750 episode reward: total was -15.720000. running mean: -18.386008\n",
      "ep 39: ep_len:880 episode reward: total was 4.080000. running mean: -18.161348\n",
      "ep 39: ep_len:605 episode reward: total was -0.860000. running mean: -17.988334\n",
      "ep 39: ep_len:500 episode reward: total was 1.660000. running mean: -17.791851\n",
      "ep 39: ep_len:500 episode reward: total was 28.330000. running mean: -17.330632\n",
      "ep 39: ep_len:620 episode reward: total was 6.280000. running mean: -17.094526\n",
      "ep 39: ep_len:499 episode reward: total was 30.770000. running mean: -16.615881\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 39: ep_len:500 episode reward: total was 32.250000. running mean: -16.127222\n",
      "ep 39: ep_len:500 episode reward: total was 1.840000. running mean: -15.947550\n",
      "ep 39: ep_len:720 episode reward: total was -5.680000. running mean: -15.844874\n",
      "ep 39: ep_len:500 episode reward: total was -16.890000. running mean: -15.855325\n",
      "ep 39: ep_len:1045 episode reward: total was -11.290000. running mean: -15.809672\n",
      "ep 39: ep_len:605 episode reward: total was 5.350000. running mean: -15.598076\n",
      "ep 39: ep_len:545 episode reward: total was -41.380000. running mean: -15.855895\n",
      "ep 39: ep_len:705 episode reward: total was -17.830000. running mean: -15.875636\n",
      "ep 39: ep_len:500 episode reward: total was 19.270000. running mean: -15.524179\n",
      "ep 39: ep_len:500 episode reward: total was 21.100000. running mean: -15.157938\n",
      "ep 39: ep_len:500 episode reward: total was 32.740000. running mean: -14.678958\n",
      "ep 39: ep_len:500 episode reward: total was 50.000000. running mean: -14.032169\n",
      "ep 39: ep_len:930 episode reward: total was -2.830000. running mean: -13.920147\n",
      "ep 39: ep_len:625 episode reward: total was -5.870000. running mean: -13.839646\n",
      "ep 39: ep_len:500 episode reward: total was -1.730000. running mean: -13.718549\n",
      "ep 39: ep_len:760 episode reward: total was -1.190000. running mean: -13.593264\n",
      "ep 39: ep_len:1205 episode reward: total was -163.820000. running mean: -15.095531\n",
      "ep 39: ep_len:210 episode reward: total was 19.500000. running mean: -14.749576\n",
      "ep 39: ep_len:1070 episode reward: total was -18.250000. running mean: -14.784580\n",
      "ep 39: ep_len:500 episode reward: total was -4.210000. running mean: -14.678834\n",
      "ep 39: ep_len:520 episode reward: total was -63.650000. running mean: -15.168546\n",
      "ep 39: ep_len:500 episode reward: total was 14.670000. running mean: -14.870160\n",
      "ep 39: ep_len:500 episode reward: total was 31.760000. running mean: -14.403859\n",
      "ep 39: ep_len:955 episode reward: total was -47.630000. running mean: -14.736120\n",
      "ep 39: ep_len:1005 episode reward: total was -79.840000. running mean: -15.387159\n",
      "ep 39: ep_len:500 episode reward: total was 17.830000. running mean: -15.054987\n",
      "ep 39: ep_len:1124 episode reward: total was -81.620000. running mean: -15.720637\n",
      "ep 39: ep_len:675 episode reward: total was 6.020000. running mean: -15.503231\n",
      "ep 39: ep_len:189 episode reward: total was 18.500000. running mean: -15.163199\n",
      "ep 39: ep_len:615 episode reward: total was -63.460000. running mean: -15.646167\n",
      "ep 39: ep_len:500 episode reward: total was -7.310000. running mean: -15.562805\n",
      "ep 39: ep_len:296 episode reward: total was 29.500000. running mean: -15.112177\n",
      "ep 39: ep_len:180 episode reward: total was 15.000000. running mean: -14.811055\n",
      "ep 39: ep_len:720 episode reward: total was -19.050000. running mean: -14.853445\n",
      "ep 39: ep_len:515 episode reward: total was -13.160000. running mean: -14.836510\n",
      "ep 39: ep_len:197 episode reward: total was 18.000000. running mean: -14.508145\n",
      "ep 39: ep_len:505 episode reward: total was -12.000000. running mean: -14.483064\n",
      "ep 39: ep_len:820 episode reward: total was -6.640000. running mean: -14.404633\n",
      "ep 39: ep_len:750 episode reward: total was 20.780000. running mean: -14.052787\n",
      "ep 39: ep_len:198 episode reward: total was 19.500000. running mean: -13.717259\n",
      "ep 39: ep_len:545 episode reward: total was -6.520000. running mean: -13.645286\n",
      "ep 39: ep_len:620 episode reward: total was -16.960000. running mean: -13.678433\n",
      "ep 39: ep_len:640 episode reward: total was 19.150000. running mean: -13.350149\n",
      "ep 39: ep_len:570 episode reward: total was -89.810000. running mean: -14.114748\n",
      "ep 39: ep_len:880 episode reward: total was 9.570000. running mean: -13.877900\n",
      "ep 39: ep_len:500 episode reward: total was 50.000000. running mean: -13.239121\n",
      "ep 39: ep_len:575 episode reward: total was -19.070000. running mean: -13.297430\n",
      "ep 39: ep_len:214 episode reward: total was 21.000000. running mean: -12.954456\n",
      "ep 39: ep_len:505 episode reward: total was -14.190000. running mean: -12.966811\n",
      "ep 39: ep_len:500 episode reward: total was 1.330000. running mean: -12.823843\n",
      "ep 39: ep_len:500 episode reward: total was 7.820000. running mean: -12.617405\n",
      "ep 39: ep_len:500 episode reward: total was -2.110000. running mean: -12.512330\n",
      "ep 39: ep_len:795 episode reward: total was 9.730000. running mean: -12.289907\n",
      "ep 39: ep_len:1225 episode reward: total was -165.260000. running mean: -13.819608\n",
      "ep 39: ep_len:500 episode reward: total was -0.670000. running mean: -13.688112\n",
      "ep 39: ep_len:500 episode reward: total was -8.830000. running mean: -13.639531\n",
      "ep 39: ep_len:550 episode reward: total was -9.540000. running mean: -13.598536\n",
      "ep 39: ep_len:247 episode reward: total was -16.450000. running mean: -13.627050\n",
      "ep 39: ep_len:690 episode reward: total was -23.550000. running mean: -13.726280\n",
      "ep 39: ep_len:1305 episode reward: total was -9.670000. running mean: -13.685717\n",
      "ep 39: ep_len:520 episode reward: total was -20.220000. running mean: -13.751060\n",
      "ep 39: ep_len:580 episode reward: total was 14.010000. running mean: -13.473449\n",
      "ep 39: ep_len:500 episode reward: total was 2.200000. running mean: -13.316715\n",
      "ep 39: ep_len:805 episode reward: total was -77.220000. running mean: -13.955748\n",
      "ep 39: ep_len:1525 episode reward: total was -177.760000. running mean: -15.593790\n",
      "ep 39: ep_len:725 episode reward: total was -3.650000. running mean: -15.474352\n",
      "ep 39: ep_len:960 episode reward: total was -46.790000. running mean: -15.787509\n",
      "ep 39: ep_len:1080 episode reward: total was -59.950000. running mean: -16.229134\n",
      "ep 39: ep_len:565 episode reward: total was -10.520000. running mean: -16.172042\n",
      "ep 39: ep_len:1030 episode reward: total was 11.860000. running mean: -15.891722\n",
      "ep 39: ep_len:230 episode reward: total was 22.000000. running mean: -15.512805\n",
      "ep 39: ep_len:1360 episode reward: total was -68.940000. running mean: -16.047077\n",
      "ep 39: ep_len:950 episode reward: total was 6.160000. running mean: -15.825006\n",
      "ep 39: ep_len:500 episode reward: total was -17.290000. running mean: -15.839656\n",
      "ep 39: ep_len:500 episode reward: total was 3.770000. running mean: -15.643559\n",
      "ep 39: ep_len:230 episode reward: total was 21.500000. running mean: -15.272124\n",
      "ep 39: ep_len:163 episode reward: total was 16.000000. running mean: -14.959402\n",
      "ep 39: ep_len:1025 episode reward: total was -30.760000. running mean: -15.117408\n",
      "ep 39: ep_len:725 episode reward: total was -48.060000. running mean: -15.446834\n",
      "ep 39: ep_len:750 episode reward: total was -43.110000. running mean: -15.723466\n",
      "ep 39: ep_len:500 episode reward: total was -2.470000. running mean: -15.590931\n",
      "ep 39: ep_len:945 episode reward: total was 3.480000. running mean: -15.400222\n",
      "ep 39: ep_len:160 episode reward: total was 13.000000. running mean: -15.116220\n",
      "ep 39: ep_len:216 episode reward: total was 21.500000. running mean: -14.750057\n",
      "ep 39: ep_len:251 episode reward: total was 25.500000. running mean: -14.347557\n",
      "ep 39: ep_len:355 episode reward: total was -19.000000. running mean: -14.394081\n",
      "ep 39: ep_len:765 episode reward: total was -13.670000. running mean: -14.386841\n",
      "ep 39: ep_len:650 episode reward: total was -4.780000. running mean: -14.290772\n",
      "ep 39: ep_len:665 episode reward: total was 26.760000. running mean: -13.880264\n",
      "ep 39: ep_len:500 episode reward: total was -6.700000. running mean: -13.808462\n",
      "ep 39: ep_len:500 episode reward: total was -59.950000. running mean: -14.269877\n",
      "ep 39: ep_len:549 episode reward: total was -66.720000. running mean: -14.794378\n",
      "ep 39: ep_len:500 episode reward: total was 2.740000. running mean: -14.619035\n",
      "ep 39: ep_len:408 episode reward: total was 2.160000. running mean: -14.451244\n",
      "ep 39: ep_len:910 episode reward: total was -8.750000. running mean: -14.394232\n",
      "ep 39: ep_len:680 episode reward: total was -37.560000. running mean: -14.625889\n",
      "ep 39: ep_len:500 episode reward: total was 11.310000. running mean: -14.366531\n",
      "ep 39: ep_len:1885 episode reward: total was -244.740000. running mean: -16.670265\n",
      "ep 39: ep_len:770 episode reward: total was -96.970000. running mean: -17.473263\n",
      "ep 39: ep_len:500 episode reward: total was -3.150000. running mean: -17.330030\n",
      "ep 39: ep_len:720 episode reward: total was 3.390000. running mean: -17.122830\n",
      "ep 39: ep_len:500 episode reward: total was 17.280000. running mean: -16.778801\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 39: ep_len:1035 episode reward: total was -106.050000. running mean: -17.671513\n",
      "ep 39: ep_len:570 episode reward: total was -72.870000. running mean: -18.223498\n",
      "ep 39: ep_len:965 episode reward: total was -53.640000. running mean: -18.577663\n",
      "ep 39: ep_len:500 episode reward: total was 5.770000. running mean: -18.334187\n",
      "ep 39: ep_len:620 episode reward: total was -26.080000. running mean: -18.411645\n",
      "ep 39: ep_len:299 episode reward: total was 28.000000. running mean: -17.947528\n",
      "ep 39: ep_len:525 episode reward: total was -47.680000. running mean: -18.244853\n",
      "ep 39: ep_len:500 episode reward: total was -11.350000. running mean: -18.175905\n",
      "ep 39: ep_len:725 episode reward: total was -10.720000. running mean: -18.101345\n",
      "ep 39: ep_len:500 episode reward: total was 21.780000. running mean: -17.702532\n",
      "ep 39: ep_len:268 episode reward: total was 26.500000. running mean: -17.260507\n",
      "ep 39: ep_len:500 episode reward: total was -26.250000. running mean: -17.350402\n",
      "ep 39: ep_len:500 episode reward: total was 28.700000. running mean: -16.889898\n",
      "ep 39: ep_len:1590 episode reward: total was -97.610000. running mean: -17.697099\n",
      "ep 39: ep_len:1090 episode reward: total was -120.570000. running mean: -18.725828\n",
      "ep 39: ep_len:525 episode reward: total was -15.160000. running mean: -18.690169\n",
      "ep 39: ep_len:615 episode reward: total was -85.680000. running mean: -19.360068\n",
      "ep 39: ep_len:530 episode reward: total was -10.910000. running mean: -19.275567\n",
      "ep 39: ep_len:930 episode reward: total was 13.300000. running mean: -18.949811\n",
      "ep 39: ep_len:745 episode reward: total was -37.950000. running mean: -19.139813\n",
      "ep 39: ep_len:1045 episode reward: total was -25.000000. running mean: -19.198415\n",
      "ep 39: ep_len:785 episode reward: total was -45.170000. running mean: -19.458131\n",
      "ep 39: ep_len:500 episode reward: total was 11.250000. running mean: -19.151050\n",
      "ep 39: ep_len:500 episode reward: total was -5.560000. running mean: -19.015139\n",
      "ep 39: ep_len:510 episode reward: total was -14.180000. running mean: -18.966788\n",
      "ep 39: ep_len:206 episode reward: total was 20.500000. running mean: -18.572120\n",
      "ep 39: ep_len:4095 episode reward: total was -779.630000. running mean: -26.182699\n",
      "ep 39: ep_len:500 episode reward: total was 12.730000. running mean: -25.793572\n",
      "ep 39: ep_len:770 episode reward: total was 12.120000. running mean: -25.414436\n",
      "ep 39: ep_len:535 episode reward: total was -12.600000. running mean: -25.286292\n",
      "ep 39: ep_len:535 episode reward: total was -3.020000. running mean: -25.063629\n",
      "ep 39: ep_len:625 episode reward: total was 19.240000. running mean: -24.620592\n",
      "ep 39: ep_len:178 episode reward: total was 17.500000. running mean: -24.199386\n",
      "ep 39: ep_len:970 episode reward: total was -9.180000. running mean: -24.049193\n",
      "ep 39: ep_len:540 episode reward: total was -12.360000. running mean: -23.932301\n",
      "ep 39: ep_len:690 episode reward: total was 0.810000. running mean: -23.684878\n",
      "ep 39: ep_len:500 episode reward: total was -11.170000. running mean: -23.559729\n",
      "ep 39: ep_len:530 episode reward: total was 15.380000. running mean: -23.170332\n",
      "ep 39: ep_len:835 episode reward: total was -34.740000. running mean: -23.286028\n",
      "ep 39: ep_len:770 episode reward: total was 32.300000. running mean: -22.730168\n",
      "ep 39: ep_len:505 episode reward: total was -7.500000. running mean: -22.577866\n",
      "ep 39: ep_len:500 episode reward: total was 4.810000. running mean: -22.303988\n",
      "ep 39: ep_len:500 episode reward: total was -47.250000. running mean: -22.553448\n",
      "ep 39: ep_len:500 episode reward: total was 27.780000. running mean: -22.050113\n",
      "ep 39: ep_len:540 episode reward: total was -10.080000. running mean: -21.930412\n",
      "ep 39: ep_len:695 episode reward: total was -6.740000. running mean: -21.778508\n",
      "ep 39: ep_len:675 episode reward: total was 1.420000. running mean: -21.546523\n",
      "ep 39: ep_len:500 episode reward: total was -27.970000. running mean: -21.610758\n",
      "ep 39: ep_len:500 episode reward: total was 4.260000. running mean: -21.352050\n",
      "ep 39: ep_len:550 episode reward: total was 14.740000. running mean: -20.991130\n",
      "ep 39: ep_len:233 episode reward: total was 20.000000. running mean: -20.581218\n",
      "ep 39: ep_len:500 episode reward: total was 16.300000. running mean: -20.212406\n",
      "ep 39: ep_len:535 episode reward: total was 9.910000. running mean: -19.911182\n",
      "ep 39: ep_len:500 episode reward: total was 50.000000. running mean: -19.212070\n",
      "ep 39: ep_len:665 episode reward: total was -28.010000. running mean: -19.300050\n",
      "ep 39: ep_len:2315 episode reward: total was -215.740000. running mean: -21.264449\n",
      "ep 39: ep_len:500 episode reward: total was 8.190000. running mean: -20.969905\n",
      "ep 39: ep_len:500 episode reward: total was 12.170000. running mean: -20.638506\n",
      "ep 39: ep_len:1735 episode reward: total was -41.430000. running mean: -20.846421\n",
      "ep 39: ep_len:1286 episode reward: total was -255.500000. running mean: -23.192956\n",
      "ep 39: ep_len:1040 episode reward: total was 6.490000. running mean: -22.896127\n",
      "ep 39: ep_len:795 episode reward: total was -9.320000. running mean: -22.760365\n",
      "ep 39: ep_len:1055 episode reward: total was -80.760000. running mean: -23.340362\n",
      "ep 39: ep_len:505 episode reward: total was 1.710000. running mean: -23.089858\n",
      "ep 39: ep_len:1440 episode reward: total was -49.690000. running mean: -23.355860\n",
      "ep 39: ep_len:165 episode reward: total was 15.000000. running mean: -22.972301\n",
      "ep 39: ep_len:950 episode reward: total was 28.260000. running mean: -22.459978\n",
      "ep 39: ep_len:500 episode reward: total was 48.500000. running mean: -21.750378\n",
      "ep 39: ep_len:500 episode reward: total was -10.470000. running mean: -21.637574\n",
      "ep 39: ep_len:525 episode reward: total was -24.250000. running mean: -21.663699\n",
      "ep 39: ep_len:510 episode reward: total was -4.080000. running mean: -21.487862\n",
      "ep 39: ep_len:202 episode reward: total was 20.000000. running mean: -21.072983\n",
      "ep 39: ep_len:119 episode reward: total was 11.500000. running mean: -20.747253\n",
      "ep 39: ep_len:269 episode reward: total was 25.500000. running mean: -20.284781\n",
      "ep 39: ep_len:860 episode reward: total was 3.330000. running mean: -20.048633\n",
      "ep 39: ep_len:500 episode reward: total was 4.750000. running mean: -19.800647\n",
      "ep 39: ep_len:720 episode reward: total was -0.630000. running mean: -19.608940\n",
      "ep 39: ep_len:1475 episode reward: total was -99.190000. running mean: -20.404751\n",
      "ep 39: ep_len:500 episode reward: total was 33.320000. running mean: -19.867503\n",
      "ep 39: ep_len:1225 episode reward: total was 5.930000. running mean: -19.609528\n",
      "ep 39: ep_len:500 episode reward: total was 9.620000. running mean: -19.317233\n",
      "ep 39: ep_len:2145 episode reward: total was -152.410000. running mean: -20.648161\n",
      "ep 39: ep_len:950 episode reward: total was -19.360000. running mean: -20.635279\n",
      "ep 39: ep_len:677 episode reward: total was -53.710000. running mean: -20.966026\n",
      "ep 39: ep_len:187 episode reward: total was 19.500000. running mean: -20.561366\n",
      "ep 39: ep_len:500 episode reward: total was 9.990000. running mean: -20.255852\n",
      "ep 39: ep_len:500 episode reward: total was -29.220000. running mean: -20.345494\n",
      "ep 39: ep_len:580 episode reward: total was -22.120000. running mean: -20.363239\n",
      "ep 39: ep_len:500 episode reward: total was -3.610000. running mean: -20.195706\n",
      "ep 39: ep_len:500 episode reward: total was 30.500000. running mean: -19.688749\n",
      "ep 39: ep_len:935 episode reward: total was -1.170000. running mean: -19.503562\n",
      "ep 39: ep_len:1219 episode reward: total was -163.210000. running mean: -20.940626\n",
      "ep 39: ep_len:1225 episode reward: total was -76.580000. running mean: -21.497020\n",
      "ep 39: ep_len:1680 episode reward: total was -120.020000. running mean: -22.482250\n",
      "ep 39: ep_len:500 episode reward: total was 20.340000. running mean: -22.054027\n",
      "ep 39: ep_len:570 episode reward: total was -31.010000. running mean: -22.143587\n",
      "ep 39: ep_len:995 episode reward: total was -78.830000. running mean: -22.710451\n",
      "ep 39: ep_len:605 episode reward: total was 34.300000. running mean: -22.140347\n",
      "ep 39: ep_len:870 episode reward: total was -13.460000. running mean: -22.053543\n",
      "ep 39: ep_len:500 episode reward: total was -13.280000. running mean: -21.965808\n",
      "ep 39: ep_len:500 episode reward: total was -10.130000. running mean: -21.847450\n",
      "ep 39: ep_len:500 episode reward: total was 3.840000. running mean: -21.590575\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 39: ep_len:672 episode reward: total was -20.220000. running mean: -21.576869\n",
      "ep 39: ep_len:905 episode reward: total was 10.830000. running mean: -21.252801\n",
      "ep 39: ep_len:500 episode reward: total was 14.280000. running mean: -20.897473\n",
      "ep 39: ep_len:301 episode reward: total was 30.000000. running mean: -20.388498\n",
      "ep 39: ep_len:500 episode reward: total was -17.440000. running mean: -20.359013\n",
      "ep 39: ep_len:690 episode reward: total was -18.870000. running mean: -20.344123\n",
      "ep 39: ep_len:860 episode reward: total was -29.640000. running mean: -20.437082\n",
      "ep 39: ep_len:500 episode reward: total was -3.510000. running mean: -20.267811\n",
      "ep 39: ep_len:705 episode reward: total was 0.610000. running mean: -20.059033\n",
      "ep 39: ep_len:570 episode reward: total was -15.070000. running mean: -20.009142\n",
      "ep 39: ep_len:11003 episode reward: total was -2107.210000. running mean: -40.881151\n",
      "ep 39: ep_len:960 episode reward: total was 11.890000. running mean: -40.353439\n",
      "ep 39: ep_len:500 episode reward: total was -15.300000. running mean: -40.102905\n",
      "ep 39: ep_len:565 episode reward: total was -31.240000. running mean: -40.014276\n",
      "ep 39: ep_len:680 episode reward: total was -5.230000. running mean: -39.666433\n",
      "ep 39: ep_len:500 episode reward: total was -0.090000. running mean: -39.270669\n",
      "ep 39: ep_len:500 episode reward: total was 3.040000. running mean: -38.847562\n",
      "ep 39: ep_len:685 episode reward: total was -6.760000. running mean: -38.526687\n",
      "ep 39: ep_len:500 episode reward: total was -2.630000. running mean: -38.167720\n",
      "ep 39: ep_len:500 episode reward: total was 19.790000. running mean: -37.588143\n",
      "ep 39: ep_len:500 episode reward: total was 26.890000. running mean: -36.943361\n",
      "ep 39: ep_len:665 episode reward: total was 32.830000. running mean: -36.245628\n",
      "ep 39: ep_len:500 episode reward: total was 17.710000. running mean: -35.706071\n",
      "ep 39: ep_len:985 episode reward: total was 25.230000. running mean: -35.096711\n",
      "ep 39: ep_len:500 episode reward: total was 23.320000. running mean: -34.512543\n",
      "ep 39: ep_len:500 episode reward: total was -60.500000. running mean: -34.772418\n",
      "ep 39: ep_len:690 episode reward: total was -2.710000. running mean: -34.451794\n",
      "ep 39: ep_len:500 episode reward: total was 11.580000. running mean: -33.991476\n",
      "ep 39: ep_len:500 episode reward: total was 6.200000. running mean: -33.589561\n",
      "ep 39: ep_len:765 episode reward: total was -16.700000. running mean: -33.420665\n",
      "ep 39: ep_len:565 episode reward: total was -0.090000. running mean: -33.087359\n",
      "ep 39: ep_len:585 episode reward: total was -11.810000. running mean: -32.874585\n",
      "ep 39: ep_len:540 episode reward: total was 9.580000. running mean: -32.450039\n",
      "ep 39: ep_len:500 episode reward: total was 12.840000. running mean: -31.997139\n",
      "ep 39: ep_len:890 episode reward: total was -20.830000. running mean: -31.885468\n",
      "ep 39: ep_len:500 episode reward: total was 26.800000. running mean: -31.298613\n",
      "ep 39: ep_len:500 episode reward: total was 18.330000. running mean: -30.802327\n",
      "ep 39: ep_len:500 episode reward: total was -35.500000. running mean: -30.849304\n",
      "ep 39: ep_len:1284 episode reward: total was -206.510000. running mean: -32.605911\n",
      "ep 39: ep_len:500 episode reward: total was -3.700000. running mean: -32.316851\n",
      "ep 39: ep_len:500 episode reward: total was 22.790000. running mean: -31.765783\n",
      "ep 39: ep_len:1720 episode reward: total was -234.530000. running mean: -33.793425\n",
      "ep 39: ep_len:500 episode reward: total was -5.840000. running mean: -33.513891\n",
      "ep 39: ep_len:336 episode reward: total was 33.500000. running mean: -32.843752\n",
      "ep 39: ep_len:130 episode reward: total was 12.000000. running mean: -32.395314\n",
      "ep 39: ep_len:500 episode reward: total was 5.860000. running mean: -32.012761\n",
      "ep 39: ep_len:500 episode reward: total was 5.150000. running mean: -31.641134\n",
      "ep 39: ep_len:835 episode reward: total was 21.050000. running mean: -31.114222\n",
      "ep 39: ep_len:540 episode reward: total was -4.020000. running mean: -30.843280\n",
      "ep 39: ep_len:610 episode reward: total was -11.000000. running mean: -30.644847\n",
      "ep 39: ep_len:234 episode reward: total was 23.000000. running mean: -30.108399\n",
      "ep 39: ep_len:500 episode reward: total was 21.810000. running mean: -29.589215\n",
      "ep 39: ep_len:705 episode reward: total was -4.700000. running mean: -29.340323\n",
      "ep 39: ep_len:720 episode reward: total was 15.420000. running mean: -28.892719\n",
      "ep 39: ep_len:715 episode reward: total was -23.870000. running mean: -28.842492\n",
      "ep 39: ep_len:1985 episode reward: total was -297.140000. running mean: -31.525467\n",
      "ep 39: ep_len:1375 episode reward: total was 24.090000. running mean: -30.969313\n",
      "ep 39: ep_len:925 episode reward: total was -0.510000. running mean: -30.664720\n",
      "ep 39: ep_len:500 episode reward: total was 16.970000. running mean: -30.188372\n",
      "ep 39: ep_len:497 episode reward: total was 7.200000. running mean: -29.814489\n",
      "ep 39: ep_len:1125 episode reward: total was -35.830000. running mean: -29.874644\n",
      "ep 39: ep_len:890 episode reward: total was 2.980000. running mean: -29.546097\n",
      "ep 39: ep_len:1269 episode reward: total was -25.650000. running mean: -29.507136\n",
      "ep 39: ep_len:880 episode reward: total was -34.860000. running mean: -29.560665\n",
      "ep 39: ep_len:920 episode reward: total was 7.450000. running mean: -29.190558\n",
      "ep 39: ep_len:525 episode reward: total was 12.310000. running mean: -28.775553\n",
      "ep 39: ep_len:2545 episode reward: total was -458.010000. running mean: -33.067897\n",
      "ep 39: ep_len:605 episode reward: total was -6.920000. running mean: -32.806418\n",
      "ep 39: ep_len:575 episode reward: total was -9.000000. running mean: -32.568354\n",
      "ep 39: ep_len:810 episode reward: total was -22.670000. running mean: -32.469370\n",
      "ep 39: ep_len:645 episode reward: total was -14.920000. running mean: -32.293877\n",
      "ep 39: ep_len:818 episode reward: total was -134.750000. running mean: -33.318438\n",
      "ep 39: ep_len:610 episode reward: total was -38.970000. running mean: -33.374954\n",
      "ep 39: ep_len:500 episode reward: total was 15.880000. running mean: -32.882404\n",
      "ep 39: ep_len:840 episode reward: total was -63.010000. running mean: -33.183680\n",
      "ep 39: ep_len:250 episode reward: total was 23.500000. running mean: -32.616843\n",
      "ep 39: ep_len:500 episode reward: total was 23.310000. running mean: -32.057575\n",
      "ep 39: ep_len:500 episode reward: total was 28.790000. running mean: -31.449099\n",
      "ep 39: ep_len:890 episode reward: total was -60.890000. running mean: -31.743508\n",
      "ep 39: ep_len:1155 episode reward: total was -227.500000. running mean: -33.701073\n",
      "ep 39: ep_len:500 episode reward: total was -15.500000. running mean: -33.519062\n",
      "ep 39: ep_len:500 episode reward: total was 4.700000. running mean: -33.136872\n",
      "ep 39: ep_len:535 episode reward: total was -27.260000. running mean: -33.078103\n",
      "ep 39: ep_len:500 episode reward: total was 19.220000. running mean: -32.555122\n",
      "ep 39: ep_len:1075 episode reward: total was -54.840000. running mean: -32.777971\n",
      "ep 39: ep_len:670 episode reward: total was -0.170000. running mean: -32.451891\n",
      "ep 39: ep_len:845 episode reward: total was 20.730000. running mean: -31.920072\n",
      "ep 39: ep_len:1510 episode reward: total was -297.490000. running mean: -34.575771\n",
      "ep 39: ep_len:605 episode reward: total was -39.240000. running mean: -34.622414\n",
      "ep 39: ep_len:690 episode reward: total was -22.910000. running mean: -34.505289\n",
      "ep 39: ep_len:500 episode reward: total was 16.250000. running mean: -33.997737\n",
      "ep 39: ep_len:870 episode reward: total was -3.620000. running mean: -33.693959\n",
      "ep 39: ep_len:500 episode reward: total was -4.190000. running mean: -33.398920\n",
      "ep 39: ep_len:500 episode reward: total was 35.770000. running mean: -32.707230\n",
      "ep 39: ep_len:650 episode reward: total was 7.320000. running mean: -32.306958\n",
      "ep 39: ep_len:735 episode reward: total was -37.970000. running mean: -32.363589\n",
      "ep 39: ep_len:1530 episode reward: total was -150.170000. running mean: -33.541653\n",
      "ep 39: ep_len:1095 episode reward: total was -84.430000. running mean: -34.050536\n",
      "ep 39: ep_len:500 episode reward: total was 9.930000. running mean: -33.610731\n",
      "ep 39: ep_len:635 episode reward: total was 17.210000. running mean: -33.102523\n",
      "ep 39: ep_len:915 episode reward: total was 17.340000. running mean: -32.598098\n",
      "ep 39: ep_len:530 episode reward: total was -20.690000. running mean: -32.479017\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 39: ep_len:494 episode reward: total was -6.720000. running mean: -32.221427\n",
      "ep 39: ep_len:500 episode reward: total was -4.800000. running mean: -31.947213\n",
      "ep 39: ep_len:965 episode reward: total was 18.730000. running mean: -31.440441\n",
      "ep 39: ep_len:500 episode reward: total was -1.710000. running mean: -31.143136\n",
      "ep 39: ep_len:500 episode reward: total was 20.980000. running mean: -30.621905\n",
      "ep 39: ep_len:665 episode reward: total was 24.840000. running mean: -30.067286\n",
      "ep 39: ep_len:500 episode reward: total was 10.030000. running mean: -29.666313\n",
      "ep 39: ep_len:520 episode reward: total was 3.870000. running mean: -29.330950\n",
      "ep 39: ep_len:720 episode reward: total was -2.650000. running mean: -29.064140\n",
      "ep 39: ep_len:655 episode reward: total was -31.060000. running mean: -29.084099\n",
      "ep 39: ep_len:905 episode reward: total was -7.380000. running mean: -28.867058\n",
      "ep 39: ep_len:218 episode reward: total was 17.000000. running mean: -28.408387\n",
      "ep 39: ep_len:535 episode reward: total was -18.430000. running mean: -28.308604\n",
      "ep 39: ep_len:930 episode reward: total was -23.740000. running mean: -28.262917\n",
      "ep 39: ep_len:500 episode reward: total was 21.930000. running mean: -27.760988\n",
      "ep 39: ep_len:318 episode reward: total was 31.500000. running mean: -27.168378\n",
      "ep 39: ep_len:920 episode reward: total was -9.740000. running mean: -26.994095\n",
      "ep 39: ep_len:500 episode reward: total was 22.120000. running mean: -26.502954\n",
      "ep 39: ep_len:805 episode reward: total was -17.630000. running mean: -26.414224\n",
      "ep 39: ep_len:825 episode reward: total was 5.220000. running mean: -26.097882\n",
      "ep 39: ep_len:555 episode reward: total was -0.590000. running mean: -25.842803\n",
      "ep 39: ep_len:925 episode reward: total was -4.590000. running mean: -25.630275\n",
      "ep 39: ep_len:1435 episode reward: total was -92.850000. running mean: -26.302472\n",
      "ep 39: ep_len:500 episode reward: total was -6.940000. running mean: -26.108848\n",
      "ep 39: ep_len:307 episode reward: total was 29.000000. running mean: -25.557759\n",
      "ep 39: ep_len:530 episode reward: total was 11.460000. running mean: -25.187582\n",
      "ep 39: ep_len:251 episode reward: total was 22.500000. running mean: -24.710706\n",
      "ep 39: ep_len:500 episode reward: total was -5.170000. running mean: -24.515299\n",
      "ep 39: ep_len:500 episode reward: total was 0.960000. running mean: -24.260546\n",
      "ep 39: ep_len:500 episode reward: total was -2.220000. running mean: -24.040140\n",
      "ep 39: ep_len:221 episode reward: total was 19.000000. running mean: -23.609739\n",
      "ep 39: ep_len:73 episode reward: total was 7.000000. running mean: -23.303641\n",
      "ep 39: ep_len:500 episode reward: total was 4.780000. running mean: -23.022805\n",
      "ep 39: ep_len:770 episode reward: total was -11.640000. running mean: -22.908977\n",
      "ep 39: ep_len:535 episode reward: total was 8.370000. running mean: -22.596187\n",
      "ep 39: ep_len:630 episode reward: total was 36.800000. running mean: -22.002225\n",
      "ep 39: ep_len:210 episode reward: total was 19.500000. running mean: -21.587203\n",
      "ep 39: ep_len:244 episode reward: total was 22.500000. running mean: -21.146331\n",
      "ep 39: ep_len:525 episode reward: total was 3.610000. running mean: -20.898768\n",
      "ep 39: ep_len:655 episode reward: total was -3.790000. running mean: -20.727680\n",
      "ep 39: ep_len:1250 episode reward: total was 17.530000. running mean: -20.345103\n",
      "ep 39: ep_len:795 episode reward: total was -13.610000. running mean: -20.277752\n",
      "ep 39: ep_len:540 episode reward: total was 21.400000. running mean: -19.860975\n",
      "ep 39: ep_len:535 episode reward: total was -9.080000. running mean: -19.753165\n",
      "ep 39: ep_len:645 episode reward: total was -11.060000. running mean: -19.666233\n",
      "ep 39: ep_len:500 episode reward: total was 18.810000. running mean: -19.281471\n",
      "ep 39: ep_len:329 episode reward: total was 16.770000. running mean: -18.920956\n",
      "ep 39: ep_len:242 episode reward: total was 24.000000. running mean: -18.491747\n",
      "ep 39: ep_len:635 episode reward: total was -19.950000. running mean: -18.506329\n",
      "ep 39: ep_len:500 episode reward: total was -7.330000. running mean: -18.394566\n",
      "ep 39: ep_len:199 episode reward: total was 19.500000. running mean: -18.015620\n",
      "ep 39: ep_len:500 episode reward: total was 5.320000. running mean: -17.782264\n",
      "ep 39: ep_len:530 episode reward: total was -11.110000. running mean: -17.715541\n",
      "ep 39: ep_len:500 episode reward: total was -9.540000. running mean: -17.633786\n",
      "ep 39: ep_len:500 episode reward: total was 8.670000. running mean: -17.370748\n",
      "ep 39: ep_len:500 episode reward: total was -27.940000. running mean: -17.476441\n",
      "ep 39: ep_len:1300 episode reward: total was -236.330000. running mean: -19.664976\n",
      "ep 39: ep_len:500 episode reward: total was 4.580000. running mean: -19.422527\n",
      "ep 39: ep_len:308 episode reward: total was 29.500000. running mean: -18.933301\n",
      "ep 39: ep_len:500 episode reward: total was -10.400000. running mean: -18.847968\n",
      "ep 39: ep_len:530 episode reward: total was -6.580000. running mean: -18.725289\n",
      "ep 39: ep_len:500 episode reward: total was 10.690000. running mean: -18.431136\n",
      "ep 39: ep_len:810 episode reward: total was -15.270000. running mean: -18.399524\n",
      "ep 39: ep_len:500 episode reward: total was 31.760000. running mean: -17.897929\n",
      "ep 39: ep_len:369 episode reward: total was 37.000000. running mean: -17.348950\n",
      "ep 39: ep_len:505 episode reward: total was -7.200000. running mean: -17.247460\n",
      "ep 39: ep_len:500 episode reward: total was 24.750000. running mean: -16.827486\n",
      "ep 39: ep_len:700 episode reward: total was 14.160000. running mean: -16.517611\n",
      "ep 39: ep_len:1180 episode reward: total was -17.170000. running mean: -16.524135\n",
      "ep 39: ep_len:500 episode reward: total was -5.950000. running mean: -16.418393\n",
      "ep 39: ep_len:1155 episode reward: total was 35.860000. running mean: -15.895609\n",
      "ep 39: ep_len:409 episode reward: total was -14.930000. running mean: -15.885953\n",
      "ep 39: ep_len:930 episode reward: total was -75.860000. running mean: -16.485694\n",
      "ep 39: ep_len:500 episode reward: total was -19.090000. running mean: -16.511737\n",
      "ep 39: ep_len:2485 episode reward: total was -371.950000. running mean: -20.066119\n",
      "ep 39: ep_len:154 episode reward: total was 15.000000. running mean: -19.715458\n",
      "ep 39: ep_len:860 episode reward: total was -13.180000. running mean: -19.650104\n",
      "ep 39: ep_len:530 episode reward: total was 6.240000. running mean: -19.391203\n",
      "ep 39: ep_len:500 episode reward: total was 50.000000. running mean: -18.697291\n",
      "ep 39: ep_len:830 episode reward: total was -6.140000. running mean: -18.571718\n",
      "ep 39: ep_len:730 episode reward: total was -10.710000. running mean: -18.493101\n",
      "ep 39: ep_len:203 episode reward: total was 20.000000. running mean: -18.108170\n",
      "ep 39: ep_len:500 episode reward: total was -21.410000. running mean: -18.141188\n",
      "ep 39: ep_len:620 episode reward: total was 1.230000. running mean: -17.947476\n",
      "ep 39: ep_len:860 episode reward: total was -9.440000. running mean: -17.862401\n",
      "ep 39: ep_len:735 episode reward: total was -63.710000. running mean: -18.320877\n",
      "ep 39: ep_len:500 episode reward: total was -22.000000. running mean: -18.357668\n",
      "ep 39: ep_len:161 episode reward: total was 16.000000. running mean: -18.014092\n",
      "ep 39: ep_len:500 episode reward: total was 11.750000. running mean: -17.716451\n",
      "ep 39: ep_len:500 episode reward: total was 28.820000. running mean: -17.251086\n",
      "ep 39: ep_len:500 episode reward: total was 7.080000. running mean: -17.007775\n",
      "ep 39: ep_len:885 episode reward: total was 17.310000. running mean: -16.664598\n",
      "ep 39: ep_len:1265 episode reward: total was -122.760000. running mean: -17.725552\n",
      "ep 39: ep_len:810 episode reward: total was -9.540000. running mean: -17.643696\n",
      "ep 39: ep_len:500 episode reward: total was -16.420000. running mean: -17.631459\n",
      "ep 39: ep_len:815 episode reward: total was 9.330000. running mean: -17.361845\n",
      "ep 39: ep_len:650 episode reward: total was -9.860000. running mean: -17.286826\n",
      "ep 39: ep_len:515 episode reward: total was 2.270000. running mean: -17.091258\n",
      "ep 39: ep_len:229 episode reward: total was 22.500000. running mean: -16.695345\n",
      "ep 39: ep_len:500 episode reward: total was 7.450000. running mean: -16.453892\n",
      "ep 39: ep_len:710 episode reward: total was -39.520000. running mean: -16.684553\n",
      "ep 39: ep_len:620 episode reward: total was 13.570000. running mean: -16.382007\n",
      "ep 39: ep_len:535 episode reward: total was -3.500000. running mean: -16.253187\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 39: ep_len:1540 episode reward: total was -201.480000. running mean: -18.105456\n",
      "ep 39: ep_len:505 episode reward: total was -44.690000. running mean: -18.371301\n",
      "ep 39: ep_len:540 episode reward: total was -0.200000. running mean: -18.189588\n",
      "ep 39: ep_len:890 episode reward: total was -13.120000. running mean: -18.138892\n",
      "ep 39: ep_len:1435 episode reward: total was -97.650000. running mean: -18.934003\n",
      "ep 39: ep_len:303 episode reward: total was 30.000000. running mean: -18.444663\n",
      "ep 39: ep_len:795 episode reward: total was -33.290000. running mean: -18.593116\n",
      "ep 39: ep_len:560 episode reward: total was -16.070000. running mean: -18.567885\n",
      "ep 39: ep_len:510 episode reward: total was -27.810000. running mean: -18.660306\n",
      "ep 39: ep_len:885 episode reward: total was -51.290000. running mean: -18.986603\n",
      "ep 39: ep_len:500 episode reward: total was 6.300000. running mean: -18.733737\n",
      "ep 39: ep_len:500 episode reward: total was 5.260000. running mean: -18.493800\n",
      "ep 39: ep_len:800 episode reward: total was 33.680000. running mean: -17.972062\n",
      "ep 39: ep_len:500 episode reward: total was 12.040000. running mean: -17.671941\n",
      "ep 39: ep_len:505 episode reward: total was -26.210000. running mean: -17.757322\n",
      "ep 39: ep_len:180 episode reward: total was 16.500000. running mean: -17.414749\n",
      "ep 39: ep_len:1065 episode reward: total was 11.090000. running mean: -17.129701\n",
      "ep 39: ep_len:500 episode reward: total was -11.800000. running mean: -17.076404\n",
      "ep 39: ep_len:505 episode reward: total was -12.580000. running mean: -17.031440\n",
      "ep 39: ep_len:760 episode reward: total was -3.610000. running mean: -16.897226\n",
      "ep 39: ep_len:710 episode reward: total was 13.600000. running mean: -16.592254\n",
      "ep 39: ep_len:575 episode reward: total was -33.820000. running mean: -16.764531\n",
      "ep 39: ep_len:500 episode reward: total was -14.680000. running mean: -16.743686\n",
      "ep 39: ep_len:550 episode reward: total was 9.580000. running mean: -16.480449\n",
      "ep 39: ep_len:1175 episode reward: total was 3.630000. running mean: -16.279344\n",
      "ep 39: ep_len:745 episode reward: total was -12.700000. running mean: -16.243551\n",
      "ep 39: ep_len:500 episode reward: total was 25.850000. running mean: -15.822615\n",
      "ep 39: ep_len:540 episode reward: total was -23.210000. running mean: -15.896489\n",
      "ep 39: ep_len:530 episode reward: total was -8.260000. running mean: -15.820124\n",
      "ep 39: ep_len:645 episode reward: total was 5.670000. running mean: -15.605223\n",
      "ep 39: ep_len:219 episode reward: total was 7.150000. running mean: -15.377671\n",
      "ep 39: ep_len:540 episode reward: total was -3.010000. running mean: -15.253994\n",
      "ep 39: ep_len:1200 episode reward: total was -45.770000. running mean: -15.559154\n",
      "ep 39: ep_len:735 episode reward: total was -10.700000. running mean: -15.510563\n",
      "ep 39: ep_len:500 episode reward: total was 16.820000. running mean: -15.187257\n",
      "ep 39: ep_len:500 episode reward: total was -7.430000. running mean: -15.109684\n",
      "ep 39: ep_len:825 episode reward: total was -38.280000. running mean: -15.341388\n",
      "ep 39: ep_len:500 episode reward: total was -4.800000. running mean: -15.235974\n",
      "ep 39: ep_len:500 episode reward: total was 28.360000. running mean: -14.800014\n",
      "ep 39: ep_len:500 episode reward: total was 33.290000. running mean: -14.319114\n",
      "ep 39: ep_len:780 episode reward: total was -16.150000. running mean: -14.337423\n",
      "ep 39: ep_len:925 episode reward: total was -15.420000. running mean: -14.348249\n",
      "ep 39: ep_len:500 episode reward: total was 21.260000. running mean: -13.992166\n",
      "ep 39: ep_len:170 episode reward: total was 15.500000. running mean: -13.697244\n",
      "ep 39: ep_len:855 episode reward: total was -5.640000. running mean: -13.616672\n",
      "ep 39: ep_len:500 episode reward: total was 26.310000. running mean: -13.217405\n",
      "ep 39: ep_len:1630 episode reward: total was -241.210000. running mean: -15.497331\n",
      "ep 39: ep_len:500 episode reward: total was 22.810000. running mean: -15.114258\n",
      "ep 39: ep_len:1395 episode reward: total was -232.590000. running mean: -17.289015\n",
      "ep 39: ep_len:1445 episode reward: total was -192.110000. running mean: -19.037225\n",
      "ep 39: ep_len:500 episode reward: total was 15.290000. running mean: -18.693953\n",
      "ep 39: ep_len:875 episode reward: total was -15.470000. running mean: -18.661713\n",
      "ep 39: ep_len:500 episode reward: total was 2.330000. running mean: -18.451796\n",
      "ep 39: ep_len:695 episode reward: total was -7.750000. running mean: -18.344778\n",
      "ep 39: ep_len:605 episode reward: total was -18.030000. running mean: -18.341630\n",
      "ep 39: ep_len:520 episode reward: total was -30.320000. running mean: -18.461414\n",
      "ep 39: ep_len:660 episode reward: total was 17.200000. running mean: -18.104800\n",
      "ep 39: ep_len:225 episode reward: total was 21.000000. running mean: -17.713752\n",
      "ep 39: ep_len:505 episode reward: total was -15.250000. running mean: -17.689114\n",
      "ep 39: ep_len:151 episode reward: total was 15.000000. running mean: -17.362223\n",
      "ep 39: ep_len:905 episode reward: total was 13.860000. running mean: -17.050001\n",
      "ep 39: ep_len:292 episode reward: total was 29.000000. running mean: -16.589501\n",
      "ep 39: ep_len:500 episode reward: total was 1.930000. running mean: -16.404306\n",
      "ep 39: ep_len:1045 episode reward: total was -114.130000. running mean: -17.381563\n",
      "ep 39: ep_len:500 episode reward: total was 8.990000. running mean: -17.117847\n",
      "ep 39: ep_len:775 episode reward: total was -3.550000. running mean: -16.982169\n",
      "ep 39: ep_len:710 episode reward: total was -74.380000. running mean: -17.556147\n",
      "ep 39: ep_len:247 episode reward: total was 23.000000. running mean: -17.150586\n",
      "ep 39: ep_len:500 episode reward: total was -8.810000. running mean: -17.067180\n",
      "ep 39: ep_len:840 episode reward: total was 10.730000. running mean: -16.789208\n",
      "ep 39: ep_len:500 episode reward: total was 22.330000. running mean: -16.398016\n",
      "ep 39: ep_len:4180 episode reward: total was -665.360000. running mean: -22.887636\n",
      "ep 39: ep_len:500 episode reward: total was 22.330000. running mean: -22.435460\n",
      "ep 39: ep_len:194 episode reward: total was 17.500000. running mean: -22.036105\n",
      "ep 39: ep_len:352 episode reward: total was 1.060000. running mean: -21.805144\n",
      "ep 39: ep_len:680 episode reward: total was 0.300000. running mean: -21.584092\n",
      "ep 39: ep_len:505 episode reward: total was -1.330000. running mean: -21.381552\n",
      "ep 39: ep_len:500 episode reward: total was 12.840000. running mean: -21.039336\n",
      "ep 39: ep_len:339 episode reward: total was 34.000000. running mean: -20.488943\n",
      "ep 39: ep_len:500 episode reward: total was 16.760000. running mean: -20.116453\n",
      "ep 39: ep_len:620 episode reward: total was -18.000000. running mean: -20.095289\n",
      "ep 39: ep_len:500 episode reward: total was 24.780000. running mean: -19.646536\n",
      "ep 39: ep_len:500 episode reward: total was 6.250000. running mean: -19.387570\n",
      "ep 39: ep_len:740 episode reward: total was -9.680000. running mean: -19.290495\n",
      "ep 39: ep_len:715 episode reward: total was 20.250000. running mean: -18.895090\n",
      "ep 39: ep_len:580 episode reward: total was -8.370000. running mean: -18.789839\n",
      "ep 39: ep_len:500 episode reward: total was 13.240000. running mean: -18.469540\n",
      "ep 39: ep_len:2455 episode reward: total was -366.610000. running mean: -21.950945\n",
      "ep 39: ep_len:500 episode reward: total was 9.780000. running mean: -21.633636\n",
      "ep 39: ep_len:505 episode reward: total was -19.240000. running mean: -21.609699\n",
      "ep 39: ep_len:472 episode reward: total was 20.220000. running mean: -21.191402\n",
      "ep 39: ep_len:1140 episode reward: total was -72.510000. running mean: -21.704588\n",
      "ep 39: ep_len:660 episode reward: total was -11.460000. running mean: -21.602142\n",
      "ep 39: ep_len:500 episode reward: total was 2.220000. running mean: -21.363921\n",
      "ep 39: ep_len:982 episode reward: total was -102.100000. running mean: -22.171282\n",
      "ep 39: ep_len:457 episode reward: total was 7.270000. running mean: -21.876869\n",
      "ep 39: ep_len:500 episode reward: total was 23.840000. running mean: -21.419700\n",
      "ep 39: ep_len:500 episode reward: total was 19.730000. running mean: -21.008203\n",
      "ep 39: ep_len:820 episode reward: total was -12.820000. running mean: -20.926321\n",
      "ep 39: ep_len:500 episode reward: total was 21.380000. running mean: -20.503258\n",
      "ep 39: ep_len:715 episode reward: total was 18.920000. running mean: -20.109025\n",
      "ep 39: ep_len:575 episode reward: total was -17.960000. running mean: -20.087535\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 39: ep_len:57 episode reward: total was 5.500000. running mean: -19.831660\n",
      "ep 39: ep_len:520 episode reward: total was 23.300000. running mean: -19.400343\n",
      "ep 39: ep_len:500 episode reward: total was 19.800000. running mean: -19.008340\n",
      "ep 39: ep_len:500 episode reward: total was 24.440000. running mean: -18.573856\n",
      "ep 39: ep_len:500 episode reward: total was 3.070000. running mean: -18.357418\n",
      "ep 39: ep_len:177 episode reward: total was 17.500000. running mean: -17.998844\n",
      "ep 39: ep_len:500 episode reward: total was 6.100000. running mean: -17.757855\n",
      "ep 39: ep_len:925 episode reward: total was 9.910000. running mean: -17.481177\n",
      "ep 39: ep_len:660 episode reward: total was -42.160000. running mean: -17.727965\n",
      "ep 39: ep_len:830 episode reward: total was -17.580000. running mean: -17.726485\n",
      "ep 39: ep_len:695 episode reward: total was -1.190000. running mean: -17.561120\n",
      "ep 39: ep_len:500 episode reward: total was -16.280000. running mean: -17.548309\n",
      "ep 39: ep_len:500 episode reward: total was -39.290000. running mean: -17.765726\n",
      "ep 39: ep_len:670 episode reward: total was 2.450000. running mean: -17.563569\n",
      "ep 39: ep_len:505 episode reward: total was -34.470000. running mean: -17.732633\n",
      "ep 39: ep_len:515 episode reward: total was 2.360000. running mean: -17.531707\n",
      "ep 39: ep_len:925 episode reward: total was 7.300000. running mean: -17.283390\n",
      "ep 39: ep_len:825 episode reward: total was 12.240000. running mean: -16.988156\n",
      "ep 39: ep_len:505 episode reward: total was -6.110000. running mean: -16.879374\n",
      "ep 39: ep_len:500 episode reward: total was -30.390000. running mean: -17.014481\n",
      "ep 39: ep_len:845 episode reward: total was -5.820000. running mean: -16.902536\n",
      "ep 39: ep_len:795 episode reward: total was -73.200000. running mean: -17.465510\n",
      "ep 39: ep_len:810 episode reward: total was 3.570000. running mean: -17.255155\n",
      "ep 39: ep_len:540 episode reward: total was 13.960000. running mean: -16.943004\n",
      "ep 39: ep_len:755 episode reward: total was 11.640000. running mean: -16.657174\n",
      "ep 39: ep_len:715 episode reward: total was -9.730000. running mean: -16.587902\n",
      "ep 39: ep_len:500 episode reward: total was 22.820000. running mean: -16.193823\n",
      "ep 39: ep_len:735 episode reward: total was -4.640000. running mean: -16.078285\n",
      "ep 39: ep_len:540 episode reward: total was -2.210000. running mean: -15.939602\n",
      "ep 39: ep_len:316 episode reward: total was 30.500000. running mean: -15.475206\n",
      "ep 39: ep_len:735 episode reward: total was -6.660000. running mean: -15.387054\n",
      "ep 39: ep_len:500 episode reward: total was -22.300000. running mean: -15.456183\n",
      "ep 39: ep_len:840 episode reward: total was -13.770000. running mean: -15.439321\n",
      "ep 39: ep_len:192 episode reward: total was 16.000000. running mean: -15.124928\n",
      "ep 39: ep_len:500 episode reward: total was 21.330000. running mean: -14.760379\n",
      "ep 39: ep_len:520 episode reward: total was -6.080000. running mean: -14.673575\n",
      "ep 39: ep_len:500 episode reward: total was 21.780000. running mean: -14.309039\n",
      "ep 39: ep_len:500 episode reward: total was -2.600000. running mean: -14.191949\n",
      "ep 39: ep_len:500 episode reward: total was 10.310000. running mean: -13.946929\n",
      "ep 39: ep_len:500 episode reward: total was -55.180000. running mean: -14.359260\n",
      "ep 39: ep_len:505 episode reward: total was -34.390000. running mean: -14.559568\n",
      "ep 39: ep_len:665 episode reward: total was 9.340000. running mean: -14.320572\n",
      "ep 39: ep_len:545 episode reward: total was -3.580000. running mean: -14.213166\n",
      "ep 39: ep_len:500 episode reward: total was 14.580000. running mean: -13.925235\n",
      "ep 39: ep_len:2730 episode reward: total was -435.490000. running mean: -18.140882\n",
      "ep 39: ep_len:875 episode reward: total was 11.010000. running mean: -17.849373\n",
      "ep 39: ep_len:5486 episode reward: total was -892.530000. running mean: -26.596180\n",
      "ep 39: ep_len:600 episode reward: total was -36.220000. running mean: -26.692418\n",
      "ep 39: ep_len:500 episode reward: total was -27.910000. running mean: -26.704594\n",
      "ep 39: ep_len:2056 episode reward: total was -171.660000. running mean: -28.154148\n",
      "ep 39: ep_len:650 episode reward: total was -38.140000. running mean: -28.254006\n",
      "ep 39: ep_len:500 episode reward: total was 47.000000. running mean: -27.501466\n",
      "ep 39: ep_len:500 episode reward: total was 9.010000. running mean: -27.136352\n",
      "epsilon:0.010000 episode_count: 31559. steps_count: 22883163.000000\n",
      "ep 40: ep_len:500 episode reward: total was 14.680000. running mean: -26.718188\n",
      "ep 40: ep_len:805 episode reward: total was -21.640000. running mean: -26.667406\n",
      "ep 40: ep_len:500 episode reward: total was -5.870000. running mean: -26.459432\n",
      "ep 40: ep_len:990 episode reward: total was -121.260000. running mean: -27.407438\n",
      "ep 40: ep_len:845 episode reward: total was 35.790000. running mean: -26.775463\n",
      "ep 40: ep_len:550 episode reward: total was -6.320000. running mean: -26.570909\n",
      "ep 40: ep_len:500 episode reward: total was 1.300000. running mean: -26.292200\n",
      "ep 40: ep_len:500 episode reward: total was 15.320000. running mean: -25.876078\n",
      "ep 40: ep_len:835 episode reward: total was -27.670000. running mean: -25.894017\n",
      "ep 40: ep_len:510 episode reward: total was -11.150000. running mean: -25.746577\n",
      "ep 40: ep_len:810 episode reward: total was 37.770000. running mean: -25.111411\n",
      "ep 40: ep_len:675 episode reward: total was -40.110000. running mean: -25.261397\n",
      "ep 40: ep_len:500 episode reward: total was 25.820000. running mean: -24.750583\n",
      "ep 40: ep_len:1170 episode reward: total was 2.460000. running mean: -24.478477\n",
      "ep 40: ep_len:850 episode reward: total was -19.560000. running mean: -24.429292\n",
      "ep 40: ep_len:500 episode reward: total was 29.800000. running mean: -23.886999\n",
      "ep 40: ep_len:670 episode reward: total was 1.290000. running mean: -23.635229\n",
      "ep 40: ep_len:500 episode reward: total was 0.690000. running mean: -23.391977\n",
      "ep 40: ep_len:299 episode reward: total was 29.500000. running mean: -22.863057\n",
      "ep 40: ep_len:560 episode reward: total was -13.070000. running mean: -22.765127\n",
      "ep 40: ep_len:710 episode reward: total was 31.270000. running mean: -22.224775\n",
      "ep 40: ep_len:1880 episode reward: total was -24.270000. running mean: -22.245228\n",
      "ep 40: ep_len:322 episode reward: total was 32.000000. running mean: -21.702775\n",
      "ep 40: ep_len:630 episode reward: total was 13.320000. running mean: -21.352548\n",
      "ep 40: ep_len:500 episode reward: total was 1.170000. running mean: -21.127322\n",
      "ep 40: ep_len:775 episode reward: total was -4.140000. running mean: -20.957449\n",
      "ep 40: ep_len:535 episode reward: total was 8.250000. running mean: -20.665374\n",
      "ep 40: ep_len:910 episode reward: total was -127.510000. running mean: -21.733821\n",
      "ep 40: ep_len:1229 episode reward: total was -192.590000. running mean: -23.442383\n",
      "ep 40: ep_len:530 episode reward: total was -4.040000. running mean: -23.248359\n",
      "ep 40: ep_len:500 episode reward: total was 16.330000. running mean: -22.852575\n",
      "ep 40: ep_len:246 episode reward: total was 23.000000. running mean: -22.394049\n",
      "ep 40: ep_len:530 episode reward: total was -2.020000. running mean: -22.190309\n",
      "ep 40: ep_len:500 episode reward: total was -0.670000. running mean: -21.975106\n",
      "ep 40: ep_len:335 episode reward: total was 15.170000. running mean: -21.603655\n",
      "ep 40: ep_len:500 episode reward: total was -6.640000. running mean: -21.454018\n",
      "ep 40: ep_len:500 episode reward: total was -45.690000. running mean: -21.696378\n",
      "ep 40: ep_len:550 episode reward: total was -11.070000. running mean: -21.590114\n",
      "ep 40: ep_len:500 episode reward: total was 4.780000. running mean: -21.326413\n",
      "ep 40: ep_len:615 episode reward: total was 21.670000. running mean: -20.896449\n",
      "ep 40: ep_len:735 episode reward: total was 10.770000. running mean: -20.579784\n",
      "ep 40: ep_len:505 episode reward: total was -0.050000. running mean: -20.374487\n",
      "ep 40: ep_len:940 episode reward: total was 25.190000. running mean: -19.918842\n",
      "ep 40: ep_len:500 episode reward: total was 21.780000. running mean: -19.501853\n",
      "ep 40: ep_len:750 episode reward: total was 12.230000. running mean: -19.184535\n",
      "ep 40: ep_len:500 episode reward: total was 50.000000. running mean: -18.492689\n",
      "ep 40: ep_len:785 episode reward: total was -13.200000. running mean: -18.439763\n",
      "ep 40: ep_len:900 episode reward: total was -41.650000. running mean: -18.671865\n",
      "ep 40: ep_len:500 episode reward: total was 16.860000. running mean: -18.316546\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 40: ep_len:156 episode reward: total was 14.000000. running mean: -17.993381\n",
      "ep 40: ep_len:780 episode reward: total was -5.070000. running mean: -17.864147\n",
      "ep 40: ep_len:500 episode reward: total was 16.450000. running mean: -17.521006\n",
      "ep 40: ep_len:500 episode reward: total was -5.260000. running mean: -17.398395\n",
      "ep 40: ep_len:680 episode reward: total was 0.300000. running mean: -17.221412\n",
      "ep 40: ep_len:457 episode reward: total was 1.110000. running mean: -17.038097\n",
      "ep 40: ep_len:500 episode reward: total was -10.160000. running mean: -16.969316\n",
      "ep 40: ep_len:500 episode reward: total was 10.110000. running mean: -16.698523\n",
      "ep 40: ep_len:915 episode reward: total was -10.520000. running mean: -16.636738\n",
      "ep 40: ep_len:765 episode reward: total was -26.860000. running mean: -16.738971\n",
      "ep 40: ep_len:585 episode reward: total was -8.980000. running mean: -16.661381\n",
      "ep 40: ep_len:900 episode reward: total was 24.670000. running mean: -16.248067\n",
      "ep 40: ep_len:660 episode reward: total was 5.900000. running mean: -16.026586\n",
      "ep 40: ep_len:1035 episode reward: total was -44.440000. running mean: -16.310721\n",
      "ep 40: ep_len:760 episode reward: total was -4.030000. running mean: -16.187913\n",
      "ep 40: ep_len:671 episode reward: total was -44.190000. running mean: -16.467934\n",
      "ep 40: ep_len:295 episode reward: total was 26.500000. running mean: -16.038255\n",
      "ep 40: ep_len:655 episode reward: total was -3.790000. running mean: -15.915772\n",
      "ep 40: ep_len:500 episode reward: total was 24.320000. running mean: -15.513415\n",
      "ep 40: ep_len:655 episode reward: total was -4.800000. running mean: -15.406280\n",
      "ep 40: ep_len:411 episode reward: total was -33.550000. running mean: -15.587718\n",
      "ep 40: ep_len:605 episode reward: total was 16.300000. running mean: -15.268841\n",
      "ep 40: ep_len:740 episode reward: total was 12.430000. running mean: -14.991852\n",
      "ep 40: ep_len:870 episode reward: total was 11.660000. running mean: -14.725334\n",
      "ep 40: ep_len:3016 episode reward: total was -345.480000. running mean: -18.032880\n",
      "ep 40: ep_len:500 episode reward: total was -60.500000. running mean: -18.457551\n",
      "ep 40: ep_len:1135 episode reward: total was -151.300000. running mean: -19.785976\n",
      "ep 40: ep_len:500 episode reward: total was 1.670000. running mean: -19.571416\n",
      "ep 40: ep_len:635 episode reward: total was -1.810000. running mean: -19.393802\n",
      "ep 40: ep_len:93 episode reward: total was 9.000000. running mean: -19.109864\n",
      "ep 40: ep_len:510 episode reward: total was -4.080000. running mean: -18.959565\n",
      "ep 40: ep_len:248 episode reward: total was 24.500000. running mean: -18.524970\n",
      "ep 40: ep_len:565 episode reward: total was 18.760000. running mean: -18.152120\n",
      "ep 40: ep_len:665 episode reward: total was -9.060000. running mean: -18.061199\n",
      "ep 40: ep_len:500 episode reward: total was 10.490000. running mean: -17.775687\n",
      "ep 40: ep_len:500 episode reward: total was 16.240000. running mean: -17.435530\n",
      "ep 40: ep_len:500 episode reward: total was 35.800000. running mean: -16.903175\n",
      "ep 40: ep_len:500 episode reward: total was -0.450000. running mean: -16.738643\n",
      "ep 40: ep_len:500 episode reward: total was 20.280000. running mean: -16.368456\n",
      "ep 40: ep_len:735 episode reward: total was -11.710000. running mean: -16.321872\n",
      "ep 40: ep_len:500 episode reward: total was 4.850000. running mean: -16.110153\n",
      "ep 40: ep_len:19195 episode reward: total was -3744.110000. running mean: -53.390152\n",
      "ep 40: ep_len:505 episode reward: total was 12.240000. running mean: -52.733850\n",
      "ep 40: ep_len:242 episode reward: total was 24.000000. running mean: -51.966512\n",
      "ep 40: ep_len:500 episode reward: total was -4.830000. running mean: -51.495147\n",
      "ep 40: ep_len:640 episode reward: total was -5.250000. running mean: -51.032695\n",
      "ep 40: ep_len:500 episode reward: total was 5.160000. running mean: -50.470768\n",
      "ep 40: ep_len:695 episode reward: total was -84.510000. running mean: -50.811160\n",
      "ep 40: ep_len:500 episode reward: total was 19.240000. running mean: -50.110649\n",
      "ep 40: ep_len:905 episode reward: total was -47.500000. running mean: -50.084542\n",
      "ep 40: ep_len:500 episode reward: total was -27.910000. running mean: -49.862797\n",
      "ep 40: ep_len:615 episode reward: total was -58.740000. running mean: -49.951569\n",
      "ep 40: ep_len:845 episode reward: total was -73.080000. running mean: -50.182853\n",
      "ep 40: ep_len:595 episode reward: total was -43.300000. running mean: -50.114025\n",
      "ep 40: ep_len:620 episode reward: total was -49.310000. running mean: -50.105984\n",
      "ep 40: ep_len:218 episode reward: total was 22.000000. running mean: -49.384925\n",
      "ep 40: ep_len:525 episode reward: total was -11.630000. running mean: -49.007375\n",
      "ep 40: ep_len:500 episode reward: total was 12.320000. running mean: -48.394102\n",
      "ep 40: ep_len:500 episode reward: total was 13.330000. running mean: -47.776861\n",
      "ep 40: ep_len:500 episode reward: total was 30.720000. running mean: -46.991892\n",
      "ep 40: ep_len:915 episode reward: total was -9.420000. running mean: -46.616173\n",
      "ep 40: ep_len:830 episode reward: total was -39.800000. running mean: -46.548011\n",
      "ep 40: ep_len:500 episode reward: total was -3.200000. running mean: -46.114531\n",
      "ep 40: ep_len:755 episode reward: total was -16.670000. running mean: -45.820086\n",
      "ep 40: ep_len:1020 episode reward: total was -30.570000. running mean: -45.667585\n",
      "ep 40: ep_len:650 episode reward: total was 15.800000. running mean: -45.052909\n",
      "ep 40: ep_len:785 episode reward: total was 13.780000. running mean: -44.464580\n",
      "ep 40: ep_len:2008 episode reward: total was -355.580000. running mean: -47.575734\n",
      "ep 40: ep_len:575 episode reward: total was -13.490000. running mean: -47.234877\n",
      "ep 40: ep_len:765 episode reward: total was -23.770000. running mean: -47.000228\n",
      "ep 40: ep_len:500 episode reward: total was 50.000000. running mean: -46.030226\n",
      "ep 40: ep_len:500 episode reward: total was 5.860000. running mean: -45.511324\n",
      "ep 40: ep_len:735 episode reward: total was -22.820000. running mean: -45.284410\n",
      "ep 40: ep_len:143 episode reward: total was 14.000000. running mean: -44.691566\n",
      "ep 40: ep_len:500 episode reward: total was 11.280000. running mean: -44.131851\n",
      "ep 40: ep_len:1005 episode reward: total was -38.800000. running mean: -44.078532\n",
      "ep 40: ep_len:1080 episode reward: total was -6.350000. running mean: -43.701247\n",
      "ep 40: ep_len:287 episode reward: total was 28.500000. running mean: -42.979234\n",
      "ep 40: ep_len:710 episode reward: total was -33.500000. running mean: -42.884442\n",
      "ep 40: ep_len:500 episode reward: total was 24.820000. running mean: -42.207398\n",
      "ep 40: ep_len:2446 episode reward: total was -207.410000. running mean: -43.859424\n",
      "ep 40: ep_len:2228 episode reward: total was -272.320000. running mean: -46.144029\n",
      "ep 40: ep_len:500 episode reward: total was 0.870000. running mean: -45.673889\n",
      "ep 40: ep_len:500 episode reward: total was -42.290000. running mean: -45.640050\n",
      "ep 40: ep_len:500 episode reward: total was 16.820000. running mean: -45.015450\n",
      "ep 40: ep_len:2485 episode reward: total was -184.960000. running mean: -46.414895\n",
      "ep 40: ep_len:500 episode reward: total was 21.720000. running mean: -45.733546\n",
      "ep 40: ep_len:520 episode reward: total was 24.820000. running mean: -45.028011\n",
      "ep 40: ep_len:1630 episode reward: total was -43.180000. running mean: -45.009531\n",
      "ep 40: ep_len:500 episode reward: total was 22.790000. running mean: -44.331535\n",
      "ep 40: ep_len:515 episode reward: total was -5.170000. running mean: -43.939920\n",
      "ep 40: ep_len:500 episode reward: total was 50.000000. running mean: -43.000521\n",
      "ep 40: ep_len:167 episode reward: total was 15.000000. running mean: -42.420516\n",
      "ep 40: ep_len:555 episode reward: total was 11.110000. running mean: -41.885210\n",
      "ep 40: ep_len:685 episode reward: total was -6.240000. running mean: -41.528758\n",
      "ep 40: ep_len:580 episode reward: total was -5.770000. running mean: -41.171171\n",
      "ep 40: ep_len:263 episode reward: total was 26.000000. running mean: -40.499459\n",
      "ep 40: ep_len:500 episode reward: total was 29.800000. running mean: -39.796464\n",
      "ep 40: ep_len:695 episode reward: total was -31.680000. running mean: -39.715300\n",
      "ep 40: ep_len:570 episode reward: total was -51.090000. running mean: -39.829047\n",
      "ep 40: ep_len:500 episode reward: total was -10.680000. running mean: -39.537556\n",
      "ep 40: ep_len:247 episode reward: total was 23.000000. running mean: -38.912181\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 40: ep_len:500 episode reward: total was 21.960000. running mean: -38.303459\n",
      "ep 40: ep_len:900 episode reward: total was 23.660000. running mean: -37.683824\n",
      "ep 40: ep_len:920 episode reward: total was 13.280000. running mean: -37.174186\n",
      "ep 40: ep_len:930 episode reward: total was 16.730000. running mean: -36.635144\n",
      "ep 40: ep_len:885 episode reward: total was 7.470000. running mean: -36.194093\n",
      "ep 40: ep_len:615 episode reward: total was -6.900000. running mean: -35.901152\n",
      "ep 40: ep_len:500 episode reward: total was 3.740000. running mean: -35.504740\n",
      "ep 40: ep_len:500 episode reward: total was 29.370000. running mean: -34.855993\n",
      "ep 40: ep_len:500 episode reward: total was 1.660000. running mean: -34.490833\n",
      "ep 40: ep_len:830 episode reward: total was -17.580000. running mean: -34.321725\n",
      "ep 40: ep_len:204 episode reward: total was 20.000000. running mean: -33.778507\n",
      "ep 40: ep_len:1000 episode reward: total was 14.150000. running mean: -33.299222\n",
      "ep 40: ep_len:555 episode reward: total was -22.170000. running mean: -33.187930\n",
      "ep 40: ep_len:500 episode reward: total was 28.270000. running mean: -32.573351\n",
      "ep 40: ep_len:715 episode reward: total was 18.360000. running mean: -32.064017\n",
      "ep 40: ep_len:615 episode reward: total was -3.870000. running mean: -31.782077\n",
      "ep 40: ep_len:500 episode reward: total was -1.650000. running mean: -31.480756\n",
      "ep 40: ep_len:785 episode reward: total was -18.680000. running mean: -31.352749\n",
      "ep 40: ep_len:500 episode reward: total was 5.550000. running mean: -30.983721\n",
      "ep 40: ep_len:560 episode reward: total was 1.270000. running mean: -30.661184\n",
      "ep 40: ep_len:735 episode reward: total was -6.660000. running mean: -30.421172\n",
      "ep 40: ep_len:76 episode reward: total was 8.000000. running mean: -30.036961\n",
      "ep 40: ep_len:1035 episode reward: total was -31.120000. running mean: -30.047791\n",
      "ep 40: ep_len:755 episode reward: total was -11.150000. running mean: -29.858813\n",
      "ep 40: ep_len:500 episode reward: total was 16.370000. running mean: -29.396525\n",
      "ep 40: ep_len:196 episode reward: total was 20.000000. running mean: -28.902560\n",
      "ep 40: ep_len:500 episode reward: total was 4.320000. running mean: -28.570334\n",
      "ep 40: ep_len:500 episode reward: total was 20.310000. running mean: -28.081531\n",
      "ep 40: ep_len:660 episode reward: total was -34.080000. running mean: -28.141515\n",
      "ep 40: ep_len:500 episode reward: total was -5.680000. running mean: -27.916900\n",
      "ep 40: ep_len:520 episode reward: total was -21.210000. running mean: -27.849831\n",
      "ep 40: ep_len:500 episode reward: total was 1.230000. running mean: -27.559033\n",
      "ep 40: ep_len:216 episode reward: total was 17.000000. running mean: -27.113443\n",
      "ep 40: ep_len:500 episode reward: total was 10.200000. running mean: -26.740308\n",
      "ep 40: ep_len:585 episode reward: total was -20.090000. running mean: -26.673805\n",
      "ep 40: ep_len:665 episode reward: total was -97.700000. running mean: -27.384067\n",
      "ep 40: ep_len:500 episode reward: total was 23.800000. running mean: -26.872226\n",
      "ep 40: ep_len:500 episode reward: total was -8.170000. running mean: -26.685204\n",
      "ep 40: ep_len:500 episode reward: total was -1.720000. running mean: -26.435552\n",
      "ep 40: ep_len:670 episode reward: total was -7.800000. running mean: -26.249197\n",
      "ep 40: ep_len:1090 episode reward: total was 25.870000. running mean: -25.728005\n",
      "ep 40: ep_len:194 episode reward: total was 19.500000. running mean: -25.275725\n",
      "ep 40: ep_len:2781 episode reward: total was -270.200000. running mean: -27.724967\n",
      "ep 40: ep_len:590 episode reward: total was -21.060000. running mean: -27.658318\n",
      "ep 40: ep_len:1916 episode reward: total was -187.090000. running mean: -29.252634\n",
      "ep 40: ep_len:500 episode reward: total was 18.290000. running mean: -28.777208\n",
      "ep 40: ep_len:500 episode reward: total was 12.200000. running mean: -28.367436\n",
      "ep 40: ep_len:935 episode reward: total was 11.720000. running mean: -27.966562\n",
      "ep 40: ep_len:840 episode reward: total was -1.270000. running mean: -27.699596\n",
      "ep 40: ep_len:1010 episode reward: total was 16.340000. running mean: -27.259200\n",
      "ep 40: ep_len:500 episode reward: total was 45.500000. running mean: -26.531608\n",
      "ep 40: ep_len:580 episode reward: total was -20.100000. running mean: -26.467292\n",
      "ep 40: ep_len:666 episode reward: total was -39.640000. running mean: -26.599019\n",
      "ep 40: ep_len:500 episode reward: total was 8.610000. running mean: -26.246929\n",
      "ep 40: ep_len:500 episode reward: total was 11.980000. running mean: -25.864660\n",
      "ep 40: ep_len:500 episode reward: total was 12.260000. running mean: -25.483413\n",
      "ep 40: ep_len:500 episode reward: total was 37.210000. running mean: -24.856479\n",
      "ep 40: ep_len:750 episode reward: total was -19.760000. running mean: -24.805514\n",
      "ep 40: ep_len:960 episode reward: total was -0.770000. running mean: -24.565159\n",
      "ep 40: ep_len:575 episode reward: total was -6.150000. running mean: -24.381007\n",
      "ep 40: ep_len:159 episode reward: total was 15.500000. running mean: -23.982197\n",
      "ep 40: ep_len:500 episode reward: total was 13.940000. running mean: -23.602975\n",
      "ep 40: ep_len:870 episode reward: total was 14.170000. running mean: -23.225246\n",
      "ep 40: ep_len:500 episode reward: total was 8.400000. running mean: -22.908993\n",
      "ep 40: ep_len:505 episode reward: total was 2.960000. running mean: -22.650303\n",
      "ep 40: ep_len:500 episode reward: total was -17.750000. running mean: -22.601300\n",
      "ep 40: ep_len:940 episode reward: total was -72.620000. running mean: -23.101487\n",
      "ep 40: ep_len:550 episode reward: total was -12.660000. running mean: -22.997072\n",
      "ep 40: ep_len:750 episode reward: total was -11.680000. running mean: -22.883902\n",
      "ep 40: ep_len:720 episode reward: total was -4.670000. running mean: -22.701763\n",
      "ep 40: ep_len:500 episode reward: total was -3.390000. running mean: -22.508645\n",
      "ep 40: ep_len:575 episode reward: total was -0.920000. running mean: -22.292758\n",
      "ep 40: ep_len:1645 episode reward: total was -213.540000. running mean: -24.205231\n",
      "ep 40: ep_len:423 episode reward: total was 21.310000. running mean: -23.750079\n",
      "ep 40: ep_len:625 episode reward: total was -29.100000. running mean: -23.803578\n",
      "ep 40: ep_len:500 episode reward: total was 4.290000. running mean: -23.522642\n",
      "ep 40: ep_len:500 episode reward: total was 4.380000. running mean: -23.243616\n",
      "ep 40: ep_len:500 episode reward: total was 31.760000. running mean: -22.693579\n",
      "ep 40: ep_len:710 episode reward: total was -4.690000. running mean: -22.513544\n",
      "ep 40: ep_len:500 episode reward: total was 6.770000. running mean: -22.220708\n",
      "ep 40: ep_len:515 episode reward: total was -3.060000. running mean: -22.029101\n",
      "ep 40: ep_len:500 episode reward: total was 29.710000. running mean: -21.511710\n",
      "ep 40: ep_len:555 episode reward: total was -49.930000. running mean: -21.795893\n",
      "ep 40: ep_len:500 episode reward: total was -4.570000. running mean: -21.623634\n",
      "ep 40: ep_len:1716 episode reward: total was -292.560000. running mean: -24.332998\n",
      "ep 40: ep_len:500 episode reward: total was 14.000000. running mean: -23.949668\n",
      "ep 40: ep_len:515 episode reward: total was -10.130000. running mean: -23.811471\n",
      "ep 40: ep_len:500 episode reward: total was 50.000000. running mean: -23.073356\n",
      "ep 40: ep_len:895 episode reward: total was 5.340000. running mean: -22.789223\n",
      "ep 40: ep_len:500 episode reward: total was 17.950000. running mean: -22.381831\n",
      "ep 40: ep_len:500 episode reward: total was 1.820000. running mean: -22.139812\n",
      "ep 40: ep_len:635 episode reward: total was -3.830000. running mean: -21.956714\n",
      "ep 40: ep_len:500 episode reward: total was 18.440000. running mean: -21.552747\n",
      "ep 40: ep_len:122 episode reward: total was 12.000000. running mean: -21.217220\n",
      "ep 40: ep_len:181 episode reward: total was 16.500000. running mean: -20.840047\n",
      "ep 40: ep_len:945 episode reward: total was 9.130000. running mean: -20.540347\n",
      "ep 40: ep_len:590 episode reward: total was -19.070000. running mean: -20.525643\n",
      "ep 40: ep_len:500 episode reward: total was -11.750000. running mean: -20.437887\n",
      "ep 40: ep_len:357 episode reward: total was 4.500000. running mean: -20.188508\n",
      "ep 40: ep_len:500 episode reward: total was 33.230000. running mean: -19.654323\n",
      "ep 40: ep_len:55 episode reward: total was 4.000000. running mean: -19.417780\n",
      "ep 40: ep_len:500 episode reward: total was 17.830000. running mean: -19.045302\n",
      "ep 40: ep_len:575 episode reward: total was -16.520000. running mean: -19.020049\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 40: ep_len:500 episode reward: total was 0.350000. running mean: -18.826348\n",
      "ep 40: ep_len:975 episode reward: total was -43.550000. running mean: -19.073585\n",
      "ep 40: ep_len:625 episode reward: total was -2.840000. running mean: -18.911249\n",
      "ep 40: ep_len:695 episode reward: total was -15.230000. running mean: -18.874437\n",
      "ep 40: ep_len:690 episode reward: total was -30.990000. running mean: -18.995592\n",
      "ep 40: ep_len:655 episode reward: total was 10.910000. running mean: -18.696536\n",
      "ep 40: ep_len:995 episode reward: total was -10.930000. running mean: -18.618871\n",
      "ep 40: ep_len:570 episode reward: total was 21.430000. running mean: -18.218382\n",
      "ep 40: ep_len:500 episode reward: total was 24.260000. running mean: -17.793598\n",
      "ep 40: ep_len:500 episode reward: total was 24.840000. running mean: -17.367262\n",
      "ep 40: ep_len:225 episode reward: total was 18.000000. running mean: -17.013590\n",
      "ep 40: ep_len:142 episode reward: total was 14.000000. running mean: -16.703454\n",
      "ep 40: ep_len:500 episode reward: total was 14.950000. running mean: -16.386919\n",
      "ep 40: ep_len:645 episode reward: total was -5.830000. running mean: -16.281350\n",
      "ep 40: ep_len:575 episode reward: total was -0.340000. running mean: -16.121937\n",
      "ep 40: ep_len:565 episode reward: total was -45.380000. running mean: -16.414517\n",
      "ep 40: ep_len:810 episode reward: total was 23.080000. running mean: -16.019572\n",
      "ep 40: ep_len:500 episode reward: total was 47.000000. running mean: -15.389376\n",
      "ep 40: ep_len:615 episode reward: total was -20.030000. running mean: -15.435783\n",
      "ep 40: ep_len:294 episode reward: total was 29.000000. running mean: -14.991425\n",
      "ep 40: ep_len:500 episode reward: total was 1.700000. running mean: -14.824511\n",
      "ep 40: ep_len:735 episode reward: total was -5.460000. running mean: -14.730866\n",
      "ep 40: ep_len:560 episode reward: total was 22.820000. running mean: -14.355357\n",
      "ep 40: ep_len:500 episode reward: total was -3.090000. running mean: -14.242703\n",
      "ep 40: ep_len:680 episode reward: total was -31.010000. running mean: -14.410376\n",
      "ep 40: ep_len:1575 episode reward: total was -128.640000. running mean: -15.552673\n",
      "ep 40: ep_len:935 episode reward: total was 22.800000. running mean: -15.169146\n",
      "ep 40: ep_len:835 episode reward: total was 31.700000. running mean: -14.700454\n",
      "ep 40: ep_len:570 episode reward: total was -93.500000. running mean: -15.488450\n",
      "ep 40: ep_len:300 episode reward: total was 15.500000. running mean: -15.178565\n",
      "ep 40: ep_len:265 episode reward: total was 25.000000. running mean: -14.776780\n",
      "ep 40: ep_len:600 episode reward: total was -18.530000. running mean: -14.814312\n",
      "ep 40: ep_len:1060 episode reward: total was -48.430000. running mean: -15.150469\n",
      "ep 40: ep_len:500 episode reward: total was 29.340000. running mean: -14.705564\n",
      "ep 40: ep_len:463 episode reward: total was 11.560000. running mean: -14.442908\n",
      "ep 40: ep_len:945 episode reward: total was 11.110000. running mean: -14.187379\n",
      "ep 40: ep_len:1180 episode reward: total was -30.570000. running mean: -14.351206\n",
      "ep 40: ep_len:2100 episode reward: total was -194.450000. running mean: -16.152193\n",
      "ep 40: ep_len:780 episode reward: total was -6.720000. running mean: -16.057872\n",
      "ep 40: ep_len:500 episode reward: total was 47.000000. running mean: -15.427293\n",
      "ep 40: ep_len:820 episode reward: total was -39.480000. running mean: -15.667820\n",
      "ep 40: ep_len:745 episode reward: total was 33.720000. running mean: -15.173942\n",
      "ep 40: ep_len:880 episode reward: total was 24.500000. running mean: -14.777202\n",
      "ep 40: ep_len:1030 episode reward: total was 14.300000. running mean: -14.486430\n",
      "ep 40: ep_len:955 episode reward: total was -31.470000. running mean: -14.656266\n",
      "ep 40: ep_len:500 episode reward: total was 21.870000. running mean: -14.291003\n",
      "ep 40: ep_len:500 episode reward: total was -10.890000. running mean: -14.256993\n",
      "ep 40: ep_len:575 episode reward: total was -1.930000. running mean: -14.133723\n",
      "ep 40: ep_len:163 episode reward: total was 13.000000. running mean: -13.862386\n",
      "ep 40: ep_len:167 episode reward: total was 16.500000. running mean: -13.558762\n",
      "ep 40: ep_len:500 episode reward: total was 23.530000. running mean: -13.187875\n",
      "ep 40: ep_len:705 episode reward: total was -24.900000. running mean: -13.304996\n",
      "ep 40: ep_len:500 episode reward: total was 27.780000. running mean: -12.894146\n",
      "ep 40: ep_len:500 episode reward: total was -8.810000. running mean: -12.853304\n",
      "ep 40: ep_len:645 episode reward: total was -32.090000. running mean: -13.045671\n",
      "ep 40: ep_len:163 episode reward: total was 16.000000. running mean: -12.755215\n",
      "ep 40: ep_len:393 episode reward: total was 36.000000. running mean: -12.267663\n",
      "ep 40: ep_len:311 episode reward: total was 18.500000. running mean: -11.959986\n",
      "ep 40: ep_len:580 episode reward: total was 8.660000. running mean: -11.753786\n",
      "ep 40: ep_len:620 episode reward: total was 1.190000. running mean: -11.624348\n",
      "ep 40: ep_len:235 episode reward: total was 20.500000. running mean: -11.303105\n",
      "ep 40: ep_len:500 episode reward: total was 15.190000. running mean: -11.038174\n",
      "ep 40: ep_len:650 episode reward: total was 3.280000. running mean: -10.894992\n",
      "ep 40: ep_len:665 episode reward: total was 1.280000. running mean: -10.773242\n",
      "ep 40: ep_len:500 episode reward: total was 48.500000. running mean: -10.180510\n",
      "ep 40: ep_len:675 episode reward: total was 2.380000. running mean: -10.054904\n",
      "ep 40: ep_len:372 episode reward: total was 37.000000. running mean: -9.584355\n",
      "ep 40: ep_len:500 episode reward: total was 10.850000. running mean: -9.380012\n",
      "ep 40: ep_len:860 episode reward: total was -4.810000. running mean: -9.334312\n",
      "ep 40: ep_len:1030 episode reward: total was -2.630000. running mean: -9.267269\n",
      "ep 40: ep_len:500 episode reward: total was 7.760000. running mean: -9.096996\n",
      "ep 40: ep_len:510 episode reward: total was -9.130000. running mean: -9.097326\n",
      "ep 40: ep_len:945 episode reward: total was 12.150000. running mean: -8.884853\n",
      "ep 40: ep_len:805 episode reward: total was -23.690000. running mean: -9.032904\n",
      "ep 40: ep_len:500 episode reward: total was -5.230000. running mean: -8.994875\n",
      "ep 40: ep_len:605 episode reward: total was -6.730000. running mean: -8.972226\n",
      "ep 40: ep_len:715 episode reward: total was -29.250000. running mean: -9.175004\n",
      "ep 40: ep_len:975 episode reward: total was -108.190000. running mean: -10.165154\n",
      "ep 40: ep_len:600 episode reward: total was -39.760000. running mean: -10.461103\n",
      "ep 40: ep_len:372 episode reward: total was -63.500000. running mean: -10.991492\n",
      "ep 40: ep_len:540 episode reward: total was 4.190000. running mean: -10.839677\n",
      "ep 40: ep_len:850 episode reward: total was 0.190000. running mean: -10.729380\n",
      "ep 40: ep_len:282 episode reward: total was 26.500000. running mean: -10.357086\n",
      "ep 40: ep_len:940 episode reward: total was 4.670000. running mean: -10.206815\n",
      "ep 40: ep_len:500 episode reward: total was 13.660000. running mean: -9.968147\n",
      "ep 40: ep_len:745 episode reward: total was -5.690000. running mean: -9.925366\n",
      "ep 40: ep_len:500 episode reward: total was 33.820000. running mean: -9.487912\n",
      "ep 40: ep_len:535 episode reward: total was 0.010000. running mean: -9.392933\n",
      "ep 40: ep_len:500 episode reward: total was 35.770000. running mean: -8.941303\n",
      "ep 40: ep_len:1835 episode reward: total was -154.330000. running mean: -10.395190\n",
      "ep 40: ep_len:229 episode reward: total was 22.500000. running mean: -10.066239\n",
      "ep 40: ep_len:1060 episode reward: total was -63.580000. running mean: -10.601376\n",
      "ep 40: ep_len:1160 episode reward: total was 17.470000. running mean: -10.320662\n",
      "ep 40: ep_len:960 episode reward: total was -50.650000. running mean: -10.723956\n",
      "ep 40: ep_len:785 episode reward: total was 13.410000. running mean: -10.482616\n",
      "ep 40: ep_len:740 episode reward: total was 0.300000. running mean: -10.374790\n",
      "ep 40: ep_len:500 episode reward: total was 1.360000. running mean: -10.257442\n",
      "ep 40: ep_len:500 episode reward: total was -1.070000. running mean: -10.165568\n",
      "ep 40: ep_len:775 episode reward: total was -24.530000. running mean: -10.309212\n",
      "ep 40: ep_len:585 episode reward: total was -14.030000. running mean: -10.346420\n",
      "ep 40: ep_len:500 episode reward: total was 22.880000. running mean: -10.014156\n",
      "ep 40: ep_len:515 episode reward: total was -8.110000. running mean: -9.995114\n",
      "ep 40: ep_len:193 episode reward: total was 19.500000. running mean: -9.700163\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 40: ep_len:685 episode reward: total was -66.350000. running mean: -10.266661\n",
      "ep 40: ep_len:500 episode reward: total was 6.250000. running mean: -10.101495\n",
      "ep 40: ep_len:720 episode reward: total was -2.160000. running mean: -10.022080\n",
      "ep 40: ep_len:555 episode reward: total was -5.000000. running mean: -9.971859\n",
      "ep 40: ep_len:550 episode reward: total was -13.580000. running mean: -10.007940\n",
      "ep 40: ep_len:505 episode reward: total was 12.230000. running mean: -9.785561\n",
      "ep 40: ep_len:500 episode reward: total was -6.260000. running mean: -9.750305\n",
      "ep 40: ep_len:500 episode reward: total was 7.230000. running mean: -9.580502\n",
      "ep 40: ep_len:940 episode reward: total was 24.290000. running mean: -9.241797\n",
      "ep 40: ep_len:500 episode reward: total was 10.660000. running mean: -9.042779\n",
      "ep 40: ep_len:565 episode reward: total was -11.040000. running mean: -9.062752\n",
      "ep 40: ep_len:1450 episode reward: total was -231.010000. running mean: -11.282224\n",
      "ep 40: ep_len:510 episode reward: total was 5.750000. running mean: -11.111902\n",
      "ep 40: ep_len:505 episode reward: total was -2.500000. running mean: -11.025783\n",
      "ep 40: ep_len:500 episode reward: total was 2.270000. running mean: -10.892825\n",
      "ep 40: ep_len:500 episode reward: total was -47.560000. running mean: -11.259497\n",
      "ep 40: ep_len:500 episode reward: total was -0.610000. running mean: -11.153002\n",
      "ep 40: ep_len:1050 episode reward: total was -21.330000. running mean: -11.254772\n",
      "ep 40: ep_len:705 episode reward: total was -2.680000. running mean: -11.169024\n",
      "ep 40: ep_len:279 episode reward: total was 27.500000. running mean: -10.782334\n",
      "ep 40: ep_len:500 episode reward: total was -50.130000. running mean: -11.175810\n",
      "ep 40: ep_len:575 episode reward: total was -30.210000. running mean: -11.366152\n",
      "ep 40: ep_len:323 episode reward: total was 30.500000. running mean: -10.947491\n",
      "ep 40: ep_len:304 episode reward: total was 30.500000. running mean: -10.533016\n",
      "ep 40: ep_len:1070 episode reward: total was 0.160000. running mean: -10.426086\n",
      "ep 40: ep_len:500 episode reward: total was 13.200000. running mean: -10.189825\n",
      "ep 40: ep_len:500 episode reward: total was 4.210000. running mean: -10.045827\n",
      "ep 40: ep_len:500 episode reward: total was 3.410000. running mean: -9.911268\n",
      "ep 40: ep_len:500 episode reward: total was -9.630000. running mean: -9.908456\n",
      "ep 40: ep_len:500 episode reward: total was 7.970000. running mean: -9.729671\n",
      "ep 40: ep_len:2365 episode reward: total was -237.060000. running mean: -12.002974\n",
      "ep 40: ep_len:875 episode reward: total was 30.310000. running mean: -11.579845\n",
      "ep 40: ep_len:500 episode reward: total was 7.800000. running mean: -11.386046\n",
      "ep 40: ep_len:1415 episode reward: total was -85.090000. running mean: -12.123086\n",
      "ep 40: ep_len:565 episode reward: total was 4.790000. running mean: -11.953955\n",
      "ep 40: ep_len:610 episode reward: total was -27.080000. running mean: -12.105215\n",
      "ep 40: ep_len:940 episode reward: total was 17.300000. running mean: -11.811163\n",
      "ep 40: ep_len:1095 episode reward: total was -61.490000. running mean: -12.307952\n",
      "ep 40: ep_len:910 episode reward: total was -0.960000. running mean: -12.194472\n",
      "ep 40: ep_len:1560 episode reward: total was -54.270000. running mean: -12.615227\n",
      "ep 40: ep_len:500 episode reward: total was -3.210000. running mean: -12.521175\n",
      "ep 40: ep_len:500 episode reward: total was 48.500000. running mean: -11.910963\n",
      "ep 40: ep_len:520 episode reward: total was -10.120000. running mean: -11.893054\n",
      "ep 40: ep_len:770 episode reward: total was -18.710000. running mean: -11.961223\n",
      "ep 40: ep_len:500 episode reward: total was 18.350000. running mean: -11.658111\n",
      "ep 40: ep_len:234 episode reward: total was 21.500000. running mean: -11.326530\n",
      "ep 40: ep_len:765 episode reward: total was -9.630000. running mean: -11.309565\n",
      "ep 40: ep_len:238 episode reward: total was 23.500000. running mean: -10.961469\n",
      "ep 40: ep_len:500 episode reward: total was 19.020000. running mean: -10.661654\n",
      "ep 40: ep_len:690 episode reward: total was -2.710000. running mean: -10.582138\n",
      "ep 40: ep_len:500 episode reward: total was -3.330000. running mean: -10.509616\n",
      "ep 40: ep_len:500 episode reward: total was 28.760000. running mean: -10.116920\n",
      "ep 40: ep_len:870 episode reward: total was -28.610000. running mean: -10.301851\n",
      "ep 40: ep_len:500 episode reward: total was 16.600000. running mean: -10.032832\n",
      "ep 40: ep_len:2088 episode reward: total was -175.210000. running mean: -11.684604\n",
      "ep 40: ep_len:975 episode reward: total was -31.920000. running mean: -11.886958\n",
      "ep 40: ep_len:500 episode reward: total was 12.130000. running mean: -11.646788\n",
      "ep 40: ep_len:1020 episode reward: total was 4.880000. running mean: -11.481521\n",
      "ep 40: ep_len:680 episode reward: total was -1.720000. running mean: -11.383905\n",
      "ep 40: ep_len:590 episode reward: total was -60.480000. running mean: -11.874866\n",
      "ep 40: ep_len:212 episode reward: total was 19.500000. running mean: -11.561118\n",
      "ep 40: ep_len:535 episode reward: total was -2.010000. running mean: -11.465606\n",
      "ep 40: ep_len:770 episode reward: total was -55.050000. running mean: -11.901450\n",
      "ep 40: ep_len:890 episode reward: total was -9.650000. running mean: -11.878936\n",
      "ep 40: ep_len:515 episode reward: total was -10.130000. running mean: -11.861447\n",
      "ep 40: ep_len:1000 episode reward: total was -65.720000. running mean: -12.400032\n",
      "ep 40: ep_len:1670 episode reward: total was -129.560000. running mean: -13.571632\n",
      "ep 40: ep_len:422 episode reward: total was 42.000000. running mean: -13.015915\n",
      "ep 40: ep_len:655 episode reward: total was -42.170000. running mean: -13.307456\n",
      "ep 40: ep_len:1000 episode reward: total was -103.090000. running mean: -14.205282\n",
      "ep 40: ep_len:500 episode reward: total was 25.850000. running mean: -13.804729\n",
      "ep 40: ep_len:880 episode reward: total was -7.380000. running mean: -13.740482\n",
      "ep 40: ep_len:770 episode reward: total was -47.020000. running mean: -14.073277\n",
      "ep 40: ep_len:600 episode reward: total was 9.390000. running mean: -13.838644\n",
      "ep 40: ep_len:645 episode reward: total was -2.800000. running mean: -13.728258\n",
      "ep 40: ep_len:801 episode reward: total was -20.240000. running mean: -13.793375\n",
      "ep 40: ep_len:930 episode reward: total was 26.720000. running mean: -13.388241\n",
      "ep 40: ep_len:885 episode reward: total was -8.030000. running mean: -13.334659\n",
      "ep 40: ep_len:315 episode reward: total was 30.000000. running mean: -12.901312\n",
      "ep 40: ep_len:1607 episode reward: total was -215.390000. running mean: -14.926199\n",
      "ep 40: ep_len:500 episode reward: total was 4.660000. running mean: -14.730337\n",
      "ep 40: ep_len:835 episode reward: total was -15.550000. running mean: -14.738534\n",
      "ep 40: ep_len:500 episode reward: total was 1.880000. running mean: -14.572348\n",
      "ep 40: ep_len:500 episode reward: total was -12.180000. running mean: -14.548425\n",
      "ep 40: ep_len:500 episode reward: total was 19.480000. running mean: -14.208141\n",
      "ep 40: ep_len:8735 episode reward: total was -1702.090000. running mean: -31.086959\n",
      "ep 40: ep_len:348 episode reward: total was 33.000000. running mean: -30.446090\n",
      "ep 40: ep_len:500 episode reward: total was 27.300000. running mean: -29.868629\n",
      "ep 40: ep_len:540 episode reward: total was -18.160000. running mean: -29.751543\n",
      "ep 40: ep_len:515 episode reward: total was -3.060000. running mean: -29.484627\n",
      "ep 40: ep_len:630 episode reward: total was 12.850000. running mean: -29.061281\n",
      "ep 40: ep_len:675 episode reward: total was 29.140000. running mean: -28.479268\n",
      "ep 40: ep_len:500 episode reward: total was 16.940000. running mean: -28.025075\n",
      "ep 40: ep_len:497 episode reward: total was 31.320000. running mean: -27.431625\n",
      "ep 40: ep_len:500 episode reward: total was 26.340000. running mean: -26.893908\n",
      "ep 40: ep_len:500 episode reward: total was 2.300000. running mean: -26.601969\n",
      "ep 40: ep_len:540 episode reward: total was 22.320000. running mean: -26.112750\n",
      "ep 40: ep_len:500 episode reward: total was 21.870000. running mean: -25.632922\n",
      "ep 40: ep_len:850 episode reward: total was 9.770000. running mean: -25.278893\n",
      "ep 40: ep_len:500 episode reward: total was 22.890000. running mean: -24.797204\n",
      "ep 40: ep_len:500 episode reward: total was 22.020000. running mean: -24.329032\n",
      "ep 40: ep_len:500 episode reward: total was 12.290000. running mean: -23.962842\n",
      "ep 40: ep_len:2105 episode reward: total was -305.940000. running mean: -26.782613\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 40: ep_len:645 episode reward: total was -33.100000. running mean: -26.845787\n",
      "ep 40: ep_len:550 episode reward: total was -15.110000. running mean: -26.728429\n",
      "ep 40: ep_len:975 episode reward: total was -21.330000. running mean: -26.674445\n",
      "ep 40: ep_len:995 episode reward: total was -98.790000. running mean: -27.395600\n",
      "ep 40: ep_len:500 episode reward: total was 8.180000. running mean: -27.039844\n",
      "ep 40: ep_len:500 episode reward: total was 13.880000. running mean: -26.630646\n",
      "ep 40: ep_len:795 episode reward: total was -28.830000. running mean: -26.652639\n",
      "ep 40: ep_len:765 episode reward: total was 12.480000. running mean: -26.261313\n",
      "ep 40: ep_len:500 episode reward: total was 25.820000. running mean: -25.740500\n",
      "ep 40: ep_len:1195 episode reward: total was -144.090000. running mean: -26.923995\n",
      "ep 40: ep_len:370 episode reward: total was 34.000000. running mean: -26.314755\n",
      "ep 40: ep_len:530 episode reward: total was -6.060000. running mean: -26.112207\n",
      "ep 40: ep_len:500 episode reward: total was 27.360000. running mean: -25.577485\n",
      "ep 40: ep_len:505 episode reward: total was 24.450000. running mean: -25.077211\n",
      "ep 40: ep_len:500 episode reward: total was -6.120000. running mean: -24.887638\n",
      "ep 40: ep_len:520 episode reward: total was -10.120000. running mean: -24.739962\n",
      "ep 40: ep_len:1060 episode reward: total was 18.920000. running mean: -24.303362\n",
      "ep 40: ep_len:685 episode reward: total was -6.760000. running mean: -24.127929\n",
      "ep 40: ep_len:935 episode reward: total was 12.490000. running mean: -23.761750\n",
      "ep 40: ep_len:830 episode reward: total was -39.800000. running mean: -23.922132\n",
      "ep 40: ep_len:191 episode reward: total was 19.000000. running mean: -23.492911\n",
      "ep 40: ep_len:500 episode reward: total was -5.230000. running mean: -23.310282\n",
      "ep 40: ep_len:760 episode reward: total was 4.750000. running mean: -23.029679\n",
      "ep 40: ep_len:515 episode reward: total was -7.100000. running mean: -22.870382\n",
      "ep 40: ep_len:760 episode reward: total was -10.650000. running mean: -22.748178\n",
      "ep 40: ep_len:500 episode reward: total was -1.060000. running mean: -22.531296\n",
      "ep 40: ep_len:950 episode reward: total was -18.350000. running mean: -22.489483\n",
      "ep 40: ep_len:970 episode reward: total was -27.570000. running mean: -22.540289\n",
      "ep 40: ep_len:625 episode reward: total was 1.200000. running mean: -22.302886\n",
      "ep 40: ep_len:458 episode reward: total was 2.780000. running mean: -22.052057\n",
      "ep 40: ep_len:885 episode reward: total was -36.660000. running mean: -22.198136\n",
      "ep 40: ep_len:625 episode reward: total was 16.610000. running mean: -21.810055\n",
      "ep 40: ep_len:695 episode reward: total was -3.710000. running mean: -21.629054\n",
      "ep 40: ep_len:1209 episode reward: total was -94.580000. running mean: -22.358564\n",
      "ep 40: ep_len:500 episode reward: total was 6.830000. running mean: -22.066678\n",
      "ep 40: ep_len:625 episode reward: total was -16.980000. running mean: -22.015811\n",
      "ep 40: ep_len:945 episode reward: total was -53.710000. running mean: -22.332753\n",
      "ep 40: ep_len:675 episode reward: total was -24.930000. running mean: -22.358726\n",
      "ep 40: ep_len:500 episode reward: total was 14.030000. running mean: -21.994838\n",
      "ep 40: ep_len:770 episode reward: total was -12.650000. running mean: -21.901390\n",
      "ep 40: ep_len:759 episode reward: total was -28.910000. running mean: -21.971476\n",
      "ep 40: ep_len:555 episode reward: total was 16.510000. running mean: -21.586661\n",
      "ep 40: ep_len:515 episode reward: total was -28.310000. running mean: -21.653895\n",
      "ep 40: ep_len:500 episode reward: total was -1.520000. running mean: -21.452556\n",
      "ep 40: ep_len:500 episode reward: total was -8.320000. running mean: -21.321230\n",
      "ep 40: ep_len:945 episode reward: total was 12.150000. running mean: -20.986518\n",
      "ep 40: ep_len:500 episode reward: total was 22.760000. running mean: -20.549053\n",
      "ep 40: ep_len:920 episode reward: total was -7.300000. running mean: -20.416562\n",
      "ep 40: ep_len:1567 episode reward: total was -211.190000. running mean: -22.324297\n",
      "ep 40: ep_len:500 episode reward: total was -2.990000. running mean: -22.130954\n",
      "ep 40: ep_len:394 episode reward: total was 39.000000. running mean: -21.519644\n",
      "ep 40: ep_len:500 episode reward: total was -10.710000. running mean: -21.411548\n",
      "ep 40: ep_len:500 episode reward: total was -2.410000. running mean: -21.221532\n",
      "ep 40: ep_len:500 episode reward: total was 4.320000. running mean: -20.966117\n",
      "ep 40: ep_len:515 episode reward: total was -10.130000. running mean: -20.857756\n",
      "ep 40: ep_len:500 episode reward: total was -6.850000. running mean: -20.717678\n",
      "ep 40: ep_len:1824 episode reward: total was -269.090000. running mean: -23.201401\n",
      "ep 40: ep_len:500 episode reward: total was 11.280000. running mean: -22.856587\n",
      "ep 40: ep_len:840 episode reward: total was 1.820000. running mean: -22.609822\n",
      "ep 40: ep_len:500 episode reward: total was 25.790000. running mean: -22.125823\n",
      "ep 40: ep_len:620 episode reward: total was -26.080000. running mean: -22.165365\n",
      "ep 40: ep_len:650 episode reward: total was 23.210000. running mean: -21.711611\n",
      "ep 40: ep_len:500 episode reward: total was 26.220000. running mean: -21.232295\n",
      "ep 40: ep_len:500 episode reward: total was -20.960000. running mean: -21.229572\n",
      "ep 40: ep_len:765 episode reward: total was -7.070000. running mean: -21.087977\n",
      "ep 40: ep_len:1470 episode reward: total was -119.320000. running mean: -22.070297\n",
      "ep 40: ep_len:1080 episode reward: total was -42.020000. running mean: -22.269794\n",
      "ep 40: ep_len:500 episode reward: total was -19.920000. running mean: -22.246296\n",
      "ep 40: ep_len:898 episode reward: total was -88.910000. running mean: -22.912933\n",
      "ep 40: ep_len:990 episode reward: total was 16.760000. running mean: -22.516204\n",
      "ep 40: ep_len:520 episode reward: total was -9.110000. running mean: -22.382142\n",
      "ep 40: ep_len:408 episode reward: total was -18.220000. running mean: -22.340520\n",
      "ep 40: ep_len:655 episode reward: total was 12.690000. running mean: -21.990215\n",
      "ep 40: ep_len:650 episode reward: total was -25.500000. running mean: -22.025313\n",
      "ep 40: ep_len:565 episode reward: total was -37.110000. running mean: -22.176160\n",
      "ep 40: ep_len:500 episode reward: total was 7.390000. running mean: -21.880498\n",
      "ep 40: ep_len:555 episode reward: total was -61.560000. running mean: -22.277293\n",
      "ep 40: ep_len:505 episode reward: total was 11.480000. running mean: -21.939720\n",
      "ep 40: ep_len:555 episode reward: total was 3.820000. running mean: -21.682123\n",
      "ep 40: ep_len:745 episode reward: total was -30.880000. running mean: -21.774102\n",
      "ep 40: ep_len:525 episode reward: total was 15.710000. running mean: -21.399261\n",
      "ep 40: ep_len:1147 episode reward: total was -82.580000. running mean: -22.011068\n",
      "ep 40: ep_len:650 episode reward: total was -87.360000. running mean: -22.664558\n",
      "ep 40: ep_len:2564 episode reward: total was -389.820000. running mean: -26.336112\n",
      "ep 40: ep_len:725 episode reward: total was -11.820000. running mean: -26.190951\n",
      "ep 40: ep_len:1095 episode reward: total was 3.780000. running mean: -25.891241\n",
      "ep 40: ep_len:500 episode reward: total was 30.260000. running mean: -25.329729\n",
      "ep 40: ep_len:1250 episode reward: total was 9.330000. running mean: -24.983132\n",
      "ep 40: ep_len:875 episode reward: total was -23.420000. running mean: -24.967500\n",
      "ep 40: ep_len:134 episode reward: total was 11.500000. running mean: -24.602825\n",
      "ep 40: ep_len:583 episode reward: total was -74.240000. running mean: -25.099197\n",
      "ep 40: ep_len:875 episode reward: total was 17.030000. running mean: -24.677905\n",
      "ep 40: ep_len:231 episode reward: total was 23.000000. running mean: -24.201126\n",
      "ep 40: ep_len:1825 episode reward: total was -342.310000. running mean: -27.382215\n",
      "ep 40: ep_len:126 episode reward: total was 11.000000. running mean: -26.998393\n",
      "ep 40: ep_len:154 episode reward: total was 15.000000. running mean: -26.578409\n",
      "ep 40: ep_len:500 episode reward: total was -11.040000. running mean: -26.423025\n",
      "ep 40: ep_len:710 episode reward: total was -36.000000. running mean: -26.518794\n",
      "ep 40: ep_len:558 episode reward: total was -83.290000. running mean: -27.086506\n",
      "ep 40: ep_len:500 episode reward: total was 15.780000. running mean: -26.657841\n",
      "ep 40: ep_len:690 episode reward: total was -36.040000. running mean: -26.751663\n",
      "ep 40: ep_len:142 episode reward: total was 14.500000. running mean: -26.339146\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 40: ep_len:71 episode reward: total was 7.000000. running mean: -26.005755\n",
      "ep 40: ep_len:500 episode reward: total was 28.770000. running mean: -25.457997\n",
      "ep 40: ep_len:780 episode reward: total was -5.560000. running mean: -25.259017\n",
      "ep 40: ep_len:500 episode reward: total was 2.270000. running mean: -24.983727\n",
      "ep 40: ep_len:237 episode reward: total was 22.000000. running mean: -24.513890\n",
      "ep 40: ep_len:570 episode reward: total was -26.180000. running mean: -24.530551\n",
      "ep 40: ep_len:500 episode reward: total was 0.650000. running mean: -24.278745\n",
      "ep 40: ep_len:735 episode reward: total was -12.690000. running mean: -24.162858\n",
      "ep 40: ep_len:885 episode reward: total was -6.480000. running mean: -23.986029\n",
      "ep 40: ep_len:1130 episode reward: total was 28.980000. running mean: -23.456369\n",
      "ep 40: ep_len:500 episode reward: total was 8.030000. running mean: -23.141505\n",
      "ep 40: ep_len:500 episode reward: total was 25.730000. running mean: -22.652790\n",
      "ep 40: ep_len:645 episode reward: total was -49.260000. running mean: -22.918862\n",
      "ep 40: ep_len:500 episode reward: total was -10.220000. running mean: -22.791874\n",
      "ep 40: ep_len:652 episode reward: total was -44.900000. running mean: -23.012955\n",
      "ep 40: ep_len:117 episode reward: total was 12.000000. running mean: -22.662826\n",
      "ep 40: ep_len:500 episode reward: total was 4.920000. running mean: -22.386997\n",
      "ep 40: ep_len:500 episode reward: total was 17.500000. running mean: -21.988127\n",
      "ep 40: ep_len:500 episode reward: total was 23.770000. running mean: -21.530546\n",
      "ep 40: ep_len:1825 episode reward: total was -325.660000. running mean: -24.571841\n",
      "ep 40: ep_len:580 episode reward: total was -61.690000. running mean: -24.943022\n",
      "ep 40: ep_len:990 episode reward: total was -143.500000. running mean: -26.128592\n",
      "ep 40: ep_len:500 episode reward: total was -29.500000. running mean: -26.162306\n",
      "ep 40: ep_len:665 episode reward: total was -8.820000. running mean: -25.988883\n",
      "ep 40: ep_len:670 episode reward: total was 1.400000. running mean: -25.714994\n",
      "ep 40: ep_len:262 episode reward: total was 24.500000. running mean: -25.212844\n",
      "ep 40: ep_len:500 episode reward: total was -2.320000. running mean: -24.983916\n",
      "ep 40: ep_len:500 episode reward: total was 10.280000. running mean: -24.631277\n",
      "ep 40: ep_len:500 episode reward: total was 10.640000. running mean: -24.278564\n",
      "ep 40: ep_len:500 episode reward: total was 9.610000. running mean: -23.939678\n",
      "ep 40: ep_len:555 episode reward: total was -28.230000. running mean: -23.982581\n",
      "ep 40: ep_len:715 episode reward: total was -10.740000. running mean: -23.850156\n",
      "ep 40: ep_len:500 episode reward: total was 8.030000. running mean: -23.531354\n",
      "ep 40: ep_len:500 episode reward: total was 23.800000. running mean: -23.058041\n",
      "ep 40: ep_len:500 episode reward: total was -12.050000. running mean: -22.947960\n",
      "ep 40: ep_len:505 episode reward: total was 13.000000. running mean: -22.588481\n",
      "ep 40: ep_len:960 episode reward: total was 9.180000. running mean: -22.270796\n",
      "ep 40: ep_len:740 episode reward: total was -7.630000. running mean: -22.124388\n",
      "ep 40: ep_len:320 episode reward: total was -0.230000. running mean: -21.905444\n",
      "ep 40: ep_len:1154 episode reward: total was -29.360000. running mean: -21.979989\n",
      "ep 40: ep_len:310 episode reward: total was 29.500000. running mean: -21.465190\n",
      "ep 40: ep_len:765 episode reward: total was -42.960000. running mean: -21.680138\n",
      "ep 40: ep_len:670 episode reward: total was -24.970000. running mean: -21.713036\n",
      "ep 40: ep_len:955 episode reward: total was -0.060000. running mean: -21.496506\n",
      "ep 40: ep_len:2672 episode reward: total was -455.330000. running mean: -25.834841\n",
      "ep 40: ep_len:500 episode reward: total was 47.000000. running mean: -25.106492\n",
      "ep 40: ep_len:835 episode reward: total was -0.520000. running mean: -24.860628\n",
      "ep 40: ep_len:890 episode reward: total was 6.400000. running mean: -24.548021\n",
      "ep 40: ep_len:860 episode reward: total was 16.020000. running mean: -24.142341\n",
      "ep 40: ep_len:620 episode reward: total was -30.120000. running mean: -24.202118\n",
      "ep 40: ep_len:870 episode reward: total was -8.380000. running mean: -24.043896\n",
      "ep 40: ep_len:975 episode reward: total was -2.550000. running mean: -23.828957\n",
      "ep 40: ep_len:1417 episode reward: total was -180.610000. running mean: -25.396768\n",
      "ep 40: ep_len:175 episode reward: total was 16.000000. running mean: -24.982800\n",
      "ep 40: ep_len:500 episode reward: total was 5.300000. running mean: -24.679972\n",
      "ep 40: ep_len:535 episode reward: total was -9.170000. running mean: -24.524872\n",
      "ep 40: ep_len:248 episode reward: total was 25.000000. running mean: -24.029624\n",
      "ep 40: ep_len:570 episode reward: total was 28.530000. running mean: -23.504028\n",
      "ep 40: ep_len:670 episode reward: total was -8.810000. running mean: -23.357087\n",
      "ep 40: ep_len:1770 episode reward: total was -145.990000. running mean: -24.583416\n",
      "ep 40: ep_len:1105 episode reward: total was 6.610000. running mean: -24.271482\n",
      "ep 40: ep_len:615 episode reward: total was 8.270000. running mean: -23.946067\n",
      "ep 40: ep_len:725 episode reward: total was -1.630000. running mean: -23.722907\n",
      "ep 40: ep_len:500 episode reward: total was 0.150000. running mean: -23.484178\n",
      "ep 40: ep_len:505 episode reward: total was -24.380000. running mean: -23.493136\n",
      "ep 40: ep_len:202 episode reward: total was 20.000000. running mean: -23.058205\n",
      "ep 40: ep_len:500 episode reward: total was 17.460000. running mean: -22.653022\n",
      "ep 40: ep_len:500 episode reward: total was 48.500000. running mean: -21.941492\n",
      "ep 40: ep_len:590 episode reward: total was -9.980000. running mean: -21.821877\n",
      "ep 40: ep_len:500 episode reward: total was 8.640000. running mean: -21.517259\n",
      "ep 40: ep_len:915 episode reward: total was -51.750000. running mean: -21.819586\n",
      "ep 40: ep_len:500 episode reward: total was -23.220000. running mean: -21.833590\n",
      "ep 40: ep_len:150 episode reward: total was 12.500000. running mean: -21.490254\n",
      "ep 40: ep_len:530 episode reward: total was 17.810000. running mean: -21.097252\n",
      "ep 40: ep_len:500 episode reward: total was -18.330000. running mean: -21.069579\n",
      "ep 40: ep_len:1240 episode reward: total was -105.640000. running mean: -21.915283\n",
      "ep 40: ep_len:500 episode reward: total was 15.230000. running mean: -21.543831\n",
      "ep 40: ep_len:630 episode reward: total was -11.670000. running mean: -21.445092\n",
      "ep 40: ep_len:500 episode reward: total was -13.250000. running mean: -21.363141\n",
      "ep 40: ep_len:960 episode reward: total was -31.270000. running mean: -21.462210\n",
      "ep 40: ep_len:565 episode reward: total was 15.820000. running mean: -21.089388\n",
      "ep 40: ep_len:695 episode reward: total was -14.820000. running mean: -21.026694\n",
      "ep 40: ep_len:500 episode reward: total was 5.150000. running mean: -20.764927\n",
      "ep 40: ep_len:880 episode reward: total was 5.700000. running mean: -20.500278\n",
      "ep 40: ep_len:500 episode reward: total was 17.260000. running mean: -20.122675\n",
      "ep 40: ep_len:805 episode reward: total was -14.600000. running mean: -20.067448\n",
      "ep 40: ep_len:500 episode reward: total was -13.280000. running mean: -19.999574\n",
      "ep 40: ep_len:500 episode reward: total was -32.960000. running mean: -20.129178\n",
      "ep 40: ep_len:770 episode reward: total was -4.570000. running mean: -19.973586\n",
      "ep 40: ep_len:500 episode reward: total was -7.360000. running mean: -19.847450\n",
      "ep 40: ep_len:500 episode reward: total was 27.290000. running mean: -19.376076\n",
      "ep 40: ep_len:505 episode reward: total was 2.730000. running mean: -19.155015\n",
      "ep 40: ep_len:715 episode reward: total was -7.710000. running mean: -19.040565\n",
      "ep 40: ep_len:835 episode reward: total was -34.740000. running mean: -19.197559\n",
      "ep 40: ep_len:500 episode reward: total was -2.620000. running mean: -19.031784\n",
      "ep 40: ep_len:500 episode reward: total was 22.790000. running mean: -18.613566\n",
      "ep 40: ep_len:535 episode reward: total was -14.360000. running mean: -18.571030\n",
      "ep 40: ep_len:284 episode reward: total was 28.000000. running mean: -18.105320\n",
      "ep 40: ep_len:500 episode reward: total was -7.310000. running mean: -17.997367\n",
      "ep 40: ep_len:500 episode reward: total was 7.300000. running mean: -17.744393\n",
      "ep 40: ep_len:485 episode reward: total was 18.170000. running mean: -17.385249\n",
      "ep 40: ep_len:500 episode reward: total was -0.210000. running mean: -17.213497\n",
      "ep 40: ep_len:1190 episode reward: total was -35.290000. running mean: -17.394262\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 40: ep_len:655 episode reward: total was -22.130000. running mean: -17.441619\n",
      "ep 40: ep_len:500 episode reward: total was -10.690000. running mean: -17.374103\n",
      "ep 40: ep_len:755 episode reward: total was 19.170000. running mean: -17.008662\n",
      "ep 40: ep_len:500 episode reward: total was 0.800000. running mean: -16.830575\n",
      "ep 40: ep_len:500 episode reward: total was -9.680000. running mean: -16.759069\n",
      "ep 40: ep_len:500 episode reward: total was 28.760000. running mean: -16.303879\n",
      "ep 40: ep_len:595 episode reward: total was 12.300000. running mean: -16.017840\n",
      "ep 40: ep_len:780 episode reward: total was -14.650000. running mean: -16.004162\n",
      "ep 40: ep_len:605 episode reward: total was -1.870000. running mean: -15.862820\n",
      "ep 40: ep_len:187 episode reward: total was 17.500000. running mean: -15.529192\n",
      "ep 40: ep_len:660 episode reward: total was -6.810000. running mean: -15.442000\n",
      "ep 40: ep_len:695 episode reward: total was 38.340000. running mean: -14.904180\n",
      "ep 40: ep_len:500 episode reward: total was 26.280000. running mean: -14.492338\n",
      "ep 40: ep_len:177 episode reward: total was 17.500000. running mean: -14.172415\n",
      "ep 40: ep_len:1320 episode reward: total was -143.860000. running mean: -15.469290\n",
      "ep 40: ep_len:545 episode reward: total was -23.200000. running mean: -15.546598\n",
      "ep 40: ep_len:500 episode reward: total was 19.910000. running mean: -15.192032\n",
      "ep 40: ep_len:500 episode reward: total was 2.530000. running mean: -15.014811\n",
      "ep 40: ep_len:740 episode reward: total was -18.150000. running mean: -15.046163\n",
      "ep 40: ep_len:615 episode reward: total was -38.210000. running mean: -15.277802\n",
      "ep 40: ep_len:500 episode reward: total was -4.770000. running mean: -15.172724\n",
      "ep 40: ep_len:885 episode reward: total was 8.310000. running mean: -14.937896\n",
      "ep 40: ep_len:157 episode reward: total was 15.500000. running mean: -14.633517\n",
      "ep 40: ep_len:595 episode reward: total was -14.010000. running mean: -14.627282\n",
      "ep 40: ep_len:1080 episode reward: total was -62.320000. running mean: -15.104209\n",
      "ep 40: ep_len:895 episode reward: total was 12.020000. running mean: -14.832967\n",
      "ep 40: ep_len:505 episode reward: total was 13.860000. running mean: -14.546038\n",
      "ep 40: ep_len:1005 episode reward: total was 25.820000. running mean: -14.142377\n",
      "ep 40: ep_len:213 episode reward: total was -2.500000. running mean: -14.025953\n",
      "ep 40: ep_len:500 episode reward: total was 24.260000. running mean: -13.643094\n",
      "ep 40: ep_len:500 episode reward: total was 15.750000. running mean: -13.349163\n",
      "ep 40: ep_len:1945 episode reward: total was -198.290000. running mean: -15.198571\n",
      "ep 40: ep_len:760 episode reward: total was -8.630000. running mean: -15.132886\n",
      "ep 40: ep_len:500 episode reward: total was 8.650000. running mean: -14.895057\n",
      "ep 40: ep_len:620 episode reward: total was 2.670000. running mean: -14.719406\n",
      "ep 40: ep_len:690 episode reward: total was -3.720000. running mean: -14.609412\n",
      "ep 40: ep_len:520 episode reward: total was -5.070000. running mean: -14.514018\n",
      "ep 40: ep_len:10388 episode reward: total was -1882.100000. running mean: -33.189878\n",
      "ep 40: ep_len:565 episode reward: total was 6.380000. running mean: -32.794179\n",
      "ep 40: ep_len:137 episode reward: total was 13.500000. running mean: -32.331237\n",
      "ep 40: ep_len:807 episode reward: total was -135.780000. running mean: -33.365725\n",
      "ep 40: ep_len:680 episode reward: total was -4.750000. running mean: -33.079568\n",
      "ep 40: ep_len:1240 episode reward: total was -3.700000. running mean: -32.785772\n",
      "ep 40: ep_len:500 episode reward: total was 48.500000. running mean: -31.972914\n",
      "ep 40: ep_len:675 episode reward: total was -3.750000. running mean: -31.690685\n",
      "ep 40: ep_len:500 episode reward: total was 13.850000. running mean: -31.235278\n",
      "ep 40: ep_len:370 episode reward: total was -17.000000. running mean: -31.092925\n",
      "ep 40: ep_len:819 episode reward: total was -76.180000. running mean: -31.543796\n",
      "ep 40: ep_len:610 episode reward: total was -17.010000. running mean: -31.398458\n",
      "ep 40: ep_len:505 episode reward: total was 3.260000. running mean: -31.051874\n",
      "ep 40: ep_len:770 episode reward: total was -6.590000. running mean: -30.807255\n",
      "ep 40: ep_len:970 episode reward: total was -43.360000. running mean: -30.932782\n",
      "ep 40: ep_len:550 episode reward: total was -8.190000. running mean: -30.705355\n",
      "ep 40: ep_len:500 episode reward: total was 3.250000. running mean: -30.365801\n",
      "ep 40: ep_len:2505 episode reward: total was -333.740000. running mean: -33.399543\n",
      "ep 40: ep_len:605 episode reward: total was -18.030000. running mean: -33.245848\n",
      "ep 40: ep_len:500 episode reward: total was -16.250000. running mean: -33.075889\n",
      "ep 40: ep_len:500 episode reward: total was -14.750000. running mean: -32.892630\n",
      "ep 40: ep_len:500 episode reward: total was 48.500000. running mean: -32.078704\n",
      "ep 40: ep_len:635 episode reward: total was -23.510000. running mean: -31.993017\n",
      "ep 40: ep_len:500 episode reward: total was 8.340000. running mean: -31.589687\n",
      "ep 40: ep_len:991 episode reward: total was -105.110000. running mean: -32.324890\n",
      "ep 40: ep_len:985 episode reward: total was 6.310000. running mean: -31.938541\n",
      "ep 40: ep_len:500 episode reward: total was -9.150000. running mean: -31.710656\n",
      "ep 40: ep_len:500 episode reward: total was 29.280000. running mean: -31.100749\n",
      "ep 40: ep_len:1349 episode reward: total was -47.260000. running mean: -31.262341\n",
      "ep 40: ep_len:500 episode reward: total was 11.370000. running mean: -30.836018\n",
      "ep 40: ep_len:510 episode reward: total was 9.800000. running mean: -30.429658\n",
      "ep 40: ep_len:500 episode reward: total was -20.410000. running mean: -30.329461\n",
      "ep 40: ep_len:56 episode reward: total was 5.500000. running mean: -29.971167\n",
      "ep 40: ep_len:500 episode reward: total was 24.380000. running mean: -29.427655\n",
      "ep 40: ep_len:500 episode reward: total was 27.840000. running mean: -28.854978\n",
      "ep 40: ep_len:500 episode reward: total was 8.150000. running mean: -28.484929\n",
      "ep 40: ep_len:875 episode reward: total was -34.660000. running mean: -28.546679\n",
      "ep 40: ep_len:239 episode reward: total was 23.500000. running mean: -28.026213\n",
      "ep 40: ep_len:1220 episode reward: total was -140.020000. running mean: -29.146150\n",
      "ep 40: ep_len:850 episode reward: total was 6.050000. running mean: -28.794189\n",
      "ep 40: ep_len:780 episode reward: total was -35.120000. running mean: -28.857447\n",
      "ep 40: ep_len:785 episode reward: total was -24.740000. running mean: -28.816273\n",
      "ep 40: ep_len:550 episode reward: total was -2.160000. running mean: -28.549710\n",
      "ep 40: ep_len:277 episode reward: total was 27.500000. running mean: -27.989213\n",
      "ep 40: ep_len:500 episode reward: total was -9.210000. running mean: -27.801421\n",
      "ep 40: ep_len:500 episode reward: total was 12.590000. running mean: -27.397506\n",
      "ep 40: ep_len:184 episode reward: total was 16.500000. running mean: -26.958531\n",
      "ep 40: ep_len:1935 episode reward: total was -137.950000. running mean: -28.068446\n",
      "ep 40: ep_len:500 episode reward: total was 4.940000. running mean: -27.738362\n",
      "ep 40: ep_len:500 episode reward: total was -2.690000. running mean: -27.487878\n",
      "ep 40: ep_len:785 episode reward: total was -9.590000. running mean: -27.308899\n",
      "ep 40: ep_len:500 episode reward: total was 15.350000. running mean: -26.882310\n",
      "ep 40: ep_len:500 episode reward: total was -6.120000. running mean: -26.674687\n",
      "ep 40: ep_len:268 episode reward: total was 26.500000. running mean: -26.142940\n",
      "ep 40: ep_len:500 episode reward: total was -13.190000. running mean: -26.013411\n",
      "ep 40: ep_len:790 episode reward: total was -10.680000. running mean: -25.860077\n",
      "ep 40: ep_len:1305 episode reward: total was -64.570000. running mean: -26.247176\n",
      "ep 40: ep_len:670 episode reward: total was -15.880000. running mean: -26.143504\n",
      "ep 40: ep_len:500 episode reward: total was 15.130000. running mean: -25.730769\n",
      "ep 40: ep_len:745 episode reward: total was 18.050000. running mean: -25.292961\n",
      "ep 40: ep_len:675 episode reward: total was -19.910000. running mean: -25.239132\n",
      "ep 40: ep_len:95 episode reward: total was 8.000000. running mean: -24.906741\n",
      "ep 40: ep_len:188 episode reward: total was 19.000000. running mean: -24.467673\n",
      "ep 40: ep_len:610 episode reward: total was -13.520000. running mean: -24.358196\n",
      "ep 40: ep_len:740 episode reward: total was -2.610000. running mean: -24.140714\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 40: ep_len:500 episode reward: total was -0.820000. running mean: -23.907507\n",
      "ep 40: ep_len:1010 episode reward: total was 5.570000. running mean: -23.612732\n",
      "ep 40: ep_len:500 episode reward: total was 15.010000. running mean: -23.226505\n",
      "ep 40: ep_len:705 episode reward: total was 12.700000. running mean: -22.867240\n",
      "ep 40: ep_len:500 episode reward: total was -3.760000. running mean: -22.676167\n",
      "ep 40: ep_len:685 episode reward: total was 14.950000. running mean: -22.299906\n",
      "ep 40: ep_len:500 episode reward: total was 27.780000. running mean: -21.799107\n",
      "ep 40: ep_len:500 episode reward: total was 28.330000. running mean: -21.297816\n",
      "ep 40: ep_len:500 episode reward: total was 21.810000. running mean: -20.866737\n",
      "ep 40: ep_len:500 episode reward: total was -57.170000. running mean: -21.229770\n",
      "ep 40: ep_len:252 episode reward: total was 25.000000. running mean: -20.767472\n",
      "ep 40: ep_len:515 episode reward: total was -14.660000. running mean: -20.706398\n",
      "ep 40: ep_len:810 episode reward: total was 29.960000. running mean: -20.199734\n",
      "ep 40: ep_len:1884 episode reward: total was -205.340000. running mean: -22.051136\n",
      "ep 40: ep_len:500 episode reward: total was 5.610000. running mean: -21.774525\n",
      "ep 40: ep_len:2675 episode reward: total was -452.500000. running mean: -26.081780\n",
      "ep 40: ep_len:500 episode reward: total was -13.190000. running mean: -25.952862\n",
      "ep 40: ep_len:5685 episode reward: total was -1135.990000. running mean: -37.053233\n",
      "ep 40: ep_len:930 episode reward: total was -11.490000. running mean: -36.797601\n",
      "ep 40: ep_len:500 episode reward: total was -18.300000. running mean: -36.612625\n",
      "ep 40: ep_len:500 episode reward: total was 21.100000. running mean: -36.035499\n",
      "ep 40: ep_len:500 episode reward: total was 48.500000. running mean: -35.190144\n",
      "ep 40: ep_len:500 episode reward: total was -27.880000. running mean: -35.117042\n",
      "ep 40: ep_len:500 episode reward: total was 17.800000. running mean: -34.587872\n",
      "ep 40: ep_len:296 episode reward: total was 26.500000. running mean: -33.976993\n",
      "epsilon:0.010000 episode_count: 32351. steps_count: 23451796.000000\n",
      "ep 41: ep_len:500 episode reward: total was 10.670000. running mean: -33.530523\n",
      "ep 41: ep_len:790 episode reward: total was -24.210000. running mean: -33.437318\n",
      "ep 41: ep_len:500 episode reward: total was 13.570000. running mean: -32.967245\n",
      "ep 41: ep_len:1005 episode reward: total was -105.590000. running mean: -33.693472\n",
      "ep 41: ep_len:1745 episode reward: total was -241.530000. running mean: -35.771838\n",
      "ep 41: ep_len:500 episode reward: total was 5.010000. running mean: -35.364019\n",
      "ep 41: ep_len:1055 episode reward: total was 18.300000. running mean: -34.827379\n",
      "ep 41: ep_len:500 episode reward: total was 17.340000. running mean: -34.305705\n",
      "ep 41: ep_len:820 episode reward: total was -28.710000. running mean: -34.249748\n",
      "ep 41: ep_len:970 episode reward: total was -15.840000. running mean: -34.065651\n",
      "ep 41: ep_len:500 episode reward: total was 19.860000. running mean: -33.526394\n",
      "ep 41: ep_len:1015 episode reward: total was -79.380000. running mean: -33.984930\n",
      "ep 41: ep_len:500 episode reward: total was 4.690000. running mean: -33.598181\n",
      "ep 41: ep_len:180 episode reward: total was 16.500000. running mean: -33.097199\n",
      "ep 41: ep_len:1538 episode reward: total was -107.770000. running mean: -33.843927\n",
      "ep 41: ep_len:885 episode reward: total was -38.680000. running mean: -33.892288\n",
      "ep 41: ep_len:430 episode reward: total was 40.000000. running mean: -33.153365\n",
      "ep 41: ep_len:750 episode reward: total was 9.780000. running mean: -32.724031\n",
      "ep 41: ep_len:500 episode reward: total was 12.470000. running mean: -32.272091\n",
      "ep 41: ep_len:296 episode reward: total was 28.000000. running mean: -31.669370\n",
      "ep 41: ep_len:675 episode reward: total was -40.780000. running mean: -31.760476\n",
      "ep 41: ep_len:615 episode reward: total was 22.040000. running mean: -31.222472\n",
      "ep 41: ep_len:1615 episode reward: total was -61.550000. running mean: -31.525747\n",
      "ep 41: ep_len:940 episode reward: total was -33.520000. running mean: -31.545690\n",
      "ep 41: ep_len:500 episode reward: total was -59.700000. running mean: -31.827233\n",
      "ep 41: ep_len:600 episode reward: total was 19.710000. running mean: -31.311860\n",
      "ep 41: ep_len:715 episode reward: total was -6.110000. running mean: -31.059842\n",
      "ep 41: ep_len:530 episode reward: total was -24.210000. running mean: -30.991343\n",
      "ep 41: ep_len:500 episode reward: total was 20.550000. running mean: -30.475930\n",
      "ep 41: ep_len:655 episode reward: total was -2.780000. running mean: -30.198971\n",
      "ep 41: ep_len:725 episode reward: total was -8.100000. running mean: -29.977981\n",
      "ep 41: ep_len:815 episode reward: total was 10.790000. running mean: -29.570301\n",
      "ep 41: ep_len:252 episode reward: total was 17.500000. running mean: -29.099598\n",
      "ep 41: ep_len:505 episode reward: total was -0.050000. running mean: -28.809102\n",
      "ep 41: ep_len:860 episode reward: total was 19.170000. running mean: -28.329311\n",
      "ep 41: ep_len:500 episode reward: total was 3.890000. running mean: -28.007118\n",
      "ep 41: ep_len:530 episode reward: total was -17.140000. running mean: -27.898447\n",
      "ep 41: ep_len:1005 episode reward: total was 12.290000. running mean: -27.496562\n",
      "ep 41: ep_len:560 episode reward: total was -8.510000. running mean: -27.306697\n",
      "ep 41: ep_len:500 episode reward: total was -2.220000. running mean: -27.055830\n",
      "ep 41: ep_len:770 episode reward: total was -2.530000. running mean: -26.810571\n",
      "ep 41: ep_len:675 episode reward: total was 8.200000. running mean: -26.460466\n",
      "ep 41: ep_len:230 episode reward: total was 20.000000. running mean: -25.995861\n",
      "ep 41: ep_len:500 episode reward: total was -18.240000. running mean: -25.918302\n",
      "ep 41: ep_len:695 episode reward: total was -34.280000. running mean: -26.001919\n",
      "ep 41: ep_len:880 episode reward: total was -14.250000. running mean: -25.884400\n",
      "ep 41: ep_len:500 episode reward: total was 13.210000. running mean: -25.493456\n",
      "ep 41: ep_len:250 episode reward: total was 8.500000. running mean: -25.153522\n",
      "ep 41: ep_len:20570 episode reward: total was -4079.190000. running mean: -65.693886\n",
      "ep 41: ep_len:755 episode reward: total was -2.580000. running mean: -65.062748\n",
      "ep 41: ep_len:935 episode reward: total was -37.080000. running mean: -64.782920\n",
      "ep 41: ep_len:206 episode reward: total was 19.000000. running mean: -63.945091\n",
      "ep 41: ep_len:500 episode reward: total was -0.880000. running mean: -63.314440\n",
      "ep 41: ep_len:314 episode reward: total was 31.000000. running mean: -62.371296\n",
      "ep 41: ep_len:820 episode reward: total was -53.230000. running mean: -62.279883\n",
      "ep 41: ep_len:745 episode reward: total was -4.100000. running mean: -61.698084\n",
      "ep 41: ep_len:500 episode reward: total was -5.340000. running mean: -61.134503\n",
      "ep 41: ep_len:780 episode reward: total was -93.030000. running mean: -61.453458\n",
      "ep 41: ep_len:100 episode reward: total was 8.500000. running mean: -60.753923\n",
      "ep 41: ep_len:500 episode reward: total was 17.710000. running mean: -59.969284\n",
      "ep 41: ep_len:500 episode reward: total was -21.790000. running mean: -59.587491\n",
      "ep 41: ep_len:500 episode reward: total was -9.510000. running mean: -59.086716\n",
      "ep 41: ep_len:2029 episode reward: total was -346.450000. running mean: -61.960349\n",
      "ep 41: ep_len:845 episode reward: total was 11.060000. running mean: -61.230146\n",
      "ep 41: ep_len:820 episode reward: total was -56.860000. running mean: -61.186444\n",
      "ep 41: ep_len:171 episode reward: total was 17.000000. running mean: -60.404580\n",
      "ep 41: ep_len:900 episode reward: total was 18.090000. running mean: -59.619634\n",
      "ep 41: ep_len:525 episode reward: total was -27.280000. running mean: -59.296238\n",
      "ep 41: ep_len:1090 episode reward: total was -109.980000. running mean: -59.803075\n",
      "ep 41: ep_len:655 episode reward: total was -32.650000. running mean: -59.531545\n",
      "ep 41: ep_len:500 episode reward: total was 24.780000. running mean: -58.688429\n",
      "ep 41: ep_len:590 episode reward: total was -12.000000. running mean: -58.221545\n",
      "ep 41: ep_len:413 episode reward: total was 33.500000. running mean: -57.304329\n",
      "ep 41: ep_len:172 episode reward: total was 17.000000. running mean: -56.561286\n",
      "ep 41: ep_len:950 episode reward: total was -3.510000. running mean: -56.030773\n",
      "ep 41: ep_len:760 episode reward: total was -10.800000. running mean: -55.578465\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 41: ep_len:1055 episode reward: total was -150.430000. running mean: -56.526981\n",
      "ep 41: ep_len:500 episode reward: total was 10.820000. running mean: -55.853511\n",
      "ep 41: ep_len:500 episode reward: total was -9.730000. running mean: -55.392276\n",
      "ep 41: ep_len:870 episode reward: total was 14.600000. running mean: -54.692353\n",
      "ep 41: ep_len:700 episode reward: total was -51.180000. running mean: -54.657230\n",
      "ep 41: ep_len:730 episode reward: total was 1.320000. running mean: -54.097457\n",
      "ep 41: ep_len:625 episode reward: total was -0.820000. running mean: -53.564683\n",
      "ep 41: ep_len:500 episode reward: total was 8.770000. running mean: -52.941336\n",
      "ep 41: ep_len:710 episode reward: total was -8.210000. running mean: -52.494023\n",
      "ep 41: ep_len:75 episode reward: total was 6.000000. running mean: -51.909082\n",
      "ep 41: ep_len:515 episode reward: total was -7.100000. running mean: -51.460991\n",
      "ep 41: ep_len:500 episode reward: total was 16.820000. running mean: -50.778182\n",
      "ep 41: ep_len:535 episode reward: total was -18.170000. running mean: -50.452100\n",
      "ep 41: ep_len:505 episode reward: total was 10.000000. running mean: -49.847579\n",
      "ep 41: ep_len:615 episode reward: total was 19.020000. running mean: -49.158903\n",
      "ep 41: ep_len:500 episode reward: total was -5.720000. running mean: -48.724514\n",
      "ep 41: ep_len:500 episode reward: total was -2.440000. running mean: -48.261669\n",
      "ep 41: ep_len:500 episode reward: total was 11.180000. running mean: -47.667252\n",
      "ep 41: ep_len:570 episode reward: total was -25.170000. running mean: -47.442280\n",
      "ep 41: ep_len:500 episode reward: total was 5.340000. running mean: -46.914457\n",
      "ep 41: ep_len:20109 episode reward: total was -283.020000. running mean: -49.275512\n",
      "ep 41: ep_len:1840 episode reward: total was -261.510000. running mean: -51.397857\n",
      "ep 41: ep_len:500 episode reward: total was -15.910000. running mean: -51.042979\n",
      "ep 41: ep_len:500 episode reward: total was 22.730000. running mean: -50.305249\n",
      "ep 41: ep_len:500 episode reward: total was -20.470000. running mean: -50.006896\n",
      "ep 41: ep_len:690 episode reward: total was -9.780000. running mean: -49.604627\n",
      "ep 41: ep_len:510 episode reward: total was -10.140000. running mean: -49.209981\n",
      "ep 41: ep_len:985 episode reward: total was -29.220000. running mean: -49.010081\n",
      "ep 41: ep_len:500 episode reward: total was -3.670000. running mean: -48.556680\n",
      "ep 41: ep_len:505 episode reward: total was -36.410000. running mean: -48.435214\n",
      "ep 41: ep_len:971 episode reward: total was -47.020000. running mean: -48.421061\n",
      "ep 41: ep_len:630 episode reward: total was -26.060000. running mean: -48.197451\n",
      "ep 41: ep_len:284 episode reward: total was -3.500000. running mean: -47.750476\n",
      "ep 41: ep_len:740 episode reward: total was -13.650000. running mean: -47.409472\n",
      "ep 41: ep_len:500 episode reward: total was -6.630000. running mean: -47.001677\n",
      "ep 41: ep_len:575 episode reward: total was 26.370000. running mean: -46.267960\n",
      "ep 41: ep_len:500 episode reward: total was 6.350000. running mean: -45.741780\n",
      "ep 41: ep_len:500 episode reward: total was 28.270000. running mean: -45.001663\n",
      "ep 41: ep_len:500 episode reward: total was 6.830000. running mean: -44.483346\n",
      "ep 41: ep_len:1195 episode reward: total was -0.050000. running mean: -44.039013\n",
      "ep 41: ep_len:745 episode reward: total was -15.730000. running mean: -43.755922\n",
      "ep 41: ep_len:1180 episode reward: total was -111.790000. running mean: -44.436263\n",
      "ep 41: ep_len:755 episode reward: total was -28.320000. running mean: -44.275101\n",
      "ep 41: ep_len:905 episode reward: total was 12.620000. running mean: -43.706150\n",
      "ep 41: ep_len:675 episode reward: total was 5.170000. running mean: -43.217388\n",
      "ep 41: ep_len:7550 episode reward: total was -900.010000. running mean: -51.785314\n",
      "ep 41: ep_len:770 episode reward: total was 2.640000. running mean: -51.241061\n",
      "ep 41: ep_len:895 episode reward: total was 5.880000. running mean: -50.669850\n",
      "ep 41: ep_len:835 episode reward: total was -54.940000. running mean: -50.712552\n",
      "ep 41: ep_len:500 episode reward: total was 2.920000. running mean: -50.176226\n",
      "ep 41: ep_len:725 episode reward: total was -7.690000. running mean: -49.751364\n",
      "ep 41: ep_len:123 episode reward: total was 12.000000. running mean: -49.133851\n",
      "ep 41: ep_len:560 episode reward: total was -10.040000. running mean: -48.742912\n",
      "ep 41: ep_len:885 episode reward: total was -24.540000. running mean: -48.500883\n",
      "ep 41: ep_len:785 episode reward: total was -40.900000. running mean: -48.424874\n",
      "ep 41: ep_len:500 episode reward: total was 12.930000. running mean: -47.811325\n",
      "ep 41: ep_len:510 episode reward: total was -15.190000. running mean: -47.485112\n",
      "ep 41: ep_len:500 episode reward: total was 32.800000. running mean: -46.682261\n",
      "ep 41: ep_len:500 episode reward: total was -8.320000. running mean: -46.298638\n",
      "ep 41: ep_len:870 episode reward: total was -27.380000. running mean: -46.109452\n",
      "ep 41: ep_len:418 episode reward: total was 40.000000. running mean: -45.248357\n",
      "ep 41: ep_len:500 episode reward: total was 27.870000. running mean: -44.517174\n",
      "ep 41: ep_len:2280 episode reward: total was -342.410000. running mean: -47.496102\n",
      "ep 41: ep_len:500 episode reward: total was 29.340000. running mean: -46.727741\n",
      "ep 41: ep_len:915 episode reward: total was 16.660000. running mean: -46.093864\n",
      "ep 41: ep_len:1445 episode reward: total was -146.640000. running mean: -47.099325\n",
      "ep 41: ep_len:500 episode reward: total was -10.190000. running mean: -46.730232\n",
      "ep 41: ep_len:570 episode reward: total was 10.920000. running mean: -46.153730\n",
      "ep 41: ep_len:500 episode reward: total was 47.000000. running mean: -45.222192\n",
      "ep 41: ep_len:500 episode reward: total was 12.680000. running mean: -44.643170\n",
      "ep 41: ep_len:705 episode reward: total was 1.880000. running mean: -44.177939\n",
      "ep 41: ep_len:500 episode reward: total was 18.350000. running mean: -43.552659\n",
      "ep 41: ep_len:505 episode reward: total was -2.070000. running mean: -43.137833\n",
      "ep 41: ep_len:620 episode reward: total was -23.050000. running mean: -42.936954\n",
      "ep 41: ep_len:535 episode reward: total was -4.030000. running mean: -42.547885\n",
      "ep 41: ep_len:500 episode reward: total was 7.720000. running mean: -42.045206\n",
      "ep 41: ep_len:500 episode reward: total was 21.470000. running mean: -41.410054\n",
      "ep 41: ep_len:500 episode reward: total was 1.870000. running mean: -40.977253\n",
      "ep 41: ep_len:500 episode reward: total was 15.970000. running mean: -40.407781\n",
      "ep 41: ep_len:905 episode reward: total was 16.110000. running mean: -39.842603\n",
      "ep 41: ep_len:900 episode reward: total was 18.150000. running mean: -39.262677\n",
      "ep 41: ep_len:840 episode reward: total was 18.260000. running mean: -38.687450\n",
      "ep 41: ep_len:1200 episode reward: total was -181.550000. running mean: -40.116076\n",
      "ep 41: ep_len:500 episode reward: total was 27.810000. running mean: -39.436815\n",
      "ep 41: ep_len:500 episode reward: total was 5.730000. running mean: -38.985147\n",
      "ep 41: ep_len:670 episode reward: total was -10.830000. running mean: -38.703595\n",
      "ep 41: ep_len:670 episode reward: total was -1.740000. running mean: -38.333959\n",
      "ep 41: ep_len:500 episode reward: total was 24.810000. running mean: -37.702520\n",
      "ep 41: ep_len:500 episode reward: total was -0.760000. running mean: -37.333095\n",
      "ep 41: ep_len:950 episode reward: total was 16.930000. running mean: -36.790464\n",
      "ep 41: ep_len:760 episode reward: total was 7.750000. running mean: -36.345059\n",
      "ep 41: ep_len:500 episode reward: total was 22.890000. running mean: -35.752708\n",
      "ep 41: ep_len:1030 episode reward: total was -15.960000. running mean: -35.554781\n",
      "ep 41: ep_len:500 episode reward: total was 0.650000. running mean: -35.192733\n",
      "ep 41: ep_len:500 episode reward: total was 4.360000. running mean: -34.797206\n",
      "ep 41: ep_len:1050 episode reward: total was 22.940000. running mean: -34.219834\n",
      "ep 41: ep_len:830 episode reward: total was -26.670000. running mean: -34.144336\n",
      "ep 41: ep_len:910 episode reward: total was 15.080000. running mean: -33.652092\n",
      "ep 41: ep_len:500 episode reward: total was 17.830000. running mean: -33.137271\n",
      "ep 41: ep_len:755 episode reward: total was -14.700000. running mean: -32.952899\n",
      "ep 41: ep_len:500 episode reward: total was 22.850000. running mean: -32.394870\n",
      "ep 41: ep_len:710 episode reward: total was -45.090000. running mean: -32.521821\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 41: ep_len:500 episode reward: total was 7.050000. running mean: -32.126103\n",
      "ep 41: ep_len:810 episode reward: total was -23.600000. running mean: -32.040842\n",
      "ep 41: ep_len:500 episode reward: total was 0.800000. running mean: -31.712433\n",
      "ep 41: ep_len:193 episode reward: total was 18.000000. running mean: -31.215309\n",
      "ep 41: ep_len:500 episode reward: total was 9.250000. running mean: -30.810656\n",
      "ep 41: ep_len:500 episode reward: total was 47.000000. running mean: -30.032549\n",
      "ep 41: ep_len:487 episode reward: total was 29.770000. running mean: -29.434524\n",
      "ep 41: ep_len:540 episode reward: total was -3.010000. running mean: -29.170279\n",
      "ep 41: ep_len:500 episode reward: total was 0.890000. running mean: -28.869676\n",
      "ep 41: ep_len:580 episode reward: total was -28.180000. running mean: -28.862779\n",
      "ep 41: ep_len:730 episode reward: total was 1.720000. running mean: -28.556951\n",
      "ep 41: ep_len:111 episode reward: total was 10.500000. running mean: -28.166382\n",
      "ep 41: ep_len:795 episode reward: total was -9.050000. running mean: -27.975218\n",
      "ep 41: ep_len:500 episode reward: total was 17.370000. running mean: -27.521766\n",
      "ep 41: ep_len:500 episode reward: total was 24.500000. running mean: -27.001548\n",
      "ep 41: ep_len:1525 episode reward: total was -222.230000. running mean: -28.953833\n",
      "ep 41: ep_len:500 episode reward: total was 21.810000. running mean: -28.446194\n",
      "ep 41: ep_len:555 episode reward: total was -28.230000. running mean: -28.444032\n",
      "ep 41: ep_len:715 episode reward: total was -14.780000. running mean: -28.307392\n",
      "ep 41: ep_len:1120 episode reward: total was 17.360000. running mean: -27.850718\n",
      "ep 41: ep_len:710 episode reward: total was -4.690000. running mean: -27.619111\n",
      "ep 41: ep_len:610 episode reward: total was -13.980000. running mean: -27.482720\n",
      "ep 41: ep_len:930 episode reward: total was 27.540000. running mean: -26.932493\n",
      "ep 41: ep_len:500 episode reward: total was 0.950000. running mean: -26.653668\n",
      "ep 41: ep_len:500 episode reward: total was 20.430000. running mean: -26.182831\n",
      "ep 41: ep_len:500 episode reward: total was 8.670000. running mean: -25.834303\n",
      "ep 41: ep_len:500 episode reward: total was -5.230000. running mean: -25.628260\n",
      "ep 41: ep_len:500 episode reward: total was 31.760000. running mean: -25.054377\n",
      "ep 41: ep_len:765 episode reward: total was -24.750000. running mean: -25.051333\n",
      "ep 41: ep_len:770 episode reward: total was -6.590000. running mean: -24.866720\n",
      "ep 41: ep_len:815 episode reward: total was -15.940000. running mean: -24.777453\n",
      "ep 41: ep_len:615 episode reward: total was -3.870000. running mean: -24.568378\n",
      "ep 41: ep_len:500 episode reward: total was 29.250000. running mean: -24.030195\n",
      "ep 41: ep_len:750 episode reward: total was 5.350000. running mean: -23.736393\n",
      "ep 41: ep_len:645 episode reward: total was 20.140000. running mean: -23.297629\n",
      "ep 41: ep_len:555 episode reward: total was -23.270000. running mean: -23.297352\n",
      "ep 41: ep_len:500 episode reward: total was 2.210000. running mean: -23.042279\n",
      "ep 41: ep_len:500 episode reward: total was 19.730000. running mean: -22.614556\n",
      "ep 41: ep_len:163 episode reward: total was 16.000000. running mean: -22.228411\n",
      "ep 41: ep_len:729 episode reward: total was -58.340000. running mean: -22.589526\n",
      "ep 41: ep_len:700 episode reward: total was -10.250000. running mean: -22.466131\n",
      "ep 41: ep_len:630 episode reward: total was 33.460000. running mean: -21.906870\n",
      "ep 41: ep_len:920 episode reward: total was 2.540000. running mean: -21.662401\n",
      "ep 41: ep_len:650 episode reward: total was -13.540000. running mean: -21.581177\n",
      "ep 41: ep_len:412 episode reward: total was 22.370000. running mean: -21.141665\n",
      "ep 41: ep_len:645 episode reward: total was 17.810000. running mean: -20.752149\n",
      "ep 41: ep_len:580 episode reward: total was 9.290000. running mean: -20.451727\n",
      "ep 41: ep_len:575 episode reward: total was 15.340000. running mean: -20.093810\n",
      "ep 41: ep_len:590 episode reward: total was 15.830000. running mean: -19.734572\n",
      "ep 41: ep_len:500 episode reward: total was 4.810000. running mean: -19.489126\n",
      "ep 41: ep_len:500 episode reward: total was 24.350000. running mean: -19.050735\n",
      "ep 41: ep_len:515 episode reward: total was -3.060000. running mean: -18.890828\n",
      "ep 41: ep_len:500 episode reward: total was 23.280000. running mean: -18.469119\n",
      "ep 41: ep_len:535 episode reward: total was -29.280000. running mean: -18.577228\n",
      "ep 41: ep_len:675 episode reward: total was 10.650000. running mean: -18.284956\n",
      "ep 41: ep_len:990 episode reward: total was 8.280000. running mean: -18.019306\n",
      "ep 41: ep_len:2173 episode reward: total was -288.070000. running mean: -20.719813\n",
      "ep 41: ep_len:545 episode reward: total was -11.080000. running mean: -20.623415\n",
      "ep 41: ep_len:715 episode reward: total was -0.640000. running mean: -20.423581\n",
      "ep 41: ep_len:675 episode reward: total was -9.810000. running mean: -20.317445\n",
      "ep 41: ep_len:500 episode reward: total was 21.960000. running mean: -19.894671\n",
      "ep 41: ep_len:635 episode reward: total was 9.250000. running mean: -19.603224\n",
      "ep 41: ep_len:980 episode reward: total was 22.830000. running mean: -19.178892\n",
      "ep 41: ep_len:500 episode reward: total was 24.410000. running mean: -18.743003\n",
      "ep 41: ep_len:890 episode reward: total was -25.660000. running mean: -18.812173\n",
      "ep 41: ep_len:510 episode reward: total was 8.630000. running mean: -18.537751\n",
      "ep 41: ep_len:915 episode reward: total was -149.720000. running mean: -19.849573\n",
      "ep 41: ep_len:540 episode reward: total was 13.650000. running mean: -19.514578\n",
      "ep 41: ep_len:499 episode reward: total was 36.710000. running mean: -18.952332\n",
      "ep 41: ep_len:78 episode reward: total was 7.500000. running mean: -18.687809\n",
      "ep 41: ep_len:910 episode reward: total was -38.630000. running mean: -18.887231\n",
      "ep 41: ep_len:1165 episode reward: total was -171.420000. running mean: -20.412558\n",
      "ep 41: ep_len:770 episode reward: total was 25.290000. running mean: -19.955533\n",
      "ep 41: ep_len:950 episode reward: total was -41.580000. running mean: -20.171777\n",
      "ep 41: ep_len:500 episode reward: total was 1.720000. running mean: -19.952860\n",
      "ep 41: ep_len:264 episode reward: total was 26.000000. running mean: -19.493331\n",
      "ep 41: ep_len:630 episode reward: total was -32.410000. running mean: -19.622498\n",
      "ep 41: ep_len:500 episode reward: total was 10.360000. running mean: -19.322673\n",
      "ep 41: ep_len:945 episode reward: total was 24.210000. running mean: -18.887346\n",
      "ep 41: ep_len:810 episode reward: total was -24.170000. running mean: -18.940172\n",
      "ep 41: ep_len:540 episode reward: total was -0.990000. running mean: -18.760671\n",
      "ep 41: ep_len:845 episode reward: total was -3.560000. running mean: -18.608664\n",
      "ep 41: ep_len:715 episode reward: total was 14.800000. running mean: -18.274577\n",
      "ep 41: ep_len:248 episode reward: total was 23.000000. running mean: -17.861832\n",
      "ep 41: ep_len:585 episode reward: total was -3.410000. running mean: -17.717313\n",
      "ep 41: ep_len:655 episode reward: total was -16.920000. running mean: -17.709340\n",
      "ep 41: ep_len:755 episode reward: total was 27.190000. running mean: -17.260347\n",
      "ep 41: ep_len:5331 episode reward: total was -910.490000. running mean: -26.192643\n",
      "ep 41: ep_len:925 episode reward: total was 19.280000. running mean: -25.737917\n",
      "ep 41: ep_len:620 episode reward: total was -16.990000. running mean: -25.650438\n",
      "ep 41: ep_len:250 episode reward: total was 23.500000. running mean: -25.158933\n",
      "ep 41: ep_len:1200 episode reward: total was -139.590000. running mean: -26.303244\n",
      "ep 41: ep_len:710 episode reward: total was -10.410000. running mean: -26.144312\n",
      "ep 41: ep_len:535 episode reward: total was -22.700000. running mean: -26.109868\n",
      "ep 41: ep_len:500 episode reward: total was -4.650000. running mean: -25.895270\n",
      "ep 41: ep_len:755 episode reward: total was -28.840000. running mean: -25.924717\n",
      "ep 41: ep_len:1630 episode reward: total was -112.120000. running mean: -26.786670\n",
      "ep 41: ep_len:650 episode reward: total was -7.840000. running mean: -26.597203\n",
      "ep 41: ep_len:500 episode reward: total was 2.210000. running mean: -26.309131\n",
      "ep 41: ep_len:500 episode reward: total was 14.340000. running mean: -25.902640\n",
      "ep 41: ep_len:211 episode reward: total was 14.000000. running mean: -25.503613\n",
      "ep 41: ep_len:214 episode reward: total was 21.000000. running mean: -25.038577\n",
      "ep 41: ep_len:945 episode reward: total was 14.530000. running mean: -24.642892\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 41: ep_len:1547 episode reward: total was -304.990000. running mean: -27.446363\n",
      "ep 41: ep_len:745 episode reward: total was 11.220000. running mean: -27.059699\n",
      "ep 41: ep_len:486 episode reward: total was 8.550000. running mean: -26.703602\n",
      "ep 41: ep_len:780 episode reward: total was -50.000000. running mean: -26.936566\n",
      "ep 41: ep_len:990 episode reward: total was -39.560000. running mean: -27.062800\n",
      "ep 41: ep_len:1735 episode reward: total was -69.010000. running mean: -27.482272\n",
      "ep 41: ep_len:930 episode reward: total was -6.630000. running mean: -27.273750\n",
      "ep 41: ep_len:500 episode reward: total was -4.770000. running mean: -27.048712\n",
      "ep 41: ep_len:500 episode reward: total was 13.170000. running mean: -26.646525\n",
      "ep 41: ep_len:585 episode reward: total was -8.460000. running mean: -26.464660\n",
      "ep 41: ep_len:885 episode reward: total was -0.260000. running mean: -26.202613\n",
      "ep 41: ep_len:220 episode reward: total was 20.500000. running mean: -25.735587\n",
      "ep 41: ep_len:1145 episode reward: total was -16.330000. running mean: -25.641531\n",
      "ep 41: ep_len:500 episode reward: total was 22.340000. running mean: -25.161716\n",
      "ep 41: ep_len:610 episode reward: total was -14.770000. running mean: -25.057799\n",
      "ep 41: ep_len:575 episode reward: total was -5.970000. running mean: -24.866921\n",
      "ep 41: ep_len:217 episode reward: total was 20.000000. running mean: -24.418251\n",
      "ep 41: ep_len:500 episode reward: total was 6.960000. running mean: -24.104469\n",
      "ep 41: ep_len:730 episode reward: total was -36.970000. running mean: -24.233124\n",
      "ep 41: ep_len:500 episode reward: total was 18.230000. running mean: -23.808493\n",
      "ep 41: ep_len:545 episode reward: total was 12.040000. running mean: -23.450008\n",
      "ep 41: ep_len:560 episode reward: total was -14.080000. running mean: -23.356308\n",
      "ep 41: ep_len:250 episode reward: total was 23.500000. running mean: -22.887745\n",
      "ep 41: ep_len:234 episode reward: total was 21.500000. running mean: -22.443867\n",
      "ep 41: ep_len:349 episode reward: total was 26.000000. running mean: -21.959429\n",
      "ep 41: ep_len:510 episode reward: total was 6.730000. running mean: -21.672535\n",
      "ep 41: ep_len:685 episode reward: total was 6.680000. running mean: -21.389009\n",
      "ep 41: ep_len:555 episode reward: total was -8.520000. running mean: -21.260319\n",
      "ep 41: ep_len:560 episode reward: total was 24.810000. running mean: -20.799616\n",
      "ep 41: ep_len:129 episode reward: total was 11.500000. running mean: -20.476620\n",
      "ep 41: ep_len:635 episode reward: total was 1.650000. running mean: -20.255354\n",
      "ep 41: ep_len:500 episode reward: total was 25.270000. running mean: -19.800100\n",
      "ep 41: ep_len:500 episode reward: total was 4.790000. running mean: -19.554199\n",
      "ep 41: ep_len:790 episode reward: total was -10.590000. running mean: -19.464557\n",
      "ep 41: ep_len:815 episode reward: total was -10.540000. running mean: -19.375311\n",
      "ep 41: ep_len:500 episode reward: total was 16.330000. running mean: -19.018258\n",
      "ep 41: ep_len:500 episode reward: total was 23.340000. running mean: -18.594676\n",
      "ep 41: ep_len:500 episode reward: total was -5.660000. running mean: -18.465329\n",
      "ep 41: ep_len:1090 episode reward: total was 7.870000. running mean: -18.201976\n",
      "ep 41: ep_len:535 episode reward: total was -21.200000. running mean: -18.231956\n",
      "ep 41: ep_len:565 episode reward: total was -49.420000. running mean: -18.543836\n",
      "ep 41: ep_len:685 episode reward: total was -16.810000. running mean: -18.526498\n",
      "ep 41: ep_len:560 episode reward: total was -17.110000. running mean: -18.512333\n",
      "ep 41: ep_len:615 episode reward: total was -31.740000. running mean: -18.644610\n",
      "ep 41: ep_len:915 episode reward: total was -15.390000. running mean: -18.612064\n",
      "ep 41: ep_len:500 episode reward: total was 12.350000. running mean: -18.302443\n",
      "ep 41: ep_len:675 episode reward: total was -16.880000. running mean: -18.288219\n",
      "ep 41: ep_len:500 episode reward: total was -2.280000. running mean: -18.128136\n",
      "ep 41: ep_len:980 episode reward: total was 22.400000. running mean: -17.722855\n",
      "ep 41: ep_len:840 episode reward: total was 11.250000. running mean: -17.433126\n",
      "ep 41: ep_len:500 episode reward: total was 32.800000. running mean: -16.930795\n",
      "ep 41: ep_len:500 episode reward: total was 2.880000. running mean: -16.732687\n",
      "ep 41: ep_len:500 episode reward: total was 30.810000. running mean: -16.257260\n",
      "ep 41: ep_len:195 episode reward: total was 18.000000. running mean: -15.914688\n",
      "ep 41: ep_len:289 episode reward: total was -1.340000. running mean: -15.768941\n",
      "ep 41: ep_len:1540 episode reward: total was -58.400000. running mean: -16.195251\n",
      "ep 41: ep_len:860 episode reward: total was -71.050000. running mean: -16.743799\n",
      "ep 41: ep_len:935 episode reward: total was -78.980000. running mean: -17.366161\n",
      "ep 41: ep_len:161 episode reward: total was 14.500000. running mean: -17.047499\n",
      "ep 41: ep_len:500 episode reward: total was 15.320000. running mean: -16.723824\n",
      "ep 41: ep_len:745 episode reward: total was -4.190000. running mean: -16.598486\n",
      "ep 41: ep_len:500 episode reward: total was -42.500000. running mean: -16.857501\n",
      "ep 41: ep_len:1055 episode reward: total was 27.860000. running mean: -16.410326\n",
      "ep 41: ep_len:895 episode reward: total was -32.610000. running mean: -16.572323\n",
      "ep 41: ep_len:500 episode reward: total was 11.340000. running mean: -16.293200\n",
      "ep 41: ep_len:500 episode reward: total was 22.940000. running mean: -15.900868\n",
      "ep 41: ep_len:1060 episode reward: total was -136.870000. running mean: -17.110559\n",
      "ep 41: ep_len:500 episode reward: total was 50.000000. running mean: -16.439453\n",
      "ep 41: ep_len:500 episode reward: total was 25.800000. running mean: -16.017059\n",
      "ep 41: ep_len:830 episode reward: total was 10.920000. running mean: -15.747688\n",
      "ep 41: ep_len:505 episode reward: total was -3.080000. running mean: -15.621011\n",
      "ep 41: ep_len:500 episode reward: total was -20.290000. running mean: -15.667701\n",
      "ep 41: ep_len:530 episode reward: total was -12.120000. running mean: -15.632224\n",
      "ep 41: ep_len:930 episode reward: total was -5.650000. running mean: -15.532402\n",
      "ep 41: ep_len:500 episode reward: total was 6.740000. running mean: -15.309678\n",
      "ep 41: ep_len:345 episode reward: total was 6.740000. running mean: -15.089181\n",
      "ep 41: ep_len:995 episode reward: total was 23.730000. running mean: -14.700989\n",
      "ep 41: ep_len:570 episode reward: total was -22.140000. running mean: -14.775380\n",
      "ep 41: ep_len:675 episode reward: total was 14.450000. running mean: -14.483126\n",
      "ep 41: ep_len:1032 episode reward: total was -76.740000. running mean: -15.105695\n",
      "ep 41: ep_len:221 episode reward: total was 22.000000. running mean: -14.734638\n",
      "ep 41: ep_len:500 episode reward: total was 7.640000. running mean: -14.510891\n",
      "ep 41: ep_len:500 episode reward: total was -31.430000. running mean: -14.680082\n",
      "ep 41: ep_len:500 episode reward: total was 30.840000. running mean: -14.224881\n",
      "ep 41: ep_len:1040 episode reward: total was 16.300000. running mean: -13.919633\n",
      "ep 41: ep_len:795 episode reward: total was 3.260000. running mean: -13.747836\n",
      "ep 41: ep_len:223 episode reward: total was 22.000000. running mean: -13.390358\n",
      "ep 41: ep_len:2665 episode reward: total was -309.890000. running mean: -16.355354\n",
      "ep 41: ep_len:600 episode reward: total was -40.260000. running mean: -16.594401\n",
      "ep 41: ep_len:600 episode reward: total was 11.720000. running mean: -16.311257\n",
      "ep 41: ep_len:685 episode reward: total was 18.660000. running mean: -15.961544\n",
      "ep 41: ep_len:500 episode reward: total was 20.740000. running mean: -15.594529\n",
      "ep 41: ep_len:500 episode reward: total was -22.520000. running mean: -15.663784\n",
      "ep 41: ep_len:500 episode reward: total was -14.680000. running mean: -15.653946\n",
      "ep 41: ep_len:720 episode reward: total was -18.810000. running mean: -15.685506\n",
      "ep 41: ep_len:579 episode reward: total was -47.360000. running mean: -16.002251\n",
      "ep 41: ep_len:500 episode reward: total was -11.290000. running mean: -15.955129\n",
      "ep 41: ep_len:705 episode reward: total was -19.330000. running mean: -15.988877\n",
      "ep 41: ep_len:1425 episode reward: total was -93.150000. running mean: -16.760489\n",
      "ep 41: ep_len:720 episode reward: total was -93.000000. running mean: -17.522884\n",
      "ep 41: ep_len:775 episode reward: total was -16.950000. running mean: -17.517155\n",
      "ep 41: ep_len:825 episode reward: total was 0.780000. running mean: -17.334183\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 41: ep_len:1030 episode reward: total was -56.570000. running mean: -17.726542\n",
      "ep 41: ep_len:500 episode reward: total was 21.820000. running mean: -17.331076\n",
      "ep 41: ep_len:1410 episode reward: total was -79.040000. running mean: -17.948165\n",
      "ep 41: ep_len:293 episode reward: total was 29.000000. running mean: -17.478684\n",
      "ep 41: ep_len:500 episode reward: total was -5.170000. running mean: -17.355597\n",
      "ep 41: ep_len:500 episode reward: total was 0.400000. running mean: -17.178041\n",
      "ep 41: ep_len:795 episode reward: total was -36.840000. running mean: -17.374660\n",
      "ep 41: ep_len:810 episode reward: total was -28.730000. running mean: -17.488214\n",
      "ep 41: ep_len:600 episode reward: total was 29.360000. running mean: -17.019732\n",
      "ep 41: ep_len:212 episode reward: total was 19.500000. running mean: -16.654534\n",
      "ep 41: ep_len:200 episode reward: total was 19.000000. running mean: -16.297989\n",
      "ep 41: ep_len:780 episode reward: total was -17.680000. running mean: -16.311809\n",
      "ep 41: ep_len:1452 episode reward: total was -158.350000. running mean: -17.732191\n",
      "ep 41: ep_len:910 episode reward: total was 15.250000. running mean: -17.402369\n",
      "ep 41: ep_len:585 episode reward: total was -78.700000. running mean: -18.015345\n",
      "ep 41: ep_len:500 episode reward: total was 28.300000. running mean: -17.552192\n",
      "ep 41: ep_len:860 episode reward: total was -46.810000. running mean: -17.844770\n",
      "ep 41: ep_len:500 episode reward: total was 4.140000. running mean: -17.624922\n",
      "ep 41: ep_len:233 episode reward: total was 23.000000. running mean: -17.218673\n",
      "ep 41: ep_len:1015 episode reward: total was -47.510000. running mean: -17.521586\n",
      "ep 41: ep_len:500 episode reward: total was 15.070000. running mean: -17.195671\n",
      "ep 41: ep_len:1115 episode reward: total was 16.520000. running mean: -16.858514\n",
      "ep 41: ep_len:500 episode reward: total was 12.190000. running mean: -16.568029\n",
      "ep 41: ep_len:1155 episode reward: total was -8.190000. running mean: -16.484248\n",
      "ep 41: ep_len:510 episode reward: total was -1.050000. running mean: -16.329906\n",
      "ep 41: ep_len:590 episode reward: total was -28.160000. running mean: -16.448207\n",
      "ep 41: ep_len:785 episode reward: total was -21.710000. running mean: -16.500825\n",
      "ep 41: ep_len:500 episode reward: total was 12.740000. running mean: -16.208417\n",
      "ep 41: ep_len:1310 episode reward: total was -30.620000. running mean: -16.352532\n",
      "ep 41: ep_len:1505 episode reward: total was -131.370000. running mean: -17.502707\n",
      "ep 41: ep_len:500 episode reward: total was 15.260000. running mean: -17.175080\n",
      "ep 41: ep_len:362 episode reward: total was -33.650000. running mean: -17.339829\n",
      "ep 41: ep_len:1000 episode reward: total was -23.520000. running mean: -17.401631\n",
      "ep 41: ep_len:500 episode reward: total was 24.350000. running mean: -16.984115\n",
      "ep 41: ep_len:915 episode reward: total was -29.530000. running mean: -17.109573\n",
      "ep 41: ep_len:630 episode reward: total was 8.260000. running mean: -16.855878\n",
      "ep 41: ep_len:725 episode reward: total was 7.110000. running mean: -16.616219\n",
      "ep 41: ep_len:500 episode reward: total was 9.870000. running mean: -16.351357\n",
      "ep 41: ep_len:878 episode reward: total was 0.820000. running mean: -16.179643\n",
      "ep 41: ep_len:535 episode reward: total was 5.570000. running mean: -15.962147\n",
      "ep 41: ep_len:500 episode reward: total was 6.810000. running mean: -15.734425\n",
      "ep 41: ep_len:500 episode reward: total was -10.710000. running mean: -15.684181\n",
      "ep 41: ep_len:500 episode reward: total was -11.990000. running mean: -15.647239\n",
      "ep 41: ep_len:870 episode reward: total was -28.610000. running mean: -15.776867\n",
      "ep 41: ep_len:660 episode reward: total was 20.480000. running mean: -15.414298\n",
      "ep 41: ep_len:515 episode reward: total was -15.180000. running mean: -15.411955\n",
      "ep 41: ep_len:500 episode reward: total was 19.910000. running mean: -15.058736\n",
      "ep 41: ep_len:12130 episode reward: total was -1938.560000. running mean: -34.293748\n",
      "ep 41: ep_len:820 episode reward: total was -5.110000. running mean: -34.001911\n",
      "ep 41: ep_len:482 episode reward: total was 37.720000. running mean: -33.284692\n",
      "ep 41: ep_len:580 episode reward: total was -19.090000. running mean: -33.142745\n",
      "ep 41: ep_len:645 episode reward: total was -0.660000. running mean: -32.817917\n",
      "ep 41: ep_len:500 episode reward: total was 19.240000. running mean: -32.297338\n",
      "ep 41: ep_len:500 episode reward: total was 5.430000. running mean: -31.920065\n",
      "ep 41: ep_len:500 episode reward: total was 18.350000. running mean: -31.417364\n",
      "ep 41: ep_len:500 episode reward: total was 25.820000. running mean: -30.844990\n",
      "ep 41: ep_len:500 episode reward: total was 30.750000. running mean: -30.229041\n",
      "ep 41: ep_len:500 episode reward: total was 24.840000. running mean: -29.678350\n",
      "ep 41: ep_len:500 episode reward: total was 22.850000. running mean: -29.153067\n",
      "ep 41: ep_len:500 episode reward: total was 14.830000. running mean: -28.713236\n",
      "ep 41: ep_len:690 episode reward: total was -4.730000. running mean: -28.473404\n",
      "ep 41: ep_len:500 episode reward: total was 25.390000. running mean: -27.934770\n",
      "ep 41: ep_len:199 episode reward: total was 16.500000. running mean: -27.490422\n",
      "ep 41: ep_len:800 episode reward: total was -18.650000. running mean: -27.402018\n",
      "ep 41: ep_len:500 episode reward: total was 3.340000. running mean: -27.094598\n",
      "ep 41: ep_len:500 episode reward: total was 19.020000. running mean: -26.633452\n",
      "ep 41: ep_len:620 episode reward: total was -35.170000. running mean: -26.718817\n",
      "ep 41: ep_len:515 episode reward: total was -13.650000. running mean: -26.588129\n",
      "ep 41: ep_len:1140 episode reward: total was -131.320000. running mean: -27.635448\n",
      "ep 41: ep_len:690 episode reward: total was -18.910000. running mean: -27.548193\n",
      "ep 41: ep_len:660 episode reward: total was 27.130000. running mean: -27.001411\n",
      "ep 41: ep_len:500 episode reward: total was 22.370000. running mean: -26.507697\n",
      "ep 41: ep_len:500 episode reward: total was -20.380000. running mean: -26.446420\n",
      "ep 41: ep_len:500 episode reward: total was 27.780000. running mean: -25.904156\n",
      "ep 41: ep_len:710 episode reward: total was 16.290000. running mean: -25.482214\n",
      "ep 41: ep_len:500 episode reward: total was -26.980000. running mean: -25.497192\n",
      "ep 41: ep_len:1855 episode reward: total was -253.870000. running mean: -27.780920\n",
      "ep 41: ep_len:500 episode reward: total was -0.200000. running mean: -27.505111\n",
      "ep 41: ep_len:500 episode reward: total was 27.380000. running mean: -26.956260\n",
      "ep 41: ep_len:585 episode reward: total was 26.030000. running mean: -26.426397\n",
      "ep 41: ep_len:500 episode reward: total was 14.740000. running mean: -26.014733\n",
      "ep 41: ep_len:500 episode reward: total was 48.500000. running mean: -25.269586\n",
      "ep 41: ep_len:500 episode reward: total was -32.440000. running mean: -25.341290\n",
      "ep 41: ep_len:760 episode reward: total was -19.740000. running mean: -25.285277\n",
      "ep 41: ep_len:575 episode reward: total was -4.960000. running mean: -25.082025\n",
      "ep 41: ep_len:500 episode reward: total was 0.900000. running mean: -24.822204\n",
      "ep 41: ep_len:500 episode reward: total was 1.380000. running mean: -24.560182\n",
      "ep 41: ep_len:715 episode reward: total was -9.210000. running mean: -24.406680\n",
      "ep 41: ep_len:500 episode reward: total was -0.090000. running mean: -24.163514\n",
      "ep 41: ep_len:11175 episode reward: total was -2033.340000. running mean: -44.255278\n",
      "ep 41: ep_len:755 episode reward: total was -26.820000. running mean: -44.080926\n",
      "ep 41: ep_len:980 episode reward: total was -23.340000. running mean: -43.873516\n",
      "ep 41: ep_len:630 episode reward: total was -21.010000. running mean: -43.644881\n",
      "ep 41: ep_len:500 episode reward: total was -21.350000. running mean: -43.421932\n",
      "ep 41: ep_len:497 episode reward: total was 10.750000. running mean: -42.880213\n",
      "ep 41: ep_len:500 episode reward: total was 6.830000. running mean: -42.383111\n",
      "ep 41: ep_len:535 episode reward: total was 4.000000. running mean: -41.919280\n",
      "ep 41: ep_len:940 episode reward: total was -9.820000. running mean: -41.598287\n",
      "ep 41: ep_len:785 episode reward: total was -60.090000. running mean: -41.783204\n",
      "ep 41: ep_len:500 episode reward: total was 47.000000. running mean: -40.895372\n",
      "ep 41: ep_len:500 episode reward: total was -13.030000. running mean: -40.616718\n",
      "ep 41: ep_len:2555 episode reward: total was -449.420000. running mean: -44.704751\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 41: ep_len:585 episode reward: total was -7.970000. running mean: -44.337404\n",
      "ep 41: ep_len:550 episode reward: total was -21.170000. running mean: -44.105730\n",
      "ep 41: ep_len:820 episode reward: total was -56.990000. running mean: -44.234572\n",
      "ep 41: ep_len:775 episode reward: total was -4.460000. running mean: -43.836827\n",
      "ep 41: ep_len:1053 episode reward: total was -119.300000. running mean: -44.591458\n",
      "ep 41: ep_len:820 episode reward: total was -64.500000. running mean: -44.790544\n",
      "ep 41: ep_len:795 episode reward: total was 12.340000. running mean: -44.219238\n",
      "ep 41: ep_len:880 episode reward: total was -34.890000. running mean: -44.125946\n",
      "ep 41: ep_len:500 episode reward: total was 25.820000. running mean: -43.426487\n",
      "ep 41: ep_len:500 episode reward: total was -9.820000. running mean: -43.090422\n",
      "ep 41: ep_len:980 episode reward: total was -41.640000. running mean: -43.075917\n",
      "ep 41: ep_len:500 episode reward: total was 16.360000. running mean: -42.481558\n",
      "ep 41: ep_len:500 episode reward: total was -8.730000. running mean: -42.144043\n",
      "ep 41: ep_len:500 episode reward: total was -7.210000. running mean: -41.794702\n",
      "ep 41: ep_len:615 episode reward: total was -12.220000. running mean: -41.498955\n",
      "ep 41: ep_len:500 episode reward: total was 9.810000. running mean: -40.985866\n",
      "ep 41: ep_len:500 episode reward: total was 2.360000. running mean: -40.552407\n",
      "ep 41: ep_len:540 episode reward: total was -15.130000. running mean: -40.298183\n",
      "ep 41: ep_len:560 episode reward: total was -2.840000. running mean: -39.923601\n",
      "ep 41: ep_len:1515 episode reward: total was -185.890000. running mean: -41.383265\n",
      "ep 41: ep_len:500 episode reward: total was -4.860000. running mean: -41.018032\n",
      "ep 41: ep_len:975 episode reward: total was 21.410000. running mean: -40.393752\n",
      "ep 41: ep_len:1395 episode reward: total was -139.640000. running mean: -41.386215\n",
      "ep 41: ep_len:710 episode reward: total was -27.670000. running mean: -41.249052\n",
      "ep 41: ep_len:500 episode reward: total was -17.230000. running mean: -41.008862\n",
      "ep 41: ep_len:500 episode reward: total was 24.750000. running mean: -40.351273\n",
      "ep 41: ep_len:500 episode reward: total was 2.300000. running mean: -39.924761\n",
      "ep 41: ep_len:745 episode reward: total was -106.410000. running mean: -40.589613\n",
      "ep 41: ep_len:218 episode reward: total was 21.500000. running mean: -39.968717\n",
      "ep 41: ep_len:1395 episode reward: total was -158.860000. running mean: -41.157630\n",
      "ep 41: ep_len:1270 episode reward: total was 1.040000. running mean: -40.735653\n",
      "ep 41: ep_len:800 episode reward: total was -30.770000. running mean: -40.635997\n",
      "ep 41: ep_len:510 episode reward: total was -10.350000. running mean: -40.333137\n",
      "ep 41: ep_len:695 episode reward: total was -4.720000. running mean: -39.977006\n",
      "ep 41: ep_len:500 episode reward: total was 16.210000. running mean: -39.415135\n",
      "ep 41: ep_len:488 episode reward: total was -3.730000. running mean: -39.058284\n",
      "ep 41: ep_len:500 episode reward: total was -4.280000. running mean: -38.710501\n",
      "ep 41: ep_len:685 episode reward: total was -12.300000. running mean: -38.446396\n",
      "ep 41: ep_len:500 episode reward: total was -7.680000. running mean: -38.138732\n",
      "ep 41: ep_len:166 episode reward: total was 16.500000. running mean: -37.592345\n",
      "ep 41: ep_len:500 episode reward: total was 5.860000. running mean: -37.157822\n",
      "ep 41: ep_len:545 episode reward: total was -23.200000. running mean: -37.018243\n",
      "ep 41: ep_len:615 episode reward: total was -10.940000. running mean: -36.757461\n",
      "ep 41: ep_len:500 episode reward: total was -0.670000. running mean: -36.396586\n",
      "ep 41: ep_len:500 episode reward: total was 24.150000. running mean: -35.791120\n",
      "ep 41: ep_len:500 episode reward: total was 15.170000. running mean: -35.281509\n",
      "ep 41: ep_len:685 episode reward: total was -11.810000. running mean: -35.046794\n",
      "ep 41: ep_len:550 episode reward: total was -31.500000. running mean: -35.011326\n",
      "ep 41: ep_len:860 episode reward: total was -33.160000. running mean: -34.992813\n",
      "ep 41: ep_len:500 episode reward: total was 9.260000. running mean: -34.550285\n",
      "ep 41: ep_len:830 episode reward: total was -24.650000. running mean: -34.451282\n",
      "ep 41: ep_len:87 episode reward: total was 8.500000. running mean: -34.021769\n",
      "ep 41: ep_len:130 episode reward: total was 11.500000. running mean: -33.566551\n",
      "ep 41: ep_len:500 episode reward: total was 17.170000. running mean: -33.059186\n",
      "ep 41: ep_len:451 episode reward: total was 25.500000. running mean: -32.473594\n",
      "ep 41: ep_len:801 episode reward: total was -76.220000. running mean: -32.911058\n",
      "ep 41: ep_len:500 episode reward: total was 11.650000. running mean: -32.465448\n",
      "ep 41: ep_len:500 episode reward: total was 4.750000. running mean: -32.093293\n",
      "ep 41: ep_len:1910 episode reward: total was -265.620000. running mean: -34.428560\n",
      "ep 41: ep_len:182 episode reward: total was 9.000000. running mean: -33.994275\n",
      "ep 41: ep_len:740 episode reward: total was 12.900000. running mean: -33.525332\n",
      "ep 41: ep_len:337 episode reward: total was 33.500000. running mean: -32.855078\n",
      "ep 41: ep_len:500 episode reward: total was 3.960000. running mean: -32.486928\n",
      "ep 41: ep_len:500 episode reward: total was 13.210000. running mean: -32.029958\n",
      "ep 41: ep_len:107 episode reward: total was 11.000000. running mean: -31.599659\n",
      "ep 41: ep_len:500 episode reward: total was 16.670000. running mean: -31.116962\n",
      "ep 41: ep_len:500 episode reward: total was -10.730000. running mean: -30.913093\n",
      "ep 41: ep_len:575 episode reward: total was -18.090000. running mean: -30.784862\n",
      "ep 41: ep_len:805 episode reward: total was -18.640000. running mean: -30.663413\n",
      "ep 41: ep_len:500 episode reward: total was 18.170000. running mean: -30.175079\n",
      "ep 41: ep_len:595 episode reward: total was 18.760000. running mean: -29.685728\n",
      "ep 41: ep_len:186 episode reward: total was 17.000000. running mean: -29.218871\n",
      "ep 41: ep_len:600 episode reward: total was 7.590000. running mean: -28.850782\n",
      "ep 41: ep_len:795 episode reward: total was 13.020000. running mean: -28.432074\n",
      "ep 41: ep_len:483 episode reward: total was 48.000000. running mean: -27.667754\n",
      "ep 41: ep_len:800 episode reward: total was -22.690000. running mean: -27.617976\n",
      "ep 41: ep_len:500 episode reward: total was 4.480000. running mean: -27.296996\n",
      "ep 41: ep_len:500 episode reward: total was 22.250000. running mean: -26.801526\n",
      "ep 41: ep_len:500 episode reward: total was 1.210000. running mean: -26.521411\n",
      "ep 41: ep_len:925 episode reward: total was -27.340000. running mean: -26.529597\n",
      "ep 41: ep_len:309 episode reward: total was 6.150000. running mean: -26.202801\n",
      "ep 41: ep_len:715 episode reward: total was -33.970000. running mean: -26.280473\n",
      "ep 41: ep_len:2150 episode reward: total was -274.510000. running mean: -28.762768\n",
      "ep 41: ep_len:134 episode reward: total was 13.000000. running mean: -28.345141\n",
      "ep 41: ep_len:500 episode reward: total was 25.300000. running mean: -27.808689\n",
      "ep 41: ep_len:1844 episode reward: total was -336.720000. running mean: -30.897802\n",
      "ep 41: ep_len:600 episode reward: total was -76.160000. running mean: -31.350424\n",
      "ep 41: ep_len:500 episode reward: total was 11.670000. running mean: -30.920220\n",
      "ep 41: ep_len:237 episode reward: total was 22.000000. running mean: -30.391018\n",
      "ep 41: ep_len:500 episode reward: total was -23.960000. running mean: -30.326708\n",
      "ep 41: ep_len:885 episode reward: total was -6.150000. running mean: -30.084941\n",
      "ep 41: ep_len:500 episode reward: total was 14.640000. running mean: -29.637691\n",
      "ep 41: ep_len:252 episode reward: total was 25.000000. running mean: -29.091314\n",
      "ep 41: ep_len:585 episode reward: total was 19.750000. running mean: -28.602901\n",
      "ep 41: ep_len:412 episode reward: total was 41.000000. running mean: -27.906872\n",
      "ep 41: ep_len:565 episode reward: total was -3.200000. running mean: -27.659803\n",
      "ep 41: ep_len:675 episode reward: total was 28.190000. running mean: -27.101305\n",
      "ep 41: ep_len:500 episode reward: total was 2.270000. running mean: -26.807592\n",
      "ep 41: ep_len:500 episode reward: total was 19.790000. running mean: -26.341616\n",
      "ep 41: ep_len:740 episode reward: total was 5.170000. running mean: -26.026500\n",
      "ep 41: ep_len:555 episode reward: total was -3.990000. running mean: -25.806135\n",
      "ep 41: ep_len:500 episode reward: total was 25.300000. running mean: -25.295074\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 41: ep_len:615 episode reward: total was 2.540000. running mean: -25.016723\n",
      "ep 41: ep_len:1000 episode reward: total was -45.580000. running mean: -25.222356\n",
      "ep 41: ep_len:990 episode reward: total was -27.180000. running mean: -25.241932\n",
      "ep 41: ep_len:234 episode reward: total was 21.500000. running mean: -24.774513\n",
      "ep 41: ep_len:500 episode reward: total was 12.620000. running mean: -24.400568\n",
      "ep 41: ep_len:315 episode reward: total was 3.160000. running mean: -24.124962\n",
      "ep 41: ep_len:1225 episode reward: total was -38.940000. running mean: -24.273113\n",
      "ep 41: ep_len:205 episode reward: total was 18.000000. running mean: -23.850381\n",
      "ep 41: ep_len:2400 episode reward: total was -379.600000. running mean: -27.407878\n",
      "ep 41: ep_len:500 episode reward: total was 5.280000. running mean: -27.080999\n",
      "ep 41: ep_len:830 episode reward: total was 4.830000. running mean: -26.761889\n",
      "ep 41: ep_len:530 episode reward: total was 25.760000. running mean: -26.236670\n",
      "ep 41: ep_len:500 episode reward: total was 50.000000. running mean: -25.474303\n",
      "ep 41: ep_len:710 episode reward: total was 5.170000. running mean: -25.167860\n",
      "ep 41: ep_len:940 episode reward: total was 13.780000. running mean: -24.778382\n",
      "ep 41: ep_len:500 episode reward: total was 5.730000. running mean: -24.473298\n",
      "ep 41: ep_len:655 episode reward: total was -19.950000. running mean: -24.428065\n",
      "ep 41: ep_len:840 episode reward: total was -9.480000. running mean: -24.278584\n",
      "ep 41: ep_len:600 episode reward: total was -19.020000. running mean: -24.225998\n",
      "ep 41: ep_len:525 episode reward: total was 7.350000. running mean: -23.910238\n",
      "ep 41: ep_len:161 episode reward: total was 16.500000. running mean: -23.506136\n",
      "ep 41: ep_len:459 episode reward: total was 33.730000. running mean: -22.933775\n",
      "ep 41: ep_len:500 episode reward: total was -4.710000. running mean: -22.751537\n",
      "ep 41: ep_len:600 episode reward: total was -4.910000. running mean: -22.573122\n",
      "ep 41: ep_len:500 episode reward: total was -2.720000. running mean: -22.374590\n",
      "ep 41: ep_len:500 episode reward: total was 3.680000. running mean: -22.114044\n",
      "ep 41: ep_len:800 episode reward: total was -12.590000. running mean: -22.018804\n",
      "ep 41: ep_len:560 episode reward: total was -37.310000. running mean: -22.171716\n",
      "ep 41: ep_len:780 episode reward: total was -7.700000. running mean: -22.026999\n",
      "ep 41: ep_len:500 episode reward: total was -2.230000. running mean: -21.829029\n",
      "ep 41: ep_len:500 episode reward: total was -5.350000. running mean: -21.664238\n",
      "ep 41: ep_len:500 episode reward: total was 19.630000. running mean: -21.251296\n",
      "ep 41: ep_len:713 episode reward: total was -0.630000. running mean: -21.045083\n",
      "ep 41: ep_len:500 episode reward: total was 15.500000. running mean: -20.679632\n",
      "ep 41: ep_len:505 episode reward: total was 12.450000. running mean: -20.348336\n",
      "ep 41: ep_len:550 episode reward: total was 10.220000. running mean: -20.042653\n",
      "ep 41: ep_len:510 episode reward: total was -21.150000. running mean: -20.053726\n",
      "ep 41: ep_len:242 episode reward: total was 24.000000. running mean: -19.613189\n",
      "ep 41: ep_len:540 episode reward: total was -3.840000. running mean: -19.455457\n",
      "ep 41: ep_len:500 episode reward: total was 10.740000. running mean: -19.153502\n",
      "ep 41: ep_len:1590 episode reward: total was -164.210000. running mean: -20.604067\n",
      "ep 41: ep_len:555 episode reward: total was -26.210000. running mean: -20.660127\n",
      "ep 41: ep_len:600 episode reward: total was -18.650000. running mean: -20.640025\n",
      "ep 41: ep_len:725 episode reward: total was -1.140000. running mean: -20.445025\n",
      "ep 41: ep_len:860 episode reward: total was -46.810000. running mean: -20.708675\n",
      "ep 41: ep_len:500 episode reward: total was 8.770000. running mean: -20.413888\n",
      "ep 41: ep_len:1370 episode reward: total was -250.330000. running mean: -22.713049\n",
      "ep 41: ep_len:1925 episode reward: total was -258.360000. running mean: -25.069519\n",
      "ep 41: ep_len:845 episode reward: total was -1.610000. running mean: -24.834924\n",
      "ep 41: ep_len:640 episode reward: total was -6.850000. running mean: -24.655074\n",
      "ep 41: ep_len:800 episode reward: total was -22.690000. running mean: -24.635424\n",
      "ep 41: ep_len:182 episode reward: total was 18.500000. running mean: -24.204069\n",
      "ep 41: ep_len:740 episode reward: total was -1.600000. running mean: -23.978029\n",
      "ep 41: ep_len:655 episode reward: total was -6.820000. running mean: -23.806448\n",
      "ep 41: ep_len:730 episode reward: total was -6.670000. running mean: -23.635084\n",
      "ep 41: ep_len:500 episode reward: total was -9.570000. running mean: -23.494433\n",
      "ep 41: ep_len:500 episode reward: total was 20.280000. running mean: -23.056689\n",
      "ep 41: ep_len:500 episode reward: total was -0.240000. running mean: -22.828522\n",
      "ep 41: ep_len:500 episode reward: total was 20.000000. running mean: -22.400237\n",
      "ep 41: ep_len:905 episode reward: total was -35.610000. running mean: -22.532334\n",
      "ep 41: ep_len:515 episode reward: total was 1.420000. running mean: -22.292811\n",
      "ep 41: ep_len:510 episode reward: total was -3.070000. running mean: -22.100583\n",
      "ep 41: ep_len:500 episode reward: total was -18.240000. running mean: -22.061977\n",
      "ep 41: ep_len:184 episode reward: total was 18.000000. running mean: -21.661357\n",
      "ep 41: ep_len:500 episode reward: total was 22.330000. running mean: -21.221444\n",
      "ep 41: ep_len:500 episode reward: total was 15.360000. running mean: -20.855629\n",
      "ep 41: ep_len:458 episode reward: total was 26.130000. running mean: -20.385773\n",
      "ep 41: ep_len:500 episode reward: total was 19.820000. running mean: -19.983715\n",
      "ep 41: ep_len:500 episode reward: total was -32.220000. running mean: -20.106078\n",
      "ep 41: ep_len:725 episode reward: total was -7.690000. running mean: -19.981917\n",
      "ep 41: ep_len:895 episode reward: total was 7.170000. running mean: -19.710398\n",
      "ep 41: ep_len:500 episode reward: total was 48.500000. running mean: -19.028294\n",
      "ep 41: ep_len:500 episode reward: total was -2.290000. running mean: -18.860911\n",
      "ep 41: ep_len:1309 episode reward: total was -171.160000. running mean: -20.383902\n",
      "ep 41: ep_len:500 episode reward: total was 24.780000. running mean: -19.932263\n",
      "ep 41: ep_len:500 episode reward: total was 2.360000. running mean: -19.709340\n",
      "ep 41: ep_len:980 episode reward: total was 16.920000. running mean: -19.343047\n",
      "ep 41: ep_len:730 episode reward: total was 7.050000. running mean: -19.079117\n",
      "ep 41: ep_len:840 episode reward: total was -1.550000. running mean: -18.903825\n",
      "ep 41: ep_len:865 episode reward: total was -23.130000. running mean: -18.946087\n",
      "ep 41: ep_len:525 episode reward: total was -11.120000. running mean: -18.867826\n",
      "ep 41: ep_len:500 episode reward: total was 17.610000. running mean: -18.503048\n",
      "ep 41: ep_len:500 episode reward: total was 18.780000. running mean: -18.130217\n",
      "ep 41: ep_len:800 episode reward: total was 4.830000. running mean: -17.900615\n",
      "ep 41: ep_len:500 episode reward: total was -4.520000. running mean: -17.766809\n",
      "ep 41: ep_len:500 episode reward: total was 11.800000. running mean: -17.471141\n",
      "ep 41: ep_len:3235 episode reward: total was -565.870000. running mean: -22.955130\n",
      "ep 41: ep_len:500 episode reward: total was 6.340000. running mean: -22.662178\n",
      "ep 41: ep_len:905 episode reward: total was 5.330000. running mean: -22.382257\n",
      "ep 41: ep_len:500 episode reward: total was 38.000000. running mean: -21.778434\n",
      "ep 41: ep_len:710 episode reward: total was -15.000000. running mean: -21.710650\n",
      "ep 41: ep_len:500 episode reward: total was 2.830000. running mean: -21.465243\n",
      "ep 41: ep_len:500 episode reward: total was 23.860000. running mean: -21.011991\n",
      "ep 41: ep_len:650 episode reward: total was -6.880000. running mean: -20.870671\n",
      "ep 41: ep_len:146 episode reward: total was 14.500000. running mean: -20.516964\n",
      "ep 41: ep_len:730 episode reward: total was 6.160000. running mean: -20.250194\n",
      "ep 41: ep_len:389 episode reward: total was 32.500000. running mean: -19.722693\n",
      "ep 41: ep_len:500 episode reward: total was 26.800000. running mean: -19.257466\n",
      "ep 41: ep_len:1095 episode reward: total was 0.930000. running mean: -19.055591\n",
      "ep 41: ep_len:500 episode reward: total was 6.480000. running mean: -18.800235\n",
      "ep 41: ep_len:535 episode reward: total was -21.200000. running mean: -18.824233\n",
      "ep 41: ep_len:600 episode reward: total was -30.130000. running mean: -18.937290\n",
      "ep 41: ep_len:535 episode reward: total was -1.490000. running mean: -18.762817\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 41: ep_len:635 episode reward: total was -0.800000. running mean: -18.583189\n",
      "ep 41: ep_len:500 episode reward: total was 27.780000. running mean: -18.119557\n",
      "ep 41: ep_len:10510 episode reward: total was -1920.230000. running mean: -37.140662\n",
      "ep 41: ep_len:550 episode reward: total was -4.000000. running mean: -36.809255\n",
      "ep 41: ep_len:570 episode reward: total was 12.140000. running mean: -36.319763\n",
      "ep 41: ep_len:695 episode reward: total was -6.710000. running mean: -36.023665\n",
      "ep 41: ep_len:500 episode reward: total was -16.980000. running mean: -35.833228\n",
      "ep 41: ep_len:500 episode reward: total was 50.000000. running mean: -34.974896\n",
      "ep 41: ep_len:705 episode reward: total was -11.770000. running mean: -34.742847\n",
      "ep 41: ep_len:456 episode reward: total was 45.500000. running mean: -33.940419\n",
      "ep 41: ep_len:500 episode reward: total was 25.330000. running mean: -33.347714\n",
      "ep 41: ep_len:286 episode reward: total was 25.500000. running mean: -32.759237\n",
      "ep 41: ep_len:500 episode reward: total was 20.770000. running mean: -32.223945\n",
      "ep 41: ep_len:500 episode reward: total was 4.690000. running mean: -31.854806\n",
      "ep 41: ep_len:915 episode reward: total was 0.750000. running mean: -31.528757\n",
      "ep 41: ep_len:735 episode reward: total was 4.070000. running mean: -31.172770\n",
      "ep 41: ep_len:500 episode reward: total was -0.730000. running mean: -30.868342\n",
      "ep 41: ep_len:500 episode reward: total was -22.950000. running mean: -30.789159\n",
      "ep 41: ep_len:1965 episode reward: total was -263.770000. running mean: -33.118967\n",
      "ep 41: ep_len:815 episode reward: total was 2.480000. running mean: -32.762977\n",
      "ep 41: ep_len:500 episode reward: total was -22.310000. running mean: -32.658448\n",
      "ep 41: ep_len:481 episode reward: total was 31.260000. running mean: -32.019263\n",
      "ep 41: ep_len:1365 episode reward: total was -121.550000. running mean: -32.914571\n",
      "ep 41: ep_len:670 episode reward: total was -13.980000. running mean: -32.725225\n",
      "ep 41: ep_len:500 episode reward: total was 5.800000. running mean: -32.339973\n",
      "ep 41: ep_len:937 episode reward: total was -102.190000. running mean: -33.038473\n",
      "ep 41: ep_len:442 episode reward: total was -2.800000. running mean: -32.736088\n",
      "ep 41: ep_len:500 episode reward: total was 15.230000. running mean: -32.256427\n",
      "ep 41: ep_len:500 episode reward: total was 32.310000. running mean: -31.610763\n",
      "ep 41: ep_len:881 episode reward: total was -113.410000. running mean: -32.428755\n",
      "ep 41: ep_len:675 episode reward: total was -79.530000. running mean: -32.899768\n",
      "ep 41: ep_len:825 episode reward: total was 21.920000. running mean: -32.351570\n",
      "ep 41: ep_len:500 episode reward: total was -2.720000. running mean: -32.055254\n",
      "ep 41: ep_len:500 episode reward: total was 13.300000. running mean: -31.601702\n",
      "ep 41: ep_len:600 episode reward: total was -0.040000. running mean: -31.286085\n",
      "ep 41: ep_len:500 episode reward: total was 10.970000. running mean: -30.863524\n",
      "ep 41: ep_len:500 episode reward: total was 6.900000. running mean: -30.485889\n",
      "ep 41: ep_len:1265 episode reward: total was -50.040000. running mean: -30.681430\n",
      "ep 41: ep_len:500 episode reward: total was -5.350000. running mean: -30.428116\n",
      "ep 41: ep_len:655 episode reward: total was -45.200000. running mean: -30.575834\n",
      "ep 41: ep_len:780 episode reward: total was -21.720000. running mean: -30.487276\n",
      "ep 41: ep_len:760 episode reward: total was -12.720000. running mean: -30.309603\n",
      "ep 41: ep_len:282 episode reward: total was 28.000000. running mean: -29.726507\n",
      "ep 41: ep_len:500 episode reward: total was -9.190000. running mean: -29.521142\n",
      "ep 41: ep_len:1005 episode reward: total was -29.890000. running mean: -29.524831\n",
      "ep 41: ep_len:500 episode reward: total was 11.840000. running mean: -29.111183\n",
      "ep 41: ep_len:615 episode reward: total was -11.490000. running mean: -28.934971\n",
      "ep 41: ep_len:486 episode reward: total was 32.250000. running mean: -28.323121\n",
      "ep 41: ep_len:780 episode reward: total was -18.690000. running mean: -28.226790\n",
      "ep 41: ep_len:505 episode reward: total was -23.180000. running mean: -28.176322\n",
      "ep 41: ep_len:500 episode reward: total was -9.700000. running mean: -27.991559\n",
      "ep 41: ep_len:730 episode reward: total was -13.350000. running mean: -27.845143\n",
      "ep 41: ep_len:940 episode reward: total was 10.730000. running mean: -27.459392\n",
      "ep 41: ep_len:1363 episode reward: total was -103.770000. running mean: -28.222498\n",
      "ep 41: ep_len:740 episode reward: total was -8.420000. running mean: -28.024473\n",
      "ep 41: ep_len:500 episode reward: total was 18.100000. running mean: -27.563228\n",
      "ep 41: ep_len:500 episode reward: total was 17.010000. running mean: -27.117496\n",
      "ep 41: ep_len:810 episode reward: total was 7.730000. running mean: -26.769021\n",
      "ep 41: ep_len:100 episode reward: total was 8.500000. running mean: -26.416331\n",
      "ep 41: ep_len:228 episode reward: total was 22.500000. running mean: -25.927167\n",
      "ep 41: ep_len:500 episode reward: total was 9.200000. running mean: -25.575896\n",
      "ep 41: ep_len:740 episode reward: total was -5.640000. running mean: -25.376537\n",
      "ep 41: ep_len:500 episode reward: total was -1.260000. running mean: -25.135371\n",
      "ep 41: ep_len:358 episode reward: total was 21.000000. running mean: -24.674018\n",
      "ep 41: ep_len:995 episode reward: total was 3.300000. running mean: -24.394277\n",
      "ep 41: ep_len:670 episode reward: total was -42.140000. running mean: -24.571735\n",
      "ep 41: ep_len:500 episode reward: total was 31.340000. running mean: -24.012617\n",
      "ep 41: ep_len:500 episode reward: total was 3.280000. running mean: -23.739691\n",
      "ep 41: ep_len:1160 episode reward: total was -95.230000. running mean: -24.454594\n",
      "ep 41: ep_len:500 episode reward: total was 22.760000. running mean: -23.982448\n",
      "ep 41: ep_len:124 episode reward: total was 12.000000. running mean: -23.622624\n",
      "ep 41: ep_len:500 episode reward: total was 25.210000. running mean: -23.134298\n",
      "ep 41: ep_len:500 episode reward: total was 22.790000. running mean: -22.675055\n",
      "ep 41: ep_len:550 episode reward: total was -67.720000. running mean: -23.125504\n",
      "ep 41: ep_len:239 episode reward: total was 23.500000. running mean: -22.659249\n",
      "ep 41: ep_len:515 episode reward: total was -25.250000. running mean: -22.685156\n",
      "ep 41: ep_len:520 episode reward: total was -2.530000. running mean: -22.483605\n",
      "ep 41: ep_len:500 episode reward: total was 3.250000. running mean: -22.226269\n",
      "ep 41: ep_len:505 episode reward: total was 0.450000. running mean: -21.999506\n",
      "ep 41: ep_len:2565 episode reward: total was -440.500000. running mean: -26.184511\n",
      "ep 41: ep_len:500 episode reward: total was -12.180000. running mean: -26.044466\n",
      "ep 41: ep_len:5290 episode reward: total was -906.680000. running mean: -34.850821\n",
      "ep 41: ep_len:1033 episode reward: total was -35.910000. running mean: -34.861413\n",
      "ep 41: ep_len:500 episode reward: total was -1.680000. running mean: -34.529599\n",
      "ep 41: ep_len:1740 episode reward: total was -103.810000. running mean: -35.222403\n",
      "ep 41: ep_len:1015 episode reward: total was -137.400000. running mean: -36.244179\n",
      "ep 41: ep_len:429 episode reward: total was 3.570000. running mean: -35.846037\n",
      "ep 41: ep_len:671 episode reward: total was -69.960000. running mean: -36.187177\n",
      "epsilon:0.010000 episode_count: 33129. steps_count: 24053990.000000\n",
      "ep 42: ep_len:500 episode reward: total was 15.810000. running mean: -35.667205\n",
      "ep 42: ep_len:790 episode reward: total was -13.620000. running mean: -35.446733\n",
      "ep 42: ep_len:500 episode reward: total was 2.460000. running mean: -35.067666\n",
      "ep 42: ep_len:580 episode reward: total was -25.150000. running mean: -34.968489\n",
      "ep 42: ep_len:500 episode reward: total was 7.170000. running mean: -34.547104\n",
      "ep 42: ep_len:500 episode reward: total was -1.490000. running mean: -34.216533\n",
      "ep 42: ep_len:500 episode reward: total was 6.530000. running mean: -33.809068\n",
      "ep 42: ep_len:500 episode reward: total was 11.220000. running mean: -33.358777\n",
      "ep 42: ep_len:1125 episode reward: total was 5.310000. running mean: -32.972089\n",
      "ep 42: ep_len:960 episode reward: total was -28.030000. running mean: -32.922668\n",
      "ep 42: ep_len:500 episode reward: total was 27.320000. running mean: -32.320242\n",
      "ep 42: ep_len:500 episode reward: total was -25.200000. running mean: -32.249039\n",
      "ep 42: ep_len:500 episode reward: total was 2.820000. running mean: -31.898349\n",
      "ep 42: ep_len:845 episode reward: total was -28.660000. running mean: -31.865965\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 42: ep_len:795 episode reward: total was -15.630000. running mean: -31.703606\n",
      "ep 42: ep_len:406 episode reward: total was 40.500000. running mean: -30.981570\n",
      "ep 42: ep_len:760 episode reward: total was 0.770000. running mean: -30.664054\n",
      "ep 42: ep_len:500 episode reward: total was 4.570000. running mean: -30.311713\n",
      "ep 42: ep_len:254 episode reward: total was 25.000000. running mean: -29.758596\n",
      "ep 42: ep_len:625 episode reward: total was -8.530000. running mean: -29.546310\n",
      "ep 42: ep_len:500 episode reward: total was 28.670000. running mean: -28.964147\n",
      "ep 42: ep_len:1375 episode reward: total was -61.940000. running mean: -29.293906\n",
      "ep 42: ep_len:239 episode reward: total was 23.500000. running mean: -28.765967\n",
      "ep 42: ep_len:1070 episode reward: total was -50.210000. running mean: -28.980407\n",
      "ep 42: ep_len:1435 episode reward: total was -77.980000. running mean: -29.470403\n",
      "ep 42: ep_len:470 episode reward: total was 20.770000. running mean: -28.967999\n",
      "ep 42: ep_len:1677 episode reward: total was -195.670000. running mean: -30.635019\n",
      "ep 42: ep_len:545 episode reward: total was -4.010000. running mean: -30.368769\n",
      "ep 42: ep_len:900 episode reward: total was -8.910000. running mean: -30.154181\n",
      "ep 42: ep_len:790 episode reward: total was 12.880000. running mean: -29.723839\n",
      "ep 42: ep_len:500 episode reward: total was 18.230000. running mean: -29.244301\n",
      "ep 42: ep_len:500 episode reward: total was -15.540000. running mean: -29.107258\n",
      "ep 42: ep_len:500 episode reward: total was 25.270000. running mean: -28.563485\n",
      "ep 42: ep_len:810 episode reward: total was -0.290000. running mean: -28.280750\n",
      "ep 42: ep_len:347 episode reward: total was 12.660000. running mean: -27.871343\n",
      "ep 42: ep_len:603 episode reward: total was -70.220000. running mean: -28.294830\n",
      "ep 42: ep_len:890 episode reward: total was -17.210000. running mean: -28.183981\n",
      "ep 42: ep_len:570 episode reward: total was -22.110000. running mean: -28.123241\n",
      "ep 42: ep_len:500 episode reward: total was 34.270000. running mean: -27.499309\n",
      "ep 42: ep_len:775 episode reward: total was 27.080000. running mean: -26.953516\n",
      "ep 42: ep_len:980 episode reward: total was -1.460000. running mean: -26.698581\n",
      "ep 42: ep_len:291 episode reward: total was 29.000000. running mean: -26.141595\n",
      "ep 42: ep_len:510 episode reward: total was -2.030000. running mean: -25.900479\n",
      "ep 42: ep_len:500 episode reward: total was -1.590000. running mean: -25.657374\n",
      "ep 42: ep_len:610 episode reward: total was -67.510000. running mean: -26.075900\n",
      "ep 42: ep_len:505 episode reward: total was -12.170000. running mean: -25.936841\n",
      "ep 42: ep_len:565 episode reward: total was -54.950000. running mean: -26.226973\n",
      "ep 42: ep_len:675 episode reward: total was -8.800000. running mean: -26.052703\n",
      "ep 42: ep_len:1050 episode reward: total was -14.070000. running mean: -25.932876\n",
      "ep 42: ep_len:206 episode reward: total was 20.500000. running mean: -25.468548\n",
      "ep 42: ep_len:690 episode reward: total was 0.320000. running mean: -25.210662\n",
      "ep 42: ep_len:680 episode reward: total was -64.610000. running mean: -25.604655\n",
      "ep 42: ep_len:645 episode reward: total was 1.450000. running mean: -25.334109\n",
      "ep 42: ep_len:500 episode reward: total was 12.720000. running mean: -24.953568\n",
      "ep 42: ep_len:690 episode reward: total was -0.690000. running mean: -24.710932\n",
      "ep 42: ep_len:121 episode reward: total was 12.000000. running mean: -24.343823\n",
      "ep 42: ep_len:500 episode reward: total was 27.750000. running mean: -23.822885\n",
      "ep 42: ep_len:955 episode reward: total was -61.010000. running mean: -24.194756\n",
      "ep 42: ep_len:500 episode reward: total was -19.120000. running mean: -24.144008\n",
      "ep 42: ep_len:1285 episode reward: total was -194.430000. running mean: -25.846868\n",
      "ep 42: ep_len:515 episode reward: total was -8.110000. running mean: -25.669499\n",
      "ep 42: ep_len:575 episode reward: total was -2.940000. running mean: -25.442204\n",
      "ep 42: ep_len:283 episode reward: total was 26.500000. running mean: -24.922782\n",
      "ep 42: ep_len:500 episode reward: total was -0.760000. running mean: -24.681155\n",
      "ep 42: ep_len:500 episode reward: total was 0.950000. running mean: -24.424843\n",
      "ep 42: ep_len:1145 episode reward: total was -40.180000. running mean: -24.582395\n",
      "ep 42: ep_len:605 episode reward: total was -10.960000. running mean: -24.446171\n",
      "ep 42: ep_len:560 episode reward: total was 19.790000. running mean: -24.003809\n",
      "ep 42: ep_len:665 episode reward: total was -24.980000. running mean: -24.013571\n",
      "ep 42: ep_len:795 episode reward: total was -4.520000. running mean: -23.818635\n",
      "ep 42: ep_len:211 episode reward: total was 21.000000. running mean: -23.370449\n",
      "ep 42: ep_len:575 episode reward: total was 36.810000. running mean: -22.768644\n",
      "ep 42: ep_len:800 episode reward: total was 1.280000. running mean: -22.528158\n",
      "ep 42: ep_len:357 episode reward: total was 1.860000. running mean: -22.284276\n",
      "ep 42: ep_len:520 episode reward: total was -32.340000. running mean: -22.384833\n",
      "ep 42: ep_len:500 episode reward: total was -3.120000. running mean: -22.192185\n",
      "ep 42: ep_len:500 episode reward: total was 0.340000. running mean: -21.966863\n",
      "ep 42: ep_len:500 episode reward: total was 0.500000. running mean: -21.742195\n",
      "ep 42: ep_len:710 episode reward: total was -0.650000. running mean: -21.531273\n",
      "ep 42: ep_len:1455 episode reward: total was -150.090000. running mean: -22.816860\n",
      "ep 42: ep_len:500 episode reward: total was 1.670000. running mean: -22.571991\n",
      "ep 42: ep_len:660 episode reward: total was -1.760000. running mean: -22.363871\n",
      "ep 42: ep_len:82 episode reward: total was 8.000000. running mean: -22.060233\n",
      "ep 42: ep_len:500 episode reward: total was 2.880000. running mean: -21.810830\n",
      "ep 42: ep_len:560 episode reward: total was 17.800000. running mean: -21.414722\n",
      "ep 42: ep_len:550 episode reward: total was -6.020000. running mean: -21.260775\n",
      "ep 42: ep_len:500 episode reward: total was 0.010000. running mean: -21.048067\n",
      "ep 42: ep_len:500 episode reward: total was 12.780000. running mean: -20.709786\n",
      "ep 42: ep_len:850 episode reward: total was 21.080000. running mean: -20.291889\n",
      "ep 42: ep_len:500 episode reward: total was 16.570000. running mean: -19.923270\n",
      "ep 42: ep_len:500 episode reward: total was 5.290000. running mean: -19.671137\n",
      "ep 42: ep_len:1085 episode reward: total was 17.290000. running mean: -19.301526\n",
      "ep 42: ep_len:500 episode reward: total was 7.790000. running mean: -19.030610\n",
      "ep 42: ep_len:500 episode reward: total was 6.050000. running mean: -18.779804\n",
      "ep 42: ep_len:580 episode reward: total was -72.760000. running mean: -19.319606\n",
      "ep 42: ep_len:505 episode reward: total was 24.820000. running mean: -18.878210\n",
      "ep 42: ep_len:500 episode reward: total was 23.770000. running mean: -18.451728\n",
      "ep 42: ep_len:500 episode reward: total was -22.430000. running mean: -18.491511\n",
      "ep 42: ep_len:950 episode reward: total was 16.740000. running mean: -18.139196\n",
      "ep 42: ep_len:520 episode reward: total was -32.340000. running mean: -18.281204\n",
      "ep 42: ep_len:233 episode reward: total was 23.500000. running mean: -17.863392\n",
      "ep 42: ep_len:900 episode reward: total was -15.470000. running mean: -17.839458\n",
      "ep 42: ep_len:500 episode reward: total was 24.810000. running mean: -17.412963\n",
      "ep 42: ep_len:500 episode reward: total was -41.500000. running mean: -17.653834\n",
      "ep 42: ep_len:266 episode reward: total was 26.500000. running mean: -17.212295\n",
      "ep 42: ep_len:1189 episode reward: total was -43.000000. running mean: -17.470172\n",
      "ep 42: ep_len:590 episode reward: total was -15.030000. running mean: -17.445771\n",
      "ep 42: ep_len:217 episode reward: total was 20.000000. running mean: -17.071313\n",
      "ep 42: ep_len:575 episode reward: total was -24.150000. running mean: -17.142100\n",
      "ep 42: ep_len:655 episode reward: total was -2.780000. running mean: -16.998479\n",
      "ep 42: ep_len:500 episode reward: total was 15.850000. running mean: -16.669994\n",
      "ep 42: ep_len:500 episode reward: total was 20.550000. running mean: -16.297794\n",
      "ep 42: ep_len:500 episode reward: total was 3.780000. running mean: -16.097016\n",
      "ep 42: ep_len:715 episode reward: total was -8.720000. running mean: -16.023246\n",
      "ep 42: ep_len:865 episode reward: total was -23.570000. running mean: -16.098713\n",
      "ep 42: ep_len:500 episode reward: total was 20.000000. running mean: -15.737726\n",
      "ep 42: ep_len:510 episode reward: total was -16.200000. running mean: -15.742349\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 42: ep_len:1103 episode reward: total was -71.060000. running mean: -16.295526\n",
      "ep 42: ep_len:500 episode reward: total was 0.280000. running mean: -16.129770\n",
      "ep 42: ep_len:500 episode reward: total was -7.250000. running mean: -16.040973\n",
      "ep 42: ep_len:525 episode reward: total was -24.220000. running mean: -16.122763\n",
      "ep 42: ep_len:720 episode reward: total was -1.440000. running mean: -15.975935\n",
      "ep 42: ep_len:745 episode reward: total was -7.650000. running mean: -15.892676\n",
      "ep 42: ep_len:1450 episode reward: total was -95.120000. running mean: -16.684949\n",
      "ep 42: ep_len:500 episode reward: total was 4.910000. running mean: -16.469000\n",
      "ep 42: ep_len:755 episode reward: total was -8.640000. running mean: -16.390710\n",
      "ep 42: ep_len:500 episode reward: total was 16.270000. running mean: -16.064103\n",
      "ep 42: ep_len:835 episode reward: total was -21.610000. running mean: -16.119562\n",
      "ep 42: ep_len:1361 episode reward: total was -146.840000. running mean: -17.426766\n",
      "ep 42: ep_len:300 episode reward: total was 27.000000. running mean: -16.982498\n",
      "ep 42: ep_len:500 episode reward: total was 16.760000. running mean: -16.645073\n",
      "ep 42: ep_len:500 episode reward: total was 14.350000. running mean: -16.335123\n",
      "ep 42: ep_len:1760 episode reward: total was -160.150000. running mean: -17.773271\n",
      "ep 42: ep_len:1875 episode reward: total was -196.280000. running mean: -19.558339\n",
      "ep 42: ep_len:1140 episode reward: total was 1.420000. running mean: -19.348555\n",
      "ep 42: ep_len:833 episode reward: total was -111.080000. running mean: -20.265870\n",
      "ep 42: ep_len:500 episode reward: total was -2.800000. running mean: -20.091211\n",
      "ep 42: ep_len:500 episode reward: total was 45.500000. running mean: -19.435299\n",
      "ep 42: ep_len:500 episode reward: total was 22.820000. running mean: -19.012746\n",
      "ep 42: ep_len:648 episode reward: total was -82.620000. running mean: -19.648818\n",
      "ep 42: ep_len:1750 episode reward: total was -50.460000. running mean: -19.956930\n",
      "ep 42: ep_len:745 episode reward: total was 12.990000. running mean: -19.627461\n",
      "ep 42: ep_len:540 episode reward: total was 4.350000. running mean: -19.387686\n",
      "ep 42: ep_len:595 episode reward: total was -20.070000. running mean: -19.394509\n",
      "ep 42: ep_len:199 episode reward: total was 19.500000. running mean: -19.005564\n",
      "ep 42: ep_len:1610 episode reward: total was -250.000000. running mean: -21.315509\n",
      "ep 42: ep_len:935 episode reward: total was 16.280000. running mean: -20.939554\n",
      "ep 42: ep_len:600 episode reward: total was 4.890000. running mean: -20.681258\n",
      "ep 42: ep_len:505 episode reward: total was -7.120000. running mean: -20.545646\n",
      "ep 42: ep_len:960 episode reward: total was 7.980000. running mean: -20.260389\n",
      "ep 42: ep_len:515 episode reward: total was -50.530000. running mean: -20.563085\n",
      "ep 42: ep_len:500 episode reward: total was -3.090000. running mean: -20.388354\n",
      "ep 42: ep_len:162 episode reward: total was 16.000000. running mean: -20.024471\n",
      "ep 42: ep_len:600 episode reward: total was -12.470000. running mean: -19.948926\n",
      "ep 42: ep_len:500 episode reward: total was -5.410000. running mean: -19.803537\n",
      "ep 42: ep_len:1338 episode reward: total was -153.440000. running mean: -21.139901\n",
      "ep 42: ep_len:500 episode reward: total was 30.290000. running mean: -20.625602\n",
      "ep 42: ep_len:900 episode reward: total was 10.010000. running mean: -20.319246\n",
      "ep 42: ep_len:805 episode reward: total was 11.180000. running mean: -20.004254\n",
      "ep 42: ep_len:500 episode reward: total was 11.240000. running mean: -19.691811\n",
      "ep 42: ep_len:500 episode reward: total was 30.260000. running mean: -19.192293\n",
      "ep 42: ep_len:500 episode reward: total was 19.970000. running mean: -18.800670\n",
      "ep 42: ep_len:960 episode reward: total was 6.500000. running mean: -18.547664\n",
      "ep 42: ep_len:710 episode reward: total was -3.680000. running mean: -18.398987\n",
      "ep 42: ep_len:500 episode reward: total was 15.780000. running mean: -18.057197\n",
      "ep 42: ep_len:500 episode reward: total was 5.120000. running mean: -17.825425\n",
      "ep 42: ep_len:930 episode reward: total was -0.180000. running mean: -17.648971\n",
      "ep 42: ep_len:715 episode reward: total was -0.730000. running mean: -17.479781\n",
      "ep 42: ep_len:685 episode reward: total was 23.160000. running mean: -17.073383\n",
      "ep 42: ep_len:500 episode reward: total was 16.270000. running mean: -16.739950\n",
      "ep 42: ep_len:500 episode reward: total was 11.150000. running mean: -16.461050\n",
      "ep 42: ep_len:725 episode reward: total was -36.150000. running mean: -16.657940\n",
      "ep 42: ep_len:795 episode reward: total was -23.430000. running mean: -16.725660\n",
      "ep 42: ep_len:500 episode reward: total was -11.260000. running mean: -16.671004\n",
      "ep 42: ep_len:735 episode reward: total was -9.690000. running mean: -16.601194\n",
      "ep 42: ep_len:520 episode reward: total was 16.800000. running mean: -16.267182\n",
      "ep 42: ep_len:865 episode reward: total was 15.540000. running mean: -15.949110\n",
      "ep 42: ep_len:950 episode reward: total was -16.090000. running mean: -15.950519\n",
      "ep 42: ep_len:820 episode reward: total was 9.050000. running mean: -15.700513\n",
      "ep 42: ep_len:555 episode reward: total was -26.210000. running mean: -15.805608\n",
      "ep 42: ep_len:525 episode reward: total was -30.160000. running mean: -15.949152\n",
      "ep 42: ep_len:500 episode reward: total was -4.100000. running mean: -15.830661\n",
      "ep 42: ep_len:220 episode reward: total was 19.000000. running mean: -15.482354\n",
      "ep 42: ep_len:500 episode reward: total was 7.230000. running mean: -15.255231\n",
      "ep 42: ep_len:575 episode reward: total was -15.550000. running mean: -15.258178\n",
      "ep 42: ep_len:725 episode reward: total was 2.210000. running mean: -15.083497\n",
      "ep 42: ep_len:645 episode reward: total was -5.670000. running mean: -14.989362\n",
      "ep 42: ep_len:630 episode reward: total was 2.200000. running mean: -14.817468\n",
      "ep 42: ep_len:500 episode reward: total was -9.720000. running mean: -14.766493\n",
      "ep 42: ep_len:357 episode reward: total was -66.500000. running mean: -15.283828\n",
      "ep 42: ep_len:260 episode reward: total was 20.000000. running mean: -14.930990\n",
      "ep 42: ep_len:900 episode reward: total was -1.550000. running mean: -14.797180\n",
      "ep 42: ep_len:250 episode reward: total was 22.000000. running mean: -14.429208\n",
      "ep 42: ep_len:1465 episode reward: total was -25.160000. running mean: -14.536516\n",
      "ep 42: ep_len:500 episode reward: total was -0.590000. running mean: -14.397051\n",
      "ep 42: ep_len:1875 episode reward: total was -290.190000. running mean: -17.154981\n",
      "ep 42: ep_len:500 episode reward: total was 22.820000. running mean: -16.755231\n",
      "ep 42: ep_len:600 episode reward: total was -29.150000. running mean: -16.879178\n",
      "ep 42: ep_len:710 episode reward: total was 0.360000. running mean: -16.706787\n",
      "ep 42: ep_len:815 episode reward: total was -9.530000. running mean: -16.635019\n",
      "ep 42: ep_len:735 episode reward: total was -4.640000. running mean: -16.515069\n",
      "ep 42: ep_len:637 episode reward: total was -117.970000. running mean: -17.529618\n",
      "ep 42: ep_len:580 episode reward: total was -15.050000. running mean: -17.504822\n",
      "ep 42: ep_len:620 episode reward: total was 15.830000. running mean: -17.171474\n",
      "ep 42: ep_len:500 episode reward: total was -5.190000. running mean: -17.051659\n",
      "ep 42: ep_len:535 episode reward: total was 16.890000. running mean: -16.712242\n",
      "ep 42: ep_len:4615 episode reward: total was -629.180000. running mean: -22.836920\n",
      "ep 42: ep_len:621 episode reward: total was -60.230000. running mean: -23.210851\n",
      "ep 42: ep_len:500 episode reward: total was 11.860000. running mean: -22.860142\n",
      "ep 42: ep_len:500 episode reward: total was 22.420000. running mean: -22.407341\n",
      "ep 42: ep_len:840 episode reward: total was -45.690000. running mean: -22.640167\n",
      "ep 42: ep_len:500 episode reward: total was -0.050000. running mean: -22.414266\n",
      "ep 42: ep_len:705 episode reward: total was -4.700000. running mean: -22.237123\n",
      "ep 42: ep_len:615 episode reward: total was 17.140000. running mean: -21.843352\n",
      "ep 42: ep_len:500 episode reward: total was 6.410000. running mean: -21.560818\n",
      "ep 42: ep_len:690 episode reward: total was -33.010000. running mean: -21.675310\n",
      "ep 42: ep_len:540 episode reward: total was -36.830000. running mean: -21.826857\n",
      "ep 42: ep_len:500 episode reward: total was 24.290000. running mean: -21.365688\n",
      "ep 42: ep_len:805 episode reward: total was -10.560000. running mean: -21.257631\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 42: ep_len:765 episode reward: total was -4.580000. running mean: -21.090855\n",
      "ep 42: ep_len:500 episode reward: total was -2.380000. running mean: -20.903747\n",
      "ep 42: ep_len:650 episode reward: total was -11.880000. running mean: -20.813509\n",
      "ep 42: ep_len:920 episode reward: total was -82.480000. running mean: -21.430174\n",
      "ep 42: ep_len:406 episode reward: total was 23.300000. running mean: -20.982872\n",
      "ep 42: ep_len:600 episode reward: total was 1.220000. running mean: -20.760844\n",
      "ep 42: ep_len:465 episode reward: total was 27.280000. running mean: -20.280435\n",
      "ep 42: ep_len:495 episode reward: total was 32.270000. running mean: -19.754931\n",
      "ep 42: ep_len:500 episode reward: total was 36.750000. running mean: -19.189881\n",
      "ep 42: ep_len:530 episode reward: total was 22.210000. running mean: -18.775883\n",
      "ep 42: ep_len:500 episode reward: total was 18.320000. running mean: -18.404924\n",
      "ep 42: ep_len:500 episode reward: total was 3.710000. running mean: -18.183775\n",
      "ep 42: ep_len:500 episode reward: total was 26.310000. running mean: -17.738837\n",
      "ep 42: ep_len:500 episode reward: total was 21.750000. running mean: -17.343948\n",
      "ep 42: ep_len:500 episode reward: total was -11.990000. running mean: -17.290409\n",
      "ep 42: ep_len:510 episode reward: total was -13.170000. running mean: -17.249205\n",
      "ep 42: ep_len:1425 episode reward: total was -22.170000. running mean: -17.298413\n",
      "ep 42: ep_len:500 episode reward: total was 32.250000. running mean: -16.802929\n",
      "ep 42: ep_len:745 episode reward: total was -6.640000. running mean: -16.701299\n",
      "ep 42: ep_len:675 episode reward: total was -3.750000. running mean: -16.571786\n",
      "ep 42: ep_len:500 episode reward: total was 13.430000. running mean: -16.271769\n",
      "ep 42: ep_len:500 episode reward: total was 5.800000. running mean: -16.051051\n",
      "ep 42: ep_len:965 episode reward: total was 21.240000. running mean: -15.678140\n",
      "ep 42: ep_len:500 episode reward: total was 15.530000. running mean: -15.366059\n",
      "ep 42: ep_len:172 episode reward: total was 17.000000. running mean: -15.042398\n",
      "ep 42: ep_len:500 episode reward: total was 20.280000. running mean: -14.689174\n",
      "ep 42: ep_len:585 episode reward: total was -4.940000. running mean: -14.591683\n",
      "ep 42: ep_len:830 episode reward: total was 12.880000. running mean: -14.316966\n",
      "ep 42: ep_len:357 episode reward: total was 0.530000. running mean: -14.168496\n",
      "ep 42: ep_len:500 episode reward: total was -5.110000. running mean: -14.077911\n",
      "ep 42: ep_len:565 episode reward: total was -33.260000. running mean: -14.269732\n",
      "ep 42: ep_len:1295 episode reward: total was -170.100000. running mean: -15.828035\n",
      "ep 42: ep_len:500 episode reward: total was 20.260000. running mean: -15.467154\n",
      "ep 42: ep_len:860 episode reward: total was -12.470000. running mean: -15.437183\n",
      "ep 42: ep_len:755 episode reward: total was 12.500000. running mean: -15.157811\n",
      "ep 42: ep_len:150 episode reward: total was 13.500000. running mean: -14.871233\n",
      "ep 42: ep_len:500 episode reward: total was 27.150000. running mean: -14.451021\n",
      "ep 42: ep_len:500 episode reward: total was -4.430000. running mean: -14.350810\n",
      "ep 42: ep_len:500 episode reward: total was -2.630000. running mean: -14.233602\n",
      "ep 42: ep_len:870 episode reward: total was -6.450000. running mean: -14.155766\n",
      "ep 42: ep_len:203 episode reward: total was 20.000000. running mean: -13.814209\n",
      "ep 42: ep_len:500 episode reward: total was 8.230000. running mean: -13.593767\n",
      "ep 42: ep_len:500 episode reward: total was 15.780000. running mean: -13.300029\n",
      "ep 42: ep_len:505 episode reward: total was 11.230000. running mean: -13.054729\n",
      "ep 42: ep_len:183 episode reward: total was 18.500000. running mean: -12.739181\n",
      "ep 42: ep_len:1095 episode reward: total was -1.630000. running mean: -12.628089\n",
      "ep 42: ep_len:211 episode reward: total was 21.000000. running mean: -12.291809\n",
      "ep 42: ep_len:655 episode reward: total was -5.810000. running mean: -12.226991\n",
      "ep 42: ep_len:500 episode reward: total was -1.140000. running mean: -12.116121\n",
      "ep 42: ep_len:179 episode reward: total was 17.500000. running mean: -11.819959\n",
      "ep 42: ep_len:500 episode reward: total was 0.290000. running mean: -11.698860\n",
      "ep 42: ep_len:685 episode reward: total was 1.320000. running mean: -11.568671\n",
      "ep 42: ep_len:500 episode reward: total was 50.000000. running mean: -10.952984\n",
      "ep 42: ep_len:500 episode reward: total was -1.340000. running mean: -10.856855\n",
      "ep 42: ep_len:144 episode reward: total was 14.000000. running mean: -10.608286\n",
      "ep 42: ep_len:500 episode reward: total was -15.330000. running mean: -10.655503\n",
      "ep 42: ep_len:500 episode reward: total was 21.960000. running mean: -10.329348\n",
      "ep 42: ep_len:500 episode reward: total was -4.760000. running mean: -10.273655\n",
      "ep 42: ep_len:515 episode reward: total was -9.610000. running mean: -10.267018\n",
      "ep 42: ep_len:720 episode reward: total was -35.980000. running mean: -10.524148\n",
      "ep 42: ep_len:1410 episode reward: total was -139.320000. running mean: -11.812107\n",
      "ep 42: ep_len:925 episode reward: total was 24.630000. running mean: -11.447685\n",
      "ep 42: ep_len:525 episode reward: total was -1.020000. running mean: -11.343409\n",
      "ep 42: ep_len:535 episode reward: total was -9.570000. running mean: -11.325675\n",
      "ep 42: ep_len:317 episode reward: total was 23.030000. running mean: -10.982118\n",
      "ep 42: ep_len:186 episode reward: total was 19.000000. running mean: -10.682297\n",
      "ep 42: ep_len:575 episode reward: total was -20.110000. running mean: -10.776574\n",
      "ep 42: ep_len:1060 episode reward: total was -32.270000. running mean: -10.991508\n",
      "ep 42: ep_len:500 episode reward: total was -8.690000. running mean: -10.968493\n",
      "ep 42: ep_len:489 episode reward: total was 20.550000. running mean: -10.653308\n",
      "ep 42: ep_len:925 episode reward: total was 5.080000. running mean: -10.495975\n",
      "ep 42: ep_len:1140 episode reward: total was -50.270000. running mean: -10.893715\n",
      "ep 42: ep_len:1430 episode reward: total was -30.520000. running mean: -11.089978\n",
      "ep 42: ep_len:845 episode reward: total was 13.320000. running mean: -10.845878\n",
      "ep 42: ep_len:500 episode reward: total was -16.400000. running mean: -10.901419\n",
      "ep 42: ep_len:505 episode reward: total was 0.200000. running mean: -10.790405\n",
      "ep 42: ep_len:835 episode reward: total was 12.570000. running mean: -10.556801\n",
      "ep 42: ep_len:880 episode reward: total was 11.850000. running mean: -10.332733\n",
      "ep 42: ep_len:960 episode reward: total was -13.280000. running mean: -10.362206\n",
      "ep 42: ep_len:500 episode reward: total was 13.270000. running mean: -10.125884\n",
      "ep 42: ep_len:946 episode reward: total was -115.350000. running mean: -11.178125\n",
      "ep 42: ep_len:500 episode reward: total was 18.780000. running mean: -10.878544\n",
      "ep 42: ep_len:565 episode reward: total was -0.420000. running mean: -10.773958\n",
      "ep 42: ep_len:935 episode reward: total was -16.930000. running mean: -10.835519\n",
      "ep 42: ep_len:925 episode reward: total was -126.460000. running mean: -11.991763\n",
      "ep 42: ep_len:510 episode reward: total was 2.570000. running mean: -11.846146\n",
      "ep 42: ep_len:635 episode reward: total was -26.050000. running mean: -11.988184\n",
      "ep 42: ep_len:219 episode reward: total was 21.500000. running mean: -11.653302\n",
      "ep 42: ep_len:241 episode reward: total was 24.000000. running mean: -11.296769\n",
      "ep 42: ep_len:389 episode reward: total was 22.500000. running mean: -10.958802\n",
      "ep 42: ep_len:1080 episode reward: total was -76.510000. running mean: -11.614314\n",
      "ep 42: ep_len:660 episode reward: total was -9.840000. running mean: -11.596571\n",
      "ep 42: ep_len:500 episode reward: total was 19.770000. running mean: -11.282905\n",
      "ep 42: ep_len:520 episode reward: total was -13.150000. running mean: -11.301576\n",
      "ep 42: ep_len:160 episode reward: total was 14.500000. running mean: -11.043560\n",
      "ep 42: ep_len:790 episode reward: total was 2.730000. running mean: -10.905824\n",
      "ep 42: ep_len:500 episode reward: total was 48.500000. running mean: -10.311766\n",
      "ep 42: ep_len:500 episode reward: total was 34.790000. running mean: -9.860749\n",
      "ep 42: ep_len:500 episode reward: total was 7.270000. running mean: -9.689441\n",
      "ep 42: ep_len:426 episode reward: total was 15.750000. running mean: -9.435047\n",
      "ep 42: ep_len:850 episode reward: total was -18.550000. running mean: -9.526196\n",
      "ep 42: ep_len:500 episode reward: total was 7.730000. running mean: -9.353634\n",
      "ep 42: ep_len:565 episode reward: total was 12.210000. running mean: -9.137998\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 42: ep_len:960 episode reward: total was 10.630000. running mean: -8.940318\n",
      "ep 42: ep_len:820 episode reward: total was -20.630000. running mean: -9.057215\n",
      "ep 42: ep_len:830 episode reward: total was 16.690000. running mean: -8.799743\n",
      "ep 42: ep_len:515 episode reward: total was -8.110000. running mean: -8.792845\n",
      "ep 42: ep_len:575 episode reward: total was -34.250000. running mean: -9.047417\n",
      "ep 42: ep_len:960 episode reward: total was -98.700000. running mean: -9.943943\n",
      "ep 42: ep_len:615 episode reward: total was -25.120000. running mean: -10.095703\n",
      "ep 42: ep_len:960 episode reward: total was -33.480000. running mean: -10.329546\n",
      "ep 42: ep_len:500 episode reward: total was 4.750000. running mean: -10.178751\n",
      "ep 42: ep_len:940 episode reward: total was 14.580000. running mean: -9.931163\n",
      "ep 42: ep_len:340 episode reward: total was 32.500000. running mean: -9.506852\n",
      "ep 42: ep_len:950 episode reward: total was 0.070000. running mean: -9.411083\n",
      "ep 42: ep_len:500 episode reward: total was -9.700000. running mean: -9.413972\n",
      "ep 42: ep_len:745 episode reward: total was -5.630000. running mean: -9.376132\n",
      "ep 42: ep_len:615 episode reward: total was 6.420000. running mean: -9.218171\n",
      "ep 42: ep_len:128 episode reward: total was 13.000000. running mean: -8.995989\n",
      "ep 42: ep_len:500 episode reward: total was 10.750000. running mean: -8.798530\n",
      "ep 42: ep_len:500 episode reward: total was -2.660000. running mean: -8.737144\n",
      "ep 42: ep_len:302 episode reward: total was 7.230000. running mean: -8.577473\n",
      "ep 42: ep_len:1410 episode reward: total was -60.500000. running mean: -9.096698\n",
      "ep 42: ep_len:1155 episode reward: total was -15.140000. running mean: -9.157131\n",
      "ep 42: ep_len:1130 episode reward: total was -146.750000. running mean: -10.533060\n",
      "ep 42: ep_len:500 episode reward: total was 11.280000. running mean: -10.314929\n",
      "ep 42: ep_len:500 episode reward: total was 25.760000. running mean: -9.954180\n",
      "ep 42: ep_len:500 episode reward: total was -4.150000. running mean: -9.896138\n",
      "ep 42: ep_len:695 episode reward: total was -42.090000. running mean: -10.218077\n",
      "ep 42: ep_len:685 episode reward: total was -56.670000. running mean: -10.682596\n",
      "ep 42: ep_len:550 episode reward: total was -7.000000. running mean: -10.645770\n",
      "ep 42: ep_len:500 episode reward: total was 17.860000. running mean: -10.360712\n",
      "ep 42: ep_len:520 episode reward: total was -13.150000. running mean: -10.388605\n",
      "ep 42: ep_len:226 episode reward: total was 22.500000. running mean: -10.059719\n",
      "ep 42: ep_len:500 episode reward: total was 16.760000. running mean: -9.791522\n",
      "ep 42: ep_len:500 episode reward: total was -3.960000. running mean: -9.733207\n",
      "ep 42: ep_len:955 episode reward: total was 22.840000. running mean: -9.407475\n",
      "ep 42: ep_len:555 episode reward: total was 5.470000. running mean: -9.258700\n",
      "ep 42: ep_len:750 episode reward: total was 10.950000. running mean: -9.056613\n",
      "ep 42: ep_len:500 episode reward: total was -11.690000. running mean: -9.082947\n",
      "ep 42: ep_len:242 episode reward: total was 24.000000. running mean: -8.752117\n",
      "ep 42: ep_len:500 episode reward: total was 4.420000. running mean: -8.620396\n",
      "ep 42: ep_len:500 episode reward: total was 6.740000. running mean: -8.466792\n",
      "ep 42: ep_len:665 episode reward: total was -4.780000. running mean: -8.429924\n",
      "ep 42: ep_len:500 episode reward: total was 27.840000. running mean: -8.067225\n",
      "ep 42: ep_len:1405 episode reward: total was -163.400000. running mean: -9.620553\n",
      "ep 42: ep_len:500 episode reward: total was 0.410000. running mean: -9.520247\n",
      "ep 42: ep_len:435 episode reward: total was -48.700000. running mean: -9.912045\n",
      "ep 42: ep_len:1455 episode reward: total was -187.630000. running mean: -11.689224\n",
      "ep 42: ep_len:500 episode reward: total was -34.920000. running mean: -11.921532\n",
      "ep 42: ep_len:500 episode reward: total was 10.820000. running mean: -11.694117\n",
      "ep 42: ep_len:1005 episode reward: total was 22.800000. running mean: -11.349176\n",
      "ep 42: ep_len:815 episode reward: total was 10.770000. running mean: -11.127984\n",
      "ep 42: ep_len:1940 episode reward: total was -52.990000. running mean: -11.546604\n",
      "ep 42: ep_len:610 episode reward: total was -38.220000. running mean: -11.813338\n",
      "ep 42: ep_len:237 episode reward: total was 22.500000. running mean: -11.470205\n",
      "ep 42: ep_len:500 episode reward: total was 12.810000. running mean: -11.227402\n",
      "ep 42: ep_len:560 episode reward: total was 18.220000. running mean: -10.932928\n",
      "ep 42: ep_len:500 episode reward: total was 8.280000. running mean: -10.740799\n",
      "ep 42: ep_len:500 episode reward: total was 5.890000. running mean: -10.574491\n",
      "ep 42: ep_len:705 episode reward: total was -82.440000. running mean: -11.293146\n",
      "ep 42: ep_len:500 episode reward: total was 8.890000. running mean: -11.091315\n",
      "ep 42: ep_len:2540 episode reward: total was -245.450000. running mean: -13.434902\n",
      "ep 42: ep_len:680 episode reward: total was 7.240000. running mean: -13.228153\n",
      "ep 42: ep_len:500 episode reward: total was -0.640000. running mean: -13.102271\n",
      "ep 42: ep_len:1475 episode reward: total was -46.590000. running mean: -13.437148\n",
      "ep 42: ep_len:1260 episode reward: total was -244.500000. running mean: -15.747777\n",
      "ep 42: ep_len:695 episode reward: total was -26.940000. running mean: -15.859699\n",
      "ep 42: ep_len:690 episode reward: total was -28.970000. running mean: -15.990802\n",
      "ep 42: ep_len:1065 episode reward: total was -96.380000. running mean: -16.794694\n",
      "ep 42: ep_len:575 episode reward: total was 12.770000. running mean: -16.499047\n",
      "ep 42: ep_len:1710 episode reward: total was 6.630000. running mean: -16.267757\n",
      "ep 42: ep_len:500 episode reward: total was 0.830000. running mean: -16.096779\n",
      "ep 42: ep_len:500 episode reward: total was 3.370000. running mean: -15.902111\n",
      "ep 42: ep_len:500 episode reward: total was 15.780000. running mean: -15.585290\n",
      "ep 42: ep_len:1010 episode reward: total was 3.480000. running mean: -15.394637\n",
      "ep 42: ep_len:500 episode reward: total was 12.810000. running mean: -15.112591\n",
      "ep 42: ep_len:715 episode reward: total was -15.790000. running mean: -15.119365\n",
      "ep 42: ep_len:790 episode reward: total was 32.440000. running mean: -14.643771\n",
      "ep 42: ep_len:695 episode reward: total was -1.260000. running mean: -14.509934\n",
      "ep 42: ep_len:605 episode reward: total was -90.500000. running mean: -15.269834\n",
      "ep 42: ep_len:229 episode reward: total was 21.000000. running mean: -14.907136\n",
      "ep 42: ep_len:500 episode reward: total was 6.770000. running mean: -14.690365\n",
      "ep 42: ep_len:895 episode reward: total was -27.550000. running mean: -14.818961\n",
      "ep 42: ep_len:500 episode reward: total was 14.150000. running mean: -14.529271\n",
      "ep 42: ep_len:2120 episode reward: total was -138.750000. running mean: -15.771479\n",
      "ep 42: ep_len:970 episode reward: total was -11.240000. running mean: -15.726164\n",
      "ep 42: ep_len:500 episode reward: total was -48.900000. running mean: -16.057902\n",
      "ep 42: ep_len:895 episode reward: total was 4.410000. running mean: -15.853223\n",
      "ep 42: ep_len:505 episode reward: total was -6.010000. running mean: -15.754791\n",
      "ep 42: ep_len:915 episode reward: total was -17.410000. running mean: -15.771343\n",
      "ep 42: ep_len:151 episode reward: total was 15.500000. running mean: -15.458630\n",
      "ep 42: ep_len:505 episode reward: total was -6.600000. running mean: -15.370043\n",
      "ep 42: ep_len:748 episode reward: total was -55.100000. running mean: -15.767343\n",
      "ep 42: ep_len:755 episode reward: total was -10.660000. running mean: -15.716270\n",
      "ep 42: ep_len:378 episode reward: total was 34.500000. running mean: -15.214107\n",
      "ep 42: ep_len:500 episode reward: total was 11.180000. running mean: -14.950166\n",
      "ep 42: ep_len:1365 episode reward: total was -82.510000. running mean: -15.625764\n",
      "ep 42: ep_len:1907 episode reward: total was -275.990000. running mean: -18.229406\n",
      "ep 42: ep_len:500 episode reward: total was 21.320000. running mean: -17.833912\n",
      "ep 42: ep_len:505 episode reward: total was -16.990000. running mean: -17.825473\n",
      "ep 42: ep_len:960 episode reward: total was -115.290000. running mean: -18.800119\n",
      "ep 42: ep_len:500 episode reward: total was 13.730000. running mean: -18.474817\n",
      "ep 42: ep_len:995 episode reward: total was -19.270000. running mean: -18.482769\n",
      "ep 42: ep_len:1155 episode reward: total was 21.660000. running mean: -18.081341\n",
      "ep 42: ep_len:725 episode reward: total was 5.060000. running mean: -17.849928\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 42: ep_len:710 episode reward: total was -3.680000. running mean: -17.708229\n",
      "ep 42: ep_len:794 episode reward: total was -8.290000. running mean: -17.614046\n",
      "ep 42: ep_len:146 episode reward: total was 14.500000. running mean: -17.292906\n",
      "ep 42: ep_len:500 episode reward: total was 16.270000. running mean: -16.957277\n",
      "ep 42: ep_len:500 episode reward: total was 17.860000. running mean: -16.609104\n",
      "ep 42: ep_len:199 episode reward: total was 19.500000. running mean: -16.248013\n",
      "ep 42: ep_len:880 episode reward: total was -9.030000. running mean: -16.175833\n",
      "ep 42: ep_len:680 episode reward: total was -48.180000. running mean: -16.495875\n",
      "ep 42: ep_len:830 episode reward: total was -13.540000. running mean: -16.466316\n",
      "ep 42: ep_len:1622 episode reward: total was -272.540000. running mean: -19.027053\n",
      "ep 42: ep_len:645 episode reward: total was 5.780000. running mean: -18.778982\n",
      "ep 42: ep_len:585 episode reward: total was -9.990000. running mean: -18.691092\n",
      "ep 42: ep_len:8505 episode reward: total was -1462.440000. running mean: -33.128582\n",
      "ep 42: ep_len:770 episode reward: total was -9.620000. running mean: -32.893496\n",
      "ep 42: ep_len:500 episode reward: total was 24.260000. running mean: -32.321961\n",
      "ep 42: ep_len:575 episode reward: total was -25.160000. running mean: -32.250341\n",
      "ep 42: ep_len:391 episode reward: total was -67.500000. running mean: -32.602838\n",
      "ep 42: ep_len:500 episode reward: total was 29.250000. running mean: -31.984309\n",
      "ep 42: ep_len:500 episode reward: total was -33.810000. running mean: -32.002566\n",
      "ep 42: ep_len:935 episode reward: total was 14.350000. running mean: -31.539041\n",
      "ep 42: ep_len:620 episode reward: total was 4.840000. running mean: -31.175250\n",
      "ep 42: ep_len:590 episode reward: total was -34.220000. running mean: -31.205698\n",
      "ep 42: ep_len:500 episode reward: total was -0.180000. running mean: -30.895441\n",
      "ep 42: ep_len:860 episode reward: total was -20.250000. running mean: -30.788986\n",
      "ep 42: ep_len:500 episode reward: total was 9.290000. running mean: -30.388196\n",
      "ep 42: ep_len:680 episode reward: total was -13.840000. running mean: -30.222714\n",
      "ep 42: ep_len:500 episode reward: total was 10.790000. running mean: -29.812587\n",
      "ep 42: ep_len:220 episode reward: total was 19.000000. running mean: -29.324461\n",
      "ep 42: ep_len:1005 episode reward: total was 8.340000. running mean: -28.947817\n",
      "ep 42: ep_len:680 episode reward: total was -6.770000. running mean: -28.726039\n",
      "ep 42: ep_len:500 episode reward: total was -20.730000. running mean: -28.646078\n",
      "ep 42: ep_len:865 episode reward: total was -22.560000. running mean: -28.585218\n",
      "ep 42: ep_len:985 episode reward: total was -19.560000. running mean: -28.494965\n",
      "ep 42: ep_len:965 episode reward: total was -23.370000. running mean: -28.443716\n",
      "ep 42: ep_len:995 episode reward: total was -83.210000. running mean: -28.991379\n",
      "ep 42: ep_len:295 episode reward: total was 22.000000. running mean: -28.481465\n",
      "ep 42: ep_len:351 episode reward: total was 1.520000. running mean: -28.181450\n",
      "ep 42: ep_len:945 episode reward: total was -21.390000. running mean: -28.113536\n",
      "ep 42: ep_len:575 episode reward: total was -39.300000. running mean: -28.225400\n",
      "ep 42: ep_len:620 episode reward: total was -5.170000. running mean: -27.994846\n",
      "ep 42: ep_len:500 episode reward: total was 13.790000. running mean: -27.576998\n",
      "ep 42: ep_len:1310 episode reward: total was -214.890000. running mean: -29.450128\n",
      "ep 42: ep_len:1329 episode reward: total was -206.450000. running mean: -31.220127\n",
      "ep 42: ep_len:715 episode reward: total was 13.300000. running mean: -30.774925\n",
      "ep 42: ep_len:500 episode reward: total was 12.780000. running mean: -30.339376\n",
      "ep 42: ep_len:500 episode reward: total was 9.990000. running mean: -29.936082\n",
      "ep 42: ep_len:500 episode reward: total was -4.160000. running mean: -29.678321\n",
      "ep 42: ep_len:207 episode reward: total was 17.500000. running mean: -29.206538\n",
      "ep 42: ep_len:515 episode reward: total was 1.280000. running mean: -28.901673\n",
      "ep 42: ep_len:910 episode reward: total was -7.530000. running mean: -28.687956\n",
      "ep 42: ep_len:805 episode reward: total was -4.220000. running mean: -28.443277\n",
      "ep 42: ep_len:515 episode reward: total was -6.090000. running mean: -28.219744\n",
      "ep 42: ep_len:500 episode reward: total was 49.000000. running mean: -27.447546\n",
      "ep 42: ep_len:121 episode reward: total was 12.000000. running mean: -27.053071\n",
      "ep 42: ep_len:500 episode reward: total was -3.700000. running mean: -26.819540\n",
      "ep 42: ep_len:945 episode reward: total was 10.850000. running mean: -26.442845\n",
      "ep 42: ep_len:570 episode reward: total was -4.690000. running mean: -26.225316\n",
      "ep 42: ep_len:12660 episode reward: total was -2384.180000. running mean: -49.804863\n",
      "ep 42: ep_len:750 episode reward: total was -40.970000. running mean: -49.716515\n",
      "ep 42: ep_len:970 episode reward: total was -18.310000. running mean: -49.402449\n",
      "ep 42: ep_len:645 episode reward: total was -59.360000. running mean: -49.502025\n",
      "ep 42: ep_len:645 episode reward: total was 0.140000. running mean: -49.005605\n",
      "ep 42: ep_len:483 episode reward: total was 29.790000. running mean: -48.217649\n",
      "ep 42: ep_len:645 episode reward: total was 4.820000. running mean: -47.687272\n",
      "ep 42: ep_len:500 episode reward: total was 37.180000. running mean: -46.838599\n",
      "ep 42: ep_len:505 episode reward: total was -19.240000. running mean: -46.562613\n",
      "ep 42: ep_len:765 episode reward: total was -35.460000. running mean: -46.451587\n",
      "ep 42: ep_len:500 episode reward: total was -0.240000. running mean: -45.989471\n",
      "ep 42: ep_len:500 episode reward: total was -13.090000. running mean: -45.660477\n",
      "ep 42: ep_len:1890 episode reward: total was -153.310000. running mean: -46.736972\n",
      "ep 42: ep_len:635 episode reward: total was -3.980000. running mean: -46.309402\n",
      "ep 42: ep_len:600 episode reward: total was -16.020000. running mean: -46.006508\n",
      "ep 42: ep_len:825 episode reward: total was -38.800000. running mean: -45.934443\n",
      "ep 42: ep_len:705 episode reward: total was 0.970000. running mean: -45.465399\n",
      "ep 42: ep_len:1026 episode reward: total was -127.310000. running mean: -46.283845\n",
      "ep 42: ep_len:735 episode reward: total was -8.680000. running mean: -45.907806\n",
      "ep 42: ep_len:500 episode reward: total was -19.180000. running mean: -45.640528\n",
      "ep 42: ep_len:780 episode reward: total was -56.060000. running mean: -45.744723\n",
      "ep 42: ep_len:885 episode reward: total was 3.920000. running mean: -45.248076\n",
      "ep 42: ep_len:500 episode reward: total was 1.290000. running mean: -44.782695\n",
      "ep 42: ep_len:1095 episode reward: total was -39.830000. running mean: -44.733168\n",
      "ep 42: ep_len:1404 episode reward: total was -94.190000. running mean: -45.227736\n",
      "ep 42: ep_len:500 episode reward: total was 0.530000. running mean: -44.770159\n",
      "ep 42: ep_len:500 episode reward: total was 20.280000. running mean: -44.119657\n",
      "ep 42: ep_len:510 episode reward: total was -18.220000. running mean: -43.860661\n",
      "ep 42: ep_len:1060 episode reward: total was -7.450000. running mean: -43.496554\n",
      "ep 42: ep_len:500 episode reward: total was -11.260000. running mean: -43.174189\n",
      "ep 42: ep_len:500 episode reward: total was -11.170000. running mean: -42.854147\n",
      "ep 42: ep_len:500 episode reward: total was 17.770000. running mean: -42.247905\n",
      "ep 42: ep_len:2548 episode reward: total was -409.610000. running mean: -45.921526\n",
      "ep 42: ep_len:615 episode reward: total was -34.170000. running mean: -45.804011\n",
      "ep 42: ep_len:680 episode reward: total was -4.750000. running mean: -45.393471\n",
      "ep 42: ep_len:565 episode reward: total was 19.770000. running mean: -44.741836\n",
      "ep 42: ep_len:795 episode reward: total was -10.080000. running mean: -44.395218\n",
      "ep 42: ep_len:500 episode reward: total was 26.800000. running mean: -43.683266\n",
      "ep 42: ep_len:545 episode reward: total was -17.140000. running mean: -43.417833\n",
      "ep 42: ep_len:1450 episode reward: total was -137.020000. running mean: -44.353855\n",
      "ep 42: ep_len:500 episode reward: total was -11.930000. running mean: -44.029616\n",
      "ep 42: ep_len:1800 episode reward: total was -112.510000. running mean: -44.714420\n",
      "ep 42: ep_len:1025 episode reward: total was -47.490000. running mean: -44.742176\n",
      "ep 42: ep_len:500 episode reward: total was -3.190000. running mean: -44.326654\n",
      "ep 42: ep_len:500 episode reward: total was -10.890000. running mean: -43.992287\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 42: ep_len:685 episode reward: total was -2.720000. running mean: -43.579564\n",
      "ep 42: ep_len:650 episode reward: total was 2.330000. running mean: -43.120469\n",
      "ep 42: ep_len:394 episode reward: total was -6.740000. running mean: -42.756664\n",
      "ep 42: ep_len:500 episode reward: total was -12.880000. running mean: -42.457898\n",
      "ep 42: ep_len:500 episode reward: total was -11.290000. running mean: -42.146219\n",
      "ep 42: ep_len:458 episode reward: total was 44.000000. running mean: -41.284756\n",
      "ep 42: ep_len:500 episode reward: total was 25.910000. running mean: -40.612809\n",
      "ep 42: ep_len:500 episode reward: total was 8.250000. running mean: -40.124181\n",
      "ep 42: ep_len:605 episode reward: total was -8.940000. running mean: -39.812339\n",
      "ep 42: ep_len:500 episode reward: total was -2.140000. running mean: -39.435616\n",
      "ep 42: ep_len:770 episode reward: total was 4.740000. running mean: -38.993859\n",
      "ep 42: ep_len:765 episode reward: total was -20.580000. running mean: -38.809721\n",
      "ep 42: ep_len:700 episode reward: total was -26.930000. running mean: -38.690924\n",
      "ep 42: ep_len:264 episode reward: total was 26.000000. running mean: -38.044014\n",
      "ep 42: ep_len:500 episode reward: total was 10.580000. running mean: -37.557774\n",
      "ep 42: ep_len:1205 episode reward: total was 2.840000. running mean: -37.153796\n",
      "ep 42: ep_len:500 episode reward: total was -27.880000. running mean: -37.061058\n",
      "ep 42: ep_len:215 episode reward: total was 20.000000. running mean: -36.490448\n",
      "ep 42: ep_len:770 episode reward: total was -16.690000. running mean: -36.292443\n",
      "ep 42: ep_len:500 episode reward: total was 29.220000. running mean: -35.637319\n",
      "ep 42: ep_len:835 episode reward: total was -17.570000. running mean: -35.456646\n",
      "ep 42: ep_len:500 episode reward: total was 26.740000. running mean: -34.834679\n",
      "ep 42: ep_len:225 episode reward: total was 21.000000. running mean: -34.276333\n",
      "ep 42: ep_len:500 episode reward: total was 11.140000. running mean: -33.822169\n",
      "ep 42: ep_len:500 episode reward: total was -1.760000. running mean: -33.501548\n",
      "ep 42: ep_len:205 episode reward: total was 19.000000. running mean: -32.976532\n",
      "ep 42: ep_len:1375 episode reward: total was -79.600000. running mean: -33.442767\n",
      "ep 42: ep_len:187 episode reward: total was 18.500000. running mean: -32.923339\n",
      "ep 42: ep_len:228 episode reward: total was 22.500000. running mean: -32.369106\n",
      "ep 42: ep_len:735 episode reward: total was 16.020000. running mean: -31.885215\n",
      "ep 42: ep_len:327 episode reward: total was 31.000000. running mean: -31.256362\n",
      "ep 42: ep_len:500 episode reward: total was 11.920000. running mean: -30.824599\n",
      "ep 42: ep_len:249 episode reward: total was 24.500000. running mean: -30.271353\n",
      "ep 42: ep_len:500 episode reward: total was 5.300000. running mean: -29.915639\n",
      "ep 42: ep_len:150 episode reward: total was 12.000000. running mean: -29.496483\n",
      "ep 42: ep_len:500 episode reward: total was 6.410000. running mean: -29.137418\n",
      "ep 42: ep_len:500 episode reward: total was -1.210000. running mean: -28.858144\n",
      "ep 42: ep_len:191 episode reward: total was 19.000000. running mean: -28.379562\n",
      "ep 42: ep_len:500 episode reward: total was 5.240000. running mean: -28.043367\n",
      "ep 42: ep_len:790 episode reward: total was -3.520000. running mean: -27.798133\n",
      "ep 42: ep_len:500 episode reward: total was 7.810000. running mean: -27.442052\n",
      "ep 42: ep_len:500 episode reward: total was 11.770000. running mean: -27.049931\n",
      "ep 42: ep_len:500 episode reward: total was 0.570000. running mean: -26.773732\n",
      "ep 42: ep_len:500 episode reward: total was -0.790000. running mean: -26.513895\n",
      "ep 42: ep_len:915 episode reward: total was -11.350000. running mean: -26.362256\n",
      "ep 42: ep_len:805 episode reward: total was -9.550000. running mean: -26.194133\n",
      "ep 42: ep_len:500 episode reward: total was 24.470000. running mean: -25.687492\n",
      "ep 42: ep_len:520 episode reward: total was -12.140000. running mean: -25.552017\n",
      "ep 42: ep_len:540 episode reward: total was -21.160000. running mean: -25.508097\n",
      "ep 42: ep_len:575 episode reward: total was 12.720000. running mean: -25.125816\n",
      "ep 42: ep_len:565 episode reward: total was -6.430000. running mean: -24.938858\n",
      "ep 42: ep_len:500 episode reward: total was -20.440000. running mean: -24.893869\n",
      "ep 42: ep_len:1020 episode reward: total was -115.170000. running mean: -25.796630\n",
      "ep 42: ep_len:500 episode reward: total was 12.680000. running mean: -25.411864\n",
      "ep 42: ep_len:525 episode reward: total was -8.090000. running mean: -25.238645\n",
      "ep 42: ep_len:500 episode reward: total was 7.020000. running mean: -24.916059\n",
      "ep 42: ep_len:500 episode reward: total was 12.810000. running mean: -24.538798\n",
      "ep 42: ep_len:500 episode reward: total was -31.400000. running mean: -24.607410\n",
      "ep 42: ep_len:925 episode reward: total was 2.040000. running mean: -24.340936\n",
      "ep 42: ep_len:660 episode reward: total was 6.870000. running mean: -24.028827\n",
      "ep 42: ep_len:574 episode reward: total was -81.730000. running mean: -24.605839\n",
      "ep 42: ep_len:500 episode reward: total was 3.290000. running mean: -24.326880\n",
      "ep 42: ep_len:850 episode reward: total was 13.030000. running mean: -23.953311\n",
      "ep 42: ep_len:555 episode reward: total was 13.280000. running mean: -23.580978\n",
      "ep 42: ep_len:550 episode reward: total was -15.110000. running mean: -23.496269\n",
      "ep 42: ep_len:975 episode reward: total was 5.280000. running mean: -23.208506\n",
      "ep 42: ep_len:510 episode reward: total was 6.620000. running mean: -22.910221\n",
      "ep 42: ep_len:520 episode reward: total was -8.100000. running mean: -22.762119\n",
      "ep 42: ep_len:500 episode reward: total was -4.860000. running mean: -22.583097\n",
      "ep 42: ep_len:965 episode reward: total was -34.480000. running mean: -22.702066\n",
      "ep 42: ep_len:935 episode reward: total was -8.530000. running mean: -22.560346\n",
      "ep 42: ep_len:750 episode reward: total was -7.640000. running mean: -22.411142\n",
      "ep 42: ep_len:286 episode reward: total was -32.840000. running mean: -22.515431\n",
      "ep 42: ep_len:860 episode reward: total was 5.480000. running mean: -22.235477\n",
      "ep 42: ep_len:173 episode reward: total was 17.000000. running mean: -21.843122\n",
      "ep 42: ep_len:500 episode reward: total was -0.910000. running mean: -21.633791\n",
      "ep 42: ep_len:835 episode reward: total was -61.000000. running mean: -22.027453\n",
      "ep 42: ep_len:288 episode reward: total was 28.500000. running mean: -21.522178\n",
      "ep 42: ep_len:940 episode reward: total was 22.760000. running mean: -21.079356\n",
      "ep 42: ep_len:500 episode reward: total was 16.730000. running mean: -20.701263\n",
      "ep 42: ep_len:500 episode reward: total was 48.500000. running mean: -20.009250\n",
      "ep 42: ep_len:770 episode reward: total was 2.230000. running mean: -19.786858\n",
      "ep 42: ep_len:800 episode reward: total was -2.490000. running mean: -19.613889\n",
      "ep 42: ep_len:129 episode reward: total was 12.500000. running mean: -19.292750\n",
      "ep 42: ep_len:500 episode reward: total was 17.770000. running mean: -18.922123\n",
      "ep 42: ep_len:720 episode reward: total was 14.720000. running mean: -18.585702\n",
      "ep 42: ep_len:895 episode reward: total was 2.050000. running mean: -18.379345\n",
      "ep 42: ep_len:660 episode reward: total was -36.070000. running mean: -18.556251\n",
      "ep 42: ep_len:655 episode reward: total was 15.940000. running mean: -18.211289\n",
      "ep 42: ep_len:224 episode reward: total was 20.500000. running mean: -17.824176\n",
      "ep 42: ep_len:500 episode reward: total was 31.790000. running mean: -17.328034\n",
      "ep 42: ep_len:505 episode reward: total was -5.100000. running mean: -17.205754\n",
      "ep 42: ep_len:1055 episode reward: total was -5.720000. running mean: -17.090896\n",
      "ep 42: ep_len:500 episode reward: total was 25.670000. running mean: -16.663287\n",
      "ep 42: ep_len:500 episode reward: total was -5.930000. running mean: -16.555954\n",
      "ep 42: ep_len:835 episode reward: total was -6.460000. running mean: -16.454995\n",
      "ep 42: ep_len:500 episode reward: total was 3.840000. running mean: -16.252045\n",
      "ep 42: ep_len:760 episode reward: total was -5.600000. running mean: -16.145524\n",
      "ep 42: ep_len:820 episode reward: total was 14.470000. running mean: -15.839369\n",
      "ep 42: ep_len:550 episode reward: total was -11.890000. running mean: -15.799875\n",
      "ep 42: ep_len:500 episode reward: total was 20.400000. running mean: -15.437877\n",
      "ep 42: ep_len:500 episode reward: total was 50.000000. running mean: -14.783498\n",
      "ep 42: ep_len:680 episode reward: total was 26.640000. running mean: -14.369263\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 42: ep_len:500 episode reward: total was 20.460000. running mean: -14.020970\n",
      "ep 42: ep_len:555 episode reward: total was -11.060000. running mean: -13.991361\n",
      "ep 42: ep_len:500 episode reward: total was -26.740000. running mean: -14.118847\n",
      "ep 42: ep_len:500 episode reward: total was 23.620000. running mean: -13.741458\n",
      "ep 42: ep_len:910 episode reward: total was -4.940000. running mean: -13.653444\n",
      "ep 42: ep_len:1671 episode reward: total was -228.990000. running mean: -15.806809\n",
      "ep 42: ep_len:840 episode reward: total was -15.540000. running mean: -15.804141\n",
      "ep 42: ep_len:535 episode reward: total was -14.130000. running mean: -15.787400\n",
      "ep 42: ep_len:950 episode reward: total was 17.440000. running mean: -15.455126\n",
      "ep 42: ep_len:1265 episode reward: total was 20.530000. running mean: -15.095275\n",
      "ep 42: ep_len:735 episode reward: total was -75.640000. running mean: -15.700722\n",
      "ep 42: ep_len:500 episode reward: total was 22.240000. running mean: -15.321315\n",
      "ep 42: ep_len:580 episode reward: total was -26.160000. running mean: -15.429702\n",
      "ep 42: ep_len:500 episode reward: total was 0.050000. running mean: -15.274905\n",
      "ep 42: ep_len:645 episode reward: total was -26.030000. running mean: -15.382455\n",
      "ep 42: ep_len:153 episode reward: total was 15.500000. running mean: -15.073631\n",
      "ep 42: ep_len:1145 episode reward: total was -0.040000. running mean: -14.923295\n",
      "ep 42: ep_len:271 episode reward: total was 19.500000. running mean: -14.579062\n",
      "ep 42: ep_len:975 episode reward: total was 12.350000. running mean: -14.309771\n",
      "ep 42: ep_len:500 episode reward: total was 17.030000. running mean: -13.996373\n",
      "ep 42: ep_len:1020 episode reward: total was 4.850000. running mean: -13.807910\n",
      "ep 42: ep_len:500 episode reward: total was -5.010000. running mean: -13.719931\n",
      "ep 42: ep_len:500 episode reward: total was 18.870000. running mean: -13.394031\n",
      "ep 42: ep_len:500 episode reward: total was 19.300000. running mean: -13.067091\n",
      "ep 42: ep_len:660 episode reward: total was -33.070000. running mean: -13.267120\n",
      "ep 42: ep_len:850 episode reward: total was -13.500000. running mean: -13.269449\n",
      "ep 42: ep_len:500 episode reward: total was 3.900000. running mean: -13.097754\n",
      "ep 42: ep_len:500 episode reward: total was 2.390000. running mean: -12.942877\n",
      "ep 42: ep_len:525 episode reward: total was -6.790000. running mean: -12.881348\n",
      "ep 42: ep_len:236 episode reward: total was 22.000000. running mean: -12.532534\n",
      "ep 42: ep_len:770 episode reward: total was 8.150000. running mean: -12.325709\n",
      "ep 42: ep_len:500 episode reward: total was 9.780000. running mean: -12.104652\n",
      "ep 42: ep_len:845 episode reward: total was -70.740000. running mean: -12.691006\n",
      "ep 42: ep_len:505 episode reward: total was -5.100000. running mean: -12.615095\n",
      "ep 42: ep_len:790 episode reward: total was -82.300000. running mean: -13.311945\n",
      "ep 42: ep_len:500 episode reward: total was 5.430000. running mean: -13.124525\n",
      "ep 42: ep_len:890 episode reward: total was -12.950000. running mean: -13.122780\n",
      "ep 42: ep_len:500 episode reward: total was 6.560000. running mean: -12.925952\n",
      "ep 42: ep_len:930 episode reward: total was -2.250000. running mean: -12.819193\n",
      "ep 42: ep_len:915 episode reward: total was 25.710000. running mean: -12.433901\n",
      "ep 42: ep_len:570 episode reward: total was 3.940000. running mean: -12.270162\n",
      "ep 42: ep_len:500 episode reward: total was 29.280000. running mean: -11.854660\n",
      "ep 42: ep_len:795 episode reward: total was -5.530000. running mean: -11.791413\n",
      "ep 42: ep_len:211 episode reward: total was 19.500000. running mean: -11.478499\n",
      "ep 42: ep_len:600 episode reward: total was -17.030000. running mean: -11.534014\n",
      "ep 42: ep_len:755 episode reward: total was -3.590000. running mean: -11.454574\n",
      "ep 42: ep_len:128 episode reward: total was 12.500000. running mean: -11.215028\n",
      "ep 42: ep_len:500 episode reward: total was 22.330000. running mean: -10.879578\n",
      "ep 42: ep_len:800 episode reward: total was -108.540000. running mean: -11.856182\n",
      "ep 42: ep_len:1704 episode reward: total was -258.710000. running mean: -14.324720\n",
      "ep 42: ep_len:510 episode reward: total was 22.870000. running mean: -13.952773\n",
      "ep 42: ep_len:805 episode reward: total was -1.190000. running mean: -13.825146\n",
      "ep 42: ep_len:760 episode reward: total was -42.970000. running mean: -14.116594\n",
      "ep 42: ep_len:500 episode reward: total was 18.900000. running mean: -13.786428\n",
      "ep 42: ep_len:500 episode reward: total was 48.500000. running mean: -13.163564\n",
      "ep 42: ep_len:500 episode reward: total was -5.660000. running mean: -13.088528\n",
      "ep 42: ep_len:715 episode reward: total was -5.690000. running mean: -13.014543\n",
      "ep 42: ep_len:222 episode reward: total was 22.000000. running mean: -12.664398\n",
      "ep 42: ep_len:925 episode reward: total was 10.480000. running mean: -12.432954\n",
      "ep 42: ep_len:500 episode reward: total was 10.270000. running mean: -12.205924\n",
      "ep 42: ep_len:500 episode reward: total was 28.240000. running mean: -11.801465\n",
      "ep 42: ep_len:500 episode reward: total was 1.640000. running mean: -11.667050\n",
      "ep 42: ep_len:261 episode reward: total was 26.000000. running mean: -11.290380\n",
      "ep 42: ep_len:965 episode reward: total was 19.810000. running mean: -10.979376\n",
      "ep 42: ep_len:540 episode reward: total was 0.360000. running mean: -10.865982\n",
      "ep 42: ep_len:875 episode reward: total was -6.380000. running mean: -10.821122\n",
      "ep 42: ep_len:1585 episode reward: total was -234.410000. running mean: -13.057011\n",
      "ep 42: ep_len:1045 episode reward: total was -9.610000. running mean: -13.022541\n",
      "ep 42: ep_len:575 episode reward: total was -24.150000. running mean: -13.133815\n",
      "ep 42: ep_len:500 episode reward: total was -6.320000. running mean: -13.065677\n",
      "ep 42: ep_len:670 episode reward: total was 1.200000. running mean: -12.923021\n",
      "ep 42: ep_len:510 episode reward: total was -7.110000. running mean: -12.864890\n",
      "ep 42: ep_len:4505 episode reward: total was -686.930000. running mean: -19.605541\n",
      "ep 42: ep_len:500 episode reward: total was 27.350000. running mean: -19.135986\n",
      "ep 42: ep_len:105 episode reward: total was 9.000000. running mean: -18.854626\n",
      "ep 42: ep_len:625 episode reward: total was 12.220000. running mean: -18.543880\n",
      "ep 42: ep_len:675 episode reward: total was 1.300000. running mean: -18.345441\n",
      "ep 42: ep_len:545 episode reward: total was 12.940000. running mean: -18.032587\n",
      "ep 42: ep_len:27480 episode reward: total was -5370.810000. running mean: -71.560361\n",
      "ep 42: ep_len:215 episode reward: total was 20.000000. running mean: -70.644757\n",
      "ep 42: ep_len:725 episode reward: total was -7.690000. running mean: -70.015210\n",
      "ep 42: ep_len:500 episode reward: total was 22.390000. running mean: -69.091158\n",
      "ep 42: ep_len:304 episode reward: total was 30.000000. running mean: -68.100246\n",
      "ep 42: ep_len:610 episode reward: total was -43.270000. running mean: -67.851944\n",
      "ep 42: ep_len:535 episode reward: total was 21.330000. running mean: -66.960124\n",
      "ep 42: ep_len:610 episode reward: total was -15.560000. running mean: -66.446123\n",
      "ep 42: ep_len:985 episode reward: total was -49.760000. running mean: -66.279262\n",
      "ep 42: ep_len:535 episode reward: total was -37.470000. running mean: -65.991169\n",
      "ep 42: ep_len:500 episode reward: total was -50.980000. running mean: -65.841057\n",
      "ep 42: ep_len:590 episode reward: total was -53.410000. running mean: -65.716747\n",
      "ep 42: ep_len:1090 episode reward: total was -129.400000. running mean: -66.353579\n",
      "ep 42: ep_len:740 episode reward: total was -28.800000. running mean: -65.978043\n",
      "ep 42: ep_len:715 episode reward: total was -37.000000. running mean: -65.688263\n",
      "ep 42: ep_len:500 episode reward: total was 28.250000. running mean: -64.748880\n",
      "ep 42: ep_len:1225 episode reward: total was -105.670000. running mean: -65.158092\n",
      "ep 42: ep_len:500 episode reward: total was 24.840000. running mean: -64.258111\n",
      "ep 42: ep_len:500 episode reward: total was 19.970000. running mean: -63.415830\n",
      "ep 42: ep_len:1072 episode reward: total was -104.610000. running mean: -63.827771\n",
      "ep 42: ep_len:850 episode reward: total was -14.290000. running mean: -63.332394\n",
      "ep 42: ep_len:520 episode reward: total was 13.740000. running mean: -62.561670\n",
      "ep 42: ep_len:500 episode reward: total was -1.940000. running mean: -61.955453\n",
      "ep 42: ep_len:824 episode reward: total was -117.570000. running mean: -62.511598\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 42: ep_len:1254 episode reward: total was -204.660000. running mean: -63.933082\n",
      "ep 42: ep_len:745 episode reward: total was -4.290000. running mean: -63.336652\n",
      "ep 42: ep_len:500 episode reward: total was -29.560000. running mean: -62.998885\n",
      "ep 42: ep_len:500 episode reward: total was 10.240000. running mean: -62.266496\n",
      "ep 42: ep_len:500 episode reward: total was 25.330000. running mean: -61.390531\n",
      "ep 42: ep_len:500 episode reward: total was 21.990000. running mean: -60.556726\n",
      "ep 42: ep_len:920 episode reward: total was -29.520000. running mean: -60.246359\n",
      "ep 42: ep_len:1365 episode reward: total was -156.310000. running mean: -61.206995\n",
      "ep 42: ep_len:855 episode reward: total was -32.380000. running mean: -60.918725\n",
      "ep 42: ep_len:690 episode reward: total was -48.160000. running mean: -60.791138\n",
      "ep 42: ep_len:1075 episode reward: total was 0.280000. running mean: -60.180427\n",
      "ep 42: ep_len:760 episode reward: total was 9.930000. running mean: -59.479322\n",
      "ep 42: ep_len:500 episode reward: total was -30.420000. running mean: -59.188729\n",
      "ep 42: ep_len:500 episode reward: total was -28.330000. running mean: -58.880142\n",
      "ep 42: ep_len:500 episode reward: total was 11.740000. running mean: -58.173940\n",
      "ep 42: ep_len:600 episode reward: total was -17.470000. running mean: -57.766901\n",
      "ep 42: ep_len:500 episode reward: total was 3.260000. running mean: -57.156632\n",
      "ep 42: ep_len:735 episode reward: total was -12.720000. running mean: -56.712266\n",
      "ep 42: ep_len:820 episode reward: total was 1.670000. running mean: -56.128443\n",
      "ep 42: ep_len:500 episode reward: total was -3.580000. running mean: -55.602959\n",
      "ep 42: ep_len:347 episode reward: total was 33.000000. running mean: -54.716929\n",
      "ep 42: ep_len:520 episode reward: total was -29.310000. running mean: -54.462860\n",
      "ep 42: ep_len:960 episode reward: total was 3.840000. running mean: -53.879831\n",
      "ep 42: ep_len:775 episode reward: total was -77.280000. running mean: -54.113833\n",
      "ep 42: ep_len:615 episode reward: total was 3.110000. running mean: -53.541594\n",
      "ep 42: ep_len:500 episode reward: total was -0.540000. running mean: -53.011578\n",
      "ep 42: ep_len:795 episode reward: total was 7.500000. running mean: -52.406463\n",
      "ep 42: ep_len:980 episode reward: total was 16.400000. running mean: -51.718398\n",
      "ep 42: ep_len:179 episode reward: total was 17.500000. running mean: -51.026214\n",
      "ep 42: ep_len:244 episode reward: total was 24.500000. running mean: -50.270952\n",
      "ep 42: ep_len:760 episode reward: total was 1.890000. running mean: -49.749342\n",
      "ep 42: ep_len:885 episode reward: total was 17.770000. running mean: -49.074149\n",
      "ep 42: ep_len:600 episode reward: total was 5.810000. running mean: -48.525308\n",
      "ep 42: ep_len:273 episode reward: total was 24.000000. running mean: -47.800054\n",
      "ep 42: ep_len:705 episode reward: total was -5.710000. running mean: -47.379154\n",
      "ep 42: ep_len:745 episode reward: total was -45.020000. running mean: -47.355562\n",
      "ep 42: ep_len:500 episode reward: total was -24.080000. running mean: -47.122807\n",
      "ep 42: ep_len:203 episode reward: total was 18.500000. running mean: -46.466579\n",
      "ep 42: ep_len:1172 episode reward: total was -195.670000. running mean: -47.958613\n",
      "ep 42: ep_len:500 episode reward: total was 30.320000. running mean: -47.175827\n",
      "ep 42: ep_len:1317 episode reward: total was -134.780000. running mean: -48.051868\n",
      "ep 42: ep_len:500 episode reward: total was 32.280000. running mean: -47.248550\n",
      "ep 42: ep_len:500 episode reward: total was 28.270000. running mean: -46.493364\n",
      "ep 42: ep_len:500 episode reward: total was -62.250000. running mean: -46.650931\n",
      "ep 42: ep_len:625 episode reward: total was -42.590000. running mean: -46.610321\n",
      "ep 42: ep_len:159 episode reward: total was 14.000000. running mean: -46.004218\n",
      "ep 42: ep_len:500 episode reward: total was 24.290000. running mean: -45.301276\n",
      "ep 42: ep_len:500 episode reward: total was 20.770000. running mean: -44.640563\n",
      "ep 42: ep_len:710 episode reward: total was -78.440000. running mean: -44.978558\n",
      "ep 42: ep_len:2605 episode reward: total was -459.990000. running mean: -49.128672\n",
      "ep 42: ep_len:500 episode reward: total was -7.160000. running mean: -48.708985\n",
      "ep 42: ep_len:5505 episode reward: total was -915.440000. running mean: -57.376295\n",
      "ep 42: ep_len:930 episode reward: total was -10.590000. running mean: -56.908432\n",
      "ep 42: ep_len:500 episode reward: total was -17.230000. running mean: -56.511648\n",
      "ep 42: ep_len:1360 episode reward: total was -45.410000. running mean: -56.400632\n",
      "ep 42: ep_len:500 episode reward: total was 48.500000. running mean: -55.351625\n",
      "ep 42: ep_len:451 episode reward: total was 16.140000. running mean: -54.636709\n",
      "ep 42: ep_len:690 episode reward: total was -2.710000. running mean: -54.117442\n",
      "epsilon:0.010000 episode_count: 33919. steps_count: 24635116.000000\n",
      "ep 43: ep_len:1560 episode reward: total was -53.180000. running mean: -54.108068\n",
      "ep 43: ep_len:780 episode reward: total was -3.600000. running mean: -53.602987\n",
      "ep 43: ep_len:500 episode reward: total was -6.450000. running mean: -53.131457\n",
      "ep 43: ep_len:820 episode reward: total was 3.320000. running mean: -52.566942\n",
      "ep 43: ep_len:680 episode reward: total was 24.220000. running mean: -51.799073\n",
      "ep 43: ep_len:595 episode reward: total was -9.930000. running mean: -51.380382\n",
      "ep 43: ep_len:500 episode reward: total was 7.480000. running mean: -50.791778\n",
      "ep 43: ep_len:500 episode reward: total was 18.360000. running mean: -50.100261\n",
      "ep 43: ep_len:1150 episode reward: total was 12.970000. running mean: -49.469558\n",
      "ep 43: ep_len:500 episode reward: total was 14.210000. running mean: -48.832763\n",
      "ep 43: ep_len:500 episode reward: total was 14.210000. running mean: -48.202335\n",
      "ep 43: ep_len:800 episode reward: total was -14.420000. running mean: -47.864512\n",
      "ep 43: ep_len:505 episode reward: total was 17.810000. running mean: -47.207766\n",
      "ep 43: ep_len:1050 episode reward: total was 13.020000. running mean: -46.605489\n",
      "ep 43: ep_len:845 episode reward: total was -17.550000. running mean: -46.314934\n",
      "ep 43: ep_len:500 episode reward: total was 28.270000. running mean: -45.569085\n",
      "ep 43: ep_len:825 episode reward: total was 0.780000. running mean: -45.105594\n",
      "ep 43: ep_len:655 episode reward: total was 20.530000. running mean: -44.449238\n",
      "ep 43: ep_len:585 episode reward: total was -9.500000. running mean: -44.099745\n",
      "ep 43: ep_len:710 episode reward: total was 33.360000. running mean: -43.325148\n",
      "ep 43: ep_len:1855 episode reward: total was -130.650000. running mean: -44.198396\n",
      "ep 43: ep_len:237 episode reward: total was 14.500000. running mean: -43.611412\n",
      "ep 43: ep_len:1085 episode reward: total was -26.460000. running mean: -43.439898\n",
      "ep 43: ep_len:1660 episode reward: total was -207.820000. running mean: -45.083699\n",
      "ep 43: ep_len:490 episode reward: total was 21.790000. running mean: -44.414962\n",
      "ep 43: ep_len:905 episode reward: total was -3.510000. running mean: -44.005913\n",
      "ep 43: ep_len:500 episode reward: total was 4.200000. running mean: -43.523854\n",
      "ep 43: ep_len:635 episode reward: total was 33.070000. running mean: -42.757915\n",
      "ep 43: ep_len:680 episode reward: total was -1.720000. running mean: -42.347536\n",
      "ep 43: ep_len:500 episode reward: total was 17.250000. running mean: -41.751561\n",
      "ep 43: ep_len:750 episode reward: total was 9.950000. running mean: -41.234545\n",
      "ep 43: ep_len:500 episode reward: total was 28.730000. running mean: -40.534900\n",
      "ep 43: ep_len:500 episode reward: total was 7.720000. running mean: -40.052351\n",
      "ep 43: ep_len:610 episode reward: total was 14.400000. running mean: -39.507827\n",
      "ep 43: ep_len:500 episode reward: total was -16.220000. running mean: -39.274949\n",
      "ep 43: ep_len:845 episode reward: total was 14.490000. running mean: -38.737299\n",
      "ep 43: ep_len:595 episode reward: total was -4.920000. running mean: -38.399126\n",
      "ep 43: ep_len:500 episode reward: total was 34.760000. running mean: -37.667535\n",
      "ep 43: ep_len:500 episode reward: total was 11.580000. running mean: -37.175060\n",
      "ep 43: ep_len:500 episode reward: total was -9.820000. running mean: -36.901509\n",
      "ep 43: ep_len:284 episode reward: total was 28.000000. running mean: -36.252494\n",
      "ep 43: ep_len:500 episode reward: total was 4.350000. running mean: -35.846469\n",
      "ep 43: ep_len:635 episode reward: total was 2.940000. running mean: -35.458604\n",
      "ep 43: ep_len:500 episode reward: total was 24.810000. running mean: -34.855918\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 43: ep_len:500 episode reward: total was 17.250000. running mean: -34.334859\n",
      "ep 43: ep_len:500 episode reward: total was 48.500000. running mean: -33.506511\n",
      "ep 43: ep_len:685 episode reward: total was -1.710000. running mean: -33.188545\n",
      "ep 43: ep_len:990 episode reward: total was -10.550000. running mean: -32.962160\n",
      "ep 43: ep_len:520 episode reward: total was 5.870000. running mean: -32.573838\n",
      "ep 43: ep_len:515 episode reward: total was -56.590000. running mean: -32.814000\n",
      "ep 43: ep_len:1835 episode reward: total was -174.590000. running mean: -34.231760\n",
      "ep 43: ep_len:500 episode reward: total was 20.860000. running mean: -33.680842\n",
      "ep 43: ep_len:745 episode reward: total was -10.680000. running mean: -33.450834\n",
      "ep 43: ep_len:550 episode reward: total was 34.310000. running mean: -32.773226\n",
      "ep 43: ep_len:915 episode reward: total was 11.600000. running mean: -32.329493\n",
      "ep 43: ep_len:545 episode reward: total was 13.450000. running mean: -31.871698\n",
      "ep 43: ep_len:1225 episode reward: total was 14.050000. running mean: -31.412481\n",
      "ep 43: ep_len:720 episode reward: total was -17.800000. running mean: -31.276357\n",
      "ep 43: ep_len:590 episode reward: total was -8.970000. running mean: -31.053293\n",
      "ep 43: ep_len:226 episode reward: total was 19.500000. running mean: -30.547760\n",
      "ep 43: ep_len:500 episode reward: total was 31.360000. running mean: -29.928683\n",
      "ep 43: ep_len:500 episode reward: total was 21.720000. running mean: -29.412196\n",
      "ep 43: ep_len:1130 episode reward: total was -49.300000. running mean: -29.611074\n",
      "ep 43: ep_len:615 episode reward: total was -5.890000. running mean: -29.373863\n",
      "ep 43: ep_len:500 episode reward: total was -18.270000. running mean: -29.262824\n",
      "ep 43: ep_len:725 episode reward: total was -29.390000. running mean: -29.264096\n",
      "ep 43: ep_len:770 episode reward: total was -1.540000. running mean: -28.986855\n",
      "ep 43: ep_len:192 episode reward: total was 19.000000. running mean: -28.506987\n",
      "ep 43: ep_len:705 episode reward: total was 8.260000. running mean: -28.139317\n",
      "ep 43: ep_len:685 episode reward: total was -1.710000. running mean: -27.875024\n",
      "ep 43: ep_len:1111 episode reward: total was -116.990000. running mean: -28.766173\n",
      "ep 43: ep_len:565 episode reward: total was 16.890000. running mean: -28.309612\n",
      "ep 43: ep_len:645 episode reward: total was 4.400000. running mean: -27.982515\n",
      "ep 43: ep_len:500 episode reward: total was -0.640000. running mean: -27.709090\n",
      "ep 43: ep_len:2185 episode reward: total was -122.620000. running mean: -28.658199\n",
      "ep 43: ep_len:500 episode reward: total was -32.160000. running mean: -28.693217\n",
      "ep 43: ep_len:660 episode reward: total was 0.260000. running mean: -28.403685\n",
      "ep 43: ep_len:500 episode reward: total was 5.220000. running mean: -28.067448\n",
      "ep 43: ep_len:985 episode reward: total was 2.710000. running mean: -27.759674\n",
      "ep 43: ep_len:720 episode reward: total was 12.460000. running mean: -27.357477\n",
      "ep 43: ep_len:252 episode reward: total was 20.500000. running mean: -26.878902\n",
      "ep 43: ep_len:500 episode reward: total was 12.350000. running mean: -26.486613\n",
      "ep 43: ep_len:685 episode reward: total was 8.100000. running mean: -26.140747\n",
      "ep 43: ep_len:500 episode reward: total was 6.100000. running mean: -25.818340\n",
      "ep 43: ep_len:805 episode reward: total was -93.380000. running mean: -26.493956\n",
      "ep 43: ep_len:500 episode reward: total was 34.760000. running mean: -25.881417\n",
      "ep 43: ep_len:500 episode reward: total was -1.370000. running mean: -25.636303\n",
      "ep 43: ep_len:500 episode reward: total was 7.750000. running mean: -25.302440\n",
      "ep 43: ep_len:565 episode reward: total was -12.050000. running mean: -25.169915\n",
      "ep 43: ep_len:500 episode reward: total was 16.820000. running mean: -24.750016\n",
      "ep 43: ep_len:500 episode reward: total was 22.330000. running mean: -24.279216\n",
      "ep 43: ep_len:500 episode reward: total was 8.230000. running mean: -23.954124\n",
      "ep 43: ep_len:870 episode reward: total was 17.510000. running mean: -23.539483\n",
      "ep 43: ep_len:940 episode reward: total was 34.910000. running mean: -22.954988\n",
      "ep 43: ep_len:500 episode reward: total was -2.750000. running mean: -22.752938\n",
      "ep 43: ep_len:665 episode reward: total was -13.840000. running mean: -22.663808\n",
      "ep 43: ep_len:654 episode reward: total was -64.300000. running mean: -23.080170\n",
      "ep 43: ep_len:680 episode reward: total was -49.190000. running mean: -23.341269\n",
      "ep 43: ep_len:500 episode reward: total was 24.750000. running mean: -22.860356\n",
      "ep 43: ep_len:505 episode reward: total was -35.400000. running mean: -22.985752\n",
      "ep 43: ep_len:515 episode reward: total was -1.040000. running mean: -22.766295\n",
      "ep 43: ep_len:800 episode reward: total was 10.630000. running mean: -22.432332\n",
      "ep 43: ep_len:500 episode reward: total was 20.250000. running mean: -22.005509\n",
      "ep 43: ep_len:139 episode reward: total was 13.500000. running mean: -21.650454\n",
      "ep 43: ep_len:600 episode reward: total was -0.870000. running mean: -21.442649\n",
      "ep 43: ep_len:565 episode reward: total was 26.350000. running mean: -20.964723\n",
      "ep 43: ep_len:775 episode reward: total was -17.690000. running mean: -20.931975\n",
      "ep 43: ep_len:500 episode reward: total was 33.750000. running mean: -20.385156\n",
      "ep 43: ep_len:825 episode reward: total was 17.560000. running mean: -20.005704\n",
      "ep 43: ep_len:825 episode reward: total was -3.450000. running mean: -19.840147\n",
      "ep 43: ep_len:740 episode reward: total was -13.720000. running mean: -19.778945\n",
      "ep 43: ep_len:540 episode reward: total was 0.910000. running mean: -19.572056\n",
      "ep 43: ep_len:1159 episode reward: total was -15.460000. running mean: -19.530935\n",
      "ep 43: ep_len:880 episode reward: total was 8.500000. running mean: -19.250626\n",
      "ep 43: ep_len:500 episode reward: total was -8.720000. running mean: -19.145320\n",
      "ep 43: ep_len:1958 episode reward: total was -367.800000. running mean: -22.631867\n",
      "ep 43: ep_len:660 episode reward: total was 0.620000. running mean: -22.399348\n",
      "ep 43: ep_len:725 episode reward: total was 3.420000. running mean: -22.141154\n",
      "ep 43: ep_len:500 episode reward: total was 48.500000. running mean: -21.434743\n",
      "ep 43: ep_len:500 episode reward: total was 9.470000. running mean: -21.125696\n",
      "ep 43: ep_len:865 episode reward: total was -2.080000. running mean: -20.935239\n",
      "ep 43: ep_len:500 episode reward: total was 21.810000. running mean: -20.507786\n",
      "ep 43: ep_len:880 episode reward: total was -9.400000. running mean: -20.396708\n",
      "ep 43: ep_len:1677 episode reward: total was -279.510000. running mean: -22.987841\n",
      "ep 43: ep_len:279 episode reward: total was 21.500000. running mean: -22.542963\n",
      "ep 43: ep_len:685 episode reward: total was -7.350000. running mean: -22.391033\n",
      "ep 43: ep_len:500 episode reward: total was -3.910000. running mean: -22.206223\n",
      "ep 43: ep_len:1900 episode reward: total was -123.510000. running mean: -23.219261\n",
      "ep 43: ep_len:1430 episode reward: total was -66.880000. running mean: -23.655868\n",
      "ep 43: ep_len:500 episode reward: total was 7.450000. running mean: -23.344809\n",
      "ep 43: ep_len:500 episode reward: total was -15.510000. running mean: -23.266461\n",
      "ep 43: ep_len:1085 episode reward: total was -163.540000. running mean: -24.669197\n",
      "ep 43: ep_len:2810 episode reward: total was -471.150000. running mean: -29.134005\n",
      "ep 43: ep_len:500 episode reward: total was 21.780000. running mean: -28.624865\n",
      "ep 43: ep_len:500 episode reward: total was 27.350000. running mean: -28.065116\n",
      "ep 43: ep_len:1530 episode reward: total was -31.970000. running mean: -28.104165\n",
      "ep 43: ep_len:520 episode reward: total was -10.120000. running mean: -27.924323\n",
      "ep 43: ep_len:500 episode reward: total was 0.340000. running mean: -27.641680\n",
      "ep 43: ep_len:112 episode reward: total was 11.000000. running mean: -27.255263\n",
      "ep 43: ep_len:209 episode reward: total was 19.000000. running mean: -26.792711\n",
      "ep 43: ep_len:500 episode reward: total was 8.000000. running mean: -26.444783\n",
      "ep 43: ep_len:278 episode reward: total was 28.000000. running mean: -25.900336\n",
      "ep 43: ep_len:570 episode reward: total was 20.600000. running mean: -25.435332\n",
      "ep 43: ep_len:955 episode reward: total was 4.870000. running mean: -25.132279\n",
      "ep 43: ep_len:500 episode reward: total was 12.260000. running mean: -24.758356\n",
      "ep 43: ep_len:262 episode reward: total was 26.000000. running mean: -24.250773\n",
      "ep 43: ep_len:500 episode reward: total was 28.790000. running mean: -23.720365\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 43: ep_len:775 episode reward: total was -20.360000. running mean: -23.686761\n",
      "ep 43: ep_len:500 episode reward: total was 48.500000. running mean: -22.964894\n",
      "ep 43: ep_len:500 episode reward: total was 11.180000. running mean: -22.623445\n",
      "ep 43: ep_len:500 episode reward: total was -2.530000. running mean: -22.422510\n",
      "ep 43: ep_len:1139 episode reward: total was -106.140000. running mean: -23.259685\n",
      "ep 43: ep_len:500 episode reward: total was 19.480000. running mean: -22.832288\n",
      "ep 43: ep_len:870 episode reward: total was 20.630000. running mean: -22.397665\n",
      "ep 43: ep_len:950 episode reward: total was 10.370000. running mean: -22.069989\n",
      "ep 43: ep_len:705 episode reward: total was -0.780000. running mean: -21.857089\n",
      "ep 43: ep_len:555 episode reward: total was -9.010000. running mean: -21.728618\n",
      "ep 43: ep_len:500 episode reward: total was 28.270000. running mean: -21.228632\n",
      "ep 43: ep_len:500 episode reward: total was 5.180000. running mean: -20.964545\n",
      "ep 43: ep_len:1615 episode reward: total was -122.060000. running mean: -21.975500\n",
      "ep 43: ep_len:705 episode reward: total was -6.720000. running mean: -21.822945\n",
      "ep 43: ep_len:500 episode reward: total was 17.770000. running mean: -21.427016\n",
      "ep 43: ep_len:487 episode reward: total was 32.220000. running mean: -20.890545\n",
      "ep 43: ep_len:600 episode reward: total was 18.590000. running mean: -20.495740\n",
      "ep 43: ep_len:409 episode reward: total was 25.500000. running mean: -20.035783\n",
      "ep 43: ep_len:500 episode reward: total was -11.120000. running mean: -19.946625\n",
      "ep 43: ep_len:510 episode reward: total was -1.220000. running mean: -19.759358\n",
      "ep 43: ep_len:500 episode reward: total was 7.050000. running mean: -19.491265\n",
      "ep 43: ep_len:500 episode reward: total was -18.810000. running mean: -19.484452\n",
      "ep 43: ep_len:690 episode reward: total was 2.340000. running mean: -19.266208\n",
      "ep 43: ep_len:1710 episode reward: total was -120.860000. running mean: -20.282146\n",
      "ep 43: ep_len:515 episode reward: total was -8.190000. running mean: -20.161224\n",
      "ep 43: ep_len:500 episode reward: total was 13.240000. running mean: -19.827212\n",
      "ep 43: ep_len:725 episode reward: total was -13.750000. running mean: -19.766440\n",
      "ep 43: ep_len:500 episode reward: total was -49.090000. running mean: -20.059675\n",
      "ep 43: ep_len:1452 episode reward: total was -185.010000. running mean: -21.709179\n",
      "ep 43: ep_len:500 episode reward: total was -19.790000. running mean: -21.689987\n",
      "ep 43: ep_len:520 episode reward: total was -50.520000. running mean: -21.978287\n",
      "ep 43: ep_len:1315 episode reward: total was -199.790000. running mean: -23.756404\n",
      "ep 43: ep_len:500 episode reward: total was 7.230000. running mean: -23.446540\n",
      "ep 43: ep_len:500 episode reward: total was -5.000000. running mean: -23.262075\n",
      "ep 43: ep_len:530 episode reward: total was -4.220000. running mean: -23.071654\n",
      "ep 43: ep_len:660 episode reward: total was 4.890000. running mean: -22.792037\n",
      "ep 43: ep_len:500 episode reward: total was 0.340000. running mean: -22.560717\n",
      "ep 43: ep_len:500 episode reward: total was -12.260000. running mean: -22.457710\n",
      "ep 43: ep_len:710 episode reward: total was -10.750000. running mean: -22.340633\n",
      "ep 43: ep_len:205 episode reward: total was 19.000000. running mean: -21.927226\n",
      "ep 43: ep_len:880 episode reward: total was 8.480000. running mean: -21.623154\n",
      "ep 43: ep_len:219 episode reward: total was 20.000000. running mean: -21.206923\n",
      "ep 43: ep_len:2170 episode reward: total was -326.990000. running mean: -24.264753\n",
      "ep 43: ep_len:555 episode reward: total was 21.060000. running mean: -23.811506\n",
      "ep 43: ep_len:1919 episode reward: total was -326.470000. running mean: -26.838091\n",
      "ep 43: ep_len:500 episode reward: total was -3.500000. running mean: -26.604710\n",
      "ep 43: ep_len:825 episode reward: total was -9.130000. running mean: -26.429963\n",
      "ep 43: ep_len:725 episode reward: total was -9.710000. running mean: -26.262763\n",
      "ep 43: ep_len:790 episode reward: total was -1.250000. running mean: -26.012636\n",
      "ep 43: ep_len:910 episode reward: total was 12.670000. running mean: -25.625809\n",
      "ep 43: ep_len:193 episode reward: total was 19.000000. running mean: -25.179551\n",
      "ep 43: ep_len:615 episode reward: total was -22.050000. running mean: -25.148256\n",
      "ep 43: ep_len:975 episode reward: total was 24.020000. running mean: -24.656573\n",
      "ep 43: ep_len:700 episode reward: total was 22.390000. running mean: -24.186107\n",
      "ep 43: ep_len:500 episode reward: total was 23.490000. running mean: -23.709346\n",
      "ep 43: ep_len:815 episode reward: total was -12.130000. running mean: -23.593553\n",
      "ep 43: ep_len:1422 episode reward: total was -230.580000. running mean: -25.663417\n",
      "ep 43: ep_len:505 episode reward: total was 3.380000. running mean: -25.372983\n",
      "ep 43: ep_len:500 episode reward: total was 22.020000. running mean: -24.899053\n",
      "ep 43: ep_len:930 episode reward: total was 2.810000. running mean: -24.621963\n",
      "ep 43: ep_len:545 episode reward: total was -11.080000. running mean: -24.486543\n",
      "ep 43: ep_len:500 episode reward: total was 15.040000. running mean: -24.091278\n",
      "ep 43: ep_len:261 episode reward: total was 26.000000. running mean: -23.590365\n",
      "ep 43: ep_len:500 episode reward: total was 28.800000. running mean: -23.066461\n",
      "ep 43: ep_len:610 episode reward: total was 17.560000. running mean: -22.660197\n",
      "ep 43: ep_len:680 episode reward: total was -36.060000. running mean: -22.794195\n",
      "ep 43: ep_len:500 episode reward: total was 7.790000. running mean: -22.488353\n",
      "ep 43: ep_len:570 episode reward: total was -54.460000. running mean: -22.808069\n",
      "ep 43: ep_len:500 episode reward: total was 8.190000. running mean: -22.498088\n",
      "ep 43: ep_len:525 episode reward: total was 9.490000. running mean: -22.178208\n",
      "ep 43: ep_len:1065 episode reward: total was 16.300000. running mean: -21.793425\n",
      "ep 43: ep_len:565 episode reward: total was 20.960000. running mean: -21.365891\n",
      "ep 43: ep_len:870 episode reward: total was 20.130000. running mean: -20.950932\n",
      "ep 43: ep_len:610 episode reward: total was -38.220000. running mean: -21.123623\n",
      "ep 43: ep_len:515 episode reward: total was 22.790000. running mean: -20.684487\n",
      "ep 43: ep_len:705 episode reward: total was 20.780000. running mean: -20.269842\n",
      "ep 43: ep_len:500 episode reward: total was 6.320000. running mean: -20.003943\n",
      "ep 43: ep_len:500 episode reward: total was 31.760000. running mean: -19.486304\n",
      "ep 43: ep_len:500 episode reward: total was 29.710000. running mean: -18.994341\n",
      "ep 43: ep_len:745 episode reward: total was -15.210000. running mean: -18.956498\n",
      "ep 43: ep_len:500 episode reward: total was -1.190000. running mean: -18.778833\n",
      "ep 43: ep_len:930 episode reward: total was -26.820000. running mean: -18.859244\n",
      "ep 43: ep_len:500 episode reward: total was 21.720000. running mean: -18.453452\n",
      "ep 43: ep_len:555 episode reward: total was -47.420000. running mean: -18.743117\n",
      "ep 43: ep_len:500 episode reward: total was 2.460000. running mean: -18.531086\n",
      "ep 43: ep_len:975 episode reward: total was 6.320000. running mean: -18.282575\n",
      "ep 43: ep_len:500 episode reward: total was 21.510000. running mean: -17.884650\n",
      "ep 43: ep_len:500 episode reward: total was 30.690000. running mean: -17.398903\n",
      "ep 43: ep_len:500 episode reward: total was 50.000000. running mean: -16.724914\n",
      "ep 43: ep_len:1015 episode reward: total was 16.320000. running mean: -16.394465\n",
      "ep 43: ep_len:500 episode reward: total was 12.620000. running mean: -16.104320\n",
      "ep 43: ep_len:500 episode reward: total was -9.670000. running mean: -16.039977\n",
      "ep 43: ep_len:905 episode reward: total was 11.640000. running mean: -15.763177\n",
      "ep 43: ep_len:575 episode reward: total was 27.410000. running mean: -15.331445\n",
      "ep 43: ep_len:167 episode reward: total was 16.500000. running mean: -15.013131\n",
      "ep 43: ep_len:192 episode reward: total was 19.000000. running mean: -14.673000\n",
      "ep 43: ep_len:970 episode reward: total was 3.640000. running mean: -14.489870\n",
      "ep 43: ep_len:760 episode reward: total was 26.080000. running mean: -14.084171\n",
      "ep 43: ep_len:500 episode reward: total was -51.080000. running mean: -14.454129\n",
      "ep 43: ep_len:390 episode reward: total was 3.680000. running mean: -14.272788\n",
      "ep 43: ep_len:500 episode reward: total was 30.750000. running mean: -13.822560\n",
      "ep 43: ep_len:605 episode reward: total was -30.150000. running mean: -13.985835\n",
      "ep 43: ep_len:1120 episode reward: total was -178.580000. running mean: -15.631776\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 43: ep_len:500 episode reward: total was -10.160000. running mean: -15.577058\n",
      "ep 43: ep_len:1438 episode reward: total was -45.130000. running mean: -15.872588\n",
      "ep 43: ep_len:625 episode reward: total was -4.860000. running mean: -15.762462\n",
      "ep 43: ep_len:635 episode reward: total was -62.410000. running mean: -16.228937\n",
      "ep 43: ep_len:500 episode reward: total was -9.480000. running mean: -16.161448\n",
      "ep 43: ep_len:500 episode reward: total was 21.290000. running mean: -15.786934\n",
      "ep 43: ep_len:500 episode reward: total was 16.270000. running mean: -15.466364\n",
      "ep 43: ep_len:560 episode reward: total was -4.960000. running mean: -15.361301\n",
      "ep 43: ep_len:990 episode reward: total was 7.360000. running mean: -15.134088\n",
      "ep 43: ep_len:500 episode reward: total was 16.300000. running mean: -14.819747\n",
      "ep 43: ep_len:163 episode reward: total was 16.000000. running mean: -14.511549\n",
      "ep 43: ep_len:500 episode reward: total was 19.420000. running mean: -14.172234\n",
      "ep 43: ep_len:620 episode reward: total was -0.830000. running mean: -14.038811\n",
      "ep 43: ep_len:720 episode reward: total was 7.100000. running mean: -13.827423\n",
      "ep 43: ep_len:226 episode reward: total was 21.000000. running mean: -13.479149\n",
      "ep 43: ep_len:500 episode reward: total was 0.240000. running mean: -13.341958\n",
      "ep 43: ep_len:500 episode reward: total was 7.840000. running mean: -13.130138\n",
      "ep 43: ep_len:500 episode reward: total was 48.500000. running mean: -12.513837\n",
      "ep 43: ep_len:500 episode reward: total was 15.780000. running mean: -12.230898\n",
      "ep 43: ep_len:164 episode reward: total was 16.000000. running mean: -11.948589\n",
      "ep 43: ep_len:500 episode reward: total was -0.760000. running mean: -11.836703\n",
      "ep 43: ep_len:500 episode reward: total was 26.460000. running mean: -11.453736\n",
      "ep 43: ep_len:500 episode reward: total was 10.820000. running mean: -11.230999\n",
      "ep 43: ep_len:695 episode reward: total was -10.290000. running mean: -11.221589\n",
      "ep 43: ep_len:500 episode reward: total was -13.150000. running mean: -11.240873\n",
      "ep 43: ep_len:1175 episode reward: total was -138.090000. running mean: -12.509364\n",
      "ep 43: ep_len:925 episode reward: total was 27.650000. running mean: -12.107771\n",
      "ep 43: ep_len:505 episode reward: total was -4.090000. running mean: -12.027593\n",
      "ep 43: ep_len:540 episode reward: total was -3.010000. running mean: -11.937417\n",
      "ep 43: ep_len:383 episode reward: total was 18.000000. running mean: -11.638043\n",
      "ep 43: ep_len:262 episode reward: total was 24.500000. running mean: -11.276662\n",
      "ep 43: ep_len:635 episode reward: total was -18.980000. running mean: -11.353696\n",
      "ep 43: ep_len:1140 episode reward: total was -49.460000. running mean: -11.734759\n",
      "ep 43: ep_len:500 episode reward: total was -0.380000. running mean: -11.621211\n",
      "ep 43: ep_len:500 episode reward: total was 10.480000. running mean: -11.400199\n",
      "ep 43: ep_len:750 episode reward: total was -10.670000. running mean: -11.392897\n",
      "ep 43: ep_len:1240 episode reward: total was -7.860000. running mean: -11.357568\n",
      "ep 43: ep_len:1600 episode reward: total was -101.860000. running mean: -12.262593\n",
      "ep 43: ep_len:985 episode reward: total was 16.320000. running mean: -11.976767\n",
      "ep 43: ep_len:770 episode reward: total was -20.730000. running mean: -12.064299\n",
      "ep 43: ep_len:500 episode reward: total was 9.190000. running mean: -11.851756\n",
      "ep 43: ep_len:715 episode reward: total was -10.490000. running mean: -11.838138\n",
      "ep 43: ep_len:905 episode reward: total was 8.350000. running mean: -11.636257\n",
      "ep 43: ep_len:262 episode reward: total was 25.000000. running mean: -11.269894\n",
      "ep 43: ep_len:960 episode reward: total was -22.340000. running mean: -11.380595\n",
      "ep 43: ep_len:500 episode reward: total was 23.890000. running mean: -11.027890\n",
      "ep 43: ep_len:500 episode reward: total was -16.400000. running mean: -11.081611\n",
      "ep 43: ep_len:500 episode reward: total was 6.710000. running mean: -10.903695\n",
      "ep 43: ep_len:123 episode reward: total was 12.000000. running mean: -10.674658\n",
      "ep 43: ep_len:500 episode reward: total was 14.550000. running mean: -10.422411\n",
      "ep 43: ep_len:755 episode reward: total was -45.000000. running mean: -10.768187\n",
      "ep 43: ep_len:1408 episode reward: total was -197.200000. running mean: -12.632505\n",
      "ep 43: ep_len:865 episode reward: total was -18.000000. running mean: -12.686180\n",
      "ep 43: ep_len:565 episode reward: total was -9.020000. running mean: -12.649518\n",
      "ep 43: ep_len:177 episode reward: total was 17.500000. running mean: -12.348023\n",
      "ep 43: ep_len:384 episode reward: total was 2.000000. running mean: -12.204543\n",
      "ep 43: ep_len:840 episode reward: total was -12.200000. running mean: -12.204497\n",
      "ep 43: ep_len:760 episode reward: total was 2.440000. running mean: -12.058052\n",
      "ep 43: ep_len:505 episode reward: total was 25.770000. running mean: -11.679772\n",
      "ep 43: ep_len:500 episode reward: total was 24.840000. running mean: -11.314574\n",
      "ep 43: ep_len:635 episode reward: total was -24.030000. running mean: -11.441728\n",
      "ep 43: ep_len:500 episode reward: total was 30.200000. running mean: -11.025311\n",
      "ep 43: ep_len:540 episode reward: total was 5.240000. running mean: -10.862658\n",
      "ep 43: ep_len:785 episode reward: total was -24.710000. running mean: -11.001131\n",
      "ep 43: ep_len:790 episode reward: total was -28.740000. running mean: -11.178520\n",
      "ep 43: ep_len:880 episode reward: total was 24.930000. running mean: -10.817435\n",
      "ep 43: ep_len:500 episode reward: total was 5.340000. running mean: -10.655861\n",
      "ep 43: ep_len:500 episode reward: total was -6.610000. running mean: -10.615402\n",
      "ep 43: ep_len:790 episode reward: total was -22.710000. running mean: -10.736348\n",
      "ep 43: ep_len:500 episode reward: total was -12.690000. running mean: -10.755884\n",
      "ep 43: ep_len:500 episode reward: total was 32.710000. running mean: -10.321226\n",
      "ep 43: ep_len:665 episode reward: total was -35.350000. running mean: -10.571513\n",
      "ep 43: ep_len:825 episode reward: total was 0.880000. running mean: -10.456998\n",
      "ep 43: ep_len:2500 episode reward: total was -417.410000. running mean: -14.526528\n",
      "ep 43: ep_len:1005 episode reward: total was -23.260000. running mean: -14.613863\n",
      "ep 43: ep_len:535 episode reward: total was -1.700000. running mean: -14.484724\n",
      "ep 43: ep_len:660 episode reward: total was -15.870000. running mean: -14.498577\n",
      "ep 43: ep_len:212 episode reward: total was 21.000000. running mean: -14.143591\n",
      "ep 43: ep_len:715 episode reward: total was -7.210000. running mean: -14.074255\n",
      "ep 43: ep_len:765 episode reward: total was 8.250000. running mean: -13.851013\n",
      "ep 43: ep_len:750 episode reward: total was -0.720000. running mean: -13.719703\n",
      "ep 43: ep_len:500 episode reward: total was 21.720000. running mean: -13.365306\n",
      "ep 43: ep_len:164 episode reward: total was 16.000000. running mean: -13.071653\n",
      "ep 43: ep_len:500 episode reward: total was 9.280000. running mean: -12.848136\n",
      "ep 43: ep_len:500 episode reward: total was 7.290000. running mean: -12.646755\n",
      "ep 43: ep_len:297 episode reward: total was 28.000000. running mean: -12.240287\n",
      "ep 43: ep_len:274 episode reward: total was 15.740000. running mean: -11.960484\n",
      "ep 43: ep_len:200 episode reward: total was 18.500000. running mean: -11.655879\n",
      "ep 43: ep_len:1060 episode reward: total was -103.980000. running mean: -12.579121\n",
      "ep 43: ep_len:600 episode reward: total was -20.760000. running mean: -12.660929\n",
      "ep 43: ep_len:5670 episode reward: total was -1030.050000. running mean: -22.834820\n",
      "ep 43: ep_len:244 episode reward: total was 24.500000. running mean: -22.361472\n",
      "ep 43: ep_len:535 episode reward: total was -24.230000. running mean: -22.380157\n",
      "ep 43: ep_len:690 episode reward: total was 1.330000. running mean: -22.143056\n",
      "ep 43: ep_len:775 episode reward: total was -57.080000. running mean: -22.492425\n",
      "ep 43: ep_len:505 episode reward: total was 17.350000. running mean: -22.094001\n",
      "ep 43: ep_len:693 episode reward: total was -20.870000. running mean: -22.081761\n",
      "ep 43: ep_len:500 episode reward: total was -1.260000. running mean: -21.873543\n",
      "ep 43: ep_len:595 episode reward: total was -85.380000. running mean: -22.508608\n",
      "ep 43: ep_len:1168 episode reward: total was -173.440000. running mean: -24.017922\n",
      "ep 43: ep_len:2705 episode reward: total was -515.800000. running mean: -28.935743\n",
      "ep 43: ep_len:500 episode reward: total was 22.330000. running mean: -28.423085\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 43: ep_len:725 episode reward: total was -2.640000. running mean: -28.165254\n",
      "ep 43: ep_len:695 episode reward: total was 5.510000. running mean: -27.828502\n",
      "ep 43: ep_len:740 episode reward: total was 11.840000. running mean: -27.431817\n",
      "ep 43: ep_len:535 episode reward: total was -19.180000. running mean: -27.349299\n",
      "ep 43: ep_len:740 episode reward: total was -11.700000. running mean: -27.192806\n",
      "ep 43: ep_len:540 episode reward: total was -32.900000. running mean: -27.249877\n",
      "ep 43: ep_len:675 episode reward: total was -2.740000. running mean: -27.004779\n",
      "ep 43: ep_len:500 episode reward: total was 15.190000. running mean: -26.582831\n",
      "ep 43: ep_len:500 episode reward: total was 8.370000. running mean: -26.233303\n",
      "ep 43: ep_len:520 episode reward: total was 2.990000. running mean: -25.941070\n",
      "ep 43: ep_len:500 episode reward: total was 5.740000. running mean: -25.624259\n",
      "ep 43: ep_len:184 episode reward: total was 18.000000. running mean: -25.188016\n",
      "ep 43: ep_len:500 episode reward: total was 8.190000. running mean: -24.854236\n",
      "ep 43: ep_len:1420 episode reward: total was -154.770000. running mean: -26.153394\n",
      "ep 43: ep_len:500 episode reward: total was -8.110000. running mean: -25.972960\n",
      "ep 43: ep_len:560 episode reward: total was -10.040000. running mean: -25.813630\n",
      "ep 43: ep_len:685 episode reward: total was -16.830000. running mean: -25.723794\n",
      "ep 43: ep_len:1070 episode reward: total was -48.060000. running mean: -25.947156\n",
      "ep 43: ep_len:980 episode reward: total was -91.010000. running mean: -26.597784\n",
      "ep 43: ep_len:255 episode reward: total was 24.000000. running mean: -26.091807\n",
      "ep 43: ep_len:236 episode reward: total was 22.000000. running mean: -25.610889\n",
      "ep 43: ep_len:500 episode reward: total was 20.310000. running mean: -25.151680\n",
      "ep 43: ep_len:500 episode reward: total was 10.140000. running mean: -24.798763\n",
      "ep 43: ep_len:500 episode reward: total was 15.840000. running mean: -24.392375\n",
      "ep 43: ep_len:735 episode reward: total was -28.880000. running mean: -24.437251\n",
      "ep 43: ep_len:500 episode reward: total was 47.000000. running mean: -23.722879\n",
      "ep 43: ep_len:700 episode reward: total was -29.960000. running mean: -23.785250\n",
      "ep 43: ep_len:2605 episode reward: total was -372.580000. running mean: -27.273198\n",
      "ep 43: ep_len:500 episode reward: total was 10.330000. running mean: -26.897166\n",
      "ep 43: ep_len:830 episode reward: total was -1.630000. running mean: -26.644494\n",
      "ep 43: ep_len:1535 episode reward: total was -186.340000. running mean: -28.241449\n",
      "ep 43: ep_len:1303 episode reward: total was -257.000000. running mean: -30.529035\n",
      "ep 43: ep_len:725 episode reward: total was -50.110000. running mean: -30.724844\n",
      "ep 43: ep_len:670 episode reward: total was -24.970000. running mean: -30.667296\n",
      "ep 43: ep_len:1100 episode reward: total was -75.100000. running mean: -31.111623\n",
      "ep 43: ep_len:780 episode reward: total was 19.190000. running mean: -30.608607\n",
      "ep 43: ep_len:1915 episode reward: total was -78.310000. running mean: -31.085621\n",
      "ep 43: ep_len:190 episode reward: total was 18.000000. running mean: -30.594764\n",
      "ep 43: ep_len:500 episode reward: total was 12.290000. running mean: -30.165917\n",
      "ep 43: ep_len:500 episode reward: total was 47.000000. running mean: -29.394258\n",
      "ep 43: ep_len:535 episode reward: total was -14.130000. running mean: -29.241615\n",
      "ep 43: ep_len:770 episode reward: total was -12.650000. running mean: -29.075699\n",
      "ep 43: ep_len:585 episode reward: total was 13.720000. running mean: -28.647742\n",
      "ep 43: ep_len:165 episode reward: total was 15.000000. running mean: -28.211264\n",
      "ep 43: ep_len:226 episode reward: total was 21.000000. running mean: -27.719152\n",
      "ep 43: ep_len:790 episode reward: total was -14.630000. running mean: -27.588260\n",
      "ep 43: ep_len:122 episode reward: total was 12.500000. running mean: -27.187378\n",
      "ep 43: ep_len:500 episode reward: total was 7.850000. running mean: -26.837004\n",
      "ep 43: ep_len:1005 episode reward: total was 19.770000. running mean: -26.370934\n",
      "ep 43: ep_len:500 episode reward: total was -32.650000. running mean: -26.433724\n",
      "ep 43: ep_len:500 episode reward: total was 16.670000. running mean: -26.002687\n",
      "ep 43: ep_len:835 episode reward: total was -41.290000. running mean: -26.155560\n",
      "ep 43: ep_len:500 episode reward: total was 17.610000. running mean: -25.717905\n",
      "ep 43: ep_len:293 episode reward: total was 29.000000. running mean: -25.170726\n",
      "ep 43: ep_len:1005 episode reward: total was -38.930000. running mean: -25.308318\n",
      "ep 43: ep_len:585 episode reward: total was 16.990000. running mean: -24.885335\n",
      "ep 43: ep_len:140 episode reward: total was 11.000000. running mean: -24.526482\n",
      "ep 43: ep_len:196 episode reward: total was 20.000000. running mean: -24.081217\n",
      "ep 43: ep_len:525 episode reward: total was -3.020000. running mean: -23.870605\n",
      "ep 43: ep_len:745 episode reward: total was -65.310000. running mean: -24.284999\n",
      "ep 43: ep_len:1005 episode reward: total was -23.340000. running mean: -24.275549\n",
      "ep 43: ep_len:142 episode reward: total was 11.000000. running mean: -23.922793\n",
      "ep 43: ep_len:530 episode reward: total was -17.200000. running mean: -23.855565\n",
      "ep 43: ep_len:930 episode reward: total was 16.860000. running mean: -23.448410\n",
      "ep 43: ep_len:785 episode reward: total was -16.660000. running mean: -23.380526\n",
      "ep 43: ep_len:870 episode reward: total was 6.980000. running mean: -23.076920\n",
      "ep 43: ep_len:1025 episode reward: total was -113.140000. running mean: -23.977551\n",
      "ep 43: ep_len:1505 episode reward: total was -62.720000. running mean: -24.364976\n",
      "ep 43: ep_len:500 episode reward: total was 13.240000. running mean: -23.988926\n",
      "ep 43: ep_len:349 episode reward: total was -24.590000. running mean: -23.994937\n",
      "ep 43: ep_len:1165 episode reward: total was -79.890000. running mean: -24.553887\n",
      "ep 43: ep_len:500 episode reward: total was 20.860000. running mean: -24.099748\n",
      "ep 43: ep_len:1330 episode reward: total was 9.590000. running mean: -23.762851\n",
      "ep 43: ep_len:500 episode reward: total was -16.280000. running mean: -23.688022\n",
      "ep 43: ep_len:500 episode reward: total was 0.800000. running mean: -23.443142\n",
      "ep 43: ep_len:845 episode reward: total was -15.370000. running mean: -23.362411\n",
      "ep 43: ep_len:856 episode reward: total was -11.220000. running mean: -23.240987\n",
      "ep 43: ep_len:510 episode reward: total was 18.830000. running mean: -22.820277\n",
      "ep 43: ep_len:900 episode reward: total was -23.580000. running mean: -22.827874\n",
      "ep 43: ep_len:1268 episode reward: total was -229.880000. running mean: -24.898395\n",
      "ep 43: ep_len:1063 episode reward: total was -135.270000. running mean: -26.002111\n",
      "ep 43: ep_len:805 episode reward: total was -17.630000. running mean: -25.918390\n",
      "ep 43: ep_len:610 episode reward: total was 15.000000. running mean: -25.509206\n",
      "ep 43: ep_len:500 episode reward: total was -7.830000. running mean: -25.332414\n",
      "ep 43: ep_len:690 episode reward: total was -23.920000. running mean: -25.318290\n",
      "ep 43: ep_len:1105 episode reward: total was 6.430000. running mean: -25.000807\n",
      "ep 43: ep_len:740 episode reward: total was -15.740000. running mean: -24.908199\n",
      "ep 43: ep_len:500 episode reward: total was 6.190000. running mean: -24.597217\n",
      "ep 43: ep_len:595 episode reward: total was -26.130000. running mean: -24.612545\n",
      "ep 43: ep_len:530 episode reward: total was -49.490000. running mean: -24.861320\n",
      "ep 43: ep_len:500 episode reward: total was 23.280000. running mean: -24.379906\n",
      "ep 43: ep_len:1244 episode reward: total was -127.840000. running mean: -25.414507\n",
      "ep 43: ep_len:730 episode reward: total was -6.150000. running mean: -25.221862\n",
      "ep 43: ep_len:500 episode reward: total was 22.760000. running mean: -24.742044\n",
      "ep 43: ep_len:720 episode reward: total was -15.560000. running mean: -24.650223\n",
      "ep 43: ep_len:500 episode reward: total was 19.330000. running mean: -24.210421\n",
      "ep 43: ep_len:585 episode reward: total was -21.100000. running mean: -24.179317\n",
      "ep 43: ep_len:500 episode reward: total was 14.770000. running mean: -23.789824\n",
      "ep 43: ep_len:610 episode reward: total was -1.340000. running mean: -23.565325\n",
      "ep 43: ep_len:500 episode reward: total was -1.620000. running mean: -23.345872\n",
      "ep 43: ep_len:780 episode reward: total was -6.570000. running mean: -23.178113\n",
      "ep 43: ep_len:710 episode reward: total was 2.290000. running mean: -22.923432\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 43: ep_len:500 episode reward: total was 11.090000. running mean: -22.583298\n",
      "ep 43: ep_len:855 episode reward: total was -14.630000. running mean: -22.503765\n",
      "ep 43: ep_len:745 episode reward: total was -12.700000. running mean: -22.405727\n",
      "ep 43: ep_len:975 episode reward: total was -21.820000. running mean: -22.399870\n",
      "ep 43: ep_len:690 episode reward: total was -13.000000. running mean: -22.305871\n",
      "ep 43: ep_len:675 episode reward: total was 23.570000. running mean: -21.847113\n",
      "ep 43: ep_len:500 episode reward: total was 11.280000. running mean: -21.515841\n",
      "ep 43: ep_len:780 episode reward: total was -2.790000. running mean: -21.328583\n",
      "ep 43: ep_len:505 episode reward: total was -7.120000. running mean: -21.186497\n",
      "ep 43: ep_len:500 episode reward: total was -2.660000. running mean: -21.001232\n",
      "ep 43: ep_len:710 episode reward: total was 24.840000. running mean: -20.542820\n",
      "ep 43: ep_len:1830 episode reward: total was -239.780000. running mean: -22.735192\n",
      "ep 43: ep_len:665 episode reward: total was 7.320000. running mean: -22.434640\n",
      "ep 43: ep_len:500 episode reward: total was 24.840000. running mean: -21.961893\n",
      "ep 43: ep_len:500 episode reward: total was 13.050000. running mean: -21.611774\n",
      "ep 43: ep_len:500 episode reward: total was 0.710000. running mean: -21.388557\n",
      "ep 43: ep_len:251 episode reward: total was 22.000000. running mean: -20.954671\n",
      "ep 43: ep_len:226 episode reward: total was 21.000000. running mean: -20.535124\n",
      "ep 43: ep_len:500 episode reward: total was 6.840000. running mean: -20.261373\n",
      "ep 43: ep_len:800 episode reward: total was -11.580000. running mean: -20.174559\n",
      "ep 43: ep_len:655 episode reward: total was -11.870000. running mean: -20.091514\n",
      "ep 43: ep_len:590 episode reward: total was -10.990000. running mean: -20.000499\n",
      "ep 43: ep_len:500 episode reward: total was -29.960000. running mean: -20.100094\n",
      "ep 43: ep_len:500 episode reward: total was -1.680000. running mean: -19.915893\n",
      "ep 43: ep_len:750 episode reward: total was -15.720000. running mean: -19.873934\n",
      "ep 43: ep_len:520 episode reward: total was -4.180000. running mean: -19.716995\n",
      "ep 43: ep_len:805 episode reward: total was -4.500000. running mean: -19.564825\n",
      "ep 43: ep_len:500 episode reward: total was 17.520000. running mean: -19.193976\n",
      "ep 43: ep_len:1160 episode reward: total was 0.540000. running mean: -18.996637\n",
      "ep 43: ep_len:670 episode reward: total was -42.140000. running mean: -19.228070\n",
      "ep 43: ep_len:685 episode reward: total was -10.770000. running mean: -19.143490\n",
      "ep 43: ep_len:467 episode reward: total was 26.790000. running mean: -18.684155\n",
      "ep 43: ep_len:500 episode reward: total was 12.910000. running mean: -18.368213\n",
      "ep 43: ep_len:570 episode reward: total was 19.220000. running mean: -17.992331\n",
      "ep 43: ep_len:745 episode reward: total was -5.630000. running mean: -17.868708\n",
      "ep 43: ep_len:770 episode reward: total was -69.180000. running mean: -18.381821\n",
      "ep 43: ep_len:500 episode reward: total was 21.260000. running mean: -17.985402\n",
      "ep 43: ep_len:500 episode reward: total was 6.050000. running mean: -17.745048\n",
      "ep 43: ep_len:1880 episode reward: total was -204.350000. running mean: -19.611098\n",
      "ep 43: ep_len:675 episode reward: total was -7.270000. running mean: -19.487687\n",
      "ep 43: ep_len:500 episode reward: total was 19.020000. running mean: -19.102610\n",
      "ep 43: ep_len:870 episode reward: total was -17.500000. running mean: -19.086584\n",
      "ep 43: ep_len:650 episode reward: total was -7.900000. running mean: -18.974718\n",
      "ep 43: ep_len:500 episode reward: total was 15.350000. running mean: -18.631471\n",
      "ep 43: ep_len:500 episode reward: total was 16.360000. running mean: -18.281556\n",
      "ep 43: ep_len:630 episode reward: total was -29.090000. running mean: -18.389641\n",
      "ep 43: ep_len:875 episode reward: total was -15.070000. running mean: -18.356444\n",
      "ep 43: ep_len:675 episode reward: total was 23.330000. running mean: -17.939580\n",
      "ep 43: ep_len:500 episode reward: total was 7.840000. running mean: -17.681784\n",
      "ep 43: ep_len:955 episode reward: total was -38.540000. running mean: -17.890366\n",
      "ep 43: ep_len:1509 episode reward: total was -223.260000. running mean: -19.944062\n",
      "ep 43: ep_len:500 episode reward: total was 2.620000. running mean: -19.718422\n",
      "ep 43: ep_len:505 episode reward: total was 3.370000. running mean: -19.487538\n",
      "ep 43: ep_len:749 episode reward: total was -54.660000. running mean: -19.839262\n",
      "ep 43: ep_len:500 episode reward: total was -3.270000. running mean: -19.673570\n",
      "ep 43: ep_len:500 episode reward: total was 1.810000. running mean: -19.458734\n",
      "ep 43: ep_len:550 episode reward: total was -8.130000. running mean: -19.345447\n",
      "ep 43: ep_len:500 episode reward: total was 17.860000. running mean: -18.973392\n",
      "ep 43: ep_len:500 episode reward: total was -30.390000. running mean: -19.087558\n",
      "ep 43: ep_len:500 episode reward: total was 17.860000. running mean: -18.718083\n",
      "ep 43: ep_len:730 episode reward: total was -7.680000. running mean: -18.607702\n",
      "ep 43: ep_len:500 episode reward: total was 22.850000. running mean: -18.193125\n",
      "ep 43: ep_len:600 episode reward: total was -16.020000. running mean: -18.171394\n",
      "ep 43: ep_len:500 episode reward: total was 13.170000. running mean: -17.857980\n",
      "ep 43: ep_len:540 episode reward: total was -11.090000. running mean: -17.790300\n",
      "ep 43: ep_len:560 episode reward: total was 8.730000. running mean: -17.525097\n",
      "ep 43: ep_len:500 episode reward: total was -6.910000. running mean: -17.418946\n",
      "ep 43: ep_len:1610 episode reward: total was -119.520000. running mean: -18.439956\n",
      "ep 43: ep_len:960 episode reward: total was -44.560000. running mean: -18.701157\n",
      "ep 43: ep_len:790 episode reward: total was -11.600000. running mean: -18.630145\n",
      "ep 43: ep_len:520 episode reward: total was 8.190000. running mean: -18.361944\n",
      "ep 43: ep_len:810 episode reward: total was -1.640000. running mean: -18.194724\n",
      "ep 43: ep_len:500 episode reward: total was 22.310000. running mean: -17.789677\n",
      "ep 43: ep_len:398 episode reward: total was -20.720000. running mean: -17.818980\n",
      "ep 43: ep_len:660 episode reward: total was 19.220000. running mean: -17.448591\n",
      "ep 43: ep_len:840 episode reward: total was 1.930000. running mean: -17.254805\n",
      "ep 43: ep_len:500 episode reward: total was -3.240000. running mean: -17.114657\n",
      "ep 43: ep_len:500 episode reward: total was 13.570000. running mean: -16.807810\n",
      "ep 43: ep_len:500 episode reward: total was 6.810000. running mean: -16.571632\n",
      "ep 43: ep_len:570 episode reward: total was -15.040000. running mean: -16.556316\n",
      "ep 43: ep_len:500 episode reward: total was 4.780000. running mean: -16.342952\n",
      "ep 43: ep_len:835 episode reward: total was 2.240000. running mean: -16.157123\n",
      "ep 43: ep_len:500 episode reward: total was 22.760000. running mean: -15.767952\n",
      "ep 43: ep_len:1000 episode reward: total was -23.620000. running mean: -15.846472\n",
      "ep 43: ep_len:703 episode reward: total was -19.880000. running mean: -15.886807\n",
      "ep 43: ep_len:820 episode reward: total was -22.130000. running mean: -15.949239\n",
      "ep 43: ep_len:735 episode reward: total was -3.140000. running mean: -15.821147\n",
      "ep 43: ep_len:670 episode reward: total was 20.670000. running mean: -15.456236\n",
      "ep 43: ep_len:106 episode reward: total was 10.500000. running mean: -15.196673\n",
      "ep 43: ep_len:236 episode reward: total was 23.500000. running mean: -14.809706\n",
      "ep 43: ep_len:500 episode reward: total was 28.300000. running mean: -14.378609\n",
      "ep 43: ep_len:1135 episode reward: total was 19.940000. running mean: -14.035423\n",
      "ep 43: ep_len:500 episode reward: total was 26.280000. running mean: -13.632269\n",
      "ep 43: ep_len:186 episode reward: total was 18.500000. running mean: -13.310946\n",
      "ep 43: ep_len:505 episode reward: total was -5.100000. running mean: -13.228837\n",
      "ep 43: ep_len:500 episode reward: total was 28.790000. running mean: -12.808649\n",
      "ep 43: ep_len:282 episode reward: total was 26.500000. running mean: -12.415562\n",
      "ep 43: ep_len:500 episode reward: total was 17.800000. running mean: -12.113406\n",
      "ep 43: ep_len:153 episode reward: total was 15.000000. running mean: -11.842272\n",
      "ep 43: ep_len:690 episode reward: total was 14.110000. running mean: -11.582750\n",
      "ep 43: ep_len:319 episode reward: total was 19.500000. running mean: -11.271922\n",
      "ep 43: ep_len:500 episode reward: total was 10.420000. running mean: -11.055003\n",
      "ep 43: ep_len:165 episode reward: total was 15.000000. running mean: -10.794453\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 43: ep_len:500 episode reward: total was 12.650000. running mean: -10.560008\n",
      "ep 43: ep_len:152 episode reward: total was 15.000000. running mean: -10.304408\n",
      "ep 43: ep_len:580 episode reward: total was 13.950000. running mean: -10.061864\n",
      "ep 43: ep_len:500 episode reward: total was 0.850000. running mean: -9.952746\n",
      "ep 43: ep_len:222 episode reward: total was 22.000000. running mean: -9.633218\n",
      "ep 43: ep_len:590 episode reward: total was 13.260000. running mean: -9.404286\n",
      "ep 43: ep_len:770 episode reward: total was -21.740000. running mean: -9.527643\n",
      "ep 43: ep_len:500 episode reward: total was 26.280000. running mean: -9.169567\n",
      "ep 43: ep_len:500 episode reward: total was 23.370000. running mean: -8.844171\n",
      "ep 43: ep_len:191 episode reward: total was 19.000000. running mean: -8.565729\n",
      "ep 43: ep_len:500 episode reward: total was -5.870000. running mean: -8.538772\n",
      "ep 43: ep_len:665 episode reward: total was 0.270000. running mean: -8.450684\n",
      "ep 43: ep_len:845 episode reward: total was -38.760000. running mean: -8.753777\n",
      "ep 43: ep_len:795 episode reward: total was -27.750000. running mean: -8.943740\n",
      "ep 43: ep_len:500 episode reward: total was 17.000000. running mean: -8.684302\n",
      "ep 43: ep_len:500 episode reward: total was 25.270000. running mean: -8.344759\n",
      "ep 43: ep_len:500 episode reward: total was 6.290000. running mean: -8.198412\n",
      "ep 43: ep_len:535 episode reward: total was -8.070000. running mean: -8.197127\n",
      "ep 43: ep_len:326 episode reward: total was 9.180000. running mean: -8.023356\n",
      "ep 43: ep_len:500 episode reward: total was -19.950000. running mean: -8.142623\n",
      "ep 43: ep_len:2255 episode reward: total was -164.250000. running mean: -9.703696\n",
      "ep 43: ep_len:172 episode reward: total was 15.500000. running mean: -9.451659\n",
      "ep 43: ep_len:500 episode reward: total was 8.180000. running mean: -9.275343\n",
      "ep 43: ep_len:1585 episode reward: total was -250.740000. running mean: -11.689989\n",
      "ep 43: ep_len:550 episode reward: total was -61.570000. running mean: -12.188790\n",
      "ep 43: ep_len:500 episode reward: total was -2.350000. running mean: -12.090402\n",
      "ep 43: ep_len:169 episode reward: total was 14.000000. running mean: -11.829498\n",
      "ep 43: ep_len:500 episode reward: total was -29.900000. running mean: -12.010203\n",
      "ep 43: ep_len:900 episode reward: total was -9.410000. running mean: -11.984201\n",
      "ep 43: ep_len:900 episode reward: total was -31.890000. running mean: -12.183259\n",
      "ep 43: ep_len:500 episode reward: total was 3.770000. running mean: -12.023726\n",
      "ep 43: ep_len:500 episode reward: total was 7.270000. running mean: -11.830789\n",
      "ep 43: ep_len:500 episode reward: total was 13.170000. running mean: -11.580781\n",
      "ep 43: ep_len:580 episode reward: total was -5.770000. running mean: -11.522673\n",
      "ep 43: ep_len:540 episode reward: total was -20.180000. running mean: -11.609246\n",
      "ep 43: ep_len:640 episode reward: total was 0.160000. running mean: -11.491554\n",
      "ep 43: ep_len:500 episode reward: total was 5.580000. running mean: -11.320838\n",
      "ep 43: ep_len:500 episode reward: total was 26.310000. running mean: -10.944530\n",
      "ep 43: ep_len:500 episode reward: total was 13.510000. running mean: -10.699985\n",
      "ep 43: ep_len:910 episode reward: total was -30.550000. running mean: -10.898485\n",
      "ep 43: ep_len:500 episode reward: total was 25.790000. running mean: -10.531600\n",
      "ep 43: ep_len:520 episode reward: total was -40.910000. running mean: -10.835384\n",
      "ep 43: ep_len:379 episode reward: total was 23.730000. running mean: -10.489730\n",
      "ep 43: ep_len:859 episode reward: total was -90.230000. running mean: -11.287133\n",
      "ep 43: ep_len:750 episode reward: total was -46.020000. running mean: -11.634461\n",
      "ep 43: ep_len:500 episode reward: total was 6.810000. running mean: -11.450017\n",
      "ep 43: ep_len:500 episode reward: total was 15.150000. running mean: -11.184017\n",
      "ep 43: ep_len:500 episode reward: total was 21.320000. running mean: -10.858977\n",
      "ep 43: ep_len:500 episode reward: total was 47.000000. running mean: -10.280387\n",
      "ep 43: ep_len:500 episode reward: total was 5.270000. running mean: -10.124883\n",
      "ep 43: ep_len:755 episode reward: total was -18.740000. running mean: -10.211034\n",
      "ep 43: ep_len:500 episode reward: total was 20.250000. running mean: -9.906424\n",
      "ep 43: ep_len:500 episode reward: total was -5.780000. running mean: -9.865160\n",
      "ep 43: ep_len:865 episode reward: total was -21.030000. running mean: -9.976808\n",
      "ep 43: ep_len:650 episode reward: total was 3.920000. running mean: -9.837840\n",
      "ep 43: ep_len:500 episode reward: total was 48.500000. running mean: -9.254461\n",
      "ep 43: ep_len:500 episode reward: total was 5.790000. running mean: -9.104017\n",
      "ep 43: ep_len:500 episode reward: total was -0.790000. running mean: -9.020877\n",
      "ep 43: ep_len:137 episode reward: total was 12.000000. running mean: -8.810668\n",
      "ep 43: ep_len:1075 episode reward: total was 7.970000. running mean: -8.642861\n",
      "ep 43: ep_len:500 episode reward: total was -10.770000. running mean: -8.664133\n",
      "ep 43: ep_len:500 episode reward: total was 3.470000. running mean: -8.542791\n",
      "ep 43: ep_len:820 episode reward: total was -20.600000. running mean: -8.663363\n",
      "ep 43: ep_len:500 episode reward: total was 8.890000. running mean: -8.487830\n",
      "ep 43: ep_len:755 episode reward: total was -11.670000. running mean: -8.519651\n",
      "ep 43: ep_len:655 episode reward: total was -3.790000. running mean: -8.472355\n",
      "ep 43: ep_len:500 episode reward: total was -3.640000. running mean: -8.424031\n",
      "ep 43: ep_len:500 episode reward: total was 22.490000. running mean: -8.114891\n",
      "ep 43: ep_len:500 episode reward: total was 50.000000. running mean: -7.533742\n",
      "ep 43: ep_len:500 episode reward: total was 14.150000. running mean: -7.316905\n",
      "ep 43: ep_len:500 episode reward: total was 22.480000. running mean: -7.018936\n",
      "ep 43: ep_len:1080 episode reward: total was -11.550000. running mean: -7.064246\n",
      "ep 43: ep_len:500 episode reward: total was -53.000000. running mean: -7.523604\n",
      "ep 43: ep_len:294 episode reward: total was 15.750000. running mean: -7.290868\n",
      "ep 43: ep_len:665 episode reward: total was -6.800000. running mean: -7.285959\n",
      "ep 43: ep_len:1260 episode reward: total was -21.770000. running mean: -7.430800\n",
      "ep 43: ep_len:257 episode reward: total was 22.500000. running mean: -7.131492\n",
      "ep 43: ep_len:975 episode reward: total was -24.670000. running mean: -7.306877\n",
      "ep 43: ep_len:500 episode reward: total was 20.810000. running mean: -7.025708\n",
      "ep 43: ep_len:965 episode reward: total was 1.770000. running mean: -6.937751\n",
      "ep 43: ep_len:452 episode reward: total was 6.740000. running mean: -6.800973\n",
      "ep 43: ep_len:500 episode reward: total was 9.290000. running mean: -6.640064\n",
      "ep 43: ep_len:500 episode reward: total was 16.260000. running mean: -6.411063\n",
      "ep 43: ep_len:500 episode reward: total was 11.280000. running mean: -6.234152\n",
      "ep 43: ep_len:670 episode reward: total was -2.230000. running mean: -6.194111\n",
      "ep 43: ep_len:500 episode reward: total was -60.500000. running mean: -6.737170\n",
      "ep 43: ep_len:158 episode reward: total was 14.000000. running mean: -6.529798\n",
      "ep 43: ep_len:1085 episode reward: total was 3.910000. running mean: -6.425400\n",
      "ep 43: ep_len:261 episode reward: total was 26.000000. running mean: -6.101146\n",
      "ep 43: ep_len:500 episode reward: total was -16.770000. running mean: -6.207835\n",
      "ep 43: ep_len:500 episode reward: total was 18.970000. running mean: -5.956056\n",
      "ep 43: ep_len:705 episode reward: total was -7.730000. running mean: -5.973796\n",
      "ep 43: ep_len:500 episode reward: total was -6.480000. running mean: -5.978858\n",
      "ep 43: ep_len:500 episode reward: total was 25.850000. running mean: -5.660569\n",
      "ep 43: ep_len:525 episode reward: total was 4.310000. running mean: -5.560863\n",
      "ep 43: ep_len:500 episode reward: total was 7.630000. running mean: -5.428955\n",
      "ep 43: ep_len:920 episode reward: total was -30.620000. running mean: -5.680865\n",
      "ep 43: ep_len:740 episode reward: total was -7.660000. running mean: -5.700657\n",
      "ep 43: ep_len:500 episode reward: total was -4.160000. running mean: -5.685250\n",
      "ep 43: ep_len:510 episode reward: total was 1.290000. running mean: -5.615497\n",
      "ep 43: ep_len:453 episode reward: total was 45.500000. running mean: -5.104343\n",
      "ep 43: ep_len:570 episode reward: total was 0.080000. running mean: -5.052499\n",
      "ep 43: ep_len:550 episode reward: total was -16.120000. running mean: -5.163174\n",
      "ep 43: ep_len:215 episode reward: total was -1.390000. running mean: -5.125442\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 43: ep_len:745 episode reward: total was 31.210000. running mean: -4.762088\n",
      "ep 43: ep_len:795 episode reward: total was -70.170000. running mean: -5.416167\n",
      "ep 43: ep_len:670 episode reward: total was 18.460000. running mean: -5.177405\n",
      "ep 43: ep_len:500 episode reward: total was -30.500000. running mean: -5.430631\n",
      "ep 43: ep_len:5540 episode reward: total was -1042.370000. running mean: -15.800025\n",
      "ep 43: ep_len:510 episode reward: total was 30.800000. running mean: -15.334025\n",
      "ep 43: ep_len:640 episode reward: total was 8.830000. running mean: -15.092385\n",
      "ep 43: ep_len:500 episode reward: total was -9.500000. running mean: -15.036461\n",
      "ep 43: ep_len:530 episode reward: total was -4.160000. running mean: -14.927696\n",
      "ep 43: ep_len:765 episode reward: total was -5.590000. running mean: -14.834319\n",
      "ep 43: ep_len:605 episode reward: total was -4.900000. running mean: -14.734976\n",
      "ep 43: ep_len:975 episode reward: total was 3.060000. running mean: -14.557026\n",
      "ep 43: ep_len:85 episode reward: total was 7.000000. running mean: -14.341456\n",
      "ep 43: ep_len:500 episode reward: total was 18.350000. running mean: -14.014541\n",
      "ep 43: ep_len:500 episode reward: total was -8.260000. running mean: -13.956996\n",
      "ep 43: ep_len:595 episode reward: total was 26.170000. running mean: -13.555726\n",
      "ep 43: ep_len:585 episode reward: total was -20.090000. running mean: -13.621069\n",
      "ep 43: ep_len:500 episode reward: total was 24.930000. running mean: -13.235558\n",
      "ep 43: ep_len:800 episode reward: total was -40.870000. running mean: -13.511902\n",
      "ep 43: ep_len:520 episode reward: total was 20.240000. running mean: -13.174383\n",
      "ep 43: ep_len:500 episode reward: total was -29.410000. running mean: -13.336740\n",
      "ep 43: ep_len:500 episode reward: total was 26.800000. running mean: -12.935372\n",
      "ep 43: ep_len:845 episode reward: total was -8.670000. running mean: -12.892718\n",
      "ep 43: ep_len:351 episode reward: total was -10.000000. running mean: -12.863791\n",
      "ep 43: ep_len:720 episode reward: total was 0.050000. running mean: -12.734653\n",
      "ep 43: ep_len:500 episode reward: total was 9.900000. running mean: -12.508307\n",
      "ep 43: ep_len:500 episode reward: total was 11.730000. running mean: -12.265924\n",
      "ep 43: ep_len:263 episode reward: total was 26.000000. running mean: -11.883265\n",
      "ep 43: ep_len:890 episode reward: total was 31.290000. running mean: -11.451532\n",
      "ep 43: ep_len:925 episode reward: total was -18.730000. running mean: -11.524317\n",
      "ep 43: ep_len:251 episode reward: total was 25.000000. running mean: -11.159073\n",
      "ep 43: ep_len:500 episode reward: total was 28.360000. running mean: -10.763883\n",
      "ep 43: ep_len:875 episode reward: total was -21.530000. running mean: -10.871544\n",
      "ep 43: ep_len:795 episode reward: total was -39.870000. running mean: -11.161528\n",
      "ep 43: ep_len:500 episode reward: total was -14.990000. running mean: -11.199813\n",
      "ep 43: ep_len:515 episode reward: total was 10.170000. running mean: -10.986115\n",
      "ep 43: ep_len:308 episode reward: total was 29.000000. running mean: -10.586254\n",
      "ep 43: ep_len:580 episode reward: total was -3.940000. running mean: -10.519791\n",
      "ep 43: ep_len:825 episode reward: total was -16.760000. running mean: -10.582193\n",
      "ep 43: ep_len:500 episode reward: total was 26.800000. running mean: -10.208371\n",
      "ep 43: ep_len:4435 episode reward: total was -660.900000. running mean: -16.715288\n",
      "ep 43: ep_len:500 episode reward: total was 26.370000. running mean: -16.284435\n",
      "ep 43: ep_len:500 episode reward: total was 22.090000. running mean: -15.900691\n",
      "ep 43: ep_len:670 episode reward: total was -8.780000. running mean: -15.829484\n",
      "ep 43: ep_len:296 episode reward: total was -42.500000. running mean: -16.096189\n",
      "ep 43: ep_len:870 episode reward: total was -22.520000. running mean: -16.160427\n",
      "ep 43: ep_len:4890 episode reward: total was -752.820000. running mean: -23.527023\n",
      "ep 43: ep_len:181 episode reward: total was 18.000000. running mean: -23.111752\n",
      "ep 43: ep_len:730 episode reward: total was -0.670000. running mean: -22.887335\n",
      "ep 43: ep_len:500 episode reward: total was 15.850000. running mean: -22.499962\n",
      "ep 43: ep_len:585 episode reward: total was -26.150000. running mean: -22.536462\n",
      "ep 43: ep_len:500 episode reward: total was 21.820000. running mean: -22.092897\n",
      "ep 43: ep_len:640 episode reward: total was 26.220000. running mean: -21.609768\n",
      "ep 43: ep_len:750 episode reward: total was -43.480000. running mean: -21.828471\n",
      "ep 43: ep_len:510 episode reward: total was 7.310000. running mean: -21.537086\n",
      "ep 43: ep_len:500 episode reward: total was 6.770000. running mean: -21.254015\n",
      "ep 43: ep_len:610 episode reward: total was -5.900000. running mean: -21.100475\n",
      "ep 43: ep_len:1020 episode reward: total was -66.870000. running mean: -21.558170\n",
      "ep 43: ep_len:500 episode reward: total was 11.340000. running mean: -21.229188\n",
      "ep 43: ep_len:535 episode reward: total was 0.300000. running mean: -21.013897\n",
      "ep 43: ep_len:500 episode reward: total was 28.210000. running mean: -20.521658\n",
      "ep 43: ep_len:1170 episode reward: total was -59.290000. running mean: -20.909341\n",
      "ep 43: ep_len:615 episode reward: total was -27.100000. running mean: -20.971248\n",
      "ep 43: ep_len:500 episode reward: total was 9.840000. running mean: -20.663135\n",
      "ep 43: ep_len:938 episode reward: total was -99.160000. running mean: -21.448104\n",
      "ep 43: ep_len:750 episode reward: total was -16.700000. running mean: -21.400623\n",
      "ep 43: ep_len:700 episode reward: total was 17.770000. running mean: -21.008917\n",
      "ep 43: ep_len:500 episode reward: total was 28.850000. running mean: -20.510327\n",
      "ep 43: ep_len:500 episode reward: total was 47.000000. running mean: -19.835224\n",
      "ep 43: ep_len:500 episode reward: total was 10.510000. running mean: -19.531772\n",
      "ep 43: ep_len:500 episode reward: total was 25.300000. running mean: -19.083454\n",
      "ep 43: ep_len:500 episode reward: total was -3.760000. running mean: -18.930220\n",
      "ep 43: ep_len:500 episode reward: total was -11.230000. running mean: -18.853217\n",
      "ep 43: ep_len:510 episode reward: total was -97.000000. running mean: -19.634685\n",
      "ep 43: ep_len:500 episode reward: total was 8.670000. running mean: -19.351638\n",
      "ep 43: ep_len:500 episode reward: total was 5.180000. running mean: -19.106322\n",
      "ep 43: ep_len:177 episode reward: total was 17.500000. running mean: -18.740259\n",
      "ep 43: ep_len:1260 episode reward: total was -57.120000. running mean: -19.124056\n",
      "ep 43: ep_len:855 episode reward: total was -5.310000. running mean: -18.985916\n",
      "ep 43: ep_len:880 episode reward: total was -10.490000. running mean: -18.900956\n",
      "ep 43: ep_len:915 episode reward: total was -21.320000. running mean: -18.925147\n",
      "ep 43: ep_len:580 episode reward: total was -4.550000. running mean: -18.781395\n",
      "ep 43: ep_len:190 episode reward: total was 17.500000. running mean: -18.418581\n",
      "ep 43: ep_len:561 episode reward: total was -69.690000. running mean: -18.931296\n",
      "ep 43: ep_len:585 episode reward: total was -58.450000. running mean: -19.326483\n",
      "ep 43: ep_len:500 episode reward: total was 26.430000. running mean: -18.868918\n",
      "ep 43: ep_len:695 episode reward: total was -34.720000. running mean: -19.027429\n",
      "ep 43: ep_len:500 episode reward: total was 1.780000. running mean: -18.819354\n",
      "ep 43: ep_len:730 episode reward: total was -10.680000. running mean: -18.737961\n",
      "ep 43: ep_len:665 episode reward: total was -20.940000. running mean: -18.759981\n",
      "ep 43: ep_len:535 episode reward: total was -5.040000. running mean: -18.622781\n",
      "ep 43: ep_len:500 episode reward: total was 22.420000. running mean: -18.212354\n",
      "ep 43: ep_len:840 episode reward: total was -1.210000. running mean: -18.042330\n",
      "ep 43: ep_len:1155 episode reward: total was -35.370000. running mean: -18.215607\n",
      "ep 43: ep_len:820 episode reward: total was -23.500000. running mean: -18.268451\n",
      "ep 43: ep_len:500 episode reward: total was 13.970000. running mean: -17.946066\n",
      "ep 43: ep_len:500 episode reward: total was 23.890000. running mean: -17.527706\n",
      "ep 43: ep_len:975 episode reward: total was 16.240000. running mean: -17.190028\n",
      "ep 43: ep_len:575 episode reward: total was -17.080000. running mean: -17.188928\n",
      "ep 43: ep_len:895 episode reward: total was -19.650000. running mean: -17.213539\n",
      "ep 43: ep_len:500 episode reward: total was 7.290000. running mean: -16.968504\n",
      "ep 43: ep_len:695 episode reward: total was -10.750000. running mean: -16.906318\n",
      "ep 43: ep_len:580 episode reward: total was 19.510000. running mean: -16.542155\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 43: ep_len:500 episode reward: total was 17.290000. running mean: -16.203834\n",
      "ep 43: ep_len:157 episode reward: total was 16.000000. running mean: -15.881795\n",
      "ep 43: ep_len:500 episode reward: total was 26.860000. running mean: -15.454377\n",
      "ep 43: ep_len:625 episode reward: total was 11.380000. running mean: -15.186034\n",
      "ep 43: ep_len:500 episode reward: total was 28.790000. running mean: -14.746273\n",
      "ep 43: ep_len:500 episode reward: total was 30.290000. running mean: -14.295911\n",
      "ep 43: ep_len:500 episode reward: total was 29.830000. running mean: -13.854652\n",
      "ep 43: ep_len:505 episode reward: total was -64.260000. running mean: -14.358705\n",
      "ep 43: ep_len:540 episode reward: total was -14.150000. running mean: -14.356618\n",
      "ep 43: ep_len:145 episode reward: total was 13.000000. running mean: -14.083052\n",
      "ep 43: ep_len:500 episode reward: total was 25.820000. running mean: -13.684021\n",
      "ep 43: ep_len:500 episode reward: total was 18.780000. running mean: -13.359381\n",
      "ep 43: ep_len:500 episode reward: total was 4.600000. running mean: -13.179787\n",
      "ep 43: ep_len:2605 episode reward: total was -431.500000. running mean: -17.362989\n",
      "ep 43: ep_len:665 episode reward: total was 11.790000. running mean: -17.071459\n",
      "ep 43: ep_len:5456 episode reward: total was -875.910000. running mean: -25.659845\n",
      "ep 43: ep_len:700 episode reward: total was -20.870000. running mean: -25.611946\n",
      "ep 43: ep_len:500 episode reward: total was -8.660000. running mean: -25.442427\n",
      "ep 43: ep_len:2039 episode reward: total was -179.780000. running mean: -26.985803\n",
      "ep 43: ep_len:675 episode reward: total was -34.050000. running mean: -27.056445\n",
      "ep 43: ep_len:462 episode reward: total was 14.110000. running mean: -26.644780\n",
      "ep 43: ep_len:500 episode reward: total was 9.780000. running mean: -26.280532\n",
      "epsilon:0.010000 episode_count: 34705. steps_count: 25173686.000000\n",
      "ep 44: ep_len:505 episode reward: total was 18.790000. running mean: -25.829827\n",
      "ep 44: ep_len:830 episode reward: total was -25.660000. running mean: -25.828129\n",
      "ep 44: ep_len:695 episode reward: total was -8.760000. running mean: -25.657448\n",
      "ep 44: ep_len:610 episode reward: total was -42.810000. running mean: -25.828973\n",
      "ep 44: ep_len:505 episode reward: total was -1.690000. running mean: -25.587583\n",
      "ep 44: ep_len:500 episode reward: total was 1.050000. running mean: -25.321207\n",
      "ep 44: ep_len:855 episode reward: total was 10.300000. running mean: -24.964995\n",
      "ep 44: ep_len:500 episode reward: total was 25.850000. running mean: -24.456845\n",
      "ep 44: ep_len:760 episode reward: total was -19.770000. running mean: -24.409977\n",
      "ep 44: ep_len:995 episode reward: total was 12.650000. running mean: -24.039377\n",
      "ep 44: ep_len:500 episode reward: total was 25.240000. running mean: -23.546583\n",
      "ep 44: ep_len:1641 episode reward: total was -295.760000. running mean: -26.268718\n",
      "ep 44: ep_len:500 episode reward: total was 4.870000. running mean: -25.957330\n",
      "ep 44: ep_len:153 episode reward: total was 15.000000. running mean: -25.547757\n",
      "ep 44: ep_len:1090 episode reward: total was -65.540000. running mean: -25.947680\n",
      "ep 44: ep_len:1030 episode reward: total was -0.460000. running mean: -25.692803\n",
      "ep 44: ep_len:500 episode reward: total was 32.280000. running mean: -25.113075\n",
      "ep 44: ep_len:670 episode reward: total was -4.770000. running mean: -24.909644\n",
      "ep 44: ep_len:500 episode reward: total was 22.020000. running mean: -24.440348\n",
      "ep 44: ep_len:180 episode reward: total was -7.500000. running mean: -24.270944\n",
      "ep 44: ep_len:545 episode reward: total was -12.090000. running mean: -24.149135\n",
      "ep 44: ep_len:575 episode reward: total was 21.010000. running mean: -23.697543\n",
      "ep 44: ep_len:1877 episode reward: total was -108.390000. running mean: -24.544468\n",
      "ep 44: ep_len:227 episode reward: total was 18.000000. running mean: -24.119023\n",
      "ep 44: ep_len:960 episode reward: total was -60.750000. running mean: -24.485333\n",
      "ep 44: ep_len:630 episode reward: total was 20.220000. running mean: -24.038280\n",
      "ep 44: ep_len:449 episode reward: total was 24.300000. running mean: -23.554897\n",
      "ep 44: ep_len:154 episode reward: total was 15.000000. running mean: -23.169348\n",
      "ep 44: ep_len:1000 episode reward: total was 1.150000. running mean: -22.926154\n",
      "ep 44: ep_len:500 episode reward: total was -4.100000. running mean: -22.737893\n",
      "ep 44: ep_len:15619 episode reward: total was -2932.950000. running mean: -51.840014\n",
      "ep 44: ep_len:500 episode reward: total was -20.180000. running mean: -51.523414\n",
      "ep 44: ep_len:510 episode reward: total was -6.100000. running mean: -51.069180\n",
      "ep 44: ep_len:500 episode reward: total was -3.930000. running mean: -50.597788\n",
      "ep 44: ep_len:500 episode reward: total was -3.640000. running mean: -50.128210\n",
      "ep 44: ep_len:830 episode reward: total was -23.370000. running mean: -49.860628\n",
      "ep 44: ep_len:500 episode reward: total was -4.180000. running mean: -49.403822\n",
      "ep 44: ep_len:500 episode reward: total was 23.280000. running mean: -48.676983\n",
      "ep 44: ep_len:500 episode reward: total was -1.840000. running mean: -48.208614\n",
      "ep 44: ep_len:575 episode reward: total was -28.190000. running mean: -48.008427\n",
      "ep 44: ep_len:500 episode reward: total was 9.220000. running mean: -47.436143\n",
      "ep 44: ep_len:500 episode reward: total was -8.560000. running mean: -47.047382\n",
      "ep 44: ep_len:500 episode reward: total was 21.750000. running mean: -46.359408\n",
      "ep 44: ep_len:312 episode reward: total was -8.000000. running mean: -45.975814\n",
      "ep 44: ep_len:565 episode reward: total was -10.210000. running mean: -45.618156\n",
      "ep 44: ep_len:500 episode reward: total was 7.120000. running mean: -45.090774\n",
      "ep 44: ep_len:565 episode reward: total was -75.680000. running mean: -45.396666\n",
      "ep 44: ep_len:785 episode reward: total was -9.800000. running mean: -45.040700\n",
      "ep 44: ep_len:19505 episode reward: total was -3701.600000. running mean: -81.606293\n",
      "ep 44: ep_len:725 episode reward: total was -41.020000. running mean: -81.200430\n",
      "ep 44: ep_len:885 episode reward: total was -64.940000. running mean: -81.037825\n",
      "ep 44: ep_len:500 episode reward: total was 9.820000. running mean: -80.129247\n",
      "ep 44: ep_len:148 episode reward: total was 13.000000. running mean: -79.197955\n",
      "ep 44: ep_len:760 episode reward: total was -38.410000. running mean: -78.790075\n",
      "ep 44: ep_len:500 episode reward: total was 5.400000. running mean: -77.948174\n",
      "ep 44: ep_len:500 episode reward: total was 9.260000. running mean: -77.076093\n",
      "ep 44: ep_len:920 episode reward: total was -28.930000. running mean: -76.594632\n",
      "ep 44: ep_len:101 episode reward: total was 10.000000. running mean: -75.728685\n",
      "ep 44: ep_len:500 episode reward: total was 26.770000. running mean: -74.703699\n",
      "ep 44: ep_len:735 episode reward: total was -29.370000. running mean: -74.250362\n",
      "ep 44: ep_len:730 episode reward: total was -70.000000. running mean: -74.207858\n",
      "ep 44: ep_len:1300 episode reward: total was -216.620000. running mean: -75.631979\n",
      "ep 44: ep_len:500 episode reward: total was 18.200000. running mean: -74.693660\n",
      "ep 44: ep_len:520 episode reward: total was -27.290000. running mean: -74.219623\n",
      "ep 44: ep_len:204 episode reward: total was 20.000000. running mean: -73.277427\n",
      "ep 44: ep_len:500 episode reward: total was -0.230000. running mean: -72.546953\n",
      "ep 44: ep_len:500 episode reward: total was -18.760000. running mean: -72.009083\n",
      "ep 44: ep_len:1215 episode reward: total was -103.560000. running mean: -72.324592\n",
      "ep 44: ep_len:605 episode reward: total was -38.720000. running mean: -71.988546\n",
      "ep 44: ep_len:510 episode reward: total was -23.240000. running mean: -71.501061\n",
      "ep 44: ep_len:640 episode reward: total was -14.560000. running mean: -70.931650\n",
      "ep 44: ep_len:745 episode reward: total was -7.130000. running mean: -70.293634\n",
      "ep 44: ep_len:132 episode reward: total was 13.000000. running mean: -69.460697\n",
      "ep 44: ep_len:890 episode reward: total was -5.560000. running mean: -68.821690\n",
      "ep 44: ep_len:700 episode reward: total was -20.840000. running mean: -68.341873\n",
      "ep 44: ep_len:384 episode reward: total was -26.070000. running mean: -67.919155\n",
      "ep 44: ep_len:665 episode reward: total was 24.260000. running mean: -66.997363\n",
      "ep 44: ep_len:500 episode reward: total was 19.700000. running mean: -66.130390\n",
      "ep 44: ep_len:500 episode reward: total was 19.210000. running mean: -65.276986\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 44: ep_len:1890 episode reward: total was -230.560000. running mean: -66.929816\n",
      "ep 44: ep_len:500 episode reward: total was -10.860000. running mean: -66.369118\n",
      "ep 44: ep_len:1000 episode reward: total was -19.280000. running mean: -65.898226\n",
      "ep 44: ep_len:500 episode reward: total was 4.670000. running mean: -65.192544\n",
      "ep 44: ep_len:625 episode reward: total was -9.880000. running mean: -64.639419\n",
      "ep 44: ep_len:78 episode reward: total was 7.500000. running mean: -63.918025\n",
      "ep 44: ep_len:500 episode reward: total was -1.710000. running mean: -63.295944\n",
      "ep 44: ep_len:226 episode reward: total was 21.500000. running mean: -62.447985\n",
      "ep 44: ep_len:500 episode reward: total was -59.830000. running mean: -62.421805\n",
      "ep 44: ep_len:585 episode reward: total was -20.090000. running mean: -61.998487\n",
      "ep 44: ep_len:670 episode reward: total was 15.570000. running mean: -61.222802\n",
      "ep 44: ep_len:590 episode reward: total was 29.340000. running mean: -60.317174\n",
      "ep 44: ep_len:765 episode reward: total was 2.800000. running mean: -59.686002\n",
      "ep 44: ep_len:775 episode reward: total was -58.090000. running mean: -59.670042\n",
      "ep 44: ep_len:3250 episode reward: total was -572.280000. running mean: -64.796142\n",
      "ep 44: ep_len:570 episode reward: total was -39.310000. running mean: -64.541280\n",
      "ep 44: ep_len:1413 episode reward: total was -151.760000. running mean: -65.413468\n",
      "ep 44: ep_len:873 episode reward: total was -141.710000. running mean: -66.176433\n",
      "ep 44: ep_len:1150 episode reward: total was -118.440000. running mean: -66.699069\n",
      "ep 44: ep_len:500 episode reward: total was 2.700000. running mean: -66.005078\n",
      "ep 44: ep_len:500 episode reward: total was -8.690000. running mean: -65.431927\n",
      "ep 44: ep_len:500 episode reward: total was 0.830000. running mean: -64.769308\n",
      "ep 44: ep_len:665 episode reward: total was -13.840000. running mean: -64.260015\n",
      "ep 44: ep_len:500 episode reward: total was 27.760000. running mean: -63.339815\n",
      "ep 44: ep_len:253 episode reward: total was 25.000000. running mean: -62.456417\n",
      "ep 44: ep_len:695 episode reward: total was -31.990000. running mean: -62.151752\n",
      "ep 44: ep_len:1294 episode reward: total was -255.000000. running mean: -64.080235\n",
      "ep 44: ep_len:700 episode reward: total was -20.340000. running mean: -63.642833\n",
      "ep 44: ep_len:505 episode reward: total was 46.000000. running mean: -62.546404\n",
      "ep 44: ep_len:595 episode reward: total was -19.060000. running mean: -62.111540\n",
      "ep 44: ep_len:232 episode reward: total was 23.000000. running mean: -61.260425\n",
      "ep 44: ep_len:750 episode reward: total was -12.620000. running mean: -60.774021\n",
      "ep 44: ep_len:277 episode reward: total was 24.500000. running mean: -59.921280\n",
      "ep 44: ep_len:189 episode reward: total was 18.500000. running mean: -59.137068\n",
      "ep 44: ep_len:500 episode reward: total was 14.900000. running mean: -58.396697\n",
      "ep 44: ep_len:500 episode reward: total was -5.200000. running mean: -57.864730\n",
      "ep 44: ep_len:720 episode reward: total was -13.760000. running mean: -57.423683\n",
      "ep 44: ep_len:500 episode reward: total was 36.720000. running mean: -56.482246\n",
      "ep 44: ep_len:935 episode reward: total was 5.550000. running mean: -55.861923\n",
      "ep 44: ep_len:267 episode reward: total was 26.500000. running mean: -55.038304\n",
      "ep 44: ep_len:1040 episode reward: total was -22.170000. running mean: -54.709621\n",
      "ep 44: ep_len:500 episode reward: total was -6.540000. running mean: -54.227925\n",
      "ep 44: ep_len:505 episode reward: total was -14.600000. running mean: -53.831646\n",
      "ep 44: ep_len:960 episode reward: total was -82.430000. running mean: -54.117629\n",
      "ep 44: ep_len:925 episode reward: total was 13.180000. running mean: -53.444653\n",
      "ep 44: ep_len:500 episode reward: total was -3.730000. running mean: -52.947506\n",
      "ep 44: ep_len:1155 episode reward: total was -97.080000. running mean: -53.388831\n",
      "ep 44: ep_len:810 episode reward: total was 16.620000. running mean: -52.688743\n",
      "ep 44: ep_len:715 episode reward: total was -10.740000. running mean: -52.269255\n",
      "ep 44: ep_len:2730 episode reward: total was -487.470000. running mean: -56.621263\n",
      "ep 44: ep_len:750 episode reward: total was -2.590000. running mean: -56.080950\n",
      "ep 44: ep_len:730 episode reward: total was -8.170000. running mean: -55.601841\n",
      "ep 44: ep_len:139 episode reward: total was 12.000000. running mean: -54.925822\n",
      "ep 44: ep_len:550 episode reward: total was -8.040000. running mean: -54.456964\n",
      "ep 44: ep_len:1140 episode reward: total was -9.660000. running mean: -54.008995\n",
      "ep 44: ep_len:1095 episode reward: total was -5.190000. running mean: -53.520805\n",
      "ep 44: ep_len:875 episode reward: total was 11.000000. running mean: -52.875597\n",
      "ep 44: ep_len:500 episode reward: total was 24.410000. running mean: -52.102741\n",
      "ep 44: ep_len:1590 episode reward: total was -106.500000. running mean: -52.646713\n",
      "ep 44: ep_len:2204 episode reward: total was -229.950000. running mean: -54.419746\n",
      "ep 44: ep_len:500 episode reward: total was 9.410000. running mean: -53.781449\n",
      "ep 44: ep_len:500 episode reward: total was -10.060000. running mean: -53.344234\n",
      "ep 44: ep_len:500 episode reward: total was -12.210000. running mean: -52.932892\n",
      "ep 44: ep_len:500 episode reward: total was 50.000000. running mean: -51.903563\n",
      "ep 44: ep_len:500 episode reward: total was 22.730000. running mean: -51.157227\n",
      "ep 44: ep_len:900 episode reward: total was 15.640000. running mean: -50.489255\n",
      "ep 44: ep_len:1560 episode reward: total was -68.640000. running mean: -50.670762\n",
      "ep 44: ep_len:500 episode reward: total was 25.240000. running mean: -49.911655\n",
      "ep 44: ep_len:500 episode reward: total was 32.220000. running mean: -49.090338\n",
      "ep 44: ep_len:630 episode reward: total was -13.940000. running mean: -48.738835\n",
      "ep 44: ep_len:186 episode reward: total was 18.500000. running mean: -48.066446\n",
      "ep 44: ep_len:500 episode reward: total was 13.630000. running mean: -47.449482\n",
      "ep 44: ep_len:935 episode reward: total was 8.810000. running mean: -46.886887\n",
      "ep 44: ep_len:500 episode reward: total was 7.270000. running mean: -46.345318\n",
      "ep 44: ep_len:500 episode reward: total was 26.220000. running mean: -45.619665\n",
      "ep 44: ep_len:650 episode reward: total was -19.960000. running mean: -45.363068\n",
      "ep 44: ep_len:720 episode reward: total was -18.400000. running mean: -45.093438\n",
      "ep 44: ep_len:950 episode reward: total was 16.180000. running mean: -44.480703\n",
      "ep 44: ep_len:500 episode reward: total was 18.530000. running mean: -43.850596\n",
      "ep 44: ep_len:915 episode reward: total was -4.530000. running mean: -43.457390\n",
      "ep 44: ep_len:535 episode reward: total was 18.390000. running mean: -42.838917\n",
      "ep 44: ep_len:940 episode reward: total was 7.980000. running mean: -42.330727\n",
      "ep 44: ep_len:805 episode reward: total was -0.580000. running mean: -41.913220\n",
      "ep 44: ep_len:307 episode reward: total was 7.730000. running mean: -41.416788\n",
      "ep 44: ep_len:500 episode reward: total was 10.810000. running mean: -40.894520\n",
      "ep 44: ep_len:500 episode reward: total was 27.870000. running mean: -40.206875\n",
      "ep 44: ep_len:690 episode reward: total was -21.380000. running mean: -40.018606\n",
      "ep 44: ep_len:1000 episode reward: total was -0.460000. running mean: -39.623020\n",
      "ep 44: ep_len:880 episode reward: total was 7.780000. running mean: -39.148990\n",
      "ep 44: ep_len:500 episode reward: total was 15.720000. running mean: -38.600300\n",
      "ep 44: ep_len:500 episode reward: total was 8.180000. running mean: -38.132497\n",
      "ep 44: ep_len:500 episode reward: total was 10.570000. running mean: -37.645472\n",
      "ep 44: ep_len:475 episode reward: total was 46.000000. running mean: -36.809017\n",
      "ep 44: ep_len:500 episode reward: total was 13.730000. running mean: -36.303627\n",
      "ep 44: ep_len:525 episode reward: total was -23.240000. running mean: -36.172991\n",
      "ep 44: ep_len:289 episode reward: total was 27.500000. running mean: -35.536261\n",
      "ep 44: ep_len:500 episode reward: total was -1.300000. running mean: -35.193898\n",
      "ep 44: ep_len:715 episode reward: total was -2.660000. running mean: -34.868559\n",
      "ep 44: ep_len:935 episode reward: total was -28.480000. running mean: -34.804674\n",
      "ep 44: ep_len:900 episode reward: total was 0.030000. running mean: -34.456327\n",
      "ep 44: ep_len:500 episode reward: total was 1.840000. running mean: -34.093364\n",
      "ep 44: ep_len:212 episode reward: total was 21.000000. running mean: -33.542430\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 44: ep_len:500 episode reward: total was -0.240000. running mean: -33.209406\n",
      "ep 44: ep_len:505 episode reward: total was 25.370000. running mean: -32.623612\n",
      "ep 44: ep_len:785 episode reward: total was 10.000000. running mean: -32.197376\n",
      "ep 44: ep_len:545 episode reward: total was -26.720000. running mean: -32.142602\n",
      "ep 44: ep_len:500 episode reward: total was -21.130000. running mean: -32.032476\n",
      "ep 44: ep_len:1267 episode reward: total was -135.650000. running mean: -33.068651\n",
      "ep 44: ep_len:180 episode reward: total was 16.500000. running mean: -32.572965\n",
      "ep 44: ep_len:580 episode reward: total was 10.300000. running mean: -32.144235\n",
      "ep 44: ep_len:595 episode reward: total was -3.910000. running mean: -31.861893\n",
      "ep 44: ep_len:500 episode reward: total was 25.270000. running mean: -31.290574\n",
      "ep 44: ep_len:500 episode reward: total was 17.780000. running mean: -30.799868\n",
      "ep 44: ep_len:500 episode reward: total was -23.830000. running mean: -30.730169\n",
      "ep 44: ep_len:500 episode reward: total was -2.560000. running mean: -30.448467\n",
      "ep 44: ep_len:710 episode reward: total was -2.670000. running mean: -30.170683\n",
      "ep 44: ep_len:232 episode reward: total was 23.000000. running mean: -29.638976\n",
      "ep 44: ep_len:154 episode reward: total was 12.500000. running mean: -29.217586\n",
      "ep 44: ep_len:870 episode reward: total was -4.210000. running mean: -28.967510\n",
      "ep 44: ep_len:131 episode reward: total was 13.000000. running mean: -28.547835\n",
      "ep 44: ep_len:1085 episode reward: total was -123.120000. running mean: -29.493557\n",
      "ep 44: ep_len:500 episode reward: total was 20.560000. running mean: -28.993021\n",
      "ep 44: ep_len:1585 episode reward: total was -179.660000. running mean: -30.499691\n",
      "ep 44: ep_len:500 episode reward: total was 22.280000. running mean: -29.971894\n",
      "ep 44: ep_len:500 episode reward: total was 14.280000. running mean: -29.529375\n",
      "ep 44: ep_len:369 episode reward: total was 35.000000. running mean: -28.884082\n",
      "ep 44: ep_len:720 episode reward: total was -6.690000. running mean: -28.662141\n",
      "ep 44: ep_len:870 episode reward: total was 16.100000. running mean: -28.214519\n",
      "ep 44: ep_len:205 episode reward: total was 19.000000. running mean: -27.742374\n",
      "ep 44: ep_len:630 episode reward: total was -8.890000. running mean: -27.553850\n",
      "ep 44: ep_len:570 episode reward: total was -5.980000. running mean: -27.338112\n",
      "ep 44: ep_len:545 episode reward: total was -10.160000. running mean: -27.166331\n",
      "ep 44: ep_len:625 episode reward: total was 21.630000. running mean: -26.678367\n",
      "ep 44: ep_len:500 episode reward: total was 7.690000. running mean: -26.334684\n",
      "ep 44: ep_len:1010 episode reward: total was -0.420000. running mean: -26.075537\n",
      "ep 44: ep_len:500 episode reward: total was 28.760000. running mean: -25.527182\n",
      "ep 44: ep_len:535 episode reward: total was 24.450000. running mean: -25.027410\n",
      "ep 44: ep_len:640 episode reward: total was 0.220000. running mean: -24.774936\n",
      "ep 44: ep_len:855 episode reward: total was -15.950000. running mean: -24.686686\n",
      "ep 44: ep_len:2165 episode reward: total was -355.310000. running mean: -27.992919\n",
      "ep 44: ep_len:795 episode reward: total was 11.600000. running mean: -27.596990\n",
      "ep 44: ep_len:1435 episode reward: total was -113.330000. running mean: -28.454320\n",
      "ep 44: ep_len:590 episode reward: total was 22.600000. running mean: -27.943777\n",
      "ep 44: ep_len:505 episode reward: total was -10.640000. running mean: -27.770739\n",
      "ep 44: ep_len:690 episode reward: total was 20.840000. running mean: -27.284632\n",
      "ep 44: ep_len:525 episode reward: total was -5.060000. running mean: -27.062386\n",
      "ep 44: ep_len:500 episode reward: total was 9.660000. running mean: -26.695162\n",
      "ep 44: ep_len:750 episode reward: total was -3.600000. running mean: -26.464210\n",
      "ep 44: ep_len:945 episode reward: total was 14.800000. running mean: -26.051568\n",
      "ep 44: ep_len:590 episode reward: total was -2.910000. running mean: -25.820152\n",
      "ep 44: ep_len:750 episode reward: total was -35.210000. running mean: -25.914051\n",
      "ep 44: ep_len:474 episode reward: total was -29.220000. running mean: -25.947110\n",
      "ep 44: ep_len:500 episode reward: total was 21.320000. running mean: -25.474439\n",
      "ep 44: ep_len:500 episode reward: total was -0.700000. running mean: -25.226695\n",
      "ep 44: ep_len:500 episode reward: total was 32.800000. running mean: -24.646428\n",
      "ep 44: ep_len:500 episode reward: total was 30.780000. running mean: -24.092164\n",
      "ep 44: ep_len:500 episode reward: total was -0.150000. running mean: -23.852742\n",
      "ep 44: ep_len:605 episode reward: total was 32.860000. running mean: -23.285615\n",
      "ep 44: ep_len:990 episode reward: total was -8.990000. running mean: -23.142658\n",
      "ep 44: ep_len:650 episode reward: total was 6.970000. running mean: -22.841532\n",
      "ep 44: ep_len:500 episode reward: total was 28.820000. running mean: -22.324917\n",
      "ep 44: ep_len:705 episode reward: total was -19.850000. running mean: -22.300167\n",
      "ep 44: ep_len:820 episode reward: total was -1.070000. running mean: -22.087866\n",
      "ep 44: ep_len:500 episode reward: total was 21.070000. running mean: -21.656287\n",
      "ep 44: ep_len:500 episode reward: total was 28.760000. running mean: -21.152124\n",
      "ep 44: ep_len:690 episode reward: total was -8.770000. running mean: -21.028303\n",
      "ep 44: ep_len:670 episode reward: total was -6.790000. running mean: -20.885920\n",
      "ep 44: ep_len:670 episode reward: total was 27.120000. running mean: -20.405861\n",
      "ep 44: ep_len:510 episode reward: total was -2.060000. running mean: -20.222402\n",
      "ep 44: ep_len:810 episode reward: total was -93.390000. running mean: -20.954078\n",
      "ep 44: ep_len:615 episode reward: total was -31.650000. running mean: -21.061037\n",
      "ep 44: ep_len:915 episode reward: total was -15.390000. running mean: -21.004327\n",
      "ep 44: ep_len:595 episode reward: total was 17.130000. running mean: -20.622984\n",
      "ep 44: ep_len:780 episode reward: total was -16.530000. running mean: -20.582054\n",
      "ep 44: ep_len:500 episode reward: total was 25.120000. running mean: -20.125033\n",
      "ep 44: ep_len:484 episode reward: total was 37.660000. running mean: -19.547183\n",
      "ep 44: ep_len:67 episode reward: total was 6.500000. running mean: -19.286711\n",
      "ep 44: ep_len:1025 episode reward: total was -4.490000. running mean: -19.138744\n",
      "ep 44: ep_len:1131 episode reward: total was -158.940000. running mean: -20.536757\n",
      "ep 44: ep_len:500 episode reward: total was 22.420000. running mean: -20.107189\n",
      "ep 44: ep_len:1065 episode reward: total was -60.000000. running mean: -20.506117\n",
      "ep 44: ep_len:670 episode reward: total was -15.360000. running mean: -20.454656\n",
      "ep 44: ep_len:500 episode reward: total was -14.530000. running mean: -20.395409\n",
      "ep 44: ep_len:515 episode reward: total was -4.340000. running mean: -20.234855\n",
      "ep 44: ep_len:535 episode reward: total was -3.020000. running mean: -20.062707\n",
      "ep 44: ep_len:815 episode reward: total was -24.650000. running mean: -20.108580\n",
      "ep 44: ep_len:500 episode reward: total was 22.510000. running mean: -19.682394\n",
      "ep 44: ep_len:1115 episode reward: total was -4.100000. running mean: -19.526570\n",
      "ep 44: ep_len:500 episode reward: total was 30.320000. running mean: -19.028104\n",
      "ep 44: ep_len:165 episode reward: total was 15.000000. running mean: -18.687823\n",
      "ep 44: ep_len:585 episode reward: total was -1.910000. running mean: -18.520045\n",
      "ep 44: ep_len:770 episode reward: total was 13.190000. running mean: -18.202944\n",
      "ep 44: ep_len:500 episode reward: total was 15.780000. running mean: -17.863115\n",
      "ep 44: ep_len:327 episode reward: total was 31.000000. running mean: -17.374484\n",
      "ep 44: ep_len:500 episode reward: total was 50.000000. running mean: -16.700739\n",
      "ep 44: ep_len:755 episode reward: total was 1.280000. running mean: -16.520932\n",
      "ep 44: ep_len:500 episode reward: total was 19.790000. running mean: -16.157822\n",
      "ep 44: ep_len:254 episode reward: total was 22.000000. running mean: -15.776244\n",
      "ep 44: ep_len:500 episode reward: total was 21.320000. running mean: -15.405282\n",
      "ep 44: ep_len:500 episode reward: total was -5.530000. running mean: -15.306529\n",
      "ep 44: ep_len:500 episode reward: total was 11.370000. running mean: -15.039764\n",
      "ep 44: ep_len:500 episode reward: total was 14.740000. running mean: -14.741966\n",
      "ep 44: ep_len:650 episode reward: total was 0.890000. running mean: -14.585646\n",
      "ep 44: ep_len:1270 episode reward: total was -164.160000. running mean: -16.081390\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 44: ep_len:500 episode reward: total was 6.340000. running mean: -15.857176\n",
      "ep 44: ep_len:500 episode reward: total was 3.830000. running mean: -15.660304\n",
      "ep 44: ep_len:500 episode reward: total was 11.890000. running mean: -15.384801\n",
      "ep 44: ep_len:192 episode reward: total was 2.500000. running mean: -15.205953\n",
      "ep 44: ep_len:187 episode reward: total was 18.500000. running mean: -14.868894\n",
      "ep 44: ep_len:203 episode reward: total was 17.000000. running mean: -14.550205\n",
      "ep 44: ep_len:915 episode reward: total was -8.180000. running mean: -14.486503\n",
      "ep 44: ep_len:1050 episode reward: total was -38.350000. running mean: -14.725138\n",
      "ep 44: ep_len:690 episode reward: total was 37.350000. running mean: -14.204386\n",
      "ep 44: ep_len:560 episode reward: total was 20.530000. running mean: -13.857042\n",
      "ep 44: ep_len:755 episode reward: total was -5.610000. running mean: -13.774572\n",
      "ep 44: ep_len:790 episode reward: total was -32.810000. running mean: -13.964926\n",
      "ep 44: ep_len:1510 episode reward: total was -73.790000. running mean: -14.563177\n",
      "ep 44: ep_len:690 episode reward: total was -1.700000. running mean: -14.434545\n",
      "ep 44: ep_len:500 episode reward: total was 47.000000. running mean: -13.820200\n",
      "ep 44: ep_len:950 episode reward: total was 2.470000. running mean: -13.657298\n",
      "ep 44: ep_len:500 episode reward: total was 6.770000. running mean: -13.453025\n",
      "ep 44: ep_len:560 episode reward: total was -3.460000. running mean: -13.353094\n",
      "ep 44: ep_len:1010 episode reward: total was 20.840000. running mean: -13.011164\n",
      "ep 44: ep_len:1340 episode reward: total was -95.340000. running mean: -13.834452\n",
      "ep 44: ep_len:1071 episode reward: total was -63.910000. running mean: -14.335207\n",
      "ep 44: ep_len:565 episode reward: total was -15.350000. running mean: -14.345355\n",
      "ep 44: ep_len:565 episode reward: total was -0.940000. running mean: -14.211302\n",
      "ep 44: ep_len:156 episode reward: total was 15.500000. running mean: -13.914189\n",
      "ep 44: ep_len:500 episode reward: total was 19.020000. running mean: -13.584847\n",
      "ep 44: ep_len:745 episode reward: total was -23.810000. running mean: -13.687098\n",
      "ep 44: ep_len:560 episode reward: total was -8.080000. running mean: -13.631027\n",
      "ep 44: ep_len:595 episode reward: total was -4.940000. running mean: -13.544117\n",
      "ep 44: ep_len:805 episode reward: total was 9.960000. running mean: -13.309076\n",
      "ep 44: ep_len:203 episode reward: total was 20.000000. running mean: -12.975985\n",
      "ep 44: ep_len:276 episode reward: total was 20.000000. running mean: -12.646225\n",
      "ep 44: ep_len:243 episode reward: total was 24.000000. running mean: -12.279763\n",
      "ep 44: ep_len:276 episode reward: total was 19.000000. running mean: -11.966965\n",
      "ep 44: ep_len:500 episode reward: total was 4.630000. running mean: -11.800996\n",
      "ep 44: ep_len:500 episode reward: total was 14.670000. running mean: -11.536286\n",
      "ep 44: ep_len:500 episode reward: total was 3.250000. running mean: -11.388423\n",
      "ep 44: ep_len:575 episode reward: total was 31.420000. running mean: -10.960339\n",
      "ep 44: ep_len:115 episode reward: total was 8.500000. running mean: -10.765735\n",
      "ep 44: ep_len:890 episode reward: total was -30.320000. running mean: -10.961278\n",
      "ep 44: ep_len:159 episode reward: total was 12.500000. running mean: -10.726665\n",
      "ep 44: ep_len:371 episode reward: total was 37.500000. running mean: -10.244399\n",
      "ep 44: ep_len:500 episode reward: total was -0.580000. running mean: -10.147755\n",
      "ep 44: ep_len:500 episode reward: total was 9.290000. running mean: -9.953377\n",
      "ep 44: ep_len:775 episode reward: total was -6.580000. running mean: -9.919643\n",
      "ep 44: ep_len:805 episode reward: total was -10.560000. running mean: -9.926047\n",
      "ep 44: ep_len:805 episode reward: total was 13.910000. running mean: -9.687686\n",
      "ep 44: ep_len:500 episode reward: total was 10.300000. running mean: -9.487810\n",
      "ep 44: ep_len:915 episode reward: total was 15.490000. running mean: -9.238031\n",
      "ep 44: ep_len:785 episode reward: total was -6.560000. running mean: -9.211251\n",
      "ep 44: ep_len:500 episode reward: total was 19.850000. running mean: -8.920639\n",
      "ep 44: ep_len:500 episode reward: total was 28.790000. running mean: -8.543532\n",
      "ep 44: ep_len:575 episode reward: total was -39.300000. running mean: -8.851097\n",
      "ep 44: ep_len:980 episode reward: total was -1.950000. running mean: -8.782086\n",
      "ep 44: ep_len:1830 episode reward: total was -280.750000. running mean: -11.501765\n",
      "ep 44: ep_len:1155 episode reward: total was 8.730000. running mean: -11.299447\n",
      "ep 44: ep_len:500 episode reward: total was 2.360000. running mean: -11.162853\n",
      "ep 44: ep_len:665 episode reward: total was -6.800000. running mean: -11.119224\n",
      "ep 44: ep_len:259 episode reward: total was 25.500000. running mean: -10.753032\n",
      "ep 44: ep_len:505 episode reward: total was -0.770000. running mean: -10.653202\n",
      "ep 44: ep_len:700 episode reward: total was -3.240000. running mean: -10.579070\n",
      "ep 44: ep_len:860 episode reward: total was 1.250000. running mean: -10.460779\n",
      "ep 44: ep_len:520 episode reward: total was -3.050000. running mean: -10.386671\n",
      "ep 44: ep_len:315 episode reward: total was -60.490000. running mean: -10.887705\n",
      "ep 44: ep_len:500 episode reward: total was 27.880000. running mean: -10.500028\n",
      "ep 44: ep_len:500 episode reward: total was 5.880000. running mean: -10.336227\n",
      "ep 44: ep_len:286 episode reward: total was 27.000000. running mean: -9.962865\n",
      "ep 44: ep_len:2025 episode reward: total was -206.060000. running mean: -11.923836\n",
      "ep 44: ep_len:1035 episode reward: total was -73.730000. running mean: -12.541898\n",
      "ep 44: ep_len:830 episode reward: total was -29.700000. running mean: -12.713479\n",
      "ep 44: ep_len:1480 episode reward: total was -190.670000. running mean: -14.493044\n",
      "ep 44: ep_len:737 episode reward: total was -50.070000. running mean: -14.848814\n",
      "ep 44: ep_len:500 episode reward: total was 31.300000. running mean: -14.387326\n",
      "ep 44: ep_len:965 episode reward: total was -151.620000. running mean: -15.759652\n",
      "ep 44: ep_len:760 episode reward: total was -31.860000. running mean: -15.920656\n",
      "ep 44: ep_len:530 episode reward: total was -63.630000. running mean: -16.397749\n",
      "ep 44: ep_len:257 episode reward: total was 25.500000. running mean: -15.978772\n",
      "ep 44: ep_len:585 episode reward: total was -17.060000. running mean: -15.989584\n",
      "ep 44: ep_len:500 episode reward: total was 24.930000. running mean: -15.580388\n",
      "ep 44: ep_len:1030 episode reward: total was -7.410000. running mean: -15.498684\n",
      "ep 44: ep_len:500 episode reward: total was 15.870000. running mean: -15.184998\n",
      "ep 44: ep_len:500 episode reward: total was 27.360000. running mean: -14.759548\n",
      "ep 44: ep_len:690 episode reward: total was -1.700000. running mean: -14.628952\n",
      "ep 44: ep_len:525 episode reward: total was -5.060000. running mean: -14.533263\n",
      "ep 44: ep_len:540 episode reward: total was -7.110000. running mean: -14.459030\n",
      "ep 44: ep_len:500 episode reward: total was 14.180000. running mean: -14.172640\n",
      "ep 44: ep_len:500 episode reward: total was -8.750000. running mean: -14.118413\n",
      "ep 44: ep_len:500 episode reward: total was 7.260000. running mean: -13.904629\n",
      "ep 44: ep_len:603 episode reward: total was -1.190000. running mean: -13.777483\n",
      "ep 44: ep_len:705 episode reward: total was 32.200000. running mean: -13.317708\n",
      "ep 44: ep_len:555 episode reward: total was -15.100000. running mean: -13.335531\n",
      "ep 44: ep_len:750 episode reward: total was 33.490000. running mean: -12.867276\n",
      "ep 44: ep_len:500 episode reward: total was 4.200000. running mean: -12.696603\n",
      "ep 44: ep_len:500 episode reward: total was 17.110000. running mean: -12.398537\n",
      "ep 44: ep_len:610 episode reward: total was -6.910000. running mean: -12.343651\n",
      "ep 44: ep_len:630 episode reward: total was 11.380000. running mean: -12.106415\n",
      "ep 44: ep_len:500 episode reward: total was 8.120000. running mean: -11.904151\n",
      "ep 44: ep_len:670 episode reward: total was 1.230000. running mean: -11.772809\n",
      "ep 44: ep_len:145 episode reward: total was 13.000000. running mean: -11.525081\n",
      "ep 44: ep_len:650 episode reward: total was 1.610000. running mean: -11.393730\n",
      "ep 44: ep_len:1180 episode reward: total was -18.280000. running mean: -11.462593\n",
      "ep 44: ep_len:286 episode reward: total was -49.500000. running mean: -11.842967\n",
      "ep 44: ep_len:500 episode reward: total was 25.820000. running mean: -11.466337\n",
      "ep 44: ep_len:500 episode reward: total was 30.350000. running mean: -11.048174\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 44: ep_len:500 episode reward: total was -5.750000. running mean: -10.995192\n",
      "ep 44: ep_len:500 episode reward: total was 10.030000. running mean: -10.784940\n",
      "ep 44: ep_len:1222 episode reward: total was -113.570000. running mean: -11.812791\n",
      "ep 44: ep_len:725 episode reward: total was 16.540000. running mean: -11.529263\n",
      "ep 44: ep_len:2065 episode reward: total was -217.110000. running mean: -13.585070\n",
      "ep 44: ep_len:500 episode reward: total was 21.840000. running mean: -13.230820\n",
      "ep 44: ep_len:755 episode reward: total was -13.660000. running mean: -13.235112\n",
      "ep 44: ep_len:1790 episode reward: total was -61.760000. running mean: -13.720360\n",
      "ep 44: ep_len:500 episode reward: total was -4.590000. running mean: -13.629057\n",
      "ep 44: ep_len:690 episode reward: total was -7.360000. running mean: -13.566366\n",
      "ep 44: ep_len:685 episode reward: total was -1.710000. running mean: -13.447803\n",
      "ep 44: ep_len:371 episode reward: total was 17.000000. running mean: -13.143325\n",
      "ep 44: ep_len:500 episode reward: total was 8.700000. running mean: -12.924891\n",
      "ep 44: ep_len:1440 episode reward: total was -108.240000. running mean: -13.878042\n",
      "ep 44: ep_len:500 episode reward: total was 7.750000. running mean: -13.661762\n",
      "ep 44: ep_len:500 episode reward: total was 48.500000. running mean: -13.040144\n",
      "ep 44: ep_len:795 episode reward: total was -13.610000. running mean: -13.045843\n",
      "ep 44: ep_len:1015 episode reward: total was -0.930000. running mean: -12.924685\n",
      "ep 44: ep_len:500 episode reward: total was 20.860000. running mean: -12.586838\n",
      "ep 44: ep_len:358 episode reward: total was 35.000000. running mean: -12.110969\n",
      "ep 44: ep_len:760 episode reward: total was -3.580000. running mean: -12.025660\n",
      "ep 44: ep_len:1010 episode reward: total was -0.160000. running mean: -11.907003\n",
      "ep 44: ep_len:500 episode reward: total was -12.480000. running mean: -11.912733\n",
      "ep 44: ep_len:545 episode reward: total was 7.320000. running mean: -11.720406\n",
      "ep 44: ep_len:1180 episode reward: total was 3.550000. running mean: -11.567702\n",
      "ep 44: ep_len:900 episode reward: total was 8.670000. running mean: -11.365325\n",
      "ep 44: ep_len:248 episode reward: total was 14.000000. running mean: -11.111671\n",
      "ep 44: ep_len:1220 episode reward: total was 7.790000. running mean: -10.922655\n",
      "ep 44: ep_len:1226 episode reward: total was -113.960000. running mean: -11.953028\n",
      "ep 44: ep_len:277 episode reward: total was 27.500000. running mean: -11.558498\n",
      "ep 44: ep_len:500 episode reward: total was 22.390000. running mean: -11.219013\n",
      "ep 44: ep_len:500 episode reward: total was 6.130000. running mean: -11.045523\n",
      "ep 44: ep_len:905 episode reward: total was -17.430000. running mean: -11.109367\n",
      "ep 44: ep_len:600 episode reward: total was 8.840000. running mean: -10.909874\n",
      "ep 44: ep_len:885 episode reward: total was -13.630000. running mean: -10.937075\n",
      "ep 44: ep_len:421 episode reward: total was 7.290000. running mean: -10.754804\n",
      "ep 44: ep_len:345 episode reward: total was 30.000000. running mean: -10.347256\n",
      "ep 44: ep_len:620 episode reward: total was -38.770000. running mean: -10.631484\n",
      "ep 44: ep_len:1050 episode reward: total was -72.690000. running mean: -11.252069\n",
      "ep 44: ep_len:1485 episode reward: total was -146.560000. running mean: -12.605148\n",
      "ep 44: ep_len:500 episode reward: total was 18.780000. running mean: -12.291297\n",
      "ep 44: ep_len:1014 episode reward: total was -87.380000. running mean: -13.042184\n",
      "ep 44: ep_len:965 episode reward: total was -6.970000. running mean: -12.981462\n",
      "ep 44: ep_len:500 episode reward: total was 21.870000. running mean: -12.632947\n",
      "ep 44: ep_len:1085 episode reward: total was 4.700000. running mean: -12.459618\n",
      "ep 44: ep_len:1760 episode reward: total was -110.660000. running mean: -13.441622\n",
      "ep 44: ep_len:520 episode reward: total was -35.430000. running mean: -13.661505\n",
      "ep 44: ep_len:500 episode reward: total was 15.930000. running mean: -13.365590\n",
      "ep 44: ep_len:781 episode reward: total was -14.190000. running mean: -13.373834\n",
      "ep 44: ep_len:500 episode reward: total was 23.280000. running mean: -13.007296\n",
      "ep 44: ep_len:670 episode reward: total was -40.120000. running mean: -13.278423\n",
      "ep 44: ep_len:199 episode reward: total was 19.500000. running mean: -12.950639\n",
      "ep 44: ep_len:500 episode reward: total was -4.400000. running mean: -12.865133\n",
      "ep 44: ep_len:665 episode reward: total was -71.440000. running mean: -13.450881\n",
      "ep 44: ep_len:1215 episode reward: total was 26.090000. running mean: -13.055472\n",
      "ep 44: ep_len:755 episode reward: total was -8.640000. running mean: -13.011318\n",
      "ep 44: ep_len:555 episode reward: total was -28.230000. running mean: -13.163504\n",
      "ep 44: ep_len:710 episode reward: total was -35.970000. running mean: -13.391569\n",
      "ep 44: ep_len:880 episode reward: total was -11.910000. running mean: -13.376754\n",
      "ep 44: ep_len:368 episode reward: total was 32.000000. running mean: -12.922986\n",
      "ep 44: ep_len:500 episode reward: total was 34.740000. running mean: -12.446356\n",
      "ep 44: ep_len:665 episode reward: total was -21.240000. running mean: -12.534293\n",
      "ep 44: ep_len:421 episode reward: total was 42.000000. running mean: -11.988950\n",
      "ep 44: ep_len:500 episode reward: total was -20.750000. running mean: -12.076560\n",
      "ep 44: ep_len:695 episode reward: total was 28.050000. running mean: -11.675295\n",
      "ep 44: ep_len:760 episode reward: total was -4.590000. running mean: -11.604442\n",
      "ep 44: ep_len:1207 episode reward: total was -115.350000. running mean: -12.641897\n",
      "ep 44: ep_len:500 episode reward: total was 20.250000. running mean: -12.312978\n",
      "ep 44: ep_len:500 episode reward: total was 25.300000. running mean: -11.936849\n",
      "ep 44: ep_len:605 episode reward: total was 26.350000. running mean: -11.553980\n",
      "ep 44: ep_len:850 episode reward: total was -18.140000. running mean: -11.619840\n",
      "ep 44: ep_len:695 episode reward: total was -0.680000. running mean: -11.510442\n",
      "ep 44: ep_len:500 episode reward: total was 20.340000. running mean: -11.191938\n",
      "ep 44: ep_len:500 episode reward: total was 13.480000. running mean: -10.945218\n",
      "ep 44: ep_len:1318 episode reward: total was -184.660000. running mean: -12.682366\n",
      "ep 44: ep_len:1925 episode reward: total was -268.610000. running mean: -15.241642\n",
      "ep 44: ep_len:500 episode reward: total was 12.320000. running mean: -14.966026\n",
      "ep 44: ep_len:545 episode reward: total was -18.150000. running mean: -14.997866\n",
      "ep 44: ep_len:685 episode reward: total was 32.350000. running mean: -14.524387\n",
      "ep 44: ep_len:1465 episode reward: total was -174.680000. running mean: -16.125943\n",
      "ep 44: ep_len:321 episode reward: total was 32.000000. running mean: -15.644684\n",
      "ep 44: ep_len:500 episode reward: total was 10.570000. running mean: -15.382537\n",
      "ep 44: ep_len:940 episode reward: total was -35.540000. running mean: -15.584111\n",
      "ep 44: ep_len:700 episode reward: total was -25.360000. running mean: -15.681870\n",
      "ep 44: ep_len:500 episode reward: total was -7.680000. running mean: -15.601852\n",
      "ep 44: ep_len:1030 episode reward: total was -134.340000. running mean: -16.789233\n",
      "ep 44: ep_len:500 episode reward: total was 23.890000. running mean: -16.382441\n",
      "ep 44: ep_len:1245 episode reward: total was -181.870000. running mean: -18.037316\n",
      "ep 44: ep_len:645 episode reward: total was 0.820000. running mean: -17.848743\n",
      "ep 44: ep_len:505 episode reward: total was 24.350000. running mean: -17.426756\n",
      "ep 44: ep_len:545 episode reward: total was -0.980000. running mean: -17.262288\n",
      "ep 44: ep_len:500 episode reward: total was 1.090000. running mean: -17.078765\n",
      "ep 44: ep_len:500 episode reward: total was 15.380000. running mean: -16.754178\n",
      "ep 44: ep_len:835 episode reward: total was -1.530000. running mean: -16.601936\n",
      "ep 44: ep_len:785 episode reward: total was -32.820000. running mean: -16.764117\n",
      "ep 44: ep_len:795 episode reward: total was 16.980000. running mean: -16.426675\n",
      "ep 44: ep_len:3165 episode reward: total was -631.000000. running mean: -22.572409\n",
      "ep 44: ep_len:179 episode reward: total was 17.500000. running mean: -22.171685\n",
      "ep 44: ep_len:745 episode reward: total was 26.370000. running mean: -21.686268\n",
      "ep 44: ep_len:985 episode reward: total was -5.240000. running mean: -21.521805\n",
      "ep 44: ep_len:500 episode reward: total was 20.250000. running mean: -21.104087\n",
      "ep 44: ep_len:11210 episode reward: total was -2090.080000. running mean: -41.793846\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 44: ep_len:760 episode reward: total was -37.400000. running mean: -41.749908\n",
      "ep 44: ep_len:1240 episode reward: total was 10.160000. running mean: -41.230809\n",
      "ep 44: ep_len:610 episode reward: total was -20.040000. running mean: -41.018900\n",
      "ep 44: ep_len:500 episode reward: total was 17.180000. running mean: -40.436911\n",
      "ep 44: ep_len:474 episode reward: total was 10.640000. running mean: -39.926142\n",
      "ep 44: ep_len:1090 episode reward: total was -39.300000. running mean: -39.919881\n",
      "ep 44: ep_len:910 episode reward: total was 12.020000. running mean: -39.400482\n",
      "ep 44: ep_len:500 episode reward: total was -7.680000. running mean: -39.083277\n",
      "ep 44: ep_len:810 episode reward: total was -96.400000. running mean: -39.656445\n",
      "ep 44: ep_len:500 episode reward: total was -14.930000. running mean: -39.409180\n",
      "ep 44: ep_len:500 episode reward: total was 9.380000. running mean: -38.921288\n",
      "ep 44: ep_len:1965 episode reward: total was -293.270000. running mean: -41.464775\n",
      "ep 44: ep_len:585 episode reward: total was -20.090000. running mean: -41.251028\n",
      "ep 44: ep_len:1836 episode reward: total was -283.740000. running mean: -43.675917\n",
      "ep 44: ep_len:780 episode reward: total was -57.560000. running mean: -43.814758\n",
      "ep 44: ep_len:595 episode reward: total was -30.950000. running mean: -43.686111\n",
      "ep 44: ep_len:500 episode reward: total was 6.200000. running mean: -43.187250\n",
      "ep 44: ep_len:765 episode reward: total was -50.030000. running mean: -43.255677\n",
      "ep 44: ep_len:655 episode reward: total was 5.500000. running mean: -42.768120\n",
      "ep 44: ep_len:975 episode reward: total was -53.210000. running mean: -42.872539\n",
      "ep 44: ep_len:197 episode reward: total was 19.500000. running mean: -42.248814\n",
      "ep 44: ep_len:500 episode reward: total was 20.750000. running mean: -41.618826\n",
      "ep 44: ep_len:500 episode reward: total was 4.750000. running mean: -41.155137\n",
      "ep 44: ep_len:935 episode reward: total was -79.990000. running mean: -41.543486\n",
      "ep 44: ep_len:1215 episode reward: total was -191.540000. running mean: -43.043451\n",
      "ep 44: ep_len:500 episode reward: total was 2.490000. running mean: -42.588117\n",
      "ep 44: ep_len:264 episode reward: total was 15.500000. running mean: -42.007235\n",
      "ep 44: ep_len:515 episode reward: total was -9.120000. running mean: -41.678363\n",
      "ep 44: ep_len:500 episode reward: total was 18.720000. running mean: -41.074379\n",
      "ep 44: ep_len:895 episode reward: total was 5.100000. running mean: -40.612636\n",
      "ep 44: ep_len:570 episode reward: total was -12.740000. running mean: -40.333909\n",
      "ep 44: ep_len:615 episode reward: total was -32.150000. running mean: -40.252070\n",
      "ep 44: ep_len:1455 episode reward: total was -84.000000. running mean: -40.689549\n",
      "ep 44: ep_len:500 episode reward: total was -5.380000. running mean: -40.336454\n",
      "ep 44: ep_len:720 episode reward: total was -34.450000. running mean: -40.277589\n",
      "ep 44: ep_len:2100 episode reward: total was -275.350000. running mean: -42.628314\n",
      "ep 44: ep_len:705 episode reward: total was -20.700000. running mean: -42.409030\n",
      "ep 44: ep_len:500 episode reward: total was 9.160000. running mean: -41.893340\n",
      "ep 44: ep_len:500 episode reward: total was 12.050000. running mean: -41.353907\n",
      "ep 44: ep_len:1450 episode reward: total was -150.670000. running mean: -42.447068\n",
      "ep 44: ep_len:630 episode reward: total was -2.480000. running mean: -42.047397\n",
      "ep 44: ep_len:1894 episode reward: total was -220.090000. running mean: -43.827823\n",
      "ep 44: ep_len:965 episode reward: total was -71.850000. running mean: -44.108045\n",
      "ep 44: ep_len:500 episode reward: total was 5.950000. running mean: -43.607464\n",
      "ep 44: ep_len:500 episode reward: total was -57.720000. running mean: -43.748590\n",
      "ep 44: ep_len:745 episode reward: total was -2.200000. running mean: -43.333104\n",
      "ep 44: ep_len:595 episode reward: total was -15.810000. running mean: -43.057873\n",
      "ep 44: ep_len:390 episode reward: total was -21.740000. running mean: -42.844694\n",
      "ep 44: ep_len:500 episode reward: total was -1.280000. running mean: -42.429047\n",
      "ep 44: ep_len:755 episode reward: total was -8.120000. running mean: -42.085957\n",
      "ep 44: ep_len:500 episode reward: total was -28.520000. running mean: -41.950297\n",
      "ep 44: ep_len:160 episode reward: total was 14.500000. running mean: -41.385794\n",
      "ep 44: ep_len:500 episode reward: total was 12.010000. running mean: -40.851836\n",
      "ep 44: ep_len:540 episode reward: total was 14.820000. running mean: -40.295118\n",
      "ep 44: ep_len:515 episode reward: total was 12.440000. running mean: -39.767767\n",
      "ep 44: ep_len:510 episode reward: total was 4.280000. running mean: -39.327289\n",
      "ep 44: ep_len:740 episode reward: total was 1.800000. running mean: -38.916016\n",
      "ep 44: ep_len:500 episode reward: total was -5.470000. running mean: -38.581556\n",
      "ep 44: ep_len:2281 episode reward: total was -328.770000. running mean: -41.483440\n",
      "ep 44: ep_len:760 episode reward: total was -71.250000. running mean: -41.781106\n",
      "ep 44: ep_len:500 episode reward: total was 11.400000. running mean: -41.249295\n",
      "ep 44: ep_len:500 episode reward: total was 13.910000. running mean: -40.697702\n",
      "ep 44: ep_len:264 episode reward: total was 26.000000. running mean: -40.030725\n",
      "ep 44: ep_len:570 episode reward: total was 26.790000. running mean: -39.362518\n",
      "ep 44: ep_len:121 episode reward: total was 12.000000. running mean: -38.848892\n",
      "ep 44: ep_len:465 episode reward: total was 13.700000. running mean: -38.323403\n",
      "ep 44: ep_len:775 episode reward: total was -12.640000. running mean: -38.066569\n",
      "ep 44: ep_len:915 episode reward: total was 17.020000. running mean: -37.515704\n",
      "ep 44: ep_len:176 episode reward: total was 17.500000. running mean: -36.965547\n",
      "ep 44: ep_len:500 episode reward: total was 20.620000. running mean: -36.389691\n",
      "ep 44: ep_len:610 episode reward: total was -36.720000. running mean: -36.392994\n",
      "ep 44: ep_len:224 episode reward: total was 22.000000. running mean: -35.809064\n",
      "ep 44: ep_len:1345 episode reward: total was -174.110000. running mean: -37.192074\n",
      "ep 44: ep_len:212 episode reward: total was 21.000000. running mean: -36.610153\n",
      "ep 44: ep_len:500 episode reward: total was -12.970000. running mean: -36.373751\n",
      "ep 44: ep_len:500 episode reward: total was -4.550000. running mean: -36.055514\n",
      "ep 44: ep_len:500 episode reward: total was 15.200000. running mean: -35.542959\n",
      "ep 44: ep_len:196 episode reward: total was 18.000000. running mean: -35.007529\n",
      "ep 44: ep_len:500 episode reward: total was 0.410000. running mean: -34.653354\n",
      "ep 44: ep_len:745 episode reward: total was -33.910000. running mean: -34.645920\n",
      "ep 44: ep_len:226 episode reward: total was 22.500000. running mean: -34.074461\n",
      "ep 44: ep_len:500 episode reward: total was 8.240000. running mean: -33.651317\n",
      "ep 44: ep_len:750 episode reward: total was -16.730000. running mean: -33.482103\n",
      "ep 44: ep_len:580 episode reward: total was 11.320000. running mean: -33.034082\n",
      "ep 44: ep_len:500 episode reward: total was 17.800000. running mean: -32.525742\n",
      "ep 44: ep_len:510 episode reward: total was 9.030000. running mean: -32.110184\n",
      "ep 44: ep_len:500 episode reward: total was 27.730000. running mean: -31.511782\n",
      "ep 44: ep_len:840 episode reward: total was -30.690000. running mean: -31.503564\n",
      "ep 44: ep_len:1005 episode reward: total was 10.210000. running mean: -31.086429\n",
      "ep 44: ep_len:500 episode reward: total was 15.910000. running mean: -30.616465\n",
      "ep 44: ep_len:505 episode reward: total was 21.760000. running mean: -30.092700\n",
      "ep 44: ep_len:500 episode reward: total was 5.780000. running mean: -29.733973\n",
      "ep 44: ep_len:500 episode reward: total was 21.810000. running mean: -29.218533\n",
      "ep 44: ep_len:500 episode reward: total was -19.050000. running mean: -29.116848\n",
      "ep 44: ep_len:157 episode reward: total was 15.500000. running mean: -28.670679\n",
      "ep 44: ep_len:725 episode reward: total was -31.930000. running mean: -28.703273\n",
      "ep 44: ep_len:720 episode reward: total was 22.290000. running mean: -28.193340\n",
      "ep 44: ep_len:500 episode reward: total was 12.110000. running mean: -27.790306\n",
      "ep 44: ep_len:1450 episode reward: total was -181.980000. running mean: -29.332203\n",
      "ep 44: ep_len:610 episode reward: total was -73.170000. running mean: -29.770581\n",
      "ep 44: ep_len:985 episode reward: total was 22.840000. running mean: -29.244476\n",
      "ep 44: ep_len:245 episode reward: total was 23.000000. running mean: -28.722031\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 44: ep_len:500 episode reward: total was -20.950000. running mean: -28.644310\n",
      "ep 44: ep_len:705 episode reward: total was -23.890000. running mean: -28.596767\n",
      "ep 44: ep_len:500 episode reward: total was 9.650000. running mean: -28.214300\n",
      "ep 44: ep_len:297 episode reward: total was 29.500000. running mean: -27.637157\n",
      "ep 44: ep_len:500 episode reward: total was 6.770000. running mean: -27.293085\n",
      "ep 44: ep_len:500 episode reward: total was 45.500000. running mean: -26.565154\n",
      "ep 44: ep_len:505 episode reward: total was -1.180000. running mean: -26.311303\n",
      "ep 44: ep_len:675 episode reward: total was 27.700000. running mean: -25.771190\n",
      "ep 44: ep_len:500 episode reward: total was 32.770000. running mean: -25.185778\n",
      "ep 44: ep_len:530 episode reward: total was -18.180000. running mean: -25.115720\n",
      "ep 44: ep_len:640 episode reward: total was -6.850000. running mean: -24.933063\n",
      "ep 44: ep_len:1040 episode reward: total was 19.390000. running mean: -24.489832\n",
      "ep 44: ep_len:500 episode reward: total was -9.670000. running mean: -24.341634\n",
      "ep 44: ep_len:500 episode reward: total was -7.920000. running mean: -24.177418\n",
      "ep 44: ep_len:930 episode reward: total was -38.590000. running mean: -24.321543\n",
      "ep 44: ep_len:885 episode reward: total was 3.410000. running mean: -24.044228\n",
      "ep 44: ep_len:665 episode reward: total was -31.370000. running mean: -24.117486\n",
      "ep 44: ep_len:278 episode reward: total was 12.230000. running mean: -23.754011\n",
      "ep 44: ep_len:615 episode reward: total was -17.000000. running mean: -23.686471\n",
      "ep 44: ep_len:213 episode reward: total was 21.000000. running mean: -23.239606\n",
      "ep 44: ep_len:500 episode reward: total was 15.500000. running mean: -22.852210\n",
      "ep 44: ep_len:500 episode reward: total was 13.370000. running mean: -22.489988\n",
      "ep 44: ep_len:220 episode reward: total was 19.000000. running mean: -22.075088\n",
      "ep 44: ep_len:795 episode reward: total was 10.730000. running mean: -21.747037\n",
      "ep 44: ep_len:500 episode reward: total was 21.840000. running mean: -21.311167\n",
      "ep 44: ep_len:500 episode reward: total was 48.500000. running mean: -20.613055\n",
      "ep 44: ep_len:785 episode reward: total was 4.220000. running mean: -20.364724\n",
      "ep 44: ep_len:745 episode reward: total was -4.620000. running mean: -20.207277\n",
      "ep 44: ep_len:820 episode reward: total was 11.570000. running mean: -19.889504\n",
      "ep 44: ep_len:635 episode reward: total was -10.900000. running mean: -19.799609\n",
      "ep 44: ep_len:835 episode reward: total was -9.490000. running mean: -19.696513\n",
      "ep 44: ep_len:500 episode reward: total was -12.180000. running mean: -19.621348\n",
      "ep 44: ep_len:500 episode reward: total was -12.970000. running mean: -19.554835\n",
      "ep 44: ep_len:500 episode reward: total was 33.750000. running mean: -19.021786\n",
      "ep 44: ep_len:500 episode reward: total was 12.140000. running mean: -18.710169\n",
      "ep 44: ep_len:500 episode reward: total was 23.980000. running mean: -18.283267\n",
      "ep 44: ep_len:500 episode reward: total was -5.170000. running mean: -18.152134\n",
      "ep 44: ep_len:540 episode reward: total was 2.630000. running mean: -17.944313\n",
      "ep 44: ep_len:930 episode reward: total was 7.940000. running mean: -17.685470\n",
      "ep 44: ep_len:860 episode reward: total was 6.990000. running mean: -17.438715\n",
      "ep 44: ep_len:695 episode reward: total was -8.760000. running mean: -17.351928\n",
      "ep 44: ep_len:500 episode reward: total was 5.270000. running mean: -17.125709\n",
      "ep 44: ep_len:637 episode reward: total was -39.180000. running mean: -17.346251\n",
      "ep 44: ep_len:500 episode reward: total was 24.960000. running mean: -16.923189\n",
      "ep 44: ep_len:1256 episode reward: total was 32.380000. running mean: -16.430157\n",
      "ep 44: ep_len:500 episode reward: total was 17.030000. running mean: -16.095555\n",
      "ep 44: ep_len:500 episode reward: total was 2.120000. running mean: -15.913400\n",
      "ep 44: ep_len:1100 episode reward: total was -6.520000. running mean: -15.819466\n",
      "ep 44: ep_len:172 episode reward: total was 17.000000. running mean: -15.491271\n",
      "ep 44: ep_len:303 episode reward: total was 19.720000. running mean: -15.139159\n",
      "ep 44: ep_len:690 episode reward: total was 0.320000. running mean: -14.984567\n",
      "ep 44: ep_len:1290 episode reward: total was -113.620000. running mean: -15.970921\n",
      "ep 44: ep_len:535 episode reward: total was -34.820000. running mean: -16.159412\n",
      "ep 44: ep_len:660 episode reward: total was -19.170000. running mean: -16.189518\n",
      "ep 44: ep_len:915 episode reward: total was 5.280000. running mean: -15.974823\n",
      "ep 44: ep_len:1130 episode reward: total was 11.350000. running mean: -15.701575\n",
      "ep 44: ep_len:500 episode reward: total was 1.300000. running mean: -15.531559\n",
      "ep 44: ep_len:891 episode reward: total was -106.310000. running mean: -16.439343\n",
      "ep 44: ep_len:620 episode reward: total was -1.840000. running mean: -16.293350\n",
      "ep 44: ep_len:785 episode reward: total was 15.180000. running mean: -15.978616\n",
      "ep 44: ep_len:500 episode reward: total was 19.240000. running mean: -15.626430\n",
      "ep 44: ep_len:188 episode reward: total was 17.000000. running mean: -15.300166\n",
      "ep 44: ep_len:800 episode reward: total was -10.570000. running mean: -15.252864\n",
      "ep 44: ep_len:219 episode reward: total was 20.000000. running mean: -14.900336\n",
      "ep 44: ep_len:790 episode reward: total was 2.390000. running mean: -14.727432\n",
      "ep 44: ep_len:570 episode reward: total was -34.380000. running mean: -14.923958\n",
      "ep 44: ep_len:695 episode reward: total was -7.720000. running mean: -14.851918\n",
      "ep 44: ep_len:500 episode reward: total was -14.500000. running mean: -14.848399\n",
      "ep 44: ep_len:620 episode reward: total was -29.040000. running mean: -14.990315\n",
      "ep 44: ep_len:1045 episode reward: total was 11.800000. running mean: -14.722412\n",
      "ep 44: ep_len:500 episode reward: total was 18.990000. running mean: -14.385288\n",
      "ep 44: ep_len:995 episode reward: total was -29.030000. running mean: -14.531735\n",
      "ep 44: ep_len:710 episode reward: total was -3.680000. running mean: -14.423218\n",
      "ep 44: ep_len:500 episode reward: total was 22.760000. running mean: -14.051385\n",
      "ep 44: ep_len:500 episode reward: total was -25.910000. running mean: -14.169972\n",
      "ep 44: ep_len:153 episode reward: total was 15.000000. running mean: -13.878272\n",
      "ep 44: ep_len:685 episode reward: total was 11.220000. running mean: -13.627289\n",
      "ep 44: ep_len:870 episode reward: total was 15.370000. running mean: -13.337316\n",
      "ep 44: ep_len:230 episode reward: total was -6.320000. running mean: -13.267143\n",
      "ep 44: ep_len:500 episode reward: total was 19.820000. running mean: -12.936272\n",
      "ep 44: ep_len:500 episode reward: total was -29.190000. running mean: -13.098809\n",
      "ep 44: ep_len:500 episode reward: total was 10.910000. running mean: -12.858721\n",
      "ep 44: ep_len:1105 episode reward: total was 23.740000. running mean: -12.492734\n",
      "ep 44: ep_len:500 episode reward: total was -4.860000. running mean: -12.416406\n",
      "ep 44: ep_len:705 episode reward: total was -8.740000. running mean: -12.379642\n",
      "ep 44: ep_len:595 episode reward: total was 0.260000. running mean: -12.253246\n",
      "ep 44: ep_len:620 episode reward: total was 1.320000. running mean: -12.117513\n",
      "ep 44: ep_len:500 episode reward: total was -1.070000. running mean: -12.007038\n",
      "ep 44: ep_len:720 episode reward: total was -10.700000. running mean: -11.993968\n",
      "ep 44: ep_len:269 episode reward: total was 25.000000. running mean: -11.624028\n",
      "ep 44: ep_len:620 episode reward: total was -0.830000. running mean: -11.516088\n",
      "ep 44: ep_len:137 episode reward: total was 12.000000. running mean: -11.280927\n",
      "ep 44: ep_len:500 episode reward: total was -16.250000. running mean: -11.330618\n",
      "ep 44: ep_len:90 episode reward: total was 6.000000. running mean: -11.157312\n",
      "ep 44: ep_len:695 episode reward: total was -38.050000. running mean: -11.426238\n",
      "ep 44: ep_len:500 episode reward: total was 18.750000. running mean: -11.124476\n",
      "ep 44: ep_len:157 episode reward: total was 15.500000. running mean: -10.858231\n",
      "ep 44: ep_len:1690 episode reward: total was -104.720000. running mean: -11.796849\n",
      "ep 44: ep_len:550 episode reward: total was -21.170000. running mean: -11.890581\n",
      "ep 44: ep_len:550 episode reward: total was 27.510000. running mean: -11.496575\n",
      "ep 44: ep_len:500 episode reward: total was -25.370000. running mean: -11.635309\n",
      "ep 44: ep_len:500 episode reward: total was 14.800000. running mean: -11.370956\n",
      "ep 44: ep_len:500 episode reward: total was 45.500000. running mean: -10.802246\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 44: ep_len:500 episode reward: total was -3.090000. running mean: -10.725124\n",
      "ep 44: ep_len:820 episode reward: total was 1.380000. running mean: -10.604073\n",
      "ep 44: ep_len:685 episode reward: total was -3.420000. running mean: -10.532232\n",
      "ep 44: ep_len:500 episode reward: total was 10.850000. running mean: -10.318410\n",
      "ep 44: ep_len:920 episode reward: total was 14.090000. running mean: -10.074325\n",
      "ep 44: ep_len:223 episode reward: total was 19.000000. running mean: -9.783582\n",
      "ep 44: ep_len:500 episode reward: total was 15.810000. running mean: -9.527646\n",
      "ep 44: ep_len:745 episode reward: total was -4.620000. running mean: -9.478570\n",
      "ep 44: ep_len:239 episode reward: total was 23.500000. running mean: -9.148784\n",
      "ep 44: ep_len:500 episode reward: total was 22.830000. running mean: -8.828996\n",
      "ep 44: ep_len:860 episode reward: total was -16.510000. running mean: -8.905806\n",
      "ep 44: ep_len:745 episode reward: total was -17.750000. running mean: -8.994248\n",
      "ep 44: ep_len:505 episode reward: total was -18.590000. running mean: -9.090206\n",
      "ep 44: ep_len:1010 episode reward: total was 13.320000. running mean: -8.866104\n",
      "ep 44: ep_len:500 episode reward: total was -9.240000. running mean: -8.869843\n",
      "ep 44: ep_len:640 episode reward: total was -4.830000. running mean: -8.829444\n",
      "ep 44: ep_len:500 episode reward: total was 24.780000. running mean: -8.493350\n",
      "ep 44: ep_len:500 episode reward: total was 9.010000. running mean: -8.318316\n",
      "ep 44: ep_len:500 episode reward: total was 27.810000. running mean: -7.957033\n",
      "ep 44: ep_len:178 episode reward: total was 17.500000. running mean: -7.702463\n",
      "ep 44: ep_len:766 episode reward: total was -123.740000. running mean: -8.862838\n",
      "ep 44: ep_len:640 episode reward: total was -1.800000. running mean: -8.792210\n",
      "ep 44: ep_len:235 episode reward: total was 20.500000. running mean: -8.499288\n",
      "ep 44: ep_len:810 episode reward: total was -29.220000. running mean: -8.706495\n",
      "ep 44: ep_len:500 episode reward: total was 47.000000. running mean: -8.149430\n",
      "ep 44: ep_len:251 episode reward: total was 25.000000. running mean: -7.817936\n",
      "ep 44: ep_len:725 episode reward: total was -1.630000. running mean: -7.756056\n",
      "ep 44: ep_len:469 episode reward: total was -22.000000. running mean: -7.898496\n",
      "ep 44: ep_len:284 episode reward: total was 17.500000. running mean: -7.644511\n",
      "ep 44: ep_len:640 episode reward: total was -26.040000. running mean: -7.828466\n",
      "ep 44: ep_len:570 episode reward: total was -19.110000. running mean: -7.941281\n",
      "ep 44: ep_len:605 episode reward: total was -41.800000. running mean: -8.279868\n",
      "ep 44: ep_len:1198 episode reward: total was -142.700000. running mean: -9.624070\n",
      "ep 44: ep_len:560 episode reward: total was -19.670000. running mean: -9.724529\n",
      "ep 44: ep_len:500 episode reward: total was 6.740000. running mean: -9.559884\n",
      "ep 44: ep_len:500 episode reward: total was 4.260000. running mean: -9.421685\n",
      "ep 44: ep_len:970 episode reward: total was -45.580000. running mean: -9.783268\n",
      "ep 44: ep_len:880 episode reward: total was 3.440000. running mean: -9.651035\n",
      "ep 44: ep_len:725 episode reward: total was -7.690000. running mean: -9.631425\n",
      "ep 44: ep_len:411 episode reward: total was 27.150000. running mean: -9.263611\n",
      "ep 44: ep_len:1410 episode reward: total was -72.020000. running mean: -9.891174\n",
      "ep 44: ep_len:500 episode reward: total was 22.300000. running mean: -9.569263\n",
      "ep 44: ep_len:500 episode reward: total was 2.310000. running mean: -9.450470\n",
      "ep 44: ep_len:941 episode reward: total was -99.150000. running mean: -10.347465\n",
      "ep 44: ep_len:430 episode reward: total was 10.340000. running mean: -10.140591\n",
      "ep 44: ep_len:500 episode reward: total was 29.380000. running mean: -9.745385\n",
      "ep 44: ep_len:500 episode reward: total was 26.800000. running mean: -9.379931\n",
      "ep 44: ep_len:982 episode reward: total was -90.740000. running mean: -10.193532\n",
      "ep 44: ep_len:500 episode reward: total was 6.500000. running mean: -10.026596\n",
      "ep 44: ep_len:615 episode reward: total was 8.720000. running mean: -9.839130\n",
      "ep 44: ep_len:705 episode reward: total was -58.720000. running mean: -10.327939\n",
      "ep 44: ep_len:46 episode reward: total was 4.500000. running mean: -10.179660\n",
      "ep 44: ep_len:610 episode reward: total was 25.810000. running mean: -9.819763\n",
      "ep 44: ep_len:500 episode reward: total was -6.640000. running mean: -9.787965\n",
      "ep 44: ep_len:500 episode reward: total was 4.140000. running mean: -9.648686\n",
      "ep 44: ep_len:500 episode reward: total was 10.480000. running mean: -9.447399\n",
      "ep 44: ep_len:1627 episode reward: total was -103.840000. running mean: -10.391325\n",
      "ep 44: ep_len:645 episode reward: total was -2.210000. running mean: -10.309512\n",
      "ep 44: ep_len:960 episode reward: total was -3.820000. running mean: -10.244617\n",
      "ep 44: ep_len:850 episode reward: total was -9.000000. running mean: -10.232170\n",
      "ep 44: ep_len:580 episode reward: total was -4.950000. running mean: -10.179349\n",
      "ep 44: ep_len:655 episode reward: total was -0.200000. running mean: -10.079555\n",
      "ep 44: ep_len:584 episode reward: total was -67.550000. running mean: -10.654260\n",
      "ep 44: ep_len:500 episode reward: total was 8.800000. running mean: -10.459717\n",
      "ep 44: ep_len:500 episode reward: total was 19.390000. running mean: -10.161220\n",
      "ep 44: ep_len:426 episode reward: total was 30.240000. running mean: -9.757208\n",
      "ep 44: ep_len:710 episode reward: total was -11.760000. running mean: -9.777236\n",
      "ep 44: ep_len:500 episode reward: total was -3.630000. running mean: -9.715763\n",
      "ep 44: ep_len:575 episode reward: total was -15.030000. running mean: -9.768906\n",
      "ep 44: ep_len:540 episode reward: total was 18.780000. running mean: -9.483417\n",
      "ep 44: ep_len:785 episode reward: total was -12.620000. running mean: -9.514782\n",
      "ep 44: ep_len:1073 episode reward: total was -124.140000. running mean: -10.661035\n",
      "ep 44: ep_len:590 episode reward: total was -7.960000. running mean: -10.634024\n",
      "ep 44: ep_len:555 episode reward: total was 3.060000. running mean: -10.497084\n",
      "ep 44: ep_len:500 episode reward: total was -2.410000. running mean: -10.416213\n",
      "ep 44: ep_len:770 episode reward: total was -2.550000. running mean: -10.337551\n",
      "ep 44: ep_len:138 episode reward: total was 6.000000. running mean: -10.174176\n",
      "ep 44: ep_len:500 episode reward: total was 11.830000. running mean: -9.954134\n",
      "ep 44: ep_len:725 episode reward: total was -7.660000. running mean: -9.931192\n",
      "ep 44: ep_len:500 episode reward: total was 30.810000. running mean: -9.523781\n",
      "ep 44: ep_len:715 episode reward: total was -13.770000. running mean: -9.566243\n",
      "ep 44: ep_len:500 episode reward: total was -0.390000. running mean: -9.474480\n",
      "ep 44: ep_len:805 episode reward: total was 16.460000. running mean: -9.215135\n",
      "ep 44: ep_len:540 episode reward: total was 29.910000. running mean: -8.823884\n",
      "ep 44: ep_len:510 episode reward: total was -6.100000. running mean: -8.796645\n",
      "ep 44: ep_len:505 episode reward: total was 0.350000. running mean: -8.705179\n",
      "ep 44: ep_len:159 episode reward: total was 15.500000. running mean: -8.463127\n",
      "ep 44: ep_len:530 episode reward: total was -3.030000. running mean: -8.408796\n",
      "ep 44: ep_len:456 episode reward: total was 24.810000. running mean: -8.076608\n",
      "ep 44: ep_len:500 episode reward: total was -58.700000. running mean: -8.582842\n",
      "ep 44: ep_len:535 episode reward: total was -14.130000. running mean: -8.638313\n",
      "ep 44: ep_len:184 episode reward: total was 16.500000. running mean: -8.386930\n",
      "ep 44: ep_len:500 episode reward: total was 24.810000. running mean: -8.054961\n",
      "ep 44: ep_len:2729 episode reward: total was -406.430000. running mean: -12.038711\n",
      "ep 44: ep_len:565 episode reward: total was 17.010000. running mean: -11.748224\n",
      "ep 44: ep_len:2745 episode reward: total was -444.130000. running mean: -16.072042\n",
      "ep 44: ep_len:915 episode reward: total was 17.660000. running mean: -15.734722\n",
      "ep 44: ep_len:5652 episode reward: total was -801.450000. running mean: -23.591874\n",
      "ep 44: ep_len:867 episode reward: total was -81.610000. running mean: -24.172056\n",
      "ep 44: ep_len:500 episode reward: total was -8.780000. running mean: -24.018135\n",
      "ep 44: ep_len:500 episode reward: total was 5.430000. running mean: -23.723654\n",
      "ep 44: ep_len:500 episode reward: total was -7.580000. running mean: -23.562217\n",
      "ep 44: ep_len:436 episode reward: total was 5.550000. running mean: -23.271095\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 44: ep_len:525 episode reward: total was 18.980000. running mean: -22.848584\n",
      "epsilon:0.010000 episode_count: 35502. steps_count: 25753213.000000\n",
      "ep 45: ep_len:500 episode reward: total was 25.270000. running mean: -22.367398\n",
      "ep 45: ep_len:1110 episode reward: total was -13.640000. running mean: -22.280124\n",
      "ep 45: ep_len:500 episode reward: total was 6.220000. running mean: -21.995123\n",
      "ep 45: ep_len:2619 episode reward: total was -377.590000. running mean: -25.551072\n",
      "ep 45: ep_len:1055 episode reward: total was -23.370000. running mean: -25.529261\n",
      "ep 45: ep_len:500 episode reward: total was 4.080000. running mean: -25.233168\n",
      "ep 45: ep_len:885 episode reward: total was -13.360000. running mean: -25.114437\n",
      "ep 45: ep_len:500 episode reward: total was 13.820000. running mean: -24.725092\n",
      "ep 45: ep_len:895 episode reward: total was -27.820000. running mean: -24.756041\n",
      "ep 45: ep_len:500 episode reward: total was 10.720000. running mean: -24.401281\n",
      "ep 45: ep_len:575 episode reward: total was -1.930000. running mean: -24.176568\n",
      "ep 45: ep_len:500 episode reward: total was 22.850000. running mean: -23.706302\n",
      "ep 45: ep_len:530 episode reward: total was -18.180000. running mean: -23.651039\n",
      "ep 45: ep_len:895 episode reward: total was -41.690000. running mean: -23.831429\n",
      "ep 45: ep_len:830 episode reward: total was -42.830000. running mean: -24.021415\n",
      "ep 45: ep_len:500 episode reward: total was 32.800000. running mean: -23.453201\n",
      "ep 45: ep_len:735 episode reward: total was 1.610000. running mean: -23.202569\n",
      "ep 45: ep_len:500 episode reward: total was 19.940000. running mean: -22.771143\n",
      "ep 45: ep_len:580 episode reward: total was -2.930000. running mean: -22.572732\n",
      "ep 45: ep_len:500 episode reward: total was -9.350000. running mean: -22.440504\n",
      "ep 45: ep_len:1425 episode reward: total was -59.820000. running mean: -22.814299\n",
      "ep 45: ep_len:985 episode reward: total was -42.520000. running mean: -23.011356\n",
      "ep 45: ep_len:2125 episode reward: total was -301.790000. running mean: -25.799143\n",
      "ep 45: ep_len:500 episode reward: total was 1.210000. running mean: -25.529051\n",
      "ep 45: ep_len:1712 episode reward: total was -164.070000. running mean: -26.914461\n",
      "ep 45: ep_len:515 episode reward: total was 13.630000. running mean: -26.509016\n",
      "ep 45: ep_len:500 episode reward: total was -10.830000. running mean: -26.352226\n",
      "ep 45: ep_len:500 episode reward: total was 23.430000. running mean: -25.854404\n",
      "ep 45: ep_len:540 episode reward: total was -8.060000. running mean: -25.676460\n",
      "ep 45: ep_len:820 episode reward: total was -10.690000. running mean: -25.526595\n",
      "ep 45: ep_len:500 episode reward: total was -0.150000. running mean: -25.272829\n",
      "ep 45: ep_len:500 episode reward: total was 28.240000. running mean: -24.737701\n",
      "ep 45: ep_len:1122 episode reward: total was -95.310000. running mean: -25.443424\n",
      "ep 45: ep_len:500 episode reward: total was 27.810000. running mean: -24.910890\n",
      "ep 45: ep_len:920 episode reward: total was 9.140000. running mean: -24.570381\n",
      "ep 45: ep_len:820 episode reward: total was 4.090000. running mean: -24.283777\n",
      "ep 45: ep_len:500 episode reward: total was -9.730000. running mean: -24.138239\n",
      "ep 45: ep_len:780 episode reward: total was -14.620000. running mean: -24.043057\n",
      "ep 45: ep_len:525 episode reward: total was 21.780000. running mean: -23.584826\n",
      "ep 45: ep_len:855 episode reward: total was 14.900000. running mean: -23.199978\n",
      "ep 45: ep_len:1255 episode reward: total was -204.160000. running mean: -25.009578\n",
      "ep 45: ep_len:555 episode reward: total was -40.350000. running mean: -25.162982\n",
      "ep 45: ep_len:900 episode reward: total was -10.070000. running mean: -25.012052\n",
      "ep 45: ep_len:500 episode reward: total was 11.870000. running mean: -24.643232\n",
      "ep 45: ep_len:725 episode reward: total was -16.780000. running mean: -24.564600\n",
      "ep 45: ep_len:985 episode reward: total was -32.220000. running mean: -24.641154\n",
      "ep 45: ep_len:835 episode reward: total was -4.170000. running mean: -24.436442\n",
      "ep 45: ep_len:200 episode reward: total was 17.000000. running mean: -24.022078\n",
      "ep 45: ep_len:800 episode reward: total was -85.740000. running mean: -24.639257\n",
      "ep 45: ep_len:500 episode reward: total was 14.250000. running mean: -24.250364\n",
      "ep 45: ep_len:595 episode reward: total was 16.250000. running mean: -23.845361\n",
      "ep 45: ep_len:865 episode reward: total was 17.270000. running mean: -23.434207\n",
      "ep 45: ep_len:107 episode reward: total was 10.500000. running mean: -23.094865\n",
      "ep 45: ep_len:497 episode reward: total was 5.110000. running mean: -22.812816\n",
      "ep 45: ep_len:735 episode reward: total was -5.650000. running mean: -22.641188\n",
      "ep 45: ep_len:500 episode reward: total was 8.180000. running mean: -22.332976\n",
      "ep 45: ep_len:1255 episode reward: total was -196.510000. running mean: -24.074747\n",
      "ep 45: ep_len:640 episode reward: total was -0.790000. running mean: -23.841899\n",
      "ep 45: ep_len:575 episode reward: total was -5.970000. running mean: -23.663180\n",
      "ep 45: ep_len:258 episode reward: total was 25.500000. running mean: -23.171548\n",
      "ep 45: ep_len:224 episode reward: total was -32.000000. running mean: -23.259833\n",
      "ep 45: ep_len:500 episode reward: total was 22.300000. running mean: -22.804234\n",
      "ep 45: ep_len:615 episode reward: total was 5.440000. running mean: -22.521792\n",
      "ep 45: ep_len:1130 episode reward: total was -29.100000. running mean: -22.587574\n",
      "ep 45: ep_len:560 episode reward: total was -0.950000. running mean: -22.371198\n",
      "ep 45: ep_len:500 episode reward: total was 15.290000. running mean: -21.994586\n",
      "ep 45: ep_len:640 episode reward: total was -9.850000. running mean: -21.873141\n",
      "ep 45: ep_len:665 episode reward: total was -6.800000. running mean: -21.722409\n",
      "ep 45: ep_len:900 episode reward: total was -9.620000. running mean: -21.601385\n",
      "ep 45: ep_len:825 episode reward: total was 21.060000. running mean: -21.174771\n",
      "ep 45: ep_len:665 episode reward: total was -64.270000. running mean: -21.605724\n",
      "ep 45: ep_len:550 episode reward: total was -40.360000. running mean: -21.793266\n",
      "ep 45: ep_len:500 episode reward: total was 24.810000. running mean: -21.327234\n",
      "ep 45: ep_len:846 episode reward: total was -89.260000. running mean: -22.006561\n",
      "ep 45: ep_len:630 episode reward: total was 12.920000. running mean: -21.657296\n",
      "ep 45: ep_len:730 episode reward: total was -17.780000. running mean: -21.618523\n",
      "ep 45: ep_len:1335 episode reward: total was -212.510000. running mean: -23.527438\n",
      "ep 45: ep_len:505 episode reward: total was 0.700000. running mean: -23.285163\n",
      "ep 45: ep_len:665 episode reward: total was -5.790000. running mean: -23.110212\n",
      "ep 45: ep_len:102 episode reward: total was 10.000000. running mean: -22.779109\n",
      "ep 45: ep_len:735 episode reward: total was 12.390000. running mean: -22.427418\n",
      "ep 45: ep_len:500 episode reward: total was 10.270000. running mean: -22.100444\n",
      "ep 45: ep_len:575 episode reward: total was -2.940000. running mean: -21.908840\n",
      "ep 45: ep_len:625 episode reward: total was 14.650000. running mean: -21.543251\n",
      "ep 45: ep_len:500 episode reward: total was 9.780000. running mean: -21.230019\n",
      "ep 45: ep_len:665 episode reward: total was -0.740000. running mean: -21.025119\n",
      "ep 45: ep_len:500 episode reward: total was 3.530000. running mean: -20.779567\n",
      "ep 45: ep_len:725 episode reward: total was 19.140000. running mean: -20.380372\n",
      "ep 45: ep_len:550 episode reward: total was -22.180000. running mean: -20.398368\n",
      "ep 45: ep_len:600 episode reward: total was 11.240000. running mean: -20.081984\n",
      "ep 45: ep_len:1535 episode reward: total was -233.700000. running mean: -22.218164\n",
      "ep 45: ep_len:505 episode reward: total was 0.820000. running mean: -21.987783\n",
      "ep 45: ep_len:925 episode reward: total was 19.550000. running mean: -21.572405\n",
      "ep 45: ep_len:500 episode reward: total was 22.300000. running mean: -21.133681\n",
      "ep 45: ep_len:500 episode reward: total was -5.320000. running mean: -20.975544\n",
      "ep 45: ep_len:805 episode reward: total was 8.150000. running mean: -20.684289\n",
      "ep 45: ep_len:500 episode reward: total was -1.590000. running mean: -20.493346\n",
      "ep 45: ep_len:1063 episode reward: total was -158.470000. running mean: -21.873112\n",
      "ep 45: ep_len:500 episode reward: total was 26.250000. running mean: -21.391881\n",
      "ep 45: ep_len:795 episode reward: total was -4.960000. running mean: -21.227562\n",
      "ep 45: ep_len:240 episode reward: total was 19.500000. running mean: -20.820287\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 45: ep_len:500 episode reward: total was -11.780000. running mean: -20.729884\n",
      "ep 45: ep_len:590 episode reward: total was -19.560000. running mean: -20.718185\n",
      "ep 45: ep_len:580 episode reward: total was -26.160000. running mean: -20.772603\n",
      "ep 45: ep_len:635 episode reward: total was -2.820000. running mean: -20.593077\n",
      "ep 45: ep_len:500 episode reward: total was -12.760000. running mean: -20.514746\n",
      "ep 45: ep_len:18955 episode reward: total was -3613.620000. running mean: -56.445799\n",
      "ep 45: ep_len:500 episode reward: total was 6.370000. running mean: -55.817641\n",
      "ep 45: ep_len:500 episode reward: total was 21.840000. running mean: -55.041065\n",
      "ep 45: ep_len:185 episode reward: total was 17.000000. running mean: -54.320654\n",
      "ep 45: ep_len:845 episode reward: total was -48.860000. running mean: -54.266047\n",
      "ep 45: ep_len:500 episode reward: total was -8.590000. running mean: -53.809287\n",
      "ep 45: ep_len:500 episode reward: total was -15.530000. running mean: -53.426494\n",
      "ep 45: ep_len:880 episode reward: total was -44.500000. running mean: -53.337229\n",
      "ep 45: ep_len:500 episode reward: total was 24.260000. running mean: -52.561257\n",
      "ep 45: ep_len:500 episode reward: total was -23.440000. running mean: -52.270044\n",
      "ep 45: ep_len:1943 episode reward: total was -347.630000. running mean: -55.223644\n",
      "ep 45: ep_len:730 episode reward: total was -9.950000. running mean: -54.770907\n",
      "ep 45: ep_len:750 episode reward: total was -28.850000. running mean: -54.511698\n",
      "ep 45: ep_len:865 episode reward: total was -48.300000. running mean: -54.449581\n",
      "ep 45: ep_len:720 episode reward: total was -38.000000. running mean: -54.285085\n",
      "ep 45: ep_len:780 episode reward: total was -18.690000. running mean: -53.929135\n",
      "ep 45: ep_len:119 episode reward: total was 11.500000. running mean: -53.274843\n",
      "ep 45: ep_len:500 episode reward: total was -28.320000. running mean: -53.025295\n",
      "ep 45: ep_len:860 episode reward: total was -38.730000. running mean: -52.882342\n",
      "ep 45: ep_len:775 episode reward: total was -38.900000. running mean: -52.742518\n",
      "ep 45: ep_len:500 episode reward: total was -31.580000. running mean: -52.530893\n",
      "ep 45: ep_len:620 episode reward: total was 25.300000. running mean: -51.752584\n",
      "ep 45: ep_len:2248 episode reward: total was -225.140000. running mean: -53.486459\n",
      "ep 45: ep_len:500 episode reward: total was -8.040000. running mean: -53.031994\n",
      "ep 45: ep_len:835 episode reward: total was -50.900000. running mean: -53.010674\n",
      "ep 45: ep_len:500 episode reward: total was -22.580000. running mean: -52.706367\n",
      "ep 45: ep_len:500 episode reward: total was 15.840000. running mean: -52.020904\n",
      "ep 45: ep_len:3045 episode reward: total was -479.230000. running mean: -56.292995\n",
      "ep 45: ep_len:500 episode reward: total was 26.280000. running mean: -55.467265\n",
      "ep 45: ep_len:890 episode reward: total was -0.540000. running mean: -54.917992\n",
      "ep 45: ep_len:2001 episode reward: total was -165.630000. running mean: -56.025112\n",
      "ep 45: ep_len:620 episode reward: total was -7.130000. running mean: -55.536161\n",
      "ep 45: ep_len:493 episode reward: total was 28.250000. running mean: -54.698299\n",
      "ep 45: ep_len:118 episode reward: total was 11.500000. running mean: -54.036316\n",
      "ep 45: ep_len:620 episode reward: total was -8.880000. running mean: -53.584753\n",
      "ep 45: ep_len:164 episode reward: total was 16.000000. running mean: -52.888906\n",
      "ep 45: ep_len:500 episode reward: total was 16.630000. running mean: -52.193717\n",
      "ep 45: ep_len:715 episode reward: total was -16.800000. running mean: -51.839779\n",
      "ep 45: ep_len:500 episode reward: total was 10.730000. running mean: -51.214082\n",
      "ep 45: ep_len:210 episode reward: total was 19.500000. running mean: -50.506941\n",
      "ep 45: ep_len:500 episode reward: total was 26.250000. running mean: -49.739371\n",
      "ep 45: ep_len:650 episode reward: total was -5.300000. running mean: -49.294978\n",
      "ep 45: ep_len:500 episode reward: total was -37.950000. running mean: -49.181528\n",
      "ep 45: ep_len:620 episode reward: total was 17.700000. running mean: -48.512713\n",
      "ep 45: ep_len:240 episode reward: total was 23.000000. running mean: -47.797585\n",
      "ep 45: ep_len:500 episode reward: total was 15.130000. running mean: -47.168310\n",
      "ep 45: ep_len:500 episode reward: total was 29.800000. running mean: -46.398627\n",
      "ep 45: ep_len:735 episode reward: total was -3.630000. running mean: -45.970940\n",
      "ep 45: ep_len:895 episode reward: total was 20.160000. running mean: -45.309631\n",
      "ep 45: ep_len:500 episode reward: total was -5.170000. running mean: -44.908235\n",
      "ep 45: ep_len:755 episode reward: total was 14.180000. running mean: -44.317352\n",
      "ep 45: ep_len:500 episode reward: total was 5.240000. running mean: -43.821779\n",
      "ep 45: ep_len:710 episode reward: total was -3.480000. running mean: -43.418361\n",
      "ep 45: ep_len:2235 episode reward: total was -372.830000. running mean: -46.712477\n",
      "ep 45: ep_len:955 episode reward: total was -14.570000. running mean: -46.391053\n",
      "ep 45: ep_len:720 episode reward: total was -0.200000. running mean: -45.929142\n",
      "ep 45: ep_len:500 episode reward: total was 16.730000. running mean: -45.302551\n",
      "ep 45: ep_len:500 episode reward: total was 3.280000. running mean: -44.816725\n",
      "ep 45: ep_len:1065 episode reward: total was -52.170000. running mean: -44.890258\n",
      "ep 45: ep_len:630 episode reward: total was -2.830000. running mean: -44.469655\n",
      "ep 45: ep_len:650 episode reward: total was 26.180000. running mean: -43.763159\n",
      "ep 45: ep_len:1040 episode reward: total was 1.210000. running mean: -43.313427\n",
      "ep 45: ep_len:500 episode reward: total was 16.050000. running mean: -42.719793\n",
      "ep 45: ep_len:660 episode reward: total was -46.200000. running mean: -42.754595\n",
      "ep 45: ep_len:695 episode reward: total was -16.320000. running mean: -42.490249\n",
      "ep 45: ep_len:131 episode reward: total was 13.000000. running mean: -41.935346\n",
      "ep 45: ep_len:1860 episode reward: total was -163.450000. running mean: -43.150493\n",
      "ep 45: ep_len:500 episode reward: total was 28.330000. running mean: -42.435688\n",
      "ep 45: ep_len:500 episode reward: total was 14.280000. running mean: -41.868531\n",
      "ep 45: ep_len:500 episode reward: total was 5.760000. running mean: -41.392246\n",
      "ep 45: ep_len:500 episode reward: total was 17.310000. running mean: -40.805223\n",
      "ep 45: ep_len:500 episode reward: total was 9.110000. running mean: -40.306071\n",
      "ep 45: ep_len:600 episode reward: total was -40.260000. running mean: -40.305610\n",
      "ep 45: ep_len:500 episode reward: total was 20.310000. running mean: -39.699454\n",
      "ep 45: ep_len:910 episode reward: total was 1.920000. running mean: -39.283260\n",
      "ep 45: ep_len:500 episode reward: total was 11.280000. running mean: -38.777627\n",
      "ep 45: ep_len:38 episode reward: total was 3.500000. running mean: -38.354851\n",
      "ep 45: ep_len:505 episode reward: total was -9.000000. running mean: -38.061302\n",
      "ep 45: ep_len:520 episode reward: total was -9.110000. running mean: -37.771789\n",
      "ep 45: ep_len:500 episode reward: total was -8.140000. running mean: -37.475472\n",
      "ep 45: ep_len:500 episode reward: total was 2.820000. running mean: -37.072517\n",
      "ep 45: ep_len:580 episode reward: total was -36.260000. running mean: -37.064392\n",
      "ep 45: ep_len:685 episode reward: total was -6.760000. running mean: -36.761348\n",
      "ep 45: ep_len:205 episode reward: total was 17.500000. running mean: -36.218734\n",
      "ep 45: ep_len:730 episode reward: total was -14.750000. running mean: -36.004047\n",
      "ep 45: ep_len:216 episode reward: total was 18.500000. running mean: -35.459006\n",
      "ep 45: ep_len:990 episode reward: total was -100.080000. running mean: -36.105216\n",
      "ep 45: ep_len:500 episode reward: total was 19.970000. running mean: -35.544464\n",
      "ep 45: ep_len:1590 episode reward: total was -205.720000. running mean: -37.246220\n",
      "ep 45: ep_len:500 episode reward: total was 25.300000. running mean: -36.620757\n",
      "ep 45: ep_len:560 episode reward: total was -24.670000. running mean: -36.501250\n",
      "ep 45: ep_len:735 episode reward: total was -6.660000. running mean: -36.202837\n",
      "ep 45: ep_len:745 episode reward: total was -9.670000. running mean: -35.937509\n",
      "ep 45: ep_len:660 episode reward: total was -2.770000. running mean: -35.605834\n",
      "ep 45: ep_len:206 episode reward: total was 15.000000. running mean: -35.099776\n",
      "ep 45: ep_len:605 episode reward: total was -20.050000. running mean: -34.949278\n",
      "ep 45: ep_len:1025 episode reward: total was 7.470000. running mean: -34.525085\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 45: ep_len:650 episode reward: total was 0.770000. running mean: -34.172134\n",
      "ep 45: ep_len:500 episode reward: total was -2.960000. running mean: -33.860013\n",
      "ep 45: ep_len:999 episode reward: total was -159.120000. running mean: -35.112613\n",
      "ep 45: ep_len:500 episode reward: total was 22.330000. running mean: -34.538187\n",
      "ep 45: ep_len:500 episode reward: total was 2.790000. running mean: -34.164905\n",
      "ep 45: ep_len:500 episode reward: total was 14.090000. running mean: -33.682356\n",
      "ep 45: ep_len:600 episode reward: total was -27.390000. running mean: -33.619432\n",
      "ep 45: ep_len:525 episode reward: total was -13.140000. running mean: -33.414638\n",
      "ep 45: ep_len:500 episode reward: total was 10.000000. running mean: -32.980491\n",
      "ep 45: ep_len:376 episode reward: total was 36.000000. running mean: -32.290686\n",
      "ep 45: ep_len:895 episode reward: total was 14.590000. running mean: -31.821880\n",
      "ep 45: ep_len:720 episode reward: total was -6.660000. running mean: -31.570261\n",
      "ep 45: ep_len:835 episode reward: total was -38.780000. running mean: -31.642358\n",
      "ep 45: ep_len:500 episode reward: total was 7.270000. running mean: -31.253235\n",
      "ep 45: ep_len:500 episode reward: total was -37.180000. running mean: -31.312502\n",
      "ep 45: ep_len:505 episode reward: total was -14.190000. running mean: -31.141277\n",
      "ep 45: ep_len:1386 episode reward: total was -176.050000. running mean: -32.590364\n",
      "ep 45: ep_len:735 episode reward: total was -5.650000. running mean: -32.320961\n",
      "ep 45: ep_len:500 episode reward: total was 23.000000. running mean: -31.767751\n",
      "ep 45: ep_len:935 episode reward: total was 37.100000. running mean: -31.079074\n",
      "ep 45: ep_len:1675 episode reward: total was -205.740000. running mean: -32.825683\n",
      "ep 45: ep_len:500 episode reward: total was 34.760000. running mean: -32.149826\n",
      "ep 45: ep_len:500 episode reward: total was 17.830000. running mean: -31.650028\n",
      "ep 45: ep_len:463 episode reward: total was 28.250000. running mean: -31.051028\n",
      "ep 45: ep_len:487 episode reward: total was 21.780000. running mean: -30.522717\n",
      "ep 45: ep_len:500 episode reward: total was 2.820000. running mean: -30.189290\n",
      "ep 45: ep_len:935 episode reward: total was 24.310000. running mean: -29.644297\n",
      "ep 45: ep_len:525 episode reward: total was 21.310000. running mean: -29.134754\n",
      "ep 45: ep_len:500 episode reward: total was -2.440000. running mean: -28.867807\n",
      "ep 45: ep_len:421 episode reward: total was 42.000000. running mean: -28.159129\n",
      "ep 45: ep_len:565 episode reward: total was -47.400000. running mean: -28.351537\n",
      "ep 45: ep_len:765 episode reward: total was 14.600000. running mean: -27.922022\n",
      "ep 45: ep_len:955 episode reward: total was 11.660000. running mean: -27.526202\n",
      "ep 45: ep_len:500 episode reward: total was 21.080000. running mean: -27.040140\n",
      "ep 45: ep_len:496 episode reward: total was 36.250000. running mean: -26.407238\n",
      "ep 45: ep_len:500 episode reward: total was 47.000000. running mean: -25.673166\n",
      "ep 45: ep_len:765 episode reward: total was -11.250000. running mean: -25.528934\n",
      "ep 45: ep_len:500 episode reward: total was 13.110000. running mean: -25.142545\n",
      "ep 45: ep_len:645 episode reward: total was 3.820000. running mean: -24.852920\n",
      "ep 45: ep_len:880 episode reward: total was 13.130000. running mean: -24.473090\n",
      "ep 45: ep_len:500 episode reward: total was 19.540000. running mean: -24.032959\n",
      "ep 45: ep_len:169 episode reward: total was 16.500000. running mean: -23.627630\n",
      "ep 45: ep_len:500 episode reward: total was 21.320000. running mean: -23.178154\n",
      "ep 45: ep_len:570 episode reward: total was -3.960000. running mean: -22.985972\n",
      "ep 45: ep_len:500 episode reward: total was 25.300000. running mean: -22.503112\n",
      "ep 45: ep_len:500 episode reward: total was 10.110000. running mean: -22.176981\n",
      "ep 45: ep_len:500 episode reward: total was 27.290000. running mean: -21.682311\n",
      "ep 45: ep_len:1115 episode reward: total was -26.270000. running mean: -21.728188\n",
      "ep 45: ep_len:800 episode reward: total was -118.120000. running mean: -22.692106\n",
      "ep 45: ep_len:500 episode reward: total was 20.280000. running mean: -22.262385\n",
      "ep 45: ep_len:850 episode reward: total was -25.620000. running mean: -22.295961\n",
      "ep 45: ep_len:500 episode reward: total was 25.790000. running mean: -21.815102\n",
      "ep 45: ep_len:185 episode reward: total was 17.000000. running mean: -21.426951\n",
      "ep 45: ep_len:805 episode reward: total was -21.250000. running mean: -21.425181\n",
      "ep 45: ep_len:705 episode reward: total was -12.780000. running mean: -21.338729\n",
      "ep 45: ep_len:266 episode reward: total was 26.500000. running mean: -20.860342\n",
      "ep 45: ep_len:725 episode reward: total was 26.420000. running mean: -20.387539\n",
      "ep 45: ep_len:1070 episode reward: total was -178.700000. running mean: -21.970663\n",
      "ep 45: ep_len:252 episode reward: total was 25.000000. running mean: -21.500957\n",
      "ep 45: ep_len:500 episode reward: total was -2.430000. running mean: -21.310247\n",
      "ep 45: ep_len:765 episode reward: total was -12.660000. running mean: -21.223745\n",
      "ep 45: ep_len:500 episode reward: total was 24.780000. running mean: -20.763707\n",
      "ep 45: ep_len:120 episode reward: total was 10.500000. running mean: -20.451070\n",
      "ep 45: ep_len:575 episode reward: total was -4.960000. running mean: -20.296159\n",
      "ep 45: ep_len:220 episode reward: total was 17.500000. running mean: -19.918198\n",
      "ep 45: ep_len:615 episode reward: total was -3.870000. running mean: -19.757716\n",
      "ep 45: ep_len:720 episode reward: total was 12.550000. running mean: -19.434639\n",
      "ep 45: ep_len:192 episode reward: total was 19.000000. running mean: -19.050292\n",
      "ep 45: ep_len:3020 episode reward: total was -159.650000. running mean: -20.456289\n",
      "ep 45: ep_len:810 episode reward: total was 12.980000. running mean: -20.121927\n",
      "ep 45: ep_len:500 episode reward: total was -7.400000. running mean: -19.994707\n",
      "ep 45: ep_len:500 episode reward: total was 23.340000. running mean: -19.561360\n",
      "ep 45: ep_len:650 episode reward: total was -6.950000. running mean: -19.435247\n",
      "ep 45: ep_len:500 episode reward: total was 8.280000. running mean: -19.158094\n",
      "ep 45: ep_len:755 episode reward: total was -4.600000. running mean: -19.012513\n",
      "ep 45: ep_len:735 episode reward: total was -3.370000. running mean: -18.856088\n",
      "ep 45: ep_len:1270 episode reward: total was -186.350000. running mean: -20.531027\n",
      "ep 45: ep_len:980 episode reward: total was 27.340000. running mean: -20.052317\n",
      "ep 45: ep_len:505 episode reward: total was 20.380000. running mean: -19.647994\n",
      "ep 45: ep_len:500 episode reward: total was 7.330000. running mean: -19.378214\n",
      "ep 45: ep_len:179 episode reward: total was 17.500000. running mean: -19.009432\n",
      "ep 45: ep_len:211 episode reward: total was 19.500000. running mean: -18.624337\n",
      "ep 45: ep_len:187 episode reward: total was 15.500000. running mean: -18.283094\n",
      "ep 45: ep_len:635 episode reward: total was -7.870000. running mean: -18.178963\n",
      "ep 45: ep_len:1005 episode reward: total was -55.610000. running mean: -18.553273\n",
      "ep 45: ep_len:510 episode reward: total was -17.210000. running mean: -18.539841\n",
      "ep 45: ep_len:500 episode reward: total was 18.070000. running mean: -18.173742\n",
      "ep 45: ep_len:500 episode reward: total was 21.780000. running mean: -17.774205\n",
      "ep 45: ep_len:1025 episode reward: total was -27.300000. running mean: -17.869463\n",
      "ep 45: ep_len:1810 episode reward: total was -109.130000. running mean: -18.782068\n",
      "ep 45: ep_len:700 episode reward: total was -3.700000. running mean: -18.631247\n",
      "ep 45: ep_len:775 episode reward: total was -18.180000. running mean: -18.626735\n",
      "ep 45: ep_len:500 episode reward: total was 10.330000. running mean: -18.337168\n",
      "ep 45: ep_len:555 episode reward: total was -8.030000. running mean: -18.234096\n",
      "ep 45: ep_len:775 episode reward: total was -7.590000. running mean: -18.127655\n",
      "ep 45: ep_len:337 episode reward: total was 30.500000. running mean: -17.641378\n",
      "ep 45: ep_len:945 episode reward: total was -43.610000. running mean: -17.901065\n",
      "ep 45: ep_len:500 episode reward: total was 15.810000. running mean: -17.563954\n",
      "ep 45: ep_len:410 episode reward: total was 39.500000. running mean: -16.993314\n",
      "ep 45: ep_len:580 episode reward: total was -4.950000. running mean: -16.872881\n",
      "ep 45: ep_len:204 episode reward: total was 18.500000. running mean: -16.519153\n",
      "ep 45: ep_len:515 episode reward: total was 6.260000. running mean: -16.291361\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 45: ep_len:770 episode reward: total was -15.680000. running mean: -16.285247\n",
      "ep 45: ep_len:500 episode reward: total was 25.790000. running mean: -15.864495\n",
      "ep 45: ep_len:695 episode reward: total was 20.580000. running mean: -15.500050\n",
      "ep 45: ep_len:585 episode reward: total was -18.070000. running mean: -15.525749\n",
      "ep 45: ep_len:198 episode reward: total was 19.500000. running mean: -15.175492\n",
      "ep 45: ep_len:171 episode reward: total was 17.000000. running mean: -14.853737\n",
      "ep 45: ep_len:343 episode reward: total was 34.000000. running mean: -14.365200\n",
      "ep 45: ep_len:221 episode reward: total was 16.500000. running mean: -14.056548\n",
      "ep 45: ep_len:500 episode reward: total was 2.180000. running mean: -13.894182\n",
      "ep 45: ep_len:885 episode reward: total was 17.480000. running mean: -13.580440\n",
      "ep 45: ep_len:218 episode reward: total was 21.500000. running mean: -13.229636\n",
      "ep 45: ep_len:873 episode reward: total was -95.220000. running mean: -14.049540\n",
      "ep 45: ep_len:885 episode reward: total was -37.670000. running mean: -14.285744\n",
      "ep 45: ep_len:655 episode reward: total was -2.780000. running mean: -14.170687\n",
      "ep 45: ep_len:216 episode reward: total was 20.000000. running mean: -13.828980\n",
      "ep 45: ep_len:500 episode reward: total was 33.760000. running mean: -13.353090\n",
      "ep 45: ep_len:630 episode reward: total was -32.120000. running mean: -13.540759\n",
      "ep 45: ep_len:422 episode reward: total was -5.260000. running mean: -13.457952\n",
      "ep 45: ep_len:980 episode reward: total was 9.390000. running mean: -13.229472\n",
      "ep 45: ep_len:560 episode reward: total was -42.360000. running mean: -13.520777\n",
      "ep 45: ep_len:1374 episode reward: total was -208.610000. running mean: -15.471670\n",
      "ep 45: ep_len:3649 episode reward: total was -547.010000. running mean: -20.787053\n",
      "ep 45: ep_len:950 episode reward: total was -8.460000. running mean: -20.663782\n",
      "ep 45: ep_len:500 episode reward: total was 9.870000. running mean: -20.358445\n",
      "ep 45: ep_len:505 episode reward: total was -9.140000. running mean: -20.246260\n",
      "ep 45: ep_len:535 episode reward: total was -38.370000. running mean: -20.427498\n",
      "ep 45: ep_len:975 episode reward: total was -35.750000. running mean: -20.580723\n",
      "ep 45: ep_len:505 episode reward: total was 15.270000. running mean: -20.222215\n",
      "ep 45: ep_len:940 episode reward: total was -27.460000. running mean: -20.294593\n",
      "ep 45: ep_len:500 episode reward: total was 50.000000. running mean: -19.591647\n",
      "ep 45: ep_len:995 episode reward: total was 26.630000. running mean: -19.129431\n",
      "ep 45: ep_len:290 episode reward: total was 24.500000. running mean: -18.693136\n",
      "ep 45: ep_len:930 episode reward: total was -21.080000. running mean: -18.717005\n",
      "ep 45: ep_len:600 episode reward: total was -33.190000. running mean: -18.861735\n",
      "ep 45: ep_len:750 episode reward: total was 1.450000. running mean: -18.658618\n",
      "ep 45: ep_len:500 episode reward: total was 31.740000. running mean: -18.154632\n",
      "ep 45: ep_len:500 episode reward: total was 27.850000. running mean: -17.694585\n",
      "ep 45: ep_len:705 episode reward: total was 8.320000. running mean: -17.434439\n",
      "ep 45: ep_len:1385 episode reward: total was -90.980000. running mean: -18.169895\n",
      "ep 45: ep_len:228 episode reward: total was 22.500000. running mean: -17.763196\n",
      "ep 45: ep_len:1045 episode reward: total was -45.920000. running mean: -18.044764\n",
      "ep 45: ep_len:615 episode reward: total was -16.200000. running mean: -18.026316\n",
      "ep 45: ep_len:500 episode reward: total was 12.810000. running mean: -17.717953\n",
      "ep 45: ep_len:218 episode reward: total was 20.000000. running mean: -17.340774\n",
      "ep 45: ep_len:550 episode reward: total was -19.150000. running mean: -17.358866\n",
      "ep 45: ep_len:975 episode reward: total was 13.100000. running mean: -17.054277\n",
      "ep 45: ep_len:500 episode reward: total was -10.210000. running mean: -16.985835\n",
      "ep 45: ep_len:1070 episode reward: total was -9.610000. running mean: -16.912076\n",
      "ep 45: ep_len:682 episode reward: total was -101.690000. running mean: -17.759855\n",
      "ep 45: ep_len:565 episode reward: total was -16.090000. running mean: -17.743157\n",
      "ep 45: ep_len:500 episode reward: total was 15.290000. running mean: -17.412825\n",
      "ep 45: ep_len:500 episode reward: total was 20.830000. running mean: -17.030397\n",
      "ep 45: ep_len:183 episode reward: total was 16.500000. running mean: -16.695093\n",
      "ep 45: ep_len:500 episode reward: total was 24.870000. running mean: -16.279442\n",
      "ep 45: ep_len:505 episode reward: total was -7.230000. running mean: -16.188948\n",
      "ep 45: ep_len:725 episode reward: total was 0.820000. running mean: -16.018858\n",
      "ep 45: ep_len:1078 episode reward: total was -75.500000. running mean: -16.613670\n",
      "ep 45: ep_len:555 episode reward: total was -5.000000. running mean: -16.497533\n",
      "ep 45: ep_len:500 episode reward: total was 7.660000. running mean: -16.255958\n",
      "ep 45: ep_len:181 episode reward: total was 18.000000. running mean: -15.913398\n",
      "ep 45: ep_len:500 episode reward: total was -6.730000. running mean: -15.821564\n",
      "ep 45: ep_len:500 episode reward: total was 7.150000. running mean: -15.591848\n",
      "ep 45: ep_len:655 episode reward: total was -3.790000. running mean: -15.473830\n",
      "ep 45: ep_len:500 episode reward: total was 9.740000. running mean: -15.221692\n",
      "ep 45: ep_len:500 episode reward: total was 11.320000. running mean: -14.956275\n",
      "ep 45: ep_len:500 episode reward: total was -0.940000. running mean: -14.816112\n",
      "ep 45: ep_len:610 episode reward: total was 15.690000. running mean: -14.511051\n",
      "ep 45: ep_len:505 episode reward: total was -6.000000. running mean: -14.425940\n",
      "ep 45: ep_len:244 episode reward: total was 24.000000. running mean: -14.041681\n",
      "ep 45: ep_len:745 episode reward: total was -4.200000. running mean: -13.943264\n",
      "ep 45: ep_len:635 episode reward: total was -52.310000. running mean: -14.326932\n",
      "ep 45: ep_len:500 episode reward: total was -1.590000. running mean: -14.199562\n",
      "ep 45: ep_len:625 episode reward: total was 16.670000. running mean: -13.890867\n",
      "ep 45: ep_len:760 episode reward: total was -5.570000. running mean: -13.807658\n",
      "ep 45: ep_len:500 episode reward: total was 10.300000. running mean: -13.566581\n",
      "ep 45: ep_len:610 episode reward: total was -44.280000. running mean: -13.873716\n",
      "ep 45: ep_len:160 episode reward: total was 15.000000. running mean: -13.584978\n",
      "ep 45: ep_len:500 episode reward: total was 17.250000. running mean: -13.276629\n",
      "ep 45: ep_len:500 episode reward: total was 7.750000. running mean: -13.066362\n",
      "ep 45: ep_len:336 episode reward: total was -8.500000. running mean: -13.020699\n",
      "ep 45: ep_len:795 episode reward: total was 12.700000. running mean: -12.763492\n",
      "ep 45: ep_len:505 episode reward: total was -15.380000. running mean: -12.789657\n",
      "ep 45: ep_len:650 episode reward: total was 3.320000. running mean: -12.628560\n",
      "ep 45: ep_len:785 episode reward: total was -21.710000. running mean: -12.719375\n",
      "ep 45: ep_len:500 episode reward: total was -8.320000. running mean: -12.675381\n",
      "ep 45: ep_len:855 episode reward: total was -57.410000. running mean: -13.122727\n",
      "ep 45: ep_len:920 episode reward: total was 2.410000. running mean: -12.967400\n",
      "ep 45: ep_len:1495 episode reward: total was -110.180000. running mean: -13.939526\n",
      "ep 45: ep_len:585 episode reward: total was -62.510000. running mean: -14.425231\n",
      "ep 45: ep_len:1045 episode reward: total was -15.670000. running mean: -14.437678\n",
      "ep 45: ep_len:830 episode reward: total was 13.620000. running mean: -14.157101\n",
      "ep 45: ep_len:1105 episode reward: total was -80.660000. running mean: -14.822130\n",
      "ep 45: ep_len:515 episode reward: total was 11.180000. running mean: -14.562109\n",
      "ep 45: ep_len:1495 episode reward: total was -85.910000. running mean: -15.275588\n",
      "ep 45: ep_len:161 episode reward: total was 16.000000. running mean: -14.962832\n",
      "ep 45: ep_len:500 episode reward: total was 26.370000. running mean: -14.549504\n",
      "ep 45: ep_len:990 episode reward: total was 22.310000. running mean: -14.180909\n",
      "ep 45: ep_len:1155 episode reward: total was 24.590000. running mean: -13.793200\n",
      "ep 45: ep_len:530 episode reward: total was -24.240000. running mean: -13.897668\n",
      "ep 45: ep_len:500 episode reward: total was -0.090000. running mean: -13.759591\n",
      "ep 45: ep_len:267 episode reward: total was 25.000000. running mean: -13.371995\n",
      "ep 45: ep_len:785 episode reward: total was -5.550000. running mean: -13.293775\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 45: ep_len:237 episode reward: total was 23.500000. running mean: -12.925837\n",
      "ep 45: ep_len:500 episode reward: total was 11.550000. running mean: -12.681079\n",
      "ep 45: ep_len:685 episode reward: total was -0.700000. running mean: -12.561268\n",
      "ep 45: ep_len:1245 episode reward: total was -161.670000. running mean: -14.052356\n",
      "ep 45: ep_len:500 episode reward: total was 32.830000. running mean: -13.583532\n",
      "ep 45: ep_len:935 episode reward: total was -14.480000. running mean: -13.592497\n",
      "ep 45: ep_len:1076 episode reward: total was -181.720000. running mean: -15.273772\n",
      "ep 45: ep_len:2063 episode reward: total was -190.440000. running mean: -17.025434\n",
      "ep 45: ep_len:1005 episode reward: total was -7.130000. running mean: -16.926480\n",
      "ep 45: ep_len:500 episode reward: total was 20.580000. running mean: -16.551415\n",
      "ep 45: ep_len:500 episode reward: total was 11.730000. running mean: -16.268601\n",
      "ep 45: ep_len:500 episode reward: total was -10.980000. running mean: -16.215715\n",
      "ep 45: ep_len:915 episode reward: total was -7.310000. running mean: -16.126658\n",
      "ep 45: ep_len:500 episode reward: total was -2.110000. running mean: -15.986491\n",
      "ep 45: ep_len:500 episode reward: total was 6.830000. running mean: -15.758326\n",
      "ep 45: ep_len:810 episode reward: total was 0.420000. running mean: -15.596543\n",
      "ep 45: ep_len:500 episode reward: total was -1.330000. running mean: -15.453877\n",
      "ep 45: ep_len:1385 episode reward: total was -71.610000. running mean: -16.015439\n",
      "ep 45: ep_len:1765 episode reward: total was -143.320000. running mean: -17.288484\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-f491d89340ca>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    326\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m         \u001b[0;31m# update value_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 328\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrrr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mupdate_criteria\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbackward_network\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreplay_memory_pos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpos_prob\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreplay_memory_neg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mreplay_memory_cx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mupdate_criteria\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    329\u001b[0m         \u001b[0;31m#numUpdateRew.append(rrr)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m         \u001b[0;31m#if np.random.rand() < 0.05:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-13-106c733a6f18>\u001b[0m in \u001b[0;36mbackward_network\u001b[0;34m(replay_memory_pos, pos_prob, replay_memory_neg, replay_memory_cx, update_criteria)\u001b[0m\n\u001b[1;32m     26\u001b[0m     y = torch.cat(tuple(reward[i] if minibatch[i][4] \\\n\u001b[1;32m     27\u001b[0m                         \u001b[0;32melse\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mgamma\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext_output\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m                         for i in range(len(minibatch))))\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0;31m# extract Q-value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-13-106c733a6f18>\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     26\u001b[0m     y = torch.cat(tuple(reward[i] if minibatch[i][4] \\\n\u001b[1;32m     27\u001b[0m                         \u001b[0;32melse\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mgamma\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext_output\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m                         for i in range(len(minibatch))))\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0;31m# extract Q-value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "maxRewSteps = 5\n",
    "max_ep_len = 500\n",
    "seq_len = 20\n",
    "h_len = seq_len\n",
    "\n",
    "while epoch < numEpoch:\n",
    "#for epoch in range(numEpoch):\n",
    "    # repeat for all pedestrians\n",
    "    #disp(pALL)\n",
    "    \n",
    "    for p in range(pALL.shape[0]): #range(pInLoop.shape[0])\n",
    "        \n",
    "        policy_net.train()\n",
    "        \n",
    "        # load p'th person data\n",
    "        ped = np.copy(pALL[p])\n",
    "\n",
    "        # camera index and frame index starts from zero\n",
    "        ped[:,0] -= 1\n",
    "        ped[:,1] -= 1\n",
    "        #print (np.unique(ped[:,0]))\n",
    "        \n",
    "        # check if camera number is correct\n",
    "        if (ped[:,0] >= num_camera).any():\n",
    "            print ('Error in person ', p)\n",
    "            break\n",
    "            \n",
    "        if ped.shape[0] < max_ep_len/4:\n",
    "            continue\n",
    "        \n",
    "        # select a camera uniformly\n",
    "        uniq_cam = np.unique(ped[:,0])\n",
    "        if len(uniq_cam) < 2 and np.random.rand() > 0.4:\n",
    "            if len(np.where(ped[1:,1]-ped[0:-1,1] != 1)[0]) == 0:\n",
    "                continue\n",
    "        rand_cam = uniq_cam[np.random.randint(len(uniq_cam))]\n",
    "        index_of_rand_cam = np.nonzero( ped[:,0]==rand_cam )[0]\n",
    "        len_indices_rand_cam = len(index_of_rand_cam)\n",
    "        \n",
    "        # Initialize with current state with start frame\n",
    "        tranIDX = np.where(ped[1:,0]-ped[0:-1,0])[0]\n",
    "        if len(uniq_cam) < 2 or np.random.rand() < 0.4:\n",
    "            startIDX = np.random.randint( 0,int(ped.shape[0]-ped.shape[0]/2) )\n",
    "        else:\n",
    "            startIDX = np.random.choice(tranIDX)-20\n",
    "        #startIDX = np.random.choice(tranIDX)-20 if np.random.rand(1) < 0.6 else np.random.randint( 0,ped.shape[0]-max_ep_len/2 )\n",
    "        #startIDX = index_of_rand_cam[np.random.randint(len_indices_rand_cam/10)]\n",
    "        myPos = ped[startIDX,0:]\n",
    "        #print (myPos)\n",
    "        \n",
    "        curr_camera = myPos[0]\n",
    "        curr_frame = myPos[1]\n",
    "        \n",
    "        # Initialize history variable (one-hot encoding)\n",
    "        ch = np.zeros((h_len,duke_cam))\n",
    "        prev_ch = ch\n",
    "        \n",
    "        # initialize total time target was occluded\n",
    "        num_steps = 0\n",
    "        occ_len = 0.01\n",
    "        hcount = np.array(10*np.log(occ_len))\n",
    "        CDataEp = []\n",
    "        inCDataEp = []\n",
    "        EpData = []\n",
    "        episodic_seq = []\n",
    "        rewSteps = 1\n",
    "        \n",
    "        tmp_replay = []\n",
    "        tmp_reward = []\n",
    "        tmp_c_seq = []\n",
    "        pivot_cam = curr_camera\n",
    "        prev_box = ped[ np.logical_and(ped[:,0]==curr_camera,ped[:,1]==curr_frame),2:][0]\n",
    "        \n",
    "        # create initial state (ct,rt,tau_t)\n",
    "        #bbox = myPos[2:]\n",
    "        #rt = afc.find_curr_rt(bbox)\n",
    "        x_t,c_t,te_tau,r_t = make_state_vector(ped, curr_camera,curr_frame,ch,occ_len)\n",
    "        prev_rt = r_t[0:4]\n",
    "        stCam = curr_camera\n",
    "        expStC = curr_camera\n",
    "        count_curr_c = 0\n",
    "        prev_camera = curr_camera\n",
    "\n",
    "        if render: # show current location\n",
    "            plt.imshow(x.reshape(input_size))\n",
    "            display.clear_output(wait=True)\n",
    "            display.display(plt.gcf())\n",
    "        episode_count += 1\n",
    "        if epsilon > finalEpsilon:\n",
    "            epsilon -= (initialEpsilon - finalEpsilon)/20000\n",
    "        \n",
    "        # select an action from the current state\n",
    "        hidden, cell = enc(torch.from_numpy(ch).float().cuda().unsqueeze(1))\n",
    "        #print (x_t.size(),h_t.size(),enc_history.size())\n",
    "        state_xt = torch.cat([x_t, te_tau], dim=1)\n",
    "        #state = torch.cat([state_xt, hidden.detach().flatten().view(1,-1)], dim=1)\n",
    "        state = torch.cat([state_xt, hidden[1,].detach()], dim=1)\n",
    "        #print ('State size: ', state.size())\n",
    "        \n",
    "        while(curr_frame <= ped[-1,1]):\n",
    "        \n",
    "            state_in = Variable(state)\n",
    "            value_c = policy_net(state_in)\n",
    "\n",
    "            steps_count += 1\n",
    "            \n",
    "            # generate random steps\n",
    "            if np.random.rand(1) < 0.01:\n",
    "                rsteps = np.random.randint(fpsc,20,1)\n",
    "            else:\n",
    "                rsteps = 1\n",
    "            curr_frame += rsteps*fpsc if rsteps > 1 else fpsc\n",
    "            num_steps += 1\n",
    "                \n",
    "            # initialize action\n",
    "            one_hot_action = torch.zeros([num_camera], dtype=torch.float32)\n",
    "            if use_cuda:  # put on GPU if CUDA is available\n",
    "                one_hot_action = one_hot_action.cuda()\n",
    "\n",
    "            # epsilon greedy exploration\n",
    "            random_action = np.random.random() <= epsilon\n",
    "            camera_index = [torch.randint(num_camera, torch.Size([]), dtype=torch.int)\n",
    "                           if random_action else torch.argmax(value_c)][0]\n",
    "            \n",
    "            if use_cuda:  # put on GPU if CUDA is available\n",
    "                camera_index = camera_index.cuda()\n",
    "\n",
    "            one_hot_action[camera_index] = 1\n",
    "            one_hot_action = one_hot_action.unsqueeze(0)\n",
    "            c = camera_index.detach().cpu().numpy().item()\n",
    "            \n",
    "            # Store the transition explored\n",
    "            #M[stCam,c] += 1\n",
    "            \n",
    "            # get correct label from ground truth\n",
    "            y = afc.find_target_camera(ped, curr_frame)\n",
    "            # get reward (give reward at end of episode)\n",
    "            \n",
    "            #print (c, 'GT box: ', ped[ np.logical_and(ped[:,0]==c,ped[:,1]==curr_frame),2:])\n",
    "            # give reward if rewardSteps reached maxRewardSteps\n",
    "            if rewSteps >= maxRewSteps:\n",
    "                \n",
    "                #if np.random.rand() < 0.5:\n",
    "                #    c = y\n",
    "                \n",
    "                if y == num_camera-1 and y == c:\n",
    "                    reward = 0.01\n",
    "                    wt = 1\n",
    "                elif y == c and occ_len< 20:\n",
    "                    reward = 0.5\n",
    "                    wt = 1\n",
    "                elif y == c:\n",
    "                    reward = 1\n",
    "                    wt = 10\n",
    "                else:\n",
    "                    wt = 1\n",
    "                    reward = -1\n",
    "                reward_sum += reward\n",
    "                rs.append(reward)\n",
    "                \n",
    "                rewSteps = 1\n",
    "                \n",
    "                pivot_cam = c\n",
    "                # take bounding box from GT\n",
    "                # get the current bounding box\n",
    "                bbox = ped[ np.logical_and(ped[:,0]==c,ped[:,1]==curr_frame),2:]\n",
    "                if len(bbox): bbox = bbox[0]\n",
    "            else:\n",
    "                rewSteps += 1\n",
    "                reward = 0\n",
    "                \n",
    "                # take nearest bounding box\n",
    "                if c != num_camera-1 and c == pivot_cam and occ_len < 20:\n",
    "                    bbox = np.array(find_nearest_box(c,curr_frame, prev_box))\n",
    "                else:\n",
    "                    bbox = np.array([])\n",
    "                \n",
    "            #print ('bbox taken: ', bbox)\n",
    "            # get the current bounding box\n",
    "            #bbox = ped[ np.logical_and(ped[:,0]==c,ped[:,1]==curr_frame),2:]\n",
    "            if bbox.shape[0] > 0:\n",
    "                #rt = afc.find_curr_rt(bbox[0]) \n",
    "                #bbox = bbox[0]\n",
    "                rt = np.zeros((8))\n",
    "                rt[0] = bbox[0]/1920 -(np.random.rand()-0.5)/100\n",
    "                rt[1] = bbox[1]/1080 -(np.random.rand()-0.5)/100\n",
    "                rt[2] = bbox[2]/1920 -(np.random.rand()-0.5)/100\n",
    "                rt[3] = bbox[3]/1080 -(np.random.rand()-0.5)/100\n",
    "                rt[4] = rt[0] - prev_rt[0] if occ_len < 0.2 else 0\n",
    "                rt[5] = rt[1] - prev_rt[1] if occ_len < 0.2 else 0\n",
    "                rt[6] = rt[2] - prev_rt[2] if occ_len < 0.2 else 0\n",
    "                rt[7] = rt[3] - prev_rt[3] if occ_len < 0.2 else 0\n",
    "                \n",
    "                curr_camera = c\n",
    "                # make next_state vector\n",
    "                this_cam = afc.make_one_hot_camera(curr_camera)\n",
    "                x_t = np.concatenate((this_cam, rt.ravel()))\n",
    "                x_t[x_t==0] = -10\n",
    "                x_t[x_t==1] = 10\n",
    "                x_t = x_t.reshape(1,-1)\n",
    "                if use_cuda:\n",
    "                    x_t = torch.from_numpy(x_t).float().cuda()\n",
    "                \n",
    "                #num_steps = 0\n",
    "                ispresent = 1\n",
    "                stCam = c\n",
    "                \n",
    "                prev_rt = rt[0:4]\n",
    "                prev_box = bbox\n",
    "            else:\n",
    "                ispresent = 0\n",
    "            \n",
    "            #if ispresent and expStC != num_camera-1 and c != num_camera-1:\n",
    "            #    trExplored[str(expStC)+'-'+str(c)].append(occ_len)\n",
    "            #    expStC = c\n",
    "            \n",
    "            \n",
    "            #-----------    reward was here\n",
    "            #EpData.append((list(value_c.detach().cpu().numpy()[0]),hcount.ravel()[0],reward,random_action,y,c,episode_reward))\n",
    "            \n",
    "            #print (np.array([rt, ispresent,c]))\n",
    "            ######################## prepare the next state  #############################\n",
    "            # count the time of prev_camera selection\n",
    "            if ispresent:\n",
    "                occ_len = 0.01\n",
    "            else:\n",
    "                occ_len += rsteps\n",
    "            #hcount = np.array(-occ_max_val + (occ_len/500)*(occ_max_val-(-occ_max_val)))\n",
    "            hcount = np.array(10*np.log(occ_len))\n",
    "            \n",
    "            # get next camera using policy network\n",
    "            this_cam = afc.make_one_hot_camera(c)\n",
    "            c_t = this_cam.reshape(1,-1)\n",
    "            \n",
    "            # update current state and history\n",
    "            prev_ch = ch\n",
    "            ch[1:,] = ch[0:-1,]\n",
    "            ch[0,0:num_camera] = afc.make_one_hot_camera(c)\n",
    "            ch[0,num_camera:] = 0\n",
    "            \n",
    "            #chCuda = torch.from_numpy(ch).float().cuda().unsqueeze(1)\n",
    "            #outSeq = model(chCuda, chCuda)\n",
    "            #print ('Encoding .. ', chCuda[:,0,].argmax(1))\n",
    "            #print ('Decoded ..', outSeq[:,0].argmax(1))\n",
    "            #print ('')\n",
    "            \n",
    "            if use_cuda:\n",
    "                c_t = torch.from_numpy(c_t).float().cuda()\n",
    "                te_tau = torch.from_numpy(hcount.reshape(1,-1)).float().cuda()\n",
    "            else:\n",
    "                c_t = torch.from_numpy(c_t).float()\n",
    "                te_tau = torch.from_numpy(hcount.reshape(1,-1)).float()\n",
    "            episodic_seq.append((c_t))\n",
    "            \n",
    "            # make next_state vector\n",
    "            hidden, cell = enc(torch.from_numpy(ch).float().cuda().unsqueeze(1))\n",
    "            #print (x_t.size(),h_t.size(),enc_history.size())\n",
    "            next_state_xt = torch.cat([x_t, te_tau], dim=1)\n",
    "            #next_state = torch.cat([next_state_xt, hidden.detach().flatten().view(1,-1)], dim=1)\n",
    "            next_state = torch.cat([next_state_xt, hidden[1,].detach()], dim=1)\n",
    "            \n",
    "            # save transition to replay memory\n",
    "            tmp_replay.append((state, one_hot_action, next_state, ispresent))\n",
    "            tmp_reward.append(reward)\n",
    "            tmp_c_seq.append(c)\n",
    "            \n",
    "            #state_xt = next_state_xt\n",
    "            state = next_state #torch.cat([state_xt, hidden.detach()], dim=1)\n",
    "            #state = torch.cat([next_state_xt, enc_history], dim=1)\n",
    "            prev_camera = c\n",
    "            \n",
    "            if num_steps >= max_ep_len and y!=num_camera-1 and y==c and reward != 0:  # break the episode\n",
    "                #print ('')\n",
    "                #print (epoch, p, random_action, rsteps)\n",
    "                #print ('x_t: ', c,rt)\n",
    "                ##print ( np.where(ch)[1])\n",
    "                #print ('Q values: ', value_c)\n",
    "                #print (y,c, curr_frame,ped[-1,1], num_steps, hcount)\n",
    "                #print ('isPresent', ispresent)\n",
    "                #print ('Pos Replay length: ', len(replay_memory_pos))\n",
    "                \n",
    "                \n",
    "                #print (pos_prob[:])\n",
    "                break\n",
    "        \n",
    "        #########################################################\n",
    "        # compute reward backward\n",
    "        #epr = np.vstack(tmp_reward)\n",
    "        discounted_epr = discount_rewards(tmp_reward, tmp_c_seq)[-1::-1]\n",
    "        #print (tmp_reward, discounted_epr)\n",
    "\n",
    "        # save transition to replay memory\n",
    "        for rLen in range(len(tmp_replay)):\n",
    "            #state, one_hot_action, next_state, ispresent = tmp_replay[rLen]\n",
    "            state = tmp_replay[rLen][0]\n",
    "            one_hot_action = tmp_replay[rLen][1]\n",
    "            next_state = tmp_replay[rLen][2]\n",
    "            ispresent = tmp_replay[rLen][3]\n",
    "\n",
    "            if use_cuda:\n",
    "                reward = torch.from_numpy(np.array([discounted_epr[rLen]], dtype=np.float32)).unsqueeze(0).cuda()\n",
    "            else:\n",
    "                reward = torch.from_numpy(np.array([discounted_epr[rLen]], dtype=np.float32)).unsqueeze(0)\n",
    "\n",
    "            if reward > 0.1:\n",
    "                replay_memory_pos.append((state, one_hot_action, reward, next_state, ispresent))\n",
    "                if reward > 0.5:\n",
    "                    wt = 10\n",
    "                else:\n",
    "                    wt = 1\n",
    "                pos_prob.append(wt)\n",
    "            elif reward <= 0.01 and reward > 0:\n",
    "                replay_memory_cx.append((state, one_hot_action, reward, next_state, ispresent))\n",
    "            elif reward != 0:\n",
    "                replay_memory_neg.append((state, one_hot_action, reward, next_state, ispresent))\n",
    "\n",
    "            # if replay memory is full, remove the oldest transition\n",
    "            if len(replay_memory_pos) > replay_memory_size:\n",
    "                replay_memory_pos.pop(0)\n",
    "                pos_prob.pop(0)\n",
    "            if len(replay_memory_neg) > replay_memory_size:\n",
    "                replay_memory_neg.pop(0)\n",
    "            if len(replay_memory_cx) > replay_memory_size:\n",
    "                replay_memory_cx.pop(0)\n",
    "        #########################################################\n",
    "\n",
    "        # update value_function\n",
    "        loss,rrr,update_criteria = backward_network(replay_memory_pos, pos_prob[:], replay_memory_neg,replay_memory_cx, update_criteria)\n",
    "        #numUpdateRew.append(rrr)\n",
    "        #if np.random.rand() < 0.05:\n",
    "        #    allEpData.append((np.stack(EpData)))\n",
    "        \n",
    "        # store episodic reward\n",
    "        #numRew.append((sum(np.stack(rs)==100),sum(np.stack(rs)==-100),sum(np.stack(rs)==0.1)))\n",
    "        rs = append_reward(rs,num_steps)\n",
    "        \n",
    "        # boring book-keeping\n",
    "        running_reward = reward_sum if running_reward is None else running_reward * 0.99 + reward_sum * 0.01\n",
    "        print ('ep %d: ep_len:%d episode reward: total was %f. running mean: %f' % (epoch, num_steps, reward_sum, running_reward))\n",
    "        reward_sum = 0\n",
    "        num_steps = 0\n",
    "        rs = []\n",
    "    \n",
    "#     if epoch % 20 == 0: # test on validation set\n",
    "#         _,accV,qv,numTR = test_func(pTest[1:2],iloc='first',eloc='last')\n",
    "#         av = np.stack(accV[0])\n",
    "#         av = sum(av[av[:,0]!=(num_camera-1),0] == av[av[:,0]!=(num_camera-1),1])/sum(av[:,0]!=(num_camera-1))\n",
    "#         validation_reward.append((qv,av,numTR)) \n",
    "    #print (M)\n",
    "    epoch += 1\n",
    "    print ('epsilon:%f episode_count: %d. steps_count: %f' % (epsilon, episode_count,steps_count))\n",
    "    if epoch % 5 == 1: \n",
    "        torch.save({'state_dict': policy_net.state_dict()}, './models/policy_duke_semisup_gtBOX_5_'+str(epoch))\n",
    "    #if epoch %200 == 100:\n",
    "        #np.save('./EpData/allEpData_ECCV_db3_pretrAE64_seq20_rp20K_'+str(epoch),np.array(allEpData),allow_pickle=True)\n",
    "        #np.save('./EpData/episode_reward_ECCV_db3_pretrAE64_seq20_rp20K_'+str(epoch), (episode_reward,validation_reward,epsilon,episode_count, steps_count,running_reward))\n",
    "    #allEpData = []\n",
    "    #print ('Time elapsed: ', tt.toc())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[55, 88, 123, 206] [51, 81, 105, 186]\n",
      "0.5571980896065499\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "chCuda = torch.from_numpy(ch).float().cuda().unsqueeze(1)\n",
    "outSeq = model(chCuda, chCuda)\n",
    "print ('Encoding .. ', chCuda[:,0,].argmax(1))\n",
    "print ('Decoded ..', outSeq[:,0].argmax(1))\n",
    "print ('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-150.0, 0.0)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# reward received during training\n",
    "rpR = np.vstack(episode_reward)\n",
    "from scipy.signal import savgol_filter\n",
    "yhat = savgol_filter(rpR[:,2], 361, 2) # window size 51, polynomial order 3\n",
    "#plt.plot(rpR[:,4])\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.plot(yhat)\n",
    "plt.ylim([-150,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "vvr = np.stack(validation_reward)\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.plot(vvr[:,1])\n",
    "plt.ylabel('Validation Acc (non-Cx)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# histogram of Q values last 10 episodes\n",
    "epn = -1\n",
    "mmat = allEpData\n",
    "episQ = np.stack(mmat[epn][:,0])[:,]\n",
    "episY = mmat[epn][:,4]*10+10\n",
    "episC = mmat[epn][:,5]*10+10\n",
    "episTau = mmat[epn][:,1]\n",
    "# print (episY)\n",
    "\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.rcParams[\"figure.figsize\"] = (20,10)\n",
    "fig, ax1 = plt.subplots()\n",
    "ax2 = ax1.twinx()\n",
    "\n",
    "ax1.plot(episY, label='GT')\n",
    "ax1.plot(episTau, label='Tau', color='black')\n",
    "#ax1.plot(episC+1, label='pi(s)', color='cyan')\n",
    "ax1.legend(loc='best')\n",
    "\n",
    "ax2.plot(episQ[:,0], label='A1')\n",
    "ax2.plot(episQ[:,1], label='A2')\n",
    "ax2.plot(episQ[:,2], label='A3')\n",
    "ax2.plot(episQ[:,3], label='A4')\n",
    "ax2.plot(episQ[:,4], label='A5')\n",
    "ax2.plot(episQ[:,5], label='Ax')\n",
    "ax2.set_ylim([-4,5])\n",
    "ax2.legend(loc='best')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_duplicates(arr): \n",
    "    final_list = [] \n",
    "    gt_tr = []\n",
    "    final_list.append(arr[0])     \n",
    "    for i in range(1,arr.shape[0]): \n",
    "        if arr[i] != arr[i-1]:\n",
    "            final_list.append(arr[i])     \n",
    "            if arr[i] != num_camera-1:\n",
    "                gt_tr.append(arr[i])\n",
    "    return final_list, gt_tr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45\n"
     ]
    }
   ],
   "source": [
    "print (epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "policy_net.load_state_dict(torch.load('./models/policy_duke_semisup_gtBOX_5_81')['state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial position:  [    7 33839   283   816    96   237]\n",
      "Initial position:  [    0 20939  1851   298    64   194]\n",
      "Initial position:  [     0 122030   1851    427     62    228]\n",
      "Initial position:  [    7 52909   233   811    97   241]\n",
      "Initial position:  [     0 126222   1847    272     68    213]\n",
      "Initial position:  [    7 88687   256   821    94   236]\n",
      "Initial position:  [    5 14238  1589   595    95   239]\n",
      "Initial position:  [    7 99379   268   820    94   237]\n",
      "Initial position:  [     5 145243    137    724    138    344]\n",
      "Initial position:  [     7 142346   1765    763     90    227]\n",
      "Initial position:  [    7 55585  1774   687    95   241]\n",
      "Initial position:  [    1 27254   698   138    67   168]\n",
      "Initial position:  [    7 71533   256   807    99   249]\n",
      "Initial position:  [     7 163928    257    807     99    247]\n",
      "Initial position:  [    5 35783  1568   582    98   248]\n",
      "Initial position:  [    7 18757  1769   726    92   232]\n",
      "Initial position:  [    7 10747   581   816    98   240]\n",
      "Initial position:  [     3 114302   1308    143     41    103]\n",
      "Initial position:  [    5 51780  1580   593    94   239]\n",
      "Initial position:  [     7 125758   1770    741     90    228]\n",
      "Initial position:  [     3 126775   1367    150     38     96]\n",
      "Initial position:  [    5 50079  1527   587    90   228]\n",
      "Initial position:  [    7 59591  1774   741    84   213]\n",
      "Initial position:  [    7 75775  1762   741    96   243]\n",
      "Initial position:  [    7 71377  1760   792    84   211]\n",
      "Initial position:  [    7 63100   205   797   103   262]\n",
      "Initial position:  [    7 51748   189   773   114   283]\n",
      "Initial position:  [    0 86452  1851   244    65   225]\n",
      "Initial position:  [    7 38212  1756   787    92   234]\n",
      "Initial position:  [     5 104275   1621    582    105    265]\n",
      "Initial position:  [     0 128500   1852    369     66    229]\n",
      "Initial position:  [    3 53076  1334   133    45   114]\n",
      "Initial position:  [    3 31131  1362   144    40   102]\n",
      "Initial position:  [    6 40442   842   566    65   166]\n",
      "Initial position:  [    3 49754  1317   129    47   118]\n",
      "Initial position:  [     7 178298   1766    791     83    211]\n",
      "Initial position:  [    7 37635  1752   770    87   221]\n",
      "Initial position:  [    7 25530   249   795   105   265]\n",
      "Initial position:  [    5 62707  1625   627    85   215]\n",
      "Initial position:  [    3 40139  1316   142    41   104]\n",
      "Initial position:  [    1 68048   699   134    68   173]\n",
      "Initial position:  [     7 171919    306    796    103    255]\n",
      "Initial position:  [    3 33956  1326   141    41   105]\n",
      "Initial position:  [     2 180306    973    377     82    208]\n",
      "Initial position:  [     5 132939   1618    619     90    228]\n",
      "Initial position:  [    3 35627  1362   125    48   122]\n",
      "Initial position:  [    7 39756  1764   758    92   233]\n",
      "Initial position:  [     7 141115   1765    728     95    239]\n",
      "Initial position:  [    7 39516  1770   722    91   230]\n",
      "Initial position:  [    7 56053   301   842    85   215]\n",
      "Initial position:  [   5 5929 1587  564  108  273]\n",
      "Initial position:  [    1 69793  1838   522    64   241]\n",
      "Initial position:  [    7 16422  1774   710    82   227]\n",
      "Initial position:  [    7 90579  1810   617    67   169]\n",
      "Initial position:  [     5 154138   1609    597     96    243]\n",
      "Initial position:  [    3 12031  1346   145    40   100]\n",
      "Initial position:  [     0 111401   1846    305     70    183]\n",
      "Initial position:  [    7 69069   283   827    91   229]\n",
      "Initial position:  [     1 165502    704    133     68    173]\n",
      "Initial position:  [    7 43741  1766   744    93   236]\n",
      "Initial position:  [     3 116471   1316    139     42    107]\n",
      "Initial position:  [    0 41577  1857   413    58   211]\n",
      "Initial position:  [     5 106657   1605    618     87    219]\n",
      "Initial position:  [     3 178725   1339    132     45    114]\n",
      "Initial position:  [    6 85878    28   584    59   210]\n",
      "Initial position:  [    7 71244   278   810    98   249]\n",
      "Initial position:  [    5 61726  1598   608    90   228]\n",
      "Initial position:  [    7 86536  1774   742    84   213]\n",
      "Initial position:  [     3 114337   1331    141     42    105]\n",
      "Initial position:  [    5 17895  1605   602    93   236]\n",
      "Initial position:  [   0 6686 1848  421   69  241]\n",
      "Initial position:  [    7 52097   328   819    95   239]\n",
      "Initial position:  [    7 69213  1765   782    89   224]\n",
      "Initial position:  [    5 86360  1626   611    92   233]\n",
      "Initial position:  [     0 140598   1852    570     63    219]\n",
      "Initial position:  [    0 17383  1861   272    52   188]\n",
      "Initial position:  [    7 42595  1776   741    84   213]\n",
      "Initial position:  [     7 179854   1767    789     86    218]\n",
      "Initial position:  [     0 146839   1850    277     67    208]\n",
      "Initial position:  [     1 107958    690    146     63    160]\n",
      "Initial position:  [    0 48829  1862   282    52   196]\n",
      "Initial position:  [     0 127242   1858    286     45    197]\n",
      "Initial position:  [    5 32106  1572   604    88   224]\n",
      "Initial position:  [    3 39690  1337   138    43   108]\n",
      "Initial position:  [    0 54316  1858   280    58   202]\n",
      "Initial position:  [    7 70830  1774   724    88   223]\n",
      "Initial position:  [    1 30775   666   119    75   190]\n",
      "Initial position:  [     0 176900   1859    288     56    198]\n",
      "Initial position:  [    5 61922  1560   607    86   216]\n",
      "Initial position:  [    1 92537   684   122    73   186]\n",
      "Initial position:  [     7 127514   1770    748     85    215]\n",
      "Initial position:  [     7 125896   1778    748     79    200]\n",
      "Initial position:  [    1 53115   735   127    70   177]\n",
      "Initial position:  [     7 129575   1743    716     90    228]\n",
      "Initial position:  [    7 47247   243   819    95   235]\n",
      "Initial position:  [    5 50586  1571   610    86   218]\n",
      "Initial position:  [    4 64386  1814   600    97   306]\n",
      "Initial position:  [     7 132993    263    808     99    251]\n",
      "Initial position:  [    7 35266  1770   728    92   232]\n",
      "Initial position:  [    1 13935   664   131    70   177]\n",
      "Initial position:  [    7 69707  1772   728    91   231]\n",
      "Initial position:  [    0 80698  1842   266    76   218]\n",
      "Initial position:  [    7 57955   205   828    91   226]\n",
      "Initial position:  [    7 98824  1752   745    91   229]\n",
      "Initial position:  [    7 54633   210   804   101   255]\n",
      "Initial position:  [    2 74271   906   370    85   216]\n",
      "Initial position:  [    0 17027  1835   270    81   219]\n",
      "Initial position:  [    7 90458  1754   711    95   242]\n",
      "Initial position:  [     4 100548   1829    603     76    296]\n",
      "Initial position:  [    7 85109   289   792   103   260]\n",
      "Initial position:  [     7 156193    206    803    101    252]\n",
      "Initial position:  [    5 54598  1610   610    91   231]\n",
      "Initial position:  [    7 97697   251   796   104   264]\n",
      "Initial position:  [     5 119098   1592    623     83    209]\n",
      "Initial position:  [     7 118661   1767    735     92    234]\n",
      "Initial position:  [     7 128447   1768    800     84    213]\n",
      "Initial position:  [    7 72742  1798   655    69   184]\n",
      "Initial position:  [    7 61130  1827   515    60   165]\n",
      "Initial position:  [    5 46376  1585   611    87   219]\n",
      "Initial position:  [    7 48089   151   797   103   261]\n",
      "Initial position:  [    7 71335  1757   815    83   209]\n",
      "Initial position:  [     7 102966    268    796    104    263]\n",
      "Initial position:  [    0 64557  1857   264    50   211]\n",
      "Initial position:  [     6 122181     22    594     65    221]\n",
      "Initial position:  [    5 32088  1600   602    93   235]\n",
      "Initial position:  [     5 104827   1597    590     98    248]\n",
      "Initial position:  [    2 79337   939   366    87   220]\n",
      "Initial position:  [    0 27055  1842   298    74   194]\n",
      "Initial position:  [    1 71481  1819   360    93   235]\n",
      "Initial position:  [    4 60060  1830   587    78   284]\n",
      "Initial position:  [    7 70508  1790   660    78   198]\n",
      "Initial position:  [     1 145403    686    126     72    181]\n",
      "Initial position:  [     4 159018   1821    592     94    295]\n",
      "Initial position:  [    2 52210    34   406   108   335]\n",
      "Initial position:  [    0 56439  1856   266    52   212]\n",
      "Initial position:  [    5 62910  1579   588    97   245]\n",
      "Initial position:  [     5 146398   1587    589     97    245]\n",
      "Initial position:  [     7 150609   1770    728     91    231]\n",
      "Initial position:  [    7 52638  1780   704    83   210]\n",
      "Initial position:  [   3 3330 1259  702  140  355]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial position:  [     7 140765    270    798    104    263]\n",
      "Initial position:  [    7 71946  1771   712    93   234]\n",
      "Initial position:  [    5 98438  1606   608    91   231]\n",
      "Initial position:  [     0 115607   1860    310     56    190]\n",
      "Initial position:  [    0 26294  1855   404    56   216]\n",
      "Initial position:  [     7 160954   1773    720     88    222]\n",
      "Initial position:  [    1 54999  1842   362    73   225]\n",
      "Initial position:  [    7 80689  1772   758    83   210]\n",
      "Initial position:  [     7 104443   1766    771     84    214]\n",
      "Initial position:  [     7 127063    244    796    105    264]\n",
      "Initial position:  [    3 49905  1321   142    41   104]\n",
      "Initial position:  [    5 45107  1585   612    87   219]\n",
      "Initial position:  [    7 74864   323   813    97   246]\n",
      "Initial position:  [    7 59765  1771   733    86   218]\n",
      "Initial position:  [    7 30506  1775   715    87   220]\n",
      "Initial position:  [    7 79859  1769   655    78   196]\n",
      "Initial position:  [    6 67191     8   598    82   225]\n",
      "Initial position:  [     5 117590   1619    598     97    245]\n",
      "Initial position:  [    5 41612  1625   605    95   240]\n",
      "Initial position:  [    7 58799   320   800   102   254]\n",
      "Initial position:  [    7 26965  1773   746    85   214]\n",
      "Initial position:  [    1 23716   710   141    65   164]\n",
      "Initial position:  [     5 132066   1601    601    103    260]\n",
      "Initial position:  [    7 35825  1774   739    84   212]\n",
      "Initial position:  [    5 63988  1600   612    89   224]\n",
      "Initial position:  [     0 106220   1856    307     61    195]\n",
      "Initial position:  [     7 161977    237    794    105    265]\n",
      "Initial position:  [     5 115570   1613    603     94    238]\n",
      "Initial position:  [    7 40241  1791   671    77   195]\n",
      "Initial position:  [    2 39192  1017   367    86   218]\n",
      "Initial position:  [   7 8262  174  775  112  284]\n",
      "Initial position:  [    7 74954   250   804    96   242]\n",
      "Initial position:  [     0 135763   1844    298     72    213]\n",
      "Initial position:  [    7 33155  1771   694    96   244]\n",
      "Initial position:  [     7 152065   1769    779     91    231]\n",
      "Initial position:  [    7 52584   260   808    99   245]\n",
      "Initial position:  [    6 56753   953   586    60   151]\n",
      "Initial position:  [   1 3024 1849  353   60  203]\n",
      "Initial position:  [    7 93589   324   801   102   259]\n",
      "Initial position:  [     5 163962     31    704    147    359]\n",
      "Initial position:  [     7 161667   1768    745     91    229]\n",
      "Initial position:  [    7 51063  1775   714    87   220]\n",
      "Initial position:  [    7 31386  1772   722    88   222]\n",
      "Initial position:  [    5 41486  1588   584   100   252]\n",
      "Initial position:  [     0 163079   1850    295     67    206]\n",
      "Initial position:  [    0 56234  1852   277    63   189]\n",
      "Initial position:  [     0 149917   1858    288     57    204]\n",
      "Initial position:  [    3 54985  1347   142    41   103]\n",
      "Initial position:  [    0 17435  1841   273    76   220]\n",
      "Initial position:  [    7 63343   238   819    95   239]\n",
      "Initial position:  [    7 44216  1765   779    88   223]\n",
      "Initial position:  [    7 35538  1819   519    65   183]\n",
      "Initial position:  [    0 77315  1857   282    59   196]\n",
      "Initial position:  [    7 23850   780   385    65   163]\n",
      "Initial position:  [     7 155100   1795    655     73    184]\n",
      "Initial position:  [     0 150740   1858    292     58    192]\n",
      "Initial position:  [    7 68132   763   834    92   232]\n",
      "Initial position:  [    2 66814  1817   549    89   294]\n",
      "Initial position:  [    7 62898  1775   738    84   212]\n",
      "Initial position:  [    7 48017  1778   718    85   214]\n",
      "Initial position:  [    5 27409  1586   619    84   213]\n",
      "Initial position:  [     0 166512   1863    313     41    184]\n",
      "Initial position:  [     1 136622    708    129     70    177]\n",
      "Initial position:  [    3 39549  1383   129    46   117]\n",
      "Initial position:  [     7 107273    239    793    105    262]\n",
      "Initial position:  [     0 127982   1847    283     69    216]\n",
      "Initial position:  [     0 100479   1854    266     51    218]\n",
      "Initial position:  [    2 24525   988   387    78   197]\n",
      "Initial position:  [    3 50863  1330   144    40   102]\n",
      "Initial position:  [    7 21508  1773   712    93   235]\n",
      "Initial position:  [    7 86556   295   800   103   261]\n",
      "Initial position:  [    5 73800  1596   623    83   211]\n",
      "Initial position:  [    7 72146  1767   771    87   221]\n",
      "Initial position:  [    7 25587  1776   737    81   204]\n",
      "Initial position:  [     7 140725    124    780    110    275]\n",
      "Initial position:  [    1 35958  1825   695    75   295]\n",
      "Initial position:  [    7 67475  1670   477    60   152]\n",
      "Initial position:  [    4 45898  1834   372    62   271]\n",
      "Initial position:  [     7 107918   1787    684     81    204]\n",
      "Initial position:  [    0 45928  1850   278    67   215]\n",
      "Initial position:  [    1 54828  1835   495    78   258]\n",
      "Initial position:  [    7 64052  1776   741    81   205]\n",
      "Initial position:  [     5 139252   1442    705    144    364]\n",
      "Initial position:  [    7 79860  1761   754    98   248]\n",
      "Initial position:  [     1 145350    744    135     67    169]\n",
      "Initial position:  [    0 56684  1850   369    59   236]\n",
      "Initial position:  [    7 84379  1770   721    94   237]\n",
      "Initial position:  [     7 163207   1785    655     86    217]\n",
      "Initial position:  [     0 115912   1855    262     62    217]\n",
      "Initial position:  [    0 34724  1843   287    73   198]\n",
      "Initial position:  [    7 48282   271   833    88   223]\n",
      "Initial position:  [     0 118006   1853    285     64    203]\n",
      "Initial position:  [    7 22692   301   796   104   258]\n",
      "Initial position:  [    2 12752   966   366    87   219]\n",
      "Initial position:  [     3 155626   1327    134     45    113]\n",
      "Initial position:  [     3 135687   1317    140     42    107]\n",
      "Initial position:  [     0 154268   1854    264     59    224]\n",
      "Initial position:  [    7 32901   237   824    92   229]\n",
      "Initial position:  [    7 36755  1776   707    89   225]\n",
      "Initial position:  [    5 58715  1577   616    84   212]\n",
      "Initial position:  [    7 59907  1771   718    90   229]\n",
      "Initial position:  [    0 90021  1834   374    78   245]\n",
      "Initial position:  [     0 118078   1837    296     80    219]\n",
      "Initial position:  [    7 79593  1749   755    92   232]\n",
      "Initial position:  [     5 145519   1613    609     92    232]\n",
      "Initial position:  [     5 158482   1585    605     90    227]\n",
      "Initial position:  [     0 117737   1851    403     64    223]\n",
      "Initial position:  [    7 54884  1770   717    90   228]\n",
      "Initial position:  [    7 99877   231   811    98   242]\n",
      "Initial position:  [     0 165071   1856    295     61    193]\n",
      "Initial position:  [    7 71425  1765   751    94   239]\n",
      "Initial position:  [    7 65294  1766   748    91   230]\n",
      "Initial position:  [     3 117204   1329    141     41    105]\n",
      "Initial position:  [     0 121070   1857    277     59    214]\n",
      "Initial position:  [     5 105949   1622    599     97    246]\n",
      "Initial position:  [    6 43766   748   562    65   164]\n",
      "Initial position:  [     0 117717   1837    400     79    215]\n",
      "Initial position:  [    5 49986  1647   615    95   239]\n",
      "Initial position:  [    1 70272  1815   653    98   320]\n",
      "Initial position:  [     5 125537   1651    597    102    258]\n",
      "Initial position:  [     5 117295   1645    616     95    240]\n",
      "Initial position:  [     7 153388   1765    739     90    227]\n",
      "Initial position:  [    7 71287  1773   733    83   211]\n",
      "Initial position:  [    1 87475   692   121    73   185]\n",
      "Initial position:  [    7 44131  1773   749    85   215]\n",
      "Initial position:  [    7 92703  1771   735    86   219]\n",
      "Initial position:  [    7 68956  1731   754    89   224]\n",
      "Initial position:  [     0 123619   1843    265     74    231]\n",
      "Initial position:  [     4 129321   1849     61     62    197]\n",
      "Initial position:  [    7 23055   147   816    96   240]\n",
      "Initial position:  [    2 87009   975   397    74   186]\n",
      "Initial position:  [    7 95334   300   824    93   235]\n",
      "Initial position:  [    3 47394  1313   145    40   101]\n",
      "Initial position:  [    7 77541  1738   777    91   231]\n",
      "Initial position:  [    3 60203  1315   151    38    96]\n",
      "Initial position:  [    7 42343   313   812    98   243]\n",
      "Initial position:  [    7 16215  1774   740    84   212]\n",
      "Initial position:  [    1 48323  1083   710   140   349]\n",
      "Initial position:  [    1 73845   677   126    72   181]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial position:  [    5 94570  1591   590    98   247]\n",
      "Initial position:  [    7 22387   176   818    94   237]\n",
      "Initial position:  [    1 53359   681   126    72   181]\n",
      "Initial position:  [     7 109779   1772    727     88    224]\n",
      "Initial position:  [    0 65115  1841   441    77   246]\n",
      "Initial position:  [    0 34154  1851   285    66   210]\n",
      "Initial position:  [     5 109371   1625    594    100    253]\n",
      "Initial position:  [    1 34868   704   133    68   173]\n",
      "Initial position:  [    7 52640  1775   741    84   213]\n",
      "Initial position:  [    0 70895  1859   271    53   194]\n",
      "Initial position:  [    3 40350  1318   134    44   112]\n",
      "Initial position:  [     0 152068   1857    287     60    191]\n",
      "Initial position:  [    7 94246  1773   726    85   216]\n",
      "Initial position:  [     7 116806   1770    736     87    219]\n",
      "Initial position:  [     1 120840    698    126     72    181]\n",
      "Initial position:  [     7 118899   1765    728     98    247]\n",
      "Initial position:  [    7 77603   172   786   107   272]\n",
      "Initial position:  [    0 18756  1859   288    57   198]\n",
      "Initial position:  [    3 30563  1325   141    41   105]\n",
      "Initial position:  [    0 46691  1855   271    60   219]\n",
      "Initial position:  [     0 176084   1828    276     85    215]\n",
      "Initial position:  [    0 48744  1831   273    85   214]\n",
      "Initial position:  [     7 155706    177    787    108    268]\n",
      "Initial position:  [    5 69618  1587   584   100   252]\n",
      "Initial position:  [     0 110953   1848    290     67    205]\n",
      "Initial position:  [    3 90500  1312   135    44   112]\n",
      "Initial position:  [     0 112394   1848    365     61    242]\n",
      "Initial position:  [     5 165599   1610    609     91    230]\n",
      "Initial position:  [    7 37742  1770   740    87   220]\n",
      "Initial position:  [    2 22942   997   388    78   197]\n",
      "Initial position:  [     5 168614   1614    601     98    247]\n",
      "Initial position:  [    7 76312  1753   779    88   223]\n",
      "Initial position:  [     0 150783   1855    291     62    218]\n",
      "Initial position:  [   0 2936 1108  328   90  228]\n",
      "Initial position:  [    7 52784  1771   729    89   224]\n",
      "Initial position:  [    7 34988  1762   751    91   231]\n",
      "Initial position:  [     4 126310   1830    596     82    268]\n",
      "Initial position:  [    5 86210  1607   597    96   244]\n",
      "Initial position:  [    0 44995  1844   321    69   174]\n",
      "Initial position:  [    0 65213  1857   260    50   216]\n",
      "Initial position:  [     7 119024    266    796    104    255]\n",
      "Initial position:  [     7 113259   1794    649     76    203]\n",
      "Initial position:  [    5 49593  1582   596    93   236]\n",
      "Initial position:  [    6 37542   745   554    68   172]\n",
      "Initial position:  [    6 40877   836   566    65   166]\n",
      "Initial position:  [    7 70522  1782   710    78   197]\n",
      "Initial position:  [     5 117073   1607    597     96    243]\n",
      "Initial position:  [    5 77516  1591   601    92   234]\n",
      "Initial position:  [    5 24072  1597   612    88   224]\n",
      "Initial position:  [     0 153607   1849    267     67    225]\n",
      "Initial position:  [    5 15631  1577   604    89   225]\n",
      "Initial position:  [    1 26205   729   124    72   182]\n",
      "Initial position:  [     7 104376   1762    801     84    214]\n",
      "Initial position:  [     0 117976   1838    280     79    215]\n",
      "Initial position:  [    7 66277  1825   524    61   167]\n",
      "Initial position:  [    7 65620   192   789   107   268]\n",
      "Initial position:  [    3 72906  1313   134    44   112]\n",
      "Initial position:  [    2 42388   887   374    83   210]\n",
      "Initial position:  [    7 23331   264   814    96   237]\n",
      "Initial position:  [     7 128664   1762    751     91    231]\n",
      "Initial position:  [     0 112185   1857    266     45    212]\n",
      "Initial position:  [    5 45718  1568   598    91   229]\n",
      "Initial position:  [     0 158740   1854    273     62    213]\n",
      "Initial position:  [     2 166000    872    369     86    216]\n",
      "Initial position:  [    3 48707  1364   133    45   113]\n",
      "Initial position:  [    3 29237  1319   131    46   115]\n",
      "Initial position:  [     3 174926   1332    135     44    111]\n",
      "Initial position:  [    2 74085   880   349    94   238]\n",
      "Initial position:  [     7 143498    302    799    103    254]\n",
      "Initial position:  [    1 45149   662   135    68   172]\n",
      "Initial position:  [     3 139020   1350    140     42    106]\n",
      "Initial position:  [    7 25674   224   805   100   250]\n",
      "Initial position:  [    0 35283  1851   393    62   227]\n",
      "Initial position:  [    5 52691  1585   583    99   251]\n",
      "Initial position:  [    3 82541  1334   144    40   102]\n",
      "Initial position:  [     7 104764   1777    719     85    214]\n",
      "Initial position:  [     0 124999   1855    269     58    219]\n",
      "Initial position:  [     0 115933   1858    290     57    205]\n",
      "Initial position:  [   7 4071  262  795  104  259]\n",
      "Initial position:  [    6 56742   894   552    72   183]\n",
      "Initial position:  [    3 54967  1319   155    36    90]\n",
      "Initial position:  [     7 141129   1739    770     90    229]\n",
      "Initial position:  [     6 121311    824    577     60    153]\n",
      "Initial position:  [    4 32388    47   233    95   241]\n",
      "Initial position:  [     3 125579   1373    144     40    102]\n",
      "Initial position:  [     7 174000   1768    734     83    211]\n",
      "Initial position:  [    7 24063  1774   722    88   222]\n",
      "Initial position:  [    3 35618  1327   136    44   110]\n",
      "Initial position:  [    7 63058  1773   758    80   202]\n",
      "Initial position:  [    7 36780  1770   722    94   238]\n",
      "Initial position:  [    5 73526  1610   592    99   250]\n",
      "Initial position:  [    0 24016  1837   352    78   232]\n",
      "Initial position:  [    1 99237  1838   395    79   218]\n",
      "Initial position:  [    1 77599   728   136    67   169]\n",
      "Initial position:  [    5 24499  1602   607    91   230]\n",
      "Initial position:  [     7 104571   1765    796     84    212]\n",
      "Initial position:  [    5 75106  1601   607    91   229]\n",
      "Initial position:  [     0 115567   1850    270     67    226]\n",
      "Initial position:  [    0 85753  1850   301    66   182]\n",
      "Initial position:  [     0 112250   1847    293     69    218]\n",
      "Initial position:  [    7 77716  1775   734    83   211]\n",
      "Initial position:  [    7 78798   175   781   110   273]\n",
      "Initial position:  [    5 62622  1588   617    85   215]\n",
      "Initial position:  [    7 63116   332   807   100   251]\n",
      "Initial position:  [    0 16563  1859   290    56   198]\n",
      "Initial position:  [    0 94209  1858   279    51   202]\n",
      "Initial position:  [    3 48284  1327   138    43   108]\n",
      "Initial position:  [    5 22170  1592   583   100   253]\n",
      "Initial position:  [     4 137902     60    176     87    219]\n",
      "Initial position:  [    0 46386  1825   280    78   197]\n",
      "Initial position:  [    7 59990  1770   760    86   218]\n",
      "Initial position:  [    5 31999  1614   604    94   238]\n",
      "Initial position:  [     7 119474   1757    772     97    245]\n",
      "Initial position:  [     5 130465   1609    602     94    237]\n",
      "Initial position:  [     7 116154    542    815     98    247]\n",
      "Initial position:  [    7 96084   248   802   102   258]\n",
      "Initial position:  [    7 65657   125   812    96   242]\n",
      "Initial position:  [    0 88124  1858   277    56   208]\n",
      "Initial position:  [     0 117992   1854    295     63    193]\n",
      "Initial position:  [    3 33560  1312   132    45   115]\n",
      "Initial position:  [    5 65148  1581   567   106   269]\n",
      "Initial position:  [    3 45898  1364   142    41   105]\n",
      "Initial position:  [    5 64798  1587   607    90   227]\n",
      "Initial position:  [    5 61898  1614   609    92   232]\n",
      "Initial position:  [   5 5894 1623  576  110  278]\n",
      "Initial position:  [    7 81047  1753   759    89   225]\n",
      "Initial position:  [    0 40574  1847   281    70   209]\n",
      "Initial position:  [     7 143435    325    800    102    257]\n",
      "Initial position:  [    0 83523  1853   300    63   188]\n",
      "Initial position:  [     2 157527    981    356     91    230]\n",
      "Initial position:  [     3 113343   1325    136     44    110]\n",
      "Initial position:  [    7 68930   289   823    93   233]\n",
      "Initial position:  [     5 151932   1615    587    102    258]\n",
      "Initial position:  [     1 141469    707    141     65    164]\n",
      "Initial position:  [     7 180147   1771    754     86    216]\n",
      "Initial position:  [    5 47546  1607   602    93   236]\n",
      "Initial position:  [    6 40826   916   569    66   167]\n",
      "Initial position:  [     0 123474   1858    285     51    210]\n",
      "Initial position:  [    7 77633  1779   744    79   199]\n",
      "Initial position:  [    5 24856  1599   590    98   248]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial position:  [    6 46717   816   576    60   153]\n",
      "Initial position:  [     0 140380   1845    273     72    214]\n",
      "Initial position:  [    0 52915  1845   265    72   212]\n",
      "Initial position:  [    7 10451  1771   713    93   234]\n",
      "Initial position:  [    7 72591  1797   502    55   138]\n",
      "Initial position:  [     3 155349   1311    140     42    106]\n",
      "Initial position:  [    3 25533  1318   142    41   104]\n",
      "Initial position:  [     7 155700     96    777    112    283]\n",
      "Initial position:  [    1 76928  1839   463    73   243]\n",
      "Initial position:  [    6 56772   801   572    62   157]\n",
      "Initial position:  [     0 117940   1843    272     74    220]\n",
      "Initial position:  [    0 68488  1856   274    50   214]\n",
      "Initial position:  [    7 71045  1758   751    91   231]\n",
      "Initial position:  [    7 53472   260   796   104   256]\n",
      "Initial position:  [    7 49309  1759   704    95   239]\n",
      "Initial position:  [    1 87395   667   132    70   177]\n",
      "Initial position:  [    7 98027   255   796   104   264]\n",
      "Initial position:  [     7 117811    239    820     94    239]\n",
      "Initial position:  [    6 13802    14   588    70   214]\n",
      "Initial position:  [     0 117981   1855    292     59    218]\n",
      "Initial position:  [    7 49719  1826   504    55   140]\n",
      "Initial position:  [    7 60165  1783   689    81   206]\n",
      "Initial position:  [     0 162506   1849    319     67    185]\n",
      "Initial position:  [    7 64749   314   812    97   247]\n",
      "Initial position:  [    0 64396  1847   410    70   224]\n",
      "Initial position:  [     5 106582   1597    596     96    242]\n",
      "Initial position:  [     0 139035   1832    407     83    253]\n",
      "Initial position:  [    1 70896   713   142    65   164]\n",
      "Initial position:  [     5 153896   1651    624     89    226]\n",
      "Initial position:  [     3 146472   1332    141     41    105]\n",
      "Initial position:  [     5 147221   1595    595     95    241]\n",
      "Initial position:  [     0 116927   1848    270     68    213]\n",
      "Initial position:  [    0 44274  1838   283    79   210]\n",
      "Initial position:  [   1 3707 1836  450   77  271]\n",
      "Initial position:  [     0 148983   1849    270     67    219]\n",
      "Initial position:  [    7 75595   133   782   109   276]\n",
      "Initial position:  [    0 41505  1852   439    46   223]\n",
      "Initial position:  [    7 18558  1768   780    82   208]\n",
      "Initial position:  [     0 135668   1860    286     48    197]\n",
      "Initial position:  [    7 69087  1753   731    89   225]\n",
      "Initial position:  [    5 78009  1579   594    94   238]\n",
      "Initial position:  [    7 54742   229   799   103   254]\n",
      "Initial position:  [    5 32212  1575   598    91   230]\n",
      "Initial position:  [     0 135010   1857    276     49    208]\n",
      "Initial position:  [    7 51595  1787   671    82   208]\n",
      "Initial position:  [    7 19867  1772   711    92   234]\n",
      "Initial position:  [    5 81796  1622   623    87   219]\n",
      "Initial position:  [     5 131021   1624    599     97    246]\n",
      "Initial position:  [    7 82694  1764   716    93   235]\n",
      "Initial position:  [    5 44139  1642   619    91   229]\n",
      "Initial position:  [    7 96712  1780   753    77   194]\n",
      "Initial position:  [    5 26104  1573   582    99   249]\n",
      "Initial position:  [     7 136503   1773    739     87    219]\n",
      "Initial position:  [    0 90565  1842   590    74   265]\n",
      "Initial position:  [    3 10345  1355   147    39    98]\n",
      "Initial position:  [    3 59097  1326   133    45   113]\n",
      "Initial position:  [    1 45236   691   130    70   177]\n",
      "Initial position:  [    5 57782  1577   582    99   250]\n",
      "Initial position:  [    0 64014  1858   271    51   207]\n",
      "Initial position:  [     5 126051   1597    574    105    266]\n",
      "Initial position:  [     3 161459   1349    142     41    103]\n",
      "Initial position:  [    5 95863  1622   617    89   225]\n",
      "Initial position:  [    5 35098  1570   592    93   236]\n",
      "Initial position:  [     7 150828   1759    701     91    231]\n",
      "Initial position:  [    3 56746  1332   144    40   102]\n",
      "Initial position:  [    7 96101   323   802   103   259]\n",
      "Initial position:  [     5 155184   1608    574    107    270]\n",
      "Initial position:  [    0 54885  1859   284    51   203]\n",
      "Initial position:  [    1 78599   713   142    65   164]\n",
      "Initial position:  [    1 54997  1843   386    67   224]\n",
      "Initial position:  [    5 52636  1596   607    90   228]\n",
      "Initial position:  [     5 178038   1586    594     94    239]\n",
      "Initial position:  [    7 45993  1822   553    62   162]\n",
      "Initial position:  [    7 56267   287   811    97   243]\n",
      "Initial position:  [    7 34355  1771   727    88   224]\n",
      "Initial position:  [    5 21129  1619   580   105   265]\n",
      "Initial position:  [     0 148176   1851    373     65    223]\n",
      "Initial position:  [    5 32134  1618   610    92   232]\n",
      "Initial position:  [     5 115274   1596    601     93    235]\n",
      "Initial position:  [    3 97565  1324   131    46   116]\n",
      "Initial position:  [     5 125619   1612    603     94    238]\n",
      "Initial position:  [    2 57037   970   382    80   203]\n",
      "Initial position:  [     1 149921    692    139     67    169]\n",
      "Initial position:  [    0 31571  1848   310    67   196]\n",
      "Initial position:  [    0 78543  1854   268    56   218]\n",
      "Initial position:  [    7 51667  1774   710    86   219]\n",
      "Initial position:  [     5 107824   1604    602     94    237]\n",
      "Initial position:  [    5 83722  1635   612    93   236]\n",
      "Initial position:  [     7 134363   1770    794     84    212]\n",
      "Initial position:  [     5 117211   1645    613     94    237]\n",
      "Initial position:  [    7 72043  1760   777    94   239]\n",
      "Initial position:  [    3 95085  1328   144    40   102]\n",
      "Initial position:  [    7 39780   268   815    96   244]\n",
      "Initial position:  [    7 75668    81   774   113   283]\n",
      "Initial position:  [     7 173603   1764    768     93    236]\n",
      "Initial position:  [    7 49686  1822   563    55   159]\n",
      "Initial position:  [    3 52946  1356   142    41   104]\n",
      "Initial position:  [     7 178352   1773    744     84    213]\n",
      "Initial position:  [    0 31496  1854   279    51   221]\n",
      "Initial position:  [    7 10406  1760   751    94   239]\n",
      "Initial position:  [    5 94973  1591   611    88   222]\n",
      "Initial position:  [    5 79272  1626   593   100   253]\n",
      "Initial position:  [    5 49858  1609   619    86   219]\n",
      "Initial position:  [    7 77380   108   812    98   247]\n",
      "Initial position:  [    5 40374  1558   565   104   262]\n",
      "Initial position:  [     0 135085   1852    315     63    197]\n",
      "Initial position:  [     7 124538     90    775    112    279]\n",
      "Initial position:  [     0 123143   1832    416     84    212]\n",
      "Initial position:  [    1 65544   680   134    68   172]\n",
      "Initial position:  [    2 25392   999   382    80   202]\n",
      "Initial position:  [    7 18306  1771   716    90   228]\n",
      "Initial position:  [    7 67716  1774   729    86   217]\n",
      "Initial position:  [    7 28005   311   831    90   226]\n",
      "Initial position:  [    5 31697  1591   622    83   209]\n",
      "Initial position:  [     5 168949   1643    624     89    225]\n",
      "Initial position:  [    7 85423  1770   752    85   216]\n",
      "Initial position:  [     5 175732   1638    595    101    255]\n",
      "Initial position:  [    7 75919   232   811    97   241]\n",
      "Initial position:  [    5 64996  1611   608    92   232]\n",
      "Initial position:  [    7 98494  1762   743    97   244]\n",
      "Initial position:  [    5 63936  1652   625    89   226]\n",
      "Initial position:  [     0 126368   1851    300     65    207]\n",
      "Initial position:  [    5 80925  1589   595    95   240]\n",
      "Initial position:  [    7 89764   135   815    96   242]\n",
      "Initial position:  [     7 119009   1771    746     88    222]\n",
      "Initial position:  [     1 142107    709    146     63    160]\n",
      "Initial position:  [     0 150015   1841    411     64    232]\n",
      "Initial position:  [    3 61636  1338   138    43   109]\n",
      "Initial position:  [    5 27327  1571   610    86   217]\n",
      "Initial position:  [   1 5726  671  127   72  181]\n",
      "Initial position:  [    7 40941   340   802   102   253]\n",
      "Initial position:  [    5 20679  1592   590   103   261]\n",
      "Initial position:  [    0 23026  1847   365    62   249]\n",
      "Initial position:  [    5 83535  1594   617    86   216]\n",
      "Initial position:  [    7 42121   192   816    96   243]\n",
      "Initial position:  [    7 61425   254   819    94   237]\n",
      "Initial position:  [   0 2936  979  330  102  257]\n",
      "Initial position:  [    7 54911   262   807    99   246]\n",
      "Initial position:  [    0 20148  1822   266    92   232]\n",
      "Initial position:  [    7 34212  1771   717    93   236]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial position:  [    0 52499  1857   278    50   208]\n",
      "Initial position:  [    5 90224  1620   587   102   258]\n",
      "Initial position:  [     7 179445    236    798    102    254]\n",
      "Initial position:  [    1 77723   710   146    63   160]\n",
      "Initial position:  [     7 137022   1768    752     91    231]\n",
      "Initial position:  [     7 172260   1768    712     93    234]\n",
      "Initial position:  [    0 35281  1830   285    83   210]\n",
      "Initial position:  [    3 44488  1337   140    42   106]\n",
      "Initial position:  [    7 40227  1799   651    72   183]\n",
      "Initial position:  [     7 107472   1772    726     85    216]\n",
      "Initial position:  [    0 58943  1855   270    62   213]\n",
      "Initial position:  [    7 50956  1771   741    87   220]\n",
      "Initial position:  [    3 50710  1321   144    40   102]\n",
      "Initial position:  [    0 79349  1855   295    61   187]\n",
      "Initial position:  [    5 62032  1589   595    95   240]\n",
      "Initial position:  [    0 42591  1830   743    77   311]\n",
      "Initial position:  [    5 51175  1583   594    94   239]\n",
      "Initial position:  [     7 138003   1755    488     59    148]\n",
      "Initial position:  [    1 35136   706   133    68   173]\n",
      "Initial position:  [     5 120661   1590    584    100    252]\n",
      "Initial position:  [    3 60114  1322   161    33    84]\n",
      "Initial position:  [    3 39140  1317   134    44   112]\n",
      "Initial position:  [     0 106172   1853    318     64    211]\n",
      "Initial position:  [     7 154705   1797    679     70    176]\n",
      "Initial position:  [    5 48228  1628   617    90   226]\n",
      "Initial position:  [     4 127771   1808    580    102    293]\n",
      "Initial position:  [     7 141674    427    818     96    243]\n",
      "Initial position:  [     0 152149   1854    298     58    213]\n",
      "Initial position:  [    7 24816   259   805   100   251]\n",
      "Initial position:  [    7 39886  1803   625    73   183]\n",
      "Initial position:  [     5 121351   1628    612     92    233]\n",
      "Initial position:  [   7 2936 1020  380   73  185]\n",
      "Initial position:  [    1 83297  1840   404    75   228]\n",
      "Initial position:  [    0 74550  1840   377    74   231]\n",
      "Initial position:  [    0 81401  1854   308    63   202]\n",
      "Initial position:  [     0 118478   1854    282     57    216]\n",
      "Initial position:  [    7 65703   273   816    96   236]\n",
      "Initial position:  [    1 38435   646   120    75   189]\n",
      "Initial position:  [     0 107765   1848    267     68    212]\n",
      "Initial position:  [     7 119408   1773    734     86    218]\n",
      "Initial position:  [     0 112350   1845    278     72    215]\n",
      "Initial position:  [    3 47912  1324   144    40   102]\n",
      "Initial position:  [     7 177708   1767    773     88    222]\n",
      "Initial position:  [    7 80730   891   806   103   261]\n",
      "Initial position:  [     7 128624   1766    778     88    223]\n",
      "Initial position:  [     7 112135    298    815     95    239]\n",
      "Initial position:  [    0 61203  1846   402    70   209]\n",
      "Initial position:  [    2 90332   972   387    78   197]\n",
      "Initial position:  [    7 21793   329   807   100   250]\n",
      "Initial position:  [     6 101401     23    587     65    213]\n",
      "Initial position:  [    7 46410  1770   702    82   231]\n",
      "Initial position:  [    7 58941  1778   758    77   195]\n",
      "Initial position:  [    5 57696  1581   610    87   220]\n",
      "Initial position:  [     7 163009    212    831     88    218]\n",
      "Initial position:  [    0 45335  1848   374    68   230]\n",
      "Initial position:  [    1 49033   708   138    67   169]\n",
      "Initial position:  [   7 3204  771  379   68  172]\n",
      "Initial position:  [    7 70766  1769   756    89   224]\n",
      "Initial position:  [    1 97620   682   136    68   173]\n",
      "Initial position:  [    5 50686  1598   607    90   229]\n",
      "Initial position:  [    7 33747  1771   750    82   208]\n",
      "Initial position:  [     1 113456   1608    774    113    280]\n",
      "Initial position:  [     7 147282   1760    765     93    235]\n",
      "Initial position:  [    5 78156  1582   583    99   251]\n",
      "Initial position:  [     7 127497   1802    563     65    175]\n",
      "Initial position:  [    1 76933   723   138    67   169]\n",
      "Initial position:  [    7 92698  1769   778    82   208]\n",
      "Initial position:  [     0 146957   1853    289     65    224]\n",
      "Initial position:  [     0 112504   1843    265     74    212]\n",
      "Initial position:  [    3 40252  1339   134    44   111]\n",
      "Initial position:  [    7 36023  1773   711    85   227]\n",
      "Initial position:  [    7 58933   129   806    99   243]\n",
      "Initial position:  [    7 52705   241   784   109   270]\n",
      "Initial position:  [    3 50066  1336   140    42   106]\n",
      "Initial position:  [     7 127540    181    815     96    244]\n",
      "Initial position:  [   3 3352 1413  698  140  353]\n",
      "Initial position:  [     7 100354   1763    733     98    249]\n",
      "Initial position:  [     7 100049   1769    723     94    238]\n",
      "Initial position:  [     0 126858   1851    427     56    228]\n",
      "Initial position:  [     7 142598   1767    724     94    238]\n",
      "Initial position:  [    7 62856   267   795   104   255]\n",
      "Initial position:  [    7 75788   218   817    95   237]\n",
      "Initial position:  [    7 56391   371   834    89   222]\n",
      "Initial position:  [    7 45475   289   823    93   236]\n",
      "Initial position:  [    7 84614  1766   730    86   217]\n",
      "Initial position:  [    3 39602  1330   130    46   116]\n",
      "Initial position:  [    3 42724  1367   136    44   110]\n",
      "Initial position:  [     7 143129   1759    736     99    250]\n",
      "Initial position:  [     7 141722   1765    781     85    216]\n",
      "Initial position:  [    0 39197  1849   402    63   244]\n",
      "Initial position:  [    5 78441  1598   617    86   218]\n",
      "Initial position:  [     7 115978    148    785    108    274]\n",
      "Initial position:  [     0 123239   1855    391     61    206]\n",
      "Initial position:  [    1 70071   626   718   137   339]\n",
      "Initial position:  [    5 74610  1588   600    92   234]\n",
      "Initial position:  [    7 20809   295   811    98   248]\n",
      "Initial position:  [    7 29789  1765   744    97   245]\n",
      "Initial position:  [    7 23818  1829   495    57   160]\n",
      "Initial position:  [    0 87059  1847   265    69   224]\n",
      "Initial position:  [     3 115168   1352    145     40    101]\n",
      "Initial position:  [     3 136441   1365    144     40    102]\n",
      "Initial position:  [     5 130619   1599    607     91    229]\n",
      "Initial position:  [     5 153055   1617    620     87    220]\n",
      "Initial position:  [    4 32208    50   214    82   208]\n",
      "Initial position:  [     2 111431    918    391     76    193]\n",
      "Initial position:  [     7 178213   1771    761     83    211]\n",
      "Initial position:  [   5 8510 1620  604   95  239]\n",
      "Initial position:  [     0 135733   1847    265     69    218]\n",
      "Initial position:  [     7 106056   1829    495     59    149]\n",
      "Initial position:  [     7 123157   1771    742     87    221]\n",
      "Initial position:  [    7 68069   480   837    89   219]\n",
      "Initial position:  [    7 86404  1743   733    83   210]\n",
      "Initial position:  [    0 78520  1839   373    77   216]\n",
      "Initial position:  [    1 36683   680   142    65   164]\n",
      "Initial position:  [    1 43823  1828   390    81   223]\n",
      "Initial position:  [    2 87117   990   387    78   197]\n",
      "Initial position:  [   5 6278 1626  606   95  239]\n",
      "Initial position:  [     0 112442   1848    395     68    221]\n",
      "Initial position:  [   0 6324 1862  333   55  157]\n",
      "Initial position:  [    5 29635  1583   588    97   245]\n",
      "Initial position:  [     0 110296   1853    261     52    223]\n",
      "Initial position:  [    7 59921  1726   724   104   262]\n",
      "Initial position:  [    2 18617  1021   388    78   196]\n",
      "Initial position:  [     1 172874    697    126     72    182]\n",
      "Initial position:  [    7 62419   255   813    96   244]\n",
      "Initial position:  [    0 18335  1853   393    53   220]\n",
      "Initial position:  [    7 68228   276   822    93   236]\n",
      "Initial position:  [    0 92224  1844   437    73   216]\n",
      "Initial position:  [     7 180154   1765    794     87    219]\n",
      "Initial position:  [    3 29938  1329   147    39    99]\n",
      "Initial position:  [    5 44485  1633   606    95   241]\n",
      "Initial position:  [    7 22423  1770   708    87   233]\n",
      "Initial position:  [    0 79870  1849   278    68   208]\n",
      "Initial position:  [     7 140565    293    798    103    256]\n",
      "Initial position:  [    7 71489  1777   725    85   216]\n",
      "Initial position:  [    0 49026  1863   294    52   187]\n",
      "Initial position:  [    3 66631  1343   140    42   106]\n",
      "Initial position:  [    7 50865   283   798   103   259]\n",
      "Initial position:  [    0 69593  1848   359    68   227]\n",
      "Initial position:  [    5 65260  1632   623    88   223]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial position:  [    7 36130   333   802   102   258]\n",
      "Initial position:  [     7 161987    321    799    102    259]\n",
      "Initial position:  [    7 74844   209   835    88   219]\n",
      "Initial position:  [    7 64913   296   817    96   238]\n",
      "Initial position:  [    7 83758  1773   722    85   215]\n",
      "Initial position:  [     7 114940    298    799    103    253]\n",
      "Initial position:  [     7 119019   1742    789     83    211]\n",
      "Initial position:  [    7 68033  1773   732    89   225]\n",
      "Initial position:  [    5 66852  1591   606    90   228]\n",
      "Initial position:  [    0 35934  1821   401    85   216]\n",
      "Initial position:  [    0 48752  1800   243    82   207]\n",
      "Initial position:  [    7 19158  1769   750    85   215]\n",
      "Initial position:  [    7 74702  1770   731    89   225]\n",
      "Initial position:  [    5 71972  1629   627    85   216]\n",
      "Initial position:  [    5 25150  1615   611    91   230]\n",
      "Initial position:  [     7 136996   1767    718     87    221]\n",
      "Initial position:  [     7 136413    294    799    103    257]\n",
      "Initial position:  [    7 51680  1769   762    86   218]\n",
      "Initial position:  [    1 45297   687   138    66   168]\n",
      "Initial position:  [     0 126555   1851    435     63    230]\n",
      "Initial position:  [     7 156391   1790    646     67    202]\n",
      "Initial position:  [    3 14647  1330   144    40   102]\n",
      "Initial position:  [    0 27413  1839   273    77   207]\n",
      "Initial position:  [    7 74299  1773   729    86   217]\n",
      "Initial position:  [    7 64894   182   810    96   243]\n",
      "Initial position:  [    6 40760   884   567    66   166]\n",
      "Initial position:  [    0 18718  1836   318    76   192]\n",
      "Initial position:  [    7 69023  1771   763    83   211]\n",
      "Initial position:  [    7 23469   216   804   101   249]\n",
      "Initial position:  [    5 58669  1640   631    85   215]\n",
      "Initial position:  [     2 168117    931    360     89    226]\n",
      "Initial position:  [    5 14492  1602   602    93   236]\n",
      "Initial position:  [    3 60209  1343   143    41   103]\n",
      "Initial position:  [    7 77309  1779   734    80   203]\n",
      "Initial position:  [    7 72000  1766   732    95   241]\n",
      "Initial position:  [     7 142105   1767    729     92    232]\n",
      "Initial position:  [    3 35205  1314   147    39    98]\n",
      "Initial position:  [    0 68668  1847   371    69   216]\n",
      "Initial position:  [     7 112415   1775    735     83    211]\n",
      "Initial position:  [     0 109657   1851    304     66    208]\n",
      "Initial position:  [     0 117016   1857    270     56    213]\n",
      "Initial position:  [    1 27362   703   142    65   165]\n",
      "Initial position:  [    5 70633  1595   608    90   228]\n",
      "Initial position:  [    0 83934  1855   260    51   217]\n",
      "Initial position:  [    7 95539  1771   723    85   215]\n",
      "Initial position:  [    5 21015  1604   603    93   235]\n",
      "Initial position:  [     7 126922     91    776    112    283]\n",
      "Initial position:  [    0 94156  1853   270    64   219]\n",
      "Initial position:  [     3 116110   1319    139     42    107]\n",
      "Initial position:  [    7 45285  1775   713    87   219]\n",
      "Initial position:  [    3 32073  1364   141    41   104]\n",
      "Initial position:  [    7 96777  1776   746    82   207]\n",
      "Initial position:  [    0 87701  1848   283    69   197]\n",
      "Initial position:  [    5 54607  1586   589    97   246]\n",
      "Initial position:  [    1 10195   689   142    65   164]\n",
      "Initial position:  [    5 49490  1561   613    84   211]\n",
      "Initial position:  [     7 142365   1770    731     89    225]\n",
      "Initial position:  [     7 117659   1792    636     69    199]\n",
      "Initial position:  [     7 166679    285    797    103    255]\n",
      "Initial position:  [     7 144374   1776    746     82    206]\n",
      "Initial position:  [    3 79709  1346   137    43   109]\n",
      "Initial position:  [    5 54923  1574   599    91   230]\n",
      "Initial position:  [    3 61384  1329   154    36    91]\n",
      "Initial position:  [    0 81761  1860   294    45   193]\n",
      "Initial position:  [    7 97782   235   794   105   266]\n",
      "Initial position:  [    4 17339  1835   488    78   251]\n",
      "Initial position:  [     0 179814   1849    292     68    199]\n",
      "Initial position:  [    1 27557   553   710   140   346]\n",
      "Initial position:  [     7 138884   1762    768     93    236]\n",
      "Initial position:  [    7 25597  1743   750    88   223]\n",
      "Initial position:  [     0 127776   1853    287     63    204]\n",
      "Initial position:  [    5 33474  1564   586    95   241]\n",
      "Initial position:  [    5 43023  1577   598    92   232]\n",
      "Initial position:  [    5 52565  1575   620    82   208]\n",
      "Initial position:  [    5 36403  1583   610    87   221]\n",
      "Initial position:  [    5 91738  1657   615    95   240]\n",
      "Initial position:  [    0 68668  1824   288    78   198]\n",
      "Initial position:  [    7 53221  1787   681    78   197]\n",
      "Initial position:  [    1 87622   706   154    60   151]\n",
      "Initial position:  [     5 136988   1611    614     89    225]\n",
      "Initial position:  [    4 59486  1830   580    70   283]\n",
      "Initial position:  [     6 144436    871    563     67    171]\n",
      "Initial position:  [    5 27643  1605   591    98   249]\n",
      "Initial position:  [    5 57873  1579   593    94   238]\n",
      "Initial position:  [     7 140566    148    771    114    283]\n",
      "Initial position:  [    0 47253  1843   257    74   229]\n",
      "Initial position:  [     1 126778    681    138     66    168]\n",
      "Initial position:  [    7 58097   263   796   104   258]\n",
      "Initial position:  [    0 75069  1835   281    80   203]\n",
      "Initial position:  [     5 165299   1594    600     93    235]\n",
      "Initial position:  [     7 143524   1771    717     93    236]\n",
      "Initial position:  [    7 12136  1766   738    93   235]\n",
      "Initial position:  [    5 56634  1594   606    91   229]\n",
      "Initial position:  [    0 52598  1819   280    83   209]\n",
      "Initial position:  [    3 55961  1305   133    45   114]\n",
      "Initial position:  [    5 17818  1637   623    89   224]\n",
      "Initial position:  [    3 21392  1323   142    41   104]\n",
      "Initial position:  [    7 71677  1775   739    87   220]\n",
      "Initial position:  [    7 61498   281   797   104   262]\n",
      "Initial position:  [    0 86048   439   734   132   333]\n",
      "Initial position:  [    7 93112  1764   759    92   233]\n",
      "Initial position:  [    7 17749   346   826    92   227]\n",
      "Initial position:  [     3 108036   1373    141     41    105]\n",
      "Initial position:  [    3 74618  1316   134    44   112]\n",
      "Initial position:  [    3 84873  1309   138    43   109]\n",
      "Initial position:  [    7 11198  1770   765    84   212]\n",
      "Initial position:  [    0 40963  1852   291    65   186]\n",
      "Initial position:  [    0 56732  1845   397    71   236]\n",
      "Initial position:  [    7 70996  1762   741    96   244]\n",
      "Initial position:  [    7 82500  1762   758    83   210]\n",
      "Initial position:  [    5 70558  1575   610    86   219]\n",
      "Initial position:  [    1 94121  1834   611    79   284]\n",
      "Initial position:  [    7 88404  1770   727    88   224]\n",
      "Initial position:  [    7 72611  1726   472    65   163]\n",
      "Initial position:  [    0 77203  1853   282    63   197]\n",
      "Initial position:  [    7 66042   208   810    98   244]\n",
      "Initial position:  [    5 40703  1586   612    87   220]\n",
      "Initial position:  [    7 56532  1777   747    82   207]\n",
      "Initial position:  [    2 33528   957   346    96   242]\n",
      "Initial position:  [   5 8372 1601  597   95  241]\n",
      "Initial position:  [    5 18505  1628   594   100   254]\n",
      "Initial position:  [     5 165405   1631    633     83    210]\n",
      "Initial position:  [     0 118350   1857    288     60    210]\n",
      "Initial position:  [     0 114350   1855    290     61    205]\n",
      "Initial position:  [    3 50386  1328   128    47   119]\n",
      "Initial position:  [    2 74059   956   371    85   214]\n",
      "Initial position:  [     1 105420   1838    351     73    236]\n",
      "Initial position:  [     0 129312   1862    297     44    187]\n",
      "Initial position:  [    1 76808   696   131    70   177]\n",
      "Initial position:  [    7 49807  1826   551    62   156]\n",
      "Initial position:  [    5 22944  1588   571   105   265]\n",
      "Initial position:  [    0 27959  1840   529    67   284]\n",
      "Initial position:  [    7 96719   310   811    98   243]\n",
      "Initial position:  [     5 140952   1619    593     99    252]\n",
      "Initial position:  [     7 123212   1700    490     56    142]\n",
      "Initial position:  [     7 119719   1749    730     89    224]\n",
      "Initial position:  [     7 112374   1757    768     93    236]\n",
      "Initial position:  [    5 47167  1600   613    88   224]\n",
      "Initial position:  [     7 173545   1761    788     89    226]\n",
      "Initial position:  [     7 129356   1774    722     88    222]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial position:  [    5 45227  1354   741   129   320]\n",
      "Initial position:  [    1 88455  1836   342    63   241]\n",
      "Initial position:  [     0 124191   1857    372     61    209]\n",
      "Initial position:  [    4 29735  1825   593    87   294]\n",
      "Initial position:  [    7 81443  1775   737    84   212]\n",
      "Initial position:  [    7 73503   288   819    93   235]\n",
      "Initial position:  [     0 116262   1855    278     61    208]\n",
      "Initial position:  [     7 154512   1771    741     87    220]\n",
      "Initial position:  [    0 67792  1841   423    74   242]\n",
      "Initial position:  [    7 17010  1770   740    87   220]\n",
      "Initial position:  [     7 152030   1774    767     84    212]\n",
      "Initial position:  [     3 102896   1310    129     46    117]\n",
      "Initial position:  [     7 177780   1770    713     93    234]\n",
      "Initial position:  [     5 115485   1627    616     90    229]\n",
      "Initial position:  [     7 141449   1738    745     82    206]\n",
      "Initial position:  [    7 71499  1771   759    86   218]\n",
      "Initial position:  [    3 13496  1321   139    42   107]\n",
      "Initial position:  [     0 153733   1854    284     52    216]\n",
      "Initial position:  [    5 57932  1593   612    88   222]\n",
      "Initial position:  [     0 147024   1860    301     56    201]\n",
      "Initial position:  [     7 110976    221    791    106    264]\n",
      "Initial position:  [    0 75443  1847   283    70   203]\n",
      "Initial position:  [    1 80147   727   716   138   344]\n",
      "Initial position:  [    7 22404   262   827    91   229]\n",
      "Initial position:  [    0 18837  1843   300    73   207]\n",
      "Initial position:  [    7 60466   294   830    90   223]\n",
      "Initial position:  [    7 50971   315   800   103   259]\n",
      "Initial position:  [     5 155228   1604    585    101    256]\n",
      "Initial position:  [    7 17639   303   830    90   224]\n",
      "Initial position:  [    7 13990   283   804   101   255]\n",
      "Initial position:  [    0 15884  1838   288    78   211]\n",
      "Initial position:  [    5 58572  1633   617    90   229]\n",
      "Initial position:  [     0 113261   1842    359     74    241]\n",
      "Initial position:  [    5 79123  1609   603    94   237]\n",
      "Initial position:  [     7 179533    277    796    104    259]\n",
      "Initial position:  [     7 131403    314    837     88    217]\n",
      "Initial position:  [     1 121912   1857    463     48    144]\n",
      "Initial position:  [    5 24562  1607   591    99   250]\n",
      "Initial position:  [     7 118159   1774    718     87    221]\n",
      "Initial position:  [    2 70312  1010   357    91   229]\n",
      "Initial position:  [     3 129497   1360    142     41    104]\n",
      "Initial position:  [     5 156094   1627    600     98    248]\n",
      "Initial position:  [     5 143986     26    740    132    332]\n",
      "Initial position:  [    7 55189  1801   655    70   178]\n",
      "Initial position:  [    7 69235   111   802   100   252]\n",
      "Initial position:  [     7 119095   1727    733     83    210]\n",
      "Initial position:  [     5 132125   1624    617     89    226]\n",
      "Initial position:  [    5 67503  1626   610    92   234]\n",
      "Initial position:  [     3 157001   1339    135     44    111]\n",
      "Initial position:  [    5 44516  1565   603    88   222]\n",
      "Initial position:  [    0 44330  1858   295    59   206]\n",
      "Initial position:  [    7 34704  1772   733    86   218]\n",
      "Initial position:  [     7 169515   1759    731     86    217]\n",
      "Initial position:  [    7 65763   255   815    97   243]\n",
      "Initial position:  [     7 145157   1777    757     80    202]\n",
      "Initial position:  [     7 152424    251    796    104    260]\n",
      "Initial position:  [    7 17838   292   820    94   233]\n",
      "Initial position:  [     0 146821   1849    291     68    199]\n",
      "Initial position:  [   1 2936 1061  418  103  260]\n",
      "Initial position:  [    7 67637   210   791   106   268]\n",
      "Initial position:  [     7 173541   1747    724     88    223]\n",
      "Initial position:  [     7 117265   1735    709     89    226]\n",
      "Initial position:  [     7 141786   1766    740     96    243]\n",
      "Initial position:  [     7 110551    310    818     95    235]\n",
      "Initial position:  [    1 44336   686   130    70   177]\n",
      "Initial position:  [    5 49380  1567   581    98   249]\n",
      "Initial position:  [     0 114601   1851    402     65    229]\n",
      "Person:  0\n",
      "Transitions:  [7, 8, 0, 8]\n",
      "GT transitions:  1\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.9574062301335029 0.9214285714285714 0.9987096774193548\n",
      "Num frames:  (840, 66)\n",
      "Accuracy:  0.9574062301335029\n",
      "Person:  1\n",
      "Transitions:  [0, 8, 1, 8]\n",
      "GT transitions:  1\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.8717241379310345 0.7326440177252584 0.7492447129909365\n",
      "Num frames:  (677, 20)\n",
      "Accuracy:  0.8717241379310345\n",
      "Person:  2\n",
      "Transitions:  [0, 8, 1, 8, 4, 8, 5, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.93923974857827 0.8764478764478765 0.9905454545454545\n",
      "Num frames:  (1554, 190)\n",
      "Accuracy:  0.93923974857827\n",
      "Person:  3\n",
      "Transitions:  [7, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.996551724137931 0.996551724137931 1.0\n",
      "Num frames:  (290, 1)\n",
      "Accuracy:  0.996551724137931\n",
      "Person:  4\n",
      "Transitions:  [0, 8, 1, 8]\n",
      "GT transitions:  1\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.8683812405446294 0.748792270531401 0.7299843014128728\n",
      "Num frames:  (621, 2)\n",
      "Accuracy:  0.8683812405446294\n",
      "Person:  5\n",
      "Transitions:  [7, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.9963369963369964 0.9963369963369964 1.0\n",
      "Num frames:  (273, 1)\n",
      "Accuracy:  0.9963369963369964\n",
      "Person:  6\n",
      "Transitions:  [5, 8, 6, 8, 7, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.9814482345900658 0.9693877551020408 0.9989484752891693\n",
      "Num frames:  (980, 30)\n",
      "Accuracy:  0.9814482345900658\n",
      "Person:  7\n",
      "Transitions:  [7, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.9958847736625515 0.9958847736625515 1.0\n",
      "Num frames:  (243, 1)\n",
      "Accuracy:  0.9958847736625515\n",
      "Person:  8\n",
      "Transitions:  [5, 8, 4, 8]\n",
      "GT transitions:  1\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.9474799811587377 0.9452424800491099 1.0\n",
      "Num frames:  (8145, 446)\n",
      "Accuracy:  0.9474799811587377\n",
      "Person:  9\n",
      "Transitions:  [7, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.9963636363636363 0.9963636363636363 1.0\n",
      "Num frames:  (275, 1)\n",
      "Accuracy:  0.9963636363636363\n",
      "Person:  10\n",
      "Transitions:  [7, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.9975369458128078 0.9975369458128078 1.0\n",
      "Num frames:  (406, 1)\n",
      "Accuracy:  0.9975369458128078\n",
      "Person:  11\n",
      "Transitions:  [1, 8, 0, 8]\n",
      "GT transitions:  1\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.8252126836813611 0.7021563342318059 0.7464183381088825\n",
      "Num frames:  (742, 49)\n",
      "Accuracy:  0.8252126836813611\n",
      "Person:  12\n",
      "Transitions:  [7, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.9966555183946488 0.9966555183946488 1.0\n",
      "Num frames:  (299, 1)\n",
      "Accuracy:  0.9966555183946488\n",
      "Person:  13\n",
      "Transitions:  [7, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.9965870307167235 0.9965870307167235 1.0\n",
      "Num frames:  (293, 1)\n",
      "Accuracy:  0.9965870307167235\n",
      "Person:  14\n",
      "Transitions:  [5, 8, 4, 8, 2, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.9293177627535341 0.9076305220883534 0.9991158267020336\n",
      "Num frames:  (1245, 114)\n",
      "Accuracy:  0.9293177627535341\n",
      "Person:  15\n",
      "Transitions:  [7, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.9965277777777778 0.9965277777777778 1.0\n",
      "Num frames:  (288, 1)\n",
      "Accuracy:  0.9965277777777778\n",
      "Person:  16\n",
      "Transitions:  [7, 8, 0, 8]\n",
      "GT transitions:  1\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.8581632653061224 0.9780487804878049 0.7551789077212806\n",
      "Num frames:  (410, 9)\n",
      "Accuracy:  0.8581632653061224\n",
      "Person:  17\n",
      "Transitions:  [3, 8, 2, 8, 1, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.8984263233190272 0.8490783410138248 0.8530092592592593\n",
      "Num frames:  (868, 15)\n",
      "Accuracy:  0.8984263233190272\n",
      "Person:  18\n",
      "Transitions:  [5, 8, 4, 8, 2, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.8904677323860273 0.8578016910069177 1.0\n",
      "Num frames:  (1301, 185)\n",
      "Accuracy:  0.8904677323860273\n",
      "Person:  19\n",
      "Transitions:  [7, 8, 6, 8, 5, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.958819913952059 0.9333333333333333 1.0\n",
      "Num frames:  (1005, 67)\n",
      "Accuracy:  0.958819913952059\n",
      "Person:  20\n",
      "Transitions:  [3, 8, 2, 8, 1, 8, 0, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.8789329685362517 0.8022346368715084 0.9264516129032258\n",
      "Num frames:  (1790, 240)\n",
      "Accuracy:  0.8789329685362517\n",
      "Person:  21\n",
      "Transitions:  [5, 8, 4, 8, 0, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.6318589956767542 0.5101769911504425 1.0\n",
      "Num frames:  (2260, 1107)\n",
      "Accuracy:  0.6318589956767542\n",
      "Person:  22\n",
      "Transitions:  [7, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.9963898916967509 0.9963898916967509 1.0\n",
      "Num frames:  (277, 1)\n",
      "Accuracy:  0.9963898916967509\n",
      "Person:  23\n",
      "Transitions:  [7, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.996415770609319 0.996415770609319 1.0\n",
      "Num frames:  (279, 1)\n",
      "Accuracy:  0.996415770609319\n",
      "Person:  24\n",
      "Transitions:  [7, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.9961685823754789 0.9961685823754789 1.0\n",
      "Num frames:  (261, 1)\n",
      "Accuracy:  0.9961685823754789\n",
      "Person:  25\n",
      "Transitions:  [7, 8, 0, 8]\n",
      "GT transitions:  1\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.9420468557336621 0.8842364532019704 1.0\n",
      "Num frames:  (812, 94)\n",
      "Accuracy:  0.9420468557336621\n",
      "Person:  26\n",
      "Transitions:  [7, 8, 0, 8]\n",
      "GT transitions:  1\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.9593199757134183 0.9278688524590164 0.9988235294117647\n",
      "Num frames:  (915, 66)\n",
      "Accuracy:  0.9593199757134183\n",
      "Person:  27\n",
      "Transitions:  [0, 8, 1, 8]\n",
      "GT transitions:  1\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.8672566371681416 0.7321428571428571 0.741307371349096\n",
      "Num frames:  (728, 9)\n",
      "Accuracy:  0.8672566371681416\n",
      "Person:  28\n",
      "Transitions:  [7, 8, 6, 8, 5, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.9072015466408894 0.8662952646239555 1.0\n",
      "Num frames:  (1436, 192)\n",
      "Accuracy:  0.9072015466408894\n",
      "Person:  29\n",
      "Transitions:  [5, 8, 4, 8, 1, 8, 0, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.9434114793856103 0.9171309192200557 0.9828358208955223\n",
      "Num frames:  (1436, 117)\n",
      "Accuracy:  0.9434114793856103\n",
      "Person:  30\n",
      "Transitions:  [0, 8, 7, 8]\n",
      "GT transitions:  1\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.901665344964314 0.7905405405405406 0.9989327641408752\n",
      "Num frames:  (1184, 247)\n",
      "Accuracy:  0.901665344964314\n",
      "Person:  31\n",
      "Transitions:  [3, 8, 2, 8, 1, 8, 0, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.8670003575259206 0.8009340338587274 0.8932291666666666\n",
      "Num frames:  (1713, 208)\n",
      "Accuracy:  0.8670003575259206\n",
      "Person:  32\n",
      "Transitions:  [3, 8, 2, 8, 1, 8, 0, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.8942470389170897 0.8348694316436251 0.832312404287902\n",
      "Num frames:  (1302, 31)\n",
      "Accuracy:  0.8942470389170897\n",
      "Person:  33\n",
      "Transitions:  [6, 8, 7, 8, 0, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.9341834635952283 0.8641765704584041 1.0\n",
      "Num frames:  (1178, 160)\n",
      "Accuracy:  0.9341834635952283\n",
      "Person:  34\n",
      "Transitions:  [3, 8, 2, 8, 1, 8, 0, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.9062383264848711 0.8456206679269062 0.93000693000693\n",
      "Num frames:  (1587, 150)\n",
      "Accuracy:  0.9062383264848711\n",
      "Person:  35\n",
      "Transitions:  [7, 8, 6, 8]\n",
      "GT transitions:  1\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.94362292051756 0.9003267973856209 1.0\n",
      "Num frames:  (612, 61)\n",
      "Accuracy:  0.94362292051756\n",
      "Person:  36\n",
      "Transitions:  [7, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A,P,R:  0.9962406015037594 0.9962406015037594 1.0\n",
      "Num frames:  (266, 1)\n",
      "Accuracy:  0.9962406015037594\n",
      "Person:  37\n",
      "Transitions:  [7, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.9968847352024922 0.9968847352024922 1.0\n",
      "Num frames:  (321, 1)\n",
      "Accuracy:  0.9968847352024922\n",
      "Person:  38\n",
      "Transitions:  [5, 8, 4, 8, 1, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.7521879318286504 0.7047200878155873 0.9922720247295209\n",
      "Num frames:  (1822, 528)\n",
      "Accuracy:  0.7521879318286504\n",
      "Person:  39\n",
      "Transitions:  [3, 8, 2, 8, 1, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.8733905579399142 0.8209408194233687 0.9077181208053692\n",
      "Num frames:  (1318, 126)\n",
      "Accuracy:  0.8733905579399142\n",
      "Person:  40\n",
      "Transitions:  [1, 8, 0, 8]\n",
      "GT transitions:  1\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.7544956997654417 0.6616231086657497 0.6143039591315453\n",
      "Num frames:  (727, 12)\n",
      "Accuracy:  0.7544956997654417\n",
      "Person:  41\n",
      "Transitions:  [7, 8, 0, 8]\n",
      "GT transitions:  1\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.9518348623853211 0.8963815789473685 1.0\n",
      "Num frames:  (608, 63)\n",
      "Accuracy:  0.9518348623853211\n",
      "Person:  42\n",
      "Transitions:  [3, 8, 2, 8, 1, 8, 0, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.9063205417607223 0.8445859872611465 0.9221140472878998\n",
      "Num frames:  (1570, 137)\n",
      "Accuracy:  0.9063205417607223\n",
      "Person:  43\n",
      "Transitions:  [2, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.9932885906040269 0.9932885906040269 1.0\n",
      "Num frames:  (149, 1)\n",
      "Accuracy:  0.9932885906040269\n",
      "Person:  44\n",
      "Transitions:  [5, 8, 6, 8, 7, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.9670804101457097 0.9485861182519281 0.9990974729241877\n",
      "Num frames:  (1167, 60)\n",
      "Accuracy:  0.9670804101457097\n",
      "Person:  45\n",
      "Transitions:  [3, 8, 2, 8, 1, 8, 0, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.8940578577013292 0.8207036535859269 0.8695340501792115\n",
      "Num frames:  (1478, 89)\n",
      "Accuracy:  0.8940578577013292\n",
      "Person:  46\n",
      "Transitions:  [7, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.9965753424657534 0.9965753424657534 1.0\n",
      "Num frames:  (292, 1)\n",
      "Accuracy:  0.9965753424657534\n",
      "Person:  47\n",
      "Transitions:  [7, 8, 6, 8, 5, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.8919549164399534 0.8555844155844156 1.0\n",
      "Num frames:  (1925, 278)\n",
      "Accuracy:  0.8919549164399534\n",
      "Person:  48\n",
      "Transitions:  [7, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.9964664310954063 0.9964664310954063 1.0\n",
      "Num frames:  (283, 1)\n",
      "Accuracy:  0.9964664310954063\n",
      "Person:  49\n",
      "Transitions:  [7, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.9964028776978417 0.9964028776978417 1.0\n",
      "Num frames:  (278, 1)\n",
      "Accuracy:  0.9964028776978417\n",
      "Person:  50\n",
      "Transitions:  [5, 8, 6, 8, 7, 8, 0, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.9865470852017937 0.9912216532553035 0.9825960841189267\n",
      "Num frames:  (1367, 12)\n",
      "Accuracy:  0.9865470852017937\n",
      "Person:  51\n",
      "Transitions:  [1, 8, 2, 8, 3, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.8507783145464305 0.7833203429462198 0.8641444539982803\n",
      "Num frames:  (1283, 120)\n",
      "Accuracy:  0.8507783145464305\n",
      "Person:  52\n",
      "Transitions:  [7, 8, 4, 8, 4, 8, 6, 8, 7, 8]\n",
      "GT transitions:  4\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.07638072855464159 0.04204753199268738 0.359375\n",
      "Num frames:  (13128, 11592)\n",
      "Accuracy:  0.07638072855464159\n",
      "Person:  53\n",
      "Transitions:  [7, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.9961685823754789 0.9961685823754789 1.0\n",
      "Num frames:  (261, 1)\n",
      "Accuracy:  0.9961685823754789\n",
      "Person:  54\n",
      "Transitions:  [5, 8, 4, 8, 1, 8, 0, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.9009937430990063 0.8456865127582017 0.9865343727852587\n",
      "Num frames:  (1646, 250)\n",
      "Accuracy:  0.9009937430990063\n",
      "Person:  55\n",
      "Transitions:  [3, 8, 2, 8, 1, 8, 0, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.9122330097087379 0.8501344086021505 0.9356508875739645\n",
      "Num frames:  (1488, 139)\n",
      "Accuracy:  0.9122330097087379\n",
      "Person:  56\n",
      "Transitions:  [0, 8, 1, 8]\n",
      "GT transitions:  1\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.8623376623376623 0.7283464566929134 0.7429718875502008\n",
      "Num frames:  (762, 20)\n",
      "Accuracy:  0.8623376623376623\n",
      "Person:  57\n",
      "Transitions:  [7, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.9961977186311787 0.9961977186311787 1.0\n",
      "Num frames:  (263, 1)\n",
      "Accuracy:  0.9961977186311787\n",
      "Person:  58\n",
      "Transitions:  [1, 8, 2, 8, 3, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.821605550049554 0.7498262682418346 0.8694601128122482\n",
      "Num frames:  (1439, 198)\n",
      "Accuracy:  0.821605550049554\n",
      "Person:  59\n",
      "Transitions:  [7, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.9966666666666667 0.9966666666666667 1.0\n",
      "Num frames:  (300, 1)\n",
      "Accuracy:  0.9966666666666667\n",
      "Person:  60\n",
      "Transitions:  [3, 8, 2, 8, 4, 8, 1, 8, 7, 8]\n",
      "GT transitions:  4\n",
      "Transitions captured:  4\n",
      "A,P,R:  0.8871103622577927 0.8207326578332035 0.9435483870967742\n",
      "Num frames:  (1283, 205)\n",
      "Accuracy:  0.8871103622577927\n",
      "Person:  61\n",
      "Transitions:  [0, 8, 1, 8, 4, 8, 5, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.8914748292436124 0.8033412887828162 0.9888366627497063\n",
      "Num frames:  (2095, 410)\n",
      "Accuracy:  0.8914748292436124\n",
      "Person:  62\n",
      "Transitions:  [5, 8, 4, 8, 1, 8, 0, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.9138706329989623 0.8577142857142858 1.0\n",
      "Num frames:  (1750, 249)\n",
      "Accuracy:  0.9138706329989623\n",
      "Person:  63\n",
      "Transitions:  [3, 8, 4, 8]\n",
      "GT transitions:  1\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.8117073170731708 0.7021604938271605 1.0\n",
      "Num frames:  (648, 193)\n",
      "Accuracy:  0.8117073170731708\n",
      "Person:  64\n",
      "Transitions:  [6, 8, 5, 8]\n",
      "GT transitions:  1\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.9335827876520112 0.9224043715846995 1.0\n",
      "Num frames:  (915, 71)\n",
      "Accuracy:  0.9335827876520112\n",
      "Person:  65\n",
      "Transitions:  [7, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.9966101694915255 0.9966101694915255 1.0\n",
      "Num frames:  (295, 1)\n",
      "Accuracy:  0.9966101694915255\n",
      "Person:  66\n",
      "Transitions:  [5, 8, 6, 8, 7, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.9362338093656593 0.9172056921086675 1.0\n",
      "Num frames:  (2319, 192)\n",
      "Accuracy:  0.9362338093656593\n",
      "Person:  67\n",
      "Transitions:  [7, 8, 6, 8, 5, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.9676567656765677 0.9463894967177243 1.0\n",
      "Num frames:  (914, 49)\n",
      "Accuracy:  0.9676567656765677\n",
      "Person:  68\n",
      "Transitions:  [3, 8, 2, 8, 1, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.9798190675017397 0.9713024282560706 0.9966024915062288\n",
      "Num frames:  (906, 26)\n",
      "Accuracy:  0.9798190675017397\n",
      "Person:  69\n",
      "Transitions:  [5, 8, 4, 8]\n",
      "GT transitions:  1\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.9770334928229665 0.9670487106017192 0.9970457902511078\n",
      "Num frames:  (698, 22)\n",
      "Accuracy:  0.9770334928229665\n",
      "Person:  70\n",
      "Transitions:  [0, 8, 7, 8]\n",
      "GT transitions:  1\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.9675186368477103 0.9331103678929766 0.9988066825775657\n",
      "Num frames:  (897, 60)\n",
      "Accuracy:  0.9675186368477103\n",
      "Person:  71\n",
      "Transitions:  [7, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.9955947136563876 0.9955947136563876 1.0\n",
      "Num frames:  (227, 1)\n",
      "Accuracy:  0.9955947136563876\n",
      "Person:  72\n",
      "Transitions:  [7, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.9876543209876543 0.9876543209876543 1.0\n",
      "Num frames:  (81, 1)\n",
      "Accuracy:  0.9876543209876543\n",
      "Person:  73\n",
      "Transitions:  [5, 8, 6, 8, 7, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.9325437693099897 0.8952837729816147 1.0\n",
      "Num frames:  (1251, 131)\n",
      "Accuracy:  0.9325437693099897\n",
      "Person:  74\n",
      "Transitions:  [0, 8, 6, 8, 5, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.8774625689519306 0.9253731343283582 0.7037457434733257\n",
      "Num frames:  (670, 50)\n",
      "Accuracy:  0.8774625689519306\n",
      "Person:  75\n",
      "Transitions:  [0, 8, 1, 8, 2, 8, 3, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.9177505738332058 0.8568249258160238 0.8690744920993227\n",
      "Num frames:  (1348, 41)\n",
      "Accuracy:  0.9177505738332058\n",
      "Person:  76\n",
      "Transitions:  [7, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.996742671009772 0.996742671009772 1.0\n",
      "Num frames:  (307, 1)\n",
      "Accuracy:  0.996742671009772\n",
      "Person:  77\n",
      "Transitions:  [7, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.9970238095238095 0.9970238095238095 1.0\n",
      "Num frames:  (336, 1)\n",
      "Accuracy:  0.9970238095238095\n",
      "Person:  78\n",
      "Transitions:  [0, 8, 1, 8, 4, 8, 5, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.8106894228609925 0.7082035306334372 0.8521449396084965\n",
      "Num frames:  (2889, 488)\n",
      "Accuracy:  0.8106894228609925\n",
      "Person:  79\n",
      "Transitions:  [1, 8, 2, 8, 4, 8, 5, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.8814942035208244 0.831453634085213 0.8840772818121253\n",
      "Num frames:  (1596, 102)\n",
      "Accuracy:  0.8814942035208244\n",
      "Person:  80\n",
      "Transitions:  [0, 8, 1, 8, 2, 8, 3, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.842963782139895 0.7459386281588448 0.8783209351753454\n",
      "Num frames:  (2216, 339)\n",
      "Accuracy:  0.842963782139895\n",
      "Person:  81\n",
      "Transitions:  [0, 8, 1, 8, 2, 8, 3, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.9023784167554135 0.8201581027667985 0.8706293706293706\n",
      "Num frames:  (1518, 90)\n",
      "Accuracy:  0.9023784167554135\n",
      "Person:  82\n",
      "Transitions:  [5, 8, 6, 8, 7, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.8995675156174916 0.849532037437005 1.0\n",
      "Num frames:  (1389, 209)\n",
      "Accuracy:  0.8995675156174916\n",
      "Person:  83\n",
      "Transitions:  [3, 8, 2, 8, 4, 8, 5, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.9041140265630061 0.8644391408114559 0.9805089334055225\n",
      "Num frames:  (2095, 260)\n",
      "Accuracy:  0.9041140265630061\n",
      "Person:  84\n",
      "Transitions:  [0, 8, 1, 8, 2, 8, 3, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.8967833156592435 0.8118421052631579 0.8720848056537103\n",
      "Num frames:  (1520, 111)\n",
      "Accuracy:  0.8967833156592435\n",
      "Person:  85\n",
      "Transitions:  [7, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.9969040247678018 0.9969040247678018 1.0\n",
      "Num frames:  (323, 1)\n",
      "Accuracy:  0.9969040247678018\n",
      "Person:  86\n",
      "Transitions:  [1, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.5730622617534943 0.5730622617534943 0.573791348600509\n",
      "Num frames:  (787, 1)\n",
      "Accuracy:  0.5730622617534943\n",
      "Person:  87\n",
      "Transitions:  [0, 8, 1, 8]\n",
      "GT transitions:  1\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.8450536352800954 0.7062146892655368 0.7378984651711924\n",
      "Num frames:  (885, 38)\n",
      "Accuracy:  0.8450536352800954\n",
      "Person:  88\n",
      "Transitions:  [5, 8, 4, 8, 1, 8, 0, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.916550279329609 0.8625866050808314 0.9993311036789297\n",
      "Num frames:  (1732, 238)\n",
      "Accuracy:  0.916550279329609\n",
      "Person:  89\n",
      "Transitions:  [1, 8, 0, 8]\n",
      "GT transitions:  1\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.8245476003147129 0.7054794520547946 0.7442196531791907\n",
      "Num frames:  (730, 46)\n",
      "Accuracy:  0.8245476003147129\n",
      "Person:  90\n",
      "Transitions:  [7, 8, 6, 8, 5, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.9647058823529412 0.9428284854563691 1.0\n",
      "Num frames:  (997, 57)\n",
      "Accuracy:  0.9647058823529412\n",
      "Person:  91\n",
      "Transitions:  [7, 8, 6, 8, 5, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.9375354911981828 0.9020480854853072 1.0\n",
      "Num frames:  (1123, 110)\n",
      "Accuracy:  0.9375354911981828\n",
      "Person:  92\n",
      "Transitions:  [1, 8, 0, 8]\n",
      "GT transitions:  1\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.7869170984455959 0.6556854410201913 0.7241784037558685\n",
      "Num frames:  (941, 94)\n",
      "Accuracy:  0.7869170984455959\n",
      "Person:  93\n",
      "Transitions:  [7, 8, 6, 8, 5, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.9585755813953488 0.9767441860465116 0.9545454545454546\n",
      "Num frames:  (817, 19)\n",
      "Accuracy:  0.9585755813953488\n",
      "Person:  94\n",
      "Transitions:  [7, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.9966777408637874 0.9966777408637874 1.0\n",
      "Num frames:  (301, 1)\n",
      "Accuracy:  0.9966777408637874\n",
      "Person:  95\n",
      "Transitions:  [5, 8, 6, 8, 7, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.9788933257273246 0.9655172413793104 1.0\n",
      "Num frames:  (1073, 37)\n",
      "Accuracy:  0.9788933257273246\n",
      "Person:  96\n",
      "Transitions:  [4, 8, 5, 8]\n",
      "GT transitions:  1\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.980276134122288 0.9775641025641025 0.9854604200323102\n",
      "Num frames:  (624, 11)\n",
      "Accuracy:  0.980276134122288\n",
      "Person:  97\n",
      "Transitions:  [7, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.9970059880239521 0.9970059880239521 1.0\n",
      "Num frames:  (334, 1)\n",
      "Accuracy:  0.9970059880239521\n",
      "Person:  98\n",
      "Transitions:  [7, 8, 6, 8, 5, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.9558080808080808 0.9304979253112033 0.9966666666666667\n",
      "Num frames:  (964, 67)\n",
      "Accuracy:  0.9558080808080808\n",
      "Person:  99\n",
      "Transitions:  [1, 8, 0, 8]\n",
      "GT transitions:  1\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.8171846435100548 0.7297551789077212 0.7804632426988922\n",
      "Num frames:  (1062, 82)\n",
      "Accuracy:  0.8171846435100548\n",
      "Person:  100\n",
      "Transitions:  [7, 8, 6, 8, 5, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.9106145251396648 0.867966991747937 1.0\n",
      "Num frames:  (1333, 176)\n",
      "Accuracy:  0.9106145251396648\n",
      "Person:  101\n",
      "Transitions:  [0, 8, 1, 8]\n",
      "GT transitions:  1\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.8568665377176016 0.7612903225806451 0.8173160173160173\n",
      "Num frames:  (1240, 85)\n",
      "Accuracy:  0.8568665377176016\n",
      "Person:  102\n",
      "Transitions:  [7, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.9969879518072289 0.9969879518072289 1.0\n",
      "Num frames:  (332, 1)\n",
      "Accuracy:  0.9969879518072289\n",
      "Person:  103\n",
      "Transitions:  [7, 8, 6, 8, 5, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.9717767799871713 0.9538784067085954 1.0\n",
      "Num frames:  (954, 44)\n",
      "Accuracy:  0.9717767799871713\n",
      "Person:  104\n",
      "Transitions:  [7, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.9970845481049563 0.9970845481049563 1.0\n",
      "Num frames:  (343, 1)\n",
      "Accuracy:  0.9970845481049563\n",
      "Person:  105\n",
      "Transitions:  [2, 8, 4, 8, 5, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.9238774903360095 0.9072463768115943 0.9940452560539896\n",
      "Num frames:  (2760, 241)\n",
      "Accuracy:  0.9238774903360095\n",
      "Person:  106\n",
      "Transitions:  [0, 8, 1, 8]\n",
      "GT transitions:  1\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.8769017980636238 0.743065693430657 0.7608370702541106\n",
      "Num frames:  (685, 18)\n",
      "Accuracy:  0.8769017980636238\n",
      "Person:  107\n",
      "Transitions:  [7, 8, 6, 8, 5, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.9709864603481625 0.9518201284796574 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num frames:  (934, 45)\n",
      "Accuracy:  0.9709864603481625\n",
      "Person:  108\n",
      "Transitions:  [4, 8, 5, 8]\n",
      "GT transitions:  1\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.9897100093545369 0.9840116279069767 0.9941262848751835\n",
      "Num frames:  (688, 7)\n",
      "Accuracy:  0.9897100093545369\n",
      "Person:  109\n",
      "Transitions:  [7, 8, 0, 8]\n",
      "GT transitions:  1\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.7453531598513011 0.609129814550642 1.0\n",
      "Num frames:  (1402, 548)\n",
      "Accuracy:  0.7453531598513011\n",
      "Person:  110\n",
      "Transitions:  [7, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.9976470588235294 0.9976470588235294 1.0\n",
      "Num frames:  (425, 1)\n",
      "Accuracy:  0.9976470588235294\n",
      "Person:  111\n",
      "Transitions:  [5, 8, 6, 8, 7, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.9429756350440642 0.9109311740890689 1.0\n",
      "Num frames:  (1235, 110)\n",
      "Accuracy:  0.9429756350440642\n",
      "Person:  112\n",
      "Transitions:  [7, 8, 0, 8]\n",
      "GT transitions:  1\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.9716267339218159 0.9476135040745053 1.0\n",
      "Num frames:  (859, 45)\n",
      "Accuracy:  0.9716267339218159\n",
      "Person:  113\n",
      "Transitions:  [5, 8, 4, 8]\n",
      "GT transitions:  1\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.9730215827338129 0.9606815203145478 1.0\n",
      "Num frames:  (763, 30)\n",
      "Accuracy:  0.9730215827338129\n",
      "Person:  114\n",
      "Transitions:  [7, 8, 6, 8, 5, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.928133704735376 0.8889845094664371 1.0\n",
      "Num frames:  (1162, 129)\n",
      "Accuracy:  0.928133704735376\n",
      "Person:  115\n",
      "Transitions:  [7, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.9824561403508771 0.9824561403508771 1.0\n",
      "Num frames:  (57, 1)\n",
      "Accuracy:  0.9824561403508771\n",
      "Person:  116\n",
      "Transitions:  [7, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.996875 0.996875 1.0\n",
      "Num frames:  (320, 1)\n",
      "Accuracy:  0.996875\n",
      "Person:  117\n",
      "Transitions:  [7, 8, 6, 8, 5, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.9464679911699779 0.9180050718512257 1.0\n",
      "Num frames:  (1183, 97)\n",
      "Accuracy:  0.9464679911699779\n",
      "Person:  118\n",
      "Transitions:  [5, 8, 6, 8, 7, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.9644670050761421 0.9416666666666667 1.0\n",
      "Num frames:  (1080, 63)\n",
      "Accuracy:  0.9644670050761421\n",
      "Person:  119\n",
      "Transitions:  [7, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.9970149253731343 0.9970149253731343 1.0\n",
      "Num frames:  (335, 1)\n",
      "Accuracy:  0.9970149253731343\n",
      "Person:  120\n",
      "Transitions:  [7, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.9814814814814815 0.9814814814814815 1.0\n",
      "Num frames:  (54, 1)\n",
      "Accuracy:  0.9814814814814815\n",
      "Person:  121\n",
      "Transitions:  [7, 8, 0, 8]\n",
      "GT transitions:  1\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.9893238434163701 0.9776785714285714 1.0\n",
      "Num frames:  (672, 15)\n",
      "Accuracy:  0.9893238434163701\n",
      "Person:  122\n",
      "Transitions:  [0, 8, 1, 8]\n",
      "GT transitions:  1\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.8762953367875648 0.7490144546649146 0.7797537619699042\n",
      "Num frames:  (761, 30)\n",
      "Accuracy:  0.8762953367875648\n",
      "Person:  123\n",
      "Transitions:  [6, 8, 5, 8]\n",
      "GT transitions:  1\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.9433962264150944 0.9347826086956522 1.0\n",
      "Num frames:  (1012, 66)\n",
      "Accuracy:  0.9433962264150944\n",
      "Person:  124\n",
      "Transitions:  [5, 8, 6, 8, 7, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.9022878932316492 0.853988603988604 1.0\n",
      "Num frames:  (1404, 205)\n",
      "Accuracy:  0.9022878932316492\n",
      "Person:  125\n",
      "Transitions:  [5, 8, 4, 8, 0, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.6487926136363636 0.5252040326452232 1.0\n",
      "Num frames:  (2083, 989)\n",
      "Accuracy:  0.6487926136363636\n",
      "Person:  126\n",
      "Transitions:  [2, 8, 1, 8, 0, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.8867699642431466 0.8056133056133056 0.8776896942242356\n",
      "Num frames:  (962, 82)\n",
      "Accuracy:  0.8867699642431466\n",
      "Person:  127\n",
      "Transitions:  [0, 8, 1, 8, 2, 8, 3, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.8256880733944955 0.7099276111685625 0.8711928934010152\n",
      "Num frames:  (1934, 367)\n",
      "Accuracy:  0.8256880733944955\n",
      "Person:  128\n",
      "Transitions:  [1, 8, 1, 8]\n",
      "GT transitions:  1\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.48621553884711777 0.48621553884711777 0.5337001375515819\n",
      "Num frames:  (798, 71)\n",
      "Accuracy:  0.48621553884711777\n",
      "Person:  129\n",
      "Transitions:  [4, 8, 5, 8]\n",
      "GT transitions:  1\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.9808510638297873 0.991304347826087 0.9726962457337884\n",
      "Num frames:  (575, 2)\n",
      "Accuracy:  0.9808510638297873\n",
      "Person:  130\n",
      "Transitions:  [7, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.9967320261437909 0.9967320261437909 1.0\n",
      "Num frames:  (306, 1)\n",
      "Accuracy:  0.9967320261437909\n",
      "Person:  131\n",
      "Transitions:  [1, 8, 0, 8]\n",
      "GT transitions:  1\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.7952350289761752 0.6747624076029567 0.7456242707117853\n",
      "Num frames:  (947, 100)\n",
      "Accuracy:  0.7952350289761752\n",
      "Person:  132\n",
      "Transitions:  [4, 8, 6, 8, 5, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.8289719626168224 0.7825567502986858 0.9805389221556886\n",
      "Num frames:  (837, 170)\n",
      "Accuracy:  0.8289719626168224\n",
      "Person:  133\n",
      "Transitions:  [2, 8, 1, 8, 0, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.8759978712080894 0.8112068965517242 0.8802619270346118\n",
      "Num frames:  (1160, 105)\n",
      "Accuracy:  0.8759978712080894\n",
      "Person:  134\n",
      "Transitions:  [0, 8, 1, 8]\n",
      "GT transitions:  1\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.8695064232589588 0.7410468319559229 0.7472222222222222\n",
      "Num frames:  (726, 11)\n",
      "Accuracy:  0.8695064232589588\n",
      "Person:  135\n",
      "Transitions:  [5, 8, 4, 8, 0, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.6300063572790846 0.5074058400338552 1.0\n",
      "Num frames:  (2363, 1164)\n",
      "Accuracy:  0.6300063572790846\n",
      "Person:  136\n",
      "Transitions:  [5, 8, 6, 8, 7, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.8764249886000912 0.8193333333333334 1.0\n",
      "Num frames:  (1500, 271)\n",
      "Accuracy:  0.8764249886000912\n",
      "Person:  137\n",
      "Transitions:  [7, 8, 6, 8, 5, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.8959007551240561 0.8419328419328419 1.0\n",
      "Num frames:  (1221, 193)\n",
      "Accuracy:  0.8959007551240561\n",
      "Person:  138\n",
      "Transitions:  [7, 8, 6, 8, 5, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.8990261404407995 0.8505311077389985 1.0\n",
      "Num frames:  (1318, 197)\n",
      "Accuracy:  0.8990261404407995\n",
      "Person:  139\n",
      "Transitions:  [3, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.9978813559322034 0.9978813559322034 1.0\n",
      "Num frames:  (472, 1)\n",
      "Accuracy:  0.9978813559322034\n",
      "Person:  140\n",
      "Transitions:  [7, 8, 0, 8]\n",
      "GT transitions:  1\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.8342696629213483 0.7160731472569779 1.0\n",
      "Num frames:  (1039, 295)\n",
      "Accuracy:  0.8342696629213483\n",
      "Person:  141\n",
      "Transitions:  [7, 8, 6, 8, 5, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.9477085781433607 0.9168224299065421 1.0\n",
      "Num frames:  (1070, 89)\n",
      "Accuracy:  0.9477085781433607\n",
      "Person:  142\n",
      "Transitions:  [5, 8, 4, 8, 1, 8, 0, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.8857566765578635 0.8260869565217391 0.9972375690607734\n",
      "Num frames:  (2185, 380)\n",
      "Accuracy:  0.8857566765578635\n",
      "Person:  143\n",
      "Transitions:  [0, 8, 1, 8, 2, 8, 3, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.8997555012224939 0.8180026281208935 0.8688066992323796\n",
      "Num frames:  (1522, 99)\n",
      "Accuracy:  0.8997555012224939\n",
      "Person:  144\n",
      "Transitions:  [0, 8, 1, 8, 4, 8, 5, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.8920103092783506 0.7974867085548574 0.9945750452079566\n",
      "Num frames:  (2069, 410)\n",
      "Accuracy:  0.8920103092783506\n",
      "Person:  145\n",
      "Transitions:  [7, 8, 6, 8, 5, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.9738562091503268 0.9586056644880174 0.9977324263038548\n",
      "Num frames:  (918, 38)\n",
      "Accuracy:  0.9738562091503268\n",
      "Person:  146\n",
      "Transitions:  [1, 8, 2, 8, 3, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.8380476982806434 0.7620211898940505 0.85\n",
      "Num frames:  (1227, 127)\n",
      "Accuracy:  0.8380476982806434\n",
      "Person:  147\n",
      "Transitions:  [7, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.9966442953020134 0.9966442953020134 1.0\n",
      "Num frames:  (298, 1)\n",
      "Accuracy:  0.9966442953020134\n",
      "Person:  148\n",
      "Transitions:  [7, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.9960629921259843 0.9960629921259843 1.0\n",
      "Num frames:  (254, 1)\n",
      "Accuracy:  0.9960629921259843\n",
      "Person:  149\n",
      "Transitions:  [7, 8, 0, 8]\n",
      "GT transitions:  1\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.9876373626373627 0.979328165374677 0.9973684210526316\n",
      "Num frames:  (774, 16)\n",
      "Accuracy:  0.9876373626373627\n",
      "Person:  150\n",
      "Transitions:  [3, 8, 2, 8, 1, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.8428642466434609 0.7841530054644809 0.9103885804916733\n",
      "Num frames:  (1464, 203)\n",
      "Accuracy:  0.8428642466434609\n",
      "Person:  151\n",
      "Transitions:  [5, 8, 6, 8, 7, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.9809113300492611 0.9697601668404588 0.9978540772532188\n",
      "Num frames:  (959, 29)\n",
      "Accuracy:  0.9809113300492611\n",
      "Person:  152\n",
      "Transitions:  [7, 8, 0, 8]\n",
      "GT transitions:  1\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.9673123486682809 0.9411764705882353 1.0\n",
      "Num frames:  (918, 54)\n",
      "Accuracy:  0.9673123486682809\n",
      "Person:  153\n",
      "Transitions:  [7, 8, 6, 8, 5, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.9446662863662293 0.9160714285714285 0.9970845481049563\n",
      "Num frames:  (1120, 94)\n",
      "Accuracy:  0.9446662863662293\n",
      "Person:  154\n",
      "Transitions:  [7, 8, 6, 8, 5, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.9620410703173615 0.9383838383838384 1.0\n",
      "Num frames:  (990, 61)\n",
      "Accuracy:  0.9620410703173615\n",
      "Person:  155\n",
      "Transitions:  [7, 8, 6, 8, 5, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.9747774480712166 0.9783989834815756 0.9783989834815756\n",
      "Num frames:  (787, 17)\n",
      "Accuracy:  0.9747774480712166\n",
      "Person:  156\n",
      "Transitions:  [6, 8, 5, 8]\n",
      "GT transitions:  1\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.9528301886792453 0.94375 1.0\n",
      "Num frames:  (800, 45)\n",
      "Accuracy:  0.9528301886792453\n",
      "Person:  157\n",
      "Transitions:  [5, 8, 4, 8, 0, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.6210137630077207 0.48635122838944495 1.0\n",
      "Num frames:  (2198, 1129)\n",
      "Accuracy:  0.6210137630077207\n",
      "Person:  158\n",
      "Transitions:  [5, 8, 6, 8, 7, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.9660249150622876 0.9440820130475303 1.0\n",
      "Num frames:  (1073, 60)\n",
      "Accuracy:  0.9660249150622876\n",
      "Person:  159\n",
      "Transitions:  [7, 8, 0, 8]\n",
      "GT transitions:  1\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.9409282700421941 0.891832229580574 1.0\n",
      "Num frames:  (906, 98)\n",
      "Accuracy:  0.9409282700421941\n",
      "Person:  160\n",
      "Transitions:  [7, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.994413407821229 0.994413407821229 1.0\n",
      "Num frames:  (179, 1)\n",
      "Accuracy:  0.994413407821229\n",
      "Person:  161\n",
      "Transitions:  [1, 8, 0, 8]\n",
      "GT transitions:  1\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.7925746569814366 0.671919770773639 0.6738505747126436\n",
      "Num frames:  (698, 30)\n",
      "Accuracy:  0.7925746569814366\n",
      "Person:  162\n",
      "Transitions:  [5, 8, 4, 8, 2, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.9311475409836065 0.9218274111675127 1.0\n",
      "Num frames:  (2955, 231)\n",
      "Accuracy:  0.9311475409836065\n",
      "Person:  163\n",
      "Transitions:  [7, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.9967741935483871 0.9967741935483871 1.0\n",
      "Num frames:  (310, 1)\n",
      "Accuracy:  0.9967741935483871\n",
      "Person:  164\n",
      "Transitions:  [5, 8, 4, 8, 0, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.6300636089722129 0.4981834695731153 1.0\n",
      "Num frames:  (2202, 1105)\n",
      "Accuracy:  0.6300636089722129\n",
      "Person:  165\n",
      "Transitions:  [0, 8, 1, 8, 4, 8, 5, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.8648954211418881 0.7679012345679013 0.8534577387486278\n",
      "Num frames:  (2025, 211)\n",
      "Accuracy:  0.8648954211418881\n",
      "Person:  166\n",
      "Transitions:  [7, 8, 0, 8]\n",
      "GT transitions:  1\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.9747899159663865 0.9965095986038395 0.9532554257095158\n",
      "Num frames:  (573, 2)\n",
      "Accuracy:  0.9747899159663865\n",
      "Person:  167\n",
      "Transitions:  [5, 8, 4, 8, 2, 8, 1, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.8883928571428571 0.8446132596685083 1.0\n",
      "Num frames:  (1448, 225)\n",
      "Accuracy:  0.8883928571428571\n",
      "Person:  168\n",
      "Transitions:  [7, 8, 6, 8, 5, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.9366197183098591 0.8998144712430427 1.0\n",
      "Num frames:  (1078, 108)\n",
      "Accuracy:  0.9366197183098591\n",
      "Person:  169\n",
      "Transitions:  [2, 8, 2, 8, 4, 8, 4, 8, 2, 8]\n",
      "GT transitions:  4\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.24264905455532434 0.22232851812876686 0.7731204258150366\n",
      "Num frames:  (10453, 7689)\n",
      "Accuracy:  0.24264905455532434\n",
      "Person:  170\n",
      "Transitions:  [7, 8, 6, 8, 4, 8, 2, 8, 3, 8]\n",
      "GT transitions:  4\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.3227222832052689 0.1638608305274972 0.21282798833819241\n",
      "Num frames:  (1782, 771)\n",
      "Accuracy:  0.3227222832052689\n",
      "Person:  171\n",
      "Transitions:  [7, 8, 0, 8]\n",
      "GT transitions:  1\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.9448319594166138 0.8909774436090225 1.0\n",
      "Num frames:  (798, 87)\n",
      "Accuracy:  0.9448319594166138\n",
      "Person:  172\n",
      "Transitions:  [0, 8, 1, 8, 4, 8, 5, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.8828288882229548 0.7926960257787325 0.8833034111310593\n",
      "Num frames:  (1862, 196)\n",
      "Accuracy:  0.8828288882229548\n",
      "Person:  173\n",
      "Transitions:  [7, 8, 6, 8, 5, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.9433741973146527 0.9094304388422035 1.0\n",
      "Num frames:  (1071, 97)\n",
      "Accuracy:  0.9433741973146527\n",
      "Person:  174\n",
      "Transitions:  [7, 8, 6, 8, 5, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.873639375295788 0.8210455764075067 1.0\n",
      "Num frames:  (1492, 267)\n",
      "Accuracy:  0.873639375295788\n",
      "Person:  175\n",
      "Transitions:  [7, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A,P,R:  0.9959183673469387 0.9959183673469387 1.0\n",
      "Num frames:  (245, 1)\n",
      "Accuracy:  0.9959183673469387\n",
      "Person:  176\n",
      "Transitions:  [6, 8, 4, 8, 2, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  0\n",
      "A,P,R:  0.3651895355045382 0.3736343772760379 0.3445265278710544\n",
      "Num frames:  (1373, 213)\n",
      "Accuracy:  0.3651895355045382\n",
      "Person:  177\n",
      "Transitions:  [1, 8, 4, 8, 5, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.886762360446571 0.8328 0.8617549668874173\n",
      "Num frames:  (1250, 46)\n",
      "Accuracy:  0.886762360446571\n",
      "Person:  178\n",
      "Transitions:  [7, 8, 0, 8]\n",
      "GT transitions:  1\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.9514792899408284 0.9141361256544502 1.0\n",
      "Num frames:  (955, 82)\n",
      "Accuracy:  0.9514792899408284\n",
      "Person:  179\n",
      "Transitions:  [5, 8, 4, 8]\n",
      "GT transitions:  1\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.9774951076320939 0.965925925925926 0.998468606431853\n",
      "Num frames:  (675, 22)\n",
      "Accuracy:  0.9774951076320939\n",
      "Person:  180\n",
      "Transitions:  [7, 8, 6, 8, 5, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.9592592592592593 0.9332659251769464 1.0\n",
      "Num frames:  (989, 66)\n",
      "Accuracy:  0.9592592592592593\n",
      "Person:  181\n",
      "Transitions:  [7, 8, 6, 8, 5, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.9439511653718091 0.9143101970865467 0.9990636704119851\n",
      "Num frames:  (1167, 100)\n",
      "Accuracy:  0.9439511653718091\n",
      "Person:  182\n",
      "Transitions:  [7, 8, 6, 8, 5, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.9265375854214123 0.8844086021505376 1.0\n",
      "Num frames:  (1116, 129)\n",
      "Accuracy:  0.9265375854214123\n",
      "Person:  183\n",
      "Transitions:  [5, 8, 4, 8, 1, 8, 0, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.9356814701378254 0.8918393782383419 0.9992743105950653\n",
      "Num frames:  (1544, 167)\n",
      "Accuracy:  0.9356814701378254\n",
      "Person:  184\n",
      "Transitions:  [0, 8, 1, 8, 2, 8, 3, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.7577043735006459 0.6527408195848856 0.8849206349206349\n",
      "Num frames:  (3758, 994)\n",
      "Accuracy:  0.7577043735006459\n",
      "Person:  185\n",
      "Transitions:  [0, 8, 1, 8, 2, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.8906783796974134 0.8280730897009967 0.8492333901192505\n",
      "Num frames:  (1204, 47)\n",
      "Accuracy:  0.8906783796974134\n",
      "Person:  186\n",
      "Transitions:  [0, 8, 1, 8, 2, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.8481375358166189 0.7300085984522786 0.804739336492891\n",
      "Num frames:  (1163, 112)\n",
      "Accuracy:  0.8481375358166189\n",
      "Person:  187\n",
      "Transitions:  [3, 8, 2, 8, 1, 8, 0, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.8975762314308053 0.8533241946538725 0.881104033970276\n",
      "Num frames:  (1459, 94)\n",
      "Accuracy:  0.8975762314308053\n",
      "Person:  188\n",
      "Transitions:  [0, 8, 1, 8, 2, 8, 3, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.8504837291116975 0.74950884086444 0.8744985673352436\n",
      "Num frames:  (2036, 291)\n",
      "Accuracy:  0.8504837291116975\n",
      "Person:  189\n",
      "Transitions:  [7, 8, 0, 8]\n",
      "GT transitions:  1\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.9388724035608309 0.8903088391906283 1.0\n",
      "Num frames:  (939, 103)\n",
      "Accuracy:  0.9388724035608309\n",
      "Person:  190\n",
      "Transitions:  [7, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.9961389961389961 0.9961389961389961 1.0\n",
      "Num frames:  (259, 1)\n",
      "Accuracy:  0.9961389961389961\n",
      "Person:  191\n",
      "Transitions:  [7, 8, 4, 8, 5, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  0\n",
      "A,P,R:  0.36644682605111295 0.17540983606557378 0.2734241908006814\n",
      "Num frames:  (1830, 684)\n",
      "Accuracy:  0.36644682605111295\n",
      "Person:  192\n",
      "Transitions:  [0, 8, 1, 8, 2, 8, 3, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.8948281846581049 0.8084291187739464 0.8701030927835052\n",
      "Num frames:  (1566, 114)\n",
      "Accuracy:  0.8948281846581049\n",
      "Person:  193\n",
      "Transitions:  [7, 8, 7, 8, 6, 8, 5, 8, 5, 8, 6, 8, 7, 8]\n",
      "GT transitions:  6\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.47474011156186613 0.46339647077869517 0.8073560106052914\n",
      "Num frames:  (30885, 13158)\n",
      "Accuracy:  0.47474011156186613\n",
      "Person:  194\n",
      "Transitions:  [7, 8, 6, 8, 5, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.9379532634971797 0.9736070381231672 0.9183955739972337\n",
      "Num frames:  (682, 18)\n",
      "Accuracy:  0.9379532634971797\n",
      "Person:  195\n",
      "Transitions:  [0, 8, 1, 8, 4, 8, 5, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.8910952528699969 0.8051082731815657 0.86463923673226\n",
      "Num frames:  (1801, 124)\n",
      "Accuracy:  0.8910952528699969\n",
      "Person:  196\n",
      "Transitions:  [7, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.9951219512195122 0.9951219512195122 1.0\n",
      "Num frames:  (205, 1)\n",
      "Accuracy:  0.9951219512195122\n",
      "Person:  197\n",
      "Transitions:  [2, 8, 3, 8]\n",
      "GT transitions:  1\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.9912451361867705 0.9853181076672104 0.9983471074380166\n",
      "Num frames:  (613, 8)\n",
      "Accuracy:  0.9912451361867705\n",
      "Person:  198\n",
      "Transitions:  [7, 8, 6, 8, 5, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.9005050505050505 0.8539659006671608 1.0\n",
      "Num frames:  (1349, 197)\n",
      "Accuracy:  0.9005050505050505\n",
      "Person:  199\n",
      "Transitions:  [7, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.9969418960244648 0.9969418960244648 1.0\n",
      "Num frames:  (327, 1)\n",
      "Accuracy:  0.9969418960244648\n",
      "Person:  200\n",
      "Transitions:  [5, 8, 6, 8, 7, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.9570378745053703 0.9366391184573003 0.9931840311587147\n",
      "Num frames:  (1089, 69)\n",
      "Accuracy:  0.9570378745053703\n",
      "Person:  201\n",
      "Transitions:  [0, 8, 4, 8, 5, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.871786197564276 0.7510339123242349 0.8284671532846716\n",
      "Num frames:  (1209, 191)\n",
      "Accuracy:  0.871786197564276\n",
      "Person:  202\n",
      "Transitions:  [1, 8, 4, 8, 5, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.8283132530120482 0.7572746628814763 0.8681855166802278\n",
      "Num frames:  (1409, 180)\n",
      "Accuracy:  0.8283132530120482\n",
      "Person:  203\n",
      "Transitions:  [3, 8, 2, 8, 4, 8, 5, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.9246809835045129 0.8907942238267148 0.999493670886076\n",
      "Num frames:  (2216, 241)\n",
      "Accuracy:  0.9246809835045129\n",
      "Person:  204\n",
      "Transitions:  [7, 8, 0, 8]\n",
      "GT transitions:  1\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.6096413874191652 0.4534979423868313 0.9769503546099291\n",
      "Num frames:  (1215, 651)\n",
      "Accuracy:  0.6096413874191652\n",
      "Person:  205\n",
      "Transitions:  [0, 8, 1, 8, 2, 8, 3, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.9023238925199709 0.8215767634854771 0.8709677419354839\n",
      "Num frames:  (1446, 93)\n",
      "Accuracy:  0.9023238925199709\n",
      "Person:  206\n",
      "Transitions:  [0, 8, 1, 8]\n",
      "GT transitions:  1\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.8680124223602484 0.7649063032367973 0.7277147487844409\n",
      "Num frames:  (587, 2)\n",
      "Accuracy:  0.8680124223602484\n",
      "Person:  207\n",
      "Transitions:  [2, 8, 1, 8, 0, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.868421052631579 0.7891891891891892 0.8917975567190227\n",
      "Num frames:  (1295, 151)\n",
      "Accuracy:  0.868421052631579\n",
      "Person:  208\n",
      "Transitions:  [3, 8, 2, 8, 1, 8, 0, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.8765638031693077 0.8136882129277566 0.8039068369646882\n",
      "Num frames:  (1315, 35)\n",
      "Accuracy:  0.8765638031693077\n",
      "Person:  209\n",
      "Transitions:  [7, 8, 6, 8, 5, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.8174750092558312 0.7602140077821011 0.9993606138107417\n",
      "Num frames:  (2056, 492)\n",
      "Accuracy:  0.8174750092558312\n",
      "Person:  210\n",
      "Transitions:  [7, 8, 0, 8]\n",
      "GT transitions:  1\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.9696601941747572 0.9450056116722784 0.9988137603795967\n",
      "Num frames:  (891, 49)\n",
      "Accuracy:  0.9696601941747572\n",
      "Person:  211\n",
      "Transitions:  [5, 8, 4, 8, 1, 8, 1, 8, 0, 8]\n",
      "GT transitions:  4\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.5812364088226157 0.4621676891615542 0.8094555873925502\n",
      "Num frames:  (2445, 1082)\n",
      "Accuracy:  0.5812364088226157\n",
      "Person:  212\n",
      "Transitions:  [7, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.9966996699669967 0.9966996699669967 1.0\n",
      "Num frames:  (303, 1)\n",
      "Accuracy:  0.9966996699669967\n",
      "Person:  213\n",
      "Transitions:  [7, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.9969604863221885 0.9969604863221885 1.0\n",
      "Num frames:  (329, 1)\n",
      "Accuracy:  0.9969604863221885\n",
      "Person:  214\n",
      "Transitions:  [7, 8, 0, 8]\n",
      "GT transitions:  1\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.8196359624931053 0.6986175115207374 1.0\n",
      "Num frames:  (1085, 327)\n",
      "Accuracy:  0.8196359624931053\n",
      "Person:  215\n",
      "Transitions:  [1, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.6538461538461539 0.6538461538461539 0.6552462526766595\n",
      "Num frames:  (468, 1)\n",
      "Accuracy:  0.6538461538461539\n",
      "Person:  216\n",
      "Transitions:  [7, 8, 6, 8, 5, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.9097154072620216 0.867910983488873 1.0\n",
      "Num frames:  (1393, 184)\n",
      "Accuracy:  0.9097154072620216\n",
      "Person:  217\n",
      "Transitions:  [4, 8, 2, 8, 3, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.8997050147492626 0.8590381426202321 0.9961538461538462\n",
      "Num frames:  (1206, 166)\n",
      "Accuracy:  0.8997050147492626\n",
      "Person:  218\n",
      "Transitions:  [7, 8, 6, 8, 5, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.8926526717557252 0.845467032967033 1.0\n",
      "Num frames:  (1456, 225)\n",
      "Accuracy:  0.8926526717557252\n",
      "Person:  219\n",
      "Transitions:  [0, 8, 1, 8, 2, 8, 3, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.8888121546961326 0.7962962962962963 0.8683844011142061\n",
      "Num frames:  (1566, 133)\n",
      "Accuracy:  0.8888121546961326\n",
      "Person:  220\n",
      "Transitions:  [1, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.5824175824175825 0.5824175824175825 0.5834862385321101\n",
      "Num frames:  (546, 1)\n",
      "Accuracy:  0.5824175824175825\n",
      "Person:  221\n",
      "Transitions:  [7, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.9968354430379747 0.9968354430379747 1.0\n",
      "Num frames:  (316, 1)\n",
      "Accuracy:  0.9968354430379747\n",
      "Person:  222\n",
      "Transitions:  [5, 8, 6, 8, 4, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.9134001823154057 0.9351100811123986 0.9539007092198581\n",
      "Num frames:  (1726, 112)\n",
      "Accuracy:  0.9134001823154057\n",
      "Person:  223\n",
      "Transitions:  [7, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.99 0.99 1.0\n",
      "Num frames:  (100, 1)\n",
      "Accuracy:  0.99\n",
      "Person:  224\n",
      "Transitions:  [1, 8, 0, 8]\n",
      "GT transitions:  1\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.7924528301886793 0.6697154471544715 0.745475113122172\n",
      "Num frames:  (984, 105)\n",
      "Accuracy:  0.7924528301886793\n",
      "Person:  225\n",
      "Transitions:  [0, 8, 1, 8, 4, 8, 5, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.8995334370139969 0.818999437886453 0.880894800483676\n",
      "Num frames:  (1779, 126)\n",
      "Accuracy:  0.8995334370139969\n",
      "Person:  226\n",
      "Transitions:  [7, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.99609375 0.99609375 1.0\n",
      "Num frames:  (256, 1)\n",
      "Accuracy:  0.99609375\n",
      "Person:  227\n",
      "Transitions:  [7, 8, 6, 8, 5, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.9553990610328639 0.9290382819794585 1.0\n",
      "Num frames:  (1071, 76)\n",
      "Accuracy:  0.9553990610328639\n",
      "Person:  228\n",
      "Transitions:  [0, 8, 1, 8, 4, 8, 5, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.89209726443769 0.8102618920363442 0.8555304740406321\n",
      "Num frames:  (1871, 99)\n",
      "Accuracy:  0.89209726443769\n",
      "Person:  229\n",
      "Transitions:  [0, 8, 1, 8]\n",
      "GT transitions:  1\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.8502705953096813 0.7151029748283753 0.741399762752076\n",
      "Num frames:  (874, 31)\n",
      "Accuracy:  0.8502705953096813\n",
      "Person:  230\n",
      "Transitions:  [7, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.9961685823754789 0.9961685823754789 1.0\n",
      "Num frames:  (261, 1)\n",
      "Accuracy:  0.9961685823754789\n",
      "Person:  231\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transitions:  [0, 8, 1, 8, 7, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.8937282229965157 0.7978723404255319 0.8714596949891068\n",
      "Num frames:  (1504, 128)\n",
      "Accuracy:  0.8937282229965157\n",
      "Person:  232\n",
      "Transitions:  [7, 8, 0, 8]\n",
      "GT transitions:  1\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.8835257082896117 0.808124459809853 1.0\n",
      "Num frames:  (1157, 222)\n",
      "Accuracy:  0.8835257082896117\n",
      "Person:  233\n",
      "Transitions:  [2, 8, 4, 8, 6, 8, 7, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.9156094870380584 0.8567335243553008 0.9857142857142858\n",
      "Num frames:  (1047, 140)\n",
      "Accuracy:  0.9156094870380584\n",
      "Person:  234\n",
      "Transitions:  [3, 8, 2, 8, 4, 8, 4, 8, 2, 8]\n",
      "GT transitions:  4\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.2027037773359841 0.1309699228568952 0.4983509234828496\n",
      "Num frames:  (11537, 8505)\n",
      "Accuracy:  0.2027037773359841\n",
      "Person:  235\n",
      "Transitions:  [3, 8, 2, 8, 1, 8, 0, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.8854258121158911 0.8258706467661692 0.8143908421913328\n",
      "Num frames:  (1206, 34)\n",
      "Accuracy:  0.8854258121158911\n",
      "Person:  236\n",
      "Transitions:  [0, 8, 1, 8, 2, 8, 3, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.907112970711297 0.8828671328671329 0.8444816053511706\n",
      "Num frames:  (1144, 36)\n",
      "Accuracy:  0.907112970711297\n",
      "Person:  237\n",
      "Transitions:  [7, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.9962962962962963 0.9962962962962963 1.0\n",
      "Num frames:  (270, 1)\n",
      "Accuracy:  0.9962962962962963\n",
      "Person:  238\n",
      "Transitions:  [7, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.9970238095238095 0.9970238095238095 1.0\n",
      "Num frames:  (336, 1)\n",
      "Accuracy:  0.9970238095238095\n",
      "Person:  239\n",
      "Transitions:  [5, 8, 6, 8, 7, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.9412065439672802 0.9090909090909091 1.0\n",
      "Num frames:  (1265, 115)\n",
      "Accuracy:  0.9412065439672802\n",
      "Person:  240\n",
      "Transitions:  [7, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.9968253968253968 0.9968253968253968 1.0\n",
      "Num frames:  (315, 1)\n",
      "Accuracy:  0.9968253968253968\n",
      "Person:  241\n",
      "Transitions:  [0, 8, 0, 8]\n",
      "GT transitions:  1\n",
      "Transitions captured:  0\n",
      "A,P,R:  0.7287308228730823 0.37333333333333335 0.20689655172413793\n",
      "Num frames:  (225, 67)\n",
      "Accuracy:  0.7287308228730823\n",
      "Person:  242\n",
      "Transitions:  [0, 8, 1, 8]\n",
      "GT transitions:  1\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.85028427037271 0.7030075187969925 0.729518855656697\n",
      "Num frames:  (798, 29)\n",
      "Accuracy:  0.85028427037271\n",
      "Person:  243\n",
      "Transitions:  [7, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.9963235294117647 0.9963235294117647 1.0\n",
      "Num frames:  (272, 1)\n",
      "Accuracy:  0.9963235294117647\n",
      "Person:  244\n",
      "Transitions:  [5, 8, 4, 8, 1, 8, 0, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.9004893964110929 0.8435054773082942 0.9908088235294118\n",
      "Num frames:  (1917, 290)\n",
      "Accuracy:  0.9004893964110929\n",
      "Person:  245\n",
      "Transitions:  [5, 8, 4, 8, 1, 8, 0, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.7701013911813251 0.6607515657620042 1.0\n",
      "Num frames:  (2874, 975)\n",
      "Accuracy:  0.7701013911813251\n",
      "Person:  246\n",
      "Transitions:  [0, 8, 1, 8, 4, 8, 5, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.9569023569023569 0.9020979020979021 0.9931565440547476\n",
      "Num frames:  (1287, 120)\n",
      "Accuracy:  0.9569023569023569\n",
      "Person:  247\n",
      "Transitions:  [7, 8, 6, 8, 5, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.9814814814814815 0.9796893667861409 0.9891435464414958\n",
      "Num frames:  (837, 17)\n",
      "Accuracy:  0.9814814814814815\n",
      "Person:  248\n",
      "Transitions:  [7, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.9958847736625515 0.9958847736625515 1.0\n",
      "Num frames:  (243, 1)\n",
      "Accuracy:  0.9958847736625515\n",
      "Person:  249\n",
      "Transitions:  [0, 8, 1, 8]\n",
      "GT transitions:  1\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.8460667798528579 0.7151832460732984 0.7605790645879733\n",
      "Num frames:  (955, 57)\n",
      "Accuracy:  0.8460667798528579\n",
      "Person:  250\n",
      "Transitions:  [7, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.9966777408637874 0.9966777408637874 1.0\n",
      "Num frames:  (301, 1)\n",
      "Accuracy:  0.9966777408637874\n",
      "Person:  251\n",
      "Transitions:  [7, 8, 6, 8, 5, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.9642196175200494 0.942173479561316 1.0\n",
      "Num frames:  (1003, 58)\n",
      "Accuracy:  0.9642196175200494\n",
      "Person:  252\n",
      "Transitions:  [3, 8, 2, 8, 1, 8, 0, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.8666235027516995 0.7891191709844559 0.9219128329297821\n",
      "Num frames:  (1930, 283)\n",
      "Accuracy:  0.8666235027516995\n",
      "Person:  253\n",
      "Transitions:  [0, 8, 7, 8]\n",
      "GT transitions:  1\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.9593667546174143 0.9186550976138829 0.9976442873969376\n",
      "Num frames:  (922, 75)\n",
      "Accuracy:  0.9593667546174143\n",
      "Person:  254\n",
      "Transitions:  [5, 8, 4, 8, 1, 8, 0, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.9433214427269124 0.9028727770177839 0.9992429977289932\n",
      "Num frames:  (1462, 142)\n",
      "Accuracy:  0.9433214427269124\n",
      "Person:  255\n",
      "Transitions:  [6, 8, 7, 8]\n",
      "GT transitions:  1\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.9166666666666666 0.8434163701067615 1.0\n",
      "Num frames:  (562, 88)\n",
      "Accuracy:  0.9166666666666666\n",
      "Person:  256\n",
      "Transitions:  [0, 8, 1, 8, 4, 8, 5, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.9602157788267026 0.9093701996927803 0.9974726200505476\n",
      "Num frames:  (1302, 115)\n",
      "Accuracy:  0.9602157788267026\n",
      "Person:  257\n",
      "Transitions:  [5, 8, 4, 8, 0, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.6362148002619515 0.5200863930885529 1.0\n",
      "Num frames:  (2315, 1111)\n",
      "Accuracy:  0.6362148002619515\n",
      "Person:  258\n",
      "Transitions:  [1, 8, 4, 8, 2, 8, 3, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.8847715736040609 0.8109908409658618 1.0\n",
      "Num frames:  (1201, 227)\n",
      "Accuracy:  0.8847715736040609\n",
      "Person:  259\n",
      "Transitions:  [5, 8, 4, 8, 1, 8, 0, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.8659058487874465 0.8005649717514124 0.9048531289910601\n",
      "Num frames:  (1770, 227)\n",
      "Accuracy:  0.8659058487874465\n",
      "Person:  260\n",
      "Transitions:  [5, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.9967637540453075 0.9967637540453075 1.0\n",
      "Num frames:  (309, 1)\n",
      "Accuracy:  0.9967637540453075\n",
      "Person:  261\n",
      "Transitions:  [7, 8, 6, 8, 5, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.9764309764309764 0.976897689768977 0.9844789356984479\n",
      "Num frames:  (909, 21)\n",
      "Accuracy:  0.9764309764309764\n",
      "Person:  262\n",
      "Transitions:  [7, 8, 6, 8, 5, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.9379582628313593 0.9033391915641477 1.0\n",
      "Num frames:  (1138, 110)\n",
      "Accuracy:  0.9379582628313593\n",
      "Person:  263\n",
      "Transitions:  [1, 8, 2, 8, 4, 8, 4, 8, 4, 8, 4, 8, 3, 8]\n",
      "GT transitions:  6\n",
      "Transitions captured:  4\n",
      "A,P,R:  0.06959127808193317 0.039127330033734704 0.4666666666666667\n",
      "Num frames:  (40611, 37611)\n",
      "Accuracy:  0.06959127808193317\n",
      "Person:  264\n",
      "Transitions:  [7, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.9964028776978417 0.9964028776978417 1.0\n",
      "Num frames:  (278, 1)\n",
      "Accuracy:  0.9964028776978417\n",
      "Person:  265\n",
      "Transitions:  [7, 8, 6, 8, 5, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.9384885764499121 0.9023255813953488 1.0\n",
      "Num frames:  (1075, 105)\n",
      "Accuracy:  0.9384885764499121\n",
      "Person:  266\n",
      "Transitions:  [7, 8, 6, 8, 5, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.9605346912794398 0.9409937888198758 0.9945295404814004\n",
      "Num frames:  (966, 57)\n",
      "Accuracy:  0.9605346912794398\n",
      "Person:  267\n",
      "Transitions:  [0, 8, 1, 8]\n",
      "GT transitions:  1\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.8469449485783425 0.7017751479289941 0.7515842839036755\n",
      "Num frames:  (845, 57)\n",
      "Accuracy:  0.8469449485783425\n",
      "Person:  268\n",
      "Transitions:  [4, 8, 2, 8, 3, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.9054652880354506 0.8426270136307311 0.9956076134699854\n",
      "Num frames:  (807, 125)\n",
      "Accuracy:  0.9054652880354506\n",
      "Person:  269\n",
      "Transitions:  [7, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.9967213114754099 0.9967213114754099 1.0\n",
      "Num frames:  (305, 1)\n",
      "Accuracy:  0.9967213114754099\n",
      "Person:  270\n",
      "Transitions:  [2, 8, 1, 8, 0, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.8862612612612613 0.8204158790170132 0.8794326241134752\n",
      "Num frames:  (1058, 83)\n",
      "Accuracy:  0.8862612612612613\n",
      "Person:  271\n",
      "Transitions:  [7, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.9970326409495549 0.9970326409495549 1.0\n",
      "Num frames:  (337, 1)\n",
      "Accuracy:  0.9970326409495549\n",
      "Person:  272\n",
      "Transitions:  [3, 8, 2, 8, 1, 8, 0, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.9022257551669316 0.8482517482517482 0.8866959064327485\n",
      "Num frames:  (1430, 91)\n",
      "Accuracy:  0.9022257551669316\n",
      "Person:  273\n",
      "Transitions:  [7, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.9947643979057592 0.9947643979057592 1.0\n",
      "Num frames:  (191, 1)\n",
      "Accuracy:  0.9947643979057592\n",
      "Person:  274\n",
      "Transitions:  [3, 8, 2, 8, 1, 8, 0, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.9116420174440653 0.8500973393900065 0.9357142857142857\n",
      "Num frames:  (1541, 143)\n",
      "Accuracy:  0.9116420174440653\n",
      "Person:  275\n",
      "Transitions:  [7, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.9959514170040485 0.9959514170040485 1.0\n",
      "Num frames:  (247, 1)\n",
      "Accuracy:  0.9959514170040485\n",
      "Person:  276\n",
      "Transitions:  [7, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A,P,R:  0.996996996996997 0.996996996996997 1.0\n",
      "Num frames:  (333, 1)\n",
      "Accuracy:  0.996996996996997\n",
      "Person:  277\n",
      "Transitions:  [1, 8, 2, 8, 3, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.8807247106190237 0.8323903818953324 0.898473282442748\n",
      "Num frames:  (1414, 104)\n",
      "Accuracy:  0.8807247106190237\n",
      "Person:  278\n",
      "Transitions:  [1, 8, 0, 8]\n",
      "GT transitions:  1\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.7685749086479903 0.6304347826086957 0.7200902934537246\n",
      "Num frames:  (1012, 132)\n",
      "Accuracy:  0.7685749086479903\n",
      "Person:  279\n",
      "Transitions:  [5, 8, 4, 8, 1, 8, 0, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.8986175115207373 0.8328462887200467 0.9985984583041345\n",
      "Num frames:  (1711, 284)\n",
      "Accuracy:  0.8986175115207373\n",
      "Person:  280\n",
      "Transitions:  [7, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.9970588235294118 0.9970588235294118 1.0\n",
      "Num frames:  (340, 1)\n",
      "Accuracy:  0.9970588235294118\n",
      "Person:  281\n",
      "Transitions:  [1, 8, 0, 8]\n",
      "GT transitions:  1\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.6943105110896818 0.5313131313131313 0.45898778359511344\n",
      "Num frames:  (495, 7)\n",
      "Accuracy:  0.6943105110896818\n",
      "Person:  282\n",
      "Transitions:  [7, 8, 6, 8, 5, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.9520426287744227 0.923368022705771 1.0\n",
      "Num frames:  (1057, 81)\n",
      "Accuracy:  0.9520426287744227\n",
      "Person:  283\n",
      "Transitions:  [0, 8, 7, 8]\n",
      "GT transitions:  1\n",
      "Transitions captured:  0\n",
      "A,P,R:  0.8291431503335044 0.9583333333333334 0.5679012345679012\n",
      "Num frames:  (432, 18)\n",
      "Accuracy:  0.8291431503335044\n",
      "Person:  284\n",
      "Transitions:  [0, 8, 1, 8, 2, 8, 4, 8, 5, 8]\n",
      "GT transitions:  4\n",
      "Transitions captured:  4\n",
      "A,P,R:  0.8155210643015521 0.7188356164383561 0.7563963963963964\n",
      "Num frames:  (2920, 156)\n",
      "Accuracy:  0.8155210643015521\n",
      "Person:  285\n",
      "Transitions:  [5, 8, 4, 8, 1, 8, 0, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.9261168384879725 0.896551724137931 0.9692058346839546\n",
      "Num frames:  (1334, 134)\n",
      "Accuracy:  0.9261168384879725\n",
      "Person:  286\n",
      "Transitions:  [1, 8, 1, 8]\n",
      "GT transitions:  1\n",
      "Transitions captured:  0\n",
      "A,P,R:  0.03591457325036491 0.00802308117935341 0.2396694214876033\n",
      "Num frames:  (25302, 24455)\n",
      "Accuracy:  0.03591457325036491\n",
      "Person:  287\n",
      "Transitions:  [7, 8, 6, 8, 5, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.9048111743404035 0.8591117917304747 1.0\n",
      "Num frames:  (1306, 184)\n",
      "Accuracy:  0.9048111743404035\n",
      "Person:  288\n",
      "Transitions:  [0, 8, 1, 8, 4, 8, 5, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.9713445995591476 0.9520605550883096 0.9725085910652921\n",
      "Num frames:  (1189, 46)\n",
      "Accuracy:  0.9713445995591476\n",
      "Person:  289\n",
      "Transitions:  [3, 8, 2, 8, 1, 8, 0, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.8932806324110671 0.8259587020648967 0.9283819628647215\n",
      "Num frames:  (1695, 189)\n",
      "Accuracy:  0.8932806324110671\n",
      "Person:  290\n",
      "Transitions:  [0, 8, 1, 8]\n",
      "GT transitions:  1\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.8367346938775511 0.6955602536997886 0.7477272727272727\n",
      "Num frames:  (946, 66)\n",
      "Accuracy:  0.8367346938775511\n",
      "Person:  291\n",
      "Transitions:  [7, 8, 6, 8, 5, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.965158924205379 0.9458661417322834 0.9979231568016614\n",
      "Num frames:  (1016, 55)\n",
      "Accuracy:  0.965158924205379\n",
      "Person:  292\n",
      "Transitions:  [7, 8, 6, 8, 5, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.9358372456964006 0.9763560500695411 0.9152542372881356\n",
      "Num frames:  (719, 17)\n",
      "Accuracy:  0.9358372456964006\n",
      "Person:  293\n",
      "Transitions:  [1, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.5147783251231527 0.5147783251231527 0.5160493827160494\n",
      "Num frames:  (406, 1)\n",
      "Accuracy:  0.5147783251231527\n",
      "Person:  294\n",
      "Transitions:  [7, 8, 6, 8, 5, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.9425219941348973 0.9091751621872104 1.0\n",
      "Num frames:  (1079, 98)\n",
      "Accuracy:  0.9425219941348973\n",
      "Person:  295\n",
      "Transitions:  [7, 8, 0, 8]\n",
      "GT transitions:  1\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.8702734147760326 0.7712820512820513 1.0\n",
      "Num frames:  (975, 223)\n",
      "Accuracy:  0.8702734147760326\n",
      "Person:  296\n",
      "Transitions:  [0, 8, 1, 8]\n",
      "GT transitions:  1\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.8546365914786967 0.7174177831912302 0.7380952380952381\n",
      "Num frames:  (821, 23)\n",
      "Accuracy:  0.8546365914786967\n",
      "Person:  297\n",
      "Transitions:  [3, 8, 2, 8, 1, 8, 0, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.8738030095759234 0.8013136288998358 0.907625542467452\n",
      "Num frames:  (1827, 220)\n",
      "Accuracy:  0.8738030095759234\n",
      "Person:  298\n",
      "Transitions:  [0, 8, 7, 8, 7, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.8075618031992244 0.6181818181818182 0.7338129496402878\n",
      "Num frames:  (660, 249)\n",
      "Accuracy:  0.8075618031992244\n",
      "Person:  299\n",
      "Transitions:  [0, 8, 1, 8]\n",
      "GT transitions:  1\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.8723118279569892 0.7493188010899182 0.7544581618655692\n",
      "Num frames:  (734, 11)\n",
      "Accuracy:  0.8723118279569892\n",
      "Person:  300\n",
      "Transitions:  [0, 8, 1, 8, 2, 8, 3, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.8346949891067538 0.7281728172817282 0.8764897074756229\n",
      "Num frames:  (2222, 379)\n",
      "Accuracy:  0.8346949891067538\n",
      "Person:  301\n",
      "Transitions:  [7, 8, 0, 8]\n",
      "GT transitions:  1\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.860078277886497 0.7821782178217822 1.0\n",
      "Num frames:  (1313, 286)\n",
      "Accuracy:  0.860078277886497\n",
      "Person:  302\n",
      "Transitions:  [5, 8, 6, 8, 4, 8, 1, 8, 0, 8]\n",
      "GT transitions:  4\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.53003003003003 0.4009146341463415 0.6488486842105263\n",
      "Num frames:  (1968, 825)\n",
      "Accuracy:  0.53003003003003\n",
      "Person:  303\n",
      "Transitions:  [0, 8, 1, 8, 2, 8, 3, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.8940568475452196 0.8719851576994434 0.8131487889273357\n",
      "Num frames:  (1078, 30)\n",
      "Accuracy:  0.8940568475452196\n",
      "Person:  304\n",
      "Transitions:  [3, 8, 2, 8, 1, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.880674448767834 0.8175473579262214 0.8401639344262295\n",
      "Num frames:  (1003, 28)\n",
      "Accuracy:  0.880674448767834\n",
      "Person:  305\n",
      "Transitions:  [0, 8, 1, 8]\n",
      "GT transitions:  1\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.5944914551186328 0.5309377401998463 0.5364006988934188\n",
      "Num frames:  (5204, 56)\n",
      "Accuracy:  0.5944914551186328\n",
      "Person:  306\n",
      "Transitions:  [5, 8, 6, 8, 7, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.9712643678160919 0.9531100478468899 0.9989969909729187\n",
      "Num frames:  (1045, 49)\n",
      "Accuracy:  0.9712643678160919\n",
      "Person:  307\n",
      "Transitions:  [7, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.9966442953020134 0.9966442953020134 1.0\n",
      "Num frames:  (298, 1)\n",
      "Accuracy:  0.9966442953020134\n",
      "Person:  308\n",
      "Transitions:  [2, 8, 4, 8, 5, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.9655844155844155 0.9736842105263158 0.950592885375494\n",
      "Num frames:  (988, 3)\n",
      "Accuracy:  0.9655844155844155\n",
      "Person:  309\n",
      "Transitions:  [5, 8, 6, 8, 7, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.9527062532842879 0.9257425742574258 1.0\n",
      "Num frames:  (1212, 90)\n",
      "Accuracy:  0.9527062532842879\n",
      "Person:  310\n",
      "Transitions:  [7, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.996268656716418 0.996268656716418 1.0\n",
      "Num frames:  (268, 1)\n",
      "Accuracy:  0.996268656716418\n",
      "Person:  311\n",
      "Transitions:  [0, 8, 1, 8, 4, 8, 5, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.889308176100629 0.803399433427762 0.8620060790273556\n",
      "Num frames:  (1765, 125)\n",
      "Accuracy:  0.889308176100629\n",
      "Person:  312\n",
      "Transitions:  [0, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.995 0.995 1.0\n",
      "Num frames:  (200, 1)\n",
      "Accuracy:  0.995\n",
      "Person:  313\n",
      "Transitions:  [7, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.9969879518072289 0.9969879518072289 1.0\n",
      "Num frames:  (332, 1)\n",
      "Accuracy:  0.9969879518072289\n",
      "Person:  314\n",
      "Transitions:  [7, 8, 6, 8, 5, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.9297848244620611 0.8903625110521662 1.0\n",
      "Num frames:  (1131, 124)\n",
      "Accuracy:  0.9297848244620611\n",
      "Person:  315\n",
      "Transitions:  [4, 8, 5, 8]\n",
      "GT transitions:  1\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.9773175542406312 0.9759615384615384 0.9806763285024155\n",
      "Num frames:  (624, 11)\n",
      "Accuracy:  0.9773175542406312\n",
      "Person:  316\n",
      "Transitions:  [5, 8, 6, 8, 7, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.8655680832610582 0.9941860465116279 0.7714285714285715\n",
      "Num frames:  (516, 3)\n",
      "Accuracy:  0.8655680832610582\n",
      "Person:  317\n",
      "Transitions:  [0, 8, 1, 8]\n",
      "GT transitions:  1\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.8560558021559924 0.7223618090452262 0.7381258023106547\n",
      "Num frames:  (796, 23)\n",
      "Accuracy:  0.8560558021559924\n",
      "Person:  318\n",
      "Transitions:  [0, 8, 1, 8]\n",
      "GT transitions:  1\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.814852492370295 0.668488160291439 0.7497446373850868\n",
      "Num frames:  (1098, 119)\n",
      "Accuracy:  0.814852492370295\n",
      "Person:  319\n",
      "Transitions:  [7, 8, 0, 8]\n",
      "GT transitions:  1\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.7003979533826038 0.5256525652565257 1.0\n",
      "Num frames:  (1111, 527)\n",
      "Accuracy:  0.7003979533826038\n",
      "Person:  320\n",
      "Transitions:  [7, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.9965277777777778 0.9965277777777778 1.0\n",
      "Num frames:  (288, 1)\n",
      "Accuracy:  0.9965277777777778\n",
      "Person:  321\n",
      "Transitions:  [5, 8, 6, 8, 7, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.9654195011337868 0.9429906542056075 1.0\n",
      "Num frames:  (1070, 61)\n",
      "Accuracy:  0.9654195011337868\n",
      "Person:  322\n",
      "Transitions:  [6, 8, 4, 8, 1, 8, 0, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.4144215530903328 0.30920728705071393 0.6349848331648129\n",
      "Num frames:  (2031, 1117)\n",
      "Accuracy:  0.4144215530903328\n",
      "Person:  323\n",
      "Transitions:  [6, 8, 7, 8, 0, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.9088820826952527 0.8260233918128655 1.0\n",
      "Num frames:  (1368, 238)\n",
      "Accuracy:  0.9088820826952527\n",
      "Person:  324\n",
      "Transitions:  [7, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.9965397923875432 0.9965397923875432 1.0\n",
      "Num frames:  (289, 1)\n",
      "Accuracy:  0.9965397923875432\n",
      "Person:  325\n",
      "Transitions:  [5, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.9961089494163424 0.9961089494163424 1.0\n",
      "Num frames:  (257, 1)\n",
      "Accuracy:  0.9961089494163424\n",
      "Person:  326\n",
      "Transitions:  [5, 8, 6, 8, 7, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.9709302325581395 0.9536231884057971 0.9979777553083923\n",
      "Num frames:  (1035, 48)\n",
      "Accuracy:  0.9709302325581395\n",
      "Person:  327\n",
      "Transitions:  [5, 8, 4, 8, 1, 8, 0, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.9172274562584118 0.8649835345773875 1.0\n",
      "Num frames:  (1822, 246)\n",
      "Accuracy:  0.9172274562584118\n",
      "Person:  328\n",
      "Transitions:  [0, 8, 1, 8, 2, 8, 3, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.8919944789510007 0.8020369191597708 0.8671713695801789\n",
      "Num frames:  (1571, 120)\n",
      "Accuracy:  0.8919944789510007\n",
      "Person:  329\n",
      "Transitions:  [5, 8, 6, 8]\n",
      "GT transitions:  1\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.9757442116868799 0.9971910112359551 0.9726027397260274\n",
      "Num frames:  (712, 2)\n",
      "Accuracy:  0.9757442116868799\n",
      "Person:  330\n",
      "Transitions:  [1, 8, 0, 8]\n",
      "GT transitions:  1\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.8099290780141843 0.6769420468557337 0.7635605006954103\n",
      "Num frames:  (811, 98)\n",
      "Accuracy:  0.8099290780141843\n",
      "Person:  331\n",
      "Transitions:  [7, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.9873417721518988 0.9873417721518988 1.0\n",
      "Num frames:  (79, 1)\n",
      "Accuracy:  0.9873417721518988\n",
      "Person:  332\n",
      "Transitions:  [0, 8, 1, 8, 2, 8, 3, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.8773859592364931 0.782183908045977 0.8702046035805626\n",
      "Num frames:  (1740, 176)\n",
      "Accuracy:  0.8773859592364931\n",
      "Person:  333\n",
      "Transitions:  [7, 8, 6, 8, 5, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.9245007306380906 0.8910751932536893 1.0\n",
      "Num frames:  (1423, 155)\n",
      "Accuracy:  0.9245007306380906\n",
      "Person:  334\n",
      "Transitions:  [7, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.9967948717948718 0.9967948717948718 1.0\n",
      "Num frames:  (312, 1)\n",
      "Accuracy:  0.9967948717948718\n",
      "Person:  335\n",
      "Transitions:  [3, 8, 2, 8, 1, 8, 0, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.8737201365187713 0.7944444444444444 0.9213917525773195\n",
      "Num frames:  (1800, 248)\n",
      "Accuracy:  0.8737201365187713\n",
      "Person:  336\n",
      "Transitions:  [2, 8, 1, 8, 0, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.8981064021641119 0.8466803559206023 0.9108983799705449\n",
      "Num frames:  (1461, 105)\n",
      "Accuracy:  0.8981064021641119\n",
      "Person:  337\n",
      "Transitions:  [7, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.996309963099631 0.996309963099631 1.0\n",
      "Num frames:  (271, 1)\n",
      "Accuracy:  0.996309963099631\n",
      "Person:  338\n",
      "Transitions:  [7, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A,P,R:  0.9961089494163424 0.9961089494163424 1.0\n",
      "Num frames:  (257, 1)\n",
      "Accuracy:  0.9961089494163424\n",
      "Person:  339\n",
      "Transitions:  [0, 8, 1, 8, 2, 8, 3, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.8444637178375253 0.7402221149203283 0.876\n",
      "Num frames:  (2071, 321)\n",
      "Accuracy:  0.8444637178375253\n",
      "Person:  340\n",
      "Transitions:  [5, 8, 6, 8, 7, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.9783132530120482 0.9631525076765609 1.0\n",
      "Num frames:  (977, 36)\n",
      "Accuracy:  0.9783132530120482\n",
      "Person:  341\n",
      "Transitions:  [0, 8, 1, 8, 4, 8, 5, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.9515828677839852 0.9023904382470119 0.9919708029197081\n",
      "Num frames:  (1506, 145)\n",
      "Accuracy:  0.9515828677839852\n",
      "Person:  342\n",
      "Transitions:  [2, 8, 1, 8]\n",
      "GT transitions:  1\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.834924965893588 0.7846975088967971 0.8242990654205608\n",
      "Num frames:  (562, 27)\n",
      "Accuracy:  0.834924965893588\n",
      "Person:  343\n",
      "Transitions:  [3, 8, 2, 8, 1, 8, 0, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.9025009061254078 0.8380493678506924 0.928\n",
      "Num frames:  (1661, 161)\n",
      "Accuracy:  0.9025009061254078\n",
      "Person:  344\n",
      "Transitions:  [3, 8, 2, 8, 1, 8, 0, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.8980704697986577 0.8553846153846154 0.8540706605222734\n",
      "Num frames:  (1300, 53)\n",
      "Accuracy:  0.8980704697986577\n",
      "Person:  345\n",
      "Transitions:  [3, 8, 2, 8, 1, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.8812636165577342 0.8520361990950226 0.9312561819980217\n",
      "Num frames:  (2210, 188)\n",
      "Accuracy:  0.8812636165577342\n",
      "Person:  346\n",
      "Transitions:  [2, 8, 4, 8, 5, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.9494038964815353 0.9388830347734457 1.0\n",
      "Num frames:  (2847, 174)\n",
      "Accuracy:  0.9494038964815353\n",
      "Person:  347\n",
      "Transitions:  [7, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.9958677685950413 0.9958677685950413 1.0\n",
      "Num frames:  (242, 1)\n",
      "Accuracy:  0.9958677685950413\n",
      "Person:  348\n",
      "Transitions:  [1, 8, 7, 8]\n",
      "GT transitions:  1\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.50382096069869 0.39721485411140584 0.5645617342130066\n",
      "Num frames:  (1508, 447)\n",
      "Accuracy:  0.50382096069869\n",
      "Person:  349\n",
      "Transitions:  [3, 8, 2, 8, 1, 8, 0, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.4140389795594993 0.26815753018009103 0.928082191780822\n",
      "Num frames:  (5053, 3593)\n",
      "Accuracy:  0.4140389795594993\n",
      "Person:  350\n",
      "Transitions:  [7, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.9972527472527473 0.9972527472527473 1.0\n",
      "Num frames:  (364, 1)\n",
      "Accuracy:  0.9972527472527473\n",
      "Person:  351\n",
      "Transitions:  [0, 8, 1, 8, 4, 8, 6, 8, 5, 8]\n",
      "GT transitions:  4\n",
      "Transitions captured:  4\n",
      "A,P,R:  0.7944664031620553 0.6792355371900827 0.8749168330006654\n",
      "Num frames:  (1936, 436)\n",
      "Accuracy:  0.7944664031620553\n",
      "Person:  352\n",
      "Transitions:  [5, 8, 4, 8, 1, 8, 0, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.9241724403387221 0.8806927517639512 0.9920520231213873\n",
      "Num frames:  (1559, 186)\n",
      "Accuracy:  0.9241724403387221\n",
      "Person:  353\n",
      "Transitions:  [3, 8, 2, 8, 1, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.8560311284046692 0.8277634961439588 0.7796610169491526\n",
      "Num frames:  (778, 3)\n",
      "Accuracy:  0.8560311284046692\n",
      "Person:  354\n",
      "Transitions:  [7, 8, 6, 8, 5, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.9385869565217392 0.9058333333333334 1.0\n",
      "Num frames:  (1200, 113)\n",
      "Accuracy:  0.9385869565217392\n",
      "Person:  355\n",
      "Transitions:  [0, 8, 1, 8, 4, 8, 5, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.9050894085281981 0.8386260531432275 0.8457516339869281\n",
      "Num frames:  (1543, 40)\n",
      "Accuracy:  0.9050894085281981\n",
      "Person:  356\n",
      "Transitions:  [0, 8, 1, 8, 4, 8, 5, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.8936430317848411 0.8175930922827847 0.8530405405405406\n",
      "Num frames:  (1853, 87)\n",
      "Accuracy:  0.8936430317848411\n",
      "Person:  357\n",
      "Transitions:  [7, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.9968253968253968 0.9968253968253968 1.0\n",
      "Num frames:  (315, 1)\n",
      "Accuracy:  0.9968253968253968\n",
      "Person:  358\n",
      "Transitions:  [6, 8, 4, 8, 2, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.45171503957783643 0.4689507494646681 0.4481582537517053\n",
      "Num frames:  (1401, 230)\n",
      "Accuracy:  0.45171503957783643\n",
      "Person:  359\n",
      "Transitions:  [3, 8, 2, 8, 1, 8, 0, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.895399134880063 0.8503448275862069 0.8819742489270386\n",
      "Num frames:  (1450, 101)\n",
      "Accuracy:  0.895399134880063\n",
      "Person:  360\n",
      "Transitions:  [7, 8, 6, 8, 5, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.808695652173913 0.7449947312961012 1.0\n",
      "Num frames:  (1898, 484)\n",
      "Accuracy:  0.808695652173913\n",
      "Person:  361\n",
      "Transitions:  [6, 8, 4, 8, 0, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.3921639108554996 0.2893356643356643 0.9019073569482289\n",
      "Num frames:  (2288, 1619)\n",
      "Accuracy:  0.3921639108554996\n",
      "Person:  362\n",
      "Transitions:  [4, 8, 1, 8, 0, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.9321322371873361 0.9187434554973822 1.0\n",
      "Num frames:  (4775, 388)\n",
      "Accuracy:  0.9321322371873361\n",
      "Person:  363\n",
      "Transitions:  [3, 8, 2, 8, 1, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.9196058091286307 0.8866130212143379 1.0\n",
      "Num frames:  (1367, 155)\n",
      "Accuracy:  0.9196058091286307\n",
      "Person:  364\n",
      "Transitions:  [7, 8, 6, 8, 5, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.8584615384615385 0.8040170419963482 1.0\n",
      "Num frames:  (1643, 322)\n",
      "Accuracy:  0.8584615384615385\n",
      "Person:  365\n",
      "Transitions:  [7, 8, 6, 8, 5, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.9452619187757504 0.9129213483146067 1.0\n",
      "Num frames:  (1068, 93)\n",
      "Accuracy:  0.9452619187757504\n",
      "Person:  366\n",
      "Transitions:  [3, 8, 2, 8, 1, 8, 0, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.9180457052797478 0.8667582417582418 0.9191551347414421\n",
      "Num frames:  (1456, 97)\n",
      "Accuracy:  0.9180457052797478\n",
      "Person:  367\n",
      "Transitions:  [7, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.9965870307167235 0.9965870307167235 1.0\n",
      "Num frames:  (293, 1)\n",
      "Accuracy:  0.9965870307167235\n",
      "Person:  368\n",
      "Transitions:  [7, 8, 6, 8, 5, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.8891118916206724 0.8371407516580692 1.0\n",
      "Num frames:  (1357, 221)\n",
      "Accuracy:  0.8891118916206724\n",
      "Person:  369\n",
      "Transitions:  [5, 8, 4, 8, 7, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.7944496707431796 0.6767751479289941 1.0\n",
      "Num frames:  (1352, 437)\n",
      "Accuracy:  0.7944496707431796\n",
      "Person:  370\n",
      "Transitions:  [0, 8, 1, 8, 2, 8, 3, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.8858392999204455 0.8653530377668309 0.8253719655442443\n",
      "Num frames:  (1218, 64)\n",
      "Accuracy:  0.8858392999204455\n",
      "Person:  371\n",
      "Transitions:  [1, 8, 4, 8]\n",
      "GT transitions:  1\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.9193548387096774 0.9005681818181818 0.9979013641133263\n",
      "Num frames:  (1056, 103)\n",
      "Accuracy:  0.9193548387096774\n",
      "Person:  372\n",
      "Transitions:  [1, 8, 2, 8, 4, 8, 5, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.8525345622119815 0.7945578231292517 0.8248587570621468\n",
      "Num frames:  (1470, 72)\n",
      "Accuracy:  0.8525345622119815\n",
      "Person:  373\n",
      "Transitions:  [5, 8, 4, 8, 1, 8, 0, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.9390462531373253 0.9076023391812865 0.9923273657289002\n",
      "Num frames:  (1710, 158)\n",
      "Accuracy:  0.9390462531373253\n",
      "Person:  374\n",
      "Transitions:  [7, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.9961389961389961 0.9961389961389961 1.0\n",
      "Num frames:  (259, 1)\n",
      "Accuracy:  0.9961389961389961\n",
      "Person:  375\n",
      "Transitions:  [5, 8, 4, 8]\n",
      "GT transitions:  1\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.9283236994219654 0.9962406015037594 0.8983050847457628\n",
      "Num frames:  (532, 2)\n",
      "Accuracy:  0.9283236994219654\n",
      "Person:  376\n",
      "Transitions:  [0, 8, 1, 8, 2, 8, 3, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.8967315716272601 0.8092783505154639 0.8692041522491349\n",
      "Num frames:  (1552, 108)\n",
      "Accuracy:  0.8967315716272601\n",
      "Person:  377\n",
      "Transitions:  [0, 8, 1, 8]\n",
      "GT transitions:  1\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.860831234256927 0.7209595959595959 0.7542932628797886\n",
      "Num frames:  (792, 35)\n",
      "Accuracy:  0.860831234256927\n",
      "Person:  378\n",
      "Transitions:  [0, 8, 1, 8, 2, 8, 3, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.8741946422516107 0.7847263980757667 0.8764271323035594\n",
      "Num frames:  (1663, 187)\n",
      "Accuracy:  0.8741946422516107\n",
      "Person:  379\n",
      "Transitions:  [7, 8, 6, 8, 5, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.9744958481613286 0.9644859813084112 0.9951783992285439\n",
      "Num frames:  (1070, 38)\n",
      "Accuracy:  0.9744958481613286\n",
      "Person:  380\n",
      "Transitions:  [7, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.9972527472527473 0.9972527472527473 1.0\n",
      "Num frames:  (364, 1)\n",
      "Accuracy:  0.9972527472527473\n",
      "Person:  381\n",
      "Transitions:  [5, 8, 4, 8, 1, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.8731730315888732 0.8343596059113301 1.0\n",
      "Num frames:  (1624, 269)\n",
      "Accuracy:  0.8731730315888732\n",
      "Person:  382\n",
      "Transitions:  [7, 8, 0, 8]\n",
      "GT transitions:  1\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.9306071871127634 0.8644918444165621 0.9942279942279942\n",
      "Num frames:  (797, 108)\n",
      "Accuracy:  0.9306071871127634\n",
      "Person:  383\n",
      "Transitions:  [0, 8, 1, 8]\n",
      "GT transitions:  1\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.8825048418334409 0.7896634615384616 0.7858851674641149\n",
      "Num frames:  (832, 3)\n",
      "Accuracy:  0.8825048418334409\n",
      "Person:  384\n",
      "Transitions:  [0, 8, 1, 8]\n",
      "GT transitions:  1\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.7940613026819924 0.6226912928759895 0.7254098360655737\n",
      "Num frames:  (1137, 162)\n",
      "Accuracy:  0.7940613026819924\n",
      "Person:  385\n",
      "Transitions:  [3, 8, 2, 8, 1, 8, 0, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.8990476190476191 0.8261154855643045 0.9230205278592375\n",
      "Num frames:  (1524, 160)\n",
      "Accuracy:  0.8990476190476191\n",
      "Person:  386\n",
      "Transitions:  [5, 8, 6, 8, 7, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.9125 0.8689704823614111 1.0\n",
      "Num frames:  (1389, 182)\n",
      "Accuracy:  0.9125\n",
      "Person:  387\n",
      "Transitions:  [4, 8, 7, 8]\n",
      "GT transitions:  1\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.8050407709414381 0.7259414225941423 0.9625520110957004\n",
      "Num frames:  (956, 236)\n",
      "Accuracy:  0.8050407709414381\n",
      "Person:  388\n",
      "Transitions:  [0, 8, 1, 8]\n",
      "GT transitions:  1\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.8418430884184309 0.6997635933806147 0.7123947051744886\n",
      "Num frames:  (846, 15)\n",
      "Accuracy:  0.8418430884184309\n",
      "Person:  389\n",
      "Transitions:  [7, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.9969230769230769 0.9969230769230769 1.0\n",
      "Num frames:  (325, 1)\n",
      "Accuracy:  0.9969230769230769\n",
      "Person:  390\n",
      "Transitions:  [5, 8, 6, 8, 7, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.919234360410831 0.8802768166089966 1.0\n",
      "Num frames:  (1445, 173)\n",
      "Accuracy:  0.919234360410831\n",
      "Person:  391\n",
      "Transitions:  [7, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.9953703703703703 0.9953703703703703 1.0\n",
      "Num frames:  (216, 1)\n",
      "Accuracy:  0.9953703703703703\n",
      "Person:  392\n",
      "Transitions:  [5, 8, 4, 8, 4, 8, 4, 8, 1, 8, 0, 8]\n",
      "GT transitions:  5\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.5666389581601552 0.4759005580923389 0.7059708981435022\n",
      "Num frames:  (5913, 1956)\n",
      "Accuracy:  0.5666389581601552\n",
      "Person:  393\n",
      "Transitions:  [7, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.9945054945054945 0.9945054945054945 1.0\n",
      "Num frames:  (182, 1)\n",
      "Accuracy:  0.9945054945054945\n",
      "Person:  394\n",
      "Transitions:  [7, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.9979166666666667 0.9979166666666667 1.0\n",
      "Num frames:  (480, 1)\n",
      "Accuracy:  0.9979166666666667\n",
      "Person:  395\n",
      "Transitions:  [7, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.9961389961389961 0.9961389961389961 1.0\n",
      "Num frames:  (259, 1)\n",
      "Accuracy:  0.9961389961389961\n",
      "Person:  396\n",
      "Transitions:  [0, 8, 1, 8, 4, 8, 5, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.8756132756132756 0.7870967741935484 0.8422729686670207\n",
      "Num frames:  (2015, 134)\n",
      "Accuracy:  0.8756132756132756\n",
      "Person:  397\n",
      "Transitions:  [0, 8, 1, 8, 7, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A,P,R:  0.8916753744339951 0.7884882108183079 0.8732718894009217\n",
      "Num frames:  (1442, 146)\n",
      "Accuracy:  0.8916753744339951\n",
      "Person:  398\n",
      "Transitions:  [3, 8, 2, 8, 1, 8, 0, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.8917299240910906 0.8492569002123143 0.8664259927797834\n",
      "Num frames:  (1413, 86)\n",
      "Accuracy:  0.8917299240910906\n",
      "Person:  399\n",
      "Transitions:  [5, 8, 4, 8, 1, 8, 0, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.9303519061583577 0.8846625766871166 0.9979238754325259\n",
      "Num frames:  (1630, 187)\n",
      "Accuracy:  0.9303519061583577\n",
      "Person:  400\n",
      "Transitions:  [3, 8, 2, 8, 1, 8, 0, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.8908801274392673 0.8095238095238095 0.8615733736762481\n",
      "Num frames:  (1407, 91)\n",
      "Accuracy:  0.8908801274392673\n",
      "Person:  401\n",
      "Transitions:  [5, 8, 6, 8, 7, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.9751724137931035 0.9913258983890955 0.9650180940892642\n",
      "Num frames:  (807, 7)\n",
      "Accuracy:  0.9751724137931035\n",
      "Person:  402\n",
      "Transitions:  [5, 8, 4, 8, 1, 8, 0, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.912487028709789 0.8576290414066932 0.9986789960369881\n",
      "Num frames:  (1763, 251)\n",
      "Accuracy:  0.912487028709789\n",
      "Person:  403\n",
      "Transitions:  [5, 8, 6, 8, 7, 8, 0, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.9870322341608003 0.9868900218499636 0.9876093294460642\n",
      "Num frames:  (1373, 18)\n",
      "Accuracy:  0.9870322341608003\n",
      "Person:  404\n",
      "Transitions:  [7, 8, 6, 8, 5, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.8633461047254151 0.8129370629370629 1.0\n",
      "Num frames:  (1716, 321)\n",
      "Accuracy:  0.8633461047254151\n",
      "Person:  405\n",
      "Transitions:  [0, 8, 4, 8, 6, 8, 5, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.7418546365914787 0.5635593220338984 0.9950124688279302\n",
      "Num frames:  (2124, 921)\n",
      "Accuracy:  0.7418546365914787\n",
      "Person:  406\n",
      "Transitions:  [7, 8, 0, 8]\n",
      "GT transitions:  1\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.7532822757111597 0.6145299145299146 1.0\n",
      "Num frames:  (1170, 451)\n",
      "Accuracy:  0.7532822757111597\n",
      "Person:  407\n",
      "Transitions:  [0, 8, 1, 8, 2, 8, 3, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.90205646566748 0.8199083169613621 0.8749126484975541\n",
      "Num frames:  (1527, 102)\n",
      "Accuracy:  0.90205646566748\n",
      "Person:  408\n",
      "Transitions:  [2, 8, 4, 8, 1, 8, 0, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.8342813803564657 0.7552526973310619 0.9172413793103448\n",
      "Num frames:  (1761, 317)\n",
      "Accuracy:  0.8342813803564657\n",
      "Person:  409\n",
      "Transitions:  [3, 8, 2, 8, 1, 8, 0, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.8882701009397842 0.8171856978085352 0.915374677002584\n",
      "Num frames:  (1734, 190)\n",
      "Accuracy:  0.8882701009397842\n",
      "Person:  410\n",
      "Transitions:  [7, 8, 0, 8]\n",
      "GT transitions:  1\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.9060509554140127 0.8441901408450704 1.0\n",
      "Num frames:  (1136, 177)\n",
      "Accuracy:  0.9060509554140127\n",
      "Person:  411\n",
      "Transitions:  [5, 8, 4, 8, 1, 8, 0, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.8753586228881096 0.8113391984359726 0.9523809523809523\n",
      "Num frames:  (2046, 308)\n",
      "Accuracy:  0.8753586228881096\n",
      "Person:  412\n",
      "Transitions:  [1, 8, 0, 8]\n",
      "GT transitions:  1\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.8002947678703022 0.6733416770963705 0.7182910547396528\n",
      "Num frames:  (799, 60)\n",
      "Accuracy:  0.8002947678703022\n",
      "Person:  413\n",
      "Transitions:  [7, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.9968152866242038 0.9968152866242038 1.0\n",
      "Num frames:  (314, 1)\n",
      "Accuracy:  0.9968152866242038\n",
      "Person:  414\n",
      "Transitions:  [5, 8, 6, 8, 4, 8, 1, 8, 0, 8]\n",
      "GT transitions:  4\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.5332948976650331 0.4373872248285817 0.8589652728561304\n",
      "Num frames:  (2771, 1420)\n",
      "Accuracy:  0.5332948976650331\n",
      "Person:  415\n",
      "Transitions:  [6, 8, 7, 8]\n",
      "GT transitions:  1\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.8697444352844188 0.7805555555555556 1.0\n",
      "Num frames:  (720, 158)\n",
      "Accuracy:  0.8697444352844188\n",
      "Person:  416\n",
      "Transitions:  [0, 8, 1, 8, 2, 8, 3, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.8575317604355717 0.7540469973890339 0.8762135922330098\n",
      "Num frames:  (1915, 267)\n",
      "Accuracy:  0.8575317604355717\n",
      "Person:  417\n",
      "Transitions:  [7, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.9939393939393939 0.9939393939393939 1.0\n",
      "Num frames:  (165, 1)\n",
      "Accuracy:  0.9939393939393939\n",
      "Person:  418\n",
      "Transitions:  [5, 8, 6, 8, 7, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.9480238224147266 0.9168831168831169 1.0\n",
      "Num frames:  (1155, 96)\n",
      "Accuracy:  0.9480238224147266\n",
      "Person:  419\n",
      "Transitions:  [6, 8, 5, 8]\n",
      "GT transitions:  1\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.9151750972762646 0.9034543844109831 1.0\n",
      "Num frames:  (1129, 109)\n",
      "Accuracy:  0.9151750972762646\n",
      "Person:  420\n",
      "Transitions:  [0, 8, 1, 8, 2, 8, 3, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.46675191815856776 0.28350515463917525 0.8709677419354839\n",
      "Num frames:  (5238, 3533)\n",
      "Accuracy:  0.46675191815856776\n",
      "Person:  421\n",
      "Transitions:  [0, 8, 1, 8, 2, 8, 3, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.8788273615635179 0.7844626168224299 0.8670109748224661\n",
      "Num frames:  (1712, 166)\n",
      "Accuracy:  0.8788273615635179\n",
      "Person:  422\n",
      "Transitions:  [7, 8, 6, 8, 5, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.9236180904522613 0.8877400295420975 1.0\n",
      "Num frames:  (1354, 152)\n",
      "Accuracy:  0.9236180904522613\n",
      "Person:  423\n",
      "Transitions:  [7, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.9984848484848485 0.9984848484848485 1.0\n",
      "Num frames:  (660, 1)\n",
      "Accuracy:  0.9984848484848485\n",
      "Person:  424\n",
      "Transitions:  [3, 8, 2, 8, 4, 8, 4, 8, 2, 8]\n",
      "GT transitions:  4\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.21426885864862738 0.1434085256025388 0.5625841184387618\n",
      "Num frames:  (11659, 8689)\n",
      "Accuracy:  0.21426885864862738\n",
      "Person:  425\n",
      "Transitions:  [3, 8, 2, 8, 1, 8, 0, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.9260715690129768 0.8755129958960328 0.9268645908761767\n",
      "Num frames:  (1462, 87)\n",
      "Accuracy:  0.9260715690129768\n",
      "Person:  426\n",
      "Transitions:  [7, 8, 0, 8]\n",
      "GT transitions:  1\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.8482056256062076 0.764484574868322 1.0\n",
      "Num frames:  (1329, 313)\n",
      "Accuracy:  0.8482056256062076\n",
      "Person:  427\n",
      "Transitions:  [1, 8, 2, 8, 3, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.8540723981900452 0.7839195979899497 0.853236098450319\n",
      "Num frames:  (1194, 97)\n",
      "Accuracy:  0.8540723981900452\n",
      "Person:  428\n",
      "Transitions:  [6, 8, 4, 8, 2, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  0\n",
      "A,P,R:  0.37073707370737075 0.3444360333080999 0.33980582524271846\n",
      "Num frames:  (1321, 260)\n",
      "Accuracy:  0.37073707370737075\n",
      "Person:  429\n",
      "Transitions:  [0, 8, 1, 8, 2, 8, 3, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.8770913770913771 0.7842465753424658 0.87017099430019\n",
      "Num frames:  (1752, 177)\n",
      "Accuracy:  0.8770913770913771\n",
      "Person:  430\n",
      "Transitions:  [0, 8, 1, 8, 2, 8, 3, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.9027181688125894 0.818733153638814 0.8703438395415473\n",
      "Num frames:  (1484, 91)\n",
      "Accuracy:  0.9027181688125894\n",
      "Person:  431\n",
      "Transitions:  [7, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.9962962962962963 0.9962962962962963 1.0\n",
      "Num frames:  (270, 1)\n",
      "Accuracy:  0.9962962962962963\n",
      "Person:  432\n",
      "Transitions:  [7, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.9965635738831615 0.9965635738831615 1.0\n",
      "Num frames:  (291, 1)\n",
      "Accuracy:  0.9965635738831615\n",
      "Person:  433\n",
      "Transitions:  [7, 8, 6, 8, 5, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.956759715380405 0.9338912133891213 1.0\n",
      "Num frames:  (1195, 79)\n",
      "Accuracy:  0.956759715380405\n",
      "Person:  434\n",
      "Transitions:  [1, 8, 2, 8, 4, 8, 4, 8, 4, 8, 4, 8, 3, 8]\n",
      "GT transitions:  6\n",
      "Transitions captured:  4\n",
      "A,P,R:  0.07059322833160427 0.03714180297626368 0.4730576441102757\n",
      "Num frames:  (40655, 37736)\n",
      "Accuracy:  0.07059322833160427\n",
      "Person:  435\n",
      "Transitions:  [7, 8, 0, 8]\n",
      "GT transitions:  1\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.9691444600280504 0.9425770308123249 0.9955621301775148\n",
      "Num frames:  (714, 41)\n",
      "Accuracy:  0.9691444600280504\n",
      "Person:  436\n",
      "Transitions:  [7, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.9962962962962963 0.9962962962962963 1.0\n",
      "Num frames:  (270, 1)\n",
      "Accuracy:  0.9962962962962963\n",
      "Person:  437\n",
      "Transitions:  [6, 8, 5, 8, 5, 8, 6, 8, 6, 8, 5, 8, 5, 8, 6, 8, 6, 8, 6, 8, 4, 8]\n",
      "GT transitions:  10\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.0673637507270686 0.04887772979982617 0.4660002630540576\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num frames:  (72487, 64887)\n",
      "Accuracy:  0.0673637507270686\n",
      "Person:  438\n",
      "Transitions:  [0, 8, 1, 8, 2, 8, 3, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.8791208791208791 0.7863296955772544 0.8697585768742059\n",
      "Num frames:  (1741, 169)\n",
      "Accuracy:  0.8791208791208791\n",
      "Person:  439\n",
      "Transitions:  [7, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.9980769230769231 0.9980769230769231 1.0\n",
      "Num frames:  (520, 1)\n",
      "Accuracy:  0.9980769230769231\n",
      "Person:  440\n",
      "Transitions:  [7, 8, 6, 8, 5, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.8990338164251208 0.8542538354253836 1.0\n",
      "Num frames:  (1434, 209)\n",
      "Accuracy:  0.8990338164251208\n",
      "Person:  441\n",
      "Transitions:  [0, 8, 1, 8]\n",
      "GT transitions:  1\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.8293650793650794 0.6789189189189189 0.7449584816132859\n",
      "Num frames:  (925, 86)\n",
      "Accuracy:  0.8293650793650794\n",
      "Person:  442\n",
      "Transitions:  [7, 8, 0, 8]\n",
      "GT transitions:  1\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.9359410430839002 0.8881188118811881 1.0\n",
      "Num frames:  (1010, 113)\n",
      "Accuracy:  0.9359410430839002\n",
      "Person:  443\n",
      "Transitions:  [0, 8, 1, 8, 4, 8, 4, 8, 4, 8, 6, 8]\n",
      "GT transitions:  5\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.5660639777468707 0.3836094158674804 0.5088666152659984\n",
      "Num frames:  (3441, 910)\n",
      "Accuracy:  0.5660639777468707\n",
      "Person:  444\n",
      "Transitions:  [5, 8, 4, 8, 1, 8, 0, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.9055706521739131 0.8505434782608695 0.9980867346938775\n",
      "Num frames:  (1840, 275)\n",
      "Accuracy:  0.9055706521739131\n",
      "Person:  445\n",
      "Transitions:  [0, 8, 4, 8, 5, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.7423926636098375 0.5249500998003992 0.650990099009901\n",
      "Num frames:  (1002, 336)\n",
      "Accuracy:  0.7423926636098375\n",
      "Person:  446\n",
      "Transitions:  [1, 8, 0, 8]\n",
      "GT transitions:  1\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.6594911937377691 0.540084388185654 0.4266666666666667\n",
      "Num frames:  (474, 4)\n",
      "Accuracy:  0.6594911937377691\n",
      "Person:  447\n",
      "Transitions:  [5, 8, 6, 8, 7, 8, 0, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.9264776549735704 0.9895833333333334 0.8558558558558559\n",
      "Num frames:  (864, 9)\n",
      "Accuracy:  0.9264776549735704\n",
      "Person:  448\n",
      "Transitions:  [3, 8, 2, 8, 1, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.8955223880597015 0.8476987447698745 0.9093357271095153\n",
      "Num frames:  (1195, 81)\n",
      "Accuracy:  0.8955223880597015\n",
      "Person:  449\n",
      "Transitions:  [5, 8, 6, 8, 4, 8, 3, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.446193109315185 0.33991088478676 0.3897810218978102\n",
      "Num frames:  (1571, 466)\n",
      "Accuracy:  0.446193109315185\n",
      "Person:  450\n",
      "Transitions:  [0, 8, 1, 8, 4, 8, 5, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.9085596424888278 0.8298969072164949 0.8621151271753681\n",
      "Num frames:  (1552, 60)\n",
      "Accuracy:  0.9085596424888278\n",
      "Person:  451\n",
      "Transitions:  [0, 8, 7, 8]\n",
      "GT transitions:  1\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.8739933680720038 0.7483124397299904 0.9897959183673469\n",
      "Num frames:  (1037, 258)\n",
      "Accuracy:  0.8739933680720038\n",
      "Person:  452\n",
      "Transitions:  [1, 8, 4, 8, 5, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.9682713347921226 0.9522613065326633 0.9991212653778558\n",
      "Num frames:  (1194, 57)\n",
      "Accuracy:  0.9682713347921226\n",
      "Person:  453\n",
      "Transitions:  [0, 8, 1, 8]\n",
      "GT transitions:  1\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.8565051020408163 0.7284105131414268 0.7367088607594937\n",
      "Num frames:  (799, 17)\n",
      "Accuracy:  0.8565051020408163\n",
      "Person:  454\n",
      "Transitions:  [7, 8, 0, 8]\n",
      "GT transitions:  1\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.9592857142857143 0.9166666666666666 1.0\n",
      "Num frames:  (684, 57)\n",
      "Accuracy:  0.9592857142857143\n",
      "Person:  455\n",
      "Transitions:  [0, 8, 4, 8, 6, 8, 5, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.7618705035971223 0.5516728624535316 0.8091603053435115\n",
      "Num frames:  (1345, 487)\n",
      "Accuracy:  0.7618705035971223\n",
      "Person:  456\n",
      "Transitions:  [7, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.9963898916967509 0.9963898916967509 1.0\n",
      "Num frames:  (277, 1)\n",
      "Accuracy:  0.9963898916967509\n",
      "Person:  457\n",
      "Transitions:  [0, 8, 1, 8, 4, 8, 5, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.9390756302521008 0.8932614555256064 0.9969915764139591\n",
      "Num frames:  (1855, 198)\n",
      "Accuracy:  0.9390756302521008\n",
      "Person:  458\n",
      "Transitions:  [7, 8, 6, 8, 5, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.9680156657963447 0.9583333333333334 0.9889746416758545\n",
      "Num frames:  (936, 39)\n",
      "Accuracy:  0.9680156657963447\n",
      "Person:  459\n",
      "Transitions:  [5, 8, 4, 8, 1, 8, 0, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.9384615384615385 0.9038199181446112 0.9858630952380952\n",
      "Num frames:  (1466, 137)\n",
      "Accuracy:  0.9384615384615385\n",
      "Person:  460\n",
      "Transitions:  [7, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.9970149253731343 0.9970149253731343 1.0\n",
      "Num frames:  (335, 1)\n",
      "Accuracy:  0.9970149253731343\n",
      "Person:  461\n",
      "Transitions:  [5, 8, 6, 8, 7, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.9099709583736689 0.864530225782957 1.0\n",
      "Num frames:  (1373, 186)\n",
      "Accuracy:  0.9099709583736689\n",
      "Person:  462\n",
      "Transitions:  [0, 8, 1, 8, 2, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.8345690454124189 0.7044701986754967 0.7916279069767442\n",
      "Num frames:  (1208, 133)\n",
      "Accuracy:  0.8345690454124189\n",
      "Person:  463\n",
      "Transitions:  [7, 8, 6, 8, 5, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.9315818281335523 0.8946925021061499 1.0\n",
      "Num frames:  (1187, 125)\n",
      "Accuracy:  0.9315818281335523\n",
      "Person:  464\n",
      "Transitions:  [7, 8, 6, 8, 5, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.9129961935834693 0.867330016583748 1.0\n",
      "Num frames:  (1206, 160)\n",
      "Accuracy:  0.9129961935834693\n",
      "Person:  465\n",
      "Transitions:  [5, 8, 6, 8, 7, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.9615170105967652 0.9376130198915009 1.0\n",
      "Num frames:  (1106, 69)\n",
      "Accuracy:  0.9615170105967652\n",
      "Person:  466\n",
      "Transitions:  [5, 8, 4, 8, 1, 8, 0, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.9084821428571429 0.8598130841121495 0.9988571428571429\n",
      "Num frames:  (2033, 285)\n",
      "Accuracy:  0.9084821428571429\n",
      "Person:  467\n",
      "Transitions:  [7, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.996742671009772 0.996742671009772 1.0\n",
      "Num frames:  (307, 1)\n",
      "Accuracy:  0.996742671009772\n",
      "Person:  468\n",
      "Transitions:  [5, 8, 6, 8, 7, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.9321175278622087 0.8951486697965572 1.0\n",
      "Num frames:  (1278, 134)\n",
      "Accuracy:  0.9321175278622087\n",
      "Person:  469\n",
      "Transitions:  [7, 8, 6, 8, 5, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.9218833600856072 0.8830128205128205 1.0\n",
      "Num frames:  (1248, 146)\n",
      "Accuracy:  0.9218833600856072\n",
      "Person:  470\n",
      "Transitions:  [5, 8, 6, 8, 7, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.9062205466540999 0.8609364081062194 1.0\n",
      "Num frames:  (1431, 199)\n",
      "Accuracy:  0.9062205466540999\n",
      "Person:  471\n",
      "Transitions:  [7, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.9970059880239521 0.9970059880239521 1.0\n",
      "Num frames:  (334, 1)\n",
      "Accuracy:  0.9970059880239521\n",
      "Person:  472\n",
      "Transitions:  [0, 8, 6, 8, 5, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.7846227316141356 0.9382352941176471 0.4259012016021362\n",
      "Num frames:  (340, 21)\n",
      "Accuracy:  0.7846227316141356\n",
      "Person:  473\n",
      "Transitions:  [3, 8, 2, 8, 1, 8, 0, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.8907791765906771 0.8264234383637369 0.9205665024630542\n",
      "Num frames:  (1809, 192)\n",
      "Accuracy:  0.8907791765906771\n",
      "Person:  474\n",
      "Transitions:  [3, 8, 2, 8, 1, 8, 0, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.8672768878718535 0.7866526537046769 0.9327102803738317\n",
      "Num frames:  (1903, 298)\n",
      "Accuracy:  0.8672768878718535\n",
      "Person:  475\n",
      "Transitions:  [1, 8, 7, 8]\n",
      "GT transitions:  1\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.599009900990099 0.4409509202453988 0.5727091633466136\n",
      "Num frames:  (1304, 300)\n",
      "Accuracy:  0.599009900990099\n",
      "Person:  476\n",
      "Transitions:  [5, 8, 6, 8, 4, 8, 1, 8, 0, 8]\n",
      "GT transitions:  4\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.546985001530456 0.45200155460551883 0.8653273809523809\n",
      "Num frames:  (2573, 1299)\n",
      "Accuracy:  0.546985001530456\n",
      "Person:  477\n",
      "Transitions:  [0, 8, 1, 8, 4, 8, 5, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.9034994697773064 0.8125884016973126 0.8731003039513677\n",
      "Num frames:  (1414, 106)\n",
      "Accuracy:  0.9034994697773064\n",
      "Person:  478\n",
      "Transitions:  [5, 8, 4, 8, 1, 8, 0, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.8707334785766159 0.7918871252204586 0.9373695198329853\n",
      "Num frames:  (1701, 266)\n",
      "Accuracy:  0.8707334785766159\n",
      "Person:  479\n",
      "Transitions:  [3, 8, 2, 8, 1, 8, 0, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.8807212205270458 0.811577752553916 0.9154929577464789\n",
      "Num frames:  (1762, 212)\n",
      "Accuracy:  0.8807212205270458\n",
      "Person:  480\n",
      "Transitions:  [5, 8, 6, 8, 7, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.9163059163059163 0.8743682310469314 1.0\n",
      "Num frames:  (1385, 174)\n",
      "Accuracy:  0.9163059163059163\n",
      "Person:  481\n",
      "Transitions:  [5, 8, 6, 8, 7, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.9734717416378316 0.9573863636363636 0.9990118577075099\n",
      "Num frames:  (1056, 45)\n",
      "Accuracy:  0.9734717416378316\n",
      "Person:  482\n",
      "Transitions:  [7, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.9984732824427481 0.9984732824427481 1.0\n",
      "Num frames:  (655, 1)\n",
      "Accuracy:  0.9984732824427481\n",
      "Person:  483\n",
      "Transitions:  [3, 8, 2, 8, 1, 8, 0, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.9053398058252428 0.8586956521739131 0.88301043219076\n",
      "Num frames:  (1380, 77)\n",
      "Accuracy:  0.9053398058252428\n",
      "Person:  484\n",
      "Transitions:  [7, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.9978540772532188 0.9978540772532188 1.0\n",
      "Num frames:  (466, 1)\n",
      "Accuracy:  0.9978540772532188\n",
      "Person:  485\n",
      "Transitions:  [5, 8, 6, 8, 7, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.968944099378882 0.9491211840888066 1.0\n",
      "Num frames:  (1081, 55)\n",
      "Accuracy:  0.968944099378882\n",
      "Person:  486\n",
      "Transitions:  [0, 8, 1, 8, 4, 8, 5, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.8779840848806366 0.7857883817427386 0.86521987435751\n",
      "Num frames:  (1928, 178)\n",
      "Accuracy:  0.8779840848806366\n",
      "Person:  487\n",
      "Transitions:  [1, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.4986225895316804 0.4986225895316804 0.5\n",
      "Num frames:  (363, 1)\n",
      "Accuracy:  0.4986225895316804\n",
      "Person:  488\n",
      "Transitions:  [1, 8, 2, 8, 3, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.8330550918196995 0.7536945812807881 0.8507877664504171\n",
      "Num frames:  (1218, 139)\n",
      "Accuracy:  0.8330550918196995\n",
      "Person:  489\n",
      "Transitions:  [5, 8, 6, 8, 7, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.9763636363636363 0.9616548940464178 0.9989517819706499\n",
      "Num frames:  (991, 38)\n",
      "Accuracy:  0.9763636363636363\n",
      "Person:  490\n",
      "Transitions:  [5, 8, 6, 8]\n",
      "GT transitions:  1\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.9727352682497801 0.9669156883671292 1.0\n",
      "Num frames:  (937, 31)\n",
      "Accuracy:  0.9727352682497801\n",
      "Person:  491\n",
      "Transitions:  [7, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.9956521739130435 0.9956521739130435 1.0\n",
      "Num frames:  (230, 1)\n",
      "Accuracy:  0.9956521739130435\n",
      "Person:  492\n",
      "Transitions:  [7, 8, 0, 8]\n",
      "GT transitions:  1\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.9414201183431953 0.8957894736842106 1.0\n",
      "Num frames:  (950, 99)\n",
      "Accuracy:  0.9414201183431953\n",
      "Person:  493\n",
      "Transitions:  [7, 8, 6, 8, 5, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.9245939675174014 0.880184331797235 1.0\n",
      "Num frames:  (1085, 130)\n",
      "Accuracy:  0.9245939675174014\n",
      "Person:  494\n",
      "Transitions:  [5, 8, 6, 8, 7, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.987081620669407 0.98635477582846 0.9921568627450981\n",
      "Num frames:  (1026, 14)\n",
      "Accuracy:  0.987081620669407\n",
      "Person:  495\n",
      "Transitions:  [0, 8, 1, 8, 4, 8, 6, 8, 5, 8]\n",
      "GT transitions:  4\n",
      "Transitions captured:  4\n",
      "A,P,R:  0.8117073170731708 0.8090614886731392 0.7267441860465116\n",
      "Num frames:  (927, 104)\n",
      "Accuracy:  0.8117073170731708\n",
      "Person:  496\n",
      "Transitions:  [5, 8, 6, 8, 7, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.9569606801275239 0.9318755256518082 1.0\n",
      "Num frames:  (1189, 81)\n",
      "Accuracy:  0.9569606801275239\n",
      "Person:  497\n",
      "Transitions:  [5, 8, 4, 8, 1, 8, 4, 8, 5, 8, 5, 8, 6, 8]\n",
      "GT transitions:  6\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.11808621658505258 0.05933727202671461 0.2755467196819085\n",
      "Num frames:  (11679, 9164)\n",
      "Accuracy:  0.11808621658505258\n",
      "Person:  498\n",
      "Transitions:  [3, 8, 2, 8, 1, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.8901018922852983 0.8465974625144176 0.8331441543700341\n",
      "Num frames:  (867, 4)\n",
      "Accuracy:  0.8901018922852983\n",
      "Person:  499\n",
      "Transitions:  [5, 8, 4, 8, 2, 8, 1, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.8907933398628796 0.8463128876636802 1.0\n",
      "Num frames:  (1451, 223)\n",
      "Accuracy:  0.8907933398628796\n",
      "Person:  500\n",
      "Transitions:  [2, 8, 1, 8]\n",
      "GT transitions:  1\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.8211920529801324 0.7688356164383562 0.8178506375227687\n",
      "Num frames:  (584, 35)\n",
      "Accuracy:  0.8211920529801324\n",
      "Person:  501\n",
      "Transitions:  [1, 8, 0, 8]\n",
      "GT transitions:  1\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.7808455565142364 0.6429725363489499 0.639871382636656\n",
      "Num frames:  (619, 30)\n",
      "Accuracy:  0.7808455565142364\n",
      "Person:  502\n",
      "Transitions:  [0, 8, 1, 8, 4, 8, 5, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A,P,R:  0.9316939890710383 0.9346534653465347 0.8847235238987816\n",
      "Num frames:  (1010, 52)\n",
      "Accuracy:  0.9316939890710383\n",
      "Person:  503\n",
      "Transitions:  [0, 8, 1, 8]\n",
      "GT transitions:  1\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.8835820895522388 0.7616822429906542 0.76049766718507\n",
      "Num frames:  (642, 2)\n",
      "Accuracy:  0.8835820895522388\n",
      "Person:  504\n",
      "Transitions:  [7, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.9971014492753624 0.9971014492753624 1.0\n",
      "Num frames:  (345, 1)\n",
      "Accuracy:  0.9971014492753624\n",
      "Person:  505\n",
      "Transitions:  [5, 8, 4, 8, 1, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.827741612418628 0.7750163505559189 0.8803863298662704\n",
      "Num frames:  (1529, 183)\n",
      "Accuracy:  0.827741612418628\n",
      "Person:  506\n",
      "Transitions:  [5, 8, 4, 8, 1, 8, 0, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.9260355029585798 0.8801986343885785 0.9950877192982456\n",
      "Num frames:  (1611, 193)\n",
      "Accuracy:  0.9260355029585798\n",
      "Person:  507\n",
      "Transitions:  [7, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.9850746268656716 0.9850746268656716 1.0\n",
      "Num frames:  (67, 1)\n",
      "Accuracy:  0.9850746268656716\n",
      "Person:  508\n",
      "Transitions:  [5, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.9959514170040485 0.9959514170040485 1.0\n",
      "Num frames:  (247, 1)\n",
      "Accuracy:  0.9959514170040485\n",
      "Person:  509\n",
      "Transitions:  [7, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.9978632478632479 0.9978632478632479 1.0\n",
      "Num frames:  (468, 1)\n",
      "Accuracy:  0.9978632478632479\n",
      "Person:  510\n",
      "Transitions:  [3, 8, 2, 8, 1, 8, 0, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.8960256924929747 0.8240282685512368 0.8649851632047477\n",
      "Num frames:  (1415, 77)\n",
      "Accuracy:  0.8960256924929747\n",
      "Person:  511\n",
      "Transitions:  [7, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.9968944099378882 0.9968944099378882 1.0\n",
      "Num frames:  (322, 1)\n",
      "Accuracy:  0.9968944099378882\n",
      "Person:  512\n",
      "Transitions:  [7, 8, 7, 8, 7, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.5594862425953607 0.5499929007525203 0.952493360873414\n",
      "Num frames:  (35215, 14948)\n",
      "Accuracy:  0.5594862425953607\n",
      "Person:  513\n",
      "Transitions:  [7, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.9971181556195965 0.9971181556195965 1.0\n",
      "Num frames:  (347, 1)\n",
      "Accuracy:  0.9971181556195965\n",
      "Person:  514\n",
      "Transitions:  [7, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.9972375690607734 0.9972375690607734 1.0\n",
      "Num frames:  (362, 1)\n",
      "Accuracy:  0.9972375690607734\n",
      "Person:  515\n",
      "Transitions:  [3, 8, 2, 8, 1, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.8610687022900764 0.8048606147248034 0.9080645161290323\n",
      "Num frames:  (1399, 159)\n",
      "Accuracy:  0.8610687022900764\n",
      "Person:  516\n",
      "Transitions:  [7, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.996551724137931 0.996551724137931 1.0\n",
      "Num frames:  (290, 1)\n",
      "Accuracy:  0.996551724137931\n",
      "Person:  517\n",
      "Transitions:  [0, 8, 1, 8, 4, 8, 5, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.9089687604971448 0.8325062034739454 0.8608082103912764\n",
      "Num frames:  (1612, 54)\n",
      "Accuracy:  0.9089687604971448\n",
      "Person:  518\n",
      "Transitions:  [7, 8, 6, 8, 5, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.9299395161290323 0.896807720861173 1.0\n",
      "Num frames:  (1347, 139)\n",
      "Accuracy:  0.9299395161290323\n",
      "Person:  519\n",
      "Transitions:  [5, 8, 4, 8, 1, 8, 0, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.9295154185022027 0.8966737438075018 0.9761171032357473\n",
      "Num frames:  (1413, 145)\n",
      "Accuracy:  0.9295154185022027\n",
      "Person:  520\n",
      "Transitions:  [5, 8, 6, 8, 4, 8, 1, 8, 0, 8]\n",
      "GT transitions:  4\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.5584988962472406 0.45656565656565656 0.894695170229612\n",
      "Num frames:  (2475, 1267)\n",
      "Accuracy:  0.5584988962472406\n",
      "Person:  521\n",
      "Transitions:  [5, 8, 4, 8, 1, 8, 0, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.877910447761194 0.8087406015037594 0.9988392338943702\n",
      "Num frames:  (2128, 407)\n",
      "Accuracy:  0.877910447761194\n",
      "Person:  522\n",
      "Transitions:  [7, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.9973544973544973 0.9973544973544973 1.0\n",
      "Num frames:  (378, 1)\n",
      "Accuracy:  0.9973544973544973\n",
      "Person:  523\n",
      "Transitions:  [5, 8, 6, 8, 7, 8, 0, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.9597720415688904 0.9253918495297806 0.999322951929587\n",
      "Num frames:  (1595, 119)\n",
      "Accuracy:  0.9597720415688904\n",
      "Person:  524\n",
      "Transitions:  [0, 8, 1, 8, 4, 8, 5, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.9024390243902439 0.8503401360544217 0.8290346352247605\n",
      "Num frames:  (1323, 28)\n",
      "Accuracy:  0.9024390243902439\n",
      "Person:  525\n",
      "Transitions:  [7, 8, 0, 8]\n",
      "GT transitions:  1\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.6692229038854806 0.5094768764215315 1.0\n",
      "Num frames:  (1319, 647)\n",
      "Accuracy:  0.6692229038854806\n",
      "Person:  526\n",
      "Transitions:  [0, 8, 4, 8, 5, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.8939241356159785 0.7625607779578606 0.9225490196078432\n",
      "Num frames:  (1234, 237)\n",
      "Accuracy:  0.8939241356159785\n",
      "Person:  527\n",
      "Transitions:  [1, 8, 2, 8]\n",
      "GT transitions:  1\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.5319650861052135 0.5152699731248473 0.5242356450410142\n",
      "Num frames:  (4093, 70)\n",
      "Accuracy:  0.5319650861052135\n",
      "Person:  528\n",
      "Transitions:  [2, 8, 4, 8, 4, 8, 5, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.4050669772859639 0.28139289482940555 0.5427408412483039\n",
      "Num frames:  (2843, 1369)\n",
      "Accuracy:  0.4050669772859639\n",
      "Person:  529\n",
      "Transitions:  [7, 8, 6, 8, 5, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.9627821842586943 0.941234084231146 0.998960498960499\n",
      "Num frames:  (1021, 60)\n",
      "Accuracy:  0.9627821842586943\n",
      "Person:  530\n",
      "Transitions:  [7, 8, 6, 8, 5, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.9101123595505618 0.8634146341463415 1.0\n",
      "Num frames:  (1230, 168)\n",
      "Accuracy:  0.9101123595505618\n",
      "Person:  531\n",
      "Transitions:  [7, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.9967637540453075 0.9967637540453075 1.0\n",
      "Num frames:  (309, 1)\n",
      "Accuracy:  0.9967637540453075\n",
      "Person:  532\n",
      "Transitions:  [5, 8, 4, 8, 1, 8, 0, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.8640533778148457 0.7913822525597269 1.0\n",
      "Num frames:  (2344, 489)\n",
      "Accuracy:  0.8640533778148457\n",
      "Person:  533\n",
      "Transitions:  [5, 8, 6, 8, 0, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.5160493827160494 0.41562313655336913 1.0\n",
      "Num frames:  (3354, 1960)\n",
      "Accuracy:  0.5160493827160494\n",
      "Person:  534\n",
      "Transitions:  [7, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.9961977186311787 0.9961977186311787 1.0\n",
      "Num frames:  (263, 1)\n",
      "Accuracy:  0.9961977186311787\n",
      "Person:  535\n",
      "Transitions:  [5, 8, 6, 8, 7, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.926509186351706 0.884393063583815 1.0\n",
      "Num frames:  (1211, 140)\n",
      "Accuracy:  0.926509186351706\n",
      "Person:  536\n",
      "Transitions:  [7, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.9963636363636363 0.9963636363636363 1.0\n",
      "Num frames:  (275, 1)\n",
      "Accuracy:  0.9963636363636363\n",
      "Person:  537\n",
      "Transitions:  [5, 8, 6, 8, 4, 8, 0, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.5035756853396901 0.3962406015037594 0.9461400359066428\n",
      "Num frames:  (2660, 1606)\n",
      "Accuracy:  0.5035756853396901\n",
      "Person:  538\n",
      "Transitions:  [7, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.9965870307167235 0.9965870307167235 1.0\n",
      "Num frames:  (293, 1)\n",
      "Accuracy:  0.9965870307167235\n",
      "Person:  539\n",
      "Transitions:  [5, 8, 4, 8, 0, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.612967251075091 0.4850352112676056 1.0\n",
      "Num frames:  (2272, 1170)\n",
      "Accuracy:  0.612967251075091\n",
      "Person:  540\n",
      "Transitions:  [0, 8, 1, 8, 4, 8, 5, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.9058333333333334 0.8662056524353577 0.920153305653146\n",
      "Num frames:  (3326, 202)\n",
      "Accuracy:  0.9058333333333334\n",
      "Person:  541\n",
      "Transitions:  [5, 8, 6, 8, 7, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.9659773182121414 0.9836448598130841 0.9579067121729238\n",
      "Num frames:  (856, 14)\n",
      "Accuracy:  0.9659773182121414\n",
      "Person:  542\n",
      "Transitions:  [7, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.996415770609319 0.996415770609319 1.0\n",
      "Num frames:  (279, 1)\n",
      "Accuracy:  0.996415770609319\n",
      "Person:  543\n",
      "Transitions:  [7, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.9967845659163987 0.9967845659163987 1.0\n",
      "Num frames:  (311, 1)\n",
      "Accuracy:  0.9967845659163987\n",
      "Person:  544\n",
      "Transitions:  [1, 8, 0, 8]\n",
      "GT transitions:  1\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.7855775366943204 0.6518134715025907 0.722158438576349\n",
      "Num frames:  (965, 94)\n",
      "Accuracy:  0.7855775366943204\n",
      "Person:  545\n",
      "Transitions:  [0, 8, 1, 8, 4, 8, 6, 8, 5, 8]\n",
      "GT transitions:  4\n",
      "Transitions captured:  0\n",
      "A,P,R:  0.7009916094584286 0.5611814345991561 0.2633663366336634\n",
      "Num frames:  (237, 20)\n",
      "Accuracy:  0.7009916094584286\n",
      "Person:  546\n",
      "Transitions:  [3, 8, 2, 8, 1, 8, 0, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.9098314606741573 0.8709150326797386 0.9334500875656743\n",
      "Num frames:  (2448, 169)\n",
      "Accuracy:  0.9098314606741573\n",
      "Person:  547\n",
      "Transitions:  [5, 8, 6, 8, 7, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.9273772204806687 0.886252045826514 1.0\n",
      "Num frames:  (1222, 139)\n",
      "Accuracy:  0.9273772204806687\n",
      "Person:  548\n",
      "Transitions:  [1, 8, 7, 8]\n",
      "GT transitions:  1\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.7823008849557522 0.6545189504373178 0.6497829232995659\n",
      "Num frames:  (686, 4)\n",
      "Accuracy:  0.7823008849557522\n",
      "Person:  549\n",
      "Transitions:  [7, 8, 0, 8]\n",
      "GT transitions:  1\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.9817001180637545 0.9678089304257529 1.0\n",
      "Num frames:  (963, 31)\n",
      "Accuracy:  0.9817001180637545\n",
      "Person:  550\n",
      "Transitions:  [5, 8, 6, 8, 7, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.95260663507109 0.9253112033195021 1.0\n",
      "Num frames:  (1205, 90)\n",
      "Accuracy:  0.95260663507109\n",
      "Person:  551\n",
      "Transitions:  [0, 8, 1, 8, 4, 8, 5, 8, 5, 8, 6, 8, 7, 8]\n",
      "GT transitions:  6\n",
      "Transitions captured:  4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A,P,R:  0.05428847256161945 0.025586817969842995 0.6844074844074844\n",
      "Num frames:  (64330, 61936)\n",
      "Accuracy:  0.05428847256161945\n",
      "Person:  552\n",
      "Transitions:  [5, 8, 4, 8, 0, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.6300448430493274 0.5103857566765578 1.0\n",
      "Num frames:  (2359, 1155)\n",
      "Accuracy:  0.6300448430493274\n",
      "Person:  553\n",
      "Transitions:  [7, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.9975247524752475 0.9975247524752475 1.0\n",
      "Num frames:  (404, 1)\n",
      "Accuracy:  0.9975247524752475\n",
      "Person:  554\n",
      "Transitions:  [7, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.996078431372549 0.996078431372549 1.0\n",
      "Num frames:  (255, 1)\n",
      "Accuracy:  0.996078431372549\n",
      "Person:  555\n",
      "Transitions:  [0, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.9997949979499795 0.9997949979499795 1.0\n",
      "Num frames:  (4878, 1)\n",
      "Accuracy:  0.9997949979499795\n",
      "Person:  556\n",
      "Transitions:  [7, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.9965986394557823 0.9965986394557823 1.0\n",
      "Num frames:  (294, 1)\n",
      "Accuracy:  0.9965986394557823\n",
      "Person:  557\n",
      "Transitions:  [0, 8, 1, 8, 2, 8, 3, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.8967719049308265 0.8085808580858086 0.8669497523000708\n",
      "Num frames:  (1515, 103)\n",
      "Accuracy:  0.8967719049308265\n",
      "Person:  558\n",
      "Transitions:  [7, 8, 6, 8, 5, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.9636247606892151 0.939873417721519 1.0\n",
      "Num frames:  (948, 57)\n",
      "Accuracy:  0.9636247606892151\n",
      "Person:  559\n",
      "Transitions:  [0, 8, 1, 8, 4, 8, 4, 8, 1, 8, 0, 8]\n",
      "GT transitions:  5\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.18013220712449504 0.09734393959822031 0.4958791208791209\n",
      "Num frames:  (14834, 11927)\n",
      "Accuracy:  0.18013220712449504\n",
      "Person:  560\n",
      "Transitions:  [5, 8, 6, 8, 0, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.5399673735725938 0.3579965850882186 0.6649048625792812\n",
      "Num frames:  (1757, 811)\n",
      "Accuracy:  0.5399673735725938\n",
      "Person:  561\n",
      "Transitions:  [7, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.9961089494163424 0.9961089494163424 1.0\n",
      "Num frames:  (257, 1)\n",
      "Accuracy:  0.9961089494163424\n",
      "Person:  562\n",
      "Transitions:  [1, 8, 0, 8]\n",
      "GT transitions:  1\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.8030199039121483 0.6728538283062645 0.7369758576874206\n",
      "Num frames:  (862, 80)\n",
      "Accuracy:  0.8030199039121483\n",
      "Person:  563\n",
      "Transitions:  [7, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.996969696969697 0.996969696969697 1.0\n",
      "Num frames:  (330, 1)\n",
      "Accuracy:  0.996969696969697\n",
      "Person:  564\n",
      "Transitions:  [7, 8, 6, 8, 5, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.9803122878479293 0.9762443438914027 0.9908151549942594\n",
      "Num frames:  (884, 21)\n",
      "Accuracy:  0.9803122878479293\n",
      "Person:  565\n",
      "Transitions:  [0, 8, 1, 8]\n",
      "GT transitions:  1\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.8609486679662118 0.7240932642487047 0.7423638778220452\n",
      "Num frames:  (772, 20)\n",
      "Accuracy:  0.8609486679662118\n",
      "Person:  566\n",
      "Transitions:  [3, 8, 2, 8, 1, 8, 0, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.8898176291793313 0.8310679611650486 0.8910478834142956\n",
      "Num frames:  (1545, 133)\n",
      "Accuracy:  0.8898176291793313\n",
      "Person:  567\n",
      "Transitions:  [7, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.9963369963369964 0.9963369963369964 1.0\n",
      "Num frames:  (273, 1)\n",
      "Accuracy:  0.9963369963369964\n",
      "Person:  568\n",
      "Transitions:  [7, 8, 6, 8, 5, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.9778239778239778 0.9635294117647059 0.998780487804878\n",
      "Num frames:  (850, 31)\n",
      "Accuracy:  0.9778239778239778\n",
      "Person:  569\n",
      "Transitions:  [0, 8, 1, 8, 2, 8, 3, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.8864005193119118 0.7971014492753623 0.870253164556962\n",
      "Num frames:  (1725, 145)\n",
      "Accuracy:  0.8864005193119118\n",
      "Person:  570\n",
      "Transitions:  [7, 8, 6, 8, 5, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.8936061381074168 0.841100076394194 1.0\n",
      "Num frames:  (1309, 208)\n",
      "Accuracy:  0.8936061381074168\n",
      "Person:  571\n",
      "Transitions:  [3, 8, 2, 8, 1, 8, 0, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.9047275351858535 0.8379373848987108 0.9216745442268738\n",
      "Num frames:  (1629, 148)\n",
      "Accuracy:  0.9047275351858535\n",
      "Person:  572\n",
      "Transitions:  [0, 8, 1, 8, 4, 8, 5, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.9078249336870027 0.8364312267657993 0.8615188257817485\n",
      "Num frames:  (1614, 61)\n",
      "Accuracy:  0.9078249336870027\n",
      "Person:  573\n",
      "Transitions:  [5, 8, 4, 8]\n",
      "GT transitions:  1\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.9393090569561158 0.9100968188105117 0.9984825493171472\n",
      "Num frames:  (723, 64)\n",
      "Accuracy:  0.9393090569561158\n",
      "Person:  574\n",
      "Transitions:  [0, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.9975124378109452 0.9975124378109452 1.0\n",
      "Num frames:  (402, 1)\n",
      "Accuracy:  0.9975124378109452\n",
      "Person:  575\n",
      "Transitions:  [5, 8, 6, 8, 7, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.9753015508328546 0.9590865842055185 1.0\n",
      "Num frames:  (1051, 43)\n",
      "Accuracy:  0.9753015508328546\n",
      "Person:  576\n",
      "Transitions:  [7, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.9980879541108987 0.9980879541108987 1.0\n",
      "Num frames:  (523, 1)\n",
      "Accuracy:  0.9980879541108987\n",
      "Person:  577\n",
      "Transitions:  [1, 8, 0, 8]\n",
      "GT transitions:  1\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.796875 0.6688034188034188 0.7443519619500595\n",
      "Num frames:  (936, 97)\n",
      "Accuracy:  0.796875\n",
      "Person:  578\n",
      "Transitions:  [5, 8, 4, 8, 1, 8, 0, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.8735047846889952 0.8040759610930986 1.0\n",
      "Num frames:  (2159, 423)\n",
      "Accuracy:  0.8735047846889952\n",
      "Person:  579\n",
      "Transitions:  [3, 8, 2, 8, 1, 8, 0, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.8434543790051877 0.7609710550887021 0.8236483072258717\n",
      "Num frames:  (2142, 164)\n",
      "Accuracy:  0.8434543790051877\n",
      "Person:  580\n",
      "Transitions:  [3, 8, 4, 8, 7, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.6455555555555555 0.5033731188375714 0.9867751780264497\n",
      "Num frames:  (1927, 944)\n",
      "Accuracy:  0.6455555555555555\n",
      "Person:  581\n",
      "Transitions:  [0, 8, 1, 8, 4, 8, 6, 8, 5, 8]\n",
      "GT transitions:  4\n",
      "Transitions captured:  4\n",
      "A,P,R:  0.8640776699029126 0.805124960455552 0.9949179046129789\n",
      "Num frames:  (3161, 603)\n",
      "Accuracy:  0.8640776699029126\n",
      "Person:  582\n",
      "Transitions:  [7, 8, 6, 8, 5, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.926948051948052 0.8882450331125827 1.0\n",
      "Num frames:  (1208, 135)\n",
      "Accuracy:  0.926948051948052\n",
      "Person:  583\n",
      "Transitions:  [5, 8, 6, 8, 7, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.9781659388646288 0.9790794979079498 0.9842271293375394\n",
      "Num frames:  (956, 20)\n",
      "Accuracy:  0.9781659388646288\n",
      "Person:  584\n",
      "Transitions:  [4, 8, 5, 8]\n",
      "GT transitions:  1\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.9625550660792952 0.9925925925925926 0.9436619718309859\n",
      "Num frames:  (540, 2)\n",
      "Accuracy:  0.9625550660792952\n",
      "Person:  585\n",
      "Transitions:  [7, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.9956140350877193 0.9956140350877193 1.0\n",
      "Num frames:  (228, 1)\n",
      "Accuracy:  0.9956140350877193\n",
      "Person:  586\n",
      "Transitions:  [0, 8, 1, 8]\n",
      "GT transitions:  1\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.8759367194004996 0.8088531187122736 0.73224043715847\n",
      "Num frames:  (497, 2)\n",
      "Accuracy:  0.8759367194004996\n",
      "Person:  587\n",
      "Transitions:  [7, 8, 0, 8]\n",
      "GT transitions:  1\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.959378733572282 0.9264864864864865 1.0\n",
      "Num frames:  (925, 68)\n",
      "Accuracy:  0.959378733572282\n",
      "Person:  588\n",
      "Transitions:  [7, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.9964912280701754 0.9964912280701754 1.0\n",
      "Num frames:  (285, 1)\n",
      "Accuracy:  0.9964912280701754\n",
      "Person:  589\n",
      "Transitions:  [5, 8, 6, 8, 7, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.9712230215827338 0.9531109107303878 1.0\n",
      "Num frames:  (1109, 52)\n",
      "Accuracy:  0.9712230215827338\n",
      "Person:  590\n",
      "Transitions:  [7, 8, 7, 8, 7, 8, 7, 8, 7, 8, 7, 8, 7, 8, 7, 8, 7, 8, 7, 8, 7, 8, 7, 8, 7, 8, 7, 8, 7, 8, 7, 8, 7, 8, 7, 8, 7, 8, 7, 8, 7, 8, 7, 8, 7, 8, 7, 8, 7, 8, 7, 8, 7, 8, 7, 8]\n",
      "GT transitions:  27\n",
      "Transitions captured:  6\n",
      "A,P,R:  0.25414849125331657 0.20156546016552 0.346874865943117\n",
      "Num frames:  (40116, 17946)\n",
      "Accuracy:  0.25414849125331657\n",
      "Person:  591\n",
      "Transitions:  [1, 8, 2, 8, 3, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.7128368588814836 0.6545834785639596 0.8947117675083373\n",
      "Num frames:  (2869, 770)\n",
      "Accuracy:  0.7128368588814836\n",
      "Person:  592\n",
      "Transitions:  [0, 8, 1, 8, 2, 8, 3, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.893624772313297 0.800275482093664 0.8569321533923304\n",
      "Num frames:  (1452, 98)\n",
      "Accuracy:  0.893624772313297\n",
      "Person:  593\n",
      "Transitions:  [0, 8, 1, 8]\n",
      "GT transitions:  1\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.8693259972489684 0.73 0.7405797101449275\n",
      "Num frames:  (700, 11)\n",
      "Accuracy:  0.8693259972489684\n",
      "Person:  594\n",
      "Transitions:  [0, 8, 1, 8, 2, 8, 3, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.9045161290322581 0.8841519925857275 0.8346456692913385\n",
      "Num frames:  (1079, 33)\n",
      "Accuracy:  0.9045161290322581\n",
      "Person:  595\n",
      "Transitions:  [7, 8, 0, 8]\n",
      "GT transitions:  1\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.8759493670886076 0.8011363636363636 1.0\n",
      "Num frames:  (1232, 245)\n",
      "Accuracy:  0.8759493670886076\n",
      "Person:  596\n",
      "Transitions:  [1, 8, 4, 8, 5, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.8009499136442142 0.7253605769230769 0.7868318122555411\n",
      "Num frames:  (1664, 134)\n",
      "Accuracy:  0.8009499136442142\n",
      "Person:  597\n",
      "Transitions:  [0, 8, 1, 8, 2, 8, 3, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.8852238303601481 0.7927651747394237 0.8689516129032258\n",
      "Num frames:  (1631, 146)\n",
      "Accuracy:  0.8852238303601481\n",
      "Person:  598\n",
      "Transitions:  [7, 8, 6, 8, 5, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.9320175438596491 0.8951817413355875 1.0\n",
      "Num frames:  (1183, 124)\n",
      "Accuracy:  0.9320175438596491\n",
      "Person:  599\n",
      "Transitions:  [0, 8, 1, 8, 4, 8, 5, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.8748145950756452 0.7793650793650794 0.8736654804270463\n",
      "Num frames:  (1890, 209)\n",
      "Accuracy:  0.8748145950756452\n",
      "Person:  600\n",
      "Transitions:  [3, 8, 2, 8, 1, 8, 0, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.9114544084400904 0.8494208494208494 0.9250175192711984\n",
      "Num frames:  (1554, 128)\n",
      "Accuracy:  0.9114544084400904\n",
      "Person:  601\n",
      "Transitions:  [7, 8, 6, 8]\n",
      "GT transitions:  1\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.9430719656283566 0.8958333333333334 0.9930715935334873\n",
      "Num frames:  (480, 50)\n",
      "Accuracy:  0.9430719656283566\n",
      "Person:  602\n",
      "Transitions:  [7, 8, 0, 8]\n",
      "GT transitions:  1\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.9497354497354498 0.9961832061068703 0.9046793760831889\n",
      "Num frames:  (524, 2)\n",
      "Accuracy:  0.9497354497354498\n",
      "Person:  603\n",
      "Transitions:  [7, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.996996996996997 0.996996996996997 1.0\n",
      "Num frames:  (333, 1)\n",
      "Accuracy:  0.996996996996997\n",
      "Person:  604\n",
      "Transitions:  [7, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.9960629921259843 0.9960629921259843 1.0\n",
      "Num frames:  (254, 1)\n",
      "Accuracy:  0.9960629921259843\n",
      "Person:  605\n",
      "Transitions:  [0, 8, 1, 8, 4, 8, 6, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.8767022451232978 0.7394366197183099 0.9916054564533053\n",
      "Num frames:  (1278, 327)\n",
      "Accuracy:  0.8767022451232978\n",
      "Person:  606\n",
      "Transitions:  [2, 8, 1, 8, 0, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.865343347639485 0.7819947043248014 0.8833499501495513\n",
      "Num frames:  (1133, 134)\n",
      "Accuracy:  0.865343347639485\n",
      "Person:  607\n",
      "Transitions:  [7, 8, 1, 8]\n",
      "GT transitions:  1\n",
      "Transitions captured:  0\n",
      "A,P,R:  0.33119315141787053 0.09877433309300648 0.10458015267175573\n",
      "Num frames:  (1387, 77)\n",
      "Accuracy:  0.33119315141787053\n",
      "Person:  608\n",
      "Transitions:  [6, 8, 5, 8]\n",
      "GT transitions:  1\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.9718614718614719 0.9662775616083009 1.0\n",
      "Num frames:  (771, 26)\n",
      "Accuracy:  0.9718614718614719\n",
      "Person:  609\n",
      "Transitions:  [7, 8, 6, 8, 5, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.9872739450770261 0.9848648648648649 0.9945414847161572\n",
      "Num frames:  (925, 14)\n",
      "Accuracy:  0.9872739450770261\n",
      "Person:  610\n",
      "Transitions:  [7, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.9966777408637874 0.9966777408637874 1.0\n",
      "Num frames:  (301, 1)\n",
      "Accuracy:  0.9966777408637874\n",
      "Person:  611\n",
      "Transitions:  [5, 8, 4, 8, 1, 8, 0, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.840260041792431 0.7683462969225566 0.9978041282389108\n",
      "Num frames:  (2957, 683)\n",
      "Accuracy:  0.840260041792431\n",
      "Person:  612\n",
      "Transitions:  [7, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.9932885906040269 0.9932885906040269 1.0\n",
      "Num frames:  (149, 1)\n",
      "Accuracy:  0.9932885906040269\n",
      "Person:  613\n",
      "Transitions:  [0, 8, 1, 8, 2, 8, 3, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.8966542750929368 0.8374455732946299 0.8466617754952311\n",
      "Num frames:  (1378, 69)\n",
      "Accuracy:  0.8966542750929368\n",
      "Person:  614\n",
      "Transitions:  [1, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.4990791896869245 0.4990791896869245 0.5\n",
      "Num frames:  (543, 1)\n",
      "Accuracy:  0.4990791896869245\n",
      "Person:  615\n",
      "Transitions:  [7, 8, 7, 8, 6, 8, 5, 8, 5, 8, 6, 8, 7, 8, 6, 8, 5, 8, 5, 8, 6, 8, 7, 8, 7, 8, 6, 8, 5, 8, 5, 8, 5, 8, 5, 8, 5, 8, 5, 8, 5, 8, 4, 8, 1, 8]\n",
      "GT transitions:  22\n",
      "Transitions captured:  2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A,P,R:  0.0441249441770456 0.023519407001243876 0.08827172256097561\n",
      "Num frames:  (78786, 57916)\n",
      "Accuracy:  0.0441249441770456\n",
      "Person:  616\n",
      "Transitions:  [7, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.9967741935483871 0.9967741935483871 1.0\n",
      "Num frames:  (310, 1)\n",
      "Accuracy:  0.9967741935483871\n",
      "Person:  617\n",
      "Transitions:  [1, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.4991364421416235 0.4991364421416235 0.5\n",
      "Num frames:  (579, 1)\n",
      "Accuracy:  0.4991364421416235\n",
      "Person:  618\n",
      "Transitions:  [5, 8, 4, 8, 1, 8, 1, 8, 1, 8]\n",
      "GT transitions:  4\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.23939131510577755 0.18114011720831114 0.5844434894714224\n",
      "Num frames:  (7508, 5181)\n",
      "Accuracy:  0.23939131510577755\n",
      "Person:  619\n",
      "Transitions:  [7, 8, 6, 8, 5, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.941839762611276 0.9089184060721063 0.9979166666666667\n",
      "Num frames:  (1054, 96)\n",
      "Accuracy:  0.941839762611276\n",
      "Person:  620\n",
      "Transitions:  [1, 8, 4, 8, 2, 8, 3, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.8409986859395532 0.7578385590393596 1.0\n",
      "Num frames:  (1499, 363)\n",
      "Accuracy:  0.8409986859395532\n",
      "Person:  621\n",
      "Transitions:  [7, 8, 6, 8, 5, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.9695898161244696 0.9507620164126612 0.9987684729064039\n",
      "Num frames:  (853, 42)\n",
      "Accuracy:  0.9695898161244696\n",
      "Person:  622\n",
      "Transitions:  [5, 8, 6, 8, 4, 8, 0, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.5146871008939975 0.34497290788681517 0.5662055335968379\n",
      "Num frames:  (1661, 701)\n",
      "Accuracy:  0.5146871008939975\n",
      "Person:  623\n",
      "Transitions:  [7, 8, 4, 8, 2, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.715311004784689 0.6946308724832215 0.5136476426799007\n",
      "Num frames:  (298, 42)\n",
      "Accuracy:  0.715311004784689\n",
      "Person:  624\n",
      "Transitions:  [1, 8, 0, 8]\n",
      "GT transitions:  1\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.7973990417522245 0.6557377049180327 0.7446808510638298\n",
      "Num frames:  (854, 104)\n",
      "Accuracy:  0.7973990417522245\n",
      "Person:  625\n",
      "Transitions:  [7, 8, 6, 8, 5, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.9475235849056604 0.9178966789667896 1.0\n",
      "Num frames:  (1084, 89)\n",
      "Accuracy:  0.9475235849056604\n",
      "Person:  626\n",
      "Transitions:  [0, 8, 1, 8, 4, 8, 5, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.8158772515010007 0.717578259373925 0.8587896253602305\n",
      "Num frames:  (2907, 485)\n",
      "Accuracy:  0.8158772515010007\n",
      "Person:  627\n",
      "Transitions:  [0, 8, 1, 8, 2, 8, 3, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.8933333333333333 0.8082360172095882 0.8790106951871658\n",
      "Num frames:  (1627, 139)\n",
      "Accuracy:  0.8933333333333333\n",
      "Person:  628\n",
      "Transitions:  [3, 8, 2, 8, 1, 8, 0, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.8899486426999267 0.8283627510651248 0.9103678929765886\n",
      "Num frames:  (1643, 166)\n",
      "Accuracy:  0.8899486426999267\n",
      "Person:  629\n",
      "Transitions:  [7, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.9966101694915255 0.9966101694915255 1.0\n",
      "Num frames:  (295, 1)\n",
      "Accuracy:  0.9966101694915255\n",
      "Person:  630\n",
      "Transitions:  [7, 8, 0, 8]\n",
      "GT transitions:  1\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.9418331374853114 0.8962264150943396 1.0\n",
      "Num frames:  (954, 99)\n",
      "Accuracy:  0.9418331374853114\n",
      "Person:  631\n",
      "Transitions:  [7, 8, 0, 8]\n",
      "GT transitions:  1\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.9364485981308411 0.8857782754759238 1.0\n",
      "Num frames:  (893, 102)\n",
      "Accuracy:  0.9364485981308411\n",
      "Person:  632\n",
      "Transitions:  [3, 8, 1, 8, 0, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  0\n",
      "A,P,R:  0.35379771743408106 0.23627906976744187 0.47388059701492535\n",
      "Num frames:  (2150, 1078)\n",
      "Accuracy:  0.35379771743408106\n",
      "Person:  633\n",
      "Transitions:  [7, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.9967213114754099 0.9967213114754099 1.0\n",
      "Num frames:  (305, 1)\n",
      "Accuracy:  0.9967213114754099\n",
      "Person:  634\n",
      "Transitions:  [3, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.997867803837953 0.997867803837953 1.0\n",
      "Num frames:  (469, 1)\n",
      "Accuracy:  0.997867803837953\n",
      "Person:  635\n",
      "Transitions:  [7, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.9964028776978417 0.9964028776978417 1.0\n",
      "Num frames:  (278, 1)\n",
      "Accuracy:  0.9964028776978417\n",
      "Person:  636\n",
      "Transitions:  [7, 8, 6, 8, 5, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.9148494288681205 0.8729666924864447 1.0\n",
      "Num frames:  (1291, 164)\n",
      "Accuracy:  0.9148494288681205\n",
      "Person:  637\n",
      "Transitions:  [0, 8, 1, 8, 4, 8, 5, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.9184644670050761 0.8799089356858281 0.8879954049396899\n",
      "Num frames:  (1757, 62)\n",
      "Accuracy:  0.9184644670050761\n",
      "Person:  638\n",
      "Transitions:  [7, 8, 6, 8, 5, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.908816120906801 0.8656273199703044 1.0\n",
      "Num frames:  (1347, 181)\n",
      "Accuracy:  0.908816120906801\n",
      "Person:  639\n",
      "Transitions:  [7, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.9961538461538462 0.9961538461538462 1.0\n",
      "Num frames:  (260, 1)\n",
      "Accuracy:  0.9961538461538462\n",
      "Person:  640\n",
      "Transitions:  [7, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.9965277777777778 0.9965277777777778 1.0\n",
      "Num frames:  (288, 1)\n",
      "Accuracy:  0.9965277777777778\n",
      "Person:  641\n",
      "Transitions:  [7, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.9954337899543378 0.9954337899543378 1.0\n",
      "Num frames:  (219, 1)\n",
      "Accuracy:  0.9954337899543378\n",
      "Person:  642\n",
      "Transitions:  [7, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.9963503649635036 0.9963503649635036 1.0\n",
      "Num frames:  (274, 1)\n",
      "Accuracy:  0.9963503649635036\n",
      "Person:  643\n",
      "Transitions:  [7, 8, 6, 8, 5, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.9710144927536232 0.9531568228105907 1.0\n",
      "Num frames:  (982, 46)\n",
      "Accuracy:  0.9710144927536232\n",
      "Person:  644\n",
      "Transitions:  [3, 8, 2, 8, 4, 8, 5, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.8964194373401535 0.8589385474860335 0.9798194370685077\n",
      "Num frames:  (2148, 286)\n",
      "Accuracy:  0.8964194373401535\n",
      "Person:  645\n",
      "Transitions:  [3, 8, 2, 8, 4, 8, 6, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.8578796561604585 0.8192419825072886 0.9842381786339754\n",
      "Num frames:  (1372, 230)\n",
      "Accuracy:  0.8578796561604585\n",
      "Person:  646\n",
      "Transitions:  [7, 8, 6, 8, 5, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.9709371293001187 0.9576427255985267 0.99712368168744\n",
      "Num frames:  (1086, 46)\n",
      "Accuracy:  0.9709371293001187\n",
      "Person:  647\n",
      "Transitions:  [7, 8, 6, 8, 5, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.9539028887523049 0.9261811023622047 1.0\n",
      "Num frames:  (1016, 75)\n",
      "Accuracy:  0.9539028887523049\n",
      "Person:  648\n",
      "Transitions:  [0, 8, 1, 8, 4, 8, 5, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.9664600802041561 0.9327586206896552 0.975653742110009\n",
      "Num frames:  (1160, 65)\n",
      "Accuracy:  0.9664600802041561\n",
      "Person:  649\n",
      "Transitions:  [5, 8, 4, 8, 0, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.6237856932587578 0.5191873589164786 1.0\n",
      "Num frames:  (2658, 1278)\n",
      "Accuracy:  0.6237856932587578\n",
      "Person:  650\n",
      "Transitions:  [7, 8, 0, 8]\n",
      "GT transitions:  1\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.3551424432641236 0.23379231210556511 1.0\n",
      "Num frames:  (3486, 2671)\n",
      "Accuracy:  0.3551424432641236\n",
      "Person:  651\n",
      "Transitions:  [0, 8, 1, 8]\n",
      "GT transitions:  1\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.8381430363864492 0.6911942098914354 0.7004889975550123\n",
      "Num frames:  (829, 13)\n",
      "Accuracy:  0.8381430363864492\n",
      "Person:  652\n",
      "Transitions:  [1, 8, 4, 8, 2, 8, 3, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.9468017732742242 0.8968058968058968 1.0\n",
      "Num frames:  (814, 84)\n",
      "Accuracy:  0.9468017732742242\n",
      "Person:  653\n",
      "Transitions:  [5, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.9978021978021978 0.9978021978021978 1.0\n",
      "Num frames:  (455, 1)\n",
      "Accuracy:  0.9978021978021978\n",
      "Person:  654\n",
      "Transitions:  [7, 8, 0, 8]\n",
      "GT transitions:  1\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.9517490952955368 0.9128540305010894 1.0\n",
      "Num frames:  (918, 80)\n",
      "Accuracy:  0.9517490952955368\n",
      "Person:  655\n",
      "Transitions:  [7, 8, 6, 8, 5, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.9281045751633987 0.8905472636815921 1.0\n",
      "Num frames:  (1206, 132)\n",
      "Accuracy:  0.9281045751633987\n",
      "Person:  656\n",
      "Transitions:  [7, 8, 1, 8, 4, 8, 2, 8, 3, 8]\n",
      "GT transitions:  4\n",
      "Transitions captured:  0\n",
      "A,P,R:  0.2801670146137787 0.009140767824497258 0.016483516483516484\n",
      "Num frames:  (1641, 829)\n",
      "Accuracy:  0.2801670146137787\n",
      "Person:  657\n",
      "Transitions:  [0, 8, 1, 8, 2, 8, 3, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.9051210797935689 0.856120826709062 0.8447058823529412\n",
      "Num frames:  (1258, 41)\n",
      "Accuracy:  0.9051210797935689\n",
      "Person:  658\n",
      "Transitions:  [3, 8, 2, 8, 1, 8, 0, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.8841463414634146 0.8435672514619883 0.8535502958579881\n",
      "Num frames:  (1368, 87)\n",
      "Accuracy:  0.8841463414634146\n",
      "Person:  659\n",
      "Transitions:  [3, 8, 2, 8, 1, 8, 0, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.924282982791587 0.8694203864090606 0.9463379260333575\n",
      "Num frames:  (1501, 124)\n",
      "Accuracy:  0.924282982791587\n",
      "Person:  660\n",
      "Transitions:  [5, 8, 4, 8, 1, 8, 0, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.8379392698737632 0.7528916929547844 0.9585006693440429\n",
      "Num frames:  (1902, 413)\n",
      "Accuracy:  0.8379392698737632\n",
      "Person:  661\n",
      "Transitions:  [5, 8, 6, 8, 7, 8, 0, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.8064619321817018 0.6651835372636262 0.9974979149291076\n",
      "Num frames:  (1798, 602)\n",
      "Accuracy:  0.8064619321817018\n",
      "Person:  662\n",
      "Transitions:  [4, 8, 1, 8, 0, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.9288558075125498 0.9154320987654321 1.0\n",
      "Num frames:  (4860, 411)\n",
      "Accuracy:  0.9288558075125498\n",
      "Person:  663\n",
      "Transitions:  [2, 8, 4, 8, 1, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.7673772011121409 0.6684280052840158 0.9638095238095238\n",
      "Num frames:  (757, 232)\n",
      "Accuracy:  0.7673772011121409\n",
      "Person:  664\n",
      "Transitions:  [7, 8, 6, 8]\n",
      "GT transitions:  1\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.9234972677595629 0.8781094527363185 1.0\n",
      "Num frames:  (804, 98)\n",
      "Accuracy:  0.9234972677595629\n",
      "Person:  665\n",
      "Transitions:  [5, 8, 4, 8, 1, 8, 0, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.9302665206279664 0.8903107861060329 0.9925271739130435\n",
      "Num frames:  (1641, 180)\n",
      "Accuracy:  0.9302665206279664\n",
      "Person:  666\n",
      "Transitions:  [0, 8, 1, 8, 4, 8, 5, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.8877182420228777 0.8 0.8745603751465416\n",
      "Num frames:  (1865, 159)\n",
      "Accuracy:  0.8877182420228777\n",
      "Person:  667\n",
      "Transitions:  [7, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.9979633401221996 0.9979633401221996 1.0\n",
      "Num frames:  (491, 1)\n",
      "Accuracy:  0.9979633401221996\n",
      "Person:  668\n",
      "Transitions:  [7, 8, 6, 8, 5, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.9035222052067381 0.8575734740015072 1.0\n",
      "Num frames:  (1327, 189)\n",
      "Accuracy:  0.9035222052067381\n",
      "Person:  669\n",
      "Transitions:  [7, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.9962406015037594 0.9962406015037594 1.0\n",
      "Num frames:  (266, 1)\n",
      "Accuracy:  0.9962406015037594\n",
      "Person:  670\n",
      "Transitions:  [7, 8, 6, 8, 5, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.9744711889132021 0.9633251833740831 0.9936948297604036\n",
      "Num frames:  (818, 30)\n",
      "Accuracy:  0.9744711889132021\n",
      "Person:  671\n",
      "Transitions:  [0, 8, 1, 8, 2, 8, 3, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.9001044204664114 0.8249522597071929 0.8792401628222524\n",
      "Num frames:  (1571, 109)\n",
      "Accuracy:  0.9001044204664114\n",
      "Person:  672\n",
      "Transitions:  [1, 8, 0, 8]\n",
      "GT transitions:  1\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.7549857549857549 0.6089743589743589 0.7142857142857143\n",
      "Num frames:  (1092, 164)\n",
      "Accuracy:  0.7549857549857549\n",
      "Person:  673\n",
      "Transitions:  [1, 8, 2, 8, 3, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.8250950570342205 0.7320197044334975 0.8690058479532163\n",
      "Num frames:  (1015, 164)\n",
      "Accuracy:  0.8250950570342205\n",
      "Person:  674\n",
      "Transitions:  [2, 8, 1, 8]\n",
      "GT transitions:  1\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.824607329842932 0.7744107744107744 0.8141592920353983\n",
      "Num frames:  (594, 29)\n",
      "Accuracy:  0.824607329842932\n",
      "Person:  675\n",
      "Transitions:  [5, 8, 6, 8, 7, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.9819136522753792 0.9699321047526673 1.0\n",
      "Num frames:  (1031, 31)\n",
      "Accuracy:  0.9819136522753792\n",
      "Person:  676\n",
      "Transitions:  [0, 8, 1, 8, 2, 8, 4, 8, 5, 8]\n",
      "GT transitions:  4\n",
      "Transitions captured:  4\n",
      "A,P,R:  0.6714886901630721 0.5910138248847926 0.6014067995310668\n",
      "Num frames:  (6076, 118)\n",
      "Accuracy:  0.6714886901630721\n",
      "Person:  677\n",
      "Transitions:  [0, 8, 1, 8, 4, 8, 4, 8, 5, 8]\n",
      "GT transitions:  4\n",
      "Transitions captured:  2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A,P,R:  0.11152794060179758 0.053424942744118256 0.39367904265111997\n",
      "Num frames:  (24015, 20760)\n",
      "Accuracy:  0.11152794060179758\n",
      "Person:  678\n",
      "Transitions:  [5, 8, 6, 8, 7, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.9802784222737819 0.9686907020872866 0.9990215264187867\n",
      "Num frames:  (1054, 33)\n",
      "Accuracy:  0.9802784222737819\n",
      "Person:  679\n",
      "Transitions:  [0, 8, 1, 8, 2, 8, 3, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.8955091151622944 0.8963474827245804 0.8136200716845878\n",
      "Num frames:  (1013, 27)\n",
      "Accuracy:  0.8955091151622944\n",
      "Person:  680\n",
      "Transitions:  [7, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.9966555183946488 0.9966555183946488 1.0\n",
      "Num frames:  (299, 1)\n",
      "Accuracy:  0.9966555183946488\n",
      "Person:  681\n",
      "Transitions:  [2, 8, 1, 8, 0, 8, 0, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.6658756525866161 0.6641883519206939 0.4986046511627907\n",
      "Num frames:  (807, 165)\n",
      "Accuracy:  0.6658756525866161\n",
      "Person:  682\n",
      "Transitions:  [1, 8, 0, 8]\n",
      "GT transitions:  1\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.7939949958298582 0.6422018348623854 0.6851549755301795\n",
      "Num frames:  (654, 54)\n",
      "Accuracy:  0.7939949958298582\n",
      "Person:  683\n",
      "Transitions:  [7, 8, 0, 8]\n",
      "GT transitions:  1\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.9446834665027658 0.8994350282485876 0.998745294855709\n",
      "Num frames:  (885, 89)\n",
      "Accuracy:  0.9446834665027658\n",
      "Person:  684\n",
      "Transitions:  [0, 8, 1, 8, 2, 8, 3, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.8781208935611038 0.7844979448032883 0.854766474728087\n",
      "Num frames:  (1703, 144)\n",
      "Accuracy:  0.8781208935611038\n",
      "Person:  685\n",
      "Transitions:  [7, 8, 1, 8]\n",
      "GT transitions:  1\n",
      "Transitions captured:  0\n",
      "A,P,R:  0.43355704697986575 0.16781836130306022 0.19473081328751432\n",
      "Num frames:  (1013, 141)\n",
      "Accuracy:  0.43355704697986575\n",
      "Person:  686\n",
      "Transitions:  [0, 8, 1, 8, 2, 8, 3, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.8532369578881207 0.746586564718733 0.8707006369426752\n",
      "Num frames:  (1831, 264)\n",
      "Accuracy:  0.8532369578881207\n",
      "Person:  687\n",
      "Transitions:  [7, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.9967845659163987 0.9967845659163987 1.0\n",
      "Num frames:  (311, 1)\n",
      "Accuracy:  0.9967845659163987\n",
      "Person:  688\n",
      "Transitions:  [3, 8, 2, 8, 1, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.883495145631068 0.830423940149626 0.9073569482288828\n",
      "Num frames:  (1203, 102)\n",
      "Accuracy:  0.883495145631068\n",
      "Person:  689\n",
      "Transitions:  [5, 8, 6, 8, 7, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.9014778325123153 0.8502994011976048 1.0\n",
      "Num frames:  (1336, 200)\n",
      "Accuracy:  0.9014778325123153\n",
      "Person:  690\n",
      "Transitions:  [7, 8, 6, 8, 5, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.9816272965879265 0.9728260869565217 0.9966592427616926\n",
      "Num frames:  (920, 25)\n",
      "Accuracy:  0.9816272965879265\n",
      "Person:  691\n",
      "Transitions:  [0, 8, 1, 8, 2, 8, 3, 8, 3, 8]\n",
      "GT transitions:  4\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.7408403361344538 0.6841686555290374 0.5779569892473119\n",
      "Num frames:  (1257, 143)\n",
      "Accuracy:  0.7408403361344538\n",
      "Person:  692\n",
      "Transitions:  [7, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.996078431372549 0.996078431372549 1.0\n",
      "Num frames:  (255, 1)\n",
      "Accuracy:  0.996078431372549\n",
      "Person:  693\n",
      "Transitions:  [7, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.9971014492753624 0.9971014492753624 1.0\n",
      "Num frames:  (345, 1)\n",
      "Accuracy:  0.9971014492753624\n",
      "Person:  694\n",
      "Transitions:  [0, 8, 1, 8]\n",
      "GT transitions:  1\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.8161648177496038 0.6611165523996082 0.7491675915649278\n",
      "Num frames:  (1021, 122)\n",
      "Accuracy:  0.8161648177496038\n",
      "Person:  695\n",
      "Transitions:  [3, 8, 2, 8, 1, 8, 0, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.8338983050847457 0.7482876712328768 0.9248677248677248\n",
      "Num frames:  (2336, 446)\n",
      "Accuracy:  0.8338983050847457\n",
      "Person:  696\n",
      "Transitions:  [7, 8, 0, 8]\n",
      "GT transitions:  1\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.9023121387283237 0.8279022403258656 1.0\n",
      "Num frames:  (982, 169)\n",
      "Accuracy:  0.9023121387283237\n",
      "Person:  697\n",
      "Transitions:  [0, 8, 1, 8, 2, 8, 3, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.8964017398181099 0.8541498791297341 0.8346456692913385\n",
      "Num frames:  (1241, 52)\n",
      "Accuracy:  0.8964017398181099\n",
      "Person:  698\n",
      "Transitions:  [5, 8, 4, 8, 1, 8, 0, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.9072483682583304 0.8513966480446927 0.9973821989528796\n",
      "Num frames:  (1790, 266)\n",
      "Accuracy:  0.9072483682583304\n",
      "Person:  699\n",
      "Transitions:  [7, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.996969696969697 0.996969696969697 1.0\n",
      "Num frames:  (330, 1)\n",
      "Accuracy:  0.996969696969697\n",
      "Person:  700\n",
      "Transitions:  [7, 8, 0, 8]\n",
      "GT transitions:  1\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.9706390328151986 0.9962546816479401 0.9432624113475178\n",
      "Num frames:  (534, 2)\n",
      "Accuracy:  0.9706390328151986\n",
      "Person:  701\n",
      "Transitions:  [7, 8, 0, 8]\n",
      "GT transitions:  1\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.9635820895522388 0.9351063829787234 1.0\n",
      "Num frames:  (940, 61)\n",
      "Accuracy:  0.9635820895522388\n",
      "Person:  702\n",
      "Transitions:  [7, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.9971181556195965 0.9971181556195965 1.0\n",
      "Num frames:  (347, 1)\n",
      "Accuracy:  0.9971181556195965\n",
      "Person:  703\n",
      "Transitions:  [7, 8, 6, 8, 5, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.9743944636678201 0.9655581947743468 0.9902557856272838\n",
      "Num frames:  (842, 29)\n",
      "Accuracy:  0.9743944636678201\n",
      "Person:  704\n",
      "Transitions:  [7, 8, 0, 8]\n",
      "GT transitions:  1\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.921455938697318 0.8532219570405728 1.0\n",
      "Num frames:  (838, 123)\n",
      "Accuracy:  0.921455938697318\n",
      "Person:  705\n",
      "Transitions:  [7, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.9965986394557823 0.9965986394557823 1.0\n",
      "Num frames:  (294, 1)\n",
      "Accuracy:  0.9965986394557823\n",
      "Person:  706\n",
      "Transitions:  [7, 8, 6, 8, 5, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.8753514526710403 0.8231382978723404 1.0\n",
      "Num frames:  (1504, 266)\n",
      "Accuracy:  0.8753514526710403\n",
      "Person:  707\n",
      "Transitions:  [5, 8, 4, 8, 1, 8, 0, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.7296008034145117 0.6154121863799283 0.9976757699012202\n",
      "Num frames:  (2790, 1073)\n",
      "Accuracy:  0.7296008034145117\n",
      "Person:  708\n",
      "Transitions:  [0, 8, 1, 8, 4, 8, 6, 8, 5, 8]\n",
      "GT transitions:  4\n",
      "Transitions captured:  4\n",
      "A,P,R:  0.8698394495412844 0.760926803580832 0.9979281767955801\n",
      "Num frames:  (1899, 451)\n",
      "Accuracy:  0.8698394495412844\n",
      "Person:  709\n",
      "Transitions:  [0, 8, 1, 8, 4, 8, 5, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.9150511103278111 0.8464592984778293 0.8583892617449664\n",
      "Num frames:  (1511, 30)\n",
      "Accuracy:  0.9150511103278111\n",
      "Person:  710\n",
      "Transitions:  [7, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.996415770609319 0.996415770609319 1.0\n",
      "Num frames:  (279, 1)\n",
      "Accuracy:  0.996415770609319\n",
      "Person:  711\n",
      "Transitions:  [7, 8, 6, 8, 5, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.9501758499413834 0.9216589861751152 1.0\n",
      "Num frames:  (1085, 85)\n",
      "Accuracy:  0.9501758499413834\n",
      "Person:  712\n",
      "Transitions:  [5, 8, 4, 8, 1, 8, 0, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.9303590859630033 0.8872727272727273 0.9959183673469387\n",
      "Num frames:  (1650, 186)\n",
      "Accuracy:  0.9303590859630033\n",
      "Person:  713\n",
      "Transitions:  [5, 8, 6, 8, 7, 8, 0, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.9315696649029982 0.8519938650306749 0.9991007194244604\n",
      "Num frames:  (1304, 193)\n",
      "Accuracy:  0.9315696649029982\n",
      "Person:  714\n",
      "Transitions:  [7, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.9971910112359551 0.9971910112359551 1.0\n",
      "Num frames:  (356, 1)\n",
      "Accuracy:  0.9971910112359551\n",
      "Person:  715\n",
      "Transitions:  [7, 8, 0, 8]\n",
      "GT transitions:  1\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.9969947407963937 0.9942363112391931 1.0\n",
      "Num frames:  (694, 4)\n",
      "Accuracy:  0.9969947407963937\n",
      "Person:  716\n",
      "Transitions:  [7, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.9970588235294118 0.9970588235294118 1.0\n",
      "Num frames:  (340, 1)\n",
      "Accuracy:  0.9970588235294118\n",
      "Person:  717\n",
      "Transitions:  [1, 8, 7, 8]\n",
      "GT transitions:  1\n",
      "Transitions captured:  0\n",
      "A,P,R:  0.3968253968253968 0.28156650911546255 0.4199395770392749\n",
      "Num frames:  (1481, 488)\n",
      "Accuracy:  0.3968253968253968\n",
      "Person:  718\n",
      "Transitions:  [0, 8, 1, 8, 2, 8, 3, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.8789756299049979 0.8763345195729537 0.7982171799027553\n",
      "Num frames:  (1124, 44)\n",
      "Accuracy:  0.8789756299049979\n",
      "Person:  719\n",
      "Transitions:  [7, 8, 6, 8, 5, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.9687045123726347 0.9798234552332913 0.9664179104477612\n",
      "Num frames:  (793, 16)\n",
      "Accuracy:  0.9687045123726347\n",
      "Person:  720\n",
      "Transitions:  [3, 8, 2, 8, 1, 8, 0, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.8806494076349276 0.8112118713932399 0.8052373158756138\n",
      "Num frames:  (1213, 34)\n",
      "Accuracy:  0.8806494076349276\n",
      "Person:  721\n",
      "Transitions:  [0, 8, 1, 8]\n",
      "GT transitions:  1\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.8754660700969426 0.7461059190031153 0.7437888198757764\n",
      "Num frames:  (642, 2)\n",
      "Accuracy:  0.8754660700969426\n",
      "Person:  722\n",
      "Transitions:  [7, 8, 6, 8, 5, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.939377085650723 0.9068376068376068 1.0\n",
      "Num frames:  (1170, 109)\n",
      "Accuracy:  0.939377085650723\n",
      "Person:  723\n",
      "Transitions:  [7, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.997275204359673 0.997275204359673 1.0\n",
      "Num frames:  (367, 1)\n",
      "Accuracy:  0.997275204359673\n",
      "Person:  724\n",
      "Transitions:  [6, 8, 7, 8]\n",
      "GT transitions:  1\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.8741935483870967 0.7914438502673797 1.0\n",
      "Num frames:  (748, 156)\n",
      "Accuracy:  0.8741935483870967\n",
      "Person:  725\n",
      "Transitions:  [0, 8, 1, 8, 2, 8, 3, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.8870094722598105 0.7929324240545568 0.8630229419703104\n",
      "Num frames:  (1613, 131)\n",
      "Accuracy:  0.8870094722598105\n",
      "Person:  726\n",
      "Transitions:  [7, 8, 6, 8, 5, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.967990515708358 0.9519852262234534 0.9980638915779284\n",
      "Num frames:  (1083, 52)\n",
      "Accuracy:  0.967990515708358\n",
      "Person:  727\n",
      "Transitions:  [7, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.9968152866242038 0.9968152866242038 1.0\n",
      "Num frames:  (314, 1)\n",
      "Accuracy:  0.9968152866242038\n",
      "Person:  728\n",
      "Transitions:  [5, 8, 6, 8, 7, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.933933933933934 0.8987730061349694 1.0\n",
      "Num frames:  (1304, 132)\n",
      "Accuracy:  0.933933933933934\n",
      "Person:  729\n",
      "Transitions:  [2, 8, 1, 8, 0, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.8077079107505071 0.7057728119180633 0.8773148148148148\n",
      "Num frames:  (1611, 315)\n",
      "Accuracy:  0.8077079107505071\n",
      "Person:  730\n",
      "Transitions:  [5, 8, 4, 8, 1, 8, 1, 8, 2, 8, 4, 8, 5, 8]\n",
      "GT transitions:  6\n",
      "Transitions captured:  5\n",
      "A,P,R:  0.354636726762388 0.3113299925119521 0.9367417677642981\n",
      "Num frames:  (17361, 11591)\n",
      "Accuracy:  0.354636726762388\n",
      "Person:  731\n",
      "Transitions:  [3, 8, 2, 8, 1, 8, 0, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.9092278719397363 0.851228978007762 0.9313517338995047\n",
      "Num frames:  (1546, 144)\n",
      "Accuracy:  0.9092278719397363\n",
      "Person:  732\n",
      "Transitions:  [7, 8, 6, 8, 5, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.9295054007959067 0.8892857142857142 1.0\n",
      "Num frames:  (1120, 124)\n",
      "Accuracy:  0.9295054007959067\n",
      "Person:  733\n",
      "Transitions:  [7, 8, 6, 8, 5, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.9327731092436975 0.897172236503856 1.0\n",
      "Num frames:  (1167, 120)\n",
      "Accuracy:  0.9327731092436975\n",
      "Person:  734\n",
      "Transitions:  [7, 8, 6, 8, 5, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.9167974882260597 0.9587345254470426 0.9016817593790427\n",
      "Num frames:  (727, 30)\n",
      "Accuracy:  0.9167974882260597\n",
      "Person:  735\n",
      "Transitions:  [3, 8, 2, 8, 4, 8, 1, 8, 0, 8]\n",
      "GT transitions:  4\n",
      "Transitions captured:  4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A,P,R:  0.6249248346361996 0.5223051885889336 0.9708185053380783\n",
      "Num frames:  (5223, 2413)\n",
      "Accuracy:  0.6249248346361996\n",
      "Person:  736\n",
      "Transitions:  [0, 8, 1, 8, 2, 8, 3, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.8892857142857142 0.7990654205607477 0.8586800573888091\n",
      "Num frames:  (1498, 113)\n",
      "Accuracy:  0.8892857142857142\n",
      "Person:  737\n",
      "Transitions:  [7, 8, 6, 8, 5, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.9536384976525821 0.9268518518518518 1.0\n",
      "Num frames:  (1080, 79)\n",
      "Accuracy:  0.9536384976525821\n",
      "Person:  738\n",
      "Transitions:  [0, 8, 1, 8, 2, 8, 3, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.8235294117647058 0.7002022244691608 0.8204976303317536\n",
      "Num frames:  (1978, 294)\n",
      "Accuracy:  0.8235294117647058\n",
      "Person:  739\n",
      "Transitions:  [0, 8, 1, 8]\n",
      "GT transitions:  1\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.8800813008130082 0.7531380753138075 0.7670454545454546\n",
      "Num frames:  (717, 13)\n",
      "Accuracy:  0.8800813008130082\n",
      "Person:  740\n",
      "Transitions:  [1, 8, 4, 8, 5, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.7858032378580324 0.7103718199608611 0.7969264544456641\n",
      "Num frames:  (1022, 159)\n",
      "Accuracy:  0.7858032378580324\n",
      "Person:  741\n",
      "Transitions:  [5, 8, 6, 8, 7, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.9696029776674938 0.9485294117647058 1.0\n",
      "Num frames:  (952, 49)\n",
      "Accuracy:  0.9696029776674938\n",
      "Person:  742\n",
      "Transitions:  [0, 8, 1, 8, 4, 8, 5, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.877720207253886 0.7721202003338898 0.8455210237659964\n",
      "Num frames:  (1198, 185)\n",
      "Accuracy:  0.877720207253886\n",
      "Person:  743\n",
      "Transitions:  [7, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.9964664310954063 0.9964664310954063 1.0\n",
      "Num frames:  (283, 1)\n",
      "Accuracy:  0.9964664310954063\n",
      "Person:  744\n",
      "Transitions:  [5, 8, 6, 8, 7, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.9255770136599152 0.8894331700489853 1.0\n",
      "Num frames:  (1429, 158)\n",
      "Accuracy:  0.9255770136599152\n",
      "Person:  745\n",
      "Transitions:  [7, 8, 0, 8]\n",
      "GT transitions:  1\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.8253658536585365 0.7096512570965126 1.0\n",
      "Num frames:  (1233, 358)\n",
      "Accuracy:  0.8253658536585365\n",
      "Person:  746\n",
      "Transitions:  [0, 8, 1, 8, 4, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.684224049331963 0.4931958762886598 0.8482269503546099\n",
      "Num frames:  (2425, 1015)\n",
      "Accuracy:  0.684224049331963\n",
      "Person:  747\n",
      "Transitions:  [3, 8, 2, 8, 1, 8, 0, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.8840970350404312 0.8278481012658228 0.8034398034398035\n",
      "Num frames:  (1185, 18)\n",
      "Accuracy:  0.8840970350404312\n",
      "Person:  748\n",
      "Transitions:  [7, 8, 6, 8, 5, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.8974093264248705 0.847457627118644 1.0\n",
      "Num frames:  (1298, 198)\n",
      "Accuracy:  0.8974093264248705\n",
      "Person:  749\n",
      "Transitions:  [3, 8, 2, 8, 1, 8, 0, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.7866836301950806 0.7068764568764568 0.9447040498442367\n",
      "Num frames:  (3432, 864)\n",
      "Accuracy:  0.7866836301950806\n",
      "Person:  750\n",
      "Transitions:  [7, 8, 6, 8, 5, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.949658172778123 0.9212362911266201 0.9978401727861771\n",
      "Num frames:  (1003, 79)\n",
      "Accuracy:  0.949658172778123\n",
      "Person:  751\n",
      "Transitions:  [0, 8, 1, 8]\n",
      "GT transitions:  1\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.8340832395950506 0.68994708994709 0.7581395348837209\n",
      "Num frames:  (945, 87)\n",
      "Accuracy:  0.8340832395950506\n",
      "Person:  752\n",
      "Transitions:  [5, 8, 6, 8, 7, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.9485446985446986 0.9195121951219513 1.0\n",
      "Num frames:  (1230, 99)\n",
      "Accuracy:  0.9485446985446986\n",
      "Person:  753\n",
      "Transitions:  [1, 8, 0, 8]\n",
      "GT transitions:  1\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.801510989010989 0.6623831775700935 0.7431192660550459\n",
      "Num frames:  (856, 93)\n",
      "Accuracy:  0.801510989010989\n",
      "Person:  754\n",
      "Transitions:  [5, 8, 6, 8, 4, 8, 1, 8, 0, 8]\n",
      "GT transitions:  4\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.5459770114942529 0.4400164338537387 0.8040540540540541\n",
      "Num frames:  (2434, 1161)\n",
      "Accuracy:  0.5459770114942529\n",
      "Person:  755\n",
      "Transitions:  [7, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.9967948717948718 0.9967948717948718 1.0\n",
      "Num frames:  (312, 1)\n",
      "Accuracy:  0.9967948717948718\n",
      "Person:  756\n",
      "Transitions:  [7, 8, 6, 8, 5, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.9484475688342121 0.9180633147113594 1.0\n",
      "Num frames:  (1074, 88)\n",
      "Accuracy:  0.9484475688342121\n",
      "Person:  757\n",
      "Transitions:  [7, 8, 0, 8]\n",
      "GT transitions:  1\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.9738941261783901 0.9500713266761769 0.9985007496251874\n",
      "Num frames:  (701, 35)\n",
      "Accuracy:  0.9738941261783901\n",
      "Person:  758\n",
      "Transitions:  [7, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.9973045822102425 0.9973045822102425 1.0\n",
      "Num frames:  (371, 1)\n",
      "Accuracy:  0.9973045822102425\n",
      "Person:  759\n",
      "Transitions:  [3, 8, 2, 8, 1, 8, 0, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.9108645753634277 0.8577049180327869 0.9211267605633803\n",
      "Num frames:  (1525, 121)\n",
      "Accuracy:  0.9108645753634277\n",
      "Person:  760\n",
      "Transitions:  [5, 8, 6, 8, 7, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.9553472987872106 0.9276139410187667 1.0\n",
      "Num frames:  (1119, 81)\n",
      "Accuracy:  0.9553472987872106\n",
      "Person:  761\n",
      "Transitions:  [3, 8, 2, 8, 1, 8, 0, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.9032612678636863 0.8372379778051788 0.9282296650717703\n",
      "Num frames:  (1622, 159)\n",
      "Accuracy:  0.9032612678636863\n",
      "Person:  762\n",
      "Transitions:  [0, 8, 1, 8, 2, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.8569314257523434 0.7336405529953917 0.804040404040404\n",
      "Num frames:  (1085, 96)\n",
      "Accuracy:  0.8569314257523434\n",
      "Person:  763\n",
      "Transitions:  [7, 8, 0, 8]\n",
      "GT transitions:  1\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.9797852179406191 0.9625730994152046 1.0\n",
      "Num frames:  (855, 32)\n",
      "Accuracy:  0.9797852179406191\n",
      "Person:  764\n",
      "Transitions:  [4, 8, 5, 8]\n",
      "GT transitions:  1\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.9341894060995185 0.9010856453558505 0.996\n",
      "Num frames:  (829, 79)\n",
      "Accuracy:  0.9341894060995185\n",
      "Person:  765\n",
      "Transitions:  [0, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.9973404255319149 0.9973404255319149 1.0\n",
      "Num frames:  (376, 1)\n",
      "Accuracy:  0.9973404255319149\n",
      "Person:  766\n",
      "Transitions:  [1, 8, 4, 8, 2, 8, 3, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.9399759903961584 0.8877665544332211 0.9974779319041615\n",
      "Num frames:  (891, 98)\n",
      "Accuracy:  0.9399759903961584\n",
      "Person:  767\n",
      "Transitions:  [7, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.9931972789115646 0.9931972789115646 1.0\n",
      "Num frames:  (147, 1)\n",
      "Accuracy:  0.9931972789115646\n",
      "Person:  768\n",
      "Transitions:  [7, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.9967741935483871 0.9967741935483871 1.0\n",
      "Num frames:  (310, 1)\n",
      "Accuracy:  0.9967741935483871\n",
      "Person:  769\n",
      "Transitions:  [0, 8, 1, 8, 4, 8, 5, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.9108348134991119 0.8534310459693538 0.8517287234042553\n",
      "Num frames:  (1501, 28)\n",
      "Accuracy:  0.9108348134991119\n",
      "Person:  770\n",
      "Transitions:  [5, 8, 6, 8, 7, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.9641411220358589 0.9448669201520913 0.9959919839679359\n",
      "Num frames:  (1052, 58)\n",
      "Accuracy:  0.9641411220358589\n",
      "Person:  771\n",
      "Transitions:  [5, 8, 4, 8, 1, 8, 0, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.8678912045213706 0.7899884925201381 0.9220953660174613\n",
      "Num frames:  (1738, 258)\n",
      "Accuracy:  0.8678912045213706\n",
      "Person:  772\n",
      "Transitions:  [5, 8, 4, 8, 1, 8, 0, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.9033290653008963 0.851431391905232 0.9994206257242179\n",
      "Num frames:  (2026, 301)\n",
      "Accuracy:  0.9033290653008963\n",
      "Person:  773\n",
      "Transitions:  [5, 8, 4, 8, 1, 8, 0, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.8688642063776424 0.7927612375948628 0.9410949410949411\n",
      "Num frames:  (1713, 281)\n",
      "Accuracy:  0.8688642063776424\n",
      "Person:  774\n",
      "Transitions:  [5, 8, 4, 8, 1, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.8997150997150997 0.8679245283018868 0.9928057553956835\n",
      "Num frames:  (1272, 168)\n",
      "Accuracy:  0.8997150997150997\n",
      "Person:  775\n",
      "Transitions:  [0, 8, 1, 8, 2, 8, 3, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.8935506241331485 0.8059606848446417 0.8640380693405847\n",
      "Num frames:  (1577, 107)\n",
      "Accuracy:  0.8935506241331485\n",
      "Person:  776\n",
      "Transitions:  [7, 8, 6, 8, 5, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.960126582278481 0.9347826086956522 1.0\n",
      "Num frames:  (966, 63)\n",
      "Accuracy:  0.960126582278481\n",
      "Person:  777\n",
      "Transitions:  [1, 8, 0, 8]\n",
      "GT transitions:  1\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.8278622898318655 0.7041666666666667 0.7511111111111111\n",
      "Num frames:  (720, 47)\n",
      "Accuracy:  0.8278622898318655\n",
      "Person:  778\n",
      "Transitions:  [5, 8, 6, 8, 4, 8, 1, 8, 0, 8]\n",
      "GT transitions:  4\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.5617103984450923 0.4559932942162615 0.7970695970695971\n",
      "Num frames:  (2386, 1076)\n",
      "Accuracy:  0.5617103984450923\n",
      "Person:  779\n",
      "Transitions:  [4, 8, 5, 8]\n",
      "GT transitions:  1\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.9611158072696534 0.9409499358151476 0.994572591587517\n",
      "Num frames:  (779, 42)\n",
      "Accuracy:  0.9611158072696534\n",
      "Person:  780\n",
      "Transitions:  [6, 8, 5, 8]\n",
      "GT transitions:  1\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.9611451942740287 0.953939393939394 1.0\n",
      "Num frames:  (825, 38)\n",
      "Accuracy:  0.9611451942740287\n",
      "Person:  781\n",
      "Transitions:  [5, 8, 4, 8, 1, 8, 0, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.9114008692744902 0.8566017316017316 1.0\n",
      "Num frames:  (1848, 265)\n",
      "Accuracy:  0.9114008692744902\n",
      "Person:  782\n",
      "Transitions:  [5, 8, 6, 8, 7, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.9466019417475728 0.9146551724137931 1.0\n",
      "Num frames:  (1160, 99)\n",
      "Accuracy:  0.9466019417475728\n",
      "Person:  783\n",
      "Transitions:  [7, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.9973045822102425 0.9973045822102425 1.0\n",
      "Num frames:  (371, 1)\n",
      "Accuracy:  0.9973045822102425\n",
      "Person:  784\n",
      "Transitions:  [0, 8, 1, 8]\n",
      "GT transitions:  1\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.8748169838945827 0.7507645259938838 0.7450682852807283\n",
      "Num frames:  (654, 3)\n",
      "Accuracy:  0.8748169838945827\n",
      "Person:  785\n",
      "Transitions:  [1, 8, 0, 8]\n",
      "GT transitions:  1\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.8067597354886114 0.6796482412060302 0.7300944669365722\n",
      "Num frames:  (796, 63)\n",
      "Accuracy:  0.8067597354886114\n",
      "Person:  786\n",
      "Transitions:  [7, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.9967637540453075 0.9967637540453075 1.0\n",
      "Num frames:  (309, 1)\n",
      "Accuracy:  0.9967637540453075\n",
      "Person:  787\n",
      "Transitions:  [0, 8, 1, 8, 2, 8, 3, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.8637059724349158 0.7638888888888888 0.873015873015873\n",
      "Num frames:  (1872, 237)\n",
      "Accuracy:  0.8637059724349158\n",
      "Person:  788\n",
      "Transitions:  [5, 8, 4, 8, 4, 8, 1, 8, 0, 8]\n",
      "GT transitions:  4\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.5179372197309418 0.45218277560727027 0.7498591549295774\n",
      "Num frames:  (5887, 2337)\n",
      "Accuracy:  0.5179372197309418\n",
      "Person:  789\n",
      "Transitions:  [7, 8, 6, 8, 5, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.9326599326599326 0.8951965065502183 1.0\n",
      "Num frames:  (1145, 120)\n",
      "Accuracy:  0.9326599326599326\n",
      "Person:  790\n",
      "Transitions:  [7, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.996551724137931 0.996551724137931 1.0\n",
      "Num frames:  (290, 1)\n",
      "Accuracy:  0.996551724137931\n",
      "Person:  791\n",
      "Transitions:  [5, 8, 4, 8, 1, 8, 0, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.9347662141779789 0.889602053915276 0.9992790194664743\n",
      "Num frames:  (1558, 172)\n",
      "Accuracy:  0.9347662141779789\n",
      "Person:  792\n",
      "Transitions:  [0, 8, 1, 8]\n",
      "GT transitions:  1\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.8748326639892905 0.7489597780859917 0.7627118644067796\n",
      "Num frames:  (721, 19)\n",
      "Accuracy:  0.8748326639892905\n",
      "Person:  793\n",
      "Transitions:  [3, 8, 2, 8, 4, 8, 1, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.8248914616497829 0.7373371924746743 0.9990196078431373\n",
      "Num frames:  (1382, 362)\n",
      "Accuracy:  0.8248914616497829\n",
      "Person:  794\n",
      "Transitions:  [5, 8, 4, 8, 1, 8, 0, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.9125862635557016 0.8582129481005886 0.9987546699875467\n",
      "Num frames:  (1869, 264)\n",
      "Accuracy:  0.9125862635557016\n",
      "Person:  795\n",
      "Transitions:  [3, 8, 2, 8, 1, 8, 0, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.8994535519125683 0.8324091189155884 0.9323671497584541\n",
      "Num frames:  (1623, 178)\n",
      "Accuracy:  0.8994535519125683\n",
      "Person:  796\n",
      "Transitions:  [7, 8, 6, 8, 5, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.9496192149970709 0.9223125564588979 1.0\n",
      "Num frames:  (1107, 86)\n",
      "Accuracy:  0.9496192149970709\n",
      "Person:  797\n",
      "Transitions:  [7, 8, 0, 8]\n",
      "GT transitions:  1\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.9471598414795245 0.896774193548387 1.0\n",
      "Num frames:  (775, 80)\n",
      "Accuracy:  0.9471598414795245\n",
      "Person:  798\n",
      "Transitions:  [0, 8, 1, 8]\n",
      "GT transitions:  1\n",
      "Transitions captured:  0\n",
      "A,P,R:  0.6713286713286714 0.7777777777777778 0.0695364238410596\n",
      "Num frames:  (27, 1)\n",
      "Accuracy:  0.6713286713286714\n",
      "Person:  799\n",
      "Transitions:  [7, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.99609375 0.99609375 1.0\n",
      "Num frames:  (256, 1)\n",
      "Accuracy:  0.99609375\n",
      "Person:  800\n",
      "Transitions:  [7, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.9962962962962963 0.9962962962962963 1.0\n",
      "Num frames:  (270, 1)\n",
      "Accuracy:  0.9962962962962963\n",
      "Person:  801\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transitions:  [3, 8, 2, 8, 1, 8, 1, 8, 4, 8, 4, 8]\n",
      "GT transitions:  5\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.09907947223074563 0.05903180121024849 0.4855705586444268\n",
      "Num frames:  (31068, 27418)\n",
      "Accuracy:  0.09907947223074563\n",
      "Person:  802\n",
      "Transitions:  [3, 8, 2, 8, 4, 8, 1, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.8665955176093917 0.7905405405405406 0.9821615949632738\n",
      "Num frames:  (1184, 233)\n",
      "Accuracy:  0.8665955176093917\n",
      "Person:  803\n",
      "Transitions:  [3, 8, 2, 8, 1, 8, 0, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.8997837058399423 0.8346268656716418 0.9338677354709419\n",
      "Num frames:  (1675, 179)\n",
      "Accuracy:  0.8997837058399423\n",
      "Person:  804\n",
      "Transitions:  [7, 8, 6, 8, 5, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.8684738955823293 0.8069270449521002 1.0\n",
      "Num frames:  (1357, 262)\n",
      "Accuracy:  0.8684738955823293\n",
      "Person:  805\n",
      "Transitions:  [0, 8, 1, 8, 2, 8, 3, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.8462204270051933 0.7427606177606177 0.8719546742209632\n",
      "Num frames:  (2072, 307)\n",
      "Accuracy:  0.8462204270051933\n",
      "Person:  806\n",
      "Transitions:  [0, 8, 1, 8, 4, 8, 5, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.9001555209953344 0.823828345567476 0.8858530661809351\n",
      "Num frames:  (1771, 133)\n",
      "Accuracy:  0.9001555209953344\n",
      "Person:  807\n",
      "Transitions:  [7, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.9953271028037384 0.9953271028037384 1.0\n",
      "Num frames:  (214, 1)\n",
      "Accuracy:  0.9953271028037384\n",
      "Person:  808\n",
      "Transitions:  [7, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.9971014492753624 0.9971014492753624 1.0\n",
      "Num frames:  (345, 1)\n",
      "Accuracy:  0.9971014492753624\n",
      "Person:  809\n",
      "Transitions:  [5, 8, 4, 8]\n",
      "GT transitions:  1\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.8814159292035398 0.8349753694581281 1.0\n",
      "Num frames:  (812, 134)\n",
      "Accuracy:  0.8814159292035398\n",
      "Person:  810\n",
      "Transitions:  [1, 8, 1, 8]\n",
      "GT transitions:  1\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.612141652613828 0.612141652613828 0.6247848537005164\n",
      "Num frames:  (593, 12)\n",
      "Accuracy:  0.612141652613828\n",
      "Person:  811\n",
      "Transitions:  [7, 8, 6, 8, 5, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.977348434377082 0.9646799116997793 0.997716894977169\n",
      "Num frames:  (906, 32)\n",
      "Accuracy:  0.977348434377082\n",
      "Person:  812\n",
      "Transitions:  [7, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.9984848484848485 0.9984848484848485 1.0\n",
      "Num frames:  (660, 1)\n",
      "Accuracy:  0.9984848484848485\n",
      "Person:  813\n",
      "Transitions:  [0, 8, 1, 8]\n",
      "GT transitions:  1\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.867214236824093 0.7309292649098474 0.7391304347826086\n",
      "Num frames:  (721, 8)\n",
      "Accuracy:  0.867214236824093\n",
      "Person:  814\n",
      "Transitions:  [7, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.99609375 0.99609375 1.0\n",
      "Num frames:  (256, 1)\n",
      "Accuracy:  0.99609375\n",
      "Person:  815\n",
      "Transitions:  [5, 8, 6, 8, 7, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.9598480737927293 0.935930735930736 1.0\n",
      "Num frames:  (1155, 74)\n",
      "Accuracy:  0.9598480737927293\n",
      "Person:  816\n",
      "Transitions:  [7, 8, 6, 8, 5, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.8324808184143222 0.7724377533294731 1.0\n",
      "Num frames:  (1727, 393)\n",
      "Accuracy:  0.8324808184143222\n",
      "Person:  817\n",
      "Transitions:  [2, 8, 4, 8, 5, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.955944055944056 0.9774266365688488 0.9382448537378115\n",
      "Num frames:  (886, 6)\n",
      "Accuracy:  0.955944055944056\n",
      "Person:  818\n",
      "Transitions:  [5, 8, 6, 8, 7, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.9900249376558603 0.9892703862660944 0.9935344827586207\n",
      "Num frames:  (932, 10)\n",
      "Accuracy:  0.9900249376558603\n",
      "Person:  819\n",
      "Transitions:  [5, 8, 6, 8, 7, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.9974763406940063 0.9968354430379747 0.9989429175475687\n",
      "Num frames:  (948, 3)\n",
      "Accuracy:  0.9974763406940063\n",
      "Person:  820\n",
      "Transitions:  [5, 8, 4, 8, 4, 8, 1, 8, 0, 8]\n",
      "GT transitions:  4\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.5052312357846853 0.4368312046945116 0.7614320096269555\n",
      "Num frames:  (5794, 2470)\n",
      "Accuracy:  0.5052312357846853\n",
      "Person:  821\n",
      "Transitions:  [0, 8, 1, 8, 1, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.8027472527472528 0.6395582329317269 0.7406976744186047\n",
      "Num frames:  (996, 136)\n",
      "Accuracy:  0.8027472527472528\n",
      "Person:  822\n",
      "Transitions:  [0, 8, 1, 8]\n",
      "GT transitions:  1\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.8460972017673049 0.7301829268292683 0.6982507288629738\n",
      "Num frames:  (656, 2)\n",
      "Accuracy:  0.8460972017673049\n",
      "Person:  823\n",
      "Transitions:  [3, 8, 2, 8, 1, 8, 0, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.9012481644640234 0.8424908424908425 0.9181636726546906\n",
      "Num frames:  (1638, 146)\n",
      "Accuracy:  0.9012481644640234\n",
      "Person:  824\n",
      "Transitions:  [2, 8, 4, 8, 5, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.9308634772462077 0.9162839985870717 1.0\n",
      "Num frames:  (2831, 237)\n",
      "Accuracy:  0.9308634772462077\n",
      "Person:  825\n",
      "Transitions:  [1, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.5411764705882353 0.5411764705882353 0.5427728613569321\n",
      "Num frames:  (340, 1)\n",
      "Accuracy:  0.5411764705882353\n",
      "Person:  826\n",
      "Transitions:  [0, 8, 1, 8, 4, 8, 5, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.8407659360040313 0.7440816326530613 0.8534644194756554\n",
      "Num frames:  (2450, 319)\n",
      "Accuracy:  0.8407659360040313\n",
      "Person:  827\n",
      "Transitions:  [1, 8, 0, 8]\n",
      "GT transitions:  1\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.7340529931305201 0.610204081632653 0.5292035398230088\n",
      "Num frames:  (490, 5)\n",
      "Accuracy:  0.7340529931305201\n",
      "Person:  828\n",
      "Transitions:  [7, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.9978448275862069 0.9978448275862069 1.0\n",
      "Num frames:  (464, 1)\n",
      "Accuracy:  0.9978448275862069\n",
      "Person:  829\n",
      "Transitions:  [5, 8, 6, 8, 7, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.9564725833804409 0.9286376274328082 1.0\n",
      "Num frames:  (1079, 77)\n",
      "Accuracy:  0.9564725833804409\n",
      "Person:  830\n",
      "Transitions:  [0, 8, 7, 8]\n",
      "GT transitions:  1\n",
      "Transitions captured:  0\n",
      "A,P,R:  0.6736672051696284 0.915929203539823 0.34966216216216217\n",
      "Num frames:  (226, 19)\n",
      "Accuracy:  0.6736672051696284\n",
      "Person:  831\n",
      "Transitions:  [7, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.9965277777777778 0.9965277777777778 1.0\n",
      "Num frames:  (288, 1)\n",
      "Accuracy:  0.9965277777777778\n",
      "Person:  832\n",
      "Transitions:  [5, 8, 6, 8, 7, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.9845679012345679 0.9850905218317358 0.9882478632478633\n",
      "Num frames:  (939, 14)\n",
      "Accuracy:  0.9845679012345679\n",
      "Person:  833\n",
      "Transitions:  [7, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.9973404255319149 0.9973404255319149 1.0\n",
      "Num frames:  (376, 1)\n",
      "Accuracy:  0.9973404255319149\n",
      "Person:  834\n",
      "Transitions:  [7, 8, 6, 8, 5, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.9555555555555556 0.9351005484460695 0.995136186770428\n",
      "Num frames:  (1094, 71)\n",
      "Accuracy:  0.9555555555555556\n",
      "Person:  835\n",
      "Transitions:  [7, 8, 6, 8, 5, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.9559785841760856 0.9314179796107507 1.0\n",
      "Num frames:  (1079, 74)\n",
      "Accuracy:  0.9559785841760856\n",
      "Person:  836\n",
      "Transitions:  [5, 8, 4, 8, 1, 8, 0, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.9339239571797712 0.8927899686520376 0.9937194696441033\n",
      "Num frames:  (1595, 170)\n",
      "Accuracy:  0.9339239571797712\n",
      "Person:  837\n",
      "Transitions:  [7, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.996969696969697 0.996969696969697 1.0\n",
      "Num frames:  (330, 1)\n",
      "Accuracy:  0.996969696969697\n",
      "Person:  838\n",
      "Transitions:  [7, 8, 6, 8, 5, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.9508584961515689 0.9221272554605888 0.9989711934156379\n",
      "Num frames:  (1053, 82)\n",
      "Accuracy:  0.9508584961515689\n",
      "Person:  839\n",
      "Transitions:  [5, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.9945652173913043 0.9945652173913043 1.0\n",
      "Num frames:  (184, 1)\n",
      "Accuracy:  0.9945652173913043\n",
      "Person:  840\n",
      "Transitions:  [1, 8, 2, 8, 3, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.8867676102699145 0.8277310924369747 0.8640350877192983\n",
      "Num frames:  (952, 48)\n",
      "Accuracy:  0.8867676102699145\n",
      "Person:  841\n",
      "Transitions:  [0, 8, 1, 8, 4, 8, 6, 8, 5, 8]\n",
      "GT transitions:  4\n",
      "Transitions captured:  4\n",
      "A,P,R:  0.9303977272727273 0.863103953147877 0.9751861042183623\n",
      "Num frames:  (1366, 166)\n",
      "Accuracy:  0.9303977272727273\n",
      "Person:  842\n",
      "Transitions:  [4, 8, 5, 8]\n",
      "GT transitions:  1\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.9902248289345064 0.9907692307692307 0.989247311827957\n",
      "Num frames:  (650, 3)\n",
      "Accuracy:  0.9902248289345064\n",
      "Person:  843\n",
      "Transitions:  [7, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.9963636363636363 0.9963636363636363 1.0\n",
      "Num frames:  (275, 1)\n",
      "Accuracy:  0.9963636363636363\n",
      "Person:  844\n",
      "Transitions:  [7, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.996742671009772 0.996742671009772 1.0\n",
      "Num frames:  (307, 1)\n",
      "Accuracy:  0.996742671009772\n",
      "Person:  845\n",
      "Transitions:  [0, 8, 1, 8, 4, 8, 5, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.8595204513399154 0.7594202898550725 0.8438003220611916\n",
      "Num frames:  (2070, 207)\n",
      "Accuracy:  0.8595204513399154\n",
      "Person:  846\n",
      "Transitions:  [7, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.9969325153374233 0.9969325153374233 1.0\n",
      "Num frames:  (326, 1)\n",
      "Accuracy:  0.9969325153374233\n",
      "Person:  847\n",
      "Transitions:  [0, 8, 7, 8]\n",
      "GT transitions:  1\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.9821073558648111 0.9593984962406015 1.0\n",
      "Num frames:  (665, 27)\n",
      "Accuracy:  0.9821073558648111\n",
      "Person:  848\n",
      "Transitions:  [7, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.996551724137931 0.996551724137931 1.0\n",
      "Num frames:  (290, 1)\n",
      "Accuracy:  0.996551724137931\n",
      "Person:  849\n",
      "Transitions:  [7, 8, 6, 8, 5, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.8764789398958827 0.8237677245104659 1.0\n",
      "Num frames:  (1481, 261)\n",
      "Accuracy:  0.8764789398958827\n",
      "Person:  850\n",
      "Transitions:  [3, 8, 2, 8, 1, 8, 0, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.8918345705196182 0.833810888252149 0.9110832811521603\n",
      "Num frames:  (1745, 164)\n",
      "Accuracy:  0.8918345705196182\n",
      "Person:  851\n",
      "Transitions:  [7, 8, 6, 8, 5, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.9566088117489987 0.9251152073732719 1.0\n",
      "Num frames:  (868, 65)\n",
      "Accuracy:  0.9566088117489987\n",
      "Person:  852\n",
      "Transitions:  [5, 8, 4, 8, 1, 8, 0, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.917578659370725 0.8706992230854605 0.9949270767279645\n",
      "Num frames:  (1802, 233)\n",
      "Accuracy:  0.917578659370725\n",
      "Person:  853\n",
      "Transitions:  [7, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.9971428571428571 0.9971428571428571 1.0\n",
      "Num frames:  (350, 1)\n",
      "Accuracy:  0.9971428571428571\n",
      "Person:  854\n",
      "Transitions:  [7, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.9969325153374233 0.9969325153374233 1.0\n",
      "Num frames:  (326, 1)\n",
      "Accuracy:  0.9969325153374233\n",
      "Person:  855\n",
      "Transitions:  [3, 8, 2, 8, 1, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.907563025210084 0.8637873754152824 0.9860935524652339\n",
      "Num frames:  (903, 121)\n",
      "Accuracy:  0.907563025210084\n",
      "Person:  856\n",
      "Transitions:  [0, 8, 1, 8, 2, 8, 3, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.9002995293110826 0.875 0.8256721595836947\n",
      "Num frames:  (1088, 32)\n",
      "Accuracy:  0.9002995293110826\n",
      "Person:  857\n",
      "Transitions:  [5, 8, 4, 8, 1, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.8678260869565217 0.819047619047619 1.0\n",
      "Num frames:  (1260, 228)\n",
      "Accuracy:  0.8678260869565217\n",
      "Person:  858\n",
      "Transitions:  [0, 8, 1, 8, 2, 8, 3, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.8740717821782178 0.7843032568072611 0.879114302812687\n",
      "Num frames:  (1873, 205)\n",
      "Accuracy:  0.8740717821782178\n",
      "Person:  859\n",
      "Transitions:  [7, 8, 1, 8]\n",
      "GT transitions:  1\n",
      "Transitions captured:  0\n",
      "A,P,R:  0.5063078216989066 0.5017667844522968 0.3333333333333333\n",
      "Num frames:  (566, 19)\n",
      "Accuracy:  0.5063078216989066\n",
      "Person:  860\n",
      "Transitions:  [0, 8, 1, 8, 2, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A,P,R:  0.8863276836158193 0.852751756440281 0.9024163568773235\n",
      "Num frames:  (3416, 188)\n",
      "Accuracy:  0.8863276836158193\n",
      "Person:  861\n",
      "Transitions:  [1, 8, 4, 8, 2, 8, 3, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.9246458923512748 0.8704453441295547 0.9942196531791907\n",
      "Num frames:  (988, 128)\n",
      "Accuracy:  0.9246458923512748\n",
      "Person:  862\n",
      "Transitions:  [7, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.9969230769230769 0.9969230769230769 1.0\n",
      "Num frames:  (325, 1)\n",
      "Accuracy:  0.9969230769230769\n",
      "Person:  863\n",
      "Transitions:  [0, 8, 1, 8]\n",
      "GT transitions:  1\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.8718801996672213 0.8088531187122736 0.7256317689530686\n",
      "Num frames:  (497, 2)\n",
      "Accuracy:  0.8718801996672213\n",
      "Person:  864\n",
      "Transitions:  [7, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.9968847352024922 0.9968847352024922 1.0\n",
      "Num frames:  (321, 1)\n",
      "Accuracy:  0.9968847352024922\n",
      "Person:  865\n",
      "Transitions:  [7, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.9963503649635036 0.9963503649635036 1.0\n",
      "Num frames:  (274, 1)\n",
      "Accuracy:  0.9963503649635036\n",
      "Person:  866\n",
      "Transitions:  [5, 8, 6, 8, 7, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.9725870930896631 0.9545884578997161 1.0\n",
      "Num frames:  (1057, 48)\n",
      "Accuracy:  0.9725870930896631\n",
      "Person:  867\n",
      "Transitions:  [7, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.9963235294117647 0.9963235294117647 1.0\n",
      "Num frames:  (272, 1)\n",
      "Accuracy:  0.9963235294117647\n",
      "Person:  868\n",
      "Transitions:  [7, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.9960474308300395 0.9960474308300395 1.0\n",
      "Num frames:  (253, 1)\n",
      "Accuracy:  0.9960474308300395\n",
      "Person:  869\n",
      "Transitions:  [0, 8, 1, 8, 4, 8, 5, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.9064462809917355 0.8343446601941747 0.8615288220551378\n",
      "Num frames:  (1648, 62)\n",
      "Accuracy:  0.9064462809917355\n",
      "Person:  870\n",
      "Transitions:  [5, 8, 4, 8, 1, 8, 0, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.9127849355797819 0.8607663248785753 0.9962523422860712\n",
      "Num frames:  (1853, 258)\n",
      "Accuracy:  0.9127849355797819\n",
      "Person:  871\n",
      "Transitions:  [0, 8, 1, 8, 4, 8, 5, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.9286005711954305 0.9453376205787781 0.8681102362204725\n",
      "Num frames:  (933, 41)\n",
      "Accuracy:  0.9286005711954305\n",
      "Person:  872\n",
      "Transitions:  [5, 8, 6, 8, 7, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.9879735417919423 0.9829488465396189 0.9969481180061037\n",
      "Num frames:  (997, 17)\n",
      "Accuracy:  0.9879735417919423\n",
      "Person:  873\n",
      "Transitions:  [7, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.9966101694915255 0.9966101694915255 1.0\n",
      "Num frames:  (295, 1)\n",
      "Accuracy:  0.9966101694915255\n",
      "Person:  874\n",
      "Transitions:  [7, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.9970238095238095 0.9970238095238095 1.0\n",
      "Num frames:  (336, 1)\n",
      "Accuracy:  0.9970238095238095\n",
      "Person:  875\n",
      "Transitions:  [1, 8, 1, 8, 2, 8, 5, 8, 6, 8, 4, 8]\n",
      "GT transitions:  5\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.1257644660498667 0.08865248226950355 0.5425070206790912\n",
      "Num frames:  (23970, 20508)\n",
      "Accuracy:  0.1257644660498667\n",
      "Person:  876\n",
      "Transitions:  [5, 8, 6, 8, 7, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.9809637120761452 0.9676767676767677 1.0\n",
      "Num frames:  (990, 32)\n",
      "Accuracy:  0.9809637120761452\n",
      "Person:  877\n",
      "Transitions:  [7, 8, 6, 8, 5, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.9499105545617174 0.9196940726577438 1.0\n",
      "Num frames:  (1046, 84)\n",
      "Accuracy:  0.9499105545617174\n",
      "Person:  878\n",
      "Transitions:  [2, 8, 1, 8]\n",
      "GT transitions:  1\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.7890909090909091 0.7343511450381679 0.8056951423785594\n",
      "Num frames:  (655, 58)\n",
      "Accuracy:  0.7890909090909091\n",
      "Person:  879\n",
      "Transitions:  [3, 8, 2, 8, 1, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  0\n",
      "A,P,R:  0.5453474676089517 0.4553191489361702 0.3835125448028674\n",
      "Num frames:  (470, 42)\n",
      "Accuracy:  0.5453474676089517\n",
      "Person:  880\n",
      "Transitions:  [5, 8, 6, 8, 4, 8, 1, 8, 1, 8, 0, 8]\n",
      "GT transitions:  5\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.7241777264858626 0.5827473042662916 0.7294600938967136\n",
      "Num frames:  (2133, 495)\n",
      "Accuracy:  0.7241777264858626\n",
      "Person:  881\n",
      "Transitions:  [5, 8, 4, 8]\n",
      "GT transitions:  1\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.9506647621140534 0.9488435684174548 1.0\n",
      "Num frames:  (8777, 449)\n",
      "Accuracy:  0.9506647621140534\n",
      "Person:  882\n",
      "Transitions:  [7, 8, 1, 8]\n",
      "GT transitions:  1\n",
      "Transitions captured:  0\n",
      "A,P,R:  0.4284377923292797 0.5469879518072289 0.2858942065491184\n",
      "Num frames:  (415, 44)\n",
      "Accuracy:  0.4284377923292797\n",
      "Person:  883\n",
      "Transitions:  [7, 8, 0, 8]\n",
      "GT transitions:  1\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.9915907498248073 0.9839142091152815 1.0\n",
      "Num frames:  (746, 12)\n",
      "Accuracy:  0.9915907498248073\n",
      "Person:  884\n",
      "Transitions:  [7, 8, 6, 8, 5, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.9589371980676329 0.9336585365853659 1.0\n",
      "Num frames:  (1025, 68)\n",
      "Accuracy:  0.9589371980676329\n",
      "Person:  885\n",
      "Transitions:  [5, 8, 6, 8, 7, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.9912826899128269 0.9927234927234927 0.9927234927234927\n",
      "Num frames:  (962, 7)\n",
      "Accuracy:  0.9912826899128269\n",
      "Person:  886\n",
      "Transitions:  [5, 8, 4, 8, 1, 8, 0, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.9002274943126422 0.8391350210970464 0.9987445072190835\n",
      "Num frames:  (1896, 305)\n",
      "Accuracy:  0.9002274943126422\n",
      "Person:  887\n",
      "Transitions:  [3, 8, 2, 8, 1, 8, 0, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.9207811348563006 0.8679012345679012 0.9286657859973579\n",
      "Num frames:  (1620, 107)\n",
      "Accuracy:  0.9207811348563006\n",
      "Person:  888\n",
      "Transitions:  [5, 8, 6, 8, 7, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.8985148514851485 0.8455162019593067 1.0\n",
      "Num frames:  (1327, 205)\n",
      "Accuracy:  0.8985148514851485\n",
      "Person:  889\n",
      "Transitions:  [0, 8, 1, 8]\n",
      "GT transitions:  1\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.7788894447223612 0.6400329489291599 0.6523929471032746\n",
      "Num frames:  (1214, 28)\n",
      "Accuracy:  0.7788894447223612\n",
      "Person:  890\n",
      "Transitions:  [7, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.9964912280701754 0.9964912280701754 1.0\n",
      "Num frames:  (285, 1)\n",
      "Accuracy:  0.9964912280701754\n",
      "Person:  891\n",
      "Transitions:  [7, 8, 6, 8, 5, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.9749530369442705 0.9592252803261978 1.0\n",
      "Num frames:  (981, 40)\n",
      "Accuracy:  0.9749530369442705\n",
      "Person:  892\n",
      "Transitions:  [7, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.9964788732394366 0.9964788732394366 1.0\n",
      "Num frames:  (284, 1)\n",
      "Accuracy:  0.9964788732394366\n",
      "Person:  893\n",
      "Transitions:  [7, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.9972144846796658 0.9972144846796658 1.0\n",
      "Num frames:  (359, 1)\n",
      "Accuracy:  0.9972144846796658\n",
      "Person:  894\n",
      "Transitions:  [7, 8, 1, 8]\n",
      "GT transitions:  1\n",
      "Transitions captured:  0\n",
      "A,P,R:  0.5026666666666667 0.4080664294187426 0.32483474976392823\n",
      "Num frames:  (843, 31)\n",
      "Accuracy:  0.5026666666666667\n",
      "Person:  895\n",
      "Transitions:  [7, 8, 0, 8]\n",
      "GT transitions:  1\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.9154370034052214 0.8526211671612265 1.0\n",
      "Num frames:  (1011, 149)\n",
      "Accuracy:  0.9154370034052214\n",
      "Person:  896\n",
      "Transitions:  [0, 8, 1, 8, 4, 8, 5, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.8172668306866473 0.7132275132275132 0.8607918263090677\n",
      "Num frames:  (2835, 490)\n",
      "Accuracy:  0.8172668306866473\n",
      "Person:  897\n",
      "Transitions:  [1, 8, 4, 8, 5, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.8986856516976999 0.8421501706484642 0.9164345403899722\n",
      "Num frames:  (1172, 95)\n",
      "Accuracy:  0.8986856516976999\n",
      "Person:  898\n",
      "Transitions:  [7, 8, 0, 8]\n",
      "GT transitions:  1\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.9611486486486487 0.9312749003984063 1.0\n",
      "Num frames:  (1004, 69)\n",
      "Accuracy:  0.9611486486486487\n",
      "Person:  899\n",
      "Transitions:  [7, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.9971988795518207 0.9971988795518207 1.0\n",
      "Num frames:  (357, 1)\n",
      "Accuracy:  0.9971988795518207\n",
      "Person:  900\n",
      "Transitions:  [7, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.9955357142857143 0.9955357142857143 1.0\n",
      "Num frames:  (224, 1)\n",
      "Accuracy:  0.9955357142857143\n",
      "Person:  901\n",
      "Transitions:  [7, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.9970238095238095 0.9970238095238095 1.0\n",
      "Num frames:  (336, 1)\n",
      "Accuracy:  0.9970238095238095\n",
      "Person:  902\n",
      "Transitions:  [7, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.996309963099631 0.996309963099631 1.0\n",
      "Num frames:  (271, 1)\n",
      "Accuracy:  0.996309963099631\n",
      "Person:  903\n",
      "Transitions:  [1, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.5 0.5 0.502262443438914\n",
      "Num frames:  (222, 1)\n",
      "Accuracy:  0.5\n",
      "Person:  904\n",
      "Transitions:  [5, 8, 6, 8, 7, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.9686274509803922 0.9494584837545126 1.0\n",
      "Num frames:  (1108, 56)\n",
      "Accuracy:  0.9686274509803922\n",
      "Person:  905\n",
      "Transitions:  [0, 8, 6, 8, 6, 8, 5, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.7567670606176135 0.5351089588377724 0.7090909090909091\n",
      "Num frames:  (1239, 366)\n",
      "Accuracy:  0.7567670606176135\n",
      "0.8759275982583791\n",
      "Average (only transitions) A,P,R 0.8468056201924162 0.7861850999840481 0.8869321593215191\n",
      "Average (all targets) A,P,R,F, ttr 0.8759275982583784 0.8289567316068615 0.90783662734109 827.6037527593819 [3, 3, 7, 1, 3, 1, 5, 1, 3, 1, 1, 3, 1, 1, 5, 1, 3, 5, 5, 5, 7, 5, 1, 1, 1, 3, 3, 3, 5, 7, 3, 7, 7, 5, 7, 3, 1, 1, 5, 5, 3, 3, 7, 1, 5, 7, 1, 5, 1, 1, 7, 5, 9, 1, 7, 7, 3, 1, 5, 1, 9, 7, 7, 3, 3, 1, 5, 5, 5, 3, 3, 1, 1, 5, 5, 7, 1, 1, 7, 7, 7, 7, 5, 7, 7, 1, 1, 3, 7, 3, 5, 5, 3, 5, 1, 5, 3, 1, 5, 3, 5, 3, 1, 5, 1, 5, 3, 5, 3, 3, 1, 5, 3, 3, 5, 1, 1, 5, 5, 1, 1, 3, 3, 3, 5, 5, 5, 7, 3, 3, 1, 3, 5, 5, 3, 5, 5, 5, 5, 1, 3, 5, 7, 7, 7, 5, 5, 1, 1, 3, 5, 5, 3, 5, 5, 5, 3, 5, 5, 3, 1, 3, 5, 1, 5, 7, 3, 7, 5, 9, 9, 3, 7, 5, 5, 1, 5, 5, 3, 3, 5, 5, 5, 7, 7, 5, 5, 7, 7, 3, 1, 5, 7, 13, 5, 7, 1, 3, 5, 1, 5, 5, 5, 7, 3, 7, 3, 5, 7, 5, 3, 9, 1, 1, 3, 1, 5, 5, 5, 7, 1, 1, 5, 1, 3, 7, 1, 5, 7, 3, 1, 5, 3, 7, 9, 7, 7, 1, 1, 5, 1, 3, 3, 1, 7, 7, 7, 5, 1, 3, 1, 5, 7, 3, 7, 3, 7, 5, 7, 7, 1, 5, 5, 13, 1, 5, 5, 3, 5, 1, 5, 1, 7, 1, 7, 1, 1, 5, 3, 7, 1, 3, 5, 3, 9, 7, 3, 5, 7, 7, 3, 5, 5, 1, 5, 3, 3, 7, 5, 3, 7, 3, 9, 7, 5, 3, 5, 1, 5, 5, 1, 7, 1, 1, 5, 3, 5, 3, 3, 3, 1, 5, 7, 5, 1, 1, 5, 7, 7, 3, 3, 1, 7, 5, 1, 7, 5, 1, 1, 7, 5, 7, 3, 7, 7, 5, 5, 1, 3, 7, 1, 9, 7, 5, 5, 7, 7, 1, 5, 7, 5, 5, 5, 5, 5, 5, 7, 1, 5, 5, 7, 3, 7, 7, 1, 3, 7, 3, 7, 5, 1, 5, 3, 3, 3, 7, 5, 3, 3, 1, 5, 1, 11, 1, 1, 1, 7, 5, 7, 7, 7, 5, 7, 7, 5, 7, 3, 7, 7, 7, 3, 7, 3, 1, 9, 3, 7, 1, 5, 3, 7, 7, 5, 1, 9, 7, 3, 5, 5, 7, 7, 1, 1, 5, 13, 3, 1, 21, 7, 1, 5, 3, 3, 11, 7, 5, 3, 7, 5, 7, 7, 3, 5, 3, 3, 7, 1, 7, 5, 7, 1, 5, 5, 5, 5, 5, 7, 1, 5, 5, 5, 1, 5, 7, 7, 3, 9, 7, 7, 7, 5, 5, 1, 7, 1, 5, 7, 1, 5, 5, 3, 1, 3, 5, 5, 9, 5, 13, 5, 7, 3, 3, 7, 3, 1, 5, 7, 1, 1, 1, 7, 1, 5, 1, 1, 5, 1, 7, 5, 7, 9, 7, 1, 7, 7, 3, 5, 3, 7, 5, 5, 1, 7, 5, 1, 5, 1, 7, 1, 5, 7, 5, 1, 1, 3, 9, 7, 5, 3, 3, 5, 13, 5, 1, 1, 1, 1, 7, 5, 11, 5, 1, 3, 1, 5, 3, 7, 1, 5, 7, 5, 7, 7, 3, 1, 5, 1, 3, 7, 7, 5, 9, 5, 5, 3, 1, 3, 3, 1, 5, 55, 5, 7, 3, 7, 3, 5, 7, 5, 7, 7, 3, 3, 1, 1, 7, 5, 3, 3, 5, 1, 7, 1, 7, 1, 45, 1, 1, 9, 5, 7, 5, 7, 5, 3, 5, 7, 7, 7, 1, 3, 3, 5, 1, 1, 1, 5, 7, 5, 1, 1, 1, 1, 5, 7, 7, 5, 5, 7, 5, 3, 3, 7, 1, 3, 5, 9, 7, 7, 7, 7, 7, 5, 5, 3, 7, 7, 1, 5, 1, 5, 7, 3, 5, 3, 5, 9, 9, 5, 7, 1, 7, 3, 3, 7, 3, 7, 1, 5, 5, 5, 9, 1, 1, 3, 7, 3, 7, 7, 1, 3, 3, 1, 5, 3, 1, 5, 7, 9, 7, 1, 5, 7, 7, 1, 3, 1, 3, 7, 5, 7, 3, 5, 1, 3, 7, 5, 1, 5, 5, 13, 7, 5, 5, 5, 9, 7, 5, 7, 3, 5, 5, 7, 1, 5, 3, 5, 7, 5, 7, 5, 3, 5, 3, 9, 1, 5, 3, 1, 7, 5, 7, 5, 3, 3, 1, 7, 1, 1, 7, 5, 7, 7, 7, 5, 7, 5, 3, 9, 3, 3, 7, 5, 1, 3, 3, 1, 7, 9, 5, 1, 7, 3, 7, 7, 7, 5, 3, 3, 1, 1, 11, 7, 7, 5, 7, 7, 1, 1, 3, 3, 5, 1, 3, 1, 5, 5, 5, 5, 5, 9, 5, 3, 7, 5, 1, 7, 3, 1, 5, 3, 1, 5, 1, 5, 5, 7, 1, 5, 1, 5, 9, 3, 1, 1, 7, 1, 3, 1, 5, 7, 5, 7, 1, 1, 5, 7, 5, 7, 3, 5, 7, 1, 3, 1, 1, 5, 1, 1, 7, 7, 7, 5, 1, 1, 11, 5, 5, 3, 5, 11, 3, 3, 3, 5, 5, 7, 7, 5, 3, 1, 5, 1, 1, 3, 3, 7, 5, 3, 1, 1, 1, 1, 1, 5, 7]\n",
      "Fscore (all targets, only transitions)  0.8591360962015422 0.8246082383184284\n",
      "2245033\n"
     ]
    }
   ],
   "source": [
    "policy_net.eval()\n",
    "req_inc = 0\n",
    "render = False\n",
    "_,acc,_,numTR = test_func(pTest,iloc='fix',eloc='last', fixLoc=2, isdebug=0, req_inc=req_inc)\n",
    "tr_acc = 0\n",
    "avg_tr_captured = []\n",
    "A,P,R,F, ttr = [],[],[],[],[]\n",
    "Fscore, Fscore_onlytr = [],[]\n",
    "A_onlytr,P_onlytr,R_onlytr = [],[],[]\n",
    "nfr = []\n",
    "for i in range(len(acc)):\n",
    "    print ('Person: ',i)\n",
    "    gt = np.array([d[0] for d in acc[i]])\n",
    "    pr = np.array([d[1] for d in acc[i]])\n",
    "    g = gt #t[gt != num_camera-1]\n",
    "    p = pr #r[gt != num_camera-1]\n",
    "\n",
    "    dups,gt_tr = remove_duplicates(g)\n",
    "    print ('Transitions: ', dups)\n",
    "    print ('GT transitions: ', len(gt_tr))\n",
    "    print ('Transitions captured: ', numTR[i])\n",
    "    if len(gt_tr) != 0:\n",
    "        avg_tr_captured.append((numTR[i],len(gt_tr)))\n",
    "        contains_tr = 1\n",
    "    else:\n",
    "        print ('')\n",
    "        contains_tr = 0\n",
    "        #continue\n",
    "\n",
    "    # plot transitions\n",
    "#     afc.plot_color_transitions(p,g)\n",
    "    # MCTA and number of frames\n",
    "    if req_inc == 1:\n",
    "        ac,pr,re,fr,tr = afc.compute_APRF_one_person_sct_ict(p,g)\n",
    "    else:\n",
    "        ac,pr,re,fr,tr = afc.compute_APRF_one_person_sct_ict(p,g)\n",
    "\n",
    "    fs = 2*(pr*re)/(pr+re)\n",
    "    if contains_tr == 1:\n",
    "        A_onlytr.append(ac)\n",
    "        P_onlytr.append(pr)\n",
    "        R_onlytr.append(re)\n",
    "        Fscore_onlytr.append(fs)\n",
    "    A.append(ac)\n",
    "    P.append(pr)\n",
    "    R.append(re)\n",
    "    F.append(fr)\n",
    "    Fscore.append(fs) \n",
    "    ttr.append(tr)\n",
    "    print ('A,P,R: ', ac,pr,re)\n",
    "    f = afc.compute_num_frames(p,g)\n",
    "    nfr.append(f)\n",
    "    print ('Num frames: ', f)\n",
    "    # Accuracy\n",
    "    tacc = np.sum(g==p, dtype=np.float)/g.shape[0]\n",
    "    tr_acc += tacc\n",
    "    print ('Accuracy: ',tacc)\n",
    "print (tr_acc/len(A))\n",
    "print ('Average (only transitions) A,P,R', np.mean(A_onlytr),np.mean(P_onlytr),np.mean(R_onlytr))\n",
    "print ('Average (all targets) A,P,R,F, ttr', np.mean(A),np.mean(P),np.mean(R),np.mean(F), ttr)\n",
    "print ('Fscore (all targets, only transitions) ', np.mean(Fscore),np.mean(Fscore_onlytr))\n",
    "print (np.sum(nfr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9372219344441567\n",
      "0.8957940991839297\n"
     ]
    }
   ],
   "source": [
    "a = np.stack(avg_tr_captured)\n",
    "print (np.mean(a[:,0]/a[:,1]))\n",
    "print (sum(a[:,0])/sum(a[:,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "def eval_policy():\n",
    "    policy_net.eval()\n",
    "    req_inc = 0\n",
    "    render = False\n",
    "    _,acc,_,numTR = test_func(pTest,iloc='fix',eloc='last', fixLoc=2, isdebug=0, req_inc=req_inc)\n",
    "    tr_acc = 0\n",
    "    avg_tr_captured = []\n",
    "    A,P,R,F, ttr = [],[],[],[],[]\n",
    "    Fscore, Fscore_onlytr = [],[]\n",
    "    A_onlytr,P_onlytr,R_onlytr = [],[],[]\n",
    "    nfr = []\n",
    "    for i in range(len(acc)):\n",
    "        print ('Person: ',i)\n",
    "        gt = np.array([d[0] for d in acc[i]])\n",
    "        pr = np.array([d[1] for d in acc[i]])\n",
    "        g = gt #t[gt != num_camera-1]\n",
    "        p = pr #r[gt != num_camera-1]\n",
    "\n",
    "        dups,gt_tr = remove_duplicates(g)\n",
    "        print ('Transitions: ', dups)\n",
    "        print ('GT transitions: ', len(gt_tr))\n",
    "        print ('Transitions captured: ', numTR[i])\n",
    "        if len(gt_tr) != 0:\n",
    "            avg_tr_captured.append((numTR[i],len(gt_tr)))\n",
    "            contains_tr = 1\n",
    "        else:\n",
    "            print ('')\n",
    "            contains_tr = 0\n",
    "            #continue\n",
    "\n",
    "        # plot transitions\n",
    "    #     afc.plot_color_transitions(p,g)\n",
    "        # MCTA and number of frames\n",
    "        if req_inc == 1:\n",
    "            ac,pr,re,fr,tr = afc.compute_APRF_one_person_sct_ict(p,g)\n",
    "        else:\n",
    "            ac,pr,re,fr,tr = afc.compute_APRF_one_person_sct_ict(p,g)\n",
    "\n",
    "        fs = 2*(pr*re)/(pr+re)\n",
    "        if contains_tr == 1:\n",
    "            A_onlytr.append(ac)\n",
    "            P_onlytr.append(pr)\n",
    "            R_onlytr.append(re)\n",
    "            Fscore_onlytr.append(fs)\n",
    "        A.append(ac)\n",
    "        P.append(pr)\n",
    "        R.append(re)\n",
    "        F.append(fr)\n",
    "        Fscore.append(fs) \n",
    "        ttr.append(tr)\n",
    "        print ('A,P,R: ', ac,pr,re)\n",
    "        f = afc.compute_num_frames(p,g)\n",
    "        nfr.append(f)\n",
    "        print ('Num frames: ', f)\n",
    "        # Accuracy\n",
    "        tacc = np.sum(g==p, dtype=np.float)/g.shape[0]\n",
    "        tr_acc += tacc\n",
    "        print ('Accuracy: ',tacc)\n",
    "    print (tr_acc/len(A))\n",
    "    print ('Average (only transitions) A,P,R', np.mean(A_onlytr),np.mean(P_onlytr),np.mean(R_onlytr))\n",
    "    print ('Average (all targets) A,P,R,F, ttr', np.mean(A),np.mean(P),np.mean(R),np.mean(F), ttr)\n",
    "    print ('Fscore (all targets, only transitions) ', np.mean(Fscore),np.mean(Fscore_onlytr))\n",
    "    print (np.sum(nfr))\n",
    "    \n",
    "    a = np.stack(avg_tr_captured)\n",
    "    PCH_1 = np.mean(a[:,0]/a[:,1])\n",
    "    PCH_2 = sum(a[:,0])/sum(a[:,1])\n",
    "    print (PCH_1)\n",
    "    print (PCH_2)\n",
    "    \n",
    "    return np.mean(A),np.mean(P),np.mean(R),np.mean(Fscore),PCH_1,PCH_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./models/policy_duke_semisup_gtBOX_5_41\n",
      "Initial position:  [    7 33839   283   816    96   237]\n",
      "Initial position:  [    0 20939  1851   298    64   194]\n",
      "Initial position:  [     0 122030   1851    427     62    228]\n",
      "Initial position:  [    7 52909   233   811    97   241]\n",
      "Initial position:  [     0 126222   1847    272     68    213]\n",
      "Initial position:  [    7 88687   256   821    94   236]\n",
      "Initial position:  [    5 14238  1589   595    95   239]\n",
      "Initial position:  [    7 99379   268   820    94   237]\n",
      "Initial position:  [     5 145243    137    724    138    344]\n",
      "Initial position:  [     7 142346   1765    763     90    227]\n",
      "Initial position:  [    7 55585  1774   687    95   241]\n",
      "Initial position:  [    1 27254   698   138    67   168]\n",
      "Initial position:  [    7 71533   256   807    99   249]\n",
      "Initial position:  [     7 163928    257    807     99    247]\n",
      "Initial position:  [    5 35783  1568   582    98   248]\n",
      "Initial position:  [    7 18757  1769   726    92   232]\n",
      "Initial position:  [    7 10747   581   816    98   240]\n",
      "Initial position:  [     3 114302   1308    143     41    103]\n",
      "Initial position:  [    5 51780  1580   593    94   239]\n",
      "Initial position:  [     7 125758   1770    741     90    228]\n",
      "Initial position:  [     3 126775   1367    150     38     96]\n",
      "Initial position:  [    5 50079  1527   587    90   228]\n",
      "Initial position:  [    7 59591  1774   741    84   213]\n",
      "Initial position:  [    7 75775  1762   741    96   243]\n",
      "Initial position:  [    7 71377  1760   792    84   211]\n",
      "Initial position:  [    7 63100   205   797   103   262]\n",
      "Initial position:  [    7 51748   189   773   114   283]\n",
      "Initial position:  [    0 86452  1851   244    65   225]\n",
      "Initial position:  [    7 38212  1756   787    92   234]\n",
      "Initial position:  [     5 104275   1621    582    105    265]\n",
      "Initial position:  [     0 128500   1852    369     66    229]\n",
      "Initial position:  [    3 53076  1334   133    45   114]\n",
      "Initial position:  [    3 31131  1362   144    40   102]\n",
      "Initial position:  [    6 40442   842   566    65   166]\n",
      "Initial position:  [    3 49754  1317   129    47   118]\n",
      "Initial position:  [     7 178298   1766    791     83    211]\n",
      "Initial position:  [    7 37635  1752   770    87   221]\n",
      "Initial position:  [    7 25530   249   795   105   265]\n",
      "Initial position:  [    5 62707  1625   627    85   215]\n",
      "Initial position:  [    3 40139  1316   142    41   104]\n",
      "Initial position:  [    1 68048   699   134    68   173]\n",
      "Initial position:  [     7 171919    306    796    103    255]\n",
      "Initial position:  [    3 33956  1326   141    41   105]\n",
      "Initial position:  [     2 180306    973    377     82    208]\n",
      "Initial position:  [     5 132939   1618    619     90    228]\n",
      "Initial position:  [    3 35627  1362   125    48   122]\n",
      "Initial position:  [    7 39756  1764   758    92   233]\n",
      "Initial position:  [     7 141115   1765    728     95    239]\n",
      "Initial position:  [    7 39516  1770   722    91   230]\n",
      "Initial position:  [    7 56053   301   842    85   215]\n",
      "Initial position:  [   5 5929 1587  564  108  273]\n",
      "Initial position:  [    1 69793  1838   522    64   241]\n",
      "Initial position:  [    7 16422  1774   710    82   227]\n",
      "Initial position:  [    7 90579  1810   617    67   169]\n",
      "Initial position:  [     5 154138   1609    597     96    243]\n",
      "Initial position:  [    3 12031  1346   145    40   100]\n",
      "Initial position:  [     0 111401   1846    305     70    183]\n",
      "Initial position:  [    7 69069   283   827    91   229]\n",
      "Initial position:  [     1 165502    704    133     68    173]\n",
      "Initial position:  [    7 43741  1766   744    93   236]\n",
      "Initial position:  [     3 116471   1316    139     42    107]\n",
      "Initial position:  [    0 41577  1857   413    58   211]\n",
      "Initial position:  [     5 106657   1605    618     87    219]\n",
      "Initial position:  [     3 178725   1339    132     45    114]\n",
      "Initial position:  [    6 85878    28   584    59   210]\n",
      "Initial position:  [    7 71244   278   810    98   249]\n",
      "Initial position:  [    5 61726  1598   608    90   228]\n",
      "Initial position:  [    7 86536  1774   742    84   213]\n",
      "Initial position:  [     3 114337   1331    141     42    105]\n",
      "Initial position:  [    5 17895  1605   602    93   236]\n",
      "Initial position:  [   0 6686 1848  421   69  241]\n",
      "Initial position:  [    7 52097   328   819    95   239]\n",
      "Initial position:  [    7 69213  1765   782    89   224]\n",
      "Initial position:  [    5 86360  1626   611    92   233]\n",
      "Initial position:  [     0 140598   1852    570     63    219]\n",
      "Initial position:  [    0 17383  1861   272    52   188]\n",
      "Initial position:  [    7 42595  1776   741    84   213]\n",
      "Initial position:  [     7 179854   1767    789     86    218]\n",
      "Initial position:  [     0 146839   1850    277     67    208]\n",
      "Initial position:  [     1 107958    690    146     63    160]\n",
      "Initial position:  [    0 48829  1862   282    52   196]\n",
      "Initial position:  [     0 127242   1858    286     45    197]\n",
      "Initial position:  [    5 32106  1572   604    88   224]\n",
      "Initial position:  [    3 39690  1337   138    43   108]\n",
      "Initial position:  [    0 54316  1858   280    58   202]\n",
      "Initial position:  [    7 70830  1774   724    88   223]\n",
      "Initial position:  [    1 30775   666   119    75   190]\n",
      "Initial position:  [     0 176900   1859    288     56    198]\n",
      "Initial position:  [    5 61922  1560   607    86   216]\n",
      "Initial position:  [    1 92537   684   122    73   186]\n",
      "Initial position:  [     7 127514   1770    748     85    215]\n",
      "Initial position:  [     7 125896   1778    748     79    200]\n",
      "Initial position:  [    1 53115   735   127    70   177]\n",
      "Initial position:  [     7 129575   1743    716     90    228]\n",
      "Initial position:  [    7 47247   243   819    95   235]\n",
      "Initial position:  [    5 50586  1571   610    86   218]\n",
      "Initial position:  [    4 64386  1814   600    97   306]\n",
      "Initial position:  [     7 132993    263    808     99    251]\n",
      "Initial position:  [    7 35266  1770   728    92   232]\n",
      "Initial position:  [    1 13935   664   131    70   177]\n",
      "Initial position:  [    7 69707  1772   728    91   231]\n",
      "Initial position:  [    0 80698  1842   266    76   218]\n",
      "Initial position:  [    7 57955   205   828    91   226]\n",
      "Initial position:  [    7 98824  1752   745    91   229]\n",
      "Initial position:  [    7 54633   210   804   101   255]\n",
      "Initial position:  [    2 74271   906   370    85   216]\n",
      "Initial position:  [    0 17027  1835   270    81   219]\n",
      "Initial position:  [    7 90458  1754   711    95   242]\n",
      "Initial position:  [     4 100548   1829    603     76    296]\n",
      "Initial position:  [    7 85109   289   792   103   260]\n",
      "Initial position:  [     7 156193    206    803    101    252]\n",
      "Initial position:  [    5 54598  1610   610    91   231]\n",
      "Initial position:  [    7 97697   251   796   104   264]\n",
      "Initial position:  [     5 119098   1592    623     83    209]\n",
      "Initial position:  [     7 118661   1767    735     92    234]\n",
      "Initial position:  [     7 128447   1768    800     84    213]\n",
      "Initial position:  [    7 72742  1798   655    69   184]\n",
      "Initial position:  [    7 61130  1827   515    60   165]\n",
      "Initial position:  [    5 46376  1585   611    87   219]\n",
      "Initial position:  [    7 48089   151   797   103   261]\n",
      "Initial position:  [    7 71335  1757   815    83   209]\n",
      "Initial position:  [     7 102966    268    796    104    263]\n",
      "Initial position:  [    0 64557  1857   264    50   211]\n",
      "Initial position:  [     6 122181     22    594     65    221]\n",
      "Initial position:  [    5 32088  1600   602    93   235]\n",
      "Initial position:  [     5 104827   1597    590     98    248]\n",
      "Initial position:  [    2 79337   939   366    87   220]\n",
      "Initial position:  [    0 27055  1842   298    74   194]\n",
      "Initial position:  [    1 71481  1819   360    93   235]\n",
      "Initial position:  [    4 60060  1830   587    78   284]\n",
      "Initial position:  [    7 70508  1790   660    78   198]\n",
      "Initial position:  [     1 145403    686    126     72    181]\n",
      "Initial position:  [     4 159018   1821    592     94    295]\n",
      "Initial position:  [    2 52210    34   406   108   335]\n",
      "Initial position:  [    0 56439  1856   266    52   212]\n",
      "Initial position:  [    5 62910  1579   588    97   245]\n",
      "Initial position:  [     5 146398   1587    589     97    245]\n",
      "Initial position:  [     7 150609   1770    728     91    231]\n",
      "Initial position:  [    7 52638  1780   704    83   210]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial position:  [   3 3330 1259  702  140  355]\n",
      "Initial position:  [     7 140765    270    798    104    263]\n",
      "Initial position:  [    7 71946  1771   712    93   234]\n",
      "Initial position:  [    5 98438  1606   608    91   231]\n",
      "Initial position:  [     0 115607   1860    310     56    190]\n",
      "Initial position:  [    0 26294  1855   404    56   216]\n",
      "Initial position:  [     7 160954   1773    720     88    222]\n",
      "Initial position:  [    1 54999  1842   362    73   225]\n",
      "Initial position:  [    7 80689  1772   758    83   210]\n",
      "Initial position:  [     7 104443   1766    771     84    214]\n",
      "Initial position:  [     7 127063    244    796    105    264]\n",
      "Initial position:  [    3 49905  1321   142    41   104]\n",
      "Initial position:  [    5 45107  1585   612    87   219]\n",
      "Initial position:  [    7 74864   323   813    97   246]\n",
      "Initial position:  [    7 59765  1771   733    86   218]\n",
      "Initial position:  [    7 30506  1775   715    87   220]\n",
      "Initial position:  [    7 79859  1769   655    78   196]\n",
      "Initial position:  [    6 67191     8   598    82   225]\n",
      "Initial position:  [     5 117590   1619    598     97    245]\n",
      "Initial position:  [    5 41612  1625   605    95   240]\n",
      "Initial position:  [    7 58799   320   800   102   254]\n",
      "Initial position:  [    7 26965  1773   746    85   214]\n",
      "Initial position:  [    1 23716   710   141    65   164]\n",
      "Initial position:  [     5 132066   1601    601    103    260]\n",
      "Initial position:  [    7 35825  1774   739    84   212]\n",
      "Initial position:  [    5 63988  1600   612    89   224]\n",
      "Initial position:  [     0 106220   1856    307     61    195]\n",
      "Initial position:  [     7 161977    237    794    105    265]\n",
      "Initial position:  [     5 115570   1613    603     94    238]\n",
      "Initial position:  [    7 40241  1791   671    77   195]\n",
      "Initial position:  [    2 39192  1017   367    86   218]\n",
      "Initial position:  [   7 8262  174  775  112  284]\n",
      "Initial position:  [    7 74954   250   804    96   242]\n",
      "Initial position:  [     0 135763   1844    298     72    213]\n",
      "Initial position:  [    7 33155  1771   694    96   244]\n",
      "Initial position:  [     7 152065   1769    779     91    231]\n",
      "Initial position:  [    7 52584   260   808    99   245]\n",
      "Initial position:  [    6 56753   953   586    60   151]\n",
      "Initial position:  [   1 3024 1849  353   60  203]\n",
      "Initial position:  [    7 93589   324   801   102   259]\n",
      "Initial position:  [     5 163962     31    704    147    359]\n",
      "Initial position:  [     7 161667   1768    745     91    229]\n",
      "Initial position:  [    7 51063  1775   714    87   220]\n",
      "Initial position:  [    7 31386  1772   722    88   222]\n",
      "Initial position:  [    5 41486  1588   584   100   252]\n",
      "Initial position:  [     0 163079   1850    295     67    206]\n",
      "Initial position:  [    0 56234  1852   277    63   189]\n",
      "Initial position:  [     0 149917   1858    288     57    204]\n",
      "Initial position:  [    3 54985  1347   142    41   103]\n",
      "Initial position:  [    0 17435  1841   273    76   220]\n",
      "Initial position:  [    7 63343   238   819    95   239]\n",
      "Initial position:  [    7 44216  1765   779    88   223]\n",
      "Initial position:  [    7 35538  1819   519    65   183]\n",
      "Initial position:  [    0 77315  1857   282    59   196]\n",
      "Initial position:  [    7 23850   780   385    65   163]\n",
      "Initial position:  [     7 155100   1795    655     73    184]\n",
      "Initial position:  [     0 150740   1858    292     58    192]\n",
      "Initial position:  [    7 68132   763   834    92   232]\n",
      "Initial position:  [    2 66814  1817   549    89   294]\n",
      "Initial position:  [    7 62898  1775   738    84   212]\n",
      "Initial position:  [    7 48017  1778   718    85   214]\n",
      "Initial position:  [    5 27409  1586   619    84   213]\n",
      "Initial position:  [     0 166512   1863    313     41    184]\n",
      "Initial position:  [     1 136622    708    129     70    177]\n",
      "Initial position:  [    3 39549  1383   129    46   117]\n",
      "Initial position:  [     7 107273    239    793    105    262]\n",
      "Initial position:  [     0 127982   1847    283     69    216]\n",
      "Initial position:  [     0 100479   1854    266     51    218]\n",
      "Initial position:  [    2 24525   988   387    78   197]\n",
      "Initial position:  [    3 50863  1330   144    40   102]\n",
      "Initial position:  [    7 21508  1773   712    93   235]\n",
      "Initial position:  [    7 86556   295   800   103   261]\n",
      "Initial position:  [    5 73800  1596   623    83   211]\n",
      "Initial position:  [    7 72146  1767   771    87   221]\n",
      "Initial position:  [    7 25587  1776   737    81   204]\n",
      "Initial position:  [     7 140725    124    780    110    275]\n",
      "Initial position:  [    1 35958  1825   695    75   295]\n",
      "Initial position:  [    7 67475  1670   477    60   152]\n",
      "Initial position:  [    4 45898  1834   372    62   271]\n",
      "Initial position:  [     7 107918   1787    684     81    204]\n",
      "Initial position:  [    0 45928  1850   278    67   215]\n",
      "Initial position:  [    1 54828  1835   495    78   258]\n",
      "Initial position:  [    7 64052  1776   741    81   205]\n",
      "Initial position:  [     5 139252   1442    705    144    364]\n",
      "Initial position:  [    7 79860  1761   754    98   248]\n",
      "Initial position:  [     1 145350    744    135     67    169]\n",
      "Initial position:  [    0 56684  1850   369    59   236]\n",
      "Initial position:  [    7 84379  1770   721    94   237]\n",
      "Initial position:  [     7 163207   1785    655     86    217]\n",
      "Initial position:  [     0 115912   1855    262     62    217]\n",
      "Initial position:  [    0 34724  1843   287    73   198]\n",
      "Initial position:  [    7 48282   271   833    88   223]\n",
      "Initial position:  [     0 118006   1853    285     64    203]\n",
      "Initial position:  [    7 22692   301   796   104   258]\n",
      "Initial position:  [    2 12752   966   366    87   219]\n",
      "Initial position:  [     3 155626   1327    134     45    113]\n",
      "Initial position:  [     3 135687   1317    140     42    107]\n",
      "Initial position:  [     0 154268   1854    264     59    224]\n",
      "Initial position:  [    7 32901   237   824    92   229]\n",
      "Initial position:  [    7 36755  1776   707    89   225]\n",
      "Initial position:  [    5 58715  1577   616    84   212]\n",
      "Initial position:  [    7 59907  1771   718    90   229]\n",
      "Initial position:  [    0 90021  1834   374    78   245]\n",
      "Initial position:  [     0 118078   1837    296     80    219]\n",
      "Initial position:  [    7 79593  1749   755    92   232]\n",
      "Initial position:  [     5 145519   1613    609     92    232]\n",
      "Initial position:  [     5 158482   1585    605     90    227]\n",
      "Initial position:  [     0 117737   1851    403     64    223]\n",
      "Initial position:  [    7 54884  1770   717    90   228]\n",
      "Initial position:  [    7 99877   231   811    98   242]\n",
      "Initial position:  [     0 165071   1856    295     61    193]\n",
      "Initial position:  [    7 71425  1765   751    94   239]\n",
      "Initial position:  [    7 65294  1766   748    91   230]\n",
      "Initial position:  [     3 117204   1329    141     41    105]\n",
      "Initial position:  [     0 121070   1857    277     59    214]\n",
      "Initial position:  [     5 105949   1622    599     97    246]\n",
      "Initial position:  [    6 43766   748   562    65   164]\n",
      "Initial position:  [     0 117717   1837    400     79    215]\n",
      "Initial position:  [    5 49986  1647   615    95   239]\n",
      "Initial position:  [    1 70272  1815   653    98   320]\n",
      "Initial position:  [     5 125537   1651    597    102    258]\n",
      "Initial position:  [     5 117295   1645    616     95    240]\n",
      "Initial position:  [     7 153388   1765    739     90    227]\n",
      "Initial position:  [    7 71287  1773   733    83   211]\n",
      "Initial position:  [    1 87475   692   121    73   185]\n",
      "Initial position:  [    7 44131  1773   749    85   215]\n",
      "Initial position:  [    7 92703  1771   735    86   219]\n",
      "Initial position:  [    7 68956  1731   754    89   224]\n",
      "Initial position:  [     0 123619   1843    265     74    231]\n",
      "Initial position:  [     4 129321   1849     61     62    197]\n",
      "Initial position:  [    7 23055   147   816    96   240]\n",
      "Initial position:  [    2 87009   975   397    74   186]\n",
      "Initial position:  [    7 95334   300   824    93   235]\n",
      "Initial position:  [    3 47394  1313   145    40   101]\n",
      "Initial position:  [    7 77541  1738   777    91   231]\n",
      "Initial position:  [    3 60203  1315   151    38    96]\n",
      "Initial position:  [    7 42343   313   812    98   243]\n",
      "Initial position:  [    7 16215  1774   740    84   212]\n",
      "Initial position:  [    1 48323  1083   710   140   349]\n",
      "Initial position:  [    1 73845   677   126    72   181]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial position:  [    5 94570  1591   590    98   247]\n",
      "Initial position:  [    7 22387   176   818    94   237]\n",
      "Initial position:  [    1 53359   681   126    72   181]\n",
      "Initial position:  [     7 109779   1772    727     88    224]\n",
      "Initial position:  [    0 65115  1841   441    77   246]\n",
      "Initial position:  [    0 34154  1851   285    66   210]\n",
      "Initial position:  [     5 109371   1625    594    100    253]\n",
      "Initial position:  [    1 34868   704   133    68   173]\n",
      "Initial position:  [    7 52640  1775   741    84   213]\n",
      "Initial position:  [    0 70895  1859   271    53   194]\n",
      "Initial position:  [    3 40350  1318   134    44   112]\n",
      "Initial position:  [     0 152068   1857    287     60    191]\n",
      "Initial position:  [    7 94246  1773   726    85   216]\n",
      "Initial position:  [     7 116806   1770    736     87    219]\n",
      "Initial position:  [     1 120840    698    126     72    181]\n",
      "Initial position:  [     7 118899   1765    728     98    247]\n",
      "Initial position:  [    7 77603   172   786   107   272]\n",
      "Initial position:  [    0 18756  1859   288    57   198]\n",
      "Initial position:  [    3 30563  1325   141    41   105]\n",
      "Initial position:  [    0 46691  1855   271    60   219]\n",
      "Initial position:  [     0 176084   1828    276     85    215]\n",
      "Initial position:  [    0 48744  1831   273    85   214]\n",
      "Initial position:  [     7 155706    177    787    108    268]\n",
      "Initial position:  [    5 69618  1587   584   100   252]\n",
      "Initial position:  [     0 110953   1848    290     67    205]\n",
      "Initial position:  [    3 90500  1312   135    44   112]\n",
      "Initial position:  [     0 112394   1848    365     61    242]\n",
      "Initial position:  [     5 165599   1610    609     91    230]\n",
      "Initial position:  [    7 37742  1770   740    87   220]\n",
      "Initial position:  [    2 22942   997   388    78   197]\n",
      "Initial position:  [     5 168614   1614    601     98    247]\n",
      "Initial position:  [    7 76312  1753   779    88   223]\n",
      "Initial position:  [     0 150783   1855    291     62    218]\n",
      "Initial position:  [   0 2936 1108  328   90  228]\n",
      "Initial position:  [    7 52784  1771   729    89   224]\n",
      "Initial position:  [    7 34988  1762   751    91   231]\n",
      "Initial position:  [     4 126310   1830    596     82    268]\n",
      "Initial position:  [    5 86210  1607   597    96   244]\n",
      "Initial position:  [    0 44995  1844   321    69   174]\n",
      "Initial position:  [    0 65213  1857   260    50   216]\n",
      "Initial position:  [     7 119024    266    796    104    255]\n",
      "Initial position:  [     7 113259   1794    649     76    203]\n",
      "Initial position:  [    5 49593  1582   596    93   236]\n",
      "Initial position:  [    6 37542   745   554    68   172]\n",
      "Initial position:  [    6 40877   836   566    65   166]\n",
      "Initial position:  [    7 70522  1782   710    78   197]\n",
      "Initial position:  [     5 117073   1607    597     96    243]\n",
      "Initial position:  [    5 77516  1591   601    92   234]\n",
      "Initial position:  [    5 24072  1597   612    88   224]\n",
      "Initial position:  [     0 153607   1849    267     67    225]\n",
      "Initial position:  [    5 15631  1577   604    89   225]\n",
      "Initial position:  [    1 26205   729   124    72   182]\n",
      "Initial position:  [     7 104376   1762    801     84    214]\n",
      "Initial position:  [     0 117976   1838    280     79    215]\n",
      "Initial position:  [    7 66277  1825   524    61   167]\n",
      "Initial position:  [    7 65620   192   789   107   268]\n",
      "Initial position:  [    3 72906  1313   134    44   112]\n",
      "Initial position:  [    2 42388   887   374    83   210]\n",
      "Initial position:  [    7 23331   264   814    96   237]\n",
      "Initial position:  [     7 128664   1762    751     91    231]\n",
      "Initial position:  [     0 112185   1857    266     45    212]\n",
      "Initial position:  [    5 45718  1568   598    91   229]\n",
      "Initial position:  [     0 158740   1854    273     62    213]\n",
      "Initial position:  [     2 166000    872    369     86    216]\n",
      "Initial position:  [    3 48707  1364   133    45   113]\n",
      "Initial position:  [    3 29237  1319   131    46   115]\n",
      "Initial position:  [     3 174926   1332    135     44    111]\n",
      "Initial position:  [    2 74085   880   349    94   238]\n",
      "Initial position:  [     7 143498    302    799    103    254]\n",
      "Initial position:  [    1 45149   662   135    68   172]\n",
      "Initial position:  [     3 139020   1350    140     42    106]\n",
      "Initial position:  [    7 25674   224   805   100   250]\n",
      "Initial position:  [    0 35283  1851   393    62   227]\n",
      "Initial position:  [    5 52691  1585   583    99   251]\n",
      "Initial position:  [    3 82541  1334   144    40   102]\n",
      "Initial position:  [     7 104764   1777    719     85    214]\n",
      "Initial position:  [     0 124999   1855    269     58    219]\n",
      "Initial position:  [     0 115933   1858    290     57    205]\n",
      "Initial position:  [   7 4071  262  795  104  259]\n",
      "Initial position:  [    6 56742   894   552    72   183]\n",
      "Initial position:  [    3 54967  1319   155    36    90]\n",
      "Initial position:  [     7 141129   1739    770     90    229]\n",
      "Initial position:  [     6 121311    824    577     60    153]\n",
      "Initial position:  [    4 32388    47   233    95   241]\n",
      "Initial position:  [     3 125579   1373    144     40    102]\n",
      "Initial position:  [     7 174000   1768    734     83    211]\n",
      "Initial position:  [    7 24063  1774   722    88   222]\n",
      "Initial position:  [    3 35618  1327   136    44   110]\n",
      "Initial position:  [    7 63058  1773   758    80   202]\n",
      "Initial position:  [    7 36780  1770   722    94   238]\n",
      "Initial position:  [    5 73526  1610   592    99   250]\n",
      "Initial position:  [    0 24016  1837   352    78   232]\n",
      "Initial position:  [    1 99237  1838   395    79   218]\n",
      "Initial position:  [    1 77599   728   136    67   169]\n",
      "Initial position:  [    5 24499  1602   607    91   230]\n",
      "Initial position:  [     7 104571   1765    796     84    212]\n",
      "Initial position:  [    5 75106  1601   607    91   229]\n",
      "Initial position:  [     0 115567   1850    270     67    226]\n",
      "Initial position:  [    0 85753  1850   301    66   182]\n",
      "Initial position:  [     0 112250   1847    293     69    218]\n",
      "Initial position:  [    7 77716  1775   734    83   211]\n",
      "Initial position:  [    7 78798   175   781   110   273]\n",
      "Initial position:  [    5 62622  1588   617    85   215]\n",
      "Initial position:  [    7 63116   332   807   100   251]\n",
      "Initial position:  [    0 16563  1859   290    56   198]\n",
      "Initial position:  [    0 94209  1858   279    51   202]\n",
      "Initial position:  [    3 48284  1327   138    43   108]\n",
      "Initial position:  [    5 22170  1592   583   100   253]\n",
      "Initial position:  [     4 137902     60    176     87    219]\n",
      "Initial position:  [    0 46386  1825   280    78   197]\n",
      "Initial position:  [    7 59990  1770   760    86   218]\n",
      "Initial position:  [    5 31999  1614   604    94   238]\n",
      "Initial position:  [     7 119474   1757    772     97    245]\n",
      "Initial position:  [     5 130465   1609    602     94    237]\n",
      "Initial position:  [     7 116154    542    815     98    247]\n",
      "Initial position:  [    7 96084   248   802   102   258]\n",
      "Initial position:  [    7 65657   125   812    96   242]\n",
      "Initial position:  [    0 88124  1858   277    56   208]\n",
      "Initial position:  [     0 117992   1854    295     63    193]\n",
      "Initial position:  [    3 33560  1312   132    45   115]\n",
      "Initial position:  [    5 65148  1581   567   106   269]\n",
      "Initial position:  [    3 45898  1364   142    41   105]\n",
      "Initial position:  [    5 64798  1587   607    90   227]\n",
      "Initial position:  [    5 61898  1614   609    92   232]\n",
      "Initial position:  [   5 5894 1623  576  110  278]\n",
      "Initial position:  [    7 81047  1753   759    89   225]\n",
      "Initial position:  [    0 40574  1847   281    70   209]\n",
      "Initial position:  [     7 143435    325    800    102    257]\n",
      "Initial position:  [    0 83523  1853   300    63   188]\n",
      "Initial position:  [     2 157527    981    356     91    230]\n",
      "Initial position:  [     3 113343   1325    136     44    110]\n",
      "Initial position:  [    7 68930   289   823    93   233]\n",
      "Initial position:  [     5 151932   1615    587    102    258]\n",
      "Initial position:  [     1 141469    707    141     65    164]\n",
      "Initial position:  [     7 180147   1771    754     86    216]\n",
      "Initial position:  [    5 47546  1607   602    93   236]\n",
      "Initial position:  [    6 40826   916   569    66   167]\n",
      "Initial position:  [     0 123474   1858    285     51    210]\n",
      "Initial position:  [    7 77633  1779   744    79   199]\n",
      "Initial position:  [    5 24856  1599   590    98   248]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial position:  [    6 46717   816   576    60   153]\n",
      "Initial position:  [     0 140380   1845    273     72    214]\n",
      "Initial position:  [    0 52915  1845   265    72   212]\n",
      "Initial position:  [    7 10451  1771   713    93   234]\n",
      "Initial position:  [    7 72591  1797   502    55   138]\n",
      "Initial position:  [     3 155349   1311    140     42    106]\n",
      "Initial position:  [    3 25533  1318   142    41   104]\n",
      "Initial position:  [     7 155700     96    777    112    283]\n",
      "Initial position:  [    1 76928  1839   463    73   243]\n",
      "Initial position:  [    6 56772   801   572    62   157]\n",
      "Initial position:  [     0 117940   1843    272     74    220]\n",
      "Initial position:  [    0 68488  1856   274    50   214]\n",
      "Initial position:  [    7 71045  1758   751    91   231]\n",
      "Initial position:  [    7 53472   260   796   104   256]\n",
      "Initial position:  [    7 49309  1759   704    95   239]\n",
      "Initial position:  [    1 87395   667   132    70   177]\n",
      "Initial position:  [    7 98027   255   796   104   264]\n",
      "Initial position:  [     7 117811    239    820     94    239]\n",
      "Initial position:  [    6 13802    14   588    70   214]\n",
      "Initial position:  [     0 117981   1855    292     59    218]\n",
      "Initial position:  [    7 49719  1826   504    55   140]\n",
      "Initial position:  [    7 60165  1783   689    81   206]\n",
      "Initial position:  [     0 162506   1849    319     67    185]\n",
      "Initial position:  [    7 64749   314   812    97   247]\n",
      "Initial position:  [    0 64396  1847   410    70   224]\n",
      "Initial position:  [     5 106582   1597    596     96    242]\n",
      "Initial position:  [     0 139035   1832    407     83    253]\n",
      "Initial position:  [    1 70896   713   142    65   164]\n",
      "Initial position:  [     5 153896   1651    624     89    226]\n",
      "Initial position:  [     3 146472   1332    141     41    105]\n",
      "Initial position:  [     5 147221   1595    595     95    241]\n",
      "Initial position:  [     0 116927   1848    270     68    213]\n",
      "Initial position:  [    0 44274  1838   283    79   210]\n",
      "Initial position:  [   1 3707 1836  450   77  271]\n",
      "Initial position:  [     0 148983   1849    270     67    219]\n",
      "Initial position:  [    7 75595   133   782   109   276]\n",
      "Initial position:  [    0 41505  1852   439    46   223]\n",
      "Initial position:  [    7 18558  1768   780    82   208]\n",
      "Initial position:  [     0 135668   1860    286     48    197]\n",
      "Initial position:  [    7 69087  1753   731    89   225]\n",
      "Initial position:  [    5 78009  1579   594    94   238]\n",
      "Initial position:  [    7 54742   229   799   103   254]\n",
      "Initial position:  [    5 32212  1575   598    91   230]\n",
      "Initial position:  [     0 135010   1857    276     49    208]\n",
      "Initial position:  [    7 51595  1787   671    82   208]\n",
      "Initial position:  [    7 19867  1772   711    92   234]\n",
      "Initial position:  [    5 81796  1622   623    87   219]\n",
      "Initial position:  [     5 131021   1624    599     97    246]\n",
      "Initial position:  [    7 82694  1764   716    93   235]\n",
      "Initial position:  [    5 44139  1642   619    91   229]\n",
      "Initial position:  [    7 96712  1780   753    77   194]\n",
      "Initial position:  [    5 26104  1573   582    99   249]\n",
      "Initial position:  [     7 136503   1773    739     87    219]\n",
      "Initial position:  [    0 90565  1842   590    74   265]\n",
      "Initial position:  [    3 10345  1355   147    39    98]\n",
      "Initial position:  [    3 59097  1326   133    45   113]\n",
      "Initial position:  [    1 45236   691   130    70   177]\n",
      "Initial position:  [    5 57782  1577   582    99   250]\n",
      "Initial position:  [    0 64014  1858   271    51   207]\n",
      "Initial position:  [     5 126051   1597    574    105    266]\n",
      "Initial position:  [     3 161459   1349    142     41    103]\n",
      "Initial position:  [    5 95863  1622   617    89   225]\n",
      "Initial position:  [    5 35098  1570   592    93   236]\n",
      "Initial position:  [     7 150828   1759    701     91    231]\n",
      "Initial position:  [    3 56746  1332   144    40   102]\n",
      "Initial position:  [    7 96101   323   802   103   259]\n",
      "Initial position:  [     5 155184   1608    574    107    270]\n",
      "Initial position:  [    0 54885  1859   284    51   203]\n",
      "Initial position:  [    1 78599   713   142    65   164]\n",
      "Initial position:  [    1 54997  1843   386    67   224]\n",
      "Initial position:  [    5 52636  1596   607    90   228]\n",
      "Initial position:  [     5 178038   1586    594     94    239]\n",
      "Initial position:  [    7 45993  1822   553    62   162]\n",
      "Initial position:  [    7 56267   287   811    97   243]\n",
      "Initial position:  [    7 34355  1771   727    88   224]\n",
      "Initial position:  [    5 21129  1619   580   105   265]\n",
      "Initial position:  [     0 148176   1851    373     65    223]\n",
      "Initial position:  [    5 32134  1618   610    92   232]\n",
      "Initial position:  [     5 115274   1596    601     93    235]\n",
      "Initial position:  [    3 97565  1324   131    46   116]\n",
      "Initial position:  [     5 125619   1612    603     94    238]\n",
      "Initial position:  [    2 57037   970   382    80   203]\n",
      "Initial position:  [     1 149921    692    139     67    169]\n",
      "Initial position:  [    0 31571  1848   310    67   196]\n",
      "Initial position:  [    0 78543  1854   268    56   218]\n",
      "Initial position:  [    7 51667  1774   710    86   219]\n",
      "Initial position:  [     5 107824   1604    602     94    237]\n",
      "Initial position:  [    5 83722  1635   612    93   236]\n",
      "Initial position:  [     7 134363   1770    794     84    212]\n",
      "Initial position:  [     5 117211   1645    613     94    237]\n",
      "Initial position:  [    7 72043  1760   777    94   239]\n",
      "Initial position:  [    3 95085  1328   144    40   102]\n",
      "Initial position:  [    7 39780   268   815    96   244]\n",
      "Initial position:  [    7 75668    81   774   113   283]\n",
      "Initial position:  [     7 173603   1764    768     93    236]\n",
      "Initial position:  [    7 49686  1822   563    55   159]\n",
      "Initial position:  [    3 52946  1356   142    41   104]\n",
      "Initial position:  [     7 178352   1773    744     84    213]\n",
      "Initial position:  [    0 31496  1854   279    51   221]\n",
      "Initial position:  [    7 10406  1760   751    94   239]\n",
      "Initial position:  [    5 94973  1591   611    88   222]\n",
      "Initial position:  [    5 79272  1626   593   100   253]\n",
      "Initial position:  [    5 49858  1609   619    86   219]\n",
      "Initial position:  [    7 77380   108   812    98   247]\n",
      "Initial position:  [    5 40374  1558   565   104   262]\n",
      "Initial position:  [     0 135085   1852    315     63    197]\n",
      "Initial position:  [     7 124538     90    775    112    279]\n",
      "Initial position:  [     0 123143   1832    416     84    212]\n",
      "Initial position:  [    1 65544   680   134    68   172]\n",
      "Initial position:  [    2 25392   999   382    80   202]\n",
      "Initial position:  [    7 18306  1771   716    90   228]\n",
      "Initial position:  [    7 67716  1774   729    86   217]\n",
      "Initial position:  [    7 28005   311   831    90   226]\n",
      "Initial position:  [    5 31697  1591   622    83   209]\n",
      "Initial position:  [     5 168949   1643    624     89    225]\n",
      "Initial position:  [    7 85423  1770   752    85   216]\n",
      "Initial position:  [     5 175732   1638    595    101    255]\n",
      "Initial position:  [    7 75919   232   811    97   241]\n",
      "Initial position:  [    5 64996  1611   608    92   232]\n",
      "Initial position:  [    7 98494  1762   743    97   244]\n",
      "Initial position:  [    5 63936  1652   625    89   226]\n",
      "Initial position:  [     0 126368   1851    300     65    207]\n",
      "Initial position:  [    5 80925  1589   595    95   240]\n",
      "Initial position:  [    7 89764   135   815    96   242]\n",
      "Initial position:  [     7 119009   1771    746     88    222]\n",
      "Initial position:  [     1 142107    709    146     63    160]\n",
      "Initial position:  [     0 150015   1841    411     64    232]\n",
      "Initial position:  [    3 61636  1338   138    43   109]\n",
      "Initial position:  [    5 27327  1571   610    86   217]\n",
      "Initial position:  [   1 5726  671  127   72  181]\n",
      "Initial position:  [    7 40941   340   802   102   253]\n",
      "Initial position:  [    5 20679  1592   590   103   261]\n",
      "Initial position:  [    0 23026  1847   365    62   249]\n",
      "Initial position:  [    5 83535  1594   617    86   216]\n",
      "Initial position:  [    7 42121   192   816    96   243]\n",
      "Initial position:  [    7 61425   254   819    94   237]\n",
      "Initial position:  [   0 2936  979  330  102  257]\n",
      "Initial position:  [    7 54911   262   807    99   246]\n",
      "Initial position:  [    0 20148  1822   266    92   232]\n",
      "Initial position:  [    7 34212  1771   717    93   236]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial position:  [    0 52499  1857   278    50   208]\n",
      "Initial position:  [    5 90224  1620   587   102   258]\n",
      "Initial position:  [     7 179445    236    798    102    254]\n",
      "Initial position:  [    1 77723   710   146    63   160]\n",
      "Initial position:  [     7 137022   1768    752     91    231]\n",
      "Initial position:  [     7 172260   1768    712     93    234]\n",
      "Initial position:  [    0 35281  1830   285    83   210]\n",
      "Initial position:  [    3 44488  1337   140    42   106]\n",
      "Initial position:  [    7 40227  1799   651    72   183]\n",
      "Initial position:  [     7 107472   1772    726     85    216]\n",
      "Initial position:  [    0 58943  1855   270    62   213]\n",
      "Initial position:  [    7 50956  1771   741    87   220]\n",
      "Initial position:  [    3 50710  1321   144    40   102]\n",
      "Initial position:  [    0 79349  1855   295    61   187]\n",
      "Initial position:  [    5 62032  1589   595    95   240]\n",
      "Initial position:  [    0 42591  1830   743    77   311]\n",
      "Initial position:  [    5 51175  1583   594    94   239]\n",
      "Initial position:  [     7 138003   1755    488     59    148]\n",
      "Initial position:  [    1 35136   706   133    68   173]\n",
      "Initial position:  [     5 120661   1590    584    100    252]\n",
      "Initial position:  [    3 60114  1322   161    33    84]\n",
      "Initial position:  [    3 39140  1317   134    44   112]\n",
      "Initial position:  [     0 106172   1853    318     64    211]\n",
      "Initial position:  [     7 154705   1797    679     70    176]\n",
      "Initial position:  [    5 48228  1628   617    90   226]\n",
      "Initial position:  [     4 127771   1808    580    102    293]\n",
      "Initial position:  [     7 141674    427    818     96    243]\n",
      "Initial position:  [     0 152149   1854    298     58    213]\n",
      "Initial position:  [    7 24816   259   805   100   251]\n",
      "Initial position:  [    7 39886  1803   625    73   183]\n",
      "Initial position:  [     5 121351   1628    612     92    233]\n",
      "Initial position:  [   7 2936 1020  380   73  185]\n",
      "Initial position:  [    1 83297  1840   404    75   228]\n",
      "Initial position:  [    0 74550  1840   377    74   231]\n",
      "Initial position:  [    0 81401  1854   308    63   202]\n",
      "Initial position:  [     0 118478   1854    282     57    216]\n",
      "Initial position:  [    7 65703   273   816    96   236]\n",
      "Initial position:  [    1 38435   646   120    75   189]\n",
      "Initial position:  [     0 107765   1848    267     68    212]\n",
      "Initial position:  [     7 119408   1773    734     86    218]\n",
      "Initial position:  [     0 112350   1845    278     72    215]\n",
      "Initial position:  [    3 47912  1324   144    40   102]\n",
      "Initial position:  [     7 177708   1767    773     88    222]\n",
      "Initial position:  [    7 80730   891   806   103   261]\n",
      "Initial position:  [     7 128624   1766    778     88    223]\n",
      "Initial position:  [     7 112135    298    815     95    239]\n",
      "Initial position:  [    0 61203  1846   402    70   209]\n",
      "Initial position:  [    2 90332   972   387    78   197]\n",
      "Initial position:  [    7 21793   329   807   100   250]\n",
      "Initial position:  [     6 101401     23    587     65    213]\n",
      "Initial position:  [    7 46410  1770   702    82   231]\n",
      "Initial position:  [    7 58941  1778   758    77   195]\n",
      "Initial position:  [    5 57696  1581   610    87   220]\n",
      "Initial position:  [     7 163009    212    831     88    218]\n",
      "Initial position:  [    0 45335  1848   374    68   230]\n",
      "Initial position:  [    1 49033   708   138    67   169]\n",
      "Initial position:  [   7 3204  771  379   68  172]\n",
      "Initial position:  [    7 70766  1769   756    89   224]\n",
      "Initial position:  [    1 97620   682   136    68   173]\n",
      "Initial position:  [    5 50686  1598   607    90   229]\n",
      "Initial position:  [    7 33747  1771   750    82   208]\n",
      "Initial position:  [     1 113456   1608    774    113    280]\n",
      "Initial position:  [     7 147282   1760    765     93    235]\n",
      "Initial position:  [    5 78156  1582   583    99   251]\n",
      "Initial position:  [     7 127497   1802    563     65    175]\n",
      "Initial position:  [    1 76933   723   138    67   169]\n",
      "Initial position:  [    7 92698  1769   778    82   208]\n",
      "Initial position:  [     0 146957   1853    289     65    224]\n",
      "Initial position:  [     0 112504   1843    265     74    212]\n",
      "Initial position:  [    3 40252  1339   134    44   111]\n",
      "Initial position:  [    7 36023  1773   711    85   227]\n",
      "Initial position:  [    7 58933   129   806    99   243]\n",
      "Initial position:  [    7 52705   241   784   109   270]\n",
      "Initial position:  [    3 50066  1336   140    42   106]\n",
      "Initial position:  [     7 127540    181    815     96    244]\n",
      "Initial position:  [   3 3352 1413  698  140  353]\n",
      "Initial position:  [     7 100354   1763    733     98    249]\n",
      "Initial position:  [     7 100049   1769    723     94    238]\n",
      "Initial position:  [     0 126858   1851    427     56    228]\n",
      "Initial position:  [     7 142598   1767    724     94    238]\n",
      "Initial position:  [    7 62856   267   795   104   255]\n",
      "Initial position:  [    7 75788   218   817    95   237]\n",
      "Initial position:  [    7 56391   371   834    89   222]\n",
      "Initial position:  [    7 45475   289   823    93   236]\n",
      "Initial position:  [    7 84614  1766   730    86   217]\n",
      "Initial position:  [    3 39602  1330   130    46   116]\n",
      "Initial position:  [    3 42724  1367   136    44   110]\n",
      "Initial position:  [     7 143129   1759    736     99    250]\n",
      "Initial position:  [     7 141722   1765    781     85    216]\n",
      "Initial position:  [    0 39197  1849   402    63   244]\n",
      "Initial position:  [    5 78441  1598   617    86   218]\n",
      "Initial position:  [     7 115978    148    785    108    274]\n",
      "Initial position:  [     0 123239   1855    391     61    206]\n",
      "Initial position:  [    1 70071   626   718   137   339]\n",
      "Initial position:  [    5 74610  1588   600    92   234]\n",
      "Initial position:  [    7 20809   295   811    98   248]\n",
      "Initial position:  [    7 29789  1765   744    97   245]\n",
      "Initial position:  [    7 23818  1829   495    57   160]\n",
      "Initial position:  [    0 87059  1847   265    69   224]\n",
      "Initial position:  [     3 115168   1352    145     40    101]\n",
      "Initial position:  [     3 136441   1365    144     40    102]\n",
      "Initial position:  [     5 130619   1599    607     91    229]\n",
      "Initial position:  [     5 153055   1617    620     87    220]\n",
      "Initial position:  [    4 32208    50   214    82   208]\n",
      "Initial position:  [     2 111431    918    391     76    193]\n",
      "Initial position:  [     7 178213   1771    761     83    211]\n",
      "Initial position:  [   5 8510 1620  604   95  239]\n",
      "Initial position:  [     0 135733   1847    265     69    218]\n",
      "Initial position:  [     7 106056   1829    495     59    149]\n",
      "Initial position:  [     7 123157   1771    742     87    221]\n",
      "Initial position:  [    7 68069   480   837    89   219]\n",
      "Initial position:  [    7 86404  1743   733    83   210]\n",
      "Initial position:  [    0 78520  1839   373    77   216]\n",
      "Initial position:  [    1 36683   680   142    65   164]\n",
      "Initial position:  [    1 43823  1828   390    81   223]\n",
      "Initial position:  [    2 87117   990   387    78   197]\n",
      "Initial position:  [   5 6278 1626  606   95  239]\n",
      "Initial position:  [     0 112442   1848    395     68    221]\n",
      "Initial position:  [   0 6324 1862  333   55  157]\n",
      "Initial position:  [    5 29635  1583   588    97   245]\n",
      "Initial position:  [     0 110296   1853    261     52    223]\n",
      "Initial position:  [    7 59921  1726   724   104   262]\n",
      "Initial position:  [    2 18617  1021   388    78   196]\n",
      "Initial position:  [     1 172874    697    126     72    182]\n",
      "Initial position:  [    7 62419   255   813    96   244]\n",
      "Initial position:  [    0 18335  1853   393    53   220]\n",
      "Initial position:  [    7 68228   276   822    93   236]\n",
      "Initial position:  [    0 92224  1844   437    73   216]\n",
      "Initial position:  [     7 180154   1765    794     87    219]\n",
      "Initial position:  [    3 29938  1329   147    39    99]\n",
      "Initial position:  [    5 44485  1633   606    95   241]\n",
      "Initial position:  [    7 22423  1770   708    87   233]\n",
      "Initial position:  [    0 79870  1849   278    68   208]\n",
      "Initial position:  [     7 140565    293    798    103    256]\n",
      "Initial position:  [    7 71489  1777   725    85   216]\n",
      "Initial position:  [    0 49026  1863   294    52   187]\n",
      "Initial position:  [    3 66631  1343   140    42   106]\n",
      "Initial position:  [    7 50865   283   798   103   259]\n",
      "Initial position:  [    0 69593  1848   359    68   227]\n",
      "Initial position:  [    5 65260  1632   623    88   223]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial position:  [    7 36130   333   802   102   258]\n",
      "Initial position:  [     7 161987    321    799    102    259]\n",
      "Initial position:  [    7 74844   209   835    88   219]\n",
      "Initial position:  [    7 64913   296   817    96   238]\n",
      "Initial position:  [    7 83758  1773   722    85   215]\n",
      "Initial position:  [     7 114940    298    799    103    253]\n",
      "Initial position:  [     7 119019   1742    789     83    211]\n",
      "Initial position:  [    7 68033  1773   732    89   225]\n",
      "Initial position:  [    5 66852  1591   606    90   228]\n",
      "Initial position:  [    0 35934  1821   401    85   216]\n",
      "Initial position:  [    0 48752  1800   243    82   207]\n",
      "Initial position:  [    7 19158  1769   750    85   215]\n",
      "Initial position:  [    7 74702  1770   731    89   225]\n",
      "Initial position:  [    5 71972  1629   627    85   216]\n",
      "Initial position:  [    5 25150  1615   611    91   230]\n",
      "Initial position:  [     7 136996   1767    718     87    221]\n",
      "Initial position:  [     7 136413    294    799    103    257]\n",
      "Initial position:  [    7 51680  1769   762    86   218]\n",
      "Initial position:  [    1 45297   687   138    66   168]\n",
      "Initial position:  [     0 126555   1851    435     63    230]\n",
      "Initial position:  [     7 156391   1790    646     67    202]\n",
      "Initial position:  [    3 14647  1330   144    40   102]\n",
      "Initial position:  [    0 27413  1839   273    77   207]\n",
      "Initial position:  [    7 74299  1773   729    86   217]\n",
      "Initial position:  [    7 64894   182   810    96   243]\n",
      "Initial position:  [    6 40760   884   567    66   166]\n",
      "Initial position:  [    0 18718  1836   318    76   192]\n",
      "Initial position:  [    7 69023  1771   763    83   211]\n",
      "Initial position:  [    7 23469   216   804   101   249]\n",
      "Initial position:  [    5 58669  1640   631    85   215]\n",
      "Initial position:  [     2 168117    931    360     89    226]\n",
      "Initial position:  [    5 14492  1602   602    93   236]\n",
      "Initial position:  [    3 60209  1343   143    41   103]\n",
      "Initial position:  [    7 77309  1779   734    80   203]\n",
      "Initial position:  [    7 72000  1766   732    95   241]\n",
      "Initial position:  [     7 142105   1767    729     92    232]\n",
      "Initial position:  [    3 35205  1314   147    39    98]\n",
      "Initial position:  [    0 68668  1847   371    69   216]\n",
      "Initial position:  [     7 112415   1775    735     83    211]\n",
      "Initial position:  [     0 109657   1851    304     66    208]\n",
      "Initial position:  [     0 117016   1857    270     56    213]\n",
      "Initial position:  [    1 27362   703   142    65   165]\n",
      "Initial position:  [    5 70633  1595   608    90   228]\n",
      "Initial position:  [    0 83934  1855   260    51   217]\n",
      "Initial position:  [    7 95539  1771   723    85   215]\n",
      "Initial position:  [    5 21015  1604   603    93   235]\n",
      "Initial position:  [     7 126922     91    776    112    283]\n",
      "Initial position:  [    0 94156  1853   270    64   219]\n",
      "Initial position:  [     3 116110   1319    139     42    107]\n",
      "Initial position:  [    7 45285  1775   713    87   219]\n",
      "Initial position:  [    3 32073  1364   141    41   104]\n",
      "Initial position:  [    7 96777  1776   746    82   207]\n",
      "Initial position:  [    0 87701  1848   283    69   197]\n",
      "Initial position:  [    5 54607  1586   589    97   246]\n",
      "Initial position:  [    1 10195   689   142    65   164]\n",
      "Initial position:  [    5 49490  1561   613    84   211]\n",
      "Initial position:  [     7 142365   1770    731     89    225]\n",
      "Initial position:  [     7 117659   1792    636     69    199]\n",
      "Initial position:  [     7 166679    285    797    103    255]\n",
      "Initial position:  [     7 144374   1776    746     82    206]\n",
      "Initial position:  [    3 79709  1346   137    43   109]\n",
      "Initial position:  [    5 54923  1574   599    91   230]\n",
      "Initial position:  [    3 61384  1329   154    36    91]\n",
      "Initial position:  [    0 81761  1860   294    45   193]\n",
      "Initial position:  [    7 97782   235   794   105   266]\n",
      "Initial position:  [    4 17339  1835   488    78   251]\n",
      "Initial position:  [     0 179814   1849    292     68    199]\n",
      "Initial position:  [    1 27557   553   710   140   346]\n",
      "Initial position:  [     7 138884   1762    768     93    236]\n",
      "Initial position:  [    7 25597  1743   750    88   223]\n",
      "Initial position:  [     0 127776   1853    287     63    204]\n",
      "Initial position:  [    5 33474  1564   586    95   241]\n",
      "Initial position:  [    5 43023  1577   598    92   232]\n",
      "Initial position:  [    5 52565  1575   620    82   208]\n",
      "Initial position:  [    5 36403  1583   610    87   221]\n",
      "Initial position:  [    5 91738  1657   615    95   240]\n",
      "Initial position:  [    0 68668  1824   288    78   198]\n",
      "Initial position:  [    7 53221  1787   681    78   197]\n",
      "Initial position:  [    1 87622   706   154    60   151]\n",
      "Initial position:  [     5 136988   1611    614     89    225]\n",
      "Initial position:  [    4 59486  1830   580    70   283]\n",
      "Initial position:  [     6 144436    871    563     67    171]\n",
      "Initial position:  [    5 27643  1605   591    98   249]\n",
      "Initial position:  [    5 57873  1579   593    94   238]\n",
      "Initial position:  [     7 140566    148    771    114    283]\n",
      "Initial position:  [    0 47253  1843   257    74   229]\n",
      "Initial position:  [     1 126778    681    138     66    168]\n",
      "Initial position:  [    7 58097   263   796   104   258]\n",
      "Initial position:  [    0 75069  1835   281    80   203]\n",
      "Initial position:  [     5 165299   1594    600     93    235]\n",
      "Initial position:  [     7 143524   1771    717     93    236]\n",
      "Initial position:  [    7 12136  1766   738    93   235]\n",
      "Initial position:  [    5 56634  1594   606    91   229]\n",
      "Initial position:  [    0 52598  1819   280    83   209]\n",
      "Initial position:  [    3 55961  1305   133    45   114]\n",
      "Initial position:  [    5 17818  1637   623    89   224]\n",
      "Initial position:  [    3 21392  1323   142    41   104]\n",
      "Initial position:  [    7 71677  1775   739    87   220]\n",
      "Initial position:  [    7 61498   281   797   104   262]\n",
      "Initial position:  [    0 86048   439   734   132   333]\n",
      "Initial position:  [    7 93112  1764   759    92   233]\n",
      "Initial position:  [    7 17749   346   826    92   227]\n",
      "Initial position:  [     3 108036   1373    141     41    105]\n",
      "Initial position:  [    3 74618  1316   134    44   112]\n",
      "Initial position:  [    3 84873  1309   138    43   109]\n",
      "Initial position:  [    7 11198  1770   765    84   212]\n",
      "Initial position:  [    0 40963  1852   291    65   186]\n",
      "Initial position:  [    0 56732  1845   397    71   236]\n",
      "Initial position:  [    7 70996  1762   741    96   244]\n",
      "Initial position:  [    7 82500  1762   758    83   210]\n",
      "Initial position:  [    5 70558  1575   610    86   219]\n",
      "Initial position:  [    1 94121  1834   611    79   284]\n",
      "Initial position:  [    7 88404  1770   727    88   224]\n",
      "Initial position:  [    7 72611  1726   472    65   163]\n",
      "Initial position:  [    0 77203  1853   282    63   197]\n",
      "Initial position:  [    7 66042   208   810    98   244]\n",
      "Initial position:  [    5 40703  1586   612    87   220]\n",
      "Initial position:  [    7 56532  1777   747    82   207]\n",
      "Initial position:  [    2 33528   957   346    96   242]\n",
      "Initial position:  [   5 8372 1601  597   95  241]\n",
      "Initial position:  [    5 18505  1628   594   100   254]\n",
      "Initial position:  [     5 165405   1631    633     83    210]\n",
      "Initial position:  [     0 118350   1857    288     60    210]\n",
      "Initial position:  [     0 114350   1855    290     61    205]\n",
      "Initial position:  [    3 50386  1328   128    47   119]\n",
      "Initial position:  [    2 74059   956   371    85   214]\n",
      "Initial position:  [     1 105420   1838    351     73    236]\n",
      "Initial position:  [     0 129312   1862    297     44    187]\n",
      "Initial position:  [    1 76808   696   131    70   177]\n",
      "Initial position:  [    7 49807  1826   551    62   156]\n",
      "Initial position:  [    5 22944  1588   571   105   265]\n",
      "Initial position:  [    0 27959  1840   529    67   284]\n",
      "Initial position:  [    7 96719   310   811    98   243]\n",
      "Initial position:  [     5 140952   1619    593     99    252]\n",
      "Initial position:  [     7 123212   1700    490     56    142]\n",
      "Initial position:  [     7 119719   1749    730     89    224]\n",
      "Initial position:  [     7 112374   1757    768     93    236]\n",
      "Initial position:  [    5 47167  1600   613    88   224]\n",
      "Initial position:  [     7 173545   1761    788     89    226]\n",
      "Initial position:  [     7 129356   1774    722     88    222]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial position:  [    5 45227  1354   741   129   320]\n",
      "Initial position:  [    1 88455  1836   342    63   241]\n",
      "Initial position:  [     0 124191   1857    372     61    209]\n",
      "Initial position:  [    4 29735  1825   593    87   294]\n",
      "Initial position:  [    7 81443  1775   737    84   212]\n",
      "Initial position:  [    7 73503   288   819    93   235]\n",
      "Initial position:  [     0 116262   1855    278     61    208]\n",
      "Initial position:  [     7 154512   1771    741     87    220]\n",
      "Initial position:  [    0 67792  1841   423    74   242]\n",
      "Initial position:  [    7 17010  1770   740    87   220]\n",
      "Initial position:  [     7 152030   1774    767     84    212]\n",
      "Initial position:  [     3 102896   1310    129     46    117]\n",
      "Initial position:  [     7 177780   1770    713     93    234]\n",
      "Initial position:  [     5 115485   1627    616     90    229]\n",
      "Initial position:  [     7 141449   1738    745     82    206]\n",
      "Initial position:  [    7 71499  1771   759    86   218]\n",
      "Initial position:  [    3 13496  1321   139    42   107]\n",
      "Initial position:  [     0 153733   1854    284     52    216]\n",
      "Initial position:  [    5 57932  1593   612    88   222]\n",
      "Initial position:  [     0 147024   1860    301     56    201]\n",
      "Initial position:  [     7 110976    221    791    106    264]\n",
      "Initial position:  [    0 75443  1847   283    70   203]\n",
      "Initial position:  [    1 80147   727   716   138   344]\n",
      "Initial position:  [    7 22404   262   827    91   229]\n",
      "Initial position:  [    0 18837  1843   300    73   207]\n",
      "Initial position:  [    7 60466   294   830    90   223]\n",
      "Initial position:  [    7 50971   315   800   103   259]\n",
      "Initial position:  [     5 155228   1604    585    101    256]\n",
      "Initial position:  [    7 17639   303   830    90   224]\n",
      "Initial position:  [    7 13990   283   804   101   255]\n",
      "Initial position:  [    0 15884  1838   288    78   211]\n",
      "Initial position:  [    5 58572  1633   617    90   229]\n",
      "Initial position:  [     0 113261   1842    359     74    241]\n",
      "Initial position:  [    5 79123  1609   603    94   237]\n",
      "Initial position:  [     7 179533    277    796    104    259]\n",
      "Initial position:  [     7 131403    314    837     88    217]\n",
      "Initial position:  [     1 121912   1857    463     48    144]\n",
      "Initial position:  [    5 24562  1607   591    99   250]\n",
      "Initial position:  [     7 118159   1774    718     87    221]\n",
      "Initial position:  [    2 70312  1010   357    91   229]\n",
      "Initial position:  [     3 129497   1360    142     41    104]\n",
      "Initial position:  [     5 156094   1627    600     98    248]\n",
      "Initial position:  [     5 143986     26    740    132    332]\n",
      "Initial position:  [    7 55189  1801   655    70   178]\n",
      "Initial position:  [    7 69235   111   802   100   252]\n",
      "Initial position:  [     7 119095   1727    733     83    210]\n",
      "Initial position:  [     5 132125   1624    617     89    226]\n",
      "Initial position:  [    5 67503  1626   610    92   234]\n",
      "Initial position:  [     3 157001   1339    135     44    111]\n",
      "Initial position:  [    5 44516  1565   603    88   222]\n",
      "Initial position:  [    0 44330  1858   295    59   206]\n",
      "Initial position:  [    7 34704  1772   733    86   218]\n",
      "Initial position:  [     7 169515   1759    731     86    217]\n",
      "Initial position:  [    7 65763   255   815    97   243]\n",
      "Initial position:  [     7 145157   1777    757     80    202]\n",
      "Initial position:  [     7 152424    251    796    104    260]\n",
      "Initial position:  [    7 17838   292   820    94   233]\n",
      "Initial position:  [     0 146821   1849    291     68    199]\n",
      "Initial position:  [   1 2936 1061  418  103  260]\n",
      "Initial position:  [    7 67637   210   791   106   268]\n",
      "Initial position:  [     7 173541   1747    724     88    223]\n",
      "Initial position:  [     7 117265   1735    709     89    226]\n",
      "Initial position:  [     7 141786   1766    740     96    243]\n",
      "Initial position:  [     7 110551    310    818     95    235]\n",
      "Initial position:  [    1 44336   686   130    70   177]\n",
      "Initial position:  [    5 49380  1567   581    98   249]\n",
      "Initial position:  [     0 114601   1851    402     65    229]\n",
      "Person:  0\n",
      "Transitions:  [7, 8, 0, 8]\n",
      "GT transitions:  1\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.954227590591227 0.9159763313609467 0.9987096774193548\n",
      "Num frames:  (845, 71)\n",
      "Accuracy:  0.954227590591227\n",
      "Person:  1\n",
      "Transitions:  [0, 8, 1, 8]\n",
      "GT transitions:  1\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.716551724137931 0.7619047619047619 0.5075528700906344\n",
      "Num frames:  (441, 85)\n",
      "Accuracy:  0.716551724137931\n",
      "Person:  2\n",
      "Transitions:  [0, 8, 1, 8, 4, 8, 5, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.3956899131996408 0.17486604968339017 0.2610909090909091\n",
      "Num frames:  (2053, 1003)\n",
      "Accuracy:  0.3956899131996408\n",
      "Person:  3\n",
      "Transitions:  [7, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.9551724137931035 0.9551724137931035 0.9584775086505191\n",
      "Num frames:  (290, 1)\n",
      "Accuracy:  0.9551724137931035\n",
      "Person:  4\n",
      "Transitions:  [0, 8, 1, 8]\n",
      "GT transitions:  1\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.745839636913767 0.9093567251461988 0.48822605965463106\n",
      "Num frames:  (342, 10)\n",
      "Accuracy:  0.745839636913767\n",
      "Person:  5\n",
      "Transitions:  [7, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.9560439560439561 0.9560439560439561 0.9595588235294118\n",
      "Num frames:  (273, 1)\n",
      "Accuracy:  0.9560439560439561\n",
      "Person:  6\n",
      "Transitions:  [5, 8, 6, 8, 7, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.8976660682226212 0.8475935828877005 1.0\n",
      "Num frames:  (1122, 171)\n",
      "Accuracy:  0.8976660682226212\n",
      "Person:  7\n",
      "Transitions:  [7, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.9958847736625515 0.9958847736625515 1.0\n",
      "Num frames:  (243, 1)\n",
      "Accuracy:  0.9958847736625515\n",
      "Person:  8\n",
      "Transitions:  [5, 8, 4, 8]\n",
      "GT transitions:  1\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.9417098445595855 0.939589943861362 1.0\n",
      "Num frames:  (8194, 495)\n",
      "Accuracy:  0.9417098445595855\n",
      "Person:  9\n",
      "Transitions:  [7, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.9418181818181818 0.9418181818181818 0.9452554744525548\n",
      "Num frames:  (275, 1)\n",
      "Accuracy:  0.9418181818181818\n",
      "Person:  10\n",
      "Transitions:  [7, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.9310344827586207 0.9310344827586207 0.9333333333333333\n",
      "Num frames:  (406, 1)\n",
      "Accuracy:  0.9310344827586207\n",
      "Person:  11\n",
      "Transitions:  [1, 8, 0, 8]\n",
      "GT transitions:  1\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.9644238205723125 0.9412568306010929 0.9871060171919771\n",
      "Num frames:  (732, 37)\n",
      "Accuracy:  0.9644238205723125\n",
      "Person:  12\n",
      "Transitions:  [7, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.9966555183946488 0.9966555183946488 1.0\n",
      "Num frames:  (299, 1)\n",
      "Accuracy:  0.9966555183946488\n",
      "Person:  13\n",
      "Transitions:  [7, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.9965870307167235 0.9965870307167235 1.0\n",
      "Num frames:  (293, 1)\n",
      "Accuracy:  0.9965870307167235\n",
      "Person:  14\n",
      "Transitions:  [5, 8, 4, 8, 2, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.8881376767055931 0.8613861386138614 1.0\n",
      "Num frames:  (1313, 182)\n",
      "Accuracy:  0.8881376767055931\n",
      "Person:  15\n",
      "Transitions:  [7, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.9513888888888888 0.9513888888888888 0.9547038327526133\n",
      "Num frames:  (288, 1)\n",
      "Accuracy:  0.9513888888888888\n",
      "Person:  16\n",
      "Transitions:  [7, 8, 0, 8]\n",
      "GT transitions:  1\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.8142857142857143 0.988795518207283 0.664783427495292\n",
      "Num frames:  (357, 4)\n",
      "Accuracy:  0.8142857142857143\n",
      "Person:  17\n",
      "Transitions:  [3, 8, 2, 8, 1, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.9484978540772532 0.9937655860349127 0.9224537037037037\n",
      "Num frames:  (802, 5)\n",
      "Accuracy:  0.9484978540772532\n",
      "Person:  18\n",
      "Transitions:  [5, 8, 4, 8, 2, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.8502072232089994 0.8151935719503287 1.0\n",
      "Num frames:  (1369, 253)\n",
      "Accuracy:  0.8502072232089994\n",
      "Person:  19\n",
      "Transitions:  [7, 8, 6, 8, 5, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.5169022741241549 0.3328785811732606 0.2601279317697228\n",
      "Num frames:  (733, 92)\n",
      "Accuracy:  0.5169022741241549\n",
      "Person:  20\n",
      "Transitions:  [3, 8, 2, 8, 1, 8, 0, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.9487004103967168 0.9117647058823529 1.0\n",
      "Num frames:  (1700, 150)\n",
      "Accuracy:  0.9487004103967168\n",
      "Person:  21\n",
      "Transitions:  [5, 8, 4, 8, 0, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.8097771865646824 0.6684057971014493 1.0\n",
      "Num frames:  (1725, 572)\n",
      "Accuracy:  0.8097771865646824\n",
      "Person:  22\n",
      "Transitions:  [7, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.9602888086642599 0.9602888086642599 0.9637681159420289\n",
      "Num frames:  (277, 1)\n",
      "Accuracy:  0.9602888086642599\n",
      "Person:  23\n",
      "Transitions:  [7, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.953405017921147 0.953405017921147 0.9568345323741008\n",
      "Num frames:  (279, 1)\n",
      "Accuracy:  0.953405017921147\n",
      "Person:  24\n",
      "Transitions:  [7, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.9693486590038314 0.9693486590038314 0.9730769230769231\n",
      "Num frames:  (261, 1)\n",
      "Accuracy:  0.9693486590038314\n",
      "Person:  25\n",
      "Transitions:  [7, 8, 0, 8]\n",
      "GT transitions:  1\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.9414303329223181 0.8815461346633416 0.9846796657381616\n",
      "Num frames:  (802, 84)\n",
      "Accuracy:  0.9414303329223181\n",
      "Person:  26\n",
      "Transitions:  [7, 8, 0, 8]\n",
      "GT transitions:  1\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.9465695203400122 0.9067245119305857 0.9835294117647059\n",
      "Num frames:  (922, 74)\n",
      "Accuracy:  0.9465695203400122\n",
      "Person:  27\n",
      "Transitions:  [0, 8, 1, 8]\n",
      "GT transitions:  1\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.7154526889040164 0.8305489260143198 0.48400556328233657\n",
      "Num frames:  (419, 47)\n",
      "Accuracy:  0.7154526889040164\n",
      "Person:  28\n",
      "Transitions:  [7, 8, 6, 8, 5, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.9255679072015467 0.8898426323319027 1.0\n",
      "Num frames:  (1398, 154)\n",
      "Accuracy:  0.9255679072015467\n",
      "Person:  29\n",
      "Transitions:  [5, 8, 4, 8, 1, 8, 0, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.9688763136620857 0.9626099706744868 0.9798507462686568\n",
      "Num frames:  (1364, 50)\n",
      "Accuracy:  0.9688763136620857\n",
      "Person:  30\n",
      "Transitions:  [0, 8, 7, 8]\n",
      "GT transitions:  1\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.8493259318001586 0.7110055423594616 0.9583778014941302\n",
      "Num frames:  (1263, 341)\n",
      "Accuracy:  0.8493259318001586\n",
      "Person:  31\n",
      "Transitions:  [3, 8, 2, 8, 1, 8, 0, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A,P,R:  0.9617447264926707 0.9359365466748018 0.9986979166666666\n",
      "Num frames:  (1639, 105)\n",
      "Accuracy:  0.9617447264926707\n",
      "Person:  32\n",
      "Transitions:  [3, 8, 2, 8, 1, 8, 0, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.8565989847715736 0.8002969561989607 0.8254211332312404\n",
      "Num frames:  (1347, 111)\n",
      "Accuracy:  0.8565989847715736\n",
      "Person:  33\n",
      "Transitions:  [6, 8, 7, 8, 0, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.8761826408885233 0.7717968157695224 1.0\n",
      "Num frames:  (1319, 301)\n",
      "Accuracy:  0.8761826408885233\n",
      "Person:  34\n",
      "Transitions:  [3, 8, 2, 8, 1, 8, 0, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.9790810608890549 0.9638795986622074 0.9986139986139986\n",
      "Num frames:  (1495, 54)\n",
      "Accuracy:  0.9790810608890549\n",
      "Person:  35\n",
      "Transitions:  [7, 8, 6, 8]\n",
      "GT transitions:  1\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.7060998151571165 0.92 0.4591651542649728\n",
      "Num frames:  (275, 20)\n",
      "Accuracy:  0.7060998151571165\n",
      "Person:  36\n",
      "Transitions:  [7, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.981203007518797 0.981203007518797 0.9849056603773585\n",
      "Num frames:  (266, 1)\n",
      "Accuracy:  0.981203007518797\n",
      "Person:  37\n",
      "Transitions:  [7, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.9626168224299065 0.9626168224299065 0.965625\n",
      "Num frames:  (321, 1)\n",
      "Accuracy:  0.9626168224299065\n",
      "Person:  38\n",
      "Transitions:  [5, 8, 4, 8, 1, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.8203592814371258 0.7687277051129607 0.999227202472952\n",
      "Num frames:  (1682, 389)\n",
      "Accuracy:  0.8203592814371258\n",
      "Person:  39\n",
      "Transitions:  [3, 8, 2, 8, 1, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.98068669527897 0.9706840390879479 1.0\n",
      "Num frames:  (1228, 36)\n",
      "Accuracy:  0.98068669527897\n",
      "Person:  40\n",
      "Transitions:  [1, 8, 0, 8]\n",
      "GT transitions:  1\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.9843627834245504 0.9871299871299871 0.979565772669221\n",
      "Num frames:  (777, 4)\n",
      "Accuracy:  0.9843627834245504\n",
      "Person:  41\n",
      "Transitions:  [7, 8, 0, 8]\n",
      "GT transitions:  1\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.9617737003058104 0.9159663865546218 1.0\n",
      "Num frames:  (595, 50)\n",
      "Accuracy:  0.9617737003058104\n",
      "Person:  42\n",
      "Transitions:  [3, 8, 2, 8, 1, 8, 0, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.9841986455981941 0.9728997289972899 0.9986091794158554\n",
      "Num frames:  (1476, 40)\n",
      "Accuracy:  0.9841986455981941\n",
      "Person:  43\n",
      "Transitions:  [2, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.9932885906040269 0.9932885906040269 1.0\n",
      "Num frames:  (149, 1)\n",
      "Accuracy:  0.9932885906040269\n",
      "Person:  44\n",
      "Transitions:  [5, 8, 6, 8, 7, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.8990825688073395 0.8555984555984556 1.0\n",
      "Num frames:  (1295, 187)\n",
      "Accuracy:  0.8990825688073395\n",
      "Person:  45\n",
      "Transitions:  [3, 8, 2, 8, 1, 8, 0, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.9710711493354183 0.9694385216773277 0.9777777777777777\n",
      "Num frames:  (1407, 43)\n",
      "Accuracy:  0.9710711493354183\n",
      "Person:  46\n",
      "Transitions:  [7, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.9417808219178082 0.9417808219178082 0.9450171821305842\n",
      "Num frames:  (292, 1)\n",
      "Accuracy:  0.9417808219178082\n",
      "Person:  47\n",
      "Transitions:  [7, 8, 6, 8, 5, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.9016712009327633 0.8668421052631579 1.0\n",
      "Num frames:  (1900, 253)\n",
      "Accuracy:  0.9016712009327633\n",
      "Person:  48\n",
      "Transitions:  [7, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.9469964664310954 0.9469964664310954 0.950354609929078\n",
      "Num frames:  (283, 1)\n",
      "Accuracy:  0.9469964664310954\n",
      "Person:  49\n",
      "Transitions:  [7, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.9964028776978417 0.9964028776978417 1.0\n",
      "Num frames:  (278, 1)\n",
      "Accuracy:  0.9964028776978417\n",
      "Person:  50\n",
      "Transitions:  [5, 8, 6, 8, 7, 8, 0, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.9581464872944694 0.9247967479674797 0.9898477157360406\n",
      "Num frames:  (1476, 98)\n",
      "Accuracy:  0.9581464872944694\n",
      "Person:  51\n",
      "Transitions:  [1, 8, 2, 8, 3, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.9431025228126677 0.9164696611505122 1.0\n",
      "Num frames:  (1269, 106)\n",
      "Accuracy:  0.9431025228126677\n",
      "Person:  52\n",
      "Transitions:  [7, 8, 4, 8, 4, 8, 6, 8, 7, 8]\n",
      "GT transitions:  4\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.1626762632197415 0.04983748645720477 0.3893229166666667\n",
      "Num frames:  (11999, 10463)\n",
      "Accuracy:  0.1626762632197415\n",
      "Person:  53\n",
      "Transitions:  [7, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.9961685823754789 0.9961685823754789 1.0\n",
      "Num frames:  (261, 1)\n",
      "Accuracy:  0.9961685823754789\n",
      "Person:  54\n",
      "Transitions:  [5, 8, 4, 8, 1, 8, 0, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.9447920500552079 0.9080906148867314 0.9943302622253721\n",
      "Num frames:  (1545, 142)\n",
      "Accuracy:  0.9447920500552079\n",
      "Person:  55\n",
      "Transitions:  [3, 8, 2, 8, 1, 8, 0, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.9813592233009709 0.9670487106017192 0.9985207100591716\n",
      "Num frames:  (1396, 46)\n",
      "Accuracy:  0.9813592233009709\n",
      "Person:  56\n",
      "Transitions:  [0, 8, 1, 8]\n",
      "GT transitions:  1\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.9474025974025974 0.9021739130434783 1.0\n",
      "Num frames:  (828, 81)\n",
      "Accuracy:  0.9474025974025974\n",
      "Person:  57\n",
      "Transitions:  [7, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.9961977186311787 0.9961977186311787 1.0\n",
      "Num frames:  (263, 1)\n",
      "Accuracy:  0.9961977186311787\n",
      "Person:  58\n",
      "Transitions:  [1, 8, 2, 8, 3, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.8994053518334986 0.8588317107093185 0.9951651893634166\n",
      "Num frames:  (1438, 197)\n",
      "Accuracy:  0.8994053518334986\n",
      "Person:  59\n",
      "Transitions:  [7, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.97 0.97 0.9732441471571907\n",
      "Num frames:  (300, 1)\n",
      "Accuracy:  0.97\n",
      "Person:  60\n",
      "Transitions:  [3, 8, 2, 8, 4, 8, 1, 8, 7, 8]\n",
      "GT transitions:  4\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.776748104465038 0.6869220607661823 0.931899641577061\n",
      "Num frames:  (1514, 454)\n",
      "Accuracy:  0.776748104465038\n",
      "Person:  61\n",
      "Transitions:  [0, 8, 1, 8, 4, 8, 5, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.40020237794080443 0.17370007535795026 0.2708578143360752\n",
      "Num frames:  (2654, 1130)\n",
      "Accuracy:  0.40020237794080443\n",
      "Person:  62\n",
      "Transitions:  [5, 8, 4, 8, 1, 8, 0, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.9363542026980284 0.8908011869436202 1.0\n",
      "Num frames:  (1685, 184)\n",
      "Accuracy:  0.9363542026980284\n",
      "Person:  63\n",
      "Transitions:  [3, 8, 4, 8]\n",
      "GT transitions:  1\n",
      "Transitions captured:  0\n",
      "A,P,R:  0.8126829268292682 0.6864406779661016 0.8901098901098901\n",
      "Num frames:  (590, 142)\n",
      "Accuracy:  0.8126829268292682\n",
      "Person:  64\n",
      "Transitions:  [6, 8, 5, 8]\n",
      "GT transitions:  1\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.9345182413470533 0.9234135667396062 1.0\n",
      "Num frames:  (914, 70)\n",
      "Accuracy:  0.9345182413470533\n",
      "Person:  65\n",
      "Transitions:  [7, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.9966101694915255 0.9966101694915255 1.0\n",
      "Num frames:  (295, 1)\n",
      "Accuracy:  0.9966101694915255\n",
      "Person:  66\n",
      "Transitions:  [5, 8, 6, 8, 7, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.8907339754234473 0.866042345276873 1.0\n",
      "Num frames:  (2456, 329)\n",
      "Accuracy:  0.8907339754234473\n",
      "Person:  67\n",
      "Transitions:  [7, 8, 6, 8, 5, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.5537953795379538 0.3644859813084112 0.2705202312138728\n",
      "Num frames:  (642, 45)\n",
      "Accuracy:  0.5537953795379538\n",
      "Person:  68\n",
      "Transitions:  [3, 8, 2, 8, 1, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.965205288796103 0.9964243146603099 0.9467723669309174\n",
      "Num frames:  (839, 3)\n",
      "Accuracy:  0.965205288796103\n",
      "Person:  69\n",
      "Transitions:  [5, 8, 4, 8]\n",
      "GT transitions:  1\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.9358851674641149 0.9099462365591398 1.0\n",
      "Num frames:  (744, 67)\n",
      "Accuracy:  0.9358851674641149\n",
      "Person:  70\n",
      "Transitions:  [0, 8, 7, 8]\n",
      "GT transitions:  1\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.8892438764643238 0.8007736943907157 0.9880668257756563\n",
      "Num frames:  (1034, 198)\n",
      "Accuracy:  0.8892438764643238\n",
      "Person:  71\n",
      "Transitions:  [7, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.9955947136563876 0.9955947136563876 1.0\n",
      "Num frames:  (227, 1)\n",
      "Accuracy:  0.9955947136563876\n",
      "Person:  72\n",
      "Transitions:  [7, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.9876543209876543 0.9876543209876543 1.0\n",
      "Num frames:  (81, 1)\n",
      "Accuracy:  0.9876543209876543\n",
      "Person:  73\n",
      "Transitions:  [5, 8, 6, 8, 7, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.8671472708547889 0.8127721335268505 1.0\n",
      "Num frames:  (1378, 258)\n",
      "Accuracy:  0.8671472708547889\n",
      "Person:  74\n",
      "Transitions:  [0, 8, 6, 8, 5, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.7899921197793538 0.5501330967169477 0.7037457434733257\n",
      "Num frames:  (1127, 272)\n",
      "Accuracy:  0.7899921197793538\n",
      "Person:  75\n",
      "Transitions:  [0, 8, 1, 8, 2, 8, 3, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.4242540168324407 0.22272727272727272 0.2580887885628292\n",
      "Num frames:  (1540, 519)\n",
      "Accuracy:  0.4242540168324407\n",
      "Person:  76\n",
      "Transitions:  [7, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.9446254071661238 0.9446254071661238 0.9477124183006536\n",
      "Num frames:  (307, 1)\n",
      "Accuracy:  0.9446254071661238\n",
      "Person:  77\n",
      "Transitions:  [7, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.9970238095238095 0.9970238095238095 1.0\n",
      "Num frames:  (336, 1)\n",
      "Accuracy:  0.9970238095238095\n",
      "Person:  78\n",
      "Transitions:  [0, 8, 1, 8, 4, 8, 5, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.2757691443970357 0.1555354993983153 0.21532694710537276\n",
      "Num frames:  (3324, 1341)\n",
      "Accuracy:  0.2757691443970357\n",
      "Person:  79\n",
      "Transitions:  [1, 8, 2, 8, 4, 8, 5, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.8973808501502791 0.8816936488169365 0.9433710859427049\n",
      "Num frames:  (1606, 154)\n",
      "Accuracy:  0.8973808501502791\n",
      "Person:  80\n",
      "Transitions:  [0, 8, 1, 8, 2, 8, 3, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.8783522256013271 0.8105081826012058 1.0\n",
      "Num frames:  (2322, 440)\n",
      "Accuracy:  0.8783522256013271\n",
      "Person:  81\n",
      "Transitions:  [0, 8, 1, 8, 2, 8, 3, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.39829605963791265 0.20740305522914218 0.24685314685314685\n",
      "Num frames:  (1702, 618)\n",
      "Accuracy:  0.39829605963791265\n",
      "Person:  82\n",
      "Transitions:  [5, 8, 6, 8, 7, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.8351753964440173 0.7747866053841103 1.0\n",
      "Num frames:  (1523, 343)\n",
      "Accuracy:  0.8351753964440173\n",
      "Person:  83\n",
      "Transitions:  [3, 8, 2, 8, 4, 8, 5, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.8875931324910917 0.8569343065693431 0.9534380075798592\n",
      "Num frames:  (2055, 261)\n",
      "Accuracy:  0.8875931324910917\n",
      "Person:  84\n",
      "Transitions:  [0, 8, 1, 8, 2, 8, 3, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.39766702014846234 0.20163170163170163 0.24452296819787986\n",
      "Num frames:  (1716, 635)\n",
      "Accuracy:  0.39766702014846234\n",
      "Person:  85\n",
      "Transitions:  [7, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.9287925696594427 0.9287925696594427 0.9316770186335404\n",
      "Num frames:  (323, 1)\n",
      "Accuracy:  0.9287925696594427\n",
      "Person:  86\n",
      "Transitions:  [1, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.9911054637865311 0.9911054637865311 0.9923664122137404\n",
      "Num frames:  (787, 1)\n",
      "Accuracy:  0.9911054637865311\n",
      "Person:  87\n",
      "Transitions:  [0, 8, 1, 8]\n",
      "GT transitions:  1\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.9284862932061978 0.8759048603929679 1.0\n",
      "Num frames:  (967, 120)\n",
      "Accuracy:  0.9284862932061978\n",
      "Person:  88\n",
      "Transitions:  [5, 8, 4, 8, 1, 8, 0, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.9402932960893855 0.897358943577431 1.0\n",
      "Num frames:  (1666, 171)\n",
      "Accuracy:  0.9402932960893855\n",
      "Person:  89\n",
      "Transitions:  [1, 8, 0, 8]\n",
      "GT transitions:  1\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.967741935483871 0.9472954230235784 0.9869942196531792\n",
      "Num frames:  (721, 32)\n",
      "Accuracy:  0.967741935483871\n",
      "Person:  90\n",
      "Transitions:  [7, 8, 6, 8, 5, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.5287925696594428 0.33612273361227335 0.25638297872340426\n",
      "Num frames:  (717, 62)\n",
      "Accuracy:  0.5287925696594428\n",
      "Person:  91\n",
      "Transitions:  [7, 8, 6, 8, 5, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.9528676888131743 0.9258241758241759 0.998025666337611\n",
      "Num frames:  (1092, 81)\n",
      "Accuracy:  0.9528676888131743\n",
      "Person:  92\n",
      "Transitions:  [1, 8, 0, 8]\n",
      "GT transitions:  1\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.6522020725388601 0.5251989389920424 0.6971830985915493\n",
      "Num frames:  (1131, 279)\n",
      "Accuracy:  0.6522020725388601\n",
      "Person:  93\n",
      "Transitions:  [7, 8, 6, 8, 5, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.940406976744186 0.994750656167979 0.9066985645933014\n",
      "Num frames:  (762, 4)\n",
      "Accuracy:  0.940406976744186\n",
      "Person:  94\n",
      "Transitions:  [7, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.9601328903654485 0.9601328903654485 0.9633333333333334\n",
      "Num frames:  (301, 1)\n",
      "Accuracy:  0.9601328903654485\n",
      "Person:  95\n",
      "Transitions:  [5, 8, 6, 8, 7, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.908157444381061 0.8654970760233918 1.0\n",
      "Num frames:  (1197, 161)\n",
      "Accuracy:  0.908157444381061\n",
      "Person:  96\n",
      "Transitions:  [4, 8, 5, 8]\n",
      "GT transitions:  1\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.9566074950690335 0.9336349924585219 1.0\n",
      "Num frames:  (663, 44)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.9566074950690335\n",
      "Person:  97\n",
      "Transitions:  [7, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.9970059880239521 0.9970059880239521 1.0\n",
      "Num frames:  (334, 1)\n",
      "Accuracy:  0.9970059880239521\n",
      "Person:  98\n",
      "Transitions:  [7, 8, 6, 8, 5, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.547979797979798 0.3545586107091172 0.2722222222222222\n",
      "Num frames:  (691, 61)\n",
      "Accuracy:  0.547979797979798\n",
      "Person:  99\n",
      "Transitions:  [1, 8, 0, 8]\n",
      "GT transitions:  1\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.946983546617916 0.9189944134078212 0.9939577039274925\n",
      "Num frames:  (1074, 81)\n",
      "Accuracy:  0.946983546617916\n",
      "Person:  100\n",
      "Transitions:  [7, 8, 6, 8, 5, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.9288979177247334 0.8920585967617579 1.0\n",
      "Num frames:  (1297, 140)\n",
      "Accuracy:  0.9288979177247334\n",
      "Person:  101\n",
      "Transitions:  [0, 8, 1, 8]\n",
      "GT transitions:  1\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.8970019342359767 0.8442982456140351 1.0\n",
      "Num frames:  (1368, 213)\n",
      "Accuracy:  0.8970019342359767\n",
      "Person:  102\n",
      "Transitions:  [7, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.9578313253012049 0.9578313253012049 0.9607250755287009\n",
      "Num frames:  (332, 1)\n",
      "Accuracy:  0.9578313253012049\n",
      "Person:  103\n",
      "Transitions:  [7, 8, 6, 8, 5, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.5195638229634381 0.3177842565597668 0.23956043956043957\n",
      "Num frames:  (686, 57)\n",
      "Accuracy:  0.5195638229634381\n",
      "Person:  104\n",
      "Transitions:  [7, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.9620991253644315 0.9620991253644315 0.9649122807017544\n",
      "Num frames:  (343, 1)\n",
      "Accuracy:  0.9620991253644315\n",
      "Person:  105\n",
      "Transitions:  [2, 8, 4, 8, 5, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.9238774903360095 0.909057572423909 0.9841206828106391\n",
      "Num frames:  (2727, 216)\n",
      "Accuracy:  0.9238774903360095\n",
      "Person:  106\n",
      "Transitions:  [0, 8, 1, 8]\n",
      "GT transitions:  1\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.9467496542185339 0.8967828418230563 1.0\n",
      "Num frames:  (746, 77)\n",
      "Accuracy:  0.9467496542185339\n",
      "Person:  107\n",
      "Transitions:  [7, 8, 6, 8, 5, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.5499677627337202 0.3520485584218513 0.2609673790776153\n",
      "Num frames:  (659, 41)\n",
      "Accuracy:  0.5499677627337202\n",
      "Person:  108\n",
      "Transitions:  [4, 8, 5, 8]\n",
      "GT transitions:  1\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.961646398503274 0.943213296398892 1.0\n",
      "Num frames:  (722, 41)\n",
      "Accuracy:  0.961646398503274\n",
      "Person:  109\n",
      "Transitions:  [7, 8, 0, 8]\n",
      "GT transitions:  1\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.7388475836431226 0.6031073446327684 1.0\n",
      "Num frames:  (1416, 562)\n",
      "Accuracy:  0.7388475836431226\n",
      "Person:  110\n",
      "Transitions:  [7, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.9670588235294117 0.9670588235294117 0.9693396226415094\n",
      "Num frames:  (425, 1)\n",
      "Accuracy:  0.9670588235294117\n",
      "Person:  111\n",
      "Transitions:  [5, 8, 6, 8, 7, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.871435977190254 0.8193736343772761 1.0\n",
      "Num frames:  (1373, 248)\n",
      "Accuracy:  0.871435977190254\n",
      "Person:  112\n",
      "Transitions:  [7, 8, 0, 8]\n",
      "GT transitions:  1\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.9520807061790668 0.9182968929804373 0.9803439803439803\n",
      "Num frames:  (869, 60)\n",
      "Accuracy:  0.9520807061790668\n",
      "Person:  113\n",
      "Transitions:  [5, 8, 4, 8]\n",
      "GT transitions:  1\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.9280575539568345 0.9015990159901599 1.0\n",
      "Num frames:  (813, 80)\n",
      "Accuracy:  0.9280575539568345\n",
      "Person:  114\n",
      "Transitions:  [7, 8, 6, 8, 5, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.9454038997214484 0.9148181011535049 0.9980638915779284\n",
      "Num frames:  (1127, 96)\n",
      "Accuracy:  0.9454038997214484\n",
      "Person:  115\n",
      "Transitions:  [7, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.9824561403508771 0.9824561403508771 1.0\n",
      "Num frames:  (57, 1)\n",
      "Accuracy:  0.9824561403508771\n",
      "Person:  116\n",
      "Transitions:  [7, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.959375 0.959375 0.9623824451410659\n",
      "Num frames:  (320, 1)\n",
      "Accuracy:  0.959375\n",
      "Person:  117\n",
      "Transitions:  [7, 8, 6, 8, 5, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.9657836644591612 0.945993031358885 1.0\n",
      "Num frames:  (1148, 62)\n",
      "Accuracy:  0.9657836644591612\n",
      "Person:  118\n",
      "Transitions:  [5, 8, 6, 8, 7, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.8900169204737732 0.8391089108910891 1.0\n",
      "Num frames:  (1212, 195)\n",
      "Accuracy:  0.8900169204737732\n",
      "Person:  119\n",
      "Transitions:  [7, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.9582089552238806 0.9582089552238806 0.9610778443113772\n",
      "Num frames:  (335, 1)\n",
      "Accuracy:  0.9582089552238806\n",
      "Person:  120\n",
      "Transitions:  [7, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.9814814814814815 0.9814814814814815 1.0\n",
      "Num frames:  (54, 1)\n",
      "Accuracy:  0.9814814814814815\n",
      "Person:  121\n",
      "Transitions:  [7, 8, 0, 8]\n",
      "GT transitions:  1\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.9779359430604982 0.9589442815249267 0.9954337899543378\n",
      "Num frames:  (682, 28)\n",
      "Accuracy:  0.9779359430604982\n",
      "Person:  122\n",
      "Transitions:  [0, 8, 1, 8]\n",
      "GT transitions:  1\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.9294041450777202 0.8702380952380953 1.0\n",
      "Num frames:  (840, 109)\n",
      "Accuracy:  0.9294041450777202\n",
      "Person:  123\n",
      "Transitions:  [6, 8, 5, 8]\n",
      "GT transitions:  1\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.9433962264150944 0.9347826086956522 1.0\n",
      "Num frames:  (1012, 66)\n",
      "Accuracy:  0.9433962264150944\n",
      "Person:  124\n",
      "Transitions:  [5, 8, 6, 8, 7, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.8341277407054337 0.7750484809308339 1.0\n",
      "Num frames:  (1547, 348)\n",
      "Accuracy:  0.8341277407054337\n",
      "Person:  125\n",
      "Transitions:  [5, 8, 4, 8, 0, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.8423295454545454 0.7113133940182055 1.0\n",
      "Num frames:  (1538, 444)\n",
      "Accuracy:  0.8423295454545454\n",
      "Person:  126\n",
      "Transitions:  [2, 8, 1, 8, 0, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.9588796185935637 0.948237885462555 0.9750849377123443\n",
      "Num frames:  (908, 47)\n",
      "Accuracy:  0.9588796185935637\n",
      "Person:  127\n",
      "Transitions:  [0, 8, 1, 8, 2, 8, 3, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.35015290519877673 0.18186046511627907 0.24809644670050762\n",
      "Num frames:  (2150, 940)\n",
      "Accuracy:  0.35015290519877673\n",
      "Person:  128\n",
      "Transitions:  [1, 8, 1, 8]\n",
      "GT transitions:  1\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.8909774436090225 0.8920953575909661 0.9779917469050894\n",
      "Num frames:  (797, 71)\n",
      "Accuracy:  0.8909774436090225\n",
      "Person:  129\n",
      "Transitions:  [4, 8, 5, 8]\n",
      "GT transitions:  1\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.9648936170212766 0.9495934959349593 0.9965870307167235\n",
      "Num frames:  (615, 31)\n",
      "Accuracy:  0.9648936170212766\n",
      "Person:  130\n",
      "Transitions:  [7, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.9379084967320261 0.9379084967320261 0.940983606557377\n",
      "Num frames:  (306, 1)\n",
      "Accuracy:  0.9379084967320261\n",
      "Person:  131\n",
      "Transitions:  [1, 8, 0, 8]\n",
      "GT transitions:  1\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.9104958145524791 0.8595959595959596 0.9929988331388565\n",
      "Num frames:  (990, 133)\n",
      "Accuracy:  0.9104958145524791\n",
      "Person:  132\n",
      "Transitions:  [4, 8, 6, 8, 5, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.3130841121495327 0.09205776173285199 0.07634730538922156\n",
      "Num frames:  (554, 118)\n",
      "Accuracy:  0.3130841121495327\n",
      "Person:  133\n",
      "Transitions:  [2, 8, 1, 8, 0, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.9787120808940926 0.9639314697926059 1.0\n",
      "Num frames:  (1109, 40)\n",
      "Accuracy:  0.9787120808940926\n",
      "Person:  134\n",
      "Transitions:  [0, 8, 1, 8]\n",
      "GT transitions:  1\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.7234617985125085 0.8341013824884793 0.5027777777777778\n",
      "Num frames:  (434, 51)\n",
      "Accuracy:  0.7234617985125085\n",
      "Person:  135\n",
      "Transitions:  [5, 8, 4, 8, 0, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.7959313413858868 0.6512764801738186 1.0\n",
      "Num frames:  (1841, 642)\n",
      "Accuracy:  0.7959313413858868\n",
      "Person:  136\n",
      "Transitions:  [5, 8, 6, 8, 7, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.8134974920200638 0.7503052503052503 1.0\n",
      "Num frames:  (1638, 409)\n",
      "Accuracy:  0.8134974920200638\n",
      "Person:  137\n",
      "Transitions:  [7, 8, 6, 8, 5, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.9169363538295577 0.8697123519458545 1.0\n",
      "Num frames:  (1182, 154)\n",
      "Accuracy:  0.9169363538295577\n",
      "Person:  138\n",
      "Transitions:  [7, 8, 6, 8, 5, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.9169656586365966 0.8737334372564303 1.0\n",
      "Num frames:  (1283, 162)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.9169656586365966\n",
      "Person:  139\n",
      "Transitions:  [3, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.9978813559322034 0.9978813559322034 1.0\n",
      "Num frames:  (472, 1)\n",
      "Accuracy:  0.9978813559322034\n",
      "Person:  140\n",
      "Transitions:  [7, 8, 0, 8]\n",
      "GT transitions:  1\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.8342696629213483 0.7160731472569779 1.0\n",
      "Num frames:  (1039, 295)\n",
      "Accuracy:  0.8342696629213483\n",
      "Person:  141\n",
      "Transitions:  [7, 8, 6, 8, 5, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.9659224441833137 0.944177093358999 1.0\n",
      "Num frames:  (1039, 58)\n",
      "Accuracy:  0.9659224441833137\n",
      "Person:  142\n",
      "Transitions:  [5, 8, 4, 8, 1, 8, 0, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.8908011869436202 0.8310376492194674 1.0\n",
      "Num frames:  (2178, 368)\n",
      "Accuracy:  0.8908011869436202\n",
      "Person:  143\n",
      "Transitions:  [0, 8, 1, 8, 2, 8, 3, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.39818372336709745 0.20530565167243367 0.24842986741102582\n",
      "Num frames:  (1734, 646)\n",
      "Accuracy:  0.39818372336709745\n",
      "Person:  144\n",
      "Transitions:  [0, 8, 1, 8, 4, 8, 5, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.7889175257731958 0.6693580944691159 0.9993972272453285\n",
      "Num frames:  (2477, 818)\n",
      "Accuracy:  0.7889175257731958\n",
      "Person:  145\n",
      "Transitions:  [7, 8, 6, 8, 5, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.5562091503267974 0.3468118195956454 0.2528344671201814\n",
      "Num frames:  (643, 20)\n",
      "Accuracy:  0.5562091503267974\n",
      "Person:  146\n",
      "Transitions:  [1, 8, 2, 8, 3, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.9295618413754853 0.8958677685950414 0.9854545454545455\n",
      "Num frames:  (1210, 111)\n",
      "Accuracy:  0.9295618413754853\n",
      "Person:  147\n",
      "Transitions:  [7, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.9429530201342282 0.9429530201342282 0.9461279461279462\n",
      "Num frames:  (298, 1)\n",
      "Accuracy:  0.9429530201342282\n",
      "Person:  148\n",
      "Transitions:  [7, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.9645669291338582 0.9645669291338582 0.9683794466403162\n",
      "Num frames:  (254, 1)\n",
      "Accuracy:  0.9645669291338582\n",
      "Person:  149\n",
      "Transitions:  [7, 8, 0, 8]\n",
      "GT transitions:  1\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.9752747252747253 0.9576379974326059 0.9815789473684211\n",
      "Num frames:  (779, 22)\n",
      "Accuracy:  0.9752747252747253\n",
      "Person:  150\n",
      "Transitions:  [3, 8, 2, 8, 1, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.947289905519642 0.922457937088515 1.0\n",
      "Num frames:  (1367, 106)\n",
      "Accuracy:  0.947289905519642\n",
      "Person:  151\n",
      "Transitions:  [5, 8, 6, 8, 7, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.9131773399014779 0.8685927306616962 1.0\n",
      "Num frames:  (1073, 141)\n",
      "Accuracy:  0.9131773399014779\n",
      "Person:  152\n",
      "Transitions:  [7, 8, 0, 8]\n",
      "GT transitions:  1\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.9576271186440678 0.9250535331905781 1.0\n",
      "Num frames:  (934, 70)\n",
      "Accuracy:  0.9576271186440678\n",
      "Person:  153\n",
      "Transitions:  [7, 8, 6, 8, 5, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.9629207073588134 0.9405850091407678 1.0\n",
      "Num frames:  (1094, 65)\n",
      "Accuracy:  0.9629207073588134\n",
      "Person:  154\n",
      "Transitions:  [7, 8, 6, 8, 5, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.5494710640945862 0.37047353760445684 0.28632938643702904\n",
      "Num frames:  (718, 61)\n",
      "Accuracy:  0.5494710640945862\n",
      "Person:  155\n",
      "Transitions:  [7, 8, 6, 8, 5, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.9547477744807121 0.9945504087193461 0.9275730622617535\n",
      "Num frames:  (734, 4)\n",
      "Accuracy:  0.9547477744807121\n",
      "Person:  156\n",
      "Transitions:  [6, 8, 5, 8]\n",
      "GT transitions:  1\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.9538784067085954 0.9449311639549437 1.0\n",
      "Num frames:  (799, 44)\n",
      "Accuracy:  0.9538784067085954\n",
      "Person:  157\n",
      "Transitions:  [5, 8, 4, 8, 0, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.7959046659953004 0.6374478234943352 1.0\n",
      "Num frames:  (1677, 608)\n",
      "Accuracy:  0.7959046659953004\n",
      "Person:  158\n",
      "Transitions:  [5, 8, 6, 8, 7, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.8890147225368064 0.8378825475599669 1.0\n",
      "Num frames:  (1209, 196)\n",
      "Accuracy:  0.8890147225368064\n",
      "Person:  159\n",
      "Transitions:  [7, 8, 0, 8]\n",
      "GT transitions:  1\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.9264617239300783 0.8688172043010752 1.0\n",
      "Num frames:  (930, 122)\n",
      "Accuracy:  0.9264617239300783\n",
      "Person:  160\n",
      "Transitions:  [7, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.994413407821229 0.994413407821229 1.0\n",
      "Num frames:  (179, 1)\n",
      "Accuracy:  0.994413407821229\n",
      "Person:  161\n",
      "Transitions:  [1, 8, 0, 8]\n",
      "GT transitions:  1\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.9870863599677159 0.9773371104815864 0.9913793103448276\n",
      "Num frames:  (706, 10)\n",
      "Accuracy:  0.9870863599677159\n",
      "Person:  162\n",
      "Transitions:  [5, 8, 4, 8, 2, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.9081967213114754 0.8984168865435356 1.0\n",
      "Num frames:  (3032, 308)\n",
      "Accuracy:  0.9081967213114754\n",
      "Person:  163\n",
      "Transitions:  [7, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.9838709677419355 0.9838709677419355 0.9870550161812298\n",
      "Num frames:  (310, 1)\n",
      "Accuracy:  0.9838709677419355\n",
      "Person:  164\n",
      "Transitions:  [5, 8, 4, 8, 0, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.8018078339471041 0.6494967436352872 1.0\n",
      "Num frames:  (1689, 592)\n",
      "Accuracy:  0.8018078339471041\n",
      "Person:  165\n",
      "Transitions:  [0, 8, 1, 8, 4, 8, 5, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.8745053702656869 0.8040600176522507 1.0\n",
      "Num frames:  (2266, 444)\n",
      "Accuracy:  0.8745053702656869\n",
      "Person:  166\n",
      "Transitions:  [7, 8, 0, 8]\n",
      "GT transitions:  1\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.9747899159663865 0.9777397260273972 0.9532554257095158\n",
      "Num frames:  (584, 2)\n",
      "Accuracy:  0.9747899159663865\n",
      "Person:  167\n",
      "Transitions:  [5, 8, 4, 8, 2, 8, 1, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.8735119047619048 0.8274695534506089 1.0\n",
      "Num frames:  (1478, 255)\n",
      "Accuracy:  0.8735119047619048\n",
      "Person:  168\n",
      "Transitions:  [7, 8, 6, 8, 5, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.9583333333333334 0.9317963496637848 1.0\n",
      "Num frames:  (1041, 71)\n",
      "Accuracy:  0.9583333333333334\n",
      "Person:  169\n",
      "Transitions:  [2, 8, 2, 8, 4, 8, 4, 8, 2, 8]\n",
      "GT transitions:  4\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.2543200940921017 0.22345764046049396 0.7554890219560878\n",
      "Num frames:  (10163, 7507)\n",
      "Accuracy:  0.2543200940921017\n",
      "Person:  170\n",
      "Transitions:  [7, 8, 6, 8, 4, 8, 2, 8, 3, 8]\n",
      "GT transitions:  4\n",
      "Transitions captured:  4\n",
      "A,P,R:  0.9085254299304794 0.8458177278401997 0.9876093294460642\n",
      "Num frames:  (1602, 233)\n",
      "Accuracy:  0.9085254299304794\n",
      "Person:  171\n",
      "Transitions:  [7, 8, 0, 8]\n",
      "GT transitions:  1\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.9201014584654407 0.847457627118644 0.9845288326300985\n",
      "Num frames:  (826, 115)\n",
      "Accuracy:  0.9201014584654407\n",
      "Person:  172\n",
      "Transitions:  [0, 8, 1, 8, 4, 8, 5, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.883428228948157 0.8111650485436893 1.0\n",
      "Num frames:  (2060, 389)\n",
      "Accuracy:  0.883428228948157\n",
      "Person:  173\n",
      "Transitions:  [7, 8, 6, 8, 5, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.9568009340338587 0.9310344827586207 0.997946611909651\n",
      "Num frames:  (1044, 72)\n",
      "Accuracy:  0.9568009340338587\n",
      "Person:  174\n",
      "Transitions:  [7, 8, 6, 8, 5, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.8968291528632276 0.8489258489258489 1.0\n",
      "Num frames:  (1443, 218)\n",
      "Accuracy:  0.8968291528632276\n",
      "Person:  175\n",
      "Transitions:  [7, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.9959183673469387 0.9959183673469387 1.0\n",
      "Num frames:  (245, 1)\n",
      "Accuracy:  0.9959183673469387\n",
      "Person:  176\n",
      "Transitions:  [6, 8, 4, 8, 2, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.8750667378537106 0.8641903656413232 1.0\n",
      "Num frames:  (1723, 234)\n",
      "Accuracy:  0.8750667378537106\n",
      "Person:  177\n",
      "Transitions:  [1, 8, 4, 8, 5, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.9106858054226475 0.8821774794929157 0.9793046357615894\n",
      "Num frames:  (1341, 143)\n",
      "Accuracy:  0.9106858054226475\n",
      "Person:  178\n",
      "Transitions:  [7, 8, 0, 8]\n",
      "GT transitions:  1\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.9467455621301775 0.908237747653806 0.997709049255441\n",
      "Num frames:  (959, 88)\n",
      "Accuracy:  0.9467455621301775\n",
      "Person:  179\n",
      "Transitions:  [5, 8, 4, 8]\n",
      "GT transitions:  1\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.9227005870841487 0.8920765027322405 1.0\n",
      "Num frames:  (732, 79)\n",
      "Accuracy:  0.9227005870841487\n",
      "Person:  180\n",
      "Transitions:  [7, 8, 6, 8, 5, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.9765432098765432 0.9604578563995838 1.0\n",
      "Num frames:  (961, 38)\n",
      "Accuracy:  0.9765432098765432\n",
      "Person:  181\n",
      "Transitions:  [7, 8, 6, 8, 5, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.9611542730299667 0.9384885764499121 1.0\n",
      "Num frames:  (1138, 70)\n",
      "Accuracy:  0.9611542730299667\n",
      "Person:  182\n",
      "Transitions:  [7, 8, 6, 8, 5, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.9424829157175398 0.9071691176470589 1.0\n",
      "Num frames:  (1088, 101)\n",
      "Accuracy:  0.9424829157175398\n",
      "Person:  183\n",
      "Transitions:  [5, 8, 4, 8, 1, 8, 0, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.9674578866768759 0.9486467730742539 0.9920174165457184\n",
      "Num frames:  (1441, 74)\n",
      "Accuracy:  0.9674578866768759\n",
      "Person:  184\n",
      "Transitions:  [0, 8, 1, 8, 2, 8, 3, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.2686842590883927 0.15136298421807748 0.22835497835497837\n",
      "Num frames:  (4182, 1824)\n",
      "Accuracy:  0.2686842590883927\n",
      "Person:  185\n",
      "Transitions:  [0, 8, 1, 8, 2, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.5475841874084919 0.3577405857740586 0.29131175468483816\n",
      "Num frames:  (956, 95)\n",
      "Accuracy:  0.5475841874084919\n",
      "Person:  186\n",
      "Transitions:  [0, 8, 1, 8, 2, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.9040114613180515 0.839968152866242 1.0\n",
      "Num frames:  (1256, 201)\n",
      "Accuracy:  0.9040114613180515\n",
      "Person:  187\n",
      "Transitions:  [3, 8, 2, 8, 1, 8, 0, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.9808444096950742 0.9823196605374823 0.9830148619957537\n",
      "Num frames:  (1414, 25)\n",
      "Accuracy:  0.9808444096950742\n",
      "Person:  188\n",
      "Transitions:  [0, 8, 1, 8, 2, 8, 3, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.8877162122544708 0.8200187969924813 1.0\n",
      "Num frames:  (2128, 383)\n",
      "Accuracy:  0.8877162122544708\n",
      "Person:  189\n",
      "Transitions:  [7, 8, 0, 8]\n",
      "GT transitions:  1\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.9252225519287833 0.8675078864353313 0.9868421052631579\n",
      "Num frames:  (951, 115)\n",
      "Accuracy:  0.9252225519287833\n",
      "Person:  190\n",
      "Transitions:  [7, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.9536679536679536 0.9536679536679536 0.9573643410852714\n",
      "Num frames:  (259, 1)\n",
      "Accuracy:  0.9536679536679536\n",
      "Person:  191\n",
      "Transitions:  [7, 8, 4, 8, 5, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.9101401483924155 0.8443804034582133 0.9982964224872232\n",
      "Num frames:  (1388, 216)\n",
      "Accuracy:  0.9101401483924155\n",
      "Person:  192\n",
      "Transitions:  [0, 8, 1, 8, 2, 8, 3, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.38424158278375564 0.19204545454545455 0.2323024054982818\n",
      "Num frames:  (1760, 657)\n",
      "Accuracy:  0.38424158278375564\n",
      "Person:  193\n",
      "Transitions:  [7, 8, 7, 8, 6, 8, 5, 8, 5, 8, 6, 8, 7, 8]\n",
      "GT transitions:  6\n",
      "Transitions captured:  0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A,P,R:  0.19761029411764705 0.18766726546174434 0.288768545157105\n",
      "Num frames:  (27277, 12709)\n",
      "Accuracy:  0.19761029411764705\n",
      "Person:  194\n",
      "Transitions:  [7, 8, 6, 8, 5, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.9202256244963739 0.9952380952380953 0.8672199170124482\n",
      "Num frames:  (630, 3)\n",
      "Accuracy:  0.9202256244963739\n",
      "Person:  195\n",
      "Transitions:  [0, 8, 1, 8, 4, 8, 5, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.33136829041265903 0.16921606118546845 0.2110912343470483\n",
      "Num frames:  (2092, 832)\n",
      "Accuracy:  0.33136829041265903\n",
      "Person:  196\n",
      "Transitions:  [7, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.9951219512195122 0.9951219512195122 1.0\n",
      "Num frames:  (205, 1)\n",
      "Accuracy:  0.9951219512195122\n",
      "Person:  197\n",
      "Transitions:  [2, 8, 3, 8]\n",
      "GT transitions:  1\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.9863813229571985 0.9820554649265906 0.9950413223140496\n",
      "Num frames:  (613, 11)\n",
      "Accuracy:  0.9863813229571985\n",
      "Person:  198\n",
      "Transitions:  [7, 8, 6, 8, 5, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.9166666666666666 0.8747152619589977 1.0\n",
      "Num frames:  (1317, 165)\n",
      "Accuracy:  0.9166666666666666\n",
      "Person:  199\n",
      "Transitions:  [7, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.9694189602446484 0.9694189602446484 0.9723926380368099\n",
      "Num frames:  (327, 1)\n",
      "Accuracy:  0.9694189602446484\n",
      "Person:  200\n",
      "Transitions:  [5, 8, 6, 8, 7, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.894855850763143 0.8466611706512778 1.0\n",
      "Num frames:  (1213, 186)\n",
      "Accuracy:  0.894855850763143\n",
      "Person:  201\n",
      "Transitions:  [0, 8, 4, 8, 5, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.7530446549391069 0.6141226818830242 0.7855839416058394\n",
      "Num frames:  (1402, 495)\n",
      "Accuracy:  0.7530446549391069\n",
      "Person:  202\n",
      "Transitions:  [1, 8, 4, 8, 5, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.8694779116465864 0.8246797033041133 0.9951179820992677\n",
      "Num frames:  (1483, 254)\n",
      "Accuracy:  0.8694779116465864\n",
      "Person:  203\n",
      "Transitions:  [3, 8, 2, 8, 4, 8, 5, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.8997821350762527 0.8667576170986813 0.9650632911392405\n",
      "Num frames:  (2199, 253)\n",
      "Accuracy:  0.8997821350762527\n",
      "Person:  204\n",
      "Transitions:  [7, 8, 0, 8]\n",
      "GT transitions:  1\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.4074074074074074 0.13476394849785409 0.2783687943262411\n",
      "Num frames:  (1165, 601)\n",
      "Accuracy:  0.4074074074074074\n",
      "Person:  205\n",
      "Transitions:  [0, 8, 1, 8, 2, 8, 3, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.4084967320261438 0.20425531914893616 0.24633431085043989\n",
      "Num frames:  (1645, 601)\n",
      "Accuracy:  0.4084967320261438\n",
      "Person:  206\n",
      "Transitions:  [0, 8, 1, 8]\n",
      "GT transitions:  1\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.7593167701863354 0.9152046783625731 0.5072933549432739\n",
      "Num frames:  (342, 6)\n",
      "Accuracy:  0.7593167701863354\n",
      "Person:  207\n",
      "Transitions:  [2, 8, 1, 8, 0, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.9205741626794258 0.8735632183908046 0.9947643979057592\n",
      "Num frames:  (1305, 160)\n",
      "Accuracy:  0.9205741626794258\n",
      "Person:  208\n",
      "Transitions:  [3, 8, 2, 8, 1, 8, 0, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.9728940783986656 0.9906976744186047 0.9601803155522164\n",
      "Num frames:  (1290, 12)\n",
      "Accuracy:  0.9728940783986656\n",
      "Person:  209\n",
      "Transitions:  [7, 8, 6, 8, 5, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.831543872639763 0.7746409113422487 1.0\n",
      "Num frames:  (2019, 455)\n",
      "Accuracy:  0.831543872639763\n",
      "Person:  210\n",
      "Transitions:  [7, 8, 0, 8]\n",
      "GT transitions:  1\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.9550970873786407 0.9193020719738277 1.0\n",
      "Num frames:  (917, 74)\n",
      "Accuracy:  0.9550970873786407\n",
      "Person:  211\n",
      "Transitions:  [5, 8, 4, 8, 1, 8, 1, 8, 0, 8]\n",
      "GT transitions:  4\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.6735010872941908 0.5866182572614108 0.8101719197707736\n",
      "Num frames:  (1928, 786)\n",
      "Accuracy:  0.6735010872941908\n",
      "Person:  212\n",
      "Transitions:  [7, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.9471947194719472 0.9471947194719472 0.9503311258278145\n",
      "Num frames:  (303, 1)\n",
      "Accuracy:  0.9471947194719472\n",
      "Person:  213\n",
      "Transitions:  [7, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.9422492401215805 0.9422492401215805 0.9451219512195121\n",
      "Num frames:  (329, 1)\n",
      "Accuracy:  0.9422492401215805\n",
      "Person:  214\n",
      "Transitions:  [7, 8, 0, 8]\n",
      "GT transitions:  1\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.8251516822945394 0.7009433962264151 0.9802110817941952\n",
      "Num frames:  (1060, 302)\n",
      "Accuracy:  0.8251516822945394\n",
      "Person:  215\n",
      "Transitions:  [1, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.9978632478632479 0.9978632478632479 1.0\n",
      "Num frames:  (468, 1)\n",
      "Accuracy:  0.9978632478632479\n",
      "Person:  216\n",
      "Transitions:  [7, 8, 6, 8, 5, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.92198233562316 0.8837719298245614 1.0\n",
      "Num frames:  (1368, 159)\n",
      "Accuracy:  0.92198233562316\n",
      "Person:  217\n",
      "Transitions:  [4, 8, 2, 8, 3, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.9056047197640118 0.8666666666666667 1.0\n",
      "Num frames:  (1200, 160)\n",
      "Accuracy:  0.9056047197640118\n",
      "Person:  218\n",
      "Transitions:  [7, 8, 6, 8, 5, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.9055343511450382 0.8614415675297411 1.0\n",
      "Num frames:  (1429, 198)\n",
      "Accuracy:  0.9055343511450382\n",
      "Person:  219\n",
      "Transitions:  [0, 8, 1, 8, 2, 8, 3, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.9409530386740331 0.8935905413814561 1.0\n",
      "Num frames:  (1607, 171)\n",
      "Accuracy:  0.9409530386740331\n",
      "Person:  220\n",
      "Transitions:  [1, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.9981684981684982 0.9981684981684982 1.0\n",
      "Num frames:  (546, 1)\n",
      "Accuracy:  0.9981684981684982\n",
      "Person:  221\n",
      "Transitions:  [7, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.9430379746835443 0.9430379746835443 0.946031746031746\n",
      "Num frames:  (316, 1)\n",
      "Accuracy:  0.9430379746835443\n",
      "Person:  222\n",
      "Transitions:  [5, 8, 6, 8, 4, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.9115770282588879 0.8992537313432836 0.9970449172576832\n",
      "Num frames:  (1876, 189)\n",
      "Accuracy:  0.9115770282588879\n",
      "Person:  223\n",
      "Transitions:  [7, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.99 0.99 1.0\n",
      "Num frames:  (100, 1)\n",
      "Accuracy:  0.99\n",
      "Person:  224\n",
      "Transitions:  [1, 8, 0, 8]\n",
      "GT transitions:  1\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.6616352201257861 0.5421276595744681 0.7205882352941176\n",
      "Num frames:  (1175, 291)\n",
      "Accuracy:  0.6616352201257861\n",
      "Person:  225\n",
      "Transitions:  [0, 8, 1, 8, 4, 8, 5, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.34805598755832035 0.166015625 0.20556227327690446\n",
      "Num frames:  (2048, 782)\n",
      "Accuracy:  0.34805598755832035\n",
      "Person:  226\n",
      "Transitions:  [7, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.9609375 0.9609375 0.9647058823529412\n",
      "Num frames:  (256, 1)\n",
      "Accuracy:  0.9609375\n",
      "Person:  227\n",
      "Transitions:  [7, 8, 6, 8, 5, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.971244131455399 0.9530651340996169 1.0\n",
      "Num frames:  (1044, 49)\n",
      "Accuracy:  0.971244131455399\n",
      "Person:  228\n",
      "Transitions:  [0, 8, 1, 8, 4, 8, 5, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.9121580547112462 0.8615309605070697 0.9971783295711061\n",
      "Num frames:  (2051, 284)\n",
      "Accuracy:  0.9121580547112462\n",
      "Person:  229\n",
      "Transitions:  [0, 8, 1, 8]\n",
      "GT transitions:  1\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.9320505111244738 0.8817991631799164 1.0\n",
      "Num frames:  (956, 113)\n",
      "Accuracy:  0.9320505111244738\n",
      "Person:  230\n",
      "Transitions:  [7, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.9961685823754789 0.9961685823754789 1.0\n",
      "Num frames:  (261, 1)\n",
      "Accuracy:  0.9961685823754789\n",
      "Person:  231\n",
      "Transitions:  [0, 8, 1, 8, 7, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.8710801393728222 0.8127767235926628 0.9331880900508351\n",
      "Num frames:  (1581, 278)\n",
      "Accuracy:  0.8710801393728222\n",
      "Person:  232\n",
      "Transitions:  [7, 8, 0, 8]\n",
      "GT transitions:  1\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.8767051416579223 0.7991452991452992 1.0\n",
      "Num frames:  (1170, 235)\n",
      "Accuracy:  0.8767051416579223\n",
      "Person:  233\n",
      "Transitions:  [2, 8, 4, 8, 6, 8, 7, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.8450082735797021 0.7717492984097287 0.9065934065934066\n",
      "Num frames:  (1069, 196)\n",
      "Accuracy:  0.8450082735797021\n",
      "Person:  234\n",
      "Transitions:  [3, 8, 2, 8, 4, 8, 4, 8, 2, 8]\n",
      "GT transitions:  4\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.2512127236580517 0.13414409434309932 0.48021108179419525\n",
      "Num frames:  (10854, 7840)\n",
      "Accuracy:  0.2512127236580517\n",
      "Person:  235\n",
      "Transitions:  [3, 8, 2, 8, 1, 8, 0, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.9657594381035997 0.9888983774551665 0.946852003270646\n",
      "Num frames:  (1171, 13)\n",
      "Accuracy:  0.9657594381035997\n",
      "Person:  236\n",
      "Transitions:  [0, 8, 1, 8, 2, 8, 3, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.9230125523012552 0.8649754500818331 0.8837792642140468\n",
      "Num frames:  (1222, 45)\n",
      "Accuracy:  0.9230125523012552\n",
      "Person:  237\n",
      "Transitions:  [7, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.9555555555555556 0.9555555555555556 0.9591078066914498\n",
      "Num frames:  (270, 1)\n",
      "Accuracy:  0.9555555555555556\n",
      "Person:  238\n",
      "Transitions:  [7, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.9583333333333334 0.9583333333333334 0.9611940298507463\n",
      "Num frames:  (336, 1)\n",
      "Accuracy:  0.9583333333333334\n",
      "Person:  239\n",
      "Transitions:  [5, 8, 6, 8, 7, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.8757668711656442 0.8255563531945441 1.0\n",
      "Num frames:  (1393, 243)\n",
      "Accuracy:  0.8757668711656442\n",
      "Person:  240\n",
      "Transitions:  [7, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.9333333333333333 0.9333333333333333 0.9363057324840764\n",
      "Num frames:  (315, 1)\n",
      "Accuracy:  0.9333333333333333\n",
      "Person:  241\n",
      "Transitions:  [0, 8, 0, 8]\n",
      "GT transitions:  1\n",
      "Transitions captured:  0\n",
      "A,P,R:  0.6178521617852162 0.2159383033419023 0.20689655172413793\n",
      "Num frames:  (389, 226)\n",
      "Accuracy:  0.6178521617852162\n",
      "Person:  242\n",
      "Transitions:  [0, 8, 1, 8]\n",
      "GT transitions:  1\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.9317751105495894 0.8768529076396807 1.0\n",
      "Num frames:  (877, 108)\n",
      "Accuracy:  0.9317751105495894\n",
      "Person:  243\n",
      "Transitions:  [7, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.9411764705882353 0.9411764705882353 0.9446494464944649\n",
      "Num frames:  (272, 1)\n",
      "Accuracy:  0.9411764705882353\n",
      "Person:  244\n",
      "Transitions:  [5, 8, 4, 8, 1, 8, 0, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.9246329526916802 0.8760064412238325 1.0\n",
      "Num frames:  (1863, 231)\n",
      "Accuracy:  0.9246329526916802\n",
      "Person:  245\n",
      "Transitions:  [5, 8, 4, 8, 1, 8, 0, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.7250648431973591 0.6195758564437194 1.0\n",
      "Num frames:  (3065, 1166)\n",
      "Accuracy:  0.7250648431973591\n",
      "Person:  246\n",
      "Transitions:  [0, 8, 1, 8, 4, 8, 5, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.49124579124579126 0.19652173913043477 0.28999144568006846\n",
      "Num frames:  (1725, 681)\n",
      "Accuracy:  0.49124579124579126\n",
      "Person:  247\n",
      "Transitions:  [7, 8, 6, 8, 5, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.9515669515669516 0.9884467265725289 0.9288299155609168\n",
      "Num frames:  (779, 9)\n",
      "Accuracy:  0.9515669515669516\n",
      "Person:  248\n",
      "Transitions:  [7, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.9958847736625515 0.9958847736625515 1.0\n",
      "Num frames:  (243, 1)\n",
      "Accuracy:  0.9958847736625515\n",
      "Person:  249\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transitions:  [0, 8, 1, 8]\n",
      "GT transitions:  1\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.9117147707979627 0.8519924098671727 1.0\n",
      "Num frames:  (1054, 156)\n",
      "Accuracy:  0.9117147707979627\n",
      "Person:  250\n",
      "Transitions:  [7, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.9568106312292359 0.9568106312292359 0.96\n",
      "Num frames:  (301, 1)\n",
      "Accuracy:  0.9568106312292359\n",
      "Person:  251\n",
      "Transitions:  [7, 8, 6, 8, 5, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.526218383713757 0.3356258596973865 0.2582010582010582\n",
      "Num frames:  (727, 67)\n",
      "Accuracy:  0.526218383713757\n",
      "Person:  252\n",
      "Transitions:  [3, 8, 2, 8, 1, 8, 0, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.9303981871155714 0.884841992501339 1.0\n",
      "Num frames:  (1867, 215)\n",
      "Accuracy:  0.9303981871155714\n",
      "Person:  253\n",
      "Transitions:  [0, 8, 7, 8]\n",
      "GT transitions:  1\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.8675461741424803 0.7713498622589532 0.9893992932862191\n",
      "Num frames:  (1089, 242)\n",
      "Accuracy:  0.8675461741424803\n",
      "Person:  254\n",
      "Transitions:  [5, 8, 4, 8, 1, 8, 0, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.9710661910424099 0.956140350877193 0.9901589704769115\n",
      "Num frames:  (1368, 60)\n",
      "Accuracy:  0.9710661910424099\n",
      "Person:  255\n",
      "Transitions:  [6, 8, 7, 8]\n",
      "GT transitions:  1\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.8106060606060606 0.7032640949554896 1.0\n",
      "Num frames:  (674, 200)\n",
      "Accuracy:  0.8106060606060606\n",
      "Person:  256\n",
      "Transitions:  [0, 8, 1, 8, 4, 8, 5, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.47707349966284557 0.19722382880277617 0.2872788542544229\n",
      "Num frames:  (1729, 705)\n",
      "Accuracy:  0.47707349966284557\n",
      "Person:  257\n",
      "Transitions:  [5, 8, 4, 8, 0, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.8172888015717092 0.6833144154370034 1.0\n",
      "Num frames:  (1762, 558)\n",
      "Accuracy:  0.8172888015717092\n",
      "Person:  258\n",
      "Transitions:  [1, 8, 4, 8, 2, 8, 3, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.8527918781725888 0.7705696202531646 1.0\n",
      "Num frames:  (1264, 290)\n",
      "Accuracy:  0.8527918781725888\n",
      "Person:  259\n",
      "Transitions:  [5, 8, 4, 8, 1, 8, 0, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.9436519258202568 0.9136310223266745 0.9929757343550447\n",
      "Num frames:  (1702, 147)\n",
      "Accuracy:  0.9436519258202568\n",
      "Person:  260\n",
      "Transitions:  [5, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.9967637540453075 0.9967637540453075 1.0\n",
      "Num frames:  (309, 1)\n",
      "Accuracy:  0.9967637540453075\n",
      "Person:  261\n",
      "Transitions:  [7, 8, 6, 8, 5, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.9683501683501684 0.9942196531791907 0.9534368070953437\n",
      "Num frames:  (865, 5)\n",
      "Accuracy:  0.9683501683501684\n",
      "Person:  262\n",
      "Transitions:  [7, 8, 6, 8, 5, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.9554427523970671 0.928635953026197 1.0\n",
      "Num frames:  (1107, 79)\n",
      "Accuracy:  0.9554427523970671\n",
      "Person:  263\n",
      "Transitions:  [1, 8, 2, 8, 4, 8, 4, 8, 4, 8, 4, 8, 3, 8]\n",
      "GT transitions:  6\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.02673683216915235 0.017722013376946736 0.213215859030837\n",
      "Num frames:  (40966, 38564)\n",
      "Accuracy:  0.02673683216915235\n",
      "Person:  264\n",
      "Transitions:  [7, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.960431654676259 0.960431654676259 0.9638989169675091\n",
      "Num frames:  (278, 1)\n",
      "Accuracy:  0.960431654676259\n",
      "Person:  265\n",
      "Transitions:  [7, 8, 6, 8, 5, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.9507908611599297 0.9227099236641222 0.9969072164948454\n",
      "Num frames:  (1048, 81)\n",
      "Accuracy:  0.9507908611599297\n",
      "Person:  266\n",
      "Transitions:  [7, 8, 6, 8, 5, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.5194143857415658 0.32947976878612717 0.24945295404814005\n",
      "Num frames:  (692, 69)\n",
      "Accuracy:  0.5194143857415658\n",
      "Person:  267\n",
      "Transitions:  [0, 8, 1, 8]\n",
      "GT transitions:  1\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.9050211736237145 0.8340380549682875 1.0\n",
      "Num frames:  (946, 157)\n",
      "Accuracy:  0.9050211736237145\n",
      "Person:  268\n",
      "Transitions:  [4, 8, 2, 8, 3, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.9224519940915805 0.866751269035533 1.0\n",
      "Num frames:  (788, 105)\n",
      "Accuracy:  0.9224519940915805\n",
      "Person:  269\n",
      "Transitions:  [7, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.9540983606557377 0.9540983606557377 0.9572368421052632\n",
      "Num frames:  (305, 1)\n",
      "Accuracy:  0.9540983606557377\n",
      "Person:  270\n",
      "Transitions:  [2, 8, 1, 8, 0, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.9695945945945946 0.9605133267522211 0.9858156028368794\n",
      "Num frames:  (1013, 40)\n",
      "Accuracy:  0.9695945945945946\n",
      "Person:  271\n",
      "Transitions:  [7, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.9970326409495549 0.9970326409495549 1.0\n",
      "Num frames:  (337, 1)\n",
      "Accuracy:  0.9970326409495549\n",
      "Person:  272\n",
      "Transitions:  [3, 8, 2, 8, 1, 8, 0, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.9888712241653418 0.9890510948905109 0.9904970760233918\n",
      "Num frames:  (1370, 15)\n",
      "Accuracy:  0.9888712241653418\n",
      "Person:  273\n",
      "Transitions:  [7, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.9947643979057592 0.9947643979057592 1.0\n",
      "Num frames:  (191, 1)\n",
      "Accuracy:  0.9947643979057592\n",
      "Person:  274\n",
      "Transitions:  [3, 8, 2, 8, 1, 8, 0, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.9745923397800531 0.9618849618849619 0.9914285714285714\n",
      "Num frames:  (1443, 55)\n",
      "Accuracy:  0.9745923397800531\n",
      "Person:  275\n",
      "Transitions:  [7, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.9959514170040485 0.9959514170040485 1.0\n",
      "Num frames:  (247, 1)\n",
      "Accuracy:  0.9959514170040485\n",
      "Person:  276\n",
      "Transitions:  [7, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.960960960960961 0.960960960960961 0.963855421686747\n",
      "Num frames:  (333, 1)\n",
      "Accuracy:  0.960960960960961\n",
      "Person:  277\n",
      "Transitions:  [1, 8, 2, 8, 3, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.9406139909411173 0.9164305949008499 0.9877862595419847\n",
      "Num frames:  (1412, 102)\n",
      "Accuracy:  0.9406139909411173\n",
      "Person:  278\n",
      "Transitions:  [1, 8, 0, 8]\n",
      "GT transitions:  1\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.8812423873325214 0.8186046511627907 0.9932279909706546\n",
      "Num frames:  (1075, 189)\n",
      "Accuracy:  0.8812423873325214\n",
      "Person:  279\n",
      "Transitions:  [5, 8, 4, 8, 1, 8, 0, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.9422190712513293 0.8984867591424969 0.9985984583041345\n",
      "Num frames:  (1586, 161)\n",
      "Accuracy:  0.9422190712513293\n",
      "Person:  280\n",
      "Transitions:  [7, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.961764705882353 0.961764705882353 0.9646017699115044\n",
      "Num frames:  (340, 1)\n",
      "Accuracy:  0.961764705882353\n",
      "Person:  281\n",
      "Transitions:  [1, 8, 0, 8]\n",
      "GT transitions:  1\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.9517839922854388 0.9795918367346939 0.9214659685863874\n",
      "Num frames:  (539, 5)\n",
      "Accuracy:  0.9517839922854388\n",
      "Person:  282\n",
      "Transitions:  [7, 8, 6, 8, 5, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.9662522202486679 0.9474196689386563 0.9969262295081968\n",
      "Num frames:  (1027, 54)\n",
      "Accuracy:  0.9662522202486679\n",
      "Person:  283\n",
      "Transitions:  [0, 8, 7, 8]\n",
      "GT transitions:  1\n",
      "Transitions captured:  0\n",
      "A,P,R:  0.7762955361723961 0.5742024965325936 0.5679012345679012\n",
      "Num frames:  (721, 121)\n",
      "Accuracy:  0.7762955361723961\n",
      "Person:  284\n",
      "Transitions:  [0, 8, 1, 8, 2, 8, 4, 8, 5, 8]\n",
      "GT transitions:  4\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.26274944567627495 0.13837037037037037 0.1682882882882883\n",
      "Num frames:  (3375, 1017)\n",
      "Accuracy:  0.26274944567627495\n",
      "Person:  285\n",
      "Transitions:  [5, 8, 4, 8, 1, 8, 0, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.9609106529209622 0.9517786561264822 0.9756888168557536\n",
      "Num frames:  (1265, 61)\n",
      "Accuracy:  0.9609106529209622\n",
      "Person:  286\n",
      "Transitions:  [1, 8, 1, 8]\n",
      "GT transitions:  1\n",
      "Transitions captured:  0\n",
      "A,P,R:  0.334447261273719 0.022881986156398377 0.4722550177095632\n",
      "Num frames:  (17481, 16880)\n",
      "Accuracy:  0.334447261273719\n",
      "Person:  287\n",
      "Transitions:  [7, 8, 6, 8, 5, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.926021727884118 0.8869565217391304 1.0\n",
      "Num frames:  (1265, 143)\n",
      "Accuracy:  0.926021727884118\n",
      "Person:  288\n",
      "Transitions:  [0, 8, 1, 8, 4, 8, 5, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.5525349008082292 0.28286852589641437 0.36597938144329895\n",
      "Num frames:  (1506, 480)\n",
      "Accuracy:  0.5525349008082292\n",
      "Person:  289\n",
      "Transitions:  [3, 8, 2, 8, 1, 8, 0, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.9698167445203019 0.947069943289225 0.996684350132626\n",
      "Num frames:  (1587, 79)\n",
      "Accuracy:  0.9698167445203019\n",
      "Person:  290\n",
      "Transitions:  [0, 8, 1, 8]\n",
      "GT transitions:  1\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.9047619047619048 0.8396946564885496 1.0\n",
      "Num frames:  (1048, 168)\n",
      "Accuracy:  0.9047619047619048\n",
      "Person:  291\n",
      "Transitions:  [7, 8, 6, 8, 5, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.5177261613691931 0.3413654618473896 0.26479750778816197\n",
      "Num frames:  (747, 81)\n",
      "Accuracy:  0.5177261613691931\n",
      "Person:  292\n",
      "Transitions:  [7, 8, 6, 8, 5, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.9154929577464789 0.9954887218045113 0.863102998696219\n",
      "Num frames:  (665, 3)\n",
      "Accuracy:  0.9154929577464789\n",
      "Person:  293\n",
      "Transitions:  [1, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.9827586206896551 0.9827586206896551 0.9851851851851852\n",
      "Num frames:  (406, 1)\n",
      "Accuracy:  0.9827586206896551\n",
      "Person:  294\n",
      "Transitions:  [7, 8, 6, 8, 5, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.4950146627565982 0.3125778331257783 0.2558613659531091\n",
      "Num frames:  (803, 131)\n",
      "Accuracy:  0.4950146627565982\n",
      "Person:  295\n",
      "Transitions:  [7, 8, 0, 8]\n",
      "GT transitions:  1\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.8650378126817917 0.7613168724279835 0.9840425531914894\n",
      "Num frames:  (972, 220)\n",
      "Accuracy:  0.8650378126817917\n",
      "Person:  296\n",
      "Transitions:  [0, 8, 1, 8]\n",
      "GT transitions:  1\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.943609022556391 0.8986486486486487 1.0\n",
      "Num frames:  (888, 90)\n",
      "Accuracy:  0.943609022556391\n",
      "Person:  297\n",
      "Transitions:  [3, 8, 2, 8, 1, 8, 0, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.9630642954856361 0.937245787332946 1.0\n",
      "Num frames:  (1721, 108)\n",
      "Accuracy:  0.9630642954856361\n",
      "Person:  298\n",
      "Transitions:  [0, 8, 7, 8, 7, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.6984973339796413 0.46275395033860045 0.737410071942446\n",
      "Num frames:  (886, 476)\n",
      "Accuracy:  0.6984973339796413\n",
      "Person:  299\n",
      "Transitions:  [0, 8, 1, 8]\n",
      "GT transitions:  1\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.7298387096774194 0.84 0.5185185185185185\n",
      "Num frames:  (450, 51)\n",
      "Accuracy:  0.7298387096774194\n",
      "Person:  300\n",
      "Transitions:  [0, 8, 1, 8, 2, 8, 3, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.8586601307189542 0.7805496828752643 1.0\n",
      "Num frames:  (2365, 519)\n",
      "Accuracy:  0.8586601307189542\n",
      "Person:  301\n",
      "Transitions:  [7, 8, 0, 8]\n",
      "GT transitions:  1\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.8635029354207436 0.7840557275541795 0.9863680623174295\n",
      "Num frames:  (1292, 265)\n",
      "Accuracy:  0.8635029354207436\n",
      "Person:  302\n",
      "Transitions:  [5, 8, 6, 8, 4, 8, 1, 8, 0, 8]\n",
      "GT transitions:  4\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.7575075075075075 0.7062228654124457 0.8026315789473685\n",
      "Num frames:  (1382, 406)\n",
      "Accuracy:  0.7575075075075075\n",
      "Person:  303\n",
      "Transitions:  [0, 8, 1, 8, 2, 8, 3, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.9242032730404823 0.8716157205240175 0.8633217993079585\n",
      "Num frames:  (1145, 18)\n",
      "Accuracy:  0.9242032730404823\n",
      "Person:  304\n",
      "Transitions:  [3, 8, 2, 8, 1, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.9766536964980544 0.9957805907172996 0.9672131147540983\n",
      "Num frames:  (948, 4)\n",
      "Accuracy:  0.9766536964980544\n",
      "Person:  305\n",
      "Transitions:  [0, 8, 1, 8]\n",
      "GT transitions:  1\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.18168242906918866 0.07722165474974464 0.07338380896913221\n",
      "Num frames:  (4895, 159)\n",
      "Accuracy:  0.18168242906918866\n",
      "Person:  306\n",
      "Transitions:  [5, 8, 6, 8, 7, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.8908045977011494 0.8399326032013479 1.0\n",
      "Num frames:  (1187, 190)\n",
      "Accuracy:  0.8908045977011494\n",
      "Person:  307\n",
      "Transitions:  [7, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.9463087248322147 0.9463087248322147 0.9494949494949495\n",
      "Num frames:  (298, 1)\n",
      "Accuracy:  0.9463087248322147\n",
      "Person:  308\n",
      "Transitions:  [2, 8, 4, 8, 5, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.9064935064935065 0.926954732510288 0.8903162055335968\n",
      "Num frames:  (972, 33)\n",
      "Accuracy:  0.9064935064935065\n",
      "Person:  309\n",
      "Transitions:  [5, 8, 6, 8, 7, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.8870204939569102 0.8391922213911742 1.0\n",
      "Num frames:  (1337, 215)\n",
      "Accuracy:  0.8870204939569102\n",
      "Person:  310\n",
      "Transitions:  [7, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.9365671641791045 0.9365671641791045 0.9400749063670412\n",
      "Num frames:  (268, 1)\n",
      "Accuracy:  0.9365671641791045\n",
      "Person:  311\n",
      "Transitions:  [0, 8, 1, 8, 4, 8, 5, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.33490566037735847 0.17008797653958943 0.2115501519756839\n",
      "Num frames:  (2046, 818)\n",
      "Accuracy:  0.33490566037735847\n",
      "Person:  312\n",
      "Transitions:  [0, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.995 0.995 1.0\n",
      "Num frames:  (200, 1)\n",
      "Accuracy:  0.995\n",
      "Person:  313\n",
      "Transitions:  [7, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.9518072289156626 0.9518072289156626 0.9546827794561934\n",
      "Num frames:  (332, 1)\n",
      "Accuracy:  0.9518072289156626\n",
      "Person:  314\n",
      "Transitions:  [7, 8, 6, 8, 5, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.9501698754246886 0.919634703196347 1.0\n",
      "Num frames:  (1095, 88)\n",
      "Accuracy:  0.9501698754246886\n",
      "Person:  315\n",
      "Transitions:  [4, 8, 5, 8]\n",
      "GT transitions:  1\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.9556213017751479 0.9337349397590361 0.998389694041868\n",
      "Num frames:  (664, 44)\n",
      "Accuracy:  0.9556213017751479\n",
      "Person:  316\n",
      "Transitions:  [5, 8, 6, 8, 7, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.8664353859496965 0.9010989010989011 0.8631578947368421\n",
      "Num frames:  (637, 63)\n",
      "Accuracy:  0.8664353859496965\n",
      "Person:  317\n",
      "Transitions:  [0, 8, 1, 8]\n",
      "GT transitions:  1\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.9441978440076094 0.8985005767012687 1.0\n",
      "Num frames:  (867, 88)\n",
      "Accuracy:  0.9441978440076094\n",
      "Person:  318\n",
      "Transitions:  [0, 8, 1, 8]\n",
      "GT transitions:  1\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.8535096642929807 0.7726913970007893 1.0\n",
      "Num frames:  (1267, 288)\n",
      "Accuracy:  0.8535096642929807\n",
      "Person:  319\n",
      "Transitions:  [7, 8, 0, 8]\n",
      "GT transitions:  1\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.8897100625355315 0.7506426735218509 1.0\n",
      "Num frames:  (778, 194)\n",
      "Accuracy:  0.8897100625355315\n",
      "Person:  320\n",
      "Transitions:  [7, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A,P,R:  0.9756944444444444 0.9756944444444444 0.9790940766550522\n",
      "Num frames:  (288, 1)\n",
      "Accuracy:  0.9756944444444444\n",
      "Person:  321\n",
      "Transitions:  [5, 8, 6, 8, 7, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.8849206349206349 0.8325082508250825 1.0\n",
      "Num frames:  (1212, 203)\n",
      "Accuracy:  0.8849206349206349\n",
      "Person:  322\n",
      "Transitions:  [6, 8, 4, 8, 1, 8, 0, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.633122028526149 0.5172921265636498 0.7108190091001011\n",
      "Num frames:  (1359, 640)\n",
      "Accuracy:  0.633122028526149\n",
      "Person:  323\n",
      "Transitions:  [6, 8, 7, 8, 0, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.8598774885145483 0.7553475935828877 1.0\n",
      "Num frames:  (1496, 366)\n",
      "Accuracy:  0.8598774885145483\n",
      "Person:  324\n",
      "Transitions:  [7, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.9515570934256056 0.9515570934256056 0.9548611111111112\n",
      "Num frames:  (289, 1)\n",
      "Accuracy:  0.9515570934256056\n",
      "Person:  325\n",
      "Transitions:  [5, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.9961089494163424 0.9961089494163424 1.0\n",
      "Num frames:  (257, 1)\n",
      "Accuracy:  0.9961089494163424\n",
      "Person:  326\n",
      "Transitions:  [5, 8, 6, 8, 7, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.9029069767441861 0.8555363321799307 1.0\n",
      "Num frames:  (1156, 167)\n",
      "Accuracy:  0.9029069767441861\n",
      "Person:  327\n",
      "Transitions:  [5, 8, 4, 8, 1, 8, 0, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.9286675639300135 0.8814317673378076 1.0\n",
      "Num frames:  (1788, 212)\n",
      "Accuracy:  0.9286675639300135\n",
      "Person:  328\n",
      "Transitions:  [0, 8, 1, 8, 2, 8, 3, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.3899240855762595 0.2094329028635598 0.2567102546455609\n",
      "Num frames:  (1781, 688)\n",
      "Accuracy:  0.3899240855762595\n",
      "Person:  329\n",
      "Transitions:  [5, 8, 6, 8]\n",
      "GT transitions:  1\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.9658213891951488 0.9653794940079894 0.9931506849315068\n",
      "Num frames:  (751, 26)\n",
      "Accuracy:  0.9658213891951488\n",
      "Person:  330\n",
      "Transitions:  [1, 8, 0, 8]\n",
      "GT transitions:  1\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.9092198581560283 0.8478002378121284 0.9916550764951322\n",
      "Num frames:  (841, 122)\n",
      "Accuracy:  0.9092198581560283\n",
      "Person:  331\n",
      "Transitions:  [7, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.9873417721518988 0.9873417721518988 1.0\n",
      "Num frames:  (79, 1)\n",
      "Accuracy:  0.9873417721518988\n",
      "Person:  332\n",
      "Transitions:  [0, 8, 1, 8, 2, 8, 3, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.923325784535749 0.8684064408661855 1.0\n",
      "Num frames:  (1801, 237)\n",
      "Accuracy:  0.923325784535749\n",
      "Person:  333\n",
      "Transitions:  [7, 8, 6, 8, 5, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.9454456892352655 0.9188405797101449 1.0\n",
      "Num frames:  (1380, 112)\n",
      "Accuracy:  0.9454456892352655\n",
      "Person:  334\n",
      "Transitions:  [7, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.9615384615384616 0.9615384615384616 0.9646302250803859\n",
      "Num frames:  (312, 1)\n",
      "Accuracy:  0.9615384615384616\n",
      "Person:  335\n",
      "Transitions:  [3, 8, 2, 8, 1, 8, 0, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.9433447098976109 0.9033760186263097 1.0\n",
      "Num frames:  (1718, 166)\n",
      "Accuracy:  0.9433447098976109\n",
      "Person:  336\n",
      "Transitions:  [2, 8, 1, 8, 0, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.951307484220018 0.9340277777777778 0.9904270986745214\n",
      "Num frames:  (1440, 95)\n",
      "Accuracy:  0.951307484220018\n",
      "Person:  337\n",
      "Transitions:  [7, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.996309963099631 0.996309963099631 1.0\n",
      "Num frames:  (271, 1)\n",
      "Accuracy:  0.996309963099631\n",
      "Person:  338\n",
      "Transitions:  [7, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.9416342412451362 0.9416342412451362 0.9453125\n",
      "Num frames:  (257, 1)\n",
      "Accuracy:  0.9416342412451362\n",
      "Person:  339\n",
      "Transitions:  [0, 8, 1, 8, 2, 8, 3, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.8777103209019947 0.8053382420616659 1.0\n",
      "Num frames:  (2173, 423)\n",
      "Accuracy:  0.8777103209019947\n",
      "Person:  340\n",
      "Transitions:  [5, 8, 6, 8, 7, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.9036144578313253 0.8546775658492279 1.0\n",
      "Num frames:  (1101, 160)\n",
      "Accuracy:  0.9036144578313253\n",
      "Person:  341\n",
      "Transitions:  [0, 8, 1, 8, 4, 8, 5, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.9016139044072005 0.8124629080118695 0.9992700729927008\n",
      "Num frames:  (1685, 316)\n",
      "Accuracy:  0.9016139044072005\n",
      "Person:  342\n",
      "Transitions:  [2, 8, 1, 8]\n",
      "GT transitions:  1\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.975443383356071 0.994263862332696 0.9719626168224299\n",
      "Num frames:  (523, 3)\n",
      "Accuracy:  0.975443383356071\n",
      "Person:  343\n",
      "Transitions:  [3, 8, 2, 8, 1, 8, 0, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.9735411380935122 0.957078795643818 0.996\n",
      "Num frames:  (1561, 67)\n",
      "Accuracy:  0.9735411380935122\n",
      "Person:  344\n",
      "Transitions:  [3, 8, 2, 8, 1, 8, 0, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.9798657718120806 0.9913793103448276 0.9715821812596006\n",
      "Num frames:  (1276, 11)\n",
      "Accuracy:  0.9798657718120806\n",
      "Person:  345\n",
      "Transitions:  [3, 8, 2, 8, 1, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.9662309368191722 0.9560283687943263 1.0\n",
      "Num frames:  (2115, 93)\n",
      "Accuracy:  0.9662309368191722\n",
      "Person:  346\n",
      "Transitions:  [2, 8, 4, 8, 5, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.9293399243966269 0.9219409282700421 0.9809203142536476\n",
      "Num frames:  (2844, 192)\n",
      "Accuracy:  0.9293399243966269\n",
      "Person:  347\n",
      "Transitions:  [7, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.9958677685950413 0.9958677685950413 1.0\n",
      "Num frames:  (242, 1)\n",
      "Accuracy:  0.9958677685950413\n",
      "Person:  348\n",
      "Transitions:  [1, 8, 7, 8]\n",
      "GT transitions:  1\n",
      "Transitions captured:  0\n",
      "A,P,R:  0.7074235807860262 0.627260083449235 0.8501413760603205\n",
      "Num frames:  (1438, 377)\n",
      "Accuracy:  0.7074235807860262\n",
      "Person:  349\n",
      "Transitions:  [3, 8, 2, 8, 1, 8, 0, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.41625732847409286 0.28238747553816046 0.9883561643835617\n",
      "Num frames:  (5110, 3667)\n",
      "Accuracy:  0.41625732847409286\n",
      "Person:  350\n",
      "Transitions:  [7, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.9642857142857143 0.9642857142857143 0.9669421487603306\n",
      "Num frames:  (364, 1)\n",
      "Accuracy:  0.9642857142857143\n",
      "Person:  351\n",
      "Transitions:  [0, 8, 1, 8, 4, 8, 6, 8, 5, 8]\n",
      "GT transitions:  4\n",
      "Transitions captured:  4\n",
      "A,P,R:  0.8201581027667985 0.732615083251714 0.9953426480372588\n",
      "Num frames:  (2042, 539)\n",
      "Accuracy:  0.8201581027667985\n",
      "Person:  352\n",
      "Transitions:  [5, 8, 4, 8, 1, 8, 0, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.939183987682833 0.9103078982597055 0.9826589595375722\n",
      "Num frames:  (1494, 134)\n",
      "Accuracy:  0.939183987682833\n",
      "Person:  353\n",
      "Transitions:  [3, 8, 2, 8, 1, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.7898832684824902 0.814868804664723 0.6767554479418886\n",
      "Num frames:  (686, 3)\n",
      "Accuracy:  0.7898832684824902\n",
      "Person:  354\n",
      "Transitions:  [7, 8, 6, 8, 5, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.9521739130434783 0.9251063829787234 1.0\n",
      "Num frames:  (1175, 88)\n",
      "Accuracy:  0.9521739130434783\n",
      "Person:  355\n",
      "Transitions:  [0, 8, 1, 8, 4, 8, 5, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.36691884456671253 0.19519015659955258 0.2281045751633987\n",
      "Num frames:  (1788, 660)\n",
      "Accuracy:  0.36691884456671253\n",
      "Person:  356\n",
      "Transitions:  [0, 8, 1, 8, 4, 8, 5, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.9202322738386308 0.8718703976435935 1.0\n",
      "Num frames:  (2037, 261)\n",
      "Accuracy:  0.9202322738386308\n",
      "Person:  357\n",
      "Transitions:  [7, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.9968253968253968 0.9968253968253968 1.0\n",
      "Num frames:  (315, 1)\n",
      "Accuracy:  0.9968253968253968\n",
      "Person:  358\n",
      "Transitions:  [6, 8, 4, 8, 2, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.8823218997361477 0.8688427299703264 0.9986357435197817\n",
      "Num frames:  (1685, 221)\n",
      "Accuracy:  0.8823218997361477\n",
      "Person:  359\n",
      "Transitions:  [3, 8, 2, 8, 1, 8, 0, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.9941014549744397 0.9914712153518124 0.9978540772532188\n",
      "Num frames:  (1407, 12)\n",
      "Accuracy:  0.9941014549744397\n",
      "Person:  360\n",
      "Transitions:  [7, 8, 6, 8, 5, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.8296442687747035 0.7663956639566396 1.0\n",
      "Num frames:  (1845, 431)\n",
      "Accuracy:  0.8296442687747035\n",
      "Person:  361\n",
      "Transitions:  [6, 8, 4, 8, 0, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.6854780733285406 0.4554643082754264 0.9822888283378747\n",
      "Num frames:  (1583, 862)\n",
      "Accuracy:  0.6854780733285406\n",
      "Person:  362\n",
      "Transitions:  [4, 8, 1, 8, 0, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.9251355606087108 0.9111111111111111 1.0\n",
      "Num frames:  (4815, 428)\n",
      "Accuracy:  0.9251355606087108\n",
      "Person:  363\n",
      "Transitions:  [3, 8, 2, 8, 1, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.9642116182572614 0.9468334636434714 0.9991749174917491\n",
      "Num frames:  (1279, 68)\n",
      "Accuracy:  0.9642116182572614\n",
      "Person:  364\n",
      "Transitions:  [7, 8, 6, 8, 5, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.8738461538461538 0.8215174129353234 1.0\n",
      "Num frames:  (1608, 287)\n",
      "Accuracy:  0.8738461538461538\n",
      "Person:  365\n",
      "Transitions:  [7, 8, 6, 8, 5, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.9623307828134197 0.9384023099133783 1.0\n",
      "Num frames:  (1039, 64)\n",
      "Accuracy:  0.9623307828134197\n",
      "Person:  366\n",
      "Transitions:  [3, 8, 2, 8, 1, 8, 0, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.9771473601260835 0.9774872912127814 0.9803350327749454\n",
      "Num frames:  (1377, 31)\n",
      "Accuracy:  0.9771473601260835\n",
      "Person:  367\n",
      "Transitions:  [7, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.9556313993174061 0.9556313993174061 0.958904109589041\n",
      "Num frames:  (293, 1)\n",
      "Accuracy:  0.9556313993174061\n",
      "Person:  368\n",
      "Transitions:  [7, 8, 6, 8, 5, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.9051680883090818 0.8573584905660377 1.0\n",
      "Num frames:  (1325, 189)\n",
      "Accuracy:  0.9051680883090818\n",
      "Person:  369\n",
      "Transitions:  [5, 8, 4, 8, 7, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.9444967074317968 0.8903036238981391 0.9934426229508196\n",
      "Num frames:  (1021, 112)\n",
      "Accuracy:  0.9444967074317968\n",
      "Person:  370\n",
      "Transitions:  [0, 8, 1, 8, 2, 8, 3, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.9077167859984089 0.8651597817614964 0.8692247454972593\n",
      "Num frames:  (1283, 65)\n",
      "Accuracy:  0.9077167859984089\n",
      "Person:  371\n",
      "Transitions:  [1, 8, 4, 8]\n",
      "GT transitions:  1\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.8540706605222734 0.8337707786526685 1.0\n",
      "Num frames:  (1143, 190)\n",
      "Accuracy:  0.8540706605222734\n",
      "Person:  372\n",
      "Transitions:  [1, 8, 2, 8, 4, 8, 5, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.9170506912442397 0.9080932784636488 0.9350282485875706\n",
      "Num frames:  (1458, 88)\n",
      "Accuracy:  0.9170506912442397\n",
      "Person:  373\n",
      "Transitions:  [5, 8, 4, 8, 1, 8, 0, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.9741842954463965 0.9565217391304348 0.9987212276214834\n",
      "Num frames:  (1633, 70)\n",
      "Accuracy:  0.9741842954463965\n",
      "Person:  374\n",
      "Transitions:  [7, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.9536679536679536 0.9536679536679536 0.9573643410852714\n",
      "Num frames:  (259, 1)\n",
      "Accuracy:  0.9536679536679536\n",
      "Person:  375\n",
      "Transitions:  [5, 8, 4, 8]\n",
      "GT transitions:  1\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.9526011560693641 0.9708404802744426 0.9593220338983051\n",
      "Num frames:  (583, 17)\n",
      "Accuracy:  0.9526011560693641\n",
      "Person:  376\n",
      "Transitions:  [0, 8, 1, 8, 2, 8, 3, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.950278164116829 0.9099496221662469 1.0\n",
      "Num frames:  (1588, 143)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.950278164116829\n",
      "Person:  377\n",
      "Transitions:  [0, 8, 1, 8]\n",
      "GT transitions:  1\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.9250629722921915 0.8641552511415526 1.0\n",
      "Num frames:  (876, 119)\n",
      "Accuracy:  0.9250629722921915\n",
      "Person:  378\n",
      "Transitions:  [0, 8, 1, 8, 2, 8, 3, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.3814852492370295 0.19241192411924118 0.2384150436534587\n",
      "Num frames:  (1845, 690)\n",
      "Accuracy:  0.3814852492370295\n",
      "Person:  379\n",
      "Transitions:  [7, 8, 6, 8, 5, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.5088967971530249 0.29912390488110135 0.2304725168756027\n",
      "Num frames:  (799, 30)\n",
      "Accuracy:  0.5088967971530249\n",
      "Person:  380\n",
      "Transitions:  [7, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.9642857142857143 0.9642857142857143 0.9669421487603306\n",
      "Num frames:  (364, 1)\n",
      "Accuracy:  0.9642857142857143\n",
      "Person:  381\n",
      "Transitions:  [5, 8, 4, 8, 1, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.9174917491749175 0.8856209150326797 1.0\n",
      "Num frames:  (1530, 175)\n",
      "Accuracy:  0.9174917491749175\n",
      "Person:  382\n",
      "Transitions:  [7, 8, 0, 8]\n",
      "GT transitions:  1\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.9392812887236679 0.8761061946902655 1.0\n",
      "Num frames:  (791, 98)\n",
      "Accuracy:  0.9392812887236679\n",
      "Person:  383\n",
      "Transitions:  [0, 8, 1, 8]\n",
      "GT transitions:  1\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.7598450613298903 0.920303605313093 0.5801435406698564\n",
      "Num frames:  (527, 21)\n",
      "Accuracy:  0.7598450613298903\n",
      "Person:  384\n",
      "Transitions:  [0, 8, 1, 8]\n",
      "GT transitions:  1\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.5627394636015326 0.47835497835497837 0.45286885245901637\n",
      "Num frames:  (924, 379)\n",
      "Accuracy:  0.5627394636015326\n",
      "Person:  385\n",
      "Transitions:  [3, 8, 2, 8, 1, 8, 0, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.9695238095238096 0.9508426966292135 0.9926686217008798\n",
      "Num frames:  (1424, 70)\n",
      "Accuracy:  0.9695238095238096\n",
      "Person:  386\n",
      "Transitions:  [5, 8, 6, 8, 7, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.8495192307692307 0.7940789473684211 1.0\n",
      "Num frames:  (1520, 313)\n",
      "Accuracy:  0.8495192307692307\n",
      "Person:  387\n",
      "Transitions:  [4, 8, 7, 8]\n",
      "GT transitions:  1\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.8584136397331357 0.9732142857142857 0.7558945908460472\n",
      "Num frames:  (560, 15)\n",
      "Accuracy:  0.8584136397331357\n",
      "Person:  388\n",
      "Transitions:  [0, 8, 1, 8]\n",
      "GT transitions:  1\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.9570361145703612 0.9233333333333333 1.0\n",
      "Num frames:  (900, 69)\n",
      "Accuracy:  0.9570361145703612\n",
      "Person:  389\n",
      "Transitions:  [7, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.9353846153846154 0.9353846153846154 0.9382716049382716\n",
      "Num frames:  (325, 1)\n",
      "Accuracy:  0.9353846153846154\n",
      "Person:  390\n",
      "Transitions:  [5, 8, 6, 8, 7, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.8496732026143791 0.7979924717691342 1.0\n",
      "Num frames:  (1594, 322)\n",
      "Accuracy:  0.8496732026143791\n",
      "Person:  391\n",
      "Transitions:  [7, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.9722222222222222 0.9722222222222222 0.9767441860465116\n",
      "Num frames:  (216, 1)\n",
      "Accuracy:  0.9722222222222222\n",
      "Person:  392\n",
      "Transitions:  [5, 8, 4, 8, 4, 8, 4, 8, 1, 8, 0, 8]\n",
      "GT transitions:  5\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.6090329731227487 0.5380020597322348 0.65529352734571\n",
      "Num frames:  (4855, 1448)\n",
      "Accuracy:  0.6090329731227487\n",
      "Person:  393\n",
      "Transitions:  [7, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.9945054945054945 0.9945054945054945 1.0\n",
      "Num frames:  (182, 1)\n",
      "Accuracy:  0.9945054945054945\n",
      "Person:  394\n",
      "Transitions:  [7, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.9708333333333333 0.9708333333333333 0.9728601252609603\n",
      "Num frames:  (480, 1)\n",
      "Accuracy:  0.9708333333333333\n",
      "Person:  395\n",
      "Transitions:  [7, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.9459459459459459 0.9459459459459459 0.9496124031007752\n",
      "Num frames:  (259, 1)\n",
      "Accuracy:  0.9459459459459459\n",
      "Person:  396\n",
      "Transitions:  [0, 8, 1, 8, 4, 8, 5, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.9079365079365079 0.8551316984559492 1.0\n",
      "Num frames:  (2202, 319)\n",
      "Accuracy:  0.9079365079365079\n",
      "Person:  397\n",
      "Transitions:  [0, 8, 1, 8, 7, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.7791710205503309 0.6347184986595175 0.7273425499231951\n",
      "Num frames:  (1492, 279)\n",
      "Accuracy:  0.7791710205503309\n",
      "Person:  398\n",
      "Transitions:  [3, 8, 2, 8, 1, 8, 0, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.9832201358369956 0.9897884755652808 0.9797833935018051\n",
      "Num frames:  (1371, 14)\n",
      "Accuracy:  0.9832201358369956\n",
      "Person:  399\n",
      "Transitions:  [5, 8, 4, 8, 1, 8, 0, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.9618768328445748 0.9339805825242719 0.9986159169550173\n",
      "Num frames:  (1545, 102)\n",
      "Accuracy:  0.9618768328445748\n",
      "Person:  400\n",
      "Transitions:  [3, 8, 2, 8, 1, 8, 0, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.966547192353644 0.9612518628912071 0.9757942511346445\n",
      "Num frames:  (1342, 52)\n",
      "Accuracy:  0.966547192353644\n",
      "Person:  401\n",
      "Transitions:  [5, 8, 6, 8, 7, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.9420689655172414 0.9116022099447514 0.9951749095295537\n",
      "Num frames:  (905, 80)\n",
      "Accuracy:  0.9420689655172414\n",
      "Person:  402\n",
      "Transitions:  [5, 8, 4, 8, 1, 8, 0, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.9325492909028018 0.8858981860737273 1.0\n",
      "Num frames:  (1709, 195)\n",
      "Accuracy:  0.9325492909028018\n",
      "Person:  403\n",
      "Transitions:  [5, 8, 6, 8, 7, 8, 0, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.9533160429788811 0.9152086137281292 0.9912536443148688\n",
      "Num frames:  (1486, 114)\n",
      "Accuracy:  0.9533160429788811\n",
      "Person:  404\n",
      "Transitions:  [7, 8, 6, 8, 5, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.8790974882928906 0.8308516974389517 1.0\n",
      "Num frames:  (1679, 284)\n",
      "Accuracy:  0.8790974882928906\n",
      "Person:  405\n",
      "Transitions:  [0, 8, 4, 8, 6, 8, 5, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.7229184071289334 0.5397196261682243 0.9600997506234414\n",
      "Num frames:  (2140, 947)\n",
      "Accuracy:  0.7229184071289334\n",
      "Person:  406\n",
      "Transitions:  [7, 8, 0, 8]\n",
      "GT transitions:  1\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.9135667396061269 0.8198403648802737 1.0\n",
      "Num frames:  (877, 158)\n",
      "Accuracy:  0.9135667396061269\n",
      "Person:  407\n",
      "Transitions:  [0, 8, 1, 8, 2, 8, 3, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.4004879749041478 0.20401146131805156 0.2487770789657582\n",
      "Num frames:  (1745, 645)\n",
      "Accuracy:  0.4004879749041478\n",
      "Person:  408\n",
      "Transitions:  [2, 8, 4, 8, 1, 8, 0, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.9279484262419416 0.8916827852998066 0.9537931034482758\n",
      "Num frames:  (1551, 123)\n",
      "Accuracy:  0.9279484262419416\n",
      "Person:  409\n",
      "Transitions:  [3, 8, 2, 8, 1, 8, 0, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.9523146536721198 0.9222022740873729 0.9954780361757106\n",
      "Num frames:  (1671, 130)\n",
      "Accuracy:  0.9523146536721198\n",
      "Person:  410\n",
      "Transitions:  [7, 8, 0, 8]\n",
      "GT transitions:  1\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.9039278131634819 0.8412280701754385 1.0\n",
      "Num frames:  (1140, 181)\n",
      "Accuracy:  0.9039278131634819\n",
      "Person:  411\n",
      "Transitions:  [5, 8, 4, 8, 1, 8, 0, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.9292317500796939 0.8870229007633588 1.0\n",
      "Num frames:  (1965, 222)\n",
      "Accuracy:  0.9292317500796939\n",
      "Person:  412\n",
      "Transitions:  [1, 8, 0, 8]\n",
      "GT transitions:  1\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.9616801768607222 0.935687263556116 0.9906542056074766\n",
      "Num frames:  (793, 45)\n",
      "Accuracy:  0.9616801768607222\n",
      "Person:  413\n",
      "Transitions:  [7, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.9554140127388535 0.9554140127388535 0.9584664536741214\n",
      "Num frames:  (314, 1)\n",
      "Accuracy:  0.9554140127388535\n",
      "Person:  414\n",
      "Transitions:  [5, 8, 6, 8, 4, 8, 1, 8, 0, 8]\n",
      "GT transitions:  4\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.7174978379936581 0.6002805049088359 0.9099929128277817\n",
      "Num frames:  (2139, 853)\n",
      "Accuracy:  0.7174978379936581\n",
      "Person:  415\n",
      "Transitions:  [6, 8, 7, 8]\n",
      "GT transitions:  1\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.7724649629018961 0.6706443914081146 1.0\n",
      "Num frames:  (838, 276)\n",
      "Accuracy:  0.7724649629018961\n",
      "Person:  416\n",
      "Transitions:  [0, 8, 1, 8, 2, 8, 3, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.8917120387174834 0.8215353938185443 1.0\n",
      "Num frames:  (2006, 358)\n",
      "Accuracy:  0.8917120387174834\n",
      "Person:  417\n",
      "Transitions:  [7, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.9939393939393939 0.9939393939393939 1.0\n",
      "Num frames:  (165, 1)\n",
      "Accuracy:  0.9939393939393939\n",
      "Person:  418\n",
      "Transitions:  [5, 8, 6, 8, 7, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.8787222523010287 0.8254091971940763 1.0\n",
      "Num frames:  (1283, 224)\n",
      "Accuracy:  0.8787222523010287\n",
      "Person:  419\n",
      "Transitions:  [6, 8, 5, 8]\n",
      "GT transitions:  1\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.9136186770428015 0.9018567639257294 1.0\n",
      "Num frames:  (1131, 111)\n",
      "Accuracy:  0.9136186770428015\n",
      "Person:  420\n",
      "Transitions:  [0, 8, 1, 8, 2, 8, 3, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.4950269963057687 0.32420612283704126 1.0\n",
      "Num frames:  (5259, 3554)\n",
      "Accuracy:  0.4950269963057687\n",
      "Person:  421\n",
      "Transitions:  [0, 8, 1, 8, 2, 8, 3, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A,P,R:  0.9218241042345277 0.8658468418110676 1.0\n",
      "Num frames:  (1789, 240)\n",
      "Accuracy:  0.9218241042345277\n",
      "Person:  422\n",
      "Transitions:  [7, 8, 6, 8, 5, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.9422110552763819 0.9126803340926348 1.0\n",
      "Num frames:  (1317, 115)\n",
      "Accuracy:  0.9422110552763819\n",
      "Person:  423\n",
      "Transitions:  [7, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.9651515151515152 0.9651515151515152 0.9666160849772383\n",
      "Num frames:  (660, 1)\n",
      "Accuracy:  0.9651515151515152\n",
      "Person:  424\n",
      "Transitions:  [3, 8, 2, 8, 4, 8, 4, 8, 2, 8]\n",
      "GT transitions:  4\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.26059938645481 0.1472034979049007 0.5437415881561238\n",
      "Num frames:  (10978, 8044)\n",
      "Accuracy:  0.26059938645481\n",
      "Person:  425\n",
      "Transitions:  [3, 8, 2, 8, 1, 8, 0, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.9764058198977585 0.9748382458662832 0.9818971759594497\n",
      "Num frames:  (1391, 35)\n",
      "Accuracy:  0.9764058198977585\n",
      "Person:  426\n",
      "Transitions:  [7, 8, 0, 8]\n",
      "GT transitions:  1\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.8477206595538312 0.7599388379204893 0.9783464566929134\n",
      "Num frames:  (1308, 292)\n",
      "Accuracy:  0.8477206595538312\n",
      "Person:  427\n",
      "Transitions:  [1, 8, 2, 8, 3, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.9496606334841629 0.9249578414839797 1.0\n",
      "Num frames:  (1186, 89)\n",
      "Accuracy:  0.9496606334841629\n",
      "Person:  428\n",
      "Transitions:  [6, 8, 4, 8, 2, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.8564356435643564 0.8420050761421319 0.9910380881254668\n",
      "Num frames:  (1576, 249)\n",
      "Accuracy:  0.8564356435643564\n",
      "Person:  429\n",
      "Transitions:  [0, 8, 1, 8, 2, 8, 3, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.9218146718146718 0.8666300768386389 1.0\n",
      "Num frames:  (1822, 243)\n",
      "Accuracy:  0.9218146718146718\n",
      "Person:  430\n",
      "Transitions:  [0, 8, 1, 8, 2, 8, 3, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.4062947067238913 0.2125 0.25573065902578795\n",
      "Num frames:  (1680, 621)\n",
      "Accuracy:  0.4062947067238913\n",
      "Person:  431\n",
      "Transitions:  [7, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.9481481481481482 0.9481481481481482 0.9516728624535316\n",
      "Num frames:  (270, 1)\n",
      "Accuracy:  0.9481481481481482\n",
      "Person:  432\n",
      "Transitions:  [7, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.9965635738831615 0.9965635738831615 1.0\n",
      "Num frames:  (291, 1)\n",
      "Accuracy:  0.9965635738831615\n",
      "Person:  433\n",
      "Transitions:  [7, 8, 6, 8, 5, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.9720853858784894 0.9570815450643777 0.9991039426523297\n",
      "Num frames:  (1165, 50)\n",
      "Accuracy:  0.9720853858784894\n",
      "Person:  434\n",
      "Transitions:  [1, 8, 2, 8, 4, 8, 4, 8, 4, 8, 4, 8, 3, 8]\n",
      "GT transitions:  6\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.02897764783551825 0.017346117250969774 0.22274436090225563\n",
      "Num frames:  (40989, 38702)\n",
      "Accuracy:  0.02897764783551825\n",
      "Person:  435\n",
      "Transitions:  [7, 8, 0, 8]\n",
      "GT transitions:  1\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.9684431977559608 0.9375866851595007 1.0\n",
      "Num frames:  (721, 45)\n",
      "Accuracy:  0.9684431977559608\n",
      "Person:  436\n",
      "Transitions:  [7, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.9962962962962963 0.9962962962962963 1.0\n",
      "Num frames:  (270, 1)\n",
      "Accuracy:  0.9962962962962963\n",
      "Person:  437\n",
      "Transitions:  [6, 8, 5, 8, 5, 8, 6, 8, 6, 8, 5, 8, 5, 8, 6, 8, 6, 8, 6, 8, 4, 8]\n",
      "GT transitions:  10\n",
      "Transitions captured:  10\n",
      "A,P,R:  0.13943484789048657 0.10640539401601348 0.9963172431934763\n",
      "Num frames:  (71190, 63591)\n",
      "Accuracy:  0.13943484789048657\n",
      "Person:  438\n",
      "Transitions:  [0, 8, 1, 8, 2, 8, 3, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.9279250161603103 0.8758351893095768 0.9993646759847522\n",
      "Num frames:  (1796, 222)\n",
      "Accuracy:  0.9279250161603103\n",
      "Person:  439\n",
      "Transitions:  [7, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.9576923076923077 0.9576923076923077 0.9595375722543352\n",
      "Num frames:  (520, 1)\n",
      "Accuracy:  0.9576923076923077\n",
      "Person:  440\n",
      "Transitions:  [7, 8, 6, 8, 5, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.914975845410628 0.8743754461099215 1.0\n",
      "Num frames:  (1401, 176)\n",
      "Accuracy:  0.914975845410628\n",
      "Person:  441\n",
      "Transitions:  [0, 8, 1, 8]\n",
      "GT transitions:  1\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.6428571428571429 0.632375189107413 0.4958481613285884\n",
      "Num frames:  (661, 205)\n",
      "Accuracy:  0.6428571428571429\n",
      "Person:  442\n",
      "Transitions:  [7, 8, 0, 8]\n",
      "GT transitions:  1\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.921201814058957 0.8658301158301158 1.0\n",
      "Num frames:  (1036, 139)\n",
      "Accuracy:  0.921201814058957\n",
      "Person:  443\n",
      "Transitions:  [0, 8, 1, 8, 4, 8, 4, 8, 4, 8, 6, 8]\n",
      "GT transitions:  5\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.2123981720643751 0.08094994892747702 0.12220508866615266\n",
      "Num frames:  (3916, 1687)\n",
      "Accuracy:  0.2123981720643751\n",
      "Person:  444\n",
      "Transitions:  [5, 8, 4, 8, 1, 8, 0, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.9269701086956522 0.8802698145025295 0.9987244897959183\n",
      "Num frames:  (1779, 213)\n",
      "Accuracy:  0.9269701086956522\n",
      "Person:  445\n",
      "Transitions:  [0, 8, 4, 8, 5, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.6840350145894123 0.45641646489104115 0.4665841584158416\n",
      "Num frames:  (826, 327)\n",
      "Accuracy:  0.6840350145894123\n",
      "Person:  446\n",
      "Transitions:  [1, 8, 0, 8]\n",
      "GT transitions:  1\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.898238747553816 0.9803921568627451 0.8333333333333334\n",
      "Num frames:  (510, 4)\n",
      "Accuracy:  0.898238747553816\n",
      "Person:  447\n",
      "Transitions:  [5, 8, 6, 8, 7, 8, 0, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.8942815953868333 0.9130434782608695 0.8618618618618619\n",
      "Num frames:  (943, 82)\n",
      "Accuracy:  0.8942815953868333\n",
      "Person:  448\n",
      "Transitions:  [3, 8, 2, 8, 1, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.9873708381171068 0.9883720930232558 0.9919210053859964\n",
      "Num frames:  (1118, 13)\n",
      "Accuracy:  0.9873708381171068\n",
      "Person:  449\n",
      "Transitions:  [5, 8, 6, 8, 4, 8, 3, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.3606975754997873 0.2826892535733192 0.3897810218978102\n",
      "Num frames:  (1889, 667)\n",
      "Accuracy:  0.3606975754997873\n",
      "Person:  450\n",
      "Transitions:  [0, 8, 1, 8, 4, 8, 5, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.3812306634582331 0.20961430967020683 0.25100401606425704\n",
      "Num frames:  (1789, 681)\n",
      "Accuracy:  0.3812306634582331\n",
      "Person:  451\n",
      "Transitions:  [0, 8, 7, 8]\n",
      "GT transitions:  1\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.7508289909995263 0.5974542561654733 0.9579081632653061\n",
      "Num frames:  (1257, 493)\n",
      "Accuracy:  0.7508289909995263\n",
      "Person:  452\n",
      "Transitions:  [1, 8, 4, 8, 5, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.9102844638949672 0.8775193798449612 0.9947275922671354\n",
      "Num frames:  (1290, 158)\n",
      "Accuracy:  0.9102844638949672\n",
      "Person:  453\n",
      "Transitions:  [0, 8, 1, 8]\n",
      "GT transitions:  1\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.9528061224489796 0.9143518518518519 1.0\n",
      "Num frames:  (864, 74)\n",
      "Accuracy:  0.9528061224489796\n",
      "Person:  454\n",
      "Transitions:  [7, 8, 0, 8]\n",
      "GT transitions:  1\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.9514285714285714 0.9005847953216374 0.9824561403508771\n",
      "Num frames:  (684, 57)\n",
      "Accuracy:  0.9514285714285714\n",
      "Person:  455\n",
      "Transitions:  [0, 8, 4, 8, 6, 8, 5, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.7863309352517985 0.617109634551495 0.8102508178844057\n",
      "Num frames:  (1204, 420)\n",
      "Accuracy:  0.7863309352517985\n",
      "Person:  456\n",
      "Transitions:  [7, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.9386281588447654 0.9386281588447654 0.9420289855072463\n",
      "Num frames:  (277, 1)\n",
      "Accuracy:  0.9386281588447654\n",
      "Person:  457\n",
      "Transitions:  [0, 8, 1, 8, 4, 8, 5, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.8703481392557023 0.7942583732057417 0.9987966305655837\n",
      "Num frames:  (2090, 430)\n",
      "Accuracy:  0.8703481392557023\n",
      "Person:  458\n",
      "Transitions:  [7, 8, 6, 8, 5, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.5489556135770235 0.35394126738794435 0.25248070562293273\n",
      "Num frames:  (647, 13)\n",
      "Accuracy:  0.5489556135770235\n",
      "Person:  459\n",
      "Transitions:  [5, 8, 4, 8, 1, 8, 0, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.9617357001972386 0.945 0.984375\n",
      "Num frames:  (1400, 76)\n",
      "Accuracy:  0.9617357001972386\n",
      "Person:  460\n",
      "Transitions:  [7, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.9611940298507463 0.9611940298507463 0.9640718562874252\n",
      "Num frames:  (335, 1)\n",
      "Accuracy:  0.9611940298507463\n",
      "Person:  461\n",
      "Transitions:  [5, 8, 6, 8, 7, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.8412391093901258 0.7834983498349835 1.0\n",
      "Num frames:  (1515, 328)\n",
      "Accuracy:  0.8412391093901258\n",
      "Person:  462\n",
      "Transitions:  [0, 8, 1, 8, 2, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.8864689527340129 0.8143939393939394 1.0\n",
      "Num frames:  (1320, 245)\n",
      "Accuracy:  0.8864689527340129\n",
      "Person:  463\n",
      "Transitions:  [7, 8, 6, 8, 5, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.9452654625068418 0.9139414802065404 1.0\n",
      "Num frames:  (1162, 100)\n",
      "Accuracy:  0.9452654625068418\n",
      "Person:  464\n",
      "Transitions:  [7, 8, 6, 8, 5, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.933115823817292 0.894781864841745 1.0\n",
      "Num frames:  (1169, 123)\n",
      "Accuracy:  0.933115823817292\n",
      "Person:  465\n",
      "Transitions:  [5, 8, 6, 8, 7, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.886781929726715 0.8362903225806452 1.0\n",
      "Num frames:  (1240, 203)\n",
      "Accuracy:  0.886781929726715\n",
      "Person:  466\n",
      "Transitions:  [5, 8, 4, 8, 1, 8, 0, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A,P,R:  0.9330357142857143 0.8932584269662921 0.9994285714285714\n",
      "Num frames:  (1958, 209)\n",
      "Accuracy:  0.9330357142857143\n",
      "Person:  467\n",
      "Transitions:  [7, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.9609120521172638 0.9609120521172638 0.9640522875816994\n",
      "Num frames:  (307, 1)\n",
      "Accuracy:  0.9609120521172638\n",
      "Person:  468\n",
      "Transitions:  [5, 8, 6, 8, 7, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.8581560283687943 0.8033707865168539 1.0\n",
      "Num frames:  (1424, 280)\n",
      "Accuracy:  0.8581560283687943\n",
      "Person:  469\n",
      "Transitions:  [7, 8, 6, 8, 5, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.9470304975922953 0.9175686927560366 1.0\n",
      "Num frames:  (1201, 99)\n",
      "Accuracy:  0.9470304975922953\n",
      "Person:  470\n",
      "Transitions:  [5, 8, 6, 8, 7, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.84684260131951 0.7912652536929994 1.0\n",
      "Num frames:  (1557, 325)\n",
      "Accuracy:  0.84684260131951\n",
      "Person:  471\n",
      "Transitions:  [7, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.9520958083832335 0.9520958083832335 0.954954954954955\n",
      "Num frames:  (334, 1)\n",
      "Accuracy:  0.9520958083832335\n",
      "Person:  472\n",
      "Transitions:  [0, 8, 6, 8, 5, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.8008595988538681 0.6731266149870802 0.6955941255006676\n",
      "Num frames:  (774, 189)\n",
      "Accuracy:  0.8008595988538681\n",
      "Person:  473\n",
      "Transitions:  [3, 8, 2, 8, 1, 8, 0, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.9639333106498809 0.9392361111111112 0.999384236453202\n",
      "Num frames:  (1728, 105)\n",
      "Accuracy:  0.9639333106498809\n",
      "Person:  474\n",
      "Transitions:  [3, 8, 2, 8, 1, 8, 0, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.9189277541680287 0.8661629789530491 1.0\n",
      "Num frames:  (1853, 248)\n",
      "Accuracy:  0.9189277541680287\n",
      "Person:  475\n",
      "Transitions:  [1, 8, 7, 8]\n",
      "GT transitions:  1\n",
      "Transitions captured:  0\n",
      "A,P,R:  0.7211221122112211 0.6291148500365764 0.8565737051792829\n",
      "Num frames:  (1367, 363)\n",
      "Accuracy:  0.7211221122112211\n",
      "Person:  476\n",
      "Transitions:  [5, 8, 6, 8, 4, 8, 1, 8, 0, 8]\n",
      "GT transitions:  4\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.7477808386899296 0.6321483771251932 0.9129464285714286\n",
      "Num frames:  (1941, 707)\n",
      "Accuracy:  0.7477808386899296\n",
      "Person:  477\n",
      "Transitions:  [0, 8, 1, 8, 4, 8, 5, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.8999646518204313 0.823418910457107 0.9992401215805471\n",
      "Num frames:  (1597, 282)\n",
      "Accuracy:  0.8999646518204313\n",
      "Person:  478\n",
      "Transitions:  [5, 8, 4, 8, 1, 8, 0, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.9415395787944808 0.9022698612862547 0.9958246346555324\n",
      "Num frames:  (1586, 155)\n",
      "Accuracy:  0.9415395787944808\n",
      "Person:  479\n",
      "Transitions:  [3, 8, 2, 8, 1, 8, 0, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.9590846047156727 0.9307875894988067 0.998719590268886\n",
      "Num frames:  (1676, 116)\n",
      "Accuracy:  0.9590846047156727\n",
      "Person:  480\n",
      "Transitions:  [5, 8, 6, 8, 7, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.8513708513708513 0.7967105263157894 1.0\n",
      "Num frames:  (1520, 309)\n",
      "Accuracy:  0.8513708513708513\n",
      "Person:  481\n",
      "Transitions:  [5, 8, 6, 8, 7, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.908881199538639 0.864957264957265 1.0\n",
      "Num frames:  (1170, 158)\n",
      "Accuracy:  0.908881199538639\n",
      "Person:  482\n",
      "Transitions:  [7, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.9465648854961832 0.9465648854961832 0.9480122324159022\n",
      "Num frames:  (655, 1)\n",
      "Accuracy:  0.9465648854961832\n",
      "Person:  483\n",
      "Transitions:  [3, 8, 2, 8, 1, 8, 0, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.9846278317152104 0.9909638554216867 0.9806259314456036\n",
      "Num frames:  (1328, 12)\n",
      "Accuracy:  0.9846278317152104\n",
      "Person:  484\n",
      "Transitions:  [7, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.9978540772532188 0.9978540772532188 1.0\n",
      "Num frames:  (466, 1)\n",
      "Accuracy:  0.9978540772532188\n",
      "Person:  485\n",
      "Transitions:  [5, 8, 6, 8, 7, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.9000564652738566 0.8528678304239401 1.0\n",
      "Num frames:  (1203, 177)\n",
      "Accuracy:  0.9000564652738566\n",
      "Person:  486\n",
      "Transitions:  [0, 8, 1, 8, 4, 8, 5, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.8924255820807545 0.8275047258979206 1.0\n",
      "Num frames:  (2116, 365)\n",
      "Accuracy:  0.8924255820807545\n",
      "Person:  487\n",
      "Transitions:  [1, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.9807162534435262 0.9807162534435262 0.9834254143646409\n",
      "Num frames:  (363, 1)\n",
      "Accuracy:  0.9807162534435262\n",
      "Person:  488\n",
      "Transitions:  [1, 8, 2, 8, 3, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.9282136894824707 0.8932119205298014 1.0\n",
      "Num frames:  (1208, 129)\n",
      "Accuracy:  0.9282136894824707\n",
      "Person:  489\n",
      "Transitions:  [5, 8, 6, 8, 7, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.9127272727272727 0.8688524590163934 1.0\n",
      "Num frames:  (1098, 144)\n",
      "Accuracy:  0.9127272727272727\n",
      "Person:  490\n",
      "Transitions:  [5, 8, 6, 8]\n",
      "GT transitions:  1\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.9498680738786279 0.940809968847352 1.0\n",
      "Num frames:  (963, 57)\n",
      "Accuracy:  0.9498680738786279\n",
      "Person:  491\n",
      "Transitions:  [7, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.9956521739130435 0.9956521739130435 1.0\n",
      "Num frames:  (230, 1)\n",
      "Accuracy:  0.9956521739130435\n",
      "Person:  492\n",
      "Transitions:  [7, 8, 0, 8]\n",
      "GT transitions:  1\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.9349112426035503 0.8879581151832461 0.9964747356051704\n",
      "Num frames:  (955, 107)\n",
      "Accuracy:  0.9349112426035503\n",
      "Person:  493\n",
      "Transitions:  [7, 8, 6, 8, 5, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.9402552204176334 0.9026465028355387 1.0\n",
      "Num frames:  (1058, 103)\n",
      "Accuracy:  0.9402552204176334\n",
      "Person:  494\n",
      "Transitions:  [5, 8, 6, 8, 7, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.9289489136817382 0.8939526730937774 1.0\n",
      "Num frames:  (1141, 121)\n",
      "Accuracy:  0.9289489136817382\n",
      "Person:  495\n",
      "Transitions:  [0, 8, 1, 8, 4, 8, 6, 8, 5, 8]\n",
      "GT transitions:  4\n",
      "Transitions captured:  4\n",
      "A,P,R:  0.7902439024390244 0.7328385899814471 0.7655038759689923\n",
      "Num frames:  (1078, 188)\n",
      "Accuracy:  0.7902439024390244\n",
      "Person:  496\n",
      "Transitions:  [5, 8, 6, 8, 7, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.8804463336875664 0.8312078019504876 1.0\n",
      "Num frames:  (1333, 225)\n",
      "Accuracy:  0.8804463336875664\n",
      "Person:  497\n",
      "Transitions:  [5, 8, 4, 8, 1, 8, 4, 8, 5, 8, 5, 8, 6, 8]\n",
      "GT transitions:  6\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.16063257606165207 0.06215804107991748 0.2755467196819085\n",
      "Num frames:  (11149, 8634)\n",
      "Accuracy:  0.16063257606165207\n",
      "Person:  498\n",
      "Transitions:  [3, 8, 2, 8, 1, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.8347889374090247 0.8433889602053916 0.7457434733257662\n",
      "Num frames:  (779, 3)\n",
      "Accuracy:  0.8347889374090247\n",
      "Person:  499\n",
      "Transitions:  [5, 8, 4, 8, 2, 8, 1, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.8795298726738492 0.8363013698630137 0.994299674267101\n",
      "Num frames:  (1460, 239)\n",
      "Accuracy:  0.8795298726738492\n",
      "Person:  500\n",
      "Transitions:  [2, 8, 1, 8]\n",
      "GT transitions:  1\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.9894039735099338 0.9963302752293578 0.9890710382513661\n",
      "Num frames:  (545, 2)\n",
      "Accuracy:  0.9894039735099338\n",
      "Person:  501\n",
      "Transitions:  [1, 8, 0, 8]\n",
      "GT transitions:  1\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.9801553062985332 0.9713831478537361 0.9823151125401929\n",
      "Num frames:  (629, 12)\n",
      "Accuracy:  0.9801553062985332\n",
      "Person:  502\n",
      "Transitions:  [0, 8, 1, 8, 4, 8, 5, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.5761124121779859 0.28403237674760856 0.36176194939081535\n",
      "Num frames:  (1359, 405)\n",
      "Accuracy:  0.5761124121779859\n",
      "Person:  503\n",
      "Transitions:  [0, 8, 1, 8]\n",
      "GT transitions:  1\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.7611940298507462 0.901595744680851 0.5272161741835147\n",
      "Num frames:  (376, 16)\n",
      "Accuracy:  0.7611940298507462\n",
      "Person:  504\n",
      "Transitions:  [7, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.9478260869565217 0.9478260869565217 0.9505813953488372\n",
      "Num frames:  (345, 1)\n",
      "Accuracy:  0.9478260869565217\n",
      "Person:  505\n",
      "Transitions:  [5, 8, 4, 8, 1, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.9629444166249375 0.9478873239436619 1.0\n",
      "Num frames:  (1420, 74)\n",
      "Accuracy:  0.9629444166249375\n",
      "Person:  506\n",
      "Transitions:  [5, 8, 4, 8, 1, 8, 0, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.9571005917159763 0.92578125 0.9978947368421053\n",
      "Num frames:  (1536, 113)\n",
      "Accuracy:  0.9571005917159763\n",
      "Person:  507\n",
      "Transitions:  [7, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.9850746268656716 0.9850746268656716 1.0\n",
      "Num frames:  (67, 1)\n",
      "Accuracy:  0.9850746268656716\n",
      "Person:  508\n",
      "Transitions:  [5, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.9959514170040485 0.9959514170040485 1.0\n",
      "Num frames:  (247, 1)\n",
      "Accuracy:  0.9959514170040485\n",
      "Person:  509\n",
      "Transitions:  [7, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.9700854700854701 0.9700854700854701 0.9721627408993576\n",
      "Num frames:  (468, 1)\n",
      "Accuracy:  0.9700854700854701\n",
      "Person:  510\n",
      "Transitions:  [3, 8, 2, 8, 1, 8, 0, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.9755118426334806 0.981301421091997 0.973293768545994\n",
      "Num frames:  (1337, 25)\n",
      "Accuracy:  0.9755118426334806\n",
      "Person:  511\n",
      "Transitions:  [7, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.9968944099378882 0.9968944099378882 1.0\n",
      "Num frames:  (322, 1)\n",
      "Accuracy:  0.9968944099378882\n",
      "Person:  512\n",
      "Transitions:  [7, 8, 7, 8, 7, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  0\n",
      "A,P,R:  0.23191053534850245 0.23732502947667564 0.3860529162978263\n",
      "Num frames:  (33077, 15264)\n",
      "Accuracy:  0.23191053534850245\n",
      "Person:  513\n",
      "Transitions:  [7, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.9654178674351584 0.9654178674351584 0.9682080924855492\n",
      "Num frames:  (347, 1)\n",
      "Accuracy:  0.9654178674351584\n",
      "Person:  514\n",
      "Transitions:  [7, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.9447513812154696 0.9447513812154696 0.9473684210526315\n",
      "Num frames:  (362, 1)\n",
      "Accuracy:  0.9447513812154696\n",
      "Person:  515\n",
      "Transitions:  [3, 8, 2, 8, 1, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.9587786259541985 0.9386828160484482 1.0\n",
      "Num frames:  (1321, 81)\n",
      "Accuracy:  0.9587786259541985\n",
      "Person:  516\n",
      "Transitions:  [7, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.9310344827586207 0.9310344827586207 0.9342560553633218\n",
      "Num frames:  (290, 1)\n",
      "Accuracy:  0.9310344827586207\n",
      "Person:  517\n",
      "Transitions:  [0, 8, 1, 8, 4, 8, 5, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A,P,R:  0.3537117903930131 0.1796116504854369 0.21359846055163567\n",
      "Num frames:  (1854, 698)\n",
      "Accuracy:  0.3537117903930131\n",
      "Person:  518\n",
      "Transitions:  [7, 8, 6, 8, 5, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.9465725806451613 0.9193302891933028 1.0\n",
      "Num frames:  (1314, 106)\n",
      "Accuracy:  0.9465725806451613\n",
      "Person:  519\n",
      "Transitions:  [5, 8, 4, 8, 1, 8, 0, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.9695634761714057 0.9585218702865762 0.9791987673343605\n",
      "Num frames:  (1326, 49)\n",
      "Accuracy:  0.9695634761714057\n",
      "Person:  520\n",
      "Transitions:  [5, 8, 6, 8, 4, 8, 1, 8, 0, 8]\n",
      "GT transitions:  4\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.7678965625985493 0.6425094645754462 0.9406175771971497\n",
      "Num frames:  (1849, 661)\n",
      "Accuracy:  0.7678965625985493\n",
      "Person:  521\n",
      "Transitions:  [5, 8, 4, 8, 1, 8, 0, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.8746268656716418 0.8040130657956136 1.0\n",
      "Num frames:  (2143, 420)\n",
      "Accuracy:  0.8746268656716418\n",
      "Person:  522\n",
      "Transitions:  [7, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.9470899470899471 0.9470899470899471 0.9496021220159151\n",
      "Num frames:  (378, 1)\n",
      "Accuracy:  0.9470899470899471\n",
      "Person:  523\n",
      "Transitions:  [5, 8, 6, 8, 7, 8, 0, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.9178679182031512 0.8577235772357723 1.0\n",
      "Num frames:  (1722, 245)\n",
      "Accuracy:  0.9178679182031512\n",
      "Person:  524\n",
      "Transitions:  [0, 8, 1, 8, 4, 8, 5, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.40375234521575987 0.20025923525599482 0.22770817980840088\n",
      "Num frames:  (1543, 541)\n",
      "Accuracy:  0.40375234521575987\n",
      "Person:  525\n",
      "Transitions:  [7, 8, 0, 8]\n",
      "GT transitions:  1\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.8420245398773006 0.6801242236024845 0.9776785714285714\n",
      "Num frames:  (966, 294)\n",
      "Accuracy:  0.8420245398773006\n",
      "Person:  526\n",
      "Transitions:  [0, 8, 4, 8, 5, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.7270896273917422 0.5522710886806056 0.7509803921568627\n",
      "Num frames:  (1387, 559)\n",
      "Accuracy:  0.7270896273917422\n",
      "Person:  527\n",
      "Transitions:  [1, 8, 2, 8]\n",
      "GT transitions:  1\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.9771172446331682 0.976421973748177 0.9985085756897838\n",
      "Num frames:  (4114, 91)\n",
      "Accuracy:  0.9771172446331682\n",
      "Person:  528\n",
      "Transitions:  [2, 8, 4, 8, 4, 8, 5, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.5832847990681421 0.35915808329601434 0.5440976933514247\n",
      "Num frames:  (2233, 759)\n",
      "Accuracy:  0.5832847990681421\n",
      "Person:  529\n",
      "Transitions:  [7, 8, 6, 8, 5, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.525320317266626 0.33152909336941816 0.25467775467775466\n",
      "Num frames:  (739, 61)\n",
      "Accuracy:  0.525320317266626\n",
      "Person:  530\n",
      "Transitions:  [7, 8, 6, 8, 5, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.9261637239165329 0.885 1.0\n",
      "Num frames:  (1200, 138)\n",
      "Accuracy:  0.9261637239165329\n",
      "Person:  531\n",
      "Transitions:  [7, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.9967637540453075 0.9967637540453075 1.0\n",
      "Num frames:  (309, 1)\n",
      "Accuracy:  0.9967637540453075\n",
      "Person:  532\n",
      "Transitions:  [5, 8, 4, 8, 1, 8, 0, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.8562691131498471 0.7820404721753794 1.0\n",
      "Num frames:  (2372, 517)\n",
      "Accuracy:  0.8562691131498471\n",
      "Person:  533\n",
      "Transitions:  [5, 8, 6, 8, 0, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.4792592592592593 0.39777270131353515 0.9992826398852224\n",
      "Num frames:  (3502, 2108)\n",
      "Accuracy:  0.4792592592592593\n",
      "Person:  534\n",
      "Transitions:  [7, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.9809885931558935 0.9809885931558935 0.9847328244274809\n",
      "Num frames:  (263, 1)\n",
      "Accuracy:  0.9809885931558935\n",
      "Person:  535\n",
      "Transitions:  [5, 8, 6, 8, 7, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.8519685039370078 0.7915742793791575 1.0\n",
      "Num frames:  (1353, 282)\n",
      "Accuracy:  0.8519685039370078\n",
      "Person:  536\n",
      "Transitions:  [7, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.9563636363636364 0.9563636363636364 0.9598540145985401\n",
      "Num frames:  (275, 1)\n",
      "Accuracy:  0.9563636363636364\n",
      "Person:  537\n",
      "Transitions:  [5, 8, 6, 8, 4, 8, 0, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.7237783075089392 0.5458108770210681 1.0\n",
      "Num frames:  (2041, 927)\n",
      "Accuracy:  0.7237783075089392\n",
      "Person:  538\n",
      "Transitions:  [7, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.9692832764505119 0.9692832764505119 0.9726027397260274\n",
      "Num frames:  (293, 1)\n",
      "Accuracy:  0.9692832764505119\n",
      "Person:  539\n",
      "Transitions:  [5, 8, 4, 8, 0, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.7902745616936818 0.6347926267281107 1.0\n",
      "Num frames:  (1736, 634)\n",
      "Accuracy:  0.7902745616936818\n",
      "Person:  540\n",
      "Transitions:  [0, 8, 1, 8, 4, 8, 5, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.23520833333333332 0.11259907078436732 0.13158735228361546\n",
      "Num frames:  (3659, 952)\n",
      "Accuracy:  0.23520833333333332\n",
      "Person:  541\n",
      "Transitions:  [5, 8, 6, 8, 7, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.9479653102068045 0.9265175718849841 0.9897610921501706\n",
      "Num frames:  (939, 69)\n",
      "Accuracy:  0.9479653102068045\n",
      "Person:  542\n",
      "Transitions:  [7, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.953405017921147 0.953405017921147 0.9568345323741008\n",
      "Num frames:  (279, 1)\n",
      "Accuracy:  0.953405017921147\n",
      "Person:  543\n",
      "Transitions:  [7, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.9453376205787781 0.9453376205787781 0.9483870967741935\n",
      "Num frames:  (311, 1)\n",
      "Accuracy:  0.9453376205787781\n",
      "Person:  544\n",
      "Transitions:  [1, 8, 0, 8]\n",
      "GT transitions:  1\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.9138481174218251 0.865 0.9931113662456946\n",
      "Num frames:  (1000, 129)\n",
      "Accuracy:  0.9138481174218251\n",
      "Person:  545\n",
      "Transitions:  [0, 8, 1, 8, 4, 8, 6, 8, 5, 8]\n",
      "GT transitions:  4\n",
      "Transitions captured:  0\n",
      "A,P,R:  0.6483600305110603 0.3384223918575064 0.2633663366336634\n",
      "Num frames:  (393, 89)\n",
      "Accuracy:  0.6483600305110603\n",
      "Person:  546\n",
      "Transitions:  [3, 8, 2, 8, 1, 8, 0, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.9800561797752809 0.9722577891591976 0.9973730297723292\n",
      "Num frames:  (2343, 65)\n",
      "Accuracy:  0.9800561797752809\n",
      "Person:  547\n",
      "Transitions:  [5, 8, 6, 8, 7, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.8594566353187043 0.8010355029585798 1.0\n",
      "Num frames:  (1352, 269)\n",
      "Accuracy:  0.8594566353187043\n",
      "Person:  548\n",
      "Transitions:  [1, 8, 7, 8]\n",
      "GT transitions:  1\n",
      "Transitions captured:  0\n",
      "A,P,R:  0.8353982300884956 0.9694656488549618 0.7351664254703328\n",
      "Num frames:  (524, 3)\n",
      "Accuracy:  0.8353982300884956\n",
      "Person:  549\n",
      "Transitions:  [7, 8, 0, 8]\n",
      "GT transitions:  1\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.9687131050767415 0.9471007121057986 0.9989270386266095\n",
      "Num frames:  (983, 52)\n",
      "Accuracy:  0.9687131050767415\n",
      "Person:  550\n",
      "Transitions:  [5, 8, 6, 8, 7, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.8830963665086888 0.8339566192969334 1.0\n",
      "Num frames:  (1337, 222)\n",
      "Accuracy:  0.8830963665086888\n",
      "Person:  551\n",
      "Transitions:  [0, 8, 1, 8, 4, 8, 5, 8, 5, 8, 6, 8, 7, 8]\n",
      "GT transitions:  6\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.7406100099556521 0.019418074220194797 0.13097713097713098\n",
      "Num frames:  (16222, 15106)\n",
      "Accuracy:  0.7406100099556521\n",
      "Person:  552\n",
      "Transitions:  [5, 8, 4, 8, 0, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.8004484304932735 0.6590038314176245 1.0\n",
      "Num frames:  (1827, 623)\n",
      "Accuracy:  0.8004484304932735\n",
      "Person:  553\n",
      "Transitions:  [7, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.9603960396039604 0.9603960396039604 0.9627791563275434\n",
      "Num frames:  (404, 1)\n",
      "Accuracy:  0.9603960396039604\n",
      "Person:  554\n",
      "Transitions:  [7, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.9529411764705882 0.9529411764705882 0.9566929133858267\n",
      "Num frames:  (255, 1)\n",
      "Accuracy:  0.9529411764705882\n",
      "Person:  555\n",
      "Transitions:  [0, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.9997949979499795 0.9997949979499795 1.0\n",
      "Num frames:  (4878, 1)\n",
      "Accuracy:  0.9997949979499795\n",
      "Person:  556\n",
      "Transitions:  [7, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.9965986394557823 0.9965986394557823 1.0\n",
      "Num frames:  (294, 1)\n",
      "Accuracy:  0.9965986394557823\n",
      "Person:  557\n",
      "Transitions:  [0, 8, 1, 8, 2, 8, 3, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.3873714083008159 0.19426565242832067 0.23496107572540695\n",
      "Num frames:  (1709, 646)\n",
      "Accuracy:  0.3873714083008159\n",
      "Person:  558\n",
      "Transitions:  [7, 8, 6, 8, 5, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.5596681557115507 0.3683431952662722 0.27946127946127947\n",
      "Num frames:  (676, 48)\n",
      "Accuracy:  0.5596681557115507\n",
      "Person:  559\n",
      "Transitions:  [0, 8, 1, 8, 4, 8, 4, 8, 1, 8, 0, 8]\n",
      "GT transitions:  5\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.2240788346186804 0.11946933388900466 0.5906593406593407\n",
      "Num frames:  (14397, 11485)\n",
      "Accuracy:  0.2240788346186804\n",
      "Person:  560\n",
      "Transitions:  [5, 8, 6, 8, 0, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.4551386623164764 0.32010178117048343 0.6649048625792812\n",
      "Num frames:  (1965, 1019)\n",
      "Accuracy:  0.4551386623164764\n",
      "Person:  561\n",
      "Transitions:  [7, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.9571984435797666 0.9571984435797666 0.9609375\n",
      "Num frames:  (257, 1)\n",
      "Accuracy:  0.9571984435797666\n",
      "Person:  562\n",
      "Transitions:  [1, 8, 0, 8]\n",
      "GT transitions:  1\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.9299931365820179 0.8844847112117781 0.9923761118170267\n",
      "Num frames:  (883, 96)\n",
      "Accuracy:  0.9299931365820179\n",
      "Person:  563\n",
      "Transitions:  [7, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.9636363636363636 0.9636363636363636 0.9665653495440729\n",
      "Num frames:  (330, 1)\n",
      "Accuracy:  0.9636363636363636\n",
      "Person:  564\n",
      "Transitions:  [7, 8, 6, 8, 5, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.5566870332654447 0.37110016420361247 0.25947187141216993\n",
      "Num frames:  (609, 8)\n",
      "Accuracy:  0.5566870332654447\n",
      "Person:  565\n",
      "Transitions:  [0, 8, 1, 8]\n",
      "GT transitions:  1\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.6985055230669266 0.7825159914712153 0.48738379814077026\n",
      "Num frames:  (469, 78)\n",
      "Accuracy:  0.6985055230669266\n",
      "Person:  566\n",
      "Transitions:  [3, 8, 2, 8, 1, 8, 0, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.9867021276595744 0.9769335142469471 0.9993060374739764\n",
      "Num frames:  (1474, 34)\n",
      "Accuracy:  0.9867021276595744\n",
      "Person:  567\n",
      "Transitions:  [7, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.9853479853479854 0.9853479853479854 0.9889705882352942\n",
      "Num frames:  (273, 1)\n",
      "Accuracy:  0.9853479853479854\n",
      "Person:  568\n",
      "Transitions:  [7, 8, 6, 8, 5, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.5703395703395704 0.3719723183391003 0.2621951219512195\n",
      "Num frames:  (578, 15)\n",
      "Accuracy:  0.5703395703395704\n",
      "Person:  569\n",
      "Transitions:  [0, 8, 1, 8, 2, 8, 3, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.37942226549821484 0.2146516393442623 0.26518987341772154\n",
      "Num frames:  (1952, 751)\n",
      "Accuracy:  0.37942226549821484\n",
      "Person:  570\n",
      "Transitions:  [7, 8, 6, 8, 5, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.9058823529411765 0.8568093385214007 1.0\n",
      "Num frames:  (1285, 184)\n",
      "Accuracy:  0.9058823529411765\n",
      "Person:  571\n",
      "Transitions:  [3, 8, 2, 8, 1, 8, 0, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.9574160952724649 0.931056293485136 0.9939230249831195\n",
      "Num frames:  (1581, 109)\n",
      "Accuracy:  0.9574160952724649\n",
      "Person:  572\n",
      "Transitions:  [0, 8, 1, 8, 4, 8, 5, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.9204244031830239 0.8688160088938299 0.9974473516273133\n",
      "Num frames:  (1799, 236)\n",
      "Accuracy:  0.9204244031830239\n",
      "Person:  573\n",
      "Transitions:  [5, 8, 4, 8]\n",
      "GT transitions:  1\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.8870214752567693 0.8448717948717949 1.0\n",
      "Num frames:  (780, 121)\n",
      "Accuracy:  0.8870214752567693\n",
      "Person:  574\n",
      "Transitions:  [0, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.9975124378109452 0.9975124378109452 1.0\n",
      "Num frames:  (402, 1)\n",
      "Accuracy:  0.9975124378109452\n",
      "Person:  575\n",
      "Transitions:  [5, 8, 6, 8, 7, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.8983342906375646 0.850632911392405 1.0\n",
      "Num frames:  (1185, 177)\n",
      "Accuracy:  0.8983342906375646\n",
      "Person:  576\n",
      "Transitions:  [7, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.9617590822179732 0.9617590822179732 0.9636015325670498\n",
      "Num frames:  (523, 1)\n",
      "Accuracy:  0.9617590822179732\n",
      "Person:  577\n",
      "Transitions:  [1, 8, 0, 8]\n",
      "GT transitions:  1\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.9134114583333334 0.862603305785124 0.9928656361474435\n",
      "Num frames:  (968, 127)\n",
      "Accuracy:  0.9134114583333334\n",
      "Person:  578\n",
      "Transitions:  [5, 8, 4, 8, 1, 8, 0, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A,P,R:  0.881578947368421 0.8142589118198874 1.0\n",
      "Num frames:  (2132, 396)\n",
      "Accuracy:  0.881578947368421\n",
      "Person:  579\n",
      "Transitions:  [3, 8, 2, 8, 1, 8, 0, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.9649069270674397 0.9493731918997107 0.9949469429004548\n",
      "Num frames:  (2074, 105)\n",
      "Accuracy:  0.9649069270674397\n",
      "Person:  580\n",
      "Transitions:  [3, 8, 4, 8, 7, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.8770370370370371 0.7476708074534162 0.9796541200406917\n",
      "Num frames:  (1288, 312)\n",
      "Accuracy:  0.8770370370370371\n",
      "Person:  581\n",
      "Transitions:  [0, 8, 1, 8, 4, 8, 6, 8, 5, 8]\n",
      "GT transitions:  4\n",
      "Transitions captured:  4\n",
      "A,P,R:  0.8011915269196822 0.7394447657605553 0.9996090695856138\n",
      "Num frames:  (3458, 900)\n",
      "Accuracy:  0.8011915269196822\n",
      "Person:  582\n",
      "Transitions:  [7, 8, 6, 8, 5, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.9442640692640693 0.9124149659863946 1.0\n",
      "Num frames:  (1176, 103)\n",
      "Accuracy:  0.9442640692640693\n",
      "Person:  583\n",
      "Transitions:  [5, 8, 6, 8, 7, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.9288833437305053 0.8935361216730038 0.9884332281808622\n",
      "Num frames:  (1052, 103)\n",
      "Accuracy:  0.9288833437305053\n",
      "Person:  584\n",
      "Transitions:  [4, 8, 5, 8]\n",
      "GT transitions:  1\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.9691629955947136 0.9530201342281879 1.0\n",
      "Num frames:  (596, 28)\n",
      "Accuracy:  0.9691629955947136\n",
      "Person:  585\n",
      "Transitions:  [7, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.9956140350877193 0.9956140350877193 1.0\n",
      "Num frames:  (228, 1)\n",
      "Accuracy:  0.9956140350877193\n",
      "Person:  586\n",
      "Transitions:  [0, 8, 1, 8]\n",
      "GT transitions:  1\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.88759367194005 0.7683823529411765 0.761384335154827\n",
      "Num frames:  (544, 4)\n",
      "Accuracy:  0.88759367194005\n",
      "Person:  587\n",
      "Transitions:  [7, 8, 0, 8]\n",
      "GT transitions:  1\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.9384707287933094 0.8914646996838778 0.9871645274212368\n",
      "Num frames:  (949, 92)\n",
      "Accuracy:  0.9384707287933094\n",
      "Person:  588\n",
      "Transitions:  [7, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.9964912280701754 0.9964912280701754 1.0\n",
      "Num frames:  (285, 1)\n",
      "Accuracy:  0.9964912280701754\n",
      "Person:  589\n",
      "Transitions:  [5, 8, 6, 8, 7, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.8959601549529607 0.8489959839357429 1.0\n",
      "Num frames:  (1245, 188)\n",
      "Accuracy:  0.8959601549529607\n",
      "Person:  590\n",
      "Transitions:  [7, 8, 7, 8, 7, 8, 7, 8, 7, 8, 7, 8, 7, 8, 7, 8, 7, 8, 7, 8, 7, 8, 7, 8, 7, 8, 7, 8, 7, 8, 7, 8, 7, 8, 7, 8, 7, 8, 7, 8, 7, 8, 7, 8, 7, 8, 7, 8, 7, 8, 7, 8, 7, 8, 7, 8]\n",
      "GT transitions:  27\n",
      "Transitions captured:  0\n",
      "A,P,R:  0.16695147726761703 0.00899943041579647 0.010166874007979066\n",
      "Num frames:  (26335, 13975)\n",
      "Accuracy:  0.16695147726761703\n",
      "Person:  591\n",
      "Transitions:  [1, 8, 2, 8, 3, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.7789046653144016 0.73340321453529 1.0\n",
      "Num frames:  (2862, 763)\n",
      "Accuracy:  0.7789046653144016\n",
      "Person:  592\n",
      "Transitions:  [0, 8, 1, 8, 2, 8, 3, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.36867030965391623 0.1623931623931624 0.19616519174041297\n",
      "Num frames:  (1638, 643)\n",
      "Accuracy:  0.36867030965391623\n",
      "Person:  593\n",
      "Transitions:  [0, 8, 1, 8]\n",
      "GT transitions:  1\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.7145804676753783 0.8067632850241546 0.48405797101449277\n",
      "Num frames:  (414, 59)\n",
      "Accuracy:  0.7145804676753783\n",
      "Person:  594\n",
      "Transitions:  [0, 8, 1, 8, 2, 8, 3, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.9165591397849462 0.8678260869565217 0.8731408573928259\n",
      "Num frames:  (1150, 49)\n",
      "Accuracy:  0.9165591397849462\n",
      "Person:  595\n",
      "Transitions:  [7, 8, 0, 8]\n",
      "GT transitions:  1\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.8744303797468355 0.7973856209150327 0.9888551165146909\n",
      "Num frames:  (1224, 237)\n",
      "Accuracy:  0.8744303797468355\n",
      "Person:  596\n",
      "Transitions:  [1, 8, 4, 8, 5, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.8886010362694301 0.8555431131019037 0.9960886571056062\n",
      "Num frames:  (1786, 252)\n",
      "Accuracy:  0.8886010362694301\n",
      "Person:  597\n",
      "Transitions:  [0, 8, 1, 8, 2, 8, 3, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.9313362504207338 0.8794326241134752 1.0\n",
      "Num frames:  (1692, 204)\n",
      "Accuracy:  0.9313362504207338\n",
      "Person:  598\n",
      "Transitions:  [7, 8, 6, 8, 5, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.9490131578947368 0.9192708333333334 1.0\n",
      "Num frames:  (1152, 93)\n",
      "Accuracy:  0.9490131578947368\n",
      "Person:  599\n",
      "Transitions:  [0, 8, 1, 8, 4, 8, 5, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.8816374962919015 0.8086330935251799 1.0\n",
      "Num frames:  (2085, 399)\n",
      "Accuracy:  0.8816374962919015\n",
      "Person:  600\n",
      "Transitions:  [3, 8, 2, 8, 1, 8, 0, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.9773926149208741 0.9684715558601782 0.9901892081289418\n",
      "Num frames:  (1459, 46)\n",
      "Accuracy:  0.9773926149208741\n",
      "Person:  601\n",
      "Transitions:  [7, 8, 6, 8]\n",
      "GT transitions:  1\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.7926960257787325 0.9573643410852714 0.5704387990762124\n",
      "Num frames:  (258, 7)\n",
      "Accuracy:  0.7926960257787325\n",
      "Person:  602\n",
      "Transitions:  [7, 8, 0, 8]\n",
      "GT transitions:  1\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.9523809523809523 0.9962049335863378 0.9098786828422877\n",
      "Num frames:  (527, 2)\n",
      "Accuracy:  0.9523809523809523\n",
      "Person:  603\n",
      "Transitions:  [7, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.948948948948949 0.948948948948949 0.9518072289156626\n",
      "Num frames:  (333, 1)\n",
      "Accuracy:  0.948948948948949\n",
      "Person:  604\n",
      "Transitions:  [7, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.9960629921259843 0.9960629921259843 1.0\n",
      "Num frames:  (254, 1)\n",
      "Accuracy:  0.9960629921259843\n",
      "Person:  605\n",
      "Transitions:  [0, 8, 1, 8, 4, 8, 6, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.8270150901729849 0.6697118763176388 1.0\n",
      "Num frames:  (1423, 470)\n",
      "Accuracy:  0.8270150901729849\n",
      "Person:  606\n",
      "Transitions:  [2, 8, 1, 8, 0, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.9640557939914163 0.9390243902439024 0.9980059820538385\n",
      "Num frames:  (1066, 65)\n",
      "Accuracy:  0.9640557939914163\n",
      "Person:  607\n",
      "Transitions:  [7, 8, 1, 8]\n",
      "GT transitions:  1\n",
      "Transitions captured:  0\n",
      "A,P,R:  0.34831460674157305 0.10201042442293373 0.10458015267175573\n",
      "Num frames:  (1343, 45)\n",
      "Accuracy:  0.34831460674157305\n",
      "Person:  608\n",
      "Transitions:  [6, 8, 5, 8]\n",
      "GT transitions:  1\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.974025974025974 0.9687906371911573 1.0\n",
      "Num frames:  (769, 24)\n",
      "Accuracy:  0.974025974025974\n",
      "Person:  609\n",
      "Transitions:  [7, 8, 6, 8, 5, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.9591426657736102 0.9908151549942594 0.9421397379912664\n",
      "Num frames:  (871, 8)\n",
      "Accuracy:  0.9591426657736102\n",
      "Person:  610\n",
      "Transitions:  [7, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.9700996677740864 0.9700996677740864 0.9733333333333334\n",
      "Num frames:  (301, 1)\n",
      "Accuracy:  0.9700996677740864\n",
      "Person:  611\n",
      "Transitions:  [5, 8, 4, 8, 1, 8, 0, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.8170420246110982 0.7429037520391517 1.0\n",
      "Num frames:  (3065, 788)\n",
      "Accuracy:  0.8170420246110982\n",
      "Person:  612\n",
      "Transitions:  [7, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.9932885906040269 0.9932885906040269 1.0\n",
      "Num frames:  (149, 1)\n",
      "Accuracy:  0.9932885906040269\n",
      "Person:  613\n",
      "Transitions:  [0, 8, 1, 8, 2, 8, 3, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.9546468401486989 0.9206680584551148 0.9706529713866471\n",
      "Num frames:  (1437, 82)\n",
      "Accuracy:  0.9546468401486989\n",
      "Person:  614\n",
      "Transitions:  [1, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.9871086556169429 0.9871086556169429 0.988929889298893\n",
      "Num frames:  (543, 1)\n",
      "Accuracy:  0.9871086556169429\n",
      "Person:  615\n",
      "Transitions:  [7, 8, 7, 8, 6, 8, 5, 8, 5, 8, 6, 8, 7, 8, 6, 8, 5, 8, 5, 8, 6, 8, 7, 8, 7, 8, 6, 8, 5, 8, 5, 8, 5, 8, 5, 8, 5, 8, 5, 8, 5, 8, 4, 8, 1, 8]\n",
      "GT transitions:  22\n",
      "Transitions captured:  0\n",
      "A,P,R:  0.43817297672803057 0.015879218472468915 0.021293826219512195\n",
      "Num frames:  (28150, 24745)\n",
      "Accuracy:  0.43817297672803057\n",
      "Person:  616\n",
      "Transitions:  [7, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.9387096774193548 0.9387096774193548 0.941747572815534\n",
      "Num frames:  (310, 1)\n",
      "Accuracy:  0.9387096774193548\n",
      "Person:  617\n",
      "Transitions:  [1, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.9879101899827288 0.9879101899827288 0.9896193771626297\n",
      "Num frames:  (579, 1)\n",
      "Accuracy:  0.9879101899827288\n",
      "Person:  618\n",
      "Transitions:  [5, 8, 4, 8, 1, 8, 1, 8, 1, 8]\n",
      "GT transitions:  4\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.24508227143387357 0.1850941850941851 0.5827245380318006\n",
      "Num frames:  (7326, 5131)\n",
      "Accuracy:  0.24508227143387357\n",
      "Person:  619\n",
      "Transitions:  [7, 8, 6, 8, 5, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.5109792284866469 0.31443298969072164 0.25416666666666665\n",
      "Num frames:  (776, 108)\n",
      "Accuracy:  0.5109792284866469\n",
      "Person:  620\n",
      "Transitions:  [1, 8, 4, 8, 2, 8, 3, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.8226018396846255 0.737183646982479 1.0\n",
      "Num frames:  (1541, 405)\n",
      "Accuracy:  0.8226018396846255\n",
      "Person:  621\n",
      "Transitions:  [7, 8, 6, 8, 5, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.9526166902404526 0.9733163913595934 0.9433497536945813\n",
      "Num frames:  (787, 21)\n",
      "Accuracy:  0.9526166902404526\n",
      "Person:  622\n",
      "Transitions:  [5, 8, 6, 8, 4, 8, 0, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.9548744146445296 0.9066427289048474 0.9980237154150198\n",
      "Num frames:  (1114, 104)\n",
      "Accuracy:  0.9548744146445296\n",
      "Person:  623\n",
      "Transitions:  [7, 8, 4, 8, 2, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  0\n",
      "A,P,R:  0.6602870813397129 0.610655737704918 0.369727047146402\n",
      "Num frames:  (244, 30)\n",
      "Accuracy:  0.6602870813397129\n",
      "Person:  624\n",
      "Transitions:  [1, 8, 0, 8]\n",
      "GT transitions:  1\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.8980150581793293 0.8335195530726257 0.9920212765957447\n",
      "Num frames:  (895, 143)\n",
      "Accuracy:  0.8980150581793293\n",
      "Person:  625\n",
      "Transitions:  [7, 8, 6, 8, 5, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.9746462264150944 0.9585741811175337 1.0\n",
      "Num frames:  (1038, 43)\n",
      "Accuracy:  0.9746462264150944\n",
      "Person:  626\n",
      "Transitions:  [0, 8, 1, 8, 4, 8, 5, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.27662886368690237 0.15354800238521168 0.21202140798682587\n",
      "Num frames:  (3354, 1339)\n",
      "Accuracy:  0.27662886368690237\n",
      "Person:  627\n",
      "Transitions:  [0, 8, 1, 8, 2, 8, 3, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.9283333333333333 0.8743424897720631 1.0\n",
      "Num frames:  (1711, 215)\n",
      "Accuracy:  0.9283333333333333\n",
      "Person:  628\n",
      "Transitions:  [3, 8, 2, 8, 1, 8, 0, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.979457079970653 0.9650937297996122 0.9986622073578595\n",
      "Num frames:  (1547, 54)\n",
      "Accuracy:  0.979457079970653\n",
      "Person:  629\n",
      "Transitions:  [7, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.9559322033898305 0.9559322033898305 0.9591836734693877\n",
      "Num frames:  (295, 1)\n",
      "Accuracy:  0.9559322033898305\n",
      "Person:  630\n",
      "Transitions:  [7, 8, 0, 8]\n",
      "GT transitions:  1\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.9253819036427732 0.8690721649484536 0.9859649122807017\n",
      "Num frames:  (970, 115)\n",
      "Accuracy:  0.9253819036427732\n",
      "Person:  631\n",
      "Transitions:  [7, 8, 0, 8]\n",
      "GT transitions:  1\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.946417445482866 0.9006928406466512 0.9860935524652339\n",
      "Num frames:  (866, 75)\n",
      "Accuracy:  0.946417445482866\n",
      "Person:  632\n",
      "Transitions:  [3, 8, 1, 8, 0, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  0\n",
      "A,P,R:  0.4179456906729634 0.2556618017111223 0.47388059701492535\n",
      "Num frames:  (1987, 915)\n",
      "Accuracy:  0.4179456906729634\n",
      "Person:  633\n",
      "Transitions:  [7, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.9475409836065574 0.9475409836065574 0.9506578947368421\n",
      "Num frames:  (305, 1)\n",
      "Accuracy:  0.9475409836065574\n",
      "Person:  634\n",
      "Transitions:  [3, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.997867803837953 0.997867803837953 1.0\n",
      "Num frames:  (469, 1)\n",
      "Accuracy:  0.997867803837953\n",
      "Person:  635\n",
      "Transitions:  [7, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.9856115107913669 0.9856115107913669 0.9891696750902527\n",
      "Num frames:  (278, 1)\n",
      "Accuracy:  0.9856115107913669\n",
      "Person:  636\n",
      "Transitions:  [7, 8, 6, 8, 5, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.9330218068535826 0.8972929936305732 1.0\n",
      "Num frames:  (1256, 129)\n",
      "Accuracy:  0.9330218068535826\n",
      "Person:  637\n",
      "Transitions:  [0, 8, 1, 8, 4, 8, 5, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.3531091370558376 0.16069651741293534 0.1855255600229753\n",
      "Num frames:  (2010, 621)\n",
      "Accuracy:  0.3531091370558376\n",
      "Person:  638\n",
      "Transitions:  [7, 8, 6, 8, 5, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.9234256926952141 0.8846737481031867 1.0\n",
      "Num frames:  (1318, 152)\n",
      "Accuracy:  0.9234256926952141\n",
      "Person:  639\n",
      "Transitions:  [7, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.9961538461538462 0.9961538461538462 1.0\n",
      "Num frames:  (260, 1)\n",
      "Accuracy:  0.9961538461538462\n",
      "Person:  640\n",
      "Transitions:  [7, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.9548611111111112 0.9548611111111112 0.9581881533101045\n",
      "Num frames:  (288, 1)\n",
      "Accuracy:  0.9548611111111112\n",
      "Person:  641\n",
      "Transitions:  [7, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.9954337899543378 0.9954337899543378 1.0\n",
      "Num frames:  (219, 1)\n",
      "Accuracy:  0.9954337899543378\n",
      "Person:  642\n",
      "Transitions:  [7, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.9963503649635036 0.9963503649635036 1.0\n",
      "Num frames:  (274, 1)\n",
      "Accuracy:  0.9963503649635036\n",
      "Person:  643\n",
      "Transitions:  [7, 8, 6, 8, 5, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.5198487712665406 0.3209700427960057 0.2403846153846154\n",
      "Num frames:  (701, 51)\n",
      "Accuracy:  0.5198487712665406\n",
      "Person:  644\n",
      "Transitions:  [3, 8, 2, 8, 4, 8, 5, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.889386189258312 0.8635486981677917 0.951141795007966\n",
      "Num frames:  (2074, 254)\n",
      "Accuracy:  0.889386189258312\n",
      "Person:  645\n",
      "Transitions:  [3, 8, 2, 8, 4, 8, 6, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.86189111747851 0.827354260089686 0.9693520140105079\n",
      "Num frames:  (1338, 206)\n",
      "Accuracy:  0.86189111747851\n",
      "Person:  646\n",
      "Transitions:  [7, 8, 6, 8, 5, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.4916963226571768 0.3202453987730061 0.25023969319271333\n",
      "Num frames:  (815, 75)\n",
      "Accuracy:  0.4916963226571768\n",
      "Person:  647\n",
      "Transitions:  [7, 8, 6, 8, 5, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.9815611555009219 0.9691040164778579 1.0\n",
      "Num frames:  (971, 30)\n",
      "Accuracy:  0.9815611555009219\n",
      "Person:  648\n",
      "Transitions:  [0, 8, 1, 8, 4, 8, 5, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.5165876777251185 0.2179908076165463 0.2993688007213706\n",
      "Num frames:  (1523, 549)\n",
      "Accuracy:  0.5165876777251185\n",
      "Person:  649\n",
      "Transitions:  [5, 8, 4, 8, 0, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A,P,R:  0.7877539005004416 0.6568300809138505 1.0\n",
      "Num frames:  (2101, 721)\n",
      "Accuracy:  0.7877539005004416\n",
      "Person:  650\n",
      "Transitions:  [7, 8, 0, 8]\n",
      "GT transitions:  1\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.4299855142443264 0.2528481012658228 0.9803680981595092\n",
      "Num frames:  (3160, 2345)\n",
      "Accuracy:  0.4299855142443264\n",
      "Person:  651\n",
      "Transitions:  [0, 8, 1, 8]\n",
      "GT transitions:  1\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.657465495608532 0.7158351409978309 0.4034229828850856\n",
      "Num frames:  (461, 58)\n",
      "Accuracy:  0.657465495608532\n",
      "Person:  652\n",
      "Transitions:  [1, 8, 4, 8, 2, 8, 3, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.902469917669411 0.8287671232876712 0.9945205479452055\n",
      "Num frames:  (876, 150)\n",
      "Accuracy:  0.902469917669411\n",
      "Person:  653\n",
      "Transitions:  [5, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.9978021978021978 0.9978021978021978 1.0\n",
      "Num frames:  (455, 1)\n",
      "Accuracy:  0.9978021978021978\n",
      "Person:  654\n",
      "Transitions:  [7, 8, 0, 8]\n",
      "GT transitions:  1\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.9457177322074789 0.9038876889848813 0.9988066825775657\n",
      "Num frames:  (926, 89)\n",
      "Accuracy:  0.9457177322074789\n",
      "Person:  655\n",
      "Transitions:  [7, 8, 6, 8, 5, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.4553376906318083 0.2745945945945946 0.23649906890130354\n",
      "Num frames:  (925, 180)\n",
      "Accuracy:  0.4553376906318083\n",
      "Person:  656\n",
      "Transitions:  [7, 8, 1, 8, 4, 8, 2, 8, 3, 8]\n",
      "GT transitions:  4\n",
      "Transitions captured:  0\n",
      "A,P,R:  0.27139874739039666 0.00900360144057623 0.016483516483516484\n",
      "Num frames:  (1666, 850)\n",
      "Accuracy:  0.27139874739039666\n",
      "Person:  657\n",
      "Transitions:  [0, 8, 1, 8, 2, 8, 3, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.9666534339023422 0.9434250764525994 0.967843137254902\n",
      "Num frames:  (1308, 43)\n",
      "Accuracy:  0.9666534339023422\n",
      "Person:  658\n",
      "Transitions:  [3, 8, 2, 8, 1, 8, 0, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.9821138211382113 0.9924698795180723 0.9748520710059172\n",
      "Num frames:  (1328, 10)\n",
      "Accuracy:  0.9821138211382113\n",
      "Person:  659\n",
      "Transitions:  [3, 8, 2, 8, 1, 8, 0, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.9514340344168261 0.9335180055401662 0.977519941986947\n",
      "Num frames:  (1444, 96)\n",
      "Accuracy:  0.9514340344168261\n",
      "Person:  660\n",
      "Transitions:  [5, 8, 4, 8, 1, 8, 0, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.8652337086318662 0.7937868237814676 0.9919678714859438\n",
      "Num frames:  (1867, 383)\n",
      "Accuracy:  0.8652337086318662\n",
      "Person:  661\n",
      "Transitions:  [5, 8, 6, 8, 7, 8, 0, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.8678822776711452 0.7444029850746269 0.9983319432860718\n",
      "Num frames:  (1608, 411)\n",
      "Accuracy:  0.8678822776711452\n",
      "Person:  662\n",
      "Transitions:  [4, 8, 1, 8, 0, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.9234897005366107 0.9096299325291352 1.0\n",
      "Num frames:  (4891, 442)\n",
      "Accuracy:  0.9234897005366107\n",
      "Person:  663\n",
      "Transitions:  [2, 8, 4, 8, 1, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.9054680259499537 0.8344947735191638 0.9123809523809524\n",
      "Num frames:  (574, 56)\n",
      "Accuracy:  0.9054680259499537\n",
      "Person:  664\n",
      "Transitions:  [7, 8, 6, 8]\n",
      "GT transitions:  1\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.9539422326307572 0.9228758169934641 1.0\n",
      "Num frames:  (765, 59)\n",
      "Accuracy:  0.9539422326307572\n",
      "Person:  665\n",
      "Transitions:  [5, 8, 4, 8, 1, 8, 0, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.9649507119386638 0.9398976982097187 0.998641304347826\n",
      "Num frames:  (1564, 94)\n",
      "Accuracy:  0.9649507119386638\n",
      "Person:  666\n",
      "Transitions:  [0, 8, 1, 8, 4, 8, 5, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.9027694160144492 0.8408082799408576 1.0\n",
      "Num frames:  (2029, 323)\n",
      "Accuracy:  0.9027694160144492\n",
      "Person:  667\n",
      "Transitions:  [7, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.9572301425661914 0.9572301425661914 0.9591836734693877\n",
      "Num frames:  (491, 1)\n",
      "Accuracy:  0.9572301425661914\n",
      "Person:  668\n",
      "Transitions:  [7, 8, 6, 8, 5, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.9213884635017866 0.8808049535603715 1.0\n",
      "Num frames:  (1292, 154)\n",
      "Accuracy:  0.9213884635017866\n",
      "Person:  669\n",
      "Transitions:  [7, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.9962406015037594 0.9962406015037594 1.0\n",
      "Num frames:  (266, 1)\n",
      "Accuracy:  0.9962406015037594\n",
      "Person:  670\n",
      "Transitions:  [7, 8, 6, 8, 5, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.9576951130561634 0.9906542056074766 0.935687263556116\n",
      "Num frames:  (749, 7)\n",
      "Accuracy:  0.9576951130561634\n",
      "Person:  671\n",
      "Transitions:  [0, 8, 1, 8, 2, 8, 3, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.410024364775496 0.21161587119033928 0.2496607869742198\n",
      "Num frames:  (1739, 589)\n",
      "Accuracy:  0.410024364775496\n",
      "Person:  672\n",
      "Transitions:  [1, 8, 0, 8]\n",
      "GT transitions:  1\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.8512820512820513 0.7799325463743676 0.9935553168635876\n",
      "Num frames:  (1186, 255)\n",
      "Accuracy:  0.8512820512820513\n",
      "Person:  673\n",
      "Transitions:  [1, 8, 2, 8, 3, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.908745247148289 0.8558558558558559 1.0\n",
      "Num frames:  (999, 144)\n",
      "Accuracy:  0.908745247148289\n",
      "Person:  674\n",
      "Transitions:  [2, 8, 1, 8]\n",
      "GT transitions:  1\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.9790575916230366 0.9963833634719711 0.9752212389380531\n",
      "Num frames:  (553, 2)\n",
      "Accuracy:  0.9790575916230366\n",
      "Person:  675\n",
      "Transitions:  [5, 8, 6, 8, 7, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.9066511085180864 0.8620689655172413 1.0\n",
      "Num frames:  (1160, 160)\n",
      "Accuracy:  0.9066511085180864\n",
      "Person:  676\n",
      "Transitions:  [0, 8, 1, 8, 2, 8, 4, 8, 5, 8]\n",
      "GT transitions:  4\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.14413466596528143 0.05610663360198388 0.06062636074359404\n",
      "Num frames:  (6452, 899)\n",
      "Accuracy:  0.14413466596528143\n",
      "Person:  677\n",
      "Transitions:  [0, 8, 1, 8, 4, 8, 4, 8, 5, 8]\n",
      "GT transitions:  4\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.4565846033606878 0.036865234375 0.13899969315741026\n",
      "Num frames:  (12288, 11100)\n",
      "Accuracy:  0.4565846033606878\n",
      "Person:  678\n",
      "Transitions:  [5, 8, 6, 8, 7, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.9147331786542924 0.874251497005988 1.0\n",
      "Num frames:  (1169, 147)\n",
      "Accuracy:  0.9147331786542924\n",
      "Person:  679\n",
      "Transitions:  [0, 8, 1, 8, 2, 8, 3, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.9266340595820365 0.8965835641735919 0.8700716845878136\n",
      "Num frames:  (1083, 20)\n",
      "Accuracy:  0.9266340595820365\n",
      "Person:  680\n",
      "Transitions:  [7, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.9464882943143813 0.9464882943143813 0.9496644295302014\n",
      "Num frames:  (299, 1)\n",
      "Accuracy:  0.9464882943143813\n",
      "Person:  681\n",
      "Transitions:  [2, 8, 1, 8, 0, 8, 0, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.7280493592785952 0.8156565656565656 0.6009302325581395\n",
      "Num frames:  (792, 144)\n",
      "Accuracy:  0.7280493592785952\n",
      "Person:  682\n",
      "Transitions:  [1, 8, 0, 8]\n",
      "GT transitions:  1\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.9683069224353628 0.9410852713178295 0.9902120717781403\n",
      "Num frames:  (645, 32)\n",
      "Accuracy:  0.9683069224353628\n",
      "Person:  683\n",
      "Transitions:  [7, 8, 0, 8]\n",
      "GT transitions:  1\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.9403810694529809 0.8914988814317674 1.0\n",
      "Num frames:  (894, 97)\n",
      "Accuracy:  0.9403810694529809\n",
      "Person:  684\n",
      "Transitions:  [0, 8, 1, 8, 2, 8, 3, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.364323258869908 0.19014830508474576 0.22968650031989762\n",
      "Num frames:  (1888, 731)\n",
      "Accuracy:  0.364323258869908\n",
      "Person:  685\n",
      "Transitions:  [7, 8, 1, 8]\n",
      "GT transitions:  1\n",
      "Transitions captured:  0\n",
      "A,P,R:  0.44966442953020136 0.16649214659685863 0.18213058419243985\n",
      "Num frames:  (955, 106)\n",
      "Accuracy:  0.44966442953020136\n",
      "Person:  686\n",
      "Transitions:  [0, 8, 1, 8, 2, 8, 3, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.9069767441860465 0.8413719185423365 1.0\n",
      "Num frames:  (1866, 296)\n",
      "Accuracy:  0.9069767441860465\n",
      "Person:  687\n",
      "Transitions:  [7, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.9678456591639871 0.9678456591639871 0.9709677419354839\n",
      "Num frames:  (311, 1)\n",
      "Accuracy:  0.9678456591639871\n",
      "Person:  688\n",
      "Transitions:  [3, 8, 2, 8, 1, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.9868646487721302 0.9847122302158273 0.9945504087193461\n",
      "Num frames:  (1112, 17)\n",
      "Accuracy:  0.9868646487721302\n",
      "Person:  689\n",
      "Transitions:  [5, 8, 6, 8, 7, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.8295566502463054 0.766531713900135 1.0\n",
      "Num frames:  (1482, 346)\n",
      "Accuracy:  0.8295566502463054\n",
      "Person:  690\n",
      "Transitions:  [7, 8, 6, 8, 5, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.526246719160105 0.3328220858895706 0.24164810690423164\n",
      "Num frames:  (652, 41)\n",
      "Accuracy:  0.526246719160105\n",
      "Person:  691\n",
      "Transitions:  [0, 8, 1, 8, 2, 8, 3, 8, 3, 8]\n",
      "GT transitions:  4\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.7892436974789916 0.8329355608591885 0.7036290322580645\n",
      "Num frames:  (1257, 186)\n",
      "Accuracy:  0.7892436974789916\n",
      "Person:  692\n",
      "Transitions:  [7, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.996078431372549 0.996078431372549 1.0\n",
      "Num frames:  (255, 1)\n",
      "Accuracy:  0.996078431372549\n",
      "Person:  693\n",
      "Transitions:  [7, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.9420289855072463 0.9420289855072463 0.9447674418604651\n",
      "Num frames:  (345, 1)\n",
      "Accuracy:  0.9420289855072463\n",
      "Person:  694\n",
      "Transitions:  [0, 8, 1, 8]\n",
      "GT transitions:  1\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.8531431590068674 0.7642069550466497 1.0\n",
      "Num frames:  (1179, 278)\n",
      "Accuracy:  0.8531431590068674\n",
      "Person:  695\n",
      "Transitions:  [3, 8, 2, 8, 1, 8, 0, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.8774011299435028 0.8132530120481928 1.0\n",
      "Num frames:  (2324, 434)\n",
      "Accuracy:  0.8774011299435028\n",
      "Person:  696\n",
      "Transitions:  [7, 8, 0, 8]\n",
      "GT transitions:  1\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.8965317919075144 0.8195564516129032 1.0\n",
      "Num frames:  (992, 179)\n",
      "Accuracy:  0.8965317919075144\n",
      "Person:  697\n",
      "Transitions:  [0, 8, 1, 8, 2, 8, 3, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.9130090945037564 0.8504240555127217 0.868503937007874\n",
      "Num frames:  (1297, 53)\n",
      "Accuracy:  0.9130090945037564\n",
      "Person:  698\n",
      "Transitions:  [5, 8, 4, 8, 1, 8, 0, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.9312950875987633 0.8847045191193511 0.9993455497382199\n",
      "Num frames:  (1726, 199)\n",
      "Accuracy:  0.9312950875987633\n",
      "Person:  699\n",
      "Transitions:  [7, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.996969696969697 0.996969696969697 1.0\n",
      "Num frames:  (330, 1)\n",
      "Accuracy:  0.996969696969697\n",
      "Person:  700\n",
      "Transitions:  [7, 8, 0, 8]\n",
      "GT transitions:  1\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.9879101899827288 0.9963898916967509 0.9787234042553191\n",
      "Num frames:  (554, 2)\n",
      "Accuracy:  0.9879101899827288\n",
      "Person:  701\n",
      "Transitions:  [7, 8, 0, 8]\n",
      "GT transitions:  1\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.951044776119403 0.9135021097046413 0.9852104664391353\n",
      "Num frames:  (948, 69)\n",
      "Accuracy:  0.951044776119403\n",
      "Person:  702\n",
      "Transitions:  [7, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.9971181556195965 0.9971181556195965 1.0\n",
      "Num frames:  (347, 1)\n",
      "Accuracy:  0.9971181556195965\n",
      "Person:  703\n",
      "Transitions:  [7, 8, 6, 8, 5, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.5743944636678201 0.37435008665511266 0.2630937880633374\n",
      "Num frames:  (577, 10)\n",
      "Accuracy:  0.5743944636678201\n",
      "Person:  704\n",
      "Transitions:  [7, 8, 0, 8]\n",
      "GT transitions:  1\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.9329501915708812 0.8719512195121951 1.0\n",
      "Num frames:  (820, 105)\n",
      "Accuracy:  0.9329501915708812\n",
      "Person:  705\n",
      "Transitions:  [7, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.9659863945578231 0.9659863945578231 0.9692832764505119\n",
      "Num frames:  (294, 1)\n",
      "Accuracy:  0.9659863945578231\n",
      "Person:  706\n",
      "Transitions:  [7, 8, 6, 8, 5, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.8922211808809747 0.8433242506811989 1.0\n",
      "Num frames:  (1468, 230)\n",
      "Accuracy:  0.8922211808809747\n",
      "Person:  707\n",
      "Transitions:  [5, 8, 4, 8, 1, 8, 0, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.7306050715541049 0.6160458452722063 0.999418942475305\n",
      "Num frames:  (2792, 1072)\n",
      "Accuracy:  0.7306050715541049\n",
      "Person:  708\n",
      "Transitions:  [0, 8, 1, 8, 4, 8, 6, 8, 5, 8]\n",
      "GT transitions:  4\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.42631880733944955 0.16839729119638827 0.2575966850828729\n",
      "Num frames:  (2215, 926)\n",
      "Accuracy:  0.42631880733944955\n",
      "Person:  709\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transitions:  [0, 8, 1, 8, 4, 8, 5, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.37151921043355657 0.1930635838150289 0.22416107382550335\n",
      "Num frames:  (1730, 627)\n",
      "Accuracy:  0.37151921043355657\n",
      "Person:  710\n",
      "Transitions:  [7, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.953405017921147 0.953405017921147 0.9568345323741008\n",
      "Num frames:  (279, 1)\n",
      "Accuracy:  0.953405017921147\n",
      "Person:  711\n",
      "Transitions:  [7, 8, 6, 8, 5, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.9730363423212193 0.9560229445506692 1.0\n",
      "Num frames:  (1046, 46)\n",
      "Accuracy:  0.9730363423212193\n",
      "Person:  712\n",
      "Transitions:  [5, 8, 4, 8, 1, 8, 0, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.9532100108813928 0.9214330609679446 0.9972789115646259\n",
      "Num frames:  (1591, 125)\n",
      "Accuracy:  0.9532100108813928\n",
      "Person:  713\n",
      "Transitions:  [5, 8, 6, 8, 7, 8, 0, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.870899470899471 0.7523680649526387 1.0\n",
      "Num frames:  (1478, 366)\n",
      "Accuracy:  0.870899470899471\n",
      "Person:  714\n",
      "Transitions:  [7, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.9382022471910112 0.9382022471910112 0.9408450704225352\n",
      "Num frames:  (356, 1)\n",
      "Accuracy:  0.9382022471910112\n",
      "Person:  715\n",
      "Transitions:  [7, 8, 0, 8]\n",
      "GT transitions:  1\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.9939894815927873 0.9913544668587896 0.9971014492753624\n",
      "Num frames:  (694, 6)\n",
      "Accuracy:  0.9939894815927873\n",
      "Person:  716\n",
      "Transitions:  [7, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.961764705882353 0.961764705882353 0.9646017699115044\n",
      "Num frames:  (340, 1)\n",
      "Accuracy:  0.961764705882353\n",
      "Person:  717\n",
      "Transitions:  [1, 8, 7, 8]\n",
      "GT transitions:  1\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.699546485260771 0.6426163182737694 0.959718026183283\n",
      "Num frames:  (1483, 490)\n",
      "Accuracy:  0.699546485260771\n",
      "Person:  718\n",
      "Transitions:  [0, 8, 1, 8, 2, 8, 3, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.8983890954151177 0.871536523929471 0.8411669367909238\n",
      "Num frames:  (1191, 50)\n",
      "Accuracy:  0.8983890954151177\n",
      "Person:  719\n",
      "Transitions:  [7, 8, 6, 8, 5, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.9657933042212519 0.9960681520314548 0.945273631840796\n",
      "Num frames:  (763, 3)\n",
      "Accuracy:  0.9657933042212519\n",
      "Person:  720\n",
      "Transitions:  [3, 8, 2, 8, 1, 8, 0, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.9666520403685828 0.9889078498293515 0.9484451718494271\n",
      "Num frames:  (1172, 13)\n",
      "Accuracy:  0.9666520403685828\n",
      "Person:  721\n",
      "Transitions:  [0, 8, 1, 8]\n",
      "GT transitions:  1\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.7457121551081283 0.8960674157303371 0.4953416149068323\n",
      "Num frames:  (356, 16)\n",
      "Accuracy:  0.7457121551081283\n",
      "Person:  722\n",
      "Transitions:  [7, 8, 6, 8, 5, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.9627363737486095 0.9406028368794326 1.0\n",
      "Num frames:  (1128, 67)\n",
      "Accuracy:  0.9627363737486095\n",
      "Person:  723\n",
      "Transitions:  [7, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.9618528610354223 0.9618528610354223 0.9644808743169399\n",
      "Num frames:  (367, 1)\n",
      "Accuracy:  0.9618528610354223\n",
      "Person:  724\n",
      "Transitions:  [6, 8, 7, 8]\n",
      "GT transitions:  1\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.7879032258064517 0.6923976608187135 1.0\n",
      "Num frames:  (855, 263)\n",
      "Accuracy:  0.7879032258064517\n",
      "Person:  725\n",
      "Transitions:  [0, 8, 1, 8, 2, 8, 3, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.36772665764546686 0.18102029621503016 0.22267206477732793\n",
      "Num frames:  (1823, 717)\n",
      "Accuracy:  0.36772665764546686\n",
      "Person:  726\n",
      "Transitions:  [7, 8, 6, 8, 5, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.4825133372851215 0.2915129151291513 0.22942884801548888\n",
      "Num frames:  (813, 77)\n",
      "Accuracy:  0.4825133372851215\n",
      "Person:  727\n",
      "Transitions:  [7, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.9585987261146497 0.9585987261146497 0.9616613418530351\n",
      "Num frames:  (314, 1)\n",
      "Accuracy:  0.9585987261146497\n",
      "Person:  728\n",
      "Transitions:  [5, 8, 6, 8, 7, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.8638638638638638 0.8116343490304709 1.0\n",
      "Num frames:  (1444, 272)\n",
      "Accuracy:  0.8638638638638638\n",
      "Person:  729\n",
      "Transitions:  [2, 8, 1, 8, 0, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.8417849898580122 0.7686832740213523 1.0\n",
      "Num frames:  (1686, 390)\n",
      "Accuracy:  0.8417849898580122\n",
      "Person:  730\n",
      "Transitions:  [5, 8, 4, 8, 1, 8, 1, 8, 2, 8, 4, 8, 5, 8]\n",
      "GT transitions:  6\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.39852099751700315 0.28341645009482336 0.6993067590987868\n",
      "Num frames:  (14237, 9408)\n",
      "Accuracy:  0.39852099751700315\n",
      "Person:  731\n",
      "Transitions:  [3, 8, 2, 8, 1, 8, 0, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.9687382297551789 0.9548563611491108 0.9879688605803255\n",
      "Num frames:  (1462, 66)\n",
      "Accuracy:  0.9687382297551789\n",
      "Person:  732\n",
      "Transitions:  [7, 8, 6, 8, 5, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.946560545764639 0.9145220588235294 0.998995983935743\n",
      "Num frames:  (1088, 93)\n",
      "Accuracy:  0.946560545764639\n",
      "Person:  733\n",
      "Transitions:  [7, 8, 6, 8, 5, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.957983193277311 0.9331550802139037 1.0\n",
      "Num frames:  (1122, 75)\n",
      "Accuracy:  0.957983193277311\n",
      "Person:  734\n",
      "Transitions:  [7, 8, 6, 8, 5, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.9042386185243328 0.9939301972685888 0.8473479948253557\n",
      "Num frames:  (659, 4)\n",
      "Accuracy:  0.9042386185243328\n",
      "Person:  735\n",
      "Transitions:  [3, 8, 2, 8, 4, 8, 1, 8, 0, 8]\n",
      "GT transitions:  4\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.5169873722188816 0.4251050821551395 0.791814946619217\n",
      "Num frames:  (5234, 2628)\n",
      "Accuracy:  0.5169873722188816\n",
      "Person:  736\n",
      "Transitions:  [0, 8, 1, 8, 2, 8, 3, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.3867857142857143 0.191044776119403 0.22955523672883787\n",
      "Num frames:  (1675, 643)\n",
      "Accuracy:  0.3867857142857143\n",
      "Person:  737\n",
      "Transitions:  [7, 8, 6, 8, 5, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.9730046948356808 0.9578139980824545 0.998001998001998\n",
      "Num frames:  (1043, 44)\n",
      "Accuracy:  0.9730046948356808\n",
      "Person:  738\n",
      "Transitions:  [0, 8, 1, 8, 2, 8, 3, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.8844221105527639 0.8119288119288119 1.0\n",
      "Num frames:  (2079, 391)\n",
      "Accuracy:  0.8844221105527639\n",
      "Person:  739\n",
      "Transitions:  [0, 8, 1, 8]\n",
      "GT transitions:  1\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.736449864498645 0.8209606986899564 0.5340909090909091\n",
      "Num frames:  (458, 61)\n",
      "Accuracy:  0.736449864498645\n",
      "Person:  740\n",
      "Transitions:  [1, 8, 4, 8, 5, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.8244084682440846 0.7725284339457568 0.969264544456641\n",
      "Num frames:  (1143, 254)\n",
      "Accuracy:  0.8244084682440846\n",
      "Person:  741\n",
      "Transitions:  [5, 8, 6, 8, 7, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.9057071960297767 0.8559241706161137 1.0\n",
      "Num frames:  (1055, 152)\n",
      "Accuracy:  0.9057071960297767\n",
      "Person:  742\n",
      "Transitions:  [0, 8, 1, 8, 4, 8, 5, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.7481865284974093 0.6102564102564103 0.7614259597806216\n",
      "Num frames:  (1365, 468)\n",
      "Accuracy:  0.7481865284974093\n",
      "Person:  743\n",
      "Transitions:  [7, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.9399293286219081 0.9399293286219081 0.9432624113475178\n",
      "Num frames:  (283, 1)\n",
      "Accuracy:  0.9399293286219081\n",
      "Person:  744\n",
      "Transitions:  [5, 8, 6, 8, 7, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.8624587847385775 0.8131797824696098 1.0\n",
      "Num frames:  (1563, 292)\n",
      "Accuracy:  0.8624587847385775\n",
      "Person:  745\n",
      "Transitions:  [7, 8, 0, 8]\n",
      "GT transitions:  1\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.7946341463414635 0.6703210649960846 0.9782857142857143\n",
      "Num frames:  (1277, 402)\n",
      "Accuracy:  0.7946341463414635\n",
      "Person:  746\n",
      "Transitions:  [0, 8, 1, 8, 4, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.4226618705035971 0.19334811529933482 0.30921985815602837\n",
      "Num frames:  (2255, 1273)\n",
      "Accuracy:  0.4226618705035971\n",
      "Person:  747\n",
      "Transitions:  [3, 8, 2, 8, 1, 8, 0, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.9555256064690026 0.9903846153846154 0.9279279279279279\n",
      "Num frames:  (1144, 11)\n",
      "Accuracy:  0.9555256064690026\n",
      "Person:  748\n",
      "Transitions:  [7, 8, 6, 8, 5, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.9176165803108808 0.8737092930897538 1.0\n",
      "Num frames:  (1259, 159)\n",
      "Accuracy:  0.9176165803108808\n",
      "Person:  749\n",
      "Transitions:  [3, 8, 2, 8, 1, 8, 0, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  0\n",
      "A,P,R:  0.3102205258693808 0.2069807175982426 0.3302180685358255\n",
      "Num frames:  (4097, 1533)\n",
      "Accuracy:  0.3102205258693808\n",
      "Person:  750\n",
      "Transitions:  [7, 8, 6, 8, 5, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.9726538222498446 0.9612970711297071 0.9924406047516199\n",
      "Num frames:  (956, 37)\n",
      "Accuracy:  0.9726538222498446\n",
      "Person:  751\n",
      "Transitions:  [0, 8, 1, 8]\n",
      "GT transitions:  1\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.6529808773903262 0.6558823529411765 0.5186046511627908\n",
      "Num frames:  (680, 203)\n",
      "Accuracy:  0.6529808773903262\n",
      "Person:  752\n",
      "Transitions:  [5, 8, 6, 8, 7, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.8783783783783784 0.8285714285714286 1.0\n",
      "Num frames:  (1365, 234)\n",
      "Accuracy:  0.8783783783783784\n",
      "Person:  753\n",
      "Transitions:  [1, 8, 0, 8]\n",
      "GT transitions:  1\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.9107142857142857 0.8534385569334837 0.9921363040629095\n",
      "Num frames:  (887, 124)\n",
      "Accuracy:  0.9107142857142857\n",
      "Person:  754\n",
      "Transitions:  [5, 8, 6, 8, 4, 8, 1, 8, 0, 8]\n",
      "GT transitions:  4\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.7177522349936143 0.6238938053097345 0.8468468468468469\n",
      "Num frames:  (1808, 680)\n",
      "Accuracy:  0.7177522349936143\n",
      "Person:  755\n",
      "Transitions:  [7, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.9455128205128205 0.9455128205128205 0.9485530546623794\n",
      "Num frames:  (312, 1)\n",
      "Accuracy:  0.9455128205128205\n",
      "Person:  756\n",
      "Transitions:  [7, 8, 6, 8, 5, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.9648506151142355 0.9426386233269598 1.0\n",
      "Num frames:  (1046, 60)\n",
      "Accuracy:  0.9648506151142355\n",
      "Person:  757\n",
      "Transitions:  [7, 8, 0, 8]\n",
      "GT transitions:  1\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.9818709209572154 0.9652173913043478 0.9985007496251874\n",
      "Num frames:  (690, 24)\n",
      "Accuracy:  0.9818709209572154\n",
      "Person:  758\n",
      "Transitions:  [7, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.9514824797843666 0.9514824797843666 0.9540540540540541\n",
      "Num frames:  (371, 1)\n",
      "Accuracy:  0.9514824797843666\n",
      "Person:  759\n",
      "Transitions:  [3, 8, 2, 8, 1, 8, 0, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.9843152257077277 0.9765031098825155 0.9950704225352113\n",
      "Num frames:  (1447, 34)\n",
      "Accuracy:  0.9843152257077277\n",
      "Person:  760\n",
      "Transitions:  [5, 8, 6, 8, 7, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.8792723263506064 0.8257756563245824 1.0\n",
      "Num frames:  (1257, 219)\n",
      "Accuracy:  0.8792723263506064\n",
      "Person:  761\n",
      "Transitions:  [3, 8, 2, 8, 1, 8, 0, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.976181751557347 0.9586614173228346 0.9986329460013671\n",
      "Num frames:  (1524, 63)\n",
      "Accuracy:  0.976181751557347\n",
      "Person:  762\n",
      "Transitions:  [0, 8, 1, 8, 2, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.9028120374938332 0.8340353833192923 1.0\n",
      "Num frames:  (1187, 197)\n",
      "Accuracy:  0.9028120374938332\n",
      "Person:  763\n",
      "Transitions:  [7, 8, 0, 8]\n",
      "GT transitions:  1\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.9589387239418825 0.9258836944127709 0.9866342648845686\n",
      "Num frames:  (877, 54)\n",
      "Accuracy:  0.9589387239418825\n",
      "Person:  764\n",
      "Transitions:  [4, 8, 5, 8]\n",
      "GT transitions:  1\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.9093097913322632 0.8690614136732329 1.0\n",
      "Num frames:  (863, 113)\n",
      "Accuracy:  0.9093097913322632\n",
      "Person:  765\n",
      "Transitions:  [0, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.9973404255319149 0.9973404255319149 1.0\n",
      "Num frames:  (376, 1)\n",
      "Accuracy:  0.9973404255319149\n",
      "Person:  766\n",
      "Transitions:  [1, 8, 4, 8, 2, 8, 3, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.897358943577431 0.8239583333333333 0.9974779319041615\n",
      "Num frames:  (960, 169)\n",
      "Accuracy:  0.897358943577431\n",
      "Person:  767\n",
      "Transitions:  [7, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.9931972789115646 0.9931972789115646 1.0\n",
      "Num frames:  (147, 1)\n",
      "Accuracy:  0.9931972789115646\n",
      "Person:  768\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transitions:  [7, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.9709677419354839 0.9709677419354839 0.9741100323624595\n",
      "Num frames:  (310, 1)\n",
      "Accuracy:  0.9709677419354839\n",
      "Person:  769\n",
      "Transitions:  [0, 8, 1, 8, 4, 8, 5, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.3545293072824156 0.18024263431542462 0.2074468085106383\n",
      "Num frames:  (1731, 625)\n",
      "Accuracy:  0.3545293072824156\n",
      "Person:  770\n",
      "Transitions:  [5, 8, 6, 8, 7, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.8999421631000578 0.852263023057216 1.0\n",
      "Num frames:  (1171, 173)\n",
      "Accuracy:  0.8999421631000578\n",
      "Person:  771\n",
      "Transitions:  [5, 8, 4, 8, 1, 8, 0, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.9215824796891557 0.8728663919952914 0.9959704499664204\n",
      "Num frames:  (1699, 216)\n",
      "Accuracy:  0.9215824796891557\n",
      "Person:  772\n",
      "Transitions:  [5, 8, 4, 8, 1, 8, 0, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.9302176696542894 0.889865563598759 0.9971031286210892\n",
      "Num frames:  (1934, 213)\n",
      "Accuracy:  0.9302176696542894\n",
      "Person:  773\n",
      "Transitions:  [5, 8, 4, 8, 1, 8, 0, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.9365818702973845 0.895625 0.9930699930699931\n",
      "Num frames:  (1600, 167)\n",
      "Accuracy:  0.9365818702973845\n",
      "Person:  774\n",
      "Transitions:  [5, 8, 4, 8, 1, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.9646723646723647 0.9486740804106074 0.9973021582733813\n",
      "Num frames:  (1169, 59)\n",
      "Accuracy:  0.9646723646723647\n",
      "Person:  775\n",
      "Transitions:  [0, 8, 1, 8, 2, 8, 3, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.3748266296809986 0.18983050847457628 0.2284160435078178\n",
      "Num frames:  (1770, 668)\n",
      "Accuracy:  0.3748266296809986\n",
      "Person:  776\n",
      "Transitions:  [7, 8, 6, 8, 5, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.5284810126582279 0.3352601156069364 0.25692137320044295\n",
      "Num frames:  (692, 74)\n",
      "Accuracy:  0.5284810126582279\n",
      "Person:  777\n",
      "Transitions:  [1, 8, 0, 8]\n",
      "GT transitions:  1\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.9711769415532426 0.9553956834532374 0.9837037037037037\n",
      "Num frames:  (695, 25)\n",
      "Accuracy:  0.9711769415532426\n",
      "Person:  778\n",
      "Transitions:  [5, 8, 6, 8, 4, 8, 1, 8, 0, 8]\n",
      "GT transitions:  4\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.7249757045675413 0.64543404735062 0.8388278388278388\n",
      "Num frames:  (1774, 629)\n",
      "Accuracy:  0.7249757045675413\n",
      "Person:  779\n",
      "Transitions:  [4, 8, 5, 8]\n",
      "GT transitions:  1\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.9315300084530854 0.9009779951100244 1.0\n",
      "Num frames:  (818, 81)\n",
      "Accuracy:  0.9315300084530854\n",
      "Person:  780\n",
      "Transitions:  [6, 8, 5, 8]\n",
      "GT transitions:  1\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.9621676891615542 0.9550970873786407 1.0\n",
      "Num frames:  (824, 37)\n",
      "Accuracy:  0.9621676891615542\n",
      "Person:  781\n",
      "Transitions:  [5, 8, 4, 8, 1, 8, 0, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.9194249414911401 0.8678728070175439 1.0\n",
      "Num frames:  (1824, 241)\n",
      "Accuracy:  0.9194249414911401\n",
      "Person:  782\n",
      "Transitions:  [5, 8, 6, 8, 7, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.8732470334412082 0.8186728395061729 1.0\n",
      "Num frames:  (1296, 235)\n",
      "Accuracy:  0.8732470334412082\n",
      "Person:  783\n",
      "Transitions:  [7, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.9595687331536388 0.9595687331536388 0.9621621621621622\n",
      "Num frames:  (371, 1)\n",
      "Accuracy:  0.9595687331536388\n",
      "Person:  784\n",
      "Transitions:  [0, 8, 1, 8]\n",
      "GT transitions:  1\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.7430453879941434 0.8803191489361702 0.5022761760242792\n",
      "Num frames:  (376, 23)\n",
      "Accuracy:  0.7430453879941434\n",
      "Person:  785\n",
      "Transitions:  [1, 8, 0, 8]\n",
      "GT transitions:  1\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.9559147685525349 0.9266750948166877 0.9892037786774629\n",
      "Num frames:  (791, 52)\n",
      "Accuracy:  0.9559147685525349\n",
      "Person:  786\n",
      "Transitions:  [7, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.9611650485436893 0.9611650485436893 0.9642857142857143\n",
      "Num frames:  (309, 1)\n",
      "Accuracy:  0.9611650485436893\n",
      "Person:  787\n",
      "Transitions:  [0, 8, 1, 8, 2, 8, 3, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.9001531393568147 0.8340122199592668 1.0\n",
      "Num frames:  (1964, 326)\n",
      "Accuracy:  0.9001531393568147\n",
      "Person:  788\n",
      "Transitions:  [5, 8, 4, 8, 4, 8, 1, 8, 0, 8]\n",
      "GT transitions:  4\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.603288490284006 0.500752445447705 0.7498591549295774\n",
      "Num frames:  (5316, 1766)\n",
      "Accuracy:  0.603288490284006\n",
      "Person:  789\n",
      "Transitions:  [7, 8, 6, 8, 5, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.9517396184062851 0.9225922592259226 1.0\n",
      "Num frames:  (1111, 86)\n",
      "Accuracy:  0.9517396184062851\n",
      "Person:  790\n",
      "Transitions:  [7, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.9517241379310345 0.9517241379310345 0.9550173010380623\n",
      "Num frames:  (290, 1)\n",
      "Accuracy:  0.9517241379310345\n",
      "Person:  791\n",
      "Transitions:  [5, 8, 4, 8, 1, 8, 0, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.9611613876319759 0.9320323014804845 0.9985580389329488\n",
      "Num frames:  (1486, 101)\n",
      "Accuracy:  0.9611613876319759\n",
      "Person:  792\n",
      "Transitions:  [0, 8, 1, 8]\n",
      "GT transitions:  1\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.7275769745649264 0.7928870292887029 0.5353107344632768\n",
      "Num frames:  (478, 78)\n",
      "Accuracy:  0.7275769745649264\n",
      "Person:  793\n",
      "Transitions:  [3, 8, 2, 8, 4, 8, 1, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.8924264351181862 0.8307291666666666 0.9382352941176471\n",
      "Num frames:  (1152, 160)\n",
      "Accuracy:  0.8924264351181862\n",
      "Person:  794\n",
      "Transitions:  [5, 8, 4, 8, 1, 8, 0, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.9250739401906014 0.8756815703380589 1.0\n",
      "Num frames:  (1834, 228)\n",
      "Accuracy:  0.9250739401906014\n",
      "Person:  795\n",
      "Transitions:  [3, 8, 2, 8, 1, 8, 0, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.9624772313296903 0.9353169469598965 0.9979296066252588\n",
      "Num frames:  (1546, 100)\n",
      "Accuracy:  0.9624772313296903\n",
      "Person:  796\n",
      "Transitions:  [7, 8, 6, 8, 5, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.9753954305799648 0.9604891815616181 1.0\n",
      "Num frames:  (1063, 42)\n",
      "Accuracy:  0.9753954305799648\n",
      "Person:  797\n",
      "Transitions:  [7, 8, 0, 8]\n",
      "GT transitions:  1\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.9392338177014531 0.8840764331210191 0.9985611510791367\n",
      "Num frames:  (785, 91)\n",
      "Accuracy:  0.9392338177014531\n",
      "Person:  798\n",
      "Transitions:  [0, 8, 1, 8]\n",
      "GT transitions:  1\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.5944055944055944 0.2846715328467153 0.2582781456953642\n",
      "Num frames:  (274, 124)\n",
      "Accuracy:  0.5944055944055944\n",
      "Person:  799\n",
      "Transitions:  [7, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.94921875 0.94921875 0.9529411764705882\n",
      "Num frames:  (256, 1)\n",
      "Accuracy:  0.94921875\n",
      "Person:  800\n",
      "Transitions:  [7, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.9962962962962963 0.9962962962962963 1.0\n",
      "Num frames:  (270, 1)\n",
      "Accuracy:  0.9962962962962963\n",
      "Person:  801\n",
      "Transitions:  [3, 8, 2, 8, 1, 8, 1, 8, 4, 8, 4, 8]\n",
      "GT transitions:  5\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.3087450138079165 0.0822756025964361 0.5268731797723061\n",
      "Num frames:  (24187, 20741)\n",
      "Accuracy:  0.3087450138079165\n",
      "Person:  802\n",
      "Transitions:  [3, 8, 2, 8, 4, 8, 1, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.7913553895410885 0.7173030056864338 0.9265477439664218\n",
      "Num frames:  (1231, 321)\n",
      "Accuracy:  0.7913553895410885\n",
      "Person:  803\n",
      "Transitions:  [3, 8, 2, 8, 1, 8, 0, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.9726027397260274 0.9516846789574063 1.0\n",
      "Num frames:  (1573, 76)\n",
      "Accuracy:  0.9726027397260274\n",
      "Person:  804\n",
      "Transitions:  [7, 8, 6, 8, 5, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.8875502008032129 0.8301743745261562 1.0\n",
      "Num frames:  (1319, 224)\n",
      "Accuracy:  0.8875502008032129\n",
      "Person:  805\n",
      "Transitions:  [0, 8, 1, 8, 2, 8, 3, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.33727639930755915 0.18851756640959727 0.24929178470254956\n",
      "Num frames:  (2334, 972)\n",
      "Accuracy:  0.33727639930755915\n",
      "Person:  806\n",
      "Transitions:  [0, 8, 1, 8, 4, 8, 5, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.35707620528771383 0.16683070866141733 0.2058287795992714\n",
      "Num frames:  (2032, 759)\n",
      "Accuracy:  0.35707620528771383\n",
      "Person:  807\n",
      "Transitions:  [7, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.9953271028037384 0.9953271028037384 1.0\n",
      "Num frames:  (214, 1)\n",
      "Accuracy:  0.9953271028037384\n",
      "Person:  808\n",
      "Transitions:  [7, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.9623188405797102 0.9623188405797102 0.9651162790697675\n",
      "Num frames:  (345, 1)\n",
      "Accuracy:  0.9623188405797102\n",
      "Person:  809\n",
      "Transitions:  [5, 8, 4, 8]\n",
      "GT transitions:  1\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.8548672566371681 0.8052256532066508 1.0\n",
      "Num frames:  (842, 164)\n",
      "Accuracy:  0.8548672566371681\n",
      "Person:  810\n",
      "Transitions:  [1, 8, 1, 8]\n",
      "GT transitions:  1\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.9797639123102867 0.9797639123102867 1.0\n",
      "Num frames:  (593, 12)\n",
      "Accuracy:  0.9797639123102867\n",
      "Person:  811\n",
      "Transitions:  [7, 8, 6, 8, 5, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.5496335776149234 0.35331230283911674 0.2557077625570776\n",
      "Num frames:  (634, 24)\n",
      "Accuracy:  0.5496335776149234\n",
      "Person:  812\n",
      "Transitions:  [7, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.95 0.95 0.9514415781487102\n",
      "Num frames:  (660, 1)\n",
      "Accuracy:  0.95\n",
      "Person:  813\n",
      "Transitions:  [0, 8, 1, 8]\n",
      "GT transitions:  1\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.7166324435318275 0.8382352941176471 0.4796633941093969\n",
      "Num frames:  (408, 43)\n",
      "Accuracy:  0.7166324435318275\n",
      "Person:  814\n",
      "Transitions:  [7, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.953125 0.953125 0.9568627450980393\n",
      "Num frames:  (256, 1)\n",
      "Accuracy:  0.953125\n",
      "Person:  815\n",
      "Transitions:  [5, 8, 6, 8, 7, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.8893109061313077 0.8412451361867704 1.0\n",
      "Num frames:  (1285, 204)\n",
      "Accuracy:  0.8893109061313077\n",
      "Person:  816\n",
      "Transitions:  [7, 8, 6, 8, 5, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.8529411764705882 0.7945205479452054 1.0\n",
      "Num frames:  (1679, 345)\n",
      "Accuracy:  0.8529411764705882\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Person:  817\n",
      "Transitions:  [2, 8, 4, 8, 5, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.9034965034965035 0.9156355455568054 0.8819068255687974\n",
      "Num frames:  (889, 29)\n",
      "Accuracy:  0.9034965034965035\n",
      "Person:  818\n",
      "Transitions:  [5, 8, 6, 8, 7, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.919576059850374 0.8779564806054873 1.0\n",
      "Num frames:  (1057, 129)\n",
      "Accuracy:  0.919576059850374\n",
      "Person:  819\n",
      "Transitions:  [5, 8, 6, 8, 7, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.9470031545741325 0.9184466019417475 1.0\n",
      "Num frames:  (1030, 84)\n",
      "Accuracy:  0.9470031545741325\n",
      "Person:  820\n",
      "Transitions:  [5, 8, 4, 8, 4, 8, 1, 8, 0, 8]\n",
      "GT transitions:  4\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.5936315390447309 0.4859006330328026 0.7620336943441637\n",
      "Num frames:  (5213, 1889)\n",
      "Accuracy:  0.5936315390447309\n",
      "Person:  821\n",
      "Transitions:  [0, 8, 1, 8, 1, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.8653846153846154 0.7782805429864253 1.0\n",
      "Num frames:  (1105, 245)\n",
      "Accuracy:  0.8653846153846154\n",
      "Person:  822\n",
      "Transitions:  [0, 8, 1, 8]\n",
      "GT transitions:  1\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.7157584683357879 0.9 0.446064139941691\n",
      "Num frames:  (340, 6)\n",
      "Accuracy:  0.7157584683357879\n",
      "Person:  823\n",
      "Transitions:  [3, 8, 2, 8, 1, 8, 0, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.9801762114537445 0.9659163987138264 0.9993346640053227\n",
      "Num frames:  (1555, 53)\n",
      "Accuracy:  0.9801762114537445\n",
      "Person:  824\n",
      "Transitions:  [2, 8, 4, 8, 5, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.9288214702450408 0.9134751773049645 0.9930609097918273\n",
      "Num frames:  (2820, 226)\n",
      "Accuracy:  0.9288214702450408\n",
      "Person:  825\n",
      "Transitions:  [1, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.95 0.9528023598820059 0.9528023598820059\n",
      "Num frames:  (339, 1)\n",
      "Accuracy:  0.95\n",
      "Person:  826\n",
      "Transitions:  [0, 8, 1, 8, 4, 8, 5, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.8614260519022424 0.7952345495160089 1.0\n",
      "Num frames:  (2686, 550)\n",
      "Accuracy:  0.8614260519022424\n",
      "Person:  827\n",
      "Transitions:  [1, 8, 0, 8]\n",
      "GT transitions:  1\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.9411187438665358 0.9807321772639692 0.9008849557522124\n",
      "Num frames:  (519, 4)\n",
      "Accuracy:  0.9411187438665358\n",
      "Person:  828\n",
      "Transitions:  [7, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.9762931034482759 0.9762931034482759 0.978401727861771\n",
      "Num frames:  (464, 1)\n",
      "Accuracy:  0.9762931034482759\n",
      "Person:  829\n",
      "Transitions:  [5, 8, 6, 8, 7, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.8829847371396269 0.8293289146644574 0.999001996007984\n",
      "Num frames:  (1207, 206)\n",
      "Accuracy:  0.8829847371396269\n",
      "Person:  830\n",
      "Transitions:  [0, 8, 7, 8]\n",
      "GT transitions:  1\n",
      "Transitions captured:  0\n",
      "A,P,R:  0.6801292407108239 0.7392857142857143 0.34966216216216217\n",
      "Num frames:  (280, 11)\n",
      "Accuracy:  0.6801292407108239\n",
      "Person:  831\n",
      "Transitions:  [7, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.9965277777777778 0.9965277777777778 1.0\n",
      "Num frames:  (288, 1)\n",
      "Accuracy:  0.9965277777777778\n",
      "Person:  832\n",
      "Transitions:  [5, 8, 6, 8, 7, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.9166666666666666 0.8746492048643593 0.9989316239316239\n",
      "Num frames:  (1069, 134)\n",
      "Accuracy:  0.9166666666666666\n",
      "Person:  833\n",
      "Transitions:  [7, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.9680851063829787 0.9680851063829787 0.9706666666666667\n",
      "Num frames:  (376, 1)\n",
      "Accuracy:  0.9680851063829787\n",
      "Person:  834\n",
      "Transitions:  [7, 8, 6, 8, 5, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.4543859649122807 0.26852976913730253 0.21498054474708173\n",
      "Num frames:  (823, 126)\n",
      "Accuracy:  0.4543859649122807\n",
      "Person:  835\n",
      "Transitions:  [7, 8, 6, 8, 5, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.4997025580011898 0.3197969543147208 0.2507462686567164\n",
      "Num frames:  (788, 88)\n",
      "Accuracy:  0.4997025580011898\n",
      "Person:  836\n",
      "Transitions:  [5, 8, 4, 8, 1, 8, 0, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.9608711701734958 0.9322475570032573 0.9986043265875785\n",
      "Num frames:  (1535, 104)\n",
      "Accuracy:  0.9608711701734958\n",
      "Person:  837\n",
      "Transitions:  [7, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.990909090909091 0.990909090909091 0.993920972644377\n",
      "Num frames:  (330, 1)\n",
      "Accuracy:  0.990909090909091\n",
      "Person:  838\n",
      "Transitions:  [7, 8, 6, 8, 5, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.9662522202486679 0.9446064139941691 1.0\n",
      "Num frames:  (1029, 57)\n",
      "Accuracy:  0.9662522202486679\n",
      "Person:  839\n",
      "Transitions:  [5, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.9945652173913043 0.9945652173913043 1.0\n",
      "Num frames:  (184, 1)\n",
      "Accuracy:  0.9945652173913043\n",
      "Person:  840\n",
      "Transitions:  [1, 8, 2, 8, 3, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.9749835418038183 0.96 1.0\n",
      "Num frames:  (950, 38)\n",
      "Accuracy:  0.9749835418038183\n",
      "Person:  841\n",
      "Transitions:  [0, 8, 1, 8, 4, 8, 6, 8, 5, 8]\n",
      "GT transitions:  4\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.6924715909090909 0.47542304593070106 0.4880066170388751\n",
      "Num frames:  (1241, 247)\n",
      "Accuracy:  0.6924715909090909\n",
      "Person:  842\n",
      "Transitions:  [4, 8, 5, 8]\n",
      "GT transitions:  1\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.9667644183773216 0.9503649635036496 1.0\n",
      "Num frames:  (685, 34)\n",
      "Accuracy:  0.9667644183773216\n",
      "Person:  843\n",
      "Transitions:  [7, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.9527272727272728 0.9527272727272728 0.9562043795620438\n",
      "Num frames:  (275, 1)\n",
      "Accuracy:  0.9527272727272728\n",
      "Person:  844\n",
      "Transitions:  [7, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.996742671009772 0.996742671009772 1.0\n",
      "Num frames:  (307, 1)\n",
      "Accuracy:  0.996742671009772\n",
      "Person:  845\n",
      "Transitions:  [0, 8, 1, 8, 4, 8, 5, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.8803949224259521 0.8146042850896371 1.0\n",
      "Num frames:  (2287, 424)\n",
      "Accuracy:  0.8803949224259521\n",
      "Person:  846\n",
      "Transitions:  [7, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.9447852760736196 0.9447852760736196 0.9476923076923077\n",
      "Num frames:  (326, 1)\n",
      "Accuracy:  0.9447852760736196\n",
      "Person:  847\n",
      "Transitions:  [0, 8, 7, 8]\n",
      "GT transitions:  1\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.9151756129887343 0.8300132802124834 0.9796238244514106\n",
      "Num frames:  (753, 115)\n",
      "Accuracy:  0.9151756129887343\n",
      "Person:  848\n",
      "Transitions:  [7, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.9448275862068966 0.9448275862068966 0.9480968858131488\n",
      "Num frames:  (290, 1)\n",
      "Accuracy:  0.9448275862068966\n",
      "Person:  849\n",
      "Transitions:  [7, 8, 6, 8, 5, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.8949361097964978 0.8460471567267683 1.0\n",
      "Num frames:  (1442, 222)\n",
      "Accuracy:  0.8949361097964978\n",
      "Person:  850\n",
      "Transitions:  [3, 8, 2, 8, 1, 8, 0, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.9791445740544362 0.966626213592233 0.9974953036944271\n",
      "Num frames:  (1648, 55)\n",
      "Accuracy:  0.9791445740544362\n",
      "Person:  851\n",
      "Transitions:  [7, 8, 6, 8, 5, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.9706275033377837 0.9523241954707986 0.9950186799501868\n",
      "Num frames:  (839, 40)\n",
      "Accuracy:  0.9706275033377837\n",
      "Person:  852\n",
      "Transitions:  [5, 8, 4, 8, 1, 8, 0, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.9593023255813954 0.9303423848878394 0.9993658845909955\n",
      "Num frames:  (1694, 118)\n",
      "Accuracy:  0.9593023255813954\n",
      "Person:  853\n",
      "Transitions:  [7, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.96 0.96 0.9627507163323782\n",
      "Num frames:  (350, 1)\n",
      "Accuracy:  0.96\n",
      "Person:  854\n",
      "Transitions:  [7, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.9662576687116564 0.9662576687116564 0.9692307692307692\n",
      "Num frames:  (326, 1)\n",
      "Accuracy:  0.9662576687116564\n",
      "Person:  855\n",
      "Transitions:  [3, 8, 2, 8, 1, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.9117647058823529 0.905982905982906 0.9380530973451328\n",
      "Num frames:  (819, 77)\n",
      "Accuracy:  0.9117647058823529\n",
      "Person:  856\n",
      "Transitions:  [0, 8, 1, 8, 2, 8, 3, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.9195549850235345 0.8642611683848798 0.8725065047701648\n",
      "Num frames:  (1164, 41)\n",
      "Accuracy:  0.9195549850235345\n",
      "Person:  857\n",
      "Transitions:  [5, 8, 4, 8, 1, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.9327536231884058 0.8989547038327527 1.0\n",
      "Num frames:  (1148, 116)\n",
      "Accuracy:  0.9327536231884058\n",
      "Person:  858\n",
      "Transitions:  [0, 8, 1, 8, 2, 8, 3, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.390470297029703 0.22943722943722944 0.28545780969479356\n",
      "Num frames:  (2079, 776)\n",
      "Accuracy:  0.390470297029703\n",
      "Person:  859\n",
      "Transitions:  [7, 8, 1, 8]\n",
      "GT transitions:  1\n",
      "Transitions captured:  0\n",
      "A,P,R:  0.5121951219512195 0.7438692098092643 0.3204225352112676\n",
      "Num frames:  (367, 1)\n",
      "Accuracy:  0.5121951219512195\n",
      "Person:  860\n",
      "Transitions:  [0, 8, 1, 8, 2, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.7297175141242938 0.7628614916286149 0.7763320941759604\n",
      "Num frames:  (3285, 474)\n",
      "Accuracy:  0.7297175141242938\n",
      "Person:  861\n",
      "Transitions:  [1, 8, 4, 8, 2, 8, 3, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.8934844192634561 0.8214624881291548 1.0\n",
      "Num frames:  (1053, 188)\n",
      "Accuracy:  0.8934844192634561\n",
      "Person:  862\n",
      "Transitions:  [7, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.9969230769230769 0.9969230769230769 1.0\n",
      "Num frames:  (325, 1)\n",
      "Accuracy:  0.9969230769230769\n",
      "Person:  863\n",
      "Transitions:  [0, 8, 1, 8]\n",
      "GT transitions:  1\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.8818635607321131 0.7545454545454545 0.7490974729241877\n",
      "Num frames:  (550, 3)\n",
      "Accuracy:  0.8818635607321131\n",
      "Person:  864\n",
      "Transitions:  [7, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.9968847352024922 0.9968847352024922 1.0\n",
      "Num frames:  (321, 1)\n",
      "Accuracy:  0.9968847352024922\n",
      "Person:  865\n",
      "Transitions:  [7, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.9963503649635036 0.9963503649635036 1.0\n",
      "Num frames:  (274, 1)\n",
      "Accuracy:  0.9963503649635036\n",
      "Person:  866\n",
      "Transitions:  [5, 8, 6, 8, 7, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.8892061679040548 0.8387364921030757 1.0\n",
      "Num frames:  (1203, 194)\n",
      "Accuracy:  0.8892061679040548\n",
      "Person:  867\n",
      "Transitions:  [7, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.9963235294117647 0.9963235294117647 1.0\n",
      "Num frames:  (272, 1)\n",
      "Accuracy:  0.9963235294117647\n",
      "Person:  868\n",
      "Transitions:  [7, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.9960474308300395 0.9960474308300395 1.0\n",
      "Num frames:  (253, 1)\n",
      "Accuracy:  0.9960474308300395\n",
      "Person:  869\n",
      "Transitions:  [0, 8, 1, 8, 4, 8, 5, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.348099173553719 0.17594537815126052 0.2098997493734336\n",
      "Num frames:  (1904, 711)\n",
      "Accuracy:  0.348099173553719\n",
      "Person:  870\n",
      "Transitions:  [5, 8, 4, 8, 1, 8, 0, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.9263296993723158 0.8777412280701754 1.0\n",
      "Num frames:  (1824, 223)\n",
      "Accuracy:  0.9263296993723158\n",
      "Person:  871\n",
      "Transitions:  [0, 8, 1, 8, 4, 8, 5, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.5454916360669114 0.23534010946051603 0.296259842519685\n",
      "Num frames:  (1279, 399)\n",
      "Accuracy:  0.5454916360669114\n",
      "Person:  872\n",
      "Transitions:  [5, 8, 6, 8, 7, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.9272399278412508 0.8903985507246377 1.0\n",
      "Num frames:  (1104, 121)\n",
      "Accuracy:  0.9272399278412508\n",
      "Person:  873\n",
      "Transitions:  [7, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.9966101694915255 0.9966101694915255 1.0\n",
      "Num frames:  (295, 1)\n",
      "Accuracy:  0.9966101694915255\n",
      "Person:  874\n",
      "Transitions:  [7, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.9970238095238095 0.9970238095238095 1.0\n",
      "Num frames:  (336, 1)\n",
      "Accuracy:  0.9970238095238095\n",
      "Person:  875\n",
      "Transitions:  [1, 8, 1, 8, 2, 8, 5, 8, 6, 8, 4, 8]\n",
      "GT transitions:  5\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.4004625999686373 0.13520612081763161 0.6045442941026296\n",
      "Num frames:  (17514, 13744)\n",
      "Accuracy:  0.4004625999686373\n",
      "Person:  876\n",
      "Transitions:  [5, 8, 6, 8, 7, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.8917311124330756 0.8409490333919156 0.9989561586638831\n",
      "Num frames:  (1138, 181)\n",
      "Accuracy:  0.8917311124330756\n",
      "Person:  877\n",
      "Transitions:  [7, 8, 6, 8, 5, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.9677996422182469 0.9477317554240631 0.998960498960499\n",
      "Num frames:  (1014, 53)\n",
      "Accuracy:  0.9677996422182469\n",
      "Person:  878\n",
      "Transitions:  [2, 8, 1, 8]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GT transitions:  1\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.9781818181818182 0.9704918032786886 0.9916247906197655\n",
      "Num frames:  (610, 13)\n",
      "Accuracy:  0.9781818181818182\n",
      "Person:  879\n",
      "Transitions:  [3, 8, 2, 8, 1, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  0\n",
      "A,P,R:  0.5877502944640753 0.5245098039215687 0.3835125448028674\n",
      "Num frames:  (408, 6)\n",
      "Accuracy:  0.5877502944640753\n",
      "Person:  880\n",
      "Transitions:  [5, 8, 6, 8, 4, 8, 1, 8, 1, 8, 0, 8]\n",
      "GT transitions:  5\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.6488747836122332 0.59822263797942 0.7505868544600939\n",
      "Num frames:  (2138, 792)\n",
      "Accuracy:  0.6488747836122332\n",
      "Person:  881\n",
      "Transitions:  [5, 8, 4, 8]\n",
      "GT transitions:  1\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.9468190308757279 0.9450748978665456 1.0\n",
      "Num frames:  (8812, 484)\n",
      "Accuracy:  0.9468190308757279\n",
      "Person:  882\n",
      "Transitions:  [7, 8, 1, 8]\n",
      "GT transitions:  1\n",
      "Transitions captured:  0\n",
      "A,P,R:  0.45556594948550044 0.8730769230769231 0.2858942065491184\n",
      "Num frames:  (260, 15)\n",
      "Accuracy:  0.45556594948550044\n",
      "Person:  883\n",
      "Transitions:  [7, 8, 0, 8]\n",
      "GT transitions:  1\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.9761737911702874 0.955026455026455 0.9836512261580381\n",
      "Num frames:  (756, 22)\n",
      "Accuracy:  0.9761737911702874\n",
      "Person:  884\n",
      "Transitions:  [7, 8, 6, 8, 5, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.9758454106280193 0.9617321248741189 0.9979101358411703\n",
      "Num frames:  (993, 38)\n",
      "Accuracy:  0.9758454106280193\n",
      "Person:  885\n",
      "Transitions:  [5, 8, 6, 8, 7, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.9389788293897883 0.9075309818875119 0.9896049896049897\n",
      "Num frames:  (1049, 88)\n",
      "Accuracy:  0.9389788293897883\n",
      "Person:  886\n",
      "Transitions:  [5, 8, 4, 8, 1, 8, 0, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.9060773480662984 0.8468085106382979 0.9993722536095417\n",
      "Num frames:  (1880, 288)\n",
      "Accuracy:  0.9060773480662984\n",
      "Person:  887\n",
      "Transitions:  [3, 8, 2, 8, 1, 8, 0, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  3\n",
      "A,P,R:  0.9690493736182756 0.9618863049095607 0.9834874504623514\n",
      "Num frames:  (1548, 59)\n",
      "Accuracy:  0.9690493736182756\n",
      "Person:  888\n",
      "Transitions:  [5, 8, 6, 8, 7, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.8326732673267326 0.7684931506849315 1.0\n",
      "Num frames:  (1460, 338)\n",
      "Accuracy:  0.8326732673267326\n",
      "Person:  889\n",
      "Transitions:  [0, 8, 1, 8]\n",
      "GT transitions:  1\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.950975487743872 0.9239720713731575 1.0\n",
      "Num frames:  (1289, 98)\n",
      "Accuracy:  0.950975487743872\n",
      "Person:  890\n",
      "Transitions:  [7, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.9438596491228071 0.9438596491228071 0.9471830985915493\n",
      "Num frames:  (285, 1)\n",
      "Accuracy:  0.9438596491228071\n",
      "Person:  891\n",
      "Transitions:  [7, 8, 6, 8, 5, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.5322479649342517 0.346045197740113 0.2603613177470776\n",
      "Num frames:  (708, 51)\n",
      "Accuracy:  0.5322479649342517\n",
      "Person:  892\n",
      "Transitions:  [7, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.9577464788732394 0.9577464788732394 0.9611307420494699\n",
      "Num frames:  (284, 1)\n",
      "Accuracy:  0.9577464788732394\n",
      "Person:  893\n",
      "Transitions:  [7, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.9554317548746518 0.9554317548746518 0.9581005586592178\n",
      "Num frames:  (359, 1)\n",
      "Accuracy:  0.9554317548746518\n",
      "Person:  894\n",
      "Transitions:  [7, 8, 1, 8]\n",
      "GT transitions:  1\n",
      "Transitions captured:  0\n",
      "A,P,R:  0.512 0.640926640926641 0.31350330500472146\n",
      "Num frames:  (518, 5)\n",
      "Accuracy:  0.512\n",
      "Person:  895\n",
      "Transitions:  [7, 8, 0, 8]\n",
      "GT transitions:  1\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.9080590238365494 0.841796875 1.0\n",
      "Num frames:  (1024, 162)\n",
      "Accuracy:  0.9080590238365494\n",
      "Person:  896\n",
      "Transitions:  [0, 8, 1, 8, 4, 8, 5, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.2800268396331917 0.15396249243799154 0.21668795232013624\n",
      "Num frames:  (3306, 1379)\n",
      "Accuracy:  0.2800268396331917\n",
      "Person:  897\n",
      "Transitions:  [1, 8, 4, 8, 5, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.9003285870755751 0.8547486033519553 0.9944289693593314\n",
      "Num frames:  (1253, 176)\n",
      "Accuracy:  0.9003285870755751\n",
      "Person:  898\n",
      "Transitions:  [7, 8, 0, 8]\n",
      "GT transitions:  1\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.9380630630630631 0.89351403678606 0.9871657754010695\n",
      "Num frames:  (1033, 98)\n",
      "Accuracy:  0.9380630630630631\n",
      "Person:  899\n",
      "Transitions:  [7, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.9411764705882353 0.9411764705882353 0.9438202247191011\n",
      "Num frames:  (357, 1)\n",
      "Accuracy:  0.9411764705882353\n",
      "Person:  900\n",
      "Transitions:  [7, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.9330357142857143 0.9330357142857143 0.9372197309417041\n",
      "Num frames:  (224, 1)\n",
      "Accuracy:  0.9330357142857143\n",
      "Person:  901\n",
      "Transitions:  [7, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.9553571428571429 0.9553571428571429 0.9582089552238806\n",
      "Num frames:  (336, 1)\n",
      "Accuracy:  0.9553571428571429\n",
      "Person:  902\n",
      "Transitions:  [7, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.996309963099631 0.996309963099631 1.0\n",
      "Num frames:  (271, 1)\n",
      "Accuracy:  0.996309963099631\n",
      "Person:  903\n",
      "Transitions:  [1, 8]\n",
      "GT transitions:  0\n",
      "Transitions captured:  0\n",
      "\n",
      "A,P,R:  0.9684684684684685 0.9684684684684685 0.9728506787330317\n",
      "Num frames:  (222, 1)\n",
      "Accuracy:  0.9684684684684685\n",
      "Person:  904\n",
      "Transitions:  [5, 8, 6, 8, 7, 8]\n",
      "GT transitions:  2\n",
      "Transitions captured:  2\n",
      "A,P,R:  0.9025210084033614 0.8580750407830342 1.0\n",
      "Num frames:  (1226, 174)\n",
      "Accuracy:  0.9025210084033614\n",
      "Person:  905\n",
      "Transitions:  [0, 8, 6, 8, 6, 8, 5, 8]\n",
      "GT transitions:  3\n",
      "Transitions captured:  1\n",
      "A,P,R:  0.7384674037361799 0.5778191985088537 0.6631016042780749\n",
      "Num frames:  (1073, 371)\n",
      "Accuracy:  0.7384674037361799\n",
      "0.846079671716917\n",
      "Average (only transitions) A,P,R 0.8098379511620858 0.7470659404420188 0.8353317574307076\n",
      "Average (all targets) A,P,R,F, ttr 0.8460796717169172 0.7974448492383246 0.866643361800407 734.8300220750552 [3, 3, 7, 1, 3, 1, 5, 1, 3, 1, 1, 3, 1, 1, 5, 1, 3, 5, 5, 5, 7, 5, 1, 1, 1, 3, 3, 3, 5, 7, 3, 7, 7, 5, 7, 3, 1, 1, 5, 5, 3, 3, 7, 1, 5, 7, 1, 5, 1, 1, 7, 5, 9, 1, 7, 7, 3, 1, 5, 1, 9, 7, 7, 3, 3, 1, 5, 5, 5, 3, 3, 1, 1, 5, 5, 7, 1, 1, 7, 7, 7, 7, 5, 7, 7, 1, 1, 3, 7, 3, 5, 5, 3, 5, 1, 5, 3, 1, 5, 3, 5, 3, 1, 5, 1, 5, 3, 5, 3, 3, 1, 5, 3, 3, 5, 1, 1, 5, 5, 1, 1, 3, 3, 3, 5, 5, 5, 7, 3, 3, 1, 3, 5, 5, 3, 5, 5, 5, 5, 1, 3, 5, 7, 7, 7, 5, 5, 1, 1, 3, 5, 5, 3, 5, 5, 5, 3, 5, 5, 3, 1, 3, 5, 1, 5, 7, 3, 7, 5, 9, 9, 3, 7, 5, 5, 1, 5, 5, 3, 3, 5, 5, 5, 7, 7, 5, 5, 7, 7, 3, 1, 5, 7, 13, 5, 7, 1, 3, 5, 1, 5, 5, 5, 7, 3, 7, 3, 5, 7, 5, 3, 9, 1, 1, 3, 1, 5, 5, 5, 7, 1, 1, 5, 1, 3, 7, 1, 5, 7, 3, 1, 5, 3, 7, 9, 7, 7, 1, 1, 5, 1, 3, 3, 1, 7, 7, 7, 5, 1, 3, 1, 5, 7, 3, 7, 3, 7, 5, 7, 7, 1, 5, 5, 13, 1, 5, 5, 3, 5, 1, 5, 1, 7, 1, 7, 1, 1, 5, 3, 7, 1, 3, 5, 3, 9, 7, 3, 5, 7, 7, 3, 5, 5, 1, 5, 3, 3, 7, 5, 3, 7, 3, 9, 7, 5, 3, 5, 1, 5, 5, 1, 7, 1, 1, 5, 3, 5, 3, 3, 3, 1, 5, 7, 5, 1, 1, 5, 7, 7, 3, 3, 1, 7, 5, 1, 7, 5, 1, 1, 7, 5, 7, 3, 7, 7, 5, 5, 1, 3, 7, 1, 9, 7, 5, 5, 7, 7, 1, 5, 7, 5, 5, 5, 5, 5, 5, 7, 1, 5, 5, 7, 3, 7, 7, 1, 3, 7, 3, 7, 5, 1, 5, 3, 3, 3, 7, 5, 3, 3, 1, 5, 1, 11, 1, 1, 1, 7, 5, 7, 7, 7, 5, 7, 7, 5, 7, 3, 7, 7, 7, 3, 7, 3, 1, 9, 3, 7, 1, 5, 3, 7, 7, 5, 1, 9, 7, 3, 5, 5, 7, 7, 1, 1, 5, 13, 3, 1, 21, 7, 1, 5, 3, 3, 11, 7, 5, 3, 7, 5, 7, 7, 3, 5, 3, 3, 7, 1, 7, 5, 7, 1, 5, 5, 5, 5, 5, 7, 1, 5, 5, 5, 1, 5, 7, 7, 3, 9, 7, 7, 7, 5, 5, 1, 7, 1, 5, 7, 1, 5, 5, 3, 1, 3, 5, 5, 9, 5, 13, 5, 7, 3, 3, 7, 3, 1, 5, 7, 1, 1, 1, 7, 1, 5, 1, 1, 5, 1, 7, 5, 7, 9, 7, 1, 7, 7, 3, 5, 3, 7, 5, 5, 1, 7, 5, 1, 5, 1, 7, 1, 5, 7, 5, 1, 1, 3, 9, 7, 5, 3, 3, 5, 13, 5, 1, 1, 1, 1, 7, 5, 11, 5, 1, 3, 1, 5, 3, 7, 1, 5, 7, 5, 7, 7, 3, 1, 5, 1, 3, 7, 7, 5, 9, 5, 5, 3, 1, 3, 3, 1, 5, 55, 5, 7, 3, 7, 3, 5, 7, 5, 7, 7, 3, 3, 1, 1, 7, 5, 3, 3, 5, 1, 7, 1, 7, 1, 45, 1, 1, 9, 5, 7, 5, 7, 5, 3, 5, 7, 7, 7, 1, 3, 3, 5, 1, 1, 1, 5, 7, 5, 1, 1, 1, 1, 5, 7, 7, 5, 5, 7, 5, 3, 3, 7, 1, 3, 5, 9, 7, 7, 7, 7, 7, 5, 5, 3, 7, 7, 1, 5, 1, 5, 7, 3, 5, 3, 5, 9, 9, 5, 7, 1, 7, 3, 3, 7, 3, 7, 1, 5, 5, 5, 9, 1, 1, 3, 7, 3, 7, 7, 1, 3, 3, 1, 5, 3, 1, 5, 7, 9, 7, 1, 5, 7, 7, 1, 3, 1, 3, 7, 5, 7, 3, 5, 1, 3, 7, 5, 1, 5, 5, 13, 7, 5, 5, 5, 9, 7, 5, 7, 3, 5, 5, 7, 1, 5, 3, 5, 7, 5, 7, 5, 3, 5, 3, 9, 1, 5, 3, 1, 7, 5, 7, 5, 3, 3, 1, 7, 1, 1, 7, 5, 7, 7, 7, 5, 7, 5, 3, 9, 3, 3, 7, 5, 1, 3, 3, 1, 7, 9, 5, 1, 7, 3, 7, 7, 7, 5, 3, 3, 1, 1, 11, 7, 7, 5, 7, 7, 1, 1, 3, 3, 5, 1, 3, 1, 5, 5, 5, 5, 5, 9, 5, 3, 7, 5, 1, 7, 3, 1, 5, 3, 1, 5, 1, 5, 5, 7, 1, 5, 1, 5, 9, 3, 1, 1, 7, 1, 3, 1, 5, 7, 5, 7, 1, 1, 5, 7, 5, 7, 3, 5, 7, 1, 3, 1, 1, 5, 1, 1, 7, 7, 7, 5, 1, 1, 11, 5, 5, 3, 5, 11, 3, 3, 3, 5, 5, 7, 7, 5, 3, 1, 5, 1, 1, 3, 3, 7, 5, 3, 1, 1, 1, 1, 1, 5, 7]\n",
      "Fscore (all targets, only transitions)  0.8230185837550474 0.7795518149363945\n",
      "1988782\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8634377967711301\n",
      "0.8041431261770244\n"
     ]
    }
   ],
   "source": [
    "\n",
    "all_metric_values = []\n",
    "for epoch_i in range(1,epoch,5):\n",
    "    modelname = './models/policy_duke_semisup_gtBOX_5_' + str(epoch_i)\n",
    "    print (modelname)\n",
    "    # load model\n",
    "    policy_net.load_state_dict(torch.load(modelname)['state_dict'])\n",
    "    \n",
    "    A,P,R,F1,PCH1,PCH2 = eval_policy()\n",
    "    all_metric_values.append((epoch_i,A,P,R,F1,PCH1,PCH2))\n",
    "    \n",
    "    clear_output(wait=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1,\n",
       "  0.6697683933154539,\n",
       "  0.6232921177719772,\n",
       "  0.7173030046992717,\n",
       "  0.6501639805948773,\n",
       "  0.47708926875593544,\n",
       "  0.43565599497802887),\n",
       " (6,\n",
       "  0.8687334968867123,\n",
       "  0.8194998836021545,\n",
       "  0.9257853202475934,\n",
       "  0.863520347577358,\n",
       "  0.8629392212725545,\n",
       "  0.8072818581293157),\n",
       " (11,\n",
       "  0.8762277267412761,\n",
       "  0.8372478383826238,\n",
       "  0.9365547611369059,\n",
       "  0.8773700975464868,\n",
       "  0.8903371320037986,\n",
       "  0.8361581920903954),\n",
       " (16,\n",
       "  0.904865889557247,\n",
       "  0.8663224524608174,\n",
       "  0.9552871628776599,\n",
       "  0.9027303844704702,\n",
       "  0.9311663644996978,\n",
       "  0.8870056497175142),\n",
       " (21,\n",
       "  0.674875914016115,\n",
       "  0.6637334800578198,\n",
       "  0.7126324395221588,\n",
       "  nan,\n",
       "  0.893613485280152,\n",
       "  0.8625235404896422),\n",
       " (26,\n",
       "  0.7560918575152582,\n",
       "  0.7026388144563787,\n",
       "  0.8056474964160066,\n",
       "  0.7448448268550223,\n",
       "  0.9178803706581484,\n",
       "  0.8700564971751412),\n",
       " (31,\n",
       "  0.6790889778258731,\n",
       "  0.6131377325609578,\n",
       "  0.7148952298050733,\n",
       "  0.6539118561752812,\n",
       "  0.8825870288833251,\n",
       "  0.8392969240426867),\n",
       " (36,\n",
       "  0.8241541455501316,\n",
       "  0.7887089283162627,\n",
       "  0.8650605163839352,\n",
       "  0.8181474402927419,\n",
       "  0.9382301169338206,\n",
       "  0.9008160703075957),\n",
       " (41,\n",
       "  0.8460796717169172,\n",
       "  0.7974448492383246,\n",
       "  0.866643361800407,\n",
       "  0.8230185837550474,\n",
       "  0.8634377967711301,\n",
       "  0.8041431261770244)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_metric_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('./all_metric_values_duke_5steps', all_metric_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_metric_values_cat = {}\n",
    "all_metric_values_cat['all_metric_values'] = np.stack(all_metric_values)\n",
    "spio.savemat('../../8tb/abstraction/unsup/all_metric_values_duke_5steps.mat', all_metric_values_cat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Test function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "backup_fname = '/media/win/HRLhkl/Q_CamSel_3L_l4_st200_db3_1tCont_2'\n",
    "hkl.dump([[episode_reward, running_reward]], backup_fname+'_variables.hkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-053482d62e48>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;36m1\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m600\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "1/np.log(600*12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pp = 1\n",
    "np.max(pTest[pp][1:,1] - pTest[pp][0:-1,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
